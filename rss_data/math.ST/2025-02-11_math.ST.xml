<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.ST updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.ST</link>
    <description>math.ST updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.ST" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 12 Feb 2025 02:55:09 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Distribution of singular values in large sample cross-covariance matrices</title>
      <link>https://arxiv.org/abs/2502.05254</link>
      <description>arXiv:2502.05254v1 Announce Type: new 
Abstract: For two large matrices ${\mathbf X}$ and ${\mathbf Y}$ with Gaussian i.i.d.\ entries and dimensions $T\times N_X$ and $T\times N_Y$, respectively, we derive the probability distribution of the singular values of $\mathbf{X}^T \mathbf{Y}$ in different parameter regimes. This extends the Marchenko-Pastur result for the distribution of eigenvalues of empirical sample covariance matrices to singular values of empirical cross-covariances. Our results will help to establish statistical significance of cross-correlations in many data-science applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05254v1</guid>
      <category>math.ST</category>
      <category>cond-mat.dis-nn</category>
      <category>physics.data-an</category>
      <category>stat.TH</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arabind Swain, Sean Alexander Ridout, Ilya Nemenman</dc:creator>
    </item>
    <item>
      <title>An effective estimation of multivariate density functions using extended-beta kernels with Bayesian adaptive bandwidths</title>
      <link>https://arxiv.org/abs/2502.05366</link>
      <description>arXiv:2502.05366v1 Announce Type: new 
Abstract: Multivariate kernel density estimations have received much spate of interest. In addition to conventional methods of (non-)classical associated-kernels for (un)bounded densities and bandwidth selections, the multiple extended-beta kernel (MEBK) estimators with Bayesian adaptive bandwidths are invested to gain a deeper and better insight into the estimation of multivariate density functions. Being unimodal, the univariate extended-beta smoother has an adaptable compact support which is suitable for each dataset, always limited. The support of the density MBEK estimator can be known or estimated by extreme values. Thus, asymptotical properties for the (non-)normalized estimators are established. Explicit and general choices of bandwidths using the flexible Bayesian adaptive method are provided. Behavioural analyses, specifically undertaken on the sensitive edges of the estimator support, are studied and compared to Gaussian and gamma kernel estimators. Finally, simulation studies and three applications on original and usual real-data sets of the proposed method yielded very interesting advantages with respect to its flexibility as well as its universality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05366v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Sobom M. Som\'e, C\'elestin C. Kokonendji, Francial G. B. Libengu\'e Dob\'el\'e-Kpoka</dc:creator>
    </item>
    <item>
      <title>Multi-Scale Conformal Prediction: A Theoretical Framework with Coverage Guarantees</title>
      <link>https://arxiv.org/abs/2502.05565</link>
      <description>arXiv:2502.05565v1 Announce Type: new 
Abstract: We propose a multi-scale extension of conformal prediction, an approach that constructs prediction sets with finite-sample coverage guarantees under minimal statistical assumptions. Classic conformal prediction relies on a single notion of conformity, overlooking the multi-level structures that arise in applications such as image analysis, hierarchical data exploration, and multi-resolution time series modeling. In contrast, the proposed framework defines a distinct conformity function at each relevant scale or resolution, producing multiple conformal predictors whose prediction sets are then intersected to form the final multi-scale output. We establish theoretical results confirming that the multi-scale prediction set retains the marginal coverage guarantees of the original conformal framework and can, in fact, yield smaller or more precise sets in practice. By distributing the total miscoverage probability across scales in proportion to their informative power, the method further refines the set sizes. We also show that dependence between scales can lead to conservative coverage, ensuring that the actual coverage exceeds the nominal level. Numerical experiments in a synthetic classification setting demonstrate that multi-scale conformal prediction achieves or surpasses the nominal coverage level while generating smaller prediction sets compared to single-scale conformal methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05565v1</guid>
      <category>math.ST</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>stat.TH</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ali Baheri, Marzieh Amiri Shahbazi</dc:creator>
    </item>
    <item>
      <title>Attainability of Two-Point Testing Rates for Finite-Sample Location Estimation</title>
      <link>https://arxiv.org/abs/2502.05730</link>
      <description>arXiv:2502.05730v1 Announce Type: new 
Abstract: LeCam's two-point testing method yields perhaps the simplest lower bound for estimating the mean of a distribution: roughly, if it is impossible to well-distinguish a distribution centered at $\mu$ from the same distribution centered at $\mu+\Delta$, then it is impossible to estimate the mean by better than $\Delta/2$. It is setting-dependent whether or not a nearly matching upper bound is attainable. We study the conditions under which the two-point testing lower bound can be attained for univariate mean estimation; both in the setting of location estimation (where the distribution is known up to translation) and adaptive location estimation (unknown distribution). Roughly, we will say an estimate nearly attains the two-point testing lower bound if it incurs error that is at most polylogarithmically larger than the Hellinger modulus of continuity for $\tilde{\Omega}(n)$ samples.
  Adaptive location estimation is particularly interesting as some distributions admit much better guarantees than sub-Gaussian rates (e.g. $\operatorname{Unif}(\mu-1,\mu+1)$ permits error $\Theta(\frac{1}{n})$, while the sub-Gaussian rate is $\Theta(\frac{1}{\sqrt{n}})$), yet it is not obvious whether these rates may be adaptively attained by one unified approach. Our main result designs an algorithm that nearly attains the two-point testing rate for mixtures of symmetric, log-concave distributions with a common mean. Moreover, this algorithm runs in near-linear time and is parameter-free. In contrast, we show the two-point testing rate is not nearly attainable even for symmetric, unimodal distributions.
  We complement this with results for location estimation, showing the two-point testing rate is nearly attainable for unimodal distributions, but unattainable for symmetric distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05730v1</guid>
      <category>math.ST</category>
      <category>cs.DS</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Spencer Compton, Gregory Valiant</dc:creator>
    </item>
    <item>
      <title>Fixed-strength spherical designs</title>
      <link>https://arxiv.org/abs/2502.06002</link>
      <description>arXiv:2502.06002v1 Announce Type: new 
Abstract: A spherical $t$-design is a finite subset $X$ of the unit sphere such that every polynomial of degree at most $t$ has the same average over $X$ as it does over the entire sphere. Determining the minimum possible size of spherical designs, especially in a fixed dimension as $t \to \infty$, has been an important research topic for several decades. This paper presents results on the complementary asymptotic regime, where $t$ is fixed and the dimension tends to infinity. We combine techniques from algebra, geometry, and probability to prove upper bounds on the size of designs, including an optimal bound for signed spherical designs. We also prove lower and upper bounds for approximate designs and establish an explicit connection between spherical and Gaussian designs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06002v1</guid>
      <category>math.ST</category>
      <category>math.MG</category>
      <category>stat.TH</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Travis Dillon</dc:creator>
    </item>
    <item>
      <title>Robust estimation with latin hypercube sampling: a central limit theorem for Z-estimators</title>
      <link>https://arxiv.org/abs/2502.06321</link>
      <description>arXiv:2502.06321v1 Announce Type: new 
Abstract: Latin hypercube sampling (LHS) is a stratified samplingmethod widely used in computer experiments. In thiswork, we extend convergence results on the sample meanwith Latin hypercube sampling to the class of Z -estimators,gathering all estimators that can be written as zeros of asample mean function. In particular, the asymptotic vari-ance of this estimate is obtained. This asymptotic vari-ance is shown to be lower using LHS than using classicindependent and identically distributed sampling. A Cen-tral Limit theorem for Z -estimators under LHS is alsogiven.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06321v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Faouzi Hakimi (UT3)</dc:creator>
    </item>
    <item>
      <title>Fractional interacting particle system: drift parameter estimation via Malliavin calculus</title>
      <link>https://arxiv.org/abs/2502.06514</link>
      <description>arXiv:2502.06514v1 Announce Type: new 
Abstract: We address the problem of estimating the drift parameter in a system of $N$ interacting particles driven by additive fractional Brownian motion of Hurst index \( H \geq 1/2 \). Considering continuous observation of the interacting particles over a fixed interval \([0, T]\), we examine the asymptotic regime as \( N \to \infty \). Our main tool is a random variable reminiscent of the least squares estimator but unobservable due to its reliance on the Skorohod integral. We demonstrate that this object is consistent and asymptotically normal by establishing a quantitative propagation of chaos for Malliavin derivatives, which holds for any \( H \in (0,1) \). Leveraging a connection between the divergence integral and the Young integral, we construct computable estimators of the drift parameter. These estimators are shown to be consistent and asymptotically Gaussian. Finally, a numerical study highlights the strong performance of the proposed estimators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06514v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chiara Amorino, Ivan Nourdin, Radomyra Shevchenko</dc:creator>
    </item>
    <item>
      <title>Covariates-Adjusted Mixed-Membership Estimation: A Novel Network Model with Optimal Guarantees</title>
      <link>https://arxiv.org/abs/2502.06671</link>
      <description>arXiv:2502.06671v1 Announce Type: new 
Abstract: This paper addresses the problem of mixed-membership estimation in networks, where the goal is to efficiently estimate the latent mixed-membership structure from the observed network. Recognizing the widespread availability and valuable information carried by node covariates, we propose a novel network model that incorporates both community information, as represented by the Degree-Corrected Mixed Membership (DCMM) model, and node covariate similarities to determine connections.
  We investigate the regularized maximum likelihood estimation (MLE) for this model and demonstrate that our approach achieves optimal estimation accuracy for both the similarity matrix and the mixed-membership, in terms of both the Frobenius norm and the entrywise loss. Since directly analyzing the original convex optimization problem is intractable, we employ nonconvex optimization to facilitate the analysis. A key contribution of our work is identifying a crucial assumption that bridges the gap between convex and nonconvex solutions, enabling the transfer of statistical guarantees from the nonconvex approach to its convex counterpart. Importantly, our analysis extends beyond the MLE loss and the mean squared error (MSE) used in matrix completion problems, generalizing to all the convex loss functions. Consequently, our analysis techniques extend to a broader set of applications, including ranking problems based on pairwise comparisons.
  Finally, simulation experiments validate our theoretical findings, and real-world data analyses confirm the practical relevance of our model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06671v1</guid>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jianqing Fan, Jiawei Ge, Jikai Hou</dc:creator>
    </item>
    <item>
      <title>Neumann eigenmaps for landmark embedding</title>
      <link>https://arxiv.org/abs/2502.06689</link>
      <description>arXiv:2502.06689v1 Announce Type: new 
Abstract: We present Neumann eigenmaps (NeuMaps), a novel approach for enhancing the standard diffusion map embedding using landmarks, i.e distinguished samples within the dataset. By interpreting these landmarks as a subgraph of the larger data graph, NeuMaps are obtained via the eigendecomposition of a renormalized Neumann Laplacian. We show that NeuMaps offer two key advantages: (1) they provide a computationally efficient embedding that accurately recovers the diffusion distance associated with the reflecting random walk on the subgraph, and (2) they naturally incorporate the Nystr\"om extension within the diffusion map framework through the discrete Neumann boundary condition. Through examples in digit classification and molecular dynamics, we demonstrate that NeuMaps not only improve upon existing landmark-based embedding methods but also enhance the stability of diffusion map embeddings to the removal of highly significant points.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06689v1</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shashank Sule, Wojciech Czaja</dc:creator>
    </item>
    <item>
      <title>Are all models wrong? Fundamental limits in distribution-free empirical model falsification</title>
      <link>https://arxiv.org/abs/2502.06765</link>
      <description>arXiv:2502.06765v1 Announce Type: new 
Abstract: In statistics and machine learning, when we train a fitted model on available data, we typically want to ensure that we are searching within a model class that contains at least one accurate model -- that is, we would like to ensure an upper bound on the model class risk (the lowest possible risk that can be attained by any model in the class). However, it is also of interest to establish lower bounds on the model class risk, for instance so that we can determine whether our fitted model is at least approximately optimal within the class, or, so that we can decide whether the model class is unsuitable for the particular task at hand. Particularly in the setting of interpolation learning where machine learning models are trained to reach zero error on the training data, we might ask if, at the very least, a positive lower bound on the model class risk is possible -- or are we unable to detect that "all models are wrong"? In this work, we answer these questions in a distribution-free setting by establishing a model-agnostic, fundamental hardness result for the problem of constructing a lower bound on the best test error achievable over a model class, and examine its implications on specific model classes such as tree-based methods and linear regression.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06765v1</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Manuel M. M\"uller, Yuetian Luo, Rina Foygel Barber</dc:creator>
    </item>
    <item>
      <title>Tropical Fr\'echet Means</title>
      <link>https://arxiv.org/abs/2502.05322</link>
      <description>arXiv:2502.05322v1 Announce Type: cross 
Abstract: The Fr\'echet mean is a key measure of central tendency as a barycenter for a given set of points in a general metric space. It is computed by solving an optimization problem and is a fundamental quantity in statistics. In this paper, we study Fr\'echet means in tropical geometry -- a piecewise linear, combinatorial, and polyhedral variant of algebraic geometry that has gained prominence in applications. A key property of Fr\'echet means is that uniqueness is generally not guaranteed, which is true in tropical settings. In solving the tropical Fr\'echet mean optimization problem, we obtain a geometric characterization of the collection of all Fr\'echet means in a general tropical space as a tropically and classically convex polytope. Furthermore, we prove that a certificate of positivity for finitely many quadratic polynomials in $\mathbb{R}[x_1,\ldots,x_n]$ always exists, given that their quadratic homogeneous components are sums of squares. We propose an algorithm to symbolically compute the Fr\'echet mean polytope based on our exact quadratic optimization result and study its complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05322v1</guid>
      <category>math.OC</category>
      <category>math.CO</category>
      <category>math.MG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bo Lin, Kamillo Ferry, Carlos Am\'endola, Anthea Monod, Ruriko Yoshida</dc:creator>
    </item>
    <item>
      <title>False Discovery Rate Control via Frequentist-assisted Horseshoe</title>
      <link>https://arxiv.org/abs/2502.05460</link>
      <description>arXiv:2502.05460v1 Announce Type: cross 
Abstract: The horseshoe prior, a widely used handy alternative to the spike-and-slab prior, has proven to be an exceptional default global-local shrinkage prior in Bayesian inference and machine learning. However, designing tests with frequentist false discovery rate (FDR) control using the horseshoe prior or the general class of global-local shrinkage priors remains an open problem. In this paper, we propose a frequentist-assisted horseshoe procedure that not only resolves this long-standing FDR control issue for the high dimensional normal means testing problem but also exhibits satisfactory finite-sample FDR control under any desired nominal level for both large-scale multiple independent and correlated tests. We carry out the frequentist-assisted horseshoe procedure in an easy and intuitive way by using the minimax estimator of the global parameter of the horseshoe prior while maintaining the remaining full Bayes vanilla horseshoe structure. The results of both intensive simulations under different sparsity levels, and real-world data demonstrate that the frequentist-assisted horseshoe procedure consistently achieves robust finite-sample FDR control. Existing frequentist or Bayesian FDR control procedures can lose finite-sample FDR control in a variety of common sparse cases. Based on the intimate relationship between the minimax estimation and the level of FDR control discovered in this work, we point out potential generalizations to achieve FDR control for both more complicated models and the general global-local shrinkage prior family.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05460v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qiaoyu Liang, Zihan Zhu, Ziang Fu, Michael Evans, Jinman Zhao</dc:creator>
    </item>
    <item>
      <title>Kernel Smoothing for Bounded Copula Densities</title>
      <link>https://arxiv.org/abs/2502.05470</link>
      <description>arXiv:2502.05470v1 Announce Type: cross 
Abstract: Nonparametric estimation of copula density functions using kernel estimators presents significant challenges. One issue is the potential unboundedness of certain copula density functions at the corners of the unit square. Another is the boundary bias inherent in kernel density estimation. This paper presents a kernel-based method for estimating bounded copula density functions, addressing boundary bias through the mirror-reflection technique. Optimal smoothing parameters are derived via Asymptotic Mean Integrated Squared Error (AMISE) minimization and cross-validation, with theoretical guarantees of consistency and asymptotic normality. Two kernel smoothing strategies are proposed: the rule-of-thumb approach and least squares cross-validation (LSCV). Simulation studies highlight the efficacy of the rule-of-thumb method in bandwidth selection for copulas with unbounded marginal supports. The methodology is further validated through an application to the Wisconsin Breast Cancer Diagnostic Dataset (WBCDD), where LSCV is used for bandwidth selection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05470v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mathias N. Muia, Olivia Atutey, Mahmud Hasan</dc:creator>
    </item>
    <item>
      <title>Mixing Time of the Proximal Sampler in Relative Fisher Information via Strong Data Processing Inequality</title>
      <link>https://arxiv.org/abs/2502.05623</link>
      <description>arXiv:2502.05623v1 Announce Type: cross 
Abstract: We study the mixing time guarantee for sampling in relative Fisher information via the Proximal Sampler algorithm, which is an approximate proximal discretization of the Langevin dynamics. We show that when the target probability distribution is strongly log-concave, the relative Fisher information converges exponentially fast along the Proximal Sampler; this matches the exponential convergence rate of the relative Fisher information along the continuous-time Langevin dynamics for strongly log-concave target. When combined with a standard implementation of the Proximal Sampler via rejection sampling, this exponential convergence rate provides a high-accuracy iteration complexity guarantee for the Proximal Sampler in relative Fisher information when the target distribution is strongly log-concave and log-smooth. Our proof proceeds by establishing a strong data processing inequality for relative Fisher information along the Gaussian channel under strong log-concavity, and a data processing inequality along the reverse Gaussian channel for a special distribution. The forward and reverse Gaussian channels compose to form the Proximal Sampler, and these data processing inequalities imply the exponential convergence rate of the relative Fisher information along the Proximal Sampler.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05623v1</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andre Wibisono</dc:creator>
    </item>
    <item>
      <title>Asymptotic FDR Control with Model-X Knockoffs: Is Moments Matching Sufficient?</title>
      <link>https://arxiv.org/abs/2502.05969</link>
      <description>arXiv:2502.05969v1 Announce Type: cross 
Abstract: We propose a unified theoretical framework for studying the robustness of the model-X knockoffs framework by investigating the asymptotic false discovery rate (FDR) control of the practically implemented approximate knockoffs procedure. This procedure deviates from the model-X knockoffs framework by substituting the true covariate distribution with a user-specified distribution that can be learned using in-sample observations. By replacing the distributional exchangeability condition of the model-X knockoff variables with three conditions on the approximate knockoff statistics, we establish that the approximate knockoffs procedure achieves the asymptotic FDR control. Using our unified framework, we further prove that an arguably most popularly used knockoff variable generation method--the Gaussian knockoffs generator based on the first two moments matching--achieves the asymptotic FDR control when the two-moment-based knockoff statistics are employed in the knockoffs inference procedure. For the first time in the literature, our theoretical results justify formally the effectiveness and robustness of the Gaussian knockoffs generator. Simulation and real data examples are conducted to validate the theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05969v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yingying Fan, Lan Gao, Jinchi Lv, Xiaocong Xu</dc:creator>
    </item>
    <item>
      <title>Nearly Optimal Sample Complexity of Offline KL-Regularized Contextual Bandits under Single-Policy Concentrability</title>
      <link>https://arxiv.org/abs/2502.06051</link>
      <description>arXiv:2502.06051v1 Announce Type: cross 
Abstract: KL-regularized policy optimization has become a workhorse in learning-based decision making, while its theoretical understanding is still very limited. Although recent progress has been made towards settling the sample complexity of KL-regularized contextual bandits, existing sample complexity bounds are either $\tilde{O}(\epsilon^{-2})$ under single-policy concentrability or $\tilde{O}(\epsilon^{-1})$ under all-policy concentrability. In this paper, we propose the \emph{first} algorithm with $\tilde{O}(\epsilon^{-1})$ sample complexity under single-policy concentrability for offline contextual bandits. Our algorithm is designed for general function approximation and based on the principle of \emph{pessimism in the face of uncertainty}. The core of our proof leverages the strong convexity of the KL regularization, and the conditional non-negativity of the gap between the true reward and its pessimistic estimator to refine a mean-value-type risk upper bound to its extreme. This in turn leads to a novel covariance-based analysis, effectively bypassing the need for uniform control over the discrepancy between any two functions in the function class. The near-optimality of our algorithm is demonstrated by an $\tilde{\Omega}(\epsilon^{-1})$ lower bound. Furthermore, we extend our algorithm to contextual dueling bandits and achieve a similar nearly optimal sample complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06051v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qingyue Zhao, Kaixuan Ji, Heyang Zhao, Tong Zhang, Quanquan Gu</dc:creator>
    </item>
    <item>
      <title>Nonasymptotic and distribution-uniform Koml\'os-Major-Tusn\'ady approximation</title>
      <link>https://arxiv.org/abs/2502.06188</link>
      <description>arXiv:2502.06188v1 Announce Type: cross 
Abstract: We present nonasymptotic concentration inequalities for sums of independent and identically distributed random variables that yield asymptotic strong Gaussian approximations of Koml\'os, Major, and Tusn\'ady (KMT) [1975,1976]. The constants appearing in our inequalities are either universal or explicit, and thus as corollaries, they imply distribution-uniform generalizations of the aforementioned KMT approximations. In particular, it is shown that uniform integrability of a random variable's $q^{\text{th}}$ moment is both necessary and sufficient for the KMT approximations to hold uniformly at the rate of $o(n^{1/q})$ for $q &gt; 2$ and that having a uniformly lower bounded Sakhanenko parameter -- equivalently, a uniformly upper-bounded Bernstein parameter -- is both necessary and sufficient for the KMT approximations to hold uniformly at the rate of $O(\log n)$. Instantiating these uniform results for a single probability space yields the analogous results of KMT exactly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06188v1</guid>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ian Waudby-Smith, Martin Larsson, Aaditya Ramdas</dc:creator>
    </item>
    <item>
      <title>Revisiting Optimal Proportions for Binary Responses: Insights from Incorporating the Absent Perspective of Type-I Error Rate Control</title>
      <link>https://arxiv.org/abs/2502.06381</link>
      <description>arXiv:2502.06381v1 Announce Type: cross 
Abstract: This work revisits optimal response-adaptive designs from a type-I error rate perspective, highlighting when and how much these allocations exacerbate type-I error rate inflation - an issue previously undocumented. We explore a range of approaches from the literature that can be applied to reduce type-I error rate inflation. However, we found that all of these approaches fail to give a robust solution to the problem. To address this, we derive two optimal proportions, incorporating the more robust score test (instead of the Wald test) with finite sample estimators (instead of the unknown true values) in the formulation of the optimization problem. One proportion optimizes statistical power and the other minimizes the total number failures in a trail while maintaining a predefined power level. Through simulations based on an early-phase and a confirmatory trial we provide crucial practical insight into how these new optimal proportion designs can offer substantial patient outcomes advantages while controlling type-I error rate. While we focused on binary outcomes, the framework offers valuable insights that naturally extend to other outcome types, multi-armed trials and alternative measures of interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06381v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lukas Pin, Sof\'ia S. Villar, William F. Rosenberger</dc:creator>
    </item>
    <item>
      <title>Inference on the cointegration and the attractor spaces via functional approximation</title>
      <link>https://arxiv.org/abs/2502.06462</link>
      <description>arXiv:2502.06462v1 Announce Type: cross 
Abstract: This paper discusses semiparametric inference on hypotheses on the cointegration and the attractor spaces for I(1) linear processes, using canonical correlation analysis and functional approximation of Brownian Motions. It proposes inference criteria based on the estimation of the number of common trends in various subsets of variables, and compares them to sequences of tests of hypotheses. The exact limit distribution for one of the test statistics is derived in the univariate case. Properties of the inferential tools are discussed theoretically and illustrated via a Monte Carlo study. An empirical analysis of exchange rates is also included.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06462v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Massimo Franchi, Paolo Paruolo</dc:creator>
    </item>
    <item>
      <title>Robust Scatter Matrix Estimation for Elliptical Distributions in Polynomial Time</title>
      <link>https://arxiv.org/abs/2502.06564</link>
      <description>arXiv:2502.06564v1 Announce Type: cross 
Abstract: We study the problem of computationally efficient robust estimation of scatter matrices of elliptical distributions under the strong contamination model. We design polynomial time algorithms that achieve dimension-independent error in Frobenius norm.
  Our first result is a sequence of efficient algorithms that approaches nearly optimal error. Specifically, under a mild assumption on the eigenvalues of the scatter matrix $\Sigma$, for every $t \in \mathbb{N}$, we design an estimator that, given $n = d^{O(t)}$ samples, in time $n^{O(t)}$ finds $\hat{\Sigma}$ such that $ \Vert{\Sigma^{-1/2}\, ({\hat{\Sigma} - \Sigma})\, \Sigma^{-1/2}}\Vert_{\text{F}} \le O(t \cdot \varepsilon^{1-\frac{1}{t}})$, where $\varepsilon$ is the fraction of corruption. We do not require any assumptions on the moments of the distribution, while all previously known computationally efficient algorithms for robust covariance/scatter estimation with dimension-independent error rely on strong assumptions on the moments, such as sub-Gaussianity or (certifiable) hypercontractivity.
  Furthermore, under a stronger assumption on the eigenvalues of $\Sigma$ (that, in particular, is satisfied by all matrices with constant condition number),
  we provide a fast (sub-quadratic in the input size) algorithm that, given nearly optimal number of samples $n = \tilde{O}(d^2/\varepsilon)$, in time $\tilde{O}({nd^2 poly(1/\varepsilon)})$ finds $\hat{\Sigma}$ such that $\Vert\hat{\Sigma} - \Sigma\Vert_{\text{F}} \le O(\Vert{\Sigma}\Vert \cdot \sqrt{\varepsilon})$.
  Our approach is based on robust covariance estimation of the spatial sign (the projection onto the sphere of radius $\sqrt{d}$) of elliptical distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06564v1</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gleb Novikov</dc:creator>
    </item>
    <item>
      <title>Gaussian Approximation and Multiplier Bootstrap for Stochastic Gradient Descent</title>
      <link>https://arxiv.org/abs/2502.06719</link>
      <description>arXiv:2502.06719v1 Announce Type: cross 
Abstract: In this paper, we establish non-asymptotic convergence rates in the central limit theorem for Polyak-Ruppert-averaged iterates of stochastic gradient descent (SGD). Our analysis builds on the result of the Gaussian approximation for nonlinear statistics of independent random variables of Shao and Zhang (2022). Using this result, we prove the non-asymptotic validity of the multiplier bootstrap for constructing the confidence sets for the optimal solution of an optimization problem. In particular, our approach avoids the need to approximate the limiting covariance of Polyak-Ruppert SGD iterates, which allows us to derive approximation rates in convex distance of order up to $1/\sqrt{n}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06719v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marina Sheshukova, Sergey Samsonov, Denis Belomestny, Eric Moulines, Qi-Man Shao, Zhuo-Song Zhang, Alexey Naumov</dc:creator>
    </item>
    <item>
      <title>Learning an Optimal Assortment Policy under Observational Data</title>
      <link>https://arxiv.org/abs/2502.06777</link>
      <description>arXiv:2502.06777v1 Announce Type: cross 
Abstract: We study the fundamental problem of offline assortment optimization under the Multinomial Logit (MNL) model, where sellers must determine the optimal subset of the products to offer based solely on historical customer choice data. While most existing approaches to learning-based assortment optimization focus on the online learning of the optimal assortment through repeated interactions with customers, such exploration can be costly or even impractical in many real-world settings. In this paper, we consider the offline learning paradigm and investigate the minimal data requirements for efficient offline assortment optimization. To this end, we introduce Pessimistic Rank-Breaking (PRB), an algorithm that combines rank-breaking with pessimistic estimation. We prove that PRB is nearly minimax optimal by establishing the tight suboptimality upper bound and a nearly matching lower bound. This further shows that "optimal item coverage" - where each item in the optimal assortment appears sufficiently often in the historical data - is both sufficient and necessary for efficient offline learning. This significantly relaxes the previous requirement of observing the complete optimal assortment in the data. Our results provide fundamental insights into the data requirements for offline assortment optimization under the MNL model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06777v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuxuan Han, Han Zhong, Miao Lu, Jose Blanchet, Zhengyuan Zhou</dc:creator>
    </item>
    <item>
      <title>Characterizing Dependence of Samples along the Langevin Dynamics and Algorithms via Contraction of $\Phi$-Mutual Information</title>
      <link>https://arxiv.org/abs/2402.17067</link>
      <description>arXiv:2402.17067v2 Announce Type: replace 
Abstract: The mixing time of a Markov chain determines how fast the iterates of the Markov chain converge to the stationary distribution; however, it does not control the dependencies between samples along the Markov chain. In this paper, we study the question of how fast the samples become approximately independent along popular Markov chains for continuous-space sampling: the Langevin dynamics in continuous time, and the Unadjusted Langevin Algorithm and the Proximal Sampler in discrete time. We measure the dependence between samples via $\Phi$-mutual information, which is a broad generalization of the standard mutual information, and which is equal to $0$ if and only if the the samples are independent. We show that along these Markov chains, the $\Phi$-mutual information between the first and the $k$-th iterate decreases to $0$ exponentially fast in $k$ when the target distribution is strongly log-concave. Our proof technique is based on showing the Strong Data Processing Inequalities (SDPIs) hold along the Markov chains. To prove fast mixing of the Markov chains, we only need to show the SDPIs hold for the stationary distribution. In contrast, to prove the contraction of $\Phi$-mutual information, we need to show the SDPIs hold along the entire trajectories of the Markov chains; we prove this when the iterates along the Markov chains satisfy the corresponding $\Phi$-Sobolev inequality, which is implied by the strong log-concavity of the target distribution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.17067v2</guid>
      <category>math.ST</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiaming Liang, Siddharth Mitra, Andre Wibisono</dc:creator>
    </item>
    <item>
      <title>Randomization-based confidence sets for the local average treatment effect</title>
      <link>https://arxiv.org/abs/2404.18786</link>
      <description>arXiv:2404.18786v3 Announce Type: replace 
Abstract: We consider the problem of generating confidence sets in randomized experiments with noncompliance. We show that a refinement of a randomization-based procedure proposed by Imbens and Rosenbaum (2005) has desirable properties. Namely, we show that using a studentized Anderson--Rubin-type statistic as a test statistic yields confidence sets that are finite-sample exact under treatment effect homogeneity, and remain asymptotically valid for the Local Average Treatment Effect when the treatment effect is heterogeneous. We provide a uniform analysis of this procedure and efficient algorithms to construct the confidence set.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18786v3</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>P. M. Aronow, Haoge Chang, Patrick Lopatto</dc:creator>
    </item>
    <item>
      <title>Minimax rates in variance and covariance changepoint testing</title>
      <link>https://arxiv.org/abs/2405.07757</link>
      <description>arXiv:2405.07757v2 Announce Type: replace 
Abstract: We study the detection of a change in the covariance matrix of $n$ independent sub-Gaussian random variables of dimension $p$. Our first contribution is to show that $\log\log(8n)$ is the exact minimax testing rate for a change in variance when $p=1$, thereby giving a complete characterization of the problem for univariate data. Our second contribution is to derive a lower bound on the minimax testing rate under the operator norm, taking a certain notion of sparsity into account. In the low- to moderate-dimensional region of the parameter space, we are able to match the lower bound from above with an optimal test based on sparse eigenvalues. In the remaining region of the parameter space, where the dimensionality is high, the minimax lower bound implies that changepoint testing is very difficult. As our third contribution, we propose a computationally feasible variant of the optimal multivariate test for a change in covariance, which is also adaptive to the nominal noise level and the sparsity level of the change.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07757v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Per August Jarval Moen</dc:creator>
    </item>
    <item>
      <title>Marchenko-Pastur law for Daniell smoothed periodograms without simultaneous diagonalizability</title>
      <link>https://arxiv.org/abs/2408.14618</link>
      <description>arXiv:2408.14618v4 Announce Type: replace 
Abstract: The eigenvectors of a spectral density matrix $F(\theta)$ to a stationary Gaussian process $(X_t)_{t \in \mathbb{Z}}$ depend explicitly on the frequency $\theta \in [0,2\pi]$. The most commonly used estimator of the spectral density matrix $F(\theta)$ is the Daniell smoothed periodogram, which takes the form $BB^*$ for random matrices $B$ with non-zero covariance between rows and columns. When the covariance matrices of the columns are not simultaneously diagonalizable, this covariance structure is non-separable and such matrices $BB^*$ are out of reach for the current state of random matrix theory. In this paper, we derive a Marchenko-Pastur law in this non-simultaneously diagonalizable case. The Marchenko-Pastur law emerges when the dimension $d$ of the process and the smoothing span $m$ of the smoothed periodogram grow at the same rate, which is slower than the number of observations $n$.
  On the technical level we prove a trace moment bound for matrices $YY^T$, where $Y$ is a matrix with correlated Gaussian entries. This allows for sub-polynomial error bounds in settings where the error $Y$ has correlations between different points in time as well as between features.
  In the regime $d \asymp m \asymp n^{\alpha}$ for $\alpha \in (\frac{1}{2},1)$ we expand our result to the non-Gaussian case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.14618v4</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ben Deitmar</dc:creator>
    </item>
    <item>
      <title>Generalized Linear Models with 1-Bit Measurements: Asymptotics of the Maximum Likelihood Estimator</title>
      <link>https://arxiv.org/abs/2501.04937</link>
      <description>arXiv:2501.04937v2 Announce Type: replace 
Abstract: This work establishes regularity conditions for consistency and asymptotic normality of the multiple parameter maximum likelihood estimator(MLE) from censored data, where the censoring mechanism is in the form of $1$-bit measurements. The underlying distribution of the uncensored data is assumed to belong to the exponential family, with natural parameters expressed as a linear combination of the predictors, known as generalized linear model (GLM). As part of the analysis, the Fisher information matrix is also derived for both censored and uncensored data, which helps to quantify the impact of censoring and assess the performance of the MLE. The choice of GLM allows one to consider a variety of practical examples where 1-bit estimation is of interest. In particular, it is shown how the derived results can be used to analyze two practically relevant scenarios: the Gaussian model with both unknown mean and variance, and the Poisson model with an unknown mean.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04937v2</guid>
      <category>math.ST</category>
      <category>cs.SY</category>
      <category>eess.AS</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <category>stat.TH</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jaimin Shah, Martina Cardone, Cynthia Rush, Alex Dytso</dc:creator>
    </item>
    <item>
      <title>Fundamentals of non-parametric statistical inference for integrated quantiles</title>
      <link>https://arxiv.org/abs/2501.17722</link>
      <description>arXiv:2501.17722v2 Announce Type: replace 
Abstract: We present a general non-parametric statistical inference theory for integrals of quantiles without assuming any specific sampling design or dependence structure. Technical considerations are accompanied by examples and discussions, including those pertaining to the bias of empirical estimators. To illustrate how the general results can be adapted to specific situations, we derive - at a stroke and under minimal conditions - consistency and asymptotic normality of the empirical tail-value-at-risk, Lorenz and Gini curves at any probability level in the case of the simple random sampling, thus facilitating a comparison of our results with what is already known in the literature. Results, notes and references concerning dependent (i.e., time series) data are also offered. As a by-product, our general results provide new and unified proofs of large-sample properties of a number of classical statistical estimators, such as trimmed means, and give additional insights into the origins of, and the reasons for, various necessary and sufficient conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.17722v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nadezhda Gribkova, Mengqi Wang, Ri\v{c}ardas Zitikis</dc:creator>
    </item>
    <item>
      <title>Rate of convergence of the smoothed empirical Wasserstein distance</title>
      <link>https://arxiv.org/abs/2205.02128</link>
      <description>arXiv:2205.02128v4 Announce Type: replace-cross 
Abstract: Consider an empirical measure $\mathbb{P}_n$ induced by $n$ iid samples from a $d$-dimensional $K$-subgaussian distribution $\mathbb{P}$ and let $\gamma = N(0,\sigma^2 I_d)$ be the isotropic Gaussian measure. We study the speed of convergence of the smoothed Wasserstein distance $W_2(\mathbb{P}_n * \gamma, \mathbb{P}*\gamma) = n^{-\alpha + o(1)}$ with $*$ being the convolution of measures. For $K&lt;\sigma$ and in any dimension $d\ge 1$ we show that $\alpha = {1\over2}$. For $K&gt;\sigma$ in dimension $d=1$ we show that the rate is slower and is given by $\alpha = {(\sigma^2 + K^2)^2\over 4 (\sigma^4 + K^4)} &lt; 1/2$. This resolves several open problems in [GGNWP20], and in particular precisely identifies the amount of smoothing $\sigma$ needed to obtain a parametric rate. In addition, for any $d$-dimensional $K$-subgaussian distribution $\mathbb{P}$, we also establish that $D_{KL}(\mathbb{P}_n * \gamma \|\mathbb{P}*\gamma)$ has rate $O(1/n)$ for $K&lt;\sigma$ but only slows down to $O({(\log n)^{d+1}\over n})$ for $K&gt;\sigma$. The surprising difference of the behavior of $W_2^2$ and KL implies the failure of $T_{2}$-transportation inequality when $\sigma &lt; K$. Consequently, it follows that for $K&gt;\sigma$ the log-Sobolev inequality (LSI) for the Gaussian mixture $\mathbb{P} * N(0, \sigma^{2})$ cannot hold. This closes an open problem in [WW+16], who established the LSI under the condition $K&lt;\sigma$ and asked if their bound can be improved.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.02128v4</guid>
      <category>math.PR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Adam Block, Zeyu Jia, Yury Polyanskiy, Alexander Rakhlin</dc:creator>
    </item>
    <item>
      <title>PAC-Chernoff Bounds: Understanding Generalization in the Interpolation Regime</title>
      <link>https://arxiv.org/abs/2306.10947</link>
      <description>arXiv:2306.10947v4 Announce Type: replace-cross 
Abstract: This paper introduces a distribution-dependent PAC-Chernoff bound that exhibits perfect tightness for interpolators, even within over-parameterized model classes. This bound, which relies on basic principles of Large Deviation Theory, defines a natural measure of the smoothness of a model, characterized by simple real-valued functions. Building upon this bound and the new concept of smoothness, we present an unified theoretical framework revealing why certain interpolators show an exceptional generalization, while others falter. We theoretically show how a wide spectrum of modern learning methodologies, encompassing techniques such as $\ell_2$-norm, distance-from-initialization and input-gradient regularization, in combination with data augmentation, invariant architectures, and over-parameterization, collectively guide the optimizer toward smoother interpolators, which, according to our theoretical framework, are the ones exhibiting superior generalization performance. This study shows that distribution-dependent bounds serve as a powerful tool to understand the complex dynamics behind the generalization capabilities of over-parameterized interpolators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.10947v4</guid>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1613/jair.1.17036</arxiv:DOI>
      <arxiv:journal_reference>Journal of Artificial Intelligence Research 82 (2025) 503-562</arxiv:journal_reference>
      <dc:creator>Andr\'es R. Masegosa, Luis A. Ortega</dc:creator>
    </item>
    <item>
      <title>Robust Bayesian inference for nondestructive one-shot device testing data under competing risk using Hamiltonian Monte Carlo method</title>
      <link>https://arxiv.org/abs/2307.12557</link>
      <description>arXiv:2307.12557v2 Announce Type: replace-cross 
Abstract: The prevalence of one-shot devices is quite prolific in engineering and medical domains. Unlike typical one-shot devices, nondestructive one-shot devices (NOSD) may survive multiple tests and offer additional data for reliability estimation. This study aims to implement the Bayesian approach of the lifetime prognosis of NOSD when failures are subject to multiple risks. With small deviations from the assumed model conditions, conventional likelihood-based Bayesian estimation may result in misleading statistical inference, raising the need for a robust Bayesian method. This work develops Bayesian estimation by exploiting a robustified posterior based on the density power divergence measure for NOSD test data. Further, the testing of the hypothesis is carried out by applying a proposed Bayes factor derived from the robustified posterior. A flexible Hamiltonian Monte Carlo approach is applied to generate posterior samples. Additionally, we assess the extent of resistance of the proposed methods to small deviations from the assumed model conditions by applying the influence function (IF) approach. In testing of hypothesis, IF reflects how outliers impact the decision-making through Bayes factor under null hypothesis. Finally, this analytical development is validated through a simulation study and a data analysis based on cancer data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.12557v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shanya Baghel, Shuvashree Mondal</dc:creator>
    </item>
    <item>
      <title>A Uniform Concentration Inequality for Kernel-Based Two-Sample Statistics</title>
      <link>https://arxiv.org/abs/2405.14051</link>
      <description>arXiv:2405.14051v3 Announce Type: replace-cross 
Abstract: In many contemporary statistical and machine learning methods, one needs to optimize an objective function that depends on the discrepancy between two probability distributions. The discrepancy can be referred to as a metric for distributions. Widely adopted examples of such a metric include Energy Distance (ED), distance Covariance (dCov), Maximum Mean Discrepancy (MMD), and the Hilbert-Schmidt Independence Criterion (HSIC). We show that these metrics can be unified under a general framework of kernel-based two-sample statistics.
  This paper establishes a novel uniform concentration inequality for the aforementioned kernel-based statistics. Our results provide upper bounds for estimation errors in the associated optimization problems, thereby offering both finite-sample and asymptotic performance guarantees. As illustrative applications, we demonstrate how these bounds facilitate the derivation of error bounds for procedures such as distance covariance-based dimension reduction, distance covariance-based independent component analysis, MMD-based fairness-constrained inference, MMD-based generative model search, and MMD-based generative adversarial networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14051v3</guid>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yijin Ni, Xiaoming Huo</dc:creator>
    </item>
    <item>
      <title>Estimating the Spectral Moments of the Kernel Integral Operator from Finite Sample Matrices</title>
      <link>https://arxiv.org/abs/2410.17998</link>
      <description>arXiv:2410.17998v3 Announce Type: replace-cross 
Abstract: Analyzing the structure of sampled features from an input data distribution is challenging when constrained by limited measurements in both the number of inputs and features. Traditional approaches often rely on the eigenvalue spectrum of the sample covariance matrix derived from finite measurement matrices; however, these spectra are sensitive to the size of the measurement matrix, leading to biased insights. In this paper, we introduce a novel algorithm that provides unbiased estimates of the spectral moments of the kernel integral operator in the limit of infinite inputs and features from finitely sampled measurement matrices. Our method, based on dynamic programming, is efficient and capable of estimating the moments of the operator spectrum. We demonstrate the accuracy of our estimator on radial basis function (RBF) kernels, highlighting its consistency with the theoretical spectra. Furthermore, we showcase the practical utility and robustness of our method in understanding the geometry of learned representations in neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.17998v3</guid>
      <category>cs.LG</category>
      <category>math.SP</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chanwoo Chun, SueYeon Chung, Daniel D. Lee</dc:creator>
    </item>
    <item>
      <title>Online Experimental Design With Estimation-Regret Trade-off Under Network Interference</title>
      <link>https://arxiv.org/abs/2412.03727</link>
      <description>arXiv:2412.03727v3 Announce Type: replace-cross 
Abstract: Network interference has attracted significant attention in the field of causal inference, encapsulating various sociological behaviors where the treatment assigned to one individual within a network may affect the outcomes of others, such as their neighbors. A key challenge in this setting is that standard causal inference methods often assume independent treatment effects among individuals, which may not hold in networked environments. To estimate interference-aware causal effects, a traditional approach is to inherit the independent settings, where practitioners randomly assign experimental participants into different groups and compare their outcomes. While effective in offline settings, this strategy becomes problematic in sequential experiments, where suboptimal decision persists, leading to substantial regret. To address this issue, we introduce a unified interference-aware framework for online experimental design. Compared to existing studies, we extend the definition of arm space by utilizing the statistical concept of exposure mapping, which allows for a more flexible and context-aware representation of treatment effects in networked settings. Crucially, we establish a Pareto-optimal trade-off between estimation accuracy and regret under the network concerning both time period and arm space, which remains superior to baseline models even without network interference. Furthermore, we propose an algorithmic implementation and discuss its generalization across different learning settings and network topology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.03727v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhiheng Zhang, Zichen Wang</dc:creator>
    </item>
    <item>
      <title>Test-time Alignment of Diffusion Models without Reward Over-optimization</title>
      <link>https://arxiv.org/abs/2501.05803</link>
      <description>arXiv:2501.05803v2 Announce Type: replace-cross 
Abstract: Diffusion models excel in generative tasks, but aligning them with specific objectives while maintaining their versatility remains challenging. Existing fine-tuning methods often suffer from reward over-optimization, while approximate guidance approaches fail to optimize target rewards effectively. Addressing these limitations, we propose a training-free, test-time method based on Sequential Monte Carlo (SMC) to sample from the reward-aligned target distribution. Our approach, tailored for diffusion sampling and incorporating tempering techniques, achieves comparable or superior target rewards to fine-tuning methods while preserving diversity and cross-reward generalization. We demonstrate its effectiveness in single-reward optimization, multi-objective scenarios, and online black-box optimization. This work offers a robust solution for aligning diffusion models with diverse downstream objectives without compromising their general capabilities. Code is available at https://github.com/krafton-ai/DAS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.05803v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sunwoo Kim, Minkyu Kim, Dongmin Park</dc:creator>
    </item>
  </channel>
</rss>
