<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 14 May 2025 01:37:38 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Fast Stochastic Second-Order Adagrad for Nonconvex Bound-Constrained Optimization</title>
      <link>https://arxiv.org/abs/2505.06374</link>
      <description>arXiv:2505.06374v1 Announce Type: new 
Abstract: ADAGB2, a generalization of the Adagrad algorithm for stochastic optimization is introduced, which is also applicable to bound-constrained problems and capable of using second-order information when available. It is shown that, given $\delta\in(0,1)$ and $\epsilon\in(0,1]$, the ADAGB2 algorithm needs at most $\calO(\epsilon^{-2})$ iterations to ensure an $\epsilon$-approximate first-order critical point of the bound-constrained problem with probability at least $1-\delta$, provided the average root mean square error of the gradient oracle is sufficiently small. Should this condition fail, it is also shown that the optimality level of iterates is bounded above by this average. The relation between the approximate and true classical projected-gradient-based optimality measures for bound constrained problems is also investigated, and it is shown that merely assuming unbiased gradient oracles may be insufficient to ensure convergence in $\calO(\epsilon^{-2})$ iterations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06374v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>S. Bellavia, S. Gratton, B. Morini, Ph. L. Toint</dc:creator>
    </item>
    <item>
      <title>A linear-time algorithm to compute the conjugate of nonconvex bivariate piecewise linear-quadratic functions</title>
      <link>https://arxiv.org/abs/2505.06442</link>
      <description>arXiv:2505.06442v1 Announce Type: new 
Abstract: We propose the first linear-time algorithm to compute the conjugate of (nonconvex) bivariate piecewise linear-quadratic (PLQ) functions (bivariate quadratic functions defined on a polyhedral subdivision). Our algorithm starts with computing the convex envelope of each quadratic piece obtaining rational functions (quadratic over linear) defined over a polyhedral subdivision. Then we compute the conjugate of each resulting piece to obtain piecewise quadratic functions defined over a parabolic subdivision. Finally we compute the maximum of all those functions to obtain the conjugate as a piecewise quadratic function defined on a parabolic subdivision. The resulting algorithm runs in linear time if the initial subdivision is a triangulation (or has a uniform upper bound on the number of vertexes for each piece).
  Our open-source implementation in MATLAB uses symbolic computation and rational numbers to avoid floating-point errors, and merges pieces as soon as possible to minimize computation time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06442v1</guid>
      <category>math.OC</category>
      <category>cs.SC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Tanmaya Karmarkar, Yves Lucet</dc:creator>
    </item>
    <item>
      <title>On the Existence of Lagrange Multipliers in Distribution Network Reconfiguration Problems</title>
      <link>https://arxiv.org/abs/2505.06488</link>
      <description>arXiv:2505.06488v1 Announce Type: new 
Abstract: Distribution network reconfiguration (DNR) is an effective approach for optimizing distribution network operation. However, the DNR problem is computationally challenging due to the mixed-integer non-convex nature. One feasible approach for addressing this challenge is to reformulate binary line on/off state variables as (continuous) non-convex constraints, leading to a nonconvex program. Unfortunately, it remains unclear whether this formulation satisfies the Karush-Kuhn-Tucker (KKT) conditions at locally optimal solutions. In this brief, we study the existence of Lagrange multipliers in DNR problems and prove that under mild assumptions, Lagrange multipliers exist for the DNR model at every locally optimal solution almost surely such that the KKT conditions hold.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06488v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rong-Peng Liu, Yue Song, Xiaozhe Wang, Bo Zeng</dc:creator>
    </item>
    <item>
      <title>Optimizing Railcar Movements to Create Outbound Trains in a Freight Railyard</title>
      <link>https://arxiv.org/abs/2505.06510</link>
      <description>arXiv:2505.06510v1 Announce Type: new 
Abstract: A typical freight railyard at a manufacturing facility contains multiple tracks used for storage, classification, and outbound train assembly. Individual railcar storage locations on classification tracks are often determined before knowledge of their destination locations is known, giving rise to railcar shunting or switching problems, which require retrieving subsets of cars distributed throughout the yard to assemble outbound trains. To address this combinatorially challenging problem class, we propose a large-scale mixed-integer programming model that tracks railcar movements and corresponding costs over a finite planning horizon. The model permits simultaneous movement of multiple car groups via a locomotive and seeks to minimize repositioning costs. We also provide a dynamic programming formulation of the problem, demonstrate the NP-hardness of the corresponding optimization problem, and present an adaptive railcar grouping dynamic programming (ARG-DP) heuristic, which groups railcars with common destinations for efficient moves. Average results from a series of numerical experiments demonstrate the efficiency and quality of the ARG-DP algorithm in both simulated yards and a real yard. On average, across 60 test cases of simulated yards, the ARG-DP algorithm obtains solutions 355 times faster than solving the mixed-integer programming model using a commercial solver, while finding an optimal solution in 60% of the instances and maintaining an average optimality gap of 6.65%. In 10 cases based on the Gaia railyard in Portugal, the ARG-DP algorithm achieves solutions 229 times faster on average, finding an optimal solution in 50% of the instances with an average optimality gap of 6.90%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06510v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruonan Zhao, Joseph Geunes, Xiaofeng Nie</dc:creator>
    </item>
    <item>
      <title>Iterative Splitting Methods for Stochastic Dynamic SVIs</title>
      <link>https://arxiv.org/abs/2505.06570</link>
      <description>arXiv:2505.06570v1 Announce Type: new 
Abstract: This paper extends split variational inclusion problems to dynamic, stochastic, and multi-agent systems in Banach spaces. We propose novel iterative algorithms to handle stochastic noise, time-varying operators, and coupled variational inclusions. Leveraging advanced splitting techniques and self-adaptive rules, we establish weak convergence under minimal assumptions on operator monotonicity. Numerical experiments demonstrate the efficacy of our algorithms, particularly in resource allocation and optimization under uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06570v1</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Saeed Hashemi Sababe, Ehsan Lotfali Ghasab</dc:creator>
    </item>
    <item>
      <title>RideAgent: How to Align Operations Research with Taxi Fleet Operators? An LLM-Enhanced Feature-Driven Optimization Framework</title>
      <link>https://arxiv.org/abs/2505.06608</link>
      <description>arXiv:2505.06608v1 Announce Type: new 
Abstract: Taxi pricing and pre-allocation problems are central to urban traffic efficiency and the convenience of residents' travel. However, previous approaches face challenges in uncertain practical scenarios: (i) unpredictable ride demands due to dynamic factors such as weather and workday variations, and (ii) diverse management objectives of non-expert operators, such as minimizing dispatch costs and enhancing customer satisfaction. This paper introduces RideAgent, a solution tailored for non-expert users, which combines a Large Language Model (LLM) with a feature-driven optimization modeling approach. Experimental results show that RideAgent improves computational efficiency by 53.15% compared to traditional solvers while maintaining an optimality gap of only 2.42%. Furthermore, its variable fixing strategy outperforms five conventional cutting methods, with minimal compromise in solution quality but a significant reduction in computation time of 42.3%. RideAgent effectively caters to personalized operational needs and enables more efficient urban management.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06608v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinyu Jiang, Haoyu Zhang, Mengyi Sha, Zihao Jiao, Long He, Junbo Zhang, Wei Qi</dc:creator>
    </item>
    <item>
      <title>Dynamic feedback linearization of two-input control systems via successive one-fold prolongations</title>
      <link>https://arxiv.org/abs/2505.06677</link>
      <description>arXiv:2505.06677v1 Announce Type: new 
Abstract: In this paper, we propose a constructive algorithm to dynamically linearize two-input control systems via successive one-fold prolongations of a control that has to be suitably chosen at each step of the algorithm. Linearization via successive one-fold prolongations requires special properties of the linearizability distributions $\mathcal{D}^0 \subset \mathcal{D}^1 \subset\mathcal{D}^2 \subset \cdots$. Contrary to the case of static feedback linearizability, they need not be involutive but the first noninvolutive one has to contain an involutive subdistribution of corank one. The main idea of the proposed algorithm is to replace, at each step, the first noninvolutive distribution by its involutive subdistribution of corank one, thus for the prolonged system we gain at least one new involutive distribution. Our algorithm is constructive, gives sufficient conditions for flatness, and can be seen as the dual of the dynamic feedback linearization algorithm of Battilotti and Califano [2003, 2005].</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06677v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Florentina Nicolau, Witold Respondek, Shunjie Li</dc:creator>
    </item>
    <item>
      <title>Distributed Event-Triggered Nash Equilibrium Seeking for Noncooperative Games</title>
      <link>https://arxiv.org/abs/2505.06691</link>
      <description>arXiv:2505.06691v1 Announce Type: new 
Abstract: We propose locally convergent Nash equilibrium seeking algorithms for $N$-player noncooperative games, which use distributed event-triggered pseudo-gradient estimates. The proposed approach employs sinusoidal perturbations to estimate the pseudo-gradients of unknown quadratic payoff functions. This is the first instance of noncooperative games being tackled in a model-free fashion with event-triggered extremum seeking. Each player evaluates independently the deviation between the corresponding current pseudo-gradient estimate and its last broadcasted value from the event-triggering mechanism to tune individually the player action, while they preserve collectively the closed-loop stability/convergence. We guarantee Zeno behavior avoidance by establishing a minimum dwell-time to avoid infinitely fast switching. In particular, the stability analysis is carried out using Lyapunov's method and averaging for systems with discontinuous right-hand sides. We quantify the size of the ultimate small residual sets around the Nash equilibrium and illustrate the theoretical results numerically on an oligopoly setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06691v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Victor Hugo Pereira Rodrigues, Tiago Roux Oliveira, Miroslav Krstic, Tamer Basar</dc:creator>
    </item>
    <item>
      <title>A stochastic gradient method for trilevel optimization</title>
      <link>https://arxiv.org/abs/2505.06805</link>
      <description>arXiv:2505.06805v1 Announce Type: new 
Abstract: With the success that the field of bilevel optimization has seen in recent years, similar methodologies have started being applied to solving more difficult applications that arise in trilevel optimization. At the helm of these applications are new machine learning formulations that have been proposed in the trilevel context and, as a result, efficient and theoretically sound stochastic methods are required. In this work, we propose the first-ever stochastic gradient descent method for solving unconstrained trilevel optimization problems and provide a convergence theory that covers all forms of inexactness of the trilevel adjoint gradient, such as the inexact solutions of the middle-level and lower-level problems, inexact computation of the trilevel adjoint formula, and noisy estimates of the gradients, Hessians, Jacobians, and tensors of third-order derivatives involved. We also demonstrate the promise of our approach by providing numerical results on both synthetic trilevel problems and trilevel formulations for hyperparameter adversarial tuning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06805v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tommaso Giovannelli, Griffin Dean Kent, Luis Nunes Vicente</dc:creator>
    </item>
    <item>
      <title>Markov control of continuous time Markov processes with long run functionals by time discretization</title>
      <link>https://arxiv.org/abs/2505.06916</link>
      <description>arXiv:2505.06916v1 Announce Type: new 
Abstract: In the paper we study continuous time controlled Markov processes using discrete time controlled Markov processes. We consider long run functionals: average reward per unit time or long run risk sensitive functional. We also investigate stability of continuous time functionals with respect to pointwise convergence of Markov controls.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06916v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lukasz Stettner</dc:creator>
    </item>
    <item>
      <title>Stochastic ADMM with batch size adaptation for nonconvex nonsmooth optimization</title>
      <link>https://arxiv.org/abs/2505.06921</link>
      <description>arXiv:2505.06921v1 Announce Type: new 
Abstract: Stochastic alternating direction method of multipliers (SADMM) is a popular method for solving nonconvex nonsmooth finite-sum optimization problems in various applications. It usually requires an empirical choice of the static batch size for gradient estimation, which leads to a tricky trade-off between variance reduction and computational cost. In this work, we instead propose adaptive batch size SADMM, a practical method that dynamically adjusts the batch size based on the history differences accumulated along the optimization path. A simple convergence analysis is developed to handle the dependence of the batch size adaptation, which matches the best known complexity with flexible parameter choices. Furthermore, we extend such an adaptive strategy to reduce the overall complexity of the popular variance-reduced algorithms SVRG-ADMM and SPIDER-ADMM. Numerical results validate the improvement of our proposed SADMM with batch size adaptation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06921v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiachen Jin, Kangkang Deng, Boyu Wang, Hongxia Wang</dc:creator>
    </item>
    <item>
      <title>Stability Regularized Cross-Validation</title>
      <link>https://arxiv.org/abs/2505.06927</link>
      <description>arXiv:2505.06927v1 Announce Type: new 
Abstract: We revisit the problem of ensuring strong test-set performance via cross-validation. Motivated by the generalization theory literature, we propose a nested k-fold cross-validation scheme that selects hyperparameters by minimizing a weighted sum of the usual cross-validation metric and an empirical model-stability measure. The weight on the stability term is itself chosen via a nested cross-validation procedure. This reduces the risk of strong validation set performance and poor test set performance due to instability. We benchmark our procedure on a suite of 13 real-world UCI datasets, and find that, compared to k-fold cross-validation over the same hyperparameters, it improves the out-of-sample MSE for sparse ridge regression and CART by 4% on average, but has no impact on XGBoost. This suggests that for interpretable and unstable models, such as sparse regression and CART, our approach is a viable and computationally affordable method for improving test-set performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06927v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ryan Cory-Wright, Andr\'es G\'omez</dc:creator>
    </item>
    <item>
      <title>The large-scale charging scheduling problem for fleet batteries: Lagrangian decomposition with time-block reformulations</title>
      <link>https://arxiv.org/abs/2505.07047</link>
      <description>arXiv:2505.07047v1 Announce Type: new 
Abstract: There is a rise in the need for efficient battery charging methods due to the high penetration of electromobility solutions. Battery swapping, a technique in which fully or partially depleted batteries are exchanged and then transported to a central facility for charging, introduces a unique scheduling problem. For scenarios involving a large number of batteries, commercial solvers and existing methods do not yield optimal or near-optimal solutions in a reasonable time due to high computational complexity. Our study presents a novel approach that combines variable layering with Lagrangian decomposition. We develop a new, tighter time-block reformulation for one of the Lagrangian sub-problems, enhancing convergence rates when used with our partial-variable fixing Lagrangian heuristic. We also propose an ergodic-iterate-based local search method to further improve the solution quality. Lower bounds are improved by learning the relation between Lagrangian multipliers and electricity cost. Our extensive benchmarks show superior computational performance against commercial solvers. We achieved, on average, a 43% lower objective value compared to state-of-the-art methods. In 71% of the instances, we obtained near-optimal solutions (optimality gap less than 6%), and 93% of the instances were below 10%. We obtained feasible solutions for all instances, compared to only 65% feasibility using incumbent methods. The developed exact method aims to support future research on charging scheduling, especially important for micromobility industry, vehicle-to-grid (V2G) applications, and second-life utilization of batteries. Furthermore, the developed polyhedral insights can be useful in other scheduling problems with a common underlying mathematical structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07047v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sunney Fotedar, Jiaming Wu, Balazs Kulcsar, Rebecka Jornsten</dc:creator>
    </item>
    <item>
      <title>Strong and weak quantitative estimates in slow-fast diffusions using filtering techniques</title>
      <link>https://arxiv.org/abs/2505.07093</link>
      <description>arXiv:2505.07093v1 Announce Type: new 
Abstract: The behavior of slow-fast diffusions as the separation of scale diverges is a well-studied problem in the literature. In this short paper, we revisit this problem and obtain a new shorter proof of existing strong quantitative convergence estimates (in particular, $L^2$ estimates) and weak convergence estimates in terms of $n$ (the parameter associated with the separation of scales). In particular, we obtain the rate of $n^{-\frac{1}{2}}$ in the strong convergence estimates and the rate of $n^{-1}$ for weak convergence estimate which are already known to be optimal in the literature. We achieve this using nonlinear filtering theory where we represent the evolution of faster diffusion in terms of its conditional distribution given the slower diffusion. We then use the well-known Kushner-Stratanovich equation which gives the evolution of the conditional distribution of the fast diffusion given the slow diffusion and establish that this conditional distribution approaches the invariant measure of the ``frozen" diffusion (obtained by freezing the slow variable in the evolution equation of the fast diffusion). At the heart of the analysis lies a key estimate of a weighted total variation distance between a generic measure and the unique invariant measure (of the ``frozen" diffusion). This estimate is in terms of the operator norm of the dual of the infinitesimal generator of the ``frozen" diffusion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07093v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sumith Reddy Anugu, Vivek S. Borkar</dc:creator>
    </item>
    <item>
      <title>Optimal control of convective Brinkman-Forchheimer equations: Dynamic programming equation and Viscosity solutions</title>
      <link>https://arxiv.org/abs/2505.07095</link>
      <description>arXiv:2505.07095v1 Announce Type: new 
Abstract: It has been pointed out in the work [F. Gozzi et.al., \emph{Arch. Ration. Mech. Anal.} {163}(4) (2002), 295--327] that the existence and uniqueness of viscosity solutions for the associated first-order Hamilton-Jacobi-Bellman equation of three-dimensional Navier-Stokes equations (NSE) have not been resolved due to the lack of global solvability and continuous dependence results. However, by adding a damping term to NSE, the so-called \emph{damped Navier-Stokes equations} fulfills the requirement of existence and uniqueness of global strong solutions. In this work, we address this issue in the context of the following two- and three-dimensional convective Brinkman-Forchheimer (CBF) equations (damped NSE) in torus $\mathbb{T}^d,\ d\in\{2,3\}$:
  \begin{align*}
  \frac{\partial\boldsymbol{u}}{\partial t}-\mu \Delta\boldsymbol{u}+(\boldsymbol{u}\cdot\nabla)\boldsymbol{u}+\alpha\boldsymbol{u}+\beta|\boldsymbol{u}|^{r-1}\boldsymbol{u}+\nabla p=\boldsymbol{f}, \ \nabla\cdot\boldsymbol{u}=0,
  \end{align*}
  where $\mu,\alpha,\beta&gt;0$, $r\in[1,\infty)$.
  We investigate the infinite-dimensional first-order Hamilton-Jacobi Bellman equation related to an optimal control problem for CBF equations using the dynamic programming method, establishing its unique global solvability results in two and three dimensions. We begin by demonstrating the existence of a viscosity solution for the infinite-dimensional Hamilton-Jacobi-Bellman equation in the supercritical case. Specifically, we consider the ranges $r\in(3,\infty)$ in $d=2$, $r\in(3,5]$ in $d=3$, and $r=3$ with $2\beta\mu\geq1$ in $d\in\{2,3\}$. Next, we establish a comparison principle for $r\in(3,\infty)$ and $r=3$ with $2\beta\mu\geq 1$ in $d\in\{2,3\}$, which provides the uniqueness of the viscosity solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07095v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sagar Gautam, Manil T. Mohan</dc:creator>
    </item>
    <item>
      <title>Subgradient Regularization: A Descent-Oriented Subgradient Method for Nonsmooth Optimization</title>
      <link>https://arxiv.org/abs/2505.07143</link>
      <description>arXiv:2505.07143v1 Announce Type: new 
Abstract: In nonsmooth optimization, a negative subgradient is not necessarily a descent direction, making the design of convergent descent methods based on zeroth-order and first-order information a challenging task. The well-studied bundle methods and gradient sampling algorithms construct descent directions by aggregating subgradients at nearby points in seemingly different ways, and are often complicated or lack deterministic guarantees. In this work, we identify a unifying principle behind these approaches, and develop a general framework of descent methods under the abstract principle that provably converge to stationary points. Within this framework, we introduce a simple yet effective technique, called subgradient regularization, to generate stable descent directions for a broad class of nonsmooth marginal functions, including finite maxima or minima of smooth functions. When applied to the composition of a convex function with a smooth map, the method naturally recovers the prox-linear method and, as a byproduct, provides a new dual interpretation of this classical algorithm. Numerical experiments demonstrate the effectiveness of our methods on several challenging classes of nonsmooth optimization problems, including the minimization of Nesterov's nonsmooth Chebyshev-Rosenbrock function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07143v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hanyang Li, Ying Cui</dc:creator>
    </item>
    <item>
      <title>Learning Quasi-LPV Models and Robust Control Invariant Sets with Reduced Conservativeness</title>
      <link>https://arxiv.org/abs/2505.07287</link>
      <description>arXiv:2505.07287v1 Announce Type: new 
Abstract: We present an approach to identify a quasi Linear Parameter Varying (qLPV) model of a plant, with the qLPV model guaranteed to admit a robust control invariant (RCI) set. It builds upon the concurrent synthesis framework presented in [1], in which the requirement of existence of an RCI set is modeled as a control-oriented regularization. Here, we reduce the conservativeness of the approach by bounding the qLPV system with an uncertain LTI system, which we derive using bound propagation approaches. The resulting regularization function is the optimal value of a nonlinear robust optimization problem that we solve via a differentiable algorithm. We numerically demonstrate the benefits of the proposed approach over two benchmark approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07287v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/LCSYS.2025.3569637</arxiv:DOI>
      <dc:creator>Sampath Kumar Mulagaleti, Alberto Bemporad</dc:creator>
    </item>
    <item>
      <title>Adaptive Learning-based Surrogate Method for Stochastic Programs with Implicitly Decision-dependent Uncertainty</title>
      <link>https://arxiv.org/abs/2505.07298</link>
      <description>arXiv:2505.07298v1 Announce Type: new 
Abstract: We consider a class of stochastic programming problems where the implicitly decision-dependent random variable follows a nonparametric regression model with heteroscedastic error. The Clarke subdifferential and surrogate functions are not readily obtainable due to the latent decision dependency. To deal with such a computational difficulty, we develop an adaptive learning-based surrogate method that integrates the simulation scheme and statistical estimates to construct estimation-based surrogate functions in a way that the simulation process is adaptively guided by the algorithmic procedure. We establish the non-asymptotic convergence rate analysis in terms of $(\nu, \delta)$-near stationarity in expectation under variable proximal parameters and batch sizes, which exhibits the superior convergence performance and enhanced stability in both theory and practice. We provide numerical results with both synthetic and real data which illustrate the benefits of the proposed algorithm in terms of algorithmic stability and efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07298v1</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Boyang Shen, Junyi Liu</dc:creator>
    </item>
    <item>
      <title>Null controllability of the 1D heat equation with interior inverse square potential</title>
      <link>https://arxiv.org/abs/2505.07302</link>
      <description>arXiv:2505.07302v1 Announce Type: new 
Abstract: This paper aims to answer an open problem posed by Morancey in 2015 concerning the null controllability of the heat equation on (-1, 1) with an internal inverse square potential located at x = 0. For the range of singularity under study, after having introduced a suitable self-adjoint extension that enables to transmit information from one side of the singularity to another, we prove null-controllability in arbitrary small time, firstly with an internal control supported in an arbitrary measurable set of positive measure, secondly with a boundary control acting on one side of the boundary. Our proof is mainly based on a precise spectral study of the singular operator together with some recent refinements of the moment method of Fattorini and Russell. This notably requires to use some fine (and sometimes new) properties for Bessel functions and their zeros.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07302v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pierre Lissy (CERMICS), Tanguy Lourme</dc:creator>
    </item>
    <item>
      <title>Non-Asymptotic Analysis of Projected Gradient Descent for Physics-Informed Neural Networks</title>
      <link>https://arxiv.org/abs/2505.07311</link>
      <description>arXiv:2505.07311v1 Announce Type: new 
Abstract: In this work, we provide a non-asymptotic convergence analysis of projected gradient descent for physics-informed neural networks for the Poisson equation. Under suitable assumptions, we show that the optimization error can be bounded by $\mathcal{O}(1/\sqrt{T} + 1/\sqrt{m} + \epsilon_{\text{approx}})$, where $T$ is the number of algorithm time steps, $m$ is the width of the neural network and $\epsilon_{\text{approx}}$ is an approximation error. The proof of our optimization result relies on bounding the linearization error and using this result together with a Lyapunov drift analysis. Additionally, we quantify the generalization error by bounding the Rademacher complexities of the neural network and its Laplacian. Combining both the optimization and generalization results, we obtain an overall error estimate based on an existing error estimate from regularity theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07311v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jonas Nie{\ss}en, Johannes M\"uller</dc:creator>
    </item>
    <item>
      <title>Sparsity for dynamic inverse problems on Wasserstein curves with bounded variation</title>
      <link>https://arxiv.org/abs/2505.07314</link>
      <description>arXiv:2505.07314v1 Announce Type: new 
Abstract: We investigate a dynamic inverse problem using a regularization which implements the so-called Wasserstein-$1$ distance. It naturally extends well-known static problems such as lasso or total variation regularized problems to a (temporally) dynamic setting. Further, the decision variables, realized as BV curves, are allowed to exhibit discontinuities, in contrast to the design variables in classical optimal transport based regularization techniques. We prove the existence and a characterization of a sparse solution. Further, we use an adaption of the fully-corrective generalized conditional gradient method to experimentally justify that the determination of BV curves in the Wasserstein-$1$ space is numerically implementable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07314v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marcello Carioni, Julius Lohmann</dc:creator>
    </item>
    <item>
      <title>Neural Operators for Adaptive Control of Traffic Flow Models</title>
      <link>https://arxiv.org/abs/2505.07353</link>
      <description>arXiv:2505.07353v1 Announce Type: new 
Abstract: The uncertainty in human driving behaviors leads to stop-and-go instabilities in freeway traffic. The traffic dynamics are typically modeled by the Aw-Rascle-Zhang (ARZ) Partial Differential Equation (PDE) models, in which the relaxation time parameter is usually unknown or hard to calibrate. This paper proposes an adaptive boundary control design based on neural operators (NO) for the ARZ PDE systems. In adaptive control, solving the backstepping kernel PDEs online requires significant computational resources at each timestep to update estimates of the unknown system parameters. To address this, we employ DeepONet to efficiently map model parameters to kernel functions. Simulations show that DeepONet generates kernel solutions nearly two orders of magnitude faster than traditional solvers while maintaining a loss on the order of \(10^{-2}\). Lyapunov analysis further validates the stability of the system when using DeepONet-approximated kernels in the adaptive controller. This result suggests that neural operators can significantly accelerate the acquisition of adaptive controllers for traffic control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07353v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kaijing Lyu, Junmin Wang, Yihuai Zhang, Huan Yu</dc:creator>
    </item>
    <item>
      <title>Anti-windup design for internal model online constrained optimization</title>
      <link>https://arxiv.org/abs/2505.07384</link>
      <description>arXiv:2505.07384v1 Announce Type: new 
Abstract: This paper proposes a novel algorithmic design procedure for online constrained optimization grounded in control-theoretic principles. By integrating the Internal Model Principle (IMP) with an anti-windup compensation mechanism, the proposed Projected-Internal Model Anti-Windup (P-IMAW) gradient descent exploits a partial knowledge of the temporal evolution of the cost function to enhance tracking performance. The algorithm is developed through a structured synthesis procedure: first, a robust controller leveraging the IMP ensures asymptotic convergence in the unconstrained setting. Second, an anti-windup augmentation guarantees stability and performance in the presence of the projection operator needed to satisfy the constraints. The effectiveness of the proposed approach is demonstrated through numerical simulations comparing it against other classical techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07384v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Umberto Casti, Sandro Zampieri</dc:creator>
    </item>
    <item>
      <title>Enhancing Accuracy in Differentially Private Distributed Optimization Through Sensitivity Reduction</title>
      <link>https://arxiv.org/abs/2505.07482</link>
      <description>arXiv:2505.07482v1 Announce Type: new 
Abstract: In this paper, we investigate the problem of differentially private distributed optimization. Recognizing that lower sensitivity leads to higher accuracy, we analyze the key factors influencing the sensitivity of differentially private distributed algorithms. Building on these insights, we propose a novel differentially private distributed algorithm that enhances optimization accuracy by reducing sensitivity. To ensure practical applicability, we derive a closed-form expression for the noise parameter as a function of the privacy budget. Furthermore, we rigorously prove that the proposed algorithm can achieve arbitrarily rigorous $\epsilon$-differential privacy, establish its convergence in the mean square sense, and provide an upper bound on its optimization accuracy. Finally, extensive comparisons with various privacy-preserving methods validate the effectiveness of our algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07482v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Furan Xie, Bing Liu, Li Chai</dc:creator>
    </item>
    <item>
      <title>Convex Trajectory Optimization via Monomial Coordinates Transcription for Cislunar Rendezvous</title>
      <link>https://arxiv.org/abs/2505.07521</link>
      <description>arXiv:2505.07521v1 Announce Type: new 
Abstract: This paper proposes a nonlinear guidance algorithm for fuel-optimal impulsive trajectories for rendezvous operations close to a reference orbit. The approach involves overparameterized monomial coordinates and a high-order approximation of the dynamic flow precomputed using Differential Algebra, which eliminates the need for real-time integration. To address non-convexity in the monomial coordinate formulation of the guidance problem, Sequential Convex Programming is applied. Using the methodology presented in this paper, repeatedly evaluating the nonlinear dynamics is not necessary, as in shooting or collocation methods. Instead, only the monomial equations require updating between iterations, drastically reducing computational burden. The proposed algorithm is tested in the Circular Restricted Three-Body Problem framework with the target spacecraft on a Near-Rectilinear Halo Orbit. The results demonstrate stability, efficiency, and low computational demand while achieving minimal terminal guidance errors. Compared to linear methods, this nonlinear convex approach exhibits superior performance in open-loop propagation of impulsive maneuvers in cislunar space, particularly in terms of accuracy. These advantages make the algorithm an attractive candidate for autonomous onboard guidance for rendezvous operations in the cislunar domain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07521v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Omar Regantini, Ethan R. Burnett, Antonio Rizza, Alessandro Morselli, Francesco Topputo</dc:creator>
    </item>
    <item>
      <title>Congestion-Sensitive Grid Aggregation for DC Optimal Power Flow</title>
      <link>https://arxiv.org/abs/2505.07545</link>
      <description>arXiv:2505.07545v1 Announce Type: new 
Abstract: The vast spatial dimension of modern interconnected electricity grids challenges the tractability of the DC optimal power flow problem. Grid aggregation methods try to overcome this challenge by reducing the number of network elements. Many existing methods use Locational Marginal Prices as a distance metric to cluster nodes. In this paper, we show that prevalent methods adopting this distance metric fail to adequately capture the impact of individual lines when there is more than one line congested. This leads to suboptimal outcomes for the optimization of the aggregated model. To overcome those issues, we propose two methods based on the novel Network Congestion Price metric, which preserves the impact of nodal power injections on individual line congestions. The proposed methods are compared to several existing aggregation methods based on Locational Marginal Prices. We demonstrate all methods on adapted versions of the IEEE RTS 24- and 300-Bus systems. We show that the proposed methods outperform existing approaches both in terms of objective function value error and maximum line limit violation, while exhibiting faster node clustering. We conclude that aggregation methods based on the novel Network Congestion Price metric are better at preserving the essential physical characteristics of the network topology in the grid aggregation process than methods based on Locational Marginal Prices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07545v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Benjamin St\"ockl, Yannick Werner, Sonja Wogrin</dc:creator>
    </item>
    <item>
      <title>State-wise Economic Viability of Long-Duration Energy Storage Systems in the United States</title>
      <link>https://arxiv.org/abs/2505.07624</link>
      <description>arXiv:2505.07624v1 Announce Type: new 
Abstract: Long-duration energy storage (LDES) assets can be fundamental resources for the next-generation power systems. However, LDES technologies are still immature and their future technology costs remain highly uncertain. In this context, we perform in this paper an extensive study to estimate the maximum LDES technology costs (which we define as viability costs) under which LDES systems would be economically viable in each state of the contiguous U.S. according to their characteristics. Our results indicate that only 4 states (out of 48) would be able to remove firm conventional generation supported by LDES systems without increasing their total system costs under the current US-DOE cost target of 1,100 US$/kW for multi-day LDES. In addition, we find that states with the highest LDES viability costs have in general low participation of thermal generation, a high share of wind generation, and higher thermal-related fixed operation and maintenance (FO&amp;M) costs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07624v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexandre Moreira, Patricia Silva, Miguel Heleno, Andre Marcato</dc:creator>
    </item>
    <item>
      <title>Convergence of Time-Averaged Mean Field Gradient Descent Dynamics for Continuous Multi-Player Zero-Sum Games</title>
      <link>https://arxiv.org/abs/2505.07642</link>
      <description>arXiv:2505.07642v1 Announce Type: new 
Abstract: The approximation of mixed Nash equilibria (MNE) for zero-sum games with mean-field interacting players has recently raised much interest in machine learning. In this paper we propose a mean-field gradient descent dynamics for finding the MNE of zero-sum games involving $K$ players with $K\geq 2$. The evolution of the players' strategy distributions follows coupled mean-field gradient descent flows with momentum, incorporating an exponentially discounted time-averaging of gradients. First, in the case of a fixed entropic regularization, we prove an exponential convergence rate for the mean-field dynamics to the mixed Nash equilibrium with respect to the total variation metric. This improves a previous polynomial convergence rate for a similar time-averaged dynamics with different averaging factors. Moreover, unlike previous two-scale approaches for finding the MNE, our approach treats all player types on the same time scale. We also show that with a suitable choice of decreasing temperature, a simulated annealing version of the mean-field dynamics converges to an MNE of the initial unregularized problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07642v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.AP</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yulong Lu, Pierre Monmarch\'e</dc:creator>
    </item>
    <item>
      <title>Zero-sum Stochastic Differential Games of Impulse Control with Random Intervention Costs</title>
      <link>https://arxiv.org/abs/2505.07666</link>
      <description>arXiv:2505.07666v1 Announce Type: new 
Abstract: We consider a finite-horizon, zero-sum game in which both players control a stochastic differential equation by invoking impulses. We derive a control randomization formulation of the game and use the existence of a value for the randomized game to show that the upper and lower value functions of the original game coincide.
  The main contribution of the present work is that we can allow intervention costs that are functions of the state as well as time, and that we do not need to impose any monotonicity assumptions on the involved coefficients.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07666v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Magnus Perninge</dc:creator>
    </item>
    <item>
      <title>Singular Control in Inventory Management with Smooth Ambiguity</title>
      <link>https://arxiv.org/abs/2505.07761</link>
      <description>arXiv:2505.07761v1 Announce Type: new 
Abstract: We consider singular control in inventory management under Knightian uncertainty, where decision makers have a smooth ambiguity preference over Gaussian-generated priors. We demonstrate that continuous-time smooth ambiguity is the infinitesimal limit of Kalman-Bucy filtering with recursive robust utility. Additionally, we prove that the cost function can be determined by solving forward-backward stochastic differential equations with quadratic growth. With a sufficient condition and utilising variational inequalities in a viscosity sense, we derive the value function and optimal control policy. By the change-of-coordinate technique, we transform the problem into two-dimensional singular control, offering insights into model learning and aligning with classical singular control free boundary problems. We numerically implement our theory using a Markov chain approximation, where inventory is modeled as cash management following an arithmetic Brownian motion. Our numerical results indicate that the continuation region can be divided into three key areas: (i) the target region; (ii) the region where it is optimal to learn and do nothing; and (iii) the region where control becomes predominant and learning should inactive. We demonstrate that ambiguity drives the decision maker to act earlier, leading to a smaller continuation region. This effect becomes more pronounced at the target region as the decision maker gains confidence from a longer learning period. However, these dynamics do not extend to the third region, where learning is excluded.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07761v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>q-fin.RM</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arnon Archankul, Jacco J. J. Thijssen</dc:creator>
    </item>
    <item>
      <title>Robo-Taxi Fleet Coordination with Accelerated High-Capacity Ridepooling</title>
      <link>https://arxiv.org/abs/2505.07776</link>
      <description>arXiv:2505.07776v1 Announce Type: new 
Abstract: Rapid urbanization has led to a surge of customizable mobility demand in urban areas, which makes on-demand services increasingly popular. On-demand services are flexible while reducing the need for private cars, thus mitigating congestion and parking issues in limited urban space. While the coordination of high-capacity ridepooling on-demand service requires effective control to ensure efficiency, the emergence of the paradigm of robo-taxi opens the opportunity for centralized fleet control for an improved service quality. In this work, we propose two acceleration algorithms for the most advanced large-scale high-capacity algorithm proposed in [1]. We prove the improvement in the real-time performance of the algorithm by using real-world on-demand data from Manhattan, NYC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07776v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xinling Li, Daniele Gammelli, Alex Wallar, Jinhua Zhao, Gioele Zardini</dc:creator>
    </item>
    <item>
      <title>Direct Data Driven Control Using Noisy Measurements</title>
      <link>https://arxiv.org/abs/2505.06407</link>
      <description>arXiv:2505.06407v1 Announce Type: cross 
Abstract: This paper presents a novel direct data-driven control framework for solving the linear quadratic regulator (LQR) under disturbances and noisy state measurements. The system dynamics are assumed unknown, and the LQR solution is learned using only a single trajectory of noisy input-output data while bypassing system identification. Our approach guarantees mean-square stability (MSS) and optimal performance by leveraging convex optimization techniques that incorporate noise statistics directly into the controller synthesis. First, we establish a theoretical result showing that the MSS of an uncertain data-driven system implies the MSS of the true closed-loop system. Building on this, we develop a robust stability condition using linear matrix inequalities (LMIs) that yields a stabilizing controller gain from noisy measurements. Finally, we formulate a data-driven LQR problem as a semidefinite program (SDP) that computes an optimal gain, minimizing the steady-state covariance. Extensive simulations on benchmark systems -- including a rotary inverted pendulum and an active suspension system -- demonstrate the superior robustness and accuracy of our method compared to existing data-driven LQR approaches. The proposed framework offers a practical and theoretically grounded solution for controller design in noise-corrupted environments where system identification is infeasible.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06407v1</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ramin Esmzad, Gokul S. Sankar, Teawon Han, Hamidreza Modares</dc:creator>
    </item>
    <item>
      <title>Data Envelopment Analysis based on robust and closest targets</title>
      <link>https://arxiv.org/abs/2505.06487</link>
      <description>arXiv:2505.06487v1 Announce Type: cross 
Abstract: As business environments grow increasingly volatile and unpredictable, the selection of benchmarking targets in data envelopment analysis should account for their ability to withstand risks, yet this aspect has not received sufficient attention. We propose a kind of robust benchmarking target defined by the intersection of the maximum number of full-dimensional efficient facets, each embedding a unique marginal substitution relationship. These targets can serve as robust projections for firms lacking prior risk information because they encompass the maximum number of marginal substitution relationships. This enables firms to adjust their outputs through these relationships, maximizing the likelihood of achieving globally optimal revenue. Furthermore, we put forward a novel well-defined efficiency measure based on robust and closest targets. Finally, we demonstrate the application of the proposed measure, using a dataset comprising 38 universities from China's 985 Project.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06487v1</guid>
      <category>stat.AP</category>
      <category>math.OC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xiuquan Huang, Xi Wang, Tao Zhang, Xiaocang Xu</dc:creator>
    </item>
    <item>
      <title>On optimal periodic dividend and capital injection strategies for general L\'evy models</title>
      <link>https://arxiv.org/abs/2505.06554</link>
      <description>arXiv:2505.06554v1 Announce Type: cross 
Abstract: We consider a version of de Finetti's dividend problem, with the bail-out contraint to keep the surplus non-negative, and where dividend payments can only be made at the arrival times of an independent Poisson process. For a general L\'evy process with positive and negative jumps, we show the optimality of a periodic-classical reflection strategy that pays the excess above a given level at each Poisson arrival time, and also reflects below at 0 in the classical sense.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06554v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dante Mata, Kei Noba, Jos\'e-Luis P\'erez</dc:creator>
    </item>
    <item>
      <title>Quadrupedal Robot Skateboard Mounting via Reverse Curriculum Learning</title>
      <link>https://arxiv.org/abs/2505.06561</link>
      <description>arXiv:2505.06561v1 Announce Type: cross 
Abstract: The aim of this work is to enable quadrupedal robots to mount skateboards using Reverse Curriculum Reinforcement Learning. Although prior work has demonstrated skateboarding for quadrupeds that are already positioned on the board, the initial mounting phase still poses a significant challenge. A goal-oriented methodology was adopted, beginning with the terminal phases of the task and progressively increasing the complexity of the problem definition to approximate the desired objective. The learning process was initiated with the skateboard rigidly fixed within the global coordinate frame and the robot positioned directly above it. Through gradual relaxation of these initial conditions, the learned policy demonstrated robustness to variations in skateboard position and orientation, ultimately exhibiting a successful transfer to scenarios involving a mobile skateboard. The code, trained models, and reproducible examples are available at the following link: https://github.com/dancher00/quadruped-skateboard-mounting</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06561v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Danil Belov, Artem Erkhov, Elizaveta Pestova, Ilya Osokin, Dzmitry Tsetserukou, Pavel Osinenko</dc:creator>
    </item>
    <item>
      <title>Optimal Transport for Machine Learners</title>
      <link>https://arxiv.org/abs/2505.06589</link>
      <description>arXiv:2505.06589v1 Announce Type: cross 
Abstract: Optimal Transport is a foundational mathematical theory that connects optimization, partial differential equations, and probability. It offers a powerful framework for comparing probability distributions and has recently become an important tool in machine learning, especially for designing and evaluating generative models. These course notes cover the fundamental mathematical aspects of OT, including the Monge and Kantorovich formulations, Brenier's theorem, the dual and dynamic formulations, the Bures metric on Gaussian distributions, and gradient flows. It also introduces numerical methods such as linear programming, semi-discrete solvers, and entropic regularization. Applications in machine learning include topics like training neural networks via gradient flows, token dynamics in transformers, and the structure of GANs and diffusion models. These notes focus primarily on mathematical content rather than deep learning techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06589v1</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gabriel Peyr\'e</dc:creator>
    </item>
    <item>
      <title>Beyond $\tilde{O}(\sqrt{T})$ Constraint Violation for Online Convex Optimization with Adversarial Constraints</title>
      <link>https://arxiv.org/abs/2505.06709</link>
      <description>arXiv:2505.06709v1 Announce Type: cross 
Abstract: We revisit the Online Convex Optimization problem with adversarial constraints (COCO) where, in each round, a learner is presented with a convex cost function and a convex constraint function, both of which may be chosen adversarially. The learner selects actions from a convex decision set in an online fashion, with the goal of minimizing both regret and the cumulative constraint violation (CCV) over a horizon of $T$ rounds. The best-known policy for this problem achieves $O(\sqrt{T})$ regret and $\tilde{O}(\sqrt{T})$ CCV. In this paper, we present a surprising improvement that achieves a significantly smaller CCV by trading it off with regret. Specifically, for any bounded convex cost and constraint functions, we propose an online policy that achieves $\tilde{O}(\sqrt{dT}+ T^\beta)$ regret and $\tilde{O}(dT^{1-\beta})$ CCV, where $d$ is the dimension of the decision set and $\beta \in [0,1]$ is a tunable parameter. We achieve this result by first considering the special case of $\textsf{Constrained Expert}$ problem where the decision set is a probability simplex and the cost and constraint functions are linear. Leveraging a new adaptive small-loss regret bound, we propose an efficient policy for the $\textsf{Constrained Expert}$ problem, that attains $O(\sqrt{T\ln N}+T^{\beta})$ regret and $\tilde{O}(T^{1-\beta} \ln N)$ CCV, where $N$ is the number of experts. The original problem is then reduced to the $\textsf{Constrained Expert}$ problem via a covering argument. Finally, with an additional smoothness assumption, we propose an efficient gradient-based policy attaining $O(T^{\max(\frac{1}{2},\beta)})$ regret and $\tilde{O}(T^{1-\beta})$ CCV.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06709v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Abhishek Sinha, Rahul Vaze</dc:creator>
    </item>
    <item>
      <title>Utility Maximization Under Endogenous Uncertainty</title>
      <link>https://arxiv.org/abs/2505.06846</link>
      <description>arXiv:2505.06846v1 Announce Type: cross 
Abstract: This paper establishes a general existence result for optimal decision-making when choices affect the probabilities of uncertain outcomes. We introduce a continuity condition - a version of upper semi-continuity for choice-dependent probability measures - which ensures upper semi-continuity of expected utility. Our topological proof does not require standard assumptions such as concavity of preferences or monotonicity of outcome distributions. Additionally, we identify sufficient conditions, including continuity of densities and stochastic dominance, which allow the main assumption to be verified in relevant economic contexts. These findings expand the applicability of expected utility theory in settings with endogenous uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06846v1</guid>
      <category>econ.TH</category>
      <category>math.OC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ayush Gupta</dc:creator>
    </item>
    <item>
      <title>Masked Subspace Clustering Methods</title>
      <link>https://arxiv.org/abs/2505.06863</link>
      <description>arXiv:2505.06863v1 Announce Type: cross 
Abstract: To further utilize the unsupervised features and pairwise information, we propose a general Bilevel Clustering Optimization (BCO) framework to improve the performance of clustering. And then we introduce three special cases on subspace clustering with two different types of masks. At first, we reformulate the original subspace clustering as a Basic Masked Subspace Clustering (BMSC), which reformulate the diagonal constraints to a hard mask. Then, we provide a General Masked Subspace Clustering (GMSC) method to integrate different clustering via a soft mask. Furthermore, based on BCO and GMSC, we induce a learnable soft mask and design a Recursive Masked Subspace Clustering (RMSC) method that can alternately update the affinity matrix and the soft mask. Numerical experiments show that our models obtain significant improvement compared with the baselines on several commonly used datasets, such as MNIST, USPS, ORL, COIL20 and COIL100.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06863v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiebo Song, Huaming Ling</dc:creator>
    </item>
    <item>
      <title>Robust Control of Uncertain Switched Affine Systems via Scenario Optimization</title>
      <link>https://arxiv.org/abs/2505.06943</link>
      <description>arXiv:2505.06943v1 Announce Type: cross 
Abstract: Switched affine systems are often used to model and control complex dynamical systems that operate in multiple modes. However, uncertainties in the system matrices can challenge their stability and performance. This paper introduces a new approach for designing switching control laws for uncertain switched affine systems using data-driven scenario optimization. Instead of relaxing invariant sets, our method creates smaller invariant sets with quadratic Lyapunov functions through scenario-based optimization, effectively reducing chattering effects and regulation error. The framework ensures robustness against parameter uncertainties while improving accuracy. We validate our method with applications in multi-objective interval Markov decision processes and power electronic converters, demonstrating its effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06943v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Negar Monir, Mahdieh S. Sadabadi, Sadegh Soudjani</dc:creator>
    </item>
    <item>
      <title>YANNs: Y-wise Affine Neural Networks for Exact and Efficient Representations of Piecewise Linear Functions</title>
      <link>https://arxiv.org/abs/2505.07054</link>
      <description>arXiv:2505.07054v1 Announce Type: cross 
Abstract: This work formally introduces Y-wise Affine Neural Networks (YANNs), a fully-explainable network architecture that continuously and efficiently represent piecewise affine functions with polytopic subdomains. Following from the proofs, it is shown that the development of YANNs requires no training to achieve the functionally equivalent representation. YANNs thus maintain all mathematical properties of the original formulations. Multi-parametric model predictive control is utilized as an application showcase of YANNs, which theoretically computes optimal control laws as a piecewise affine function of states, outputs, setpoints, and disturbances. With the exact representation of multi-parametric control laws, YANNs retain essential control-theoretic guarantees such as recursive feasibility and stability. This sets YANNs apart from the existing works which apply neural networks for approximating optimal control laws instead of exactly representing them. By optimizing the inference speed of the networks, YANNs can evaluate substantially faster in real-time compared to traditional piecewise affine function calculations. Numerical case studies are presented to demonstrate the algorithmic scalability with respect to the input/output dimensions and the number of subdomains. YANNs represent a significant advancement in control as the first neural network-based controller that inherently ensures both feasibility and stability. Future applications can leverage them as an efficient and interpretable starting point for data-driven modeling/control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07054v1</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Austin Braniff, Yuhe Tian</dc:creator>
    </item>
    <item>
      <title>A Rapid Reconstruction Method of Gamma Radiation Field based on Normalized Proper Orthogonal Decomposition</title>
      <link>https://arxiv.org/abs/2505.07088</link>
      <description>arXiv:2505.07088v1 Announce Type: cross 
Abstract: When a fault occurs in nuclear facilities, accurately reconstructing gamma radiation fields through measurements from the mobile radiation detection (MRD) system becomes crucial to enable access to internal facility areas for essential safety assessments and repairs. Reconstruction of these fields is difficult because of the uncertainty in the positions and intensities of the gamma sources, the complexity of the gamma distribution, and the physics and radiation hardness constraints on the MRD systems. In this work, a novel reconstruction framework of the gamma radiation is proposed. This system entails a NPOD-based reconstruction algorithm with MRD data, and a variation-based adaptive measurements selection mechanism. Our approach has been thoroughly assessed using extensive simulations, and the results clearly prove its success and efficiency in reconstruction radiation fields accurately and quickly. Furthermore, the designed selection algorithm is also promising for extensive application to other optimization tasks of location selection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07088v1</guid>
      <category>physics.med-ph</category>
      <category>math.OC</category>
      <category>physics.app-ph</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kai Tan, Hojoon Son, Fan Zhang</dc:creator>
    </item>
    <item>
      <title>Carleman estimates for the Korteweg-de Vries equation with piecewise constant main coefficient</title>
      <link>https://arxiv.org/abs/2505.07264</link>
      <description>arXiv:2505.07264v1 Announce Type: cross 
Abstract: In this article, we investigate observability-related properties of the Korteweg-de Vries equation with a discontinuous main coefficient, coupled by suitable interface conditions. The main result is a novel two-parameter Carleman estimate for the linear equation with internal observation, assuming a monotonicity condition on the main coefficient. As a primary application, we establish the local exact controllability to the trajectories by employing a duality argument for the linear case and a local inversion theorem for the nonlinear equation. Secondly, we establish the Lipschitz-stability of the inverse problem of retrieving an unknown potential using the Bukhge{\u\i}m-Klibanov method, when some further assumptions on the interface are made. We conclude with some remarks on the boundary observability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07264v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Crist\'obal Loyola</dc:creator>
    </item>
    <item>
      <title>Optimal Low Emission Zones scheduling as an example of transport policy backcasting</title>
      <link>https://arxiv.org/abs/2505.07451</link>
      <description>arXiv:2505.07451v1 Announce Type: cross 
Abstract: This study presents a backcasting approach that considers the passenger car fleet dynamics to determine optimal policy roadmaps in transport systems. As opposed to the scenario-based approach, backcasting sets emission reduction targets first, then identifies policies that meet the constraint. The policy is the implementation of Low Emission Zones (LEZs), in the Ile-de-France region as a case study. The aim is to minimize the number of scrapped vehicles due to LEZs under CO2 emission targets and to deduce an interdiction schedule of polluting vehicles by 2050. To explore potential solutions, we use a genetic algorithm that provides a first insight into optimal policy pathways.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07451v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Asmae Alami, Vinith Lakshmanan, Antonio Sciarretta</dc:creator>
    </item>
    <item>
      <title>Finite-Sample-Based Reachability for Safe Control with Gaussian Process Dynamics</title>
      <link>https://arxiv.org/abs/2505.07594</link>
      <description>arXiv:2505.07594v1 Announce Type: cross 
Abstract: Gaussian Process (GP) regression is shown to be effective for learning unknown dynamics, enabling efficient and safety-aware control strategies across diverse applications. However, existing GP-based model predictive control (GP-MPC) methods either rely on approximations, thus lacking guarantees, or are overly conservative, which limits their practical utility. To close this gap, we present a sampling-based framework that efficiently propagates the model's epistemic uncertainty while avoiding conservatism. We establish a novel sample complexity result that enables the construction of a reachable set using a finite number of dynamics functions sampled from the GP posterior. Building on this, we design a sampling-based GP-MPC scheme that is recursively feasible and guarantees closed-loop safety and stability with high probability. Finally, we showcase the effectiveness of our method on two numerical examples, highlighting accurate reachable set over-approximation and safe closed-loop performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07594v1</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Manish Prajapat, Johannes K\"ohler, Amon Lahr, Andreas Krause, Melanie N. Zeilinger</dc:creator>
    </item>
    <item>
      <title>Trial and Trust: Addressing Byzantine Attacks with Comprehensive Defense Strategy</title>
      <link>https://arxiv.org/abs/2505.07614</link>
      <description>arXiv:2505.07614v1 Announce Type: cross 
Abstract: Recent advancements in machine learning have improved performance while also increasing computational demands. While federated and distributed setups address these issues, their structure is vulnerable to malicious influences. In this paper, we address a specific threat, Byzantine attacks, where compromised clients inject adversarial updates to derail global convergence. We combine the trust scores concept with trial function methodology to dynamically filter outliers. Our methods address the critical limitations of previous approaches, allowing functionality even when Byzantine nodes are in the majority. Moreover, our algorithms adapt to widely used scaled methods like Adam and RMSProp, as well as practical scenarios, including local training and partial participation. We validate the robustness of our methods by conducting extensive experiments on both synthetic and real ECG data collected from medical institutions. Furthermore, we provide a broad theoretical analysis of our algorithms and their extensions to aforementioned practical setups. The convergence guarantees of our methods are comparable to those of classical algorithms developed without Byzantine interference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07614v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gleb Molodtsov, Daniil Medyakov, Sergey Skorik, Nikolas Khachaturov, Shahane Tigranyan, Vladimir Aletov, Aram Avetisyan, Martin Tak\'a\v{c}, Aleksandr Beznosikov</dc:creator>
    </item>
    <item>
      <title>One-Point Feedback for Composite Optimization with Applications to Distributed and Federated Learning</title>
      <link>https://arxiv.org/abs/2107.05951</link>
      <description>arXiv:2107.05951v3 Announce Type: replace 
Abstract: This work is devoted to solving the composite optimization problem with the mixture oracle: for the smooth part of the problem, we have access to the gradient, and for the non-smooth part, only the one-point zero-order oracle is available. For such a setup, we present a new method based on the sliding algorithm. Our method allows to separate the oracle complexities and to compute the gradient for one of the functions as rarely as possible. The paper also presents the applicability of our new method to the problems of distributed optimization and federated learning. Experimental results confirm the theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2107.05951v3</guid>
      <category>math.OC</category>
      <category>cs.DC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aleksandr Beznosikov, Ivan Stepanov, Artyom Voronov, Alexander Gasnikov</dc:creator>
    </item>
    <item>
      <title>Optimal Cross-Validation for Sparse Linear Regression</title>
      <link>https://arxiv.org/abs/2306.14851</link>
      <description>arXiv:2306.14851v3 Announce Type: replace 
Abstract: Given a high-dimensional covariate matrix and a response vector, ridge-regularized sparse linear regression selects a subset of features that explains the relationship between covariates and the response in an interpretable manner. To select the sparsity and robustness of linear regressors, techniques like k-fold cross-validation are commonly used for hyperparameter tuning. However, cross-validation substantially increases the computational cost of sparse regression as it requires solving many mixed-integer optimization problems (MIOs) for each hyperparameter combination. To improve upon this state of affairs, we obtain computationally tractable relaxations of k-fold cross-validation metrics, facilitating hyperparameter selection after solving 50-80% fewer MIOs in practice. These relaxations result in an efficient cyclic coordinate descent scheme, achieving 10%-30% lower validation errors than via traditional methods such as grid search with MCP or GLMNet across a suite of 13 real-world datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.14851v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ryan Cory-Wright, Andr\'es G\'omez</dc:creator>
    </item>
    <item>
      <title>Homogeneous Second-Order Descent Framework: A Fast Alternative to Newton-Type Methods</title>
      <link>https://arxiv.org/abs/2306.17516</link>
      <description>arXiv:2306.17516v4 Announce Type: replace 
Abstract: This paper proposes a homogeneous second-order descent framework (HSODF) for nonconvex and convex optimization based on the generalized homogeneous model (GHM). In comparison to the Newton steps, the GHM can be solved by extremal symmetric eigenvalue procedures and thus grant an advantage in ill-conditioned problems. Moreover, GHM extends the ordinary homogeneous model (OHM) (Zhang et al. 2022) to allow adaptiveness in the construction of the aggregated matrix. Consequently, HSODF is able to recover some well-known second-order methods, such as trust-region methods and gradient regularized methods, while maintaining comparable iteration complexity bounds. We also study two specific realizations of HSODF. One is adaptive HSODM, which has a parameter-free $O(\epsilon^{-3/2})$ global complexity bound for nonconvex second-order Lipschitz continuous objective functions. The other one is homotopy HSODM, which is proven to have a global linear rate of convergence without strong convexity. The efficiency of our approach to ill-conditioned and high-dimensional problems is justified by some preliminary numerical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.17516v4</guid>
      <category>math.OC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Chang He, Yuntian Jiang, Chuwen Zhang, Dongdong Ge, Bo Jiang, Yinyu Ye</dc:creator>
    </item>
    <item>
      <title>Distributionally Robust Optimization with Polynomial Robust Constraints</title>
      <link>https://arxiv.org/abs/2308.15591</link>
      <description>arXiv:2308.15591v2 Announce Type: replace 
Abstract: This paper studies distributionally robust optimization (DRO) with polynomial robust constraints. We give a Moment-SOS relaxation approach to solve the DRO. This reduces to solving linear conic optimization with semidefinite constraints. When the DRO problem is SOS-convex, we show that it is equivalent to the linear conic relaxation and it can be solved by the Moment-SOS algorithm. For nonconvex cases, we also give concrete conditions such that the DRO can be solved globally. Numerical experiments are given to show the efficiency of the method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.15591v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiawang Nie, Suhan Zhong</dc:creator>
    </item>
    <item>
      <title>Stochastic Halpern iteration in normed spaces and applications to reinforcement learning</title>
      <link>https://arxiv.org/abs/2403.12338</link>
      <description>arXiv:2403.12338v4 Announce Type: replace 
Abstract: We analyze the oracle complexity of the stochastic Halpern iteration with minibatch, where we aim to approximate fixed-points of nonexpansive and contractive operators in a normed finite-dimensional space. We show that if the underlying stochastic oracle has uniformly bounded variance, our method exhibits an overall oracle complexity of $\tilde{O}(\varepsilon^{-5})$, to obtain $\varepsilon$ expected fixed-point residual for nonexpansive operators, improving recent rates established for the stochastic Krasnoselskii-Mann iteration. Also, we establish a lower bound of $\Omega(\varepsilon^{-3})$ which applies to a wide range of algorithms, including all averaged iterations even with minibatching. Using a suitable modification of our approach, we derive a $O(\varepsilon^{-2}(1-\gamma)^{-3})$ complexity bound in the case in which the operator is a $\gamma$-contraction to obtain an approximation of the fixed-point. As an application, we propose new model-free algorithms for average and discounted reward MDPs. For the average reward case, our method applies to weakly communicating MDPs without requiring prior parameter knowledge.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12338v4</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mario Bravo, Juan Pablo Contreras</dc:creator>
    </item>
    <item>
      <title>A new framework for constrained optimization via feedback control of Lagrange multipliers</title>
      <link>https://arxiv.org/abs/2403.12738</link>
      <description>arXiv:2403.12738v2 Announce Type: replace 
Abstract: The continuous-time analysis of existing iterative algorithms for optimization has a long history. This work proposes a novel continuous-time control-theoretic framework for equality-constrained optimization. The key idea is to design a feedback control system where the Lagrange multipliers are the control input, and the output represents the constraints. The system converges to a stationary point of the constrained optimization problem through suitable regulation. Regarding the Lagrange multipliers, we consider two control laws: proportional-integral control and feedback linearization. These choices give rise to a family of different methods. We rigorously develop the related algorithms, theoretically analyze their convergence and present several numerical experiments to support their effectiveness concerning the state-of-the-art approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12738v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>V. Cerone, S. M. Fosson, S. Pirrera, D. Regruto</dc:creator>
    </item>
    <item>
      <title>Shape Optimization of Supercapacitor Electrode to Maximize Charge Storage</title>
      <link>https://arxiv.org/abs/2406.09616</link>
      <description>arXiv:2406.09616v3 Announce Type: replace 
Abstract: We build a new mathematical model of shape optimization for maximizing ionic concentration governed by the multi-physical coupling steady-state Poisson-Nernst-Planck system. Shape sensitivity analysis is performed to obtain the Eulerian derivative of the cost functional. The Gummel fixed-point method with inverse harmonic averaging technique on exponential coefficient is used to solve efficiently the steady-state Poisson-Nernst-Planck system. Various numerical results using a shape gradient algorithm in 2d and 3d are presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.09616v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Jiajie Li, Shenggao Zhou, Shengfeng Zhu</dc:creator>
    </item>
    <item>
      <title>Algorithmic aspects of semistability of quiver representations</title>
      <link>https://arxiv.org/abs/2407.06493</link>
      <description>arXiv:2407.06493v3 Announce Type: replace 
Abstract: We study the semistability of quiver representations from an algorithmic perspective. We present efficient algorithms for several fundamental computational problems on the semistability of quiver representations: deciding the semistability and $\sigma$-semistability, finding the maximizers of King's criterion, and computing the Harder--Narasimhan filtration. We also investigate a class of polyhedral cones defined by the linear system in King's criterion, which we refer to as King cones. For rank-one representations, we demonstrate that these King cones can be encoded by submodular flow polytopes, enabling us to decide the $\sigma$-semistability in strongly polynomial time. Our approach employs submodularity in quiver representations, which may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06493v3</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <category>math.RT</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuni Iwamasa, Taihei Oki, Tasuku Soma</dc:creator>
    </item>
    <item>
      <title>On pairs of spectrum maximizing products with distinct factor multiplicities</title>
      <link>https://arxiv.org/abs/2407.10513</link>
      <description>arXiv:2407.10513v4 Announce Type: replace 
Abstract: Recently, Bochi and Laskawiec constructed an example of a set of matrices $\{A,B\}$ having two different (up to cyclic permutations of factors) spectrum maximizing products, $AABABB$ and $BBABAA$. In this paper, we identify a class of matrix sets for which the existence of at least one spectrum maximizing product with an odd number of factors automatically entails the existence of another spectrum maximizing product. Moreover, in addition to Bochi--Laskawiec's example, the number of factors of the same name (factors of the form $A$ or $B$) in these matrix products turns out to be different. The efficiency of the proposed approach is confirmed by constructing an example of a set of $2\times2$ matrices $\{A,B\}$ that has spectrum maximizing products of the form $BAA$ and $BBA$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10513v4</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1137/24M1688503</arxiv:DOI>
      <arxiv:journal_reference>SIAM J. Matrix Anal. Appl. 46 (2025), no. 2, 1328-1345</arxiv:journal_reference>
      <dc:creator>Victor Kozyakin</dc:creator>
    </item>
    <item>
      <title>A line search filter sequential adaptive cubic regularisation algorithm for nonlinearly constrained optimization</title>
      <link>https://arxiv.org/abs/2409.04784</link>
      <description>arXiv:2409.04784v2 Announce Type: replace 
Abstract: In this paper, a sequential adaptive regularization algorithm using cubics (ARC) is presented to solve nonlinear equality constrained optimization. It is motivated by the idea of handling constraints in sequential quadratic programming methods. In each iteration, we decompose the new step into the sum of the normal step and the tangential step by using composite step approaches. Using a projective matrix, we transform the constrained ARC subproblem into a standard ARC subproblem which generates the tangential step. After the new step is computed, we employ line search filter techniques to generate the next iteration point. Line search filter techniques enable the algorithm to avoid the difficulty of choosing an appropriate penalty parameter in merit functions and the possibility of solving ARC subproblem many times in one iteration in ARC framework. Global convergence is analyzed under some mild assumptions. Preliminary numerical results and comparison are reported.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04784v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yonggang Pei, Jingyi Wang, Shaofang Song, Qinghui Gao, Detong Zhu</dc:creator>
    </item>
    <item>
      <title>Energetic Resilience of Linear Driftless Systems</title>
      <link>https://arxiv.org/abs/2410.00323</link>
      <description>arXiv:2410.00323v3 Announce Type: replace 
Abstract: When a malfunction causes a control system to lose authority over a subset of its actuators, achieving a task may require spending additional energy in order to compensate for the effect of uncontrolled inputs. To understand this increase in energy, we introduce an energetic resilience metric that quantifies the maximal additional energy required to achieve finite-time regulation in linear driftless systems that suffer this malfunction. We first derive optimal control signals and minimum energies to achieve this task in both the nominal and malfunctioning systems. We then obtain a bound on the worst-case energy used by the malfunctioning system, and its exact expression in the special case of loss of authority over one actuator. Further considering this special case, we derive a bound on the metric for energetic resilience. A simulation example on a model of an underwater robot demonstrates that this bound is useful in quantifying the increased energy used by a system suffering such a malfunction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00323v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ram Padmanabhan, Melkior Ornik</dc:creator>
    </item>
    <item>
      <title>Dynamic Programming: From Local Optimality to Global Optimality</title>
      <link>https://arxiv.org/abs/2411.11062</link>
      <description>arXiv:2411.11062v3 Announce Type: replace 
Abstract: In the theory of dynamic programming, an optimal policy is a policy whose lifetime value dominates that of all other policies from every possible initial condition in the state space. This raises a natural question: when does optimality from a single state imply optimality from every state? Working in a general setting, we provide sufficient conditions for this property that relate to reachability and irreducibility. Our results have significant implications for modern policy-based algorithms used to solve large-scale dynamic programs. We illustrate our findings by applying them to an optimal savings problem via an algorithm that implements gradient ascent in a policy space constructed from neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11062v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>John Stachurski, Jingni Yang, Ziyue Yang</dc:creator>
    </item>
    <item>
      <title>CB$^2$O: Consensus-Based Bi-Level Optimization</title>
      <link>https://arxiv.org/abs/2411.13394</link>
      <description>arXiv:2411.13394v2 Announce Type: replace 
Abstract: Bi-level optimization problems, where one wishes to find the global minimizer of an upper-level objective function over the globally optimal solution set of a lower-level objective, arise in a variety of scenarios throughout science and engineering, machine learning, and artificial intelligence. In this paper, we propose and investigate, analytically and experimentally, consensus-based bi-level optimization (CB$^2$O), a multi-particle metaheuristic derivative-free optimization method designed to solve bi-level optimization problems when both objectives may be nonconvex. Our method leverages within the computation of the consensus point a carefully designed particle selection principle implemented through a suitable choice of a quantile on the level of the lower-level objective, together with a Laplace principle-type approximation w.r.t. the upper-level objective function, to ensure that the bi-level optimization problem is solved in an intrinsic manner. We give an existence proof of solutions to a corresponding mean-field dynamics, for which we first establish the stability of our consensus point w.r.t. a combination of Wasserstein and $L^2$ perturbations, and consecutively resort to PDE considerations extending the classical Picard iteration to construct a solution. For such solution, we provide a global convergence analysis in mean-field law showing that the solution of the associated nonlinear nonlocal Fokker-Planck equation converges exponentially fast to the unique solution of the bi-level optimization problem provided suitable choices of the hyperparameters. The practicability and efficiency of our CB$^2$O algorithm is demonstrated through extensive numerical experiments in the settings of constrained global optimization, sparse representation learning, and robust (clustered) federated learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13394v2</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicol\'as Garc\'ia Trillos, Sixu Li, Konstantin Riedl, Yuhua Zhu</dc:creator>
    </item>
    <item>
      <title>A Modified Proximal Bundle Method Under A Frank-Wolfe Perspective</title>
      <link>https://arxiv.org/abs/2411.15926</link>
      <description>arXiv:2411.15926v2 Announce Type: replace 
Abstract: The proximal bundle method (PBM) is a fundamental and computationally effective algorithm for solving optimization problems with nonsmooth components. In this paper, we conduct a theoretical investigation of a modified proximal bundle method, which we call the Modified Proximal Bundle with Fixed Absolute Accuracy (MPB-FA). MPB-FA modifies PBM in two key aspects. Firstly, the null-step test of MPB-FA is based on an absolute accuracy criterion, and the accuracy is fixed over iterations, while the standard PBM uses a relative accuracy in the null-step test, which changes with iterations. Secondly, the proximal parameter in MPB-FA is also fixed over iterations, while it is permitted to change in the standard PBM. These modifications allow us to interpret a sequence of null steps of MPB-FA as a Frank-Wolfe algorithm on the Moreau envelope of the dual problem. In light of this correspondence, we first extend the linear convergence of Kelley's method on convex piecewise linear functions from the positive homogeneous to the general case. Building on this result, we propose a novel complexity analysis of MPB-FA and derive an $\mathcal{O}(\epsilon^{-4/5})$ iteration complexity, improving upon the best known $\mathcal{O}(\epsilon^{-2})$ guarantee on a related variant of PBM. It is worth-noting that the best known complexity bound for the classic PBM is $\mathcal{O}(\epsilon^{-3})$. Our approach also reveals new insights on bundle management.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15926v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>David Fersztand, Xu Andy Sun</dc:creator>
    </item>
    <item>
      <title>Inexact Proximal Point Algorithms for Zeroth-Order Global Optimization</title>
      <link>https://arxiv.org/abs/2412.11485</link>
      <description>arXiv:2412.11485v3 Announce Type: replace 
Abstract: This work concerns the zeroth-order global minimization of continuous nonconvex functions with a unique global minimizer and possibly multiple local minimizers. We formulate a theoretical framework for inexact proximal point (IPP) methods for global optimization, establishing convergence guarantees under mild assumptions when either deterministic or stochastic estimates of proximal operators are used. The quadratic regularization in the proximal operator and the scaling effect of a parameter $\delta&gt;0$ create a concentrated landscape of an associated Gibbs measure that is practically effective for sampling. The convergence of the expectation under the Gibbs measure as $\delta\to 0^+$ is established, and the convergence rate of $\mathcal O(\delta)$ is derived under additional assumptions. These results provide a theoretical foundation for evaluating proximal operators inexactly using sampling-based methods such as Monte Carlo (MC) integration. In addition, we propose a new approach based on tensor train (TT) approximation. This approach employs a randomized TT cross algorithm to efficiently construct a low-rank TT approximation of a discretized function using a small number of function evaluations, and we provide an error analysis for the TT-based estimation. We then propose two practical IPP algorithms, TT-IPP and MC-IPP. The TT-IPP algorithm leverages TT estimates of the proximal operators, while the MC-IPP algorithm employs MC integration to estimate the proximal operators. Both algorithms are designed to adaptively balance efficiency and accuracy in inexact evaluations of proximal operators. The effectiveness of the two algorithms is demonstrated through experiments on diverse benchmark functions and various applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.11485v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Minxin Zhang, Fuqun Han, Yat Tin Chow, Stanley Osher, Hayden Schaeffer</dc:creator>
    </item>
    <item>
      <title>Optimal error estimates of the stochastic parabolic optimal control problem with integral state constraint</title>
      <link>https://arxiv.org/abs/2412.18173</link>
      <description>arXiv:2412.18173v4 Announce Type: replace 
Abstract: In this paper, the optimal strong error estimates for stochastic parabolic optimal control problem with additive noise and integral state constraint are derived based on time-implicit and finite element discretization. The continuous and discrete first-order optimality conditions are deduced by constructing the Lagrange functional, which contains forward-backward stochastic parabolic equations and a variational equation. The fully discrete version of forward-backward stochastic parabolic equations is introduced as an auxiliary problem and the optimal strong convergence orders are estimated, which further allows the optimal a priori error estimates for control, state, adjoint state and multiplier to be derived. Then, a simple and yet efficient gradient projection algorithm is proposed to solve stochastic parabolic control problem and its convergence rate is proved. Numerical experiments are carried out to illustrate the theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.18173v4</guid>
      <category>math.OC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiming Wang, Wanfang Shen, Wenbin Liu</dc:creator>
    </item>
    <item>
      <title>Estimation-Aware Trajectory Optimization with Set-Valued Measurement Uncertainties</title>
      <link>https://arxiv.org/abs/2501.09192</link>
      <description>arXiv:2501.09192v3 Announce Type: replace 
Abstract: In this paper, an optimization-based framework for generating estimation-aware trajectories is presented. In this setup, measurement (output) uncertainties are state-dependent and set-valued. Enveloping ellipsoids are employed to characterize state-dependent uncertainties with unknown distributions. The concept of regularity for set-valued output maps is then introduced, facilitating the formulation of the estimation-aware trajectory generation problem. Specifically, it is demonstrated that for output-regular maps, one can utilize a set-valued observability measure that is concave with respect to the finite horizon state trajectories. By maximizing this measure, estimation-aware trajectories can then be synthesized for a broad class of systems. Trajectory planning routines are also examined in this work, by which the observability measure is optimized for systems with locally linearized dynamics. To illustrate the effectiveness of the proposed approach, representative examples in the context of trajectory planning with vision-based estimation are presented. Moreover, the paper presents estimation-aware planning for an uncooperative Target-Rendezvous problem, where an Ego-satellite employs an onboard machine learning (ML)-based estimation module to realize the rendezvous trajectory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09192v3</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aditya Deole, Mehran Mesbahi</dc:creator>
    </item>
    <item>
      <title>Mixed-Integer Optimization for Loopless Flux Distributions in Metabolic Networks</title>
      <link>https://arxiv.org/abs/2502.00807</link>
      <description>arXiv:2502.00807v2 Announce Type: replace 
Abstract: Constraint-based metabolic models can be used to investigate the intracellular physiology of microorganisms. These models couple genes to reactions, and typically seek to predict metabolite fluxes that optimize some biologically important metric. Classical techniques, like Flux Balance Analysis (FBA), formulate the metabolism of a microbe as an optimization problem where growth rate is maximized. While FBA has found widespread use, it often leads to thermodynamically infeasible solutions that contain internal cycles (loops). To address this shortcoming, Loopless-Flux Balance Analysis (ll-FBA) seeks to predict flux distributions that do not contain these loops. ll-FBA is a disjunctive program, usually reformulated as a mixed-integer program, and is challenging to solve for biological models that often contain thousands of reactions and metabolites. In this paper, we compare various reformulations of ll-FBA and different solution approaches. Overall, the combinatorial Benders' decomposition is the most promising of the tested approaches with which we could solve most instances. However, the model size and numerical instability pose a challenge to the combinatorial Benders' method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00807v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hannah Troppens, Mathieu Besan\c{c}on, St. Elmo Wilken, Sebastian Pokutta</dc:creator>
    </item>
    <item>
      <title>Approximate Energetic Resilience of Nonlinear Systems under Partial Loss of Control Authority</title>
      <link>https://arxiv.org/abs/2502.07603</link>
      <description>arXiv:2502.07603v2 Announce Type: replace 
Abstract: In this paper, we quantify the resilience of nonlinear dynamical systems by studying the increased energy used by all inputs of a system that suffers a partial loss of control authority, either through actuator malfunctions or through adversarial attacks. To quantify the maximal increase in energy, we introduce the notion of an energetic resilience metric. Prior work in this particular setting does not consider general nonlinear dynamical systems. In developing this framework, we first consider the special case of linear driftless systems and recall the energies in the control signal in the nominal and malfunctioning systems. Using these energies, we derive a bound on the energetic resilience metric. For general nonlinear systems, we first obtain a condition on the mean value of the control signal in both the nominal and malfunctioning systems, which allows us to approximate the energy in the control. We then obtain a worst-case approximation of this energy for the malfunctioning system, over all malfunctioning inputs. Assuming this approximation is exact, we derive bounds on the energetic resilience metric when control authority is lost over one actuator. A set of simulation examples demonstrate that the metric is useful in quantifying the resilience of the system without significant conservatism, despite the approximations used in obtaining control energies for nonlinear systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07603v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ram Padmanabhan, Melkior Ornik</dc:creator>
    </item>
    <item>
      <title>Stochastic Gradient Descent for Constrained Optimization based on Adaptive Relaxed Barrier Functions</title>
      <link>https://arxiv.org/abs/2503.10384</link>
      <description>arXiv:2503.10384v2 Announce Type: replace 
Abstract: This paper presents a novel stochastic gradient descent algorithm for constrained optimization. The proposed algorithm randomly samples constraints and components of the finite sum objective function and relies on a relaxed logarithmic barrier function that is appropriately adapted in each optimization iteration. For a strongly convex objective function and affine inequality constraints, step-size rules and barrier adaptation rules are established that guarantee asymptotic convergence with probability one. The theoretical results in the paper are complemented by numerical studies which highlight potential advantages of the proposed algorithm for optimization problems with a large number of constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10384v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Naum Dimitrieski, Jing Cao, Christian Ebenbauer</dc:creator>
    </item>
    <item>
      <title>Extremum Seeking for Controlled Vibrational Stabilization of Second Order Mechanical Systems</title>
      <link>https://arxiv.org/abs/2504.04174</link>
      <description>arXiv:2504.04174v3 Announce Type: replace 
Abstract: This paper presents a novel extremum seeking control (ESC) approach for the vibrational stabilization of a class of mechanical systems (e.g., systems characterized by equations of motion resulting from Newton second law or Euler-Lagrange mechanics). Inspired by flapping insects mechanics, the proposed ESC approach is operable by only one perturbation signal and can admit generalized forces that are quadratic in velocities. We test our ESC, and compare it against approaches from literature, on some classical mechanical systems (e.g., mass-spring and an inverted pendulum systems). We also provide a novel, first-of-its-kind, application of the introduced ESC by achieving a 1D model-free source-seeking of a flapping system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04174v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ahmed A. Elgohary, Sameh A. Eisa</dc:creator>
    </item>
    <item>
      <title>Punitive policies to combat misreporting in dynamic supply chains</title>
      <link>https://arxiv.org/abs/2504.13780</link>
      <description>arXiv:2504.13780v2 Announce Type: replace 
Abstract: Wholesale price contracts are known to be associated with double marginalization effects, which prevents supply chains from achieving their true market share. In a dynamic setting under information asymmetry, these inefficiencies manifest in the form of misreporting of the market potential by the manufacturer to the supplier, again leading to the loss of market share. We pose the dynamics of interaction between the supplier and manufacturer as the Stackelberg game and develop theoretical results for optimal punitive strategies that the supplier can implement to ensure that the manufacturer truthfully reveals the market potential in the single-stage setting. Later, we validate these results through the randomly generated, Monte-Carlo simulation based numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.13780v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Madhu Dhiman, Atul Maurya, Veeraruna Kavitha, Priyank Sinha</dc:creator>
    </item>
    <item>
      <title>Meta-Learning the Optimal Mixture of Strategies for Online Portfolio Selection</title>
      <link>https://arxiv.org/abs/2505.03659</link>
      <description>arXiv:2505.03659v2 Announce Type: replace 
Abstract: This paper presents an innovative online portfolio selection model, situated within a meta-learning framework, that leverages a mixture policies strategy. The core idea is to simulate a fund that employs multiple fund managers, each skilled in handling different market environments, and dynamically allocate our funding to these fund managers for investment. To address the non-stationary nature of financial markets, we divide the long-term process into multiple short-term processes to adapt to changing environments. We use a clustering method to identify a set of historically high-performing policies, characterized by low similarity, as candidate policies. Additionally, we employ a meta-learning method to search for initial parameters that can quickly adapt to upcoming target investment tasks, effectively providing a set of well-suited initial strategies. Subsequently, we update the initial parameters using the target tasks and determine the optimal mixture weights for these candidate policies. Empirical tests show that our algorithm excels in terms of training time and data requirements, making it particularly suitable for high-frequency algorithmic trading. To validate the effectiveness of our method, we conduct numerical tests on cross-training datasets, demonstrating its excellent transferability and robustness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03659v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiayu Shen, Jia Liu, Zhiping Chen</dc:creator>
    </item>
    <item>
      <title>Accelerated Decentralized Constraint-Coupled Optimization: A Dual$^2$ Approach</title>
      <link>https://arxiv.org/abs/2505.03719</link>
      <description>arXiv:2505.03719v2 Announce Type: replace 
Abstract: In this paper, we focus on a class of decentralized constraint-coupled optimization problem: $\min_{x_i \in \mathbb{R}^{d_i}, i \in \mathcal{I}; y \in \mathbb{R}^p}$ $\sum_{i=1}^n\left(f_i(x_i) + g_i(x_i)\right) + h(y) \ \text{s.t.} \ \sum_{i=1}^{n}A_ix_i = y$, over an undirected and connected network of $n$ agents. Here, $f_i$, $g_i$, and $A_i$ represent private information of agent $i \in \mathcal{I} = \{1, \cdots, n\}$, while $h$ is public for all agents. Building on a novel dual$^2$ approach, we develop two accelerated algorithms to solve this problem: the inexact Dual$^2$ Accelerated (iD2A) gradient method and the Multi-consensus inexact Dual$^2$ Accelerated (MiD2A) gradient method. We demonstrate that both iD2A and MiD2A can guarantee asymptotic convergence under a milder condition on $h$ compared to existing algorithms. Furthermore, under additional assumptions, we establish linear convergence rates and derive significantly lower communication and computational complexity bounds than those of existing algorithms. Several numerical experiments validate our theoretical analysis and demonstrate the practical superiority of the proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03719v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jingwang Li, Vincent Lau</dc:creator>
    </item>
    <item>
      <title>Towards Optimal Branching of Linear and Semidefinite Relaxations for Neural Network Robustness Certification</title>
      <link>https://arxiv.org/abs/2101.09306</link>
      <description>arXiv:2101.09306v4 Announce Type: replace-cross 
Abstract: In this paper, we study certifying the robustness of ReLU neural networks against adversarial input perturbations. To diminish the relaxation error suffered by the popular linear programming (LP) and semidefinite programming (SDP) certification methods, we take a branch-and-bound approach to propose partitioning the input uncertainty set and solving the relaxations on each part separately. We show that this approach reduces relaxation error, and that the error is eliminated entirely upon performing an LP relaxation with a partition intelligently designed to exploit the nature of the ReLU activations. To scale this approach to large networks, we consider using a coarser partition whereby the number of parts in the partition is reduced. We prove that computing such a coarse partition that directly minimizes the LP relaxation error is NP-hard. By instead minimizing the worst-case LP relaxation error, we develop a closed-form branching scheme in the single-hidden layer case. We extend the analysis to the SDP, where the feasible set geometry is exploited to design a branching scheme that minimizes the worst-case SDP relaxation error. Experiments on MNIST, CIFAR-10, and Wisconsin breast cancer diagnosis classifiers demonstrate significant increases in the percentages of test samples certified. By independently increasing the input size and the number of layers, we empirically illustrate under which regimes the branched LP and branched SDP are best applied. Finally, we extend our LP branching method into a multi-layer branching heuristic, which attains comparable performance to prior state-of-the-art heuristics on large-scale, deep neural network certification benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2101.09306v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Brendon G. Anderson, Ziye Ma, Jingqi Li, Somayeh Sojoudi</dc:creator>
    </item>
    <item>
      <title>Tight Finite Time Bounds of Two-Time-Scale Linear Stochastic Approximation with Markovian Noise</title>
      <link>https://arxiv.org/abs/2401.00364</link>
      <description>arXiv:2401.00364v2 Announce Type: replace-cross 
Abstract: Stochastic approximation (SA) is an iterative algorithm for finding the fixed point of an operator using noisy samples and widely used in optimization and Reinforcement Learning (RL). The noise in RL exhibits a Markovian structure, and in some cases, such as gradient temporal difference (GTD) methods, SA is employed in a two-time-scale framework. This combination introduces significant theoretical challenges for analysis.
  We derive an upper bound on the error for the iterations of linear two-time-scale SA with Markovian noise. We demonstrate that the mean squared error decreases as $trace (\Sigma^y)/k + o(1/k)$ where $k$ is the number of iterates, and $\Sigma^y$ is an appropriately defined covariance matrix. A key feature of our bounds is that the leading term, $\Sigma^y$, exactly matches with the covariance in the Central Limit Theorem (CLT) for the two-time-scale SA, and we call them tight finite-time bounds. We illustrate their use in RL by establishing sample complexity for off-policy algorithms, TDC, GTD, and GTD2.
  A special case of linear two-time-scale SA that is extensively studied is linear SA with Polyak-Ruppert averaging. We present tight finite time bounds corresponding to the covariance matrix of the CLT. Such bounds can be used to study TD-learning with Polyak-Ruppert averaging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.00364v2</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shaan Ul Haque, Sajad Khodadadian, Siva Theja Maguluri</dc:creator>
    </item>
    <item>
      <title>Demystifying SGD with Doubly Stochastic Gradients</title>
      <link>https://arxiv.org/abs/2406.00920</link>
      <description>arXiv:2406.00920v2 Announce Type: replace-cross 
Abstract: Optimization objectives in the form of a sum of intractable expectations are rising in importance (e.g., diffusion models, variational autoencoders, and many more), a setting also known as "finite sum with infinite data." For these problems, a popular strategy is to employ SGD with doubly stochastic gradients (doubly SGD): the expectations are estimated using the gradient estimator of each component, while the sum is estimated by subsampling over these estimators. Despite its popularity, little is known about the convergence properties of doubly SGD, except under strong assumptions such as bounded variance. In this work, we establish the convergence of doubly SGD with independent minibatching and random reshuffling under general conditions, which encompasses dependent component gradient estimators. In particular, for dependent estimators, our analysis allows fined-grained analysis of the effect correlations. As a result, under a per-iteration computational budget of $b \times m$, where $b$ is the minibatch size and $m$ is the number of Monte Carlo samples, our analysis suggests where one should invest most of the budget in general. Furthermore, we prove that random reshuffling (RR) improves the complexity dependence on the subsampling noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00920v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kyurae Kim, Joohwan Ko, Yi-An Ma, Jacob R. Gardner</dc:creator>
    </item>
    <item>
      <title>Exact controllability to eigensolutions of the fractional heat equation via bilinear controls on N-dimensional domains</title>
      <link>https://arxiv.org/abs/2406.17348</link>
      <description>arXiv:2406.17348v2 Announce Type: replace-cross 
Abstract: The exact controllability of heat-type equations in the presence of bilinear controls has been successfully studied in recent works, motivated by numerous applications to engineering, neurobiology, chemistry, and life sciences. Nevertheless, the result has only been achieved for $1$-dimensional domains due to the limitations of the existing techniques. In this work, we consider a fractional heat-type equation as $\partial_t\psi+(-\Delta)^s\psi+\langle v(t), Q\rangle \psi(t)=0$ with $s&gt;0$ and on a domain $\Omega\subset \mathbb R^N$ for $N\in\mathbb N^*.$ We study the so-called exact controllability to the eigensolutions of the equations when $s&gt;\max(\frac{4N}{5},N-1)$. The result is implied by the null controllability of a suitable linearized equation, and the main novelty of the work is the strategy of its proof. First, the null controllability in a finite-dimensional subspace has to be ensured via the solvability of a suitable moment problem. Explicit bounds on the control cost with respect to the dimension of the controlled space are also required. Second, the controllability can be extended to the whole Hilbert space, thanks to the Lebeau-Robbiano-Miller method, when the control cost does not grow too fast with respect to the dimension of the finite-dimensional subspace. We firstly develop our techniques in the general case when suitable hypotheses on the problem are verified. Secondly, we apply our procedure to the bilinear heat equation on rectangular domains, and we ensure its exact controllability to the eigensolutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17348v2</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>R\'emi Buffe, Alessandro Duca</dc:creator>
    </item>
    <item>
      <title>HPPP: Halpern-type Preconditioned Proximal Point Algorithms and Applications to Image Restoration</title>
      <link>https://arxiv.org/abs/2407.13120</link>
      <description>arXiv:2407.13120v3 Announce Type: replace-cross 
Abstract: Recently, the degenerate preconditioned proximal point (PPP) method provides a unified and flexible framework for designing and analyzing operator-splitting algorithms such as Douglas-Rachford (DR). However, the degenerate PPP method exhibits weak convergence in the infinite-dimensional Hilbert space and lacks accelerated variants. To address these issues, we propose a Halpern-type PPP (HPPP) algorithm, which leverages the strong convergence and acceleration properties of Halpern's iteration method. Moreover, we propose a novel algorithm for image restoration by combining HPPP with denoiser priors such as Plug-and-Play (PnP) prior, which can be viewed as an accelerated PnP method. Finally, numerical experiments including several toy examples and image restoration validate the effectiveness of our proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13120v3</guid>
      <category>cs.CV</category>
      <category>math.OC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuchang Zhang, Hui Zhang, Hongxia Wang</dc:creator>
    </item>
    <item>
      <title>Differentially Private Bilevel Optimization</title>
      <link>https://arxiv.org/abs/2409.19800</link>
      <description>arXiv:2409.19800v2 Announce Type: replace-cross 
Abstract: We present differentially private (DP) algorithms for bilevel optimization, a problem class that received significant attention lately in various machine learning applications. These are the first algorithms for such problems under standard DP constraints, and are also the first to avoid Hessian computations which are prohibitive in large-scale settings. Under the well-studied setting in which the upper-level is not necessarily convex and the lower-level problem is strongly-convex, our proposed gradient-based $(\epsilon,\delta)$-DP algorithm returns a point with hypergradient norm at most $\widetilde{\mathcal{O}}\left((\sqrt{d_\mathrm{up}}/\epsilon n)^{1/2}+(\sqrt{d_\mathrm{low}}/\epsilon n)^{1/3}\right)$ where $n$ is the dataset size, and $d_\mathrm{up}/d_\mathrm{low}$ are the upper/lower level dimensions. Our analysis covers constrained and unconstrained problems alike, accounts for mini-batch gradients, and applies to both empirical and population losses. As an application, we specialize our analysis to derive a simple private rule for tuning a regularization hyperparameter.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19800v2</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>math.OC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guy Kornowski</dc:creator>
    </item>
    <item>
      <title>Distributed Coordination of Grid-Forming and Grid-Following Inverters for Optimal Frequency Control in Power Systems</title>
      <link>https://arxiv.org/abs/2411.12682</link>
      <description>arXiv:2411.12682v2 Announce Type: replace-cross 
Abstract: The large-scale integration of inverter-interfaced renewable energy sources presents significant challenges to maintaining power balance and nominal frequency in modern power systems. This paper studies grid-level coordinated control of grid-forming (GFM) and grid-following (GFL) inverter-based resources (IBRs) for scalable and optimal frequency control. We propose a fully distributed optimal frequency control algorithm based on the projected primal-dual gradient method and by leveraging the structure of the underlying physical system dynamics. The proposed algorithm i) restores the nominal system frequency while minimizing total control cost and enforcing IBR power capacity limits and line thermal constraints, and ii) operates in a distributed manner that only needs local measurements and neighbor-to-neighbor communication. In particular, when the line thermal constraints are disregarded, the proposed algorithm admits a fully local implementation that requires no communication, while still ensuring optimality and satisfying IBR power capacity limits. We establish the global asymptotic convergence of the algorithm using Lyapunov stability analysis. The effectiveness and optimality of the proposed algorithms are validated through high-fidelity, 100% inverter-based electromagnetic transient (EMT) simulations on the IEEE 39-bus system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12682v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xiaoyang Wang, Xin Chen</dc:creator>
    </item>
    <item>
      <title>Formal Verification of Markov Processes with Learned Parameters</title>
      <link>https://arxiv.org/abs/2501.15767</link>
      <description>arXiv:2501.15767v2 Announce Type: replace-cross 
Abstract: We introduce the problem of formally verifying properties of Markov processes where the parameters are given by the output of machine learning models. For a broad class of machine learning models, including linear models, tree-based models, and neural networks, verifying properties of Markov chains like reachability, hitting time, and total reward can be formulated as a bilinear program. We develop a decomposition and bound propagation scheme for solving the bilinear program and show through computational experiments that our method solves the problem to global optimality up to 100x faster than state-of-the-art solvers. To demonstrate the practical utility of our approach, we apply it to a real-world healthcare case study. Along with the paper, we release markovml, an open-source tool for building Markov processes, integrating pretrained machine learning models, and verifying their properties, available at https://github.com/mmaaz-git/markovml.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.15767v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Muhammad Maaz, Timothy C. Y. Chan</dc:creator>
    </item>
    <item>
      <title>Learning to Fuse Temporal Proximity Networks: A Case Study in Chimpanzee Social Interactions</title>
      <link>https://arxiv.org/abs/2502.00302</link>
      <description>arXiv:2502.00302v2 Announce Type: replace-cross 
Abstract: How can we identify groups of primate individuals which could be conjectured to drive social structure? To address this question, one of us has collected a time series of data for social interactions between chimpanzees. Here we use a network representation, leading to the task of combining these data into a time series of a single weighted network per time stamp, where different proximities should be given different weights reflecting their relative importance. We optimize these proximity-type weights in a principled way, using an innovative loss function which rewards structural consistency across time. The approach is empirically validated by carefully designed synthetic data. Using statistical tests, we provide a way of identifying groups of individuals that stay related for a significant length of time. Applying the approach to the chimpanzee data set, we detect cliques in the animal social network time series, which can be validated by real-world intuition from prior research and qualitative observations by chimpanzee experts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00302v2</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yixuan He, Aaron Sandel, David Wipf, Mihai Cucuringu, John Mitani, Gesine Reinert</dc:creator>
    </item>
    <item>
      <title>Pareto-Nash Allocations under Incomplete Information: A Model of Stable Optima</title>
      <link>https://arxiv.org/abs/2503.22825</link>
      <description>arXiv:2503.22825v2 Announce Type: replace-cross 
Abstract: Prior literature on two-firm two-market and two-stage extended dynamic models has introduced what Guth (2016) succinctly terms a social dilemma. A state in which conglomerate firms competing in a Bertrand duopoly consider jointly optimizing profits under a tacit self-enforcing agreement to deter market entry. This theoretical article reinterprets the social dilemma highlighted by Guth (2016) not only in the context of allocation but also through the lens of competition where entry must legally be permitted even if cooperative signalling would otherwise sustain joint profitability. This study explores the significance of a sufficiency condition on each firm's non-instantaneous reaction function requiring the maintenance of a stable long-run equilibrium through retaliative restraint characterized by either two negative eigenvalues or a saddle-path trajectory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.22825v2</guid>
      <category>econ.GN</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alfred A. B. Mayaki</dc:creator>
    </item>
  </channel>
</rss>
