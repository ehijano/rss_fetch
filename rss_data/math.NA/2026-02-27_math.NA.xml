<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.NA</link>
    <description>math.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 27 Feb 2026 05:00:22 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A Reduced Order Model approach for First-Principles Molecular Dynamics Computations</title>
      <link>https://arxiv.org/abs/2602.22390</link>
      <description>arXiv:2602.22390v1 Announce Type: new 
Abstract: To leverage the redundancy between the electronic structure computed at each step of first-principles molecular dynamics, we present a data-driven modeling framework for Kohn-Sham Density Functional Theory that bypasses the explicit optimization of electronic wavefunctions. We sample a priori representative atomic configurations and construct a low-dimensional basis that efficiently approximates the electronic structure subspace. Subsequently, we employ this reduced basis in a direct solver for the electronic single particle density matrix, thereby enabling the efficient determination of ground state without iterative wavefunction optimization. We demonstrate the efficacy of our approach in a Born-Oppenheimer molecular dynamics of a water molecule, showing that the resulting simulations accurately reproduce key structural properties, such as bond lengths and bond angle, obtained from full first-principles molecular dynamics. This work highlights the potential of data-driven approaches to develop efficient electronic structure solvers for first-principles simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.22390v1</guid>
      <category>math.NA</category>
      <category>cond-mat.mtrl-sci</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Siu Wun Cheung, Youngsoo Choi, Jean-Luc Fattebert, Jonas Kaufman, Daniel Osei-Kuffuor</dc:creator>
    </item>
    <item>
      <title>Error Analysis of Parameter Prediction via Gaussian Process Regression and Its Application to Weighted Jacobi Iteration</title>
      <link>https://arxiv.org/abs/2602.22679</link>
      <description>arXiv:2602.22679v1 Announce Type: new 
Abstract: In this paper, we introduce a novel theoretical framework for Gaussian process regression error analysis, leveraging a function-space decomposition. Based on this framework, we develop a weighted Jacobi iterative method that utilizes Gaussian process regression for parameter prediction and provide a corresponding convergence analysis. Moreover, the convergence conditions are designed to be compatible with other error bounds, enabling a more general analysis. Experimental results show that the parameters predicted based on Gaussian process regression significantly accelerate the convergence speed of Jacobi iterations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.22679v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tiantian Sun, Juan Zhang</dc:creator>
    </item>
    <item>
      <title>Comparison of Structure-Preserving Methods for the Cahn-Hilliard-Navier-Stokes Equations</title>
      <link>https://arxiv.org/abs/2602.22861</link>
      <description>arXiv:2602.22861v1 Announce Type: new 
Abstract: We develop structure-preserving discontinuous Galerkin methods for the Cahn-Hilliard-Navier-Stokes equations with degenerate mobility. The proposed SWIPD-L and SIPGD-L methods incorporate parametrized mobility fluxes with edge-wise mobility treatments for enhanced coercivity-stability control. We prove coercivity for the generalized trilinear form and demonstrate optimal convergence rates while preserving mass conservation, energy dissipation, and the discrete maximum principle. Comparisons with existing SIPG-L and SWIP-L methods confirm similar stability. Validation on $hp$-adaptive meshes for both standalone Cahn-Hilliard and coupled systems shows significant computational savings without accuracy loss.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.22861v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jimmy Kornelije Gunnarsson, Robert Kl\"ofkorn</dc:creator>
    </item>
    <item>
      <title>A Reduced Magnetic Vector Potential Approach with Higher-Order Splines</title>
      <link>https://arxiv.org/abs/2602.22997</link>
      <description>arXiv:2602.22997v1 Announce Type: new 
Abstract: This work presents a high-order isogeometric formulation for magnetoquasistatic eddy-current problems based on a decomposition into Biot-Savart-driven source fields and finite-element reaction fields. Building upon a recently proposed surface-only Biot-Savart evaluation, we generalize the reduced magnetic vector potential framework to the quasistatic regime and introduce a consistent high-order spline discretization. The resulting method avoids coil meshing, supports arbitrary winding paths, and enables high-order field approximation within a reduced computational domain. Beyond establishing optimal convergence rates, the numerical investigation identifies the requirements necessary to recover high-order accuracy in practice, including geometric regularity of the enclosing interface, accurate kernel quadrature, and compatible trace spaces for the source-reaction coupling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.22997v1</guid>
      <category>math.NA</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Merle Backmeyer, Laura A. M. D'Angelo, Brahim Ramdane, Sebastian Sch\"ops</dc:creator>
    </item>
    <item>
      <title>Nearest Reversible Markov Chains with Sparsity Constraints: An Optimization Approach</title>
      <link>https://arxiv.org/abs/2602.23059</link>
      <description>arXiv:2602.23059v1 Announce Type: new 
Abstract: Reversibility is a key property of Markov chains, central to algorithms such as Metropolis-Hastings and other MCMC methods. Yet many applications yield non-reversible chains, motivating the problem of approximating them by reversible ones with minimal modification. We formulate this task as a matrix nearness problem and focus on the practically relevant case of sparse transition matrices. The resulting optimization problem is a quadratic programming problem, and numerical experiments illustrate the effectiveness of the approach. This framework provides a principled way to enforce reversibility and sparsity patterns in Markov chains with applications in MCMC, computational chemistry, and data-driven modeling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.23059v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Stefano Cipolla, Fabio Durastante, Miryam Gnazzo, Beatrice Meini</dc:creator>
    </item>
    <item>
      <title>A Hyperbolic Transport Model for Passenger Flow on Tram Networks</title>
      <link>https://arxiv.org/abs/2602.23081</link>
      <description>arXiv:2602.23081v1 Announce Type: new 
Abstract: We introduce a modeling framework for an urban tram network based on a hyperbolic partial differential equation describing the transport of passengers along the network, coupled with a family of stochastic processes representing passenger boarding. Solutions are considered in a measure-valued sense. The system is further extended and subjected to uncertainties such as delays and service interruptions through a numerical study. Its robustness is assessed using appropriate risk measures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.23081v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Schillinger</dc:creator>
    </item>
    <item>
      <title>On the choice of viscous discontinuous Galerkin discretization for entropy correction artificial viscosity methods</title>
      <link>https://arxiv.org/abs/2602.23210</link>
      <description>arXiv:2602.23210v1 Announce Type: new 
Abstract: Entropy correction artificial viscosity (ECAV) is an approach for enforcing a semi-discrete entropy inequality through an entropy dissipative correction term. The resulting method can be implemented as an artificial viscosity with an extremely small viscosity coefficient. In this work, we analyze ECAV when the artificial viscosity is discretized using a local discontinuous Galerkin (LDG) method. We prove an $O(h)$ upper bound on the ECAV coefficient, indicating that ECAV does not result in a restrictive time-step condition. We additionally show that ECAV is contact preserving, and compare ECAV to traditional shock capturing artificial viscosity methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.23210v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Samuel Q. Van Fleet, Jesse Chan</dc:creator>
    </item>
    <item>
      <title>Learning geometry-dependent lead-field operators for forward ECG modeling</title>
      <link>https://arxiv.org/abs/2602.22367</link>
      <description>arXiv:2602.22367v1 Announce Type: cross 
Abstract: Modern forward electrocardiogram (ECG) computational models rely on an accurate representation of the torso domain. The lead-field method enables fast ECG simulations while preserving full geometric fidelity. Achieving high anatomical accuracy in torso representation is, however, challenging in clinical practice, as imaging protocols are typically focused on the heart and often do not include the entire torso. In addition, the computational cost of the lead-field method scales linearly with the number of electrodes, limiting its applicability in high-density recording settings. To date, no existing approach simultaneously achieves high anatomical fidelity, low data requirements and computational efficiency. In this work, we propose a shape-informed surrogate model of the lead-field operator that serves as a drop-in replacement for the full-order model in forward ECG simulations. The proposed framework consists of two components: a geometry-encoding module that maps anatomical shapes into a low-dimensional latent space, and a geometry-conditioned neural surrogate that predicts lead-field gradients from spatial coordinates, electrode positions and latent codes. The proposed method achieves high accuracy in approximating lead fields both within the torso (mean angular error 5{\deg}) and inside the heart, resulting in highly accurate ECG simulations (relative mean squared error &lt;2.5%. The surrogate consistently outperforms the widely used pseudo lead-field approximation while preserving negligible inference cost. Owing to its compact latent representation, the method does not require a fully detailed torso segmentation and can therefore be deployed in data-limited settings while preserving high-fidelity ECG simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.22367v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>q-bio.TO</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arsenii Dokuchaev, Francesca Bonizzoni, Stefano Pagani, Francesco Regazzoni, Simone Pezzuto</dc:creator>
    </item>
    <item>
      <title>Quadratization of Autonomous Partial Differential Equations: Theory and Algorithms</title>
      <link>https://arxiv.org/abs/2602.22371</link>
      <description>arXiv:2602.22371v1 Announce Type: cross 
Abstract: Quadratization for partial differential equations (PDEs) is a process that transforms a nonquadratic PDE into a quadratic form by introducing auxiliary variables. This symbolic transformation has been used in diverse fields to simplify the analysis, simulation, and control of nonlinear and nonquadratic PDE models. This paper presents a rigorous definition of PDE quadratization, theoretical results for the PDE quadratization problem of spatially one-dimensional PDEs-including results on existence and complexity-and introduces QuPDE, an algorithm based on symbolic computation and discrete optimization that outputs a quadratization for any spatially one-dimensional polynomial or rational PDE. This algorithm is the first computational tool to find quadratizations for PDEs to date. We demonstrate QuPDE's performance by applying it to fourteen nonquadratic PDEs in diverse areas such as fluid mechanics, space physics, chemical engineering, and biological processes. QuPDE delivers a low-order quadratization in each case, uncovering quadratic transformations with fewer auxiliary variables than those previously discovered in the literature for some examples, and finding quadratizations for systems that had not been transformed to quadratic form before.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.22371v1</guid>
      <category>cs.SC</category>
      <category>cs.MS</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <category>math.NA</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Albani Olivieri, Gleb Pogudin, Boris Kramer</dc:creator>
    </item>
    <item>
      <title>TorchLean: Formalizing Neural Networks in Lean</title>
      <link>https://arxiv.org/abs/2602.22631</link>
      <description>arXiv:2602.22631v1 Announce Type: cross 
Abstract: Neural networks are increasingly deployed in safety- and mission-critical pipelines, yet many verification and analysis results are produced outside the programming environment that defines and runs the model. This separation creates a semantic gap between the executed network and the analyzed artifact, so guarantees can hinge on implicit conventions such as operator semantics, tensor layouts, preprocessing, and floating-point corner cases. We introduce TorchLean, a framework in the Lean 4 theorem prover that treats learned models as first-class mathematical objects with a single, precise semantics shared by execution and verification. TorchLean unifies (1) a PyTorch-style verified API with eager and compiled modes that lower to a shared op-tagged SSA/DAG computation-graph IR, (2) explicit Float32 semantics via an executable IEEE-754 binary32 kernel and proof-relevant rounding models, and (3) verification via IBP and CROWN/LiRPA-style bound propagation with certificate checking. We validate TorchLean end-to-end on certified robustness, physics-informed residual bounds for PINNs, and Lyapunov-style neural controller verification, alongside mechanized theoretical results including a universal approximation theorem. These results demonstrate a semantics-first infrastructure for fully formal, end-to-end verification of learning-enabled systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.22631v1</guid>
      <category>cs.MS</category>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <category>cs.NA</category>
      <category>cs.PL</category>
      <category>math.NA</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Robert Joseph George, Jennifer Cruden, Xiangru Zhong, Huan Zhang, Anima Anandkumar</dc:creator>
    </item>
    <item>
      <title>QuadSync: Quadrifocal Tensor Synchronization via Tucker Decomposition</title>
      <link>https://arxiv.org/abs/2602.22639</link>
      <description>arXiv:2602.22639v1 Announce Type: cross 
Abstract: In structure from motion, quadrifocal tensors capture more information than their pairwise counterparts (essential matrices), yet they have often been thought of as impractical and only of theoretical interest. In this work, we challenge such beliefs by providing a new framework to recover $n$ cameras from the corresponding collection of quadrifocal tensors. We form the block quadrifocal tensor and show that it admits a Tucker decomposition whose factor matrices are the stacked camera matrices, and which thus has a multilinear rank of (4,~4,~4,~4) independent of $n$. We develop the first synchronization algorithm for quadrifocal tensors, using Tucker decomposition, alternating direction method of multipliers, and iteratively reweighted least squares. We further establish relationships between the block quadrifocal, trifocal, and bifocal tensors, and introduce an algorithm that jointly synchronizes these three entities. Numerical experiments demonstrate the effectiveness of our methods on modern datasets, indicating the potential and importance of using higher-order information in synchronization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.22639v1</guid>
      <category>cs.CV</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Daniel Miao, Gilad Lerman, Joe Kileel</dc:creator>
    </item>
    <item>
      <title>The AI Research Assistant: Promise, Peril, and a Proof of Concept</title>
      <link>https://arxiv.org/abs/2602.22842</link>
      <description>arXiv:2602.22842v1 Announce Type: cross 
Abstract: Can artificial intelligence truly contribute to creative mathematical research, or does it merely automate routine calculations while introducing risks of error? We provide empirical evidence through a detailed case study: the discovery of novel error representations and bounds for Hermite quadrature rules via systematic human-AI collaboration.
  Working with multiple AI assistants, we extended results beyond what manual work achieved, formulating and proving several theorems with AI assistance. The collaboration revealed both remarkable capabilities and critical limitations. AI excelled at algebraic manipulation, systematic proof exploration, literature synthesis, and LaTeX preparation. However, every step required rigorous human verification, mathematical intuition for problem formulation, and strategic direction.
  We document the complete research workflow with unusual transparency, revealing patterns in successful human-AI mathematical collaboration and identifying failure modes researchers must anticipate. Our experience suggests that, when used with appropriate skepticism and verification protocols, AI tools can meaningfully accelerate mathematical discovery while demanding careful human oversight and deep domain expertise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.22842v1</guid>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tan Bui-Thanh</dc:creator>
    </item>
    <item>
      <title>Multidimensional Task Learning: A Unified Tensor Framework for Computer Vision Tasks</title>
      <link>https://arxiv.org/abs/2602.23217</link>
      <description>arXiv:2602.23217v1 Announce Type: cross 
Abstract: This paper introduces Multidimensional Task Learning (MTL), a unified mathematical framework based on Generalized Einstein MLPs (GE-MLPs) that operate directly on tensors via the Einstein product. We argue that current computer vision task formulations are inherently constrained by matrix-based thinking: standard architectures rely on matrix-valued weights and vectorvalued biases, requiring structural flattening that restricts the space of naturally expressible tasks. GE-MLPs lift this constraint by operating with tensor-valued parameters, enabling explicit control over which dimensions are preserved or contracted without information loss. Through rigorous mathematical derivations, we demonstrate that classification, segmentation, and detection are special cases of MTL, differing only in their dimensional configuration within a formally defined task space. We further prove that this task space is strictly larger than what matrix-based formulations can natively express, enabling principled task configurations such as spatiotemporal or cross modal predictions that require destructive flattening under conventional approaches. This work provides a mathematical foundation for understanding, comparing, and designing computer vision tasks through the lens of tensor algebra.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.23217v1</guid>
      <category>cs.CV</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alaa El Ichi, Khalide Jbilou</dc:creator>
    </item>
    <item>
      <title>Convergence of spectral discretization for the flow of diffeomorphisms</title>
      <link>https://arxiv.org/abs/2410.06788</link>
      <description>arXiv:2410.06788v2 Announce Type: replace 
Abstract: The Large Deformation Diffeomorphic Metric Mapping (LDDMM) or flow of diffeomorphism is a classical framework in the field of shape spaces and is widely applied in mathematical imaging and computational anatomy. Essentially, it equips a group of diffeomorphisms with a right-invariant Riemannian metric, which allows to compute (Riemannian) distances or interpolations between different deformations. The associated Euler--Lagrange equation of shortest interpolation paths is one of the standard examples of a partial differential equation that can be approached with Lie group theory (by interpreting it as a geodesic ordinary differential equation on the Lie group of diffeomorphisms). The particular group $\mathcal D^m$ of Sobolev diffeomorphisms is by now sufficiently understood to allow the analysis of geodesics and their numerical approximation. We prove convergence of a widely used Fourier-type space discretization of the geodesic equation. It is based on a regularity estimate, for which we also provide a new proof: Geodesics in $\mathcal D^m$ preserve any higher order Sobolev regularity of their initial velocity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06788v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Benedikt Wirth</dc:creator>
    </item>
    <item>
      <title>Well-posedness and Regularity of the Integral Invariant Model from Linear Scalar Transport Equation</title>
      <link>https://arxiv.org/abs/2503.07028</link>
      <description>arXiv:2503.07028v3 Announce Type: replace 
Abstract: An integral invariant model derived from the coupling of the transport equation and its adjoint equation is investigated.Despite extensive research on the numerical implementation of this model,no studies have yet explored the well-posedness and regularity of the model itself.To address this gap,firstly, a comprehensive mathematical definition is formulated as a Cauchy initial value problem for the integral invariant model.This formulation preserves essential background information derived from relevant numerical algorithms.In the above definition,we directly evolve the time-dependent test function $\psi(\mathbf{x},t)$ through explicit construction rather than solving the adjoint equation,which enables reducing the required regularity of the test function $\Psi(\mathbf{x})$ from $C^1(\Omega)$ to $L^2(\Omega)$,contributing to stability proof. The challenge arising from the mismatch of integration domains on both sides of the model's equivalent form is overcome through the compact support property of test functions. For any arbitrary time instant $t^{*}\in[0,T]$,an abstract function $\mathcal{U}(\lambda)$ taking values in the Banach space $L^2(\mathbb{R}^d)$ is initially constructed on the entire space $\mathbb{R}^d$ via the Riesz representation theorem.Subsequently,this function is properly restricted to the time-dependent bounded domain $\widetilde{\Omega}(t)$ through multiplication by the characteristic function. The existence of this model's solution in $L^{1}([0,T],L^2(\widetilde{\Omega}(t)))$ is then rigorously established.Furthermore,by judiciously selecting test functions $\Psi$, the stability of the integral invariant model is proved, from which the uniqueness naturally follows.Finally, when the initial value \(\widetilde{U}_0 \in L^{2}(\widetilde{\Omega}(0))\),the temporal integrability of the model over $[0,T]$ can be enhanced to \(L^{\infty}([0,T],L^2(\widetilde{\Omega}(t)))\).</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.07028v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhengrong Xie</dc:creator>
    </item>
    <item>
      <title>Extracting Dual Analytic Geometries of Linear Transformations to Achieve Efficient Computation</title>
      <link>https://arxiv.org/abs/2506.11990</link>
      <description>arXiv:2506.11990v3 Announce Type: replace 
Abstract: We propose a novel framework for fast integral operations by uncovering hidden geometries in the row and column structures of the underlying operators. This is accomplished through the \texttt{Questionnaire} algorithm, an iterative procedure that constructs adaptive hierarchical partition trees, revealing latent multiscale organizations and exposing local low-rank structures within the data. Guided by these geometries, we employ two complementary techniques: (1) The \texttt{\texttt{Butterfly}} algorithm, which exploits the learned hierarchical low-rank structure; and (2) Adaptive \texttt{eGHWT}, best tilings in both space and frequency using all levels of the generalized Haar--Walsh wavelet packets. These techniques enable efficient matrix factorization and multiplication. We coin our algorithms as \texttt{Questionnaire Factorization and Fast Transform (QFFT)}. Unlike classical approaches that rely on prior knowledge of the underlying geometry, \texttt{QFFT} is fully data-driven and applicable to matrices arising from irregular or unknown distributions. Even when the rows and columns both appear mutually orthogonal, our framework identifies the intrinsic ordering of orthogonal vectors that reveal hidden sparsity of the kernel. We demonstrate the effectiveness of our approach on matrices associated with heterogeneous operators and families of orthogonal polynomials. The resulting compressed representations reduce storage complexity from $\mathcal{O}(N^2)$ to $\mathcal{O}(N \log N)$, enabling fast computation and scalable implementation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11990v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Pei-Chun Su, Ronald R. Coifman</dc:creator>
    </item>
    <item>
      <title>Robust Containment Queries over Collections of Trimmed NURBS Surfaces via Generalized Winding Numbers</title>
      <link>https://arxiv.org/abs/2504.11435</link>
      <description>arXiv:2504.11435v3 Announce Type: replace-cross 
Abstract: We propose a containment query that is robust to the watertightness of regions bound by trimmed NURBS surfaces, as this property is difficult to guarantee for in-the-wild CAD models. Containment is determined through the generalized winding number (GWN), a mathematical construction that is indifferent to the arrangement of surfaces in the shape. Applying contemporary techniques for the 3D GWN to trimmed NURBS surfaces requires some form of geometric discretization, introducing computational inefficiency to the algorithm and even risking containment misclassifications near the surface. In contrast, our proposed method leverages properties of the 3D solid angle to solve the relevant surface integral using a boundary formulation with rapidly converging adaptive quadrature. Batches of queries are further accelerated by \textit{memoizing} (i.e. caching and reusing) quadrature node positions and tangents as they are evaluated. We demonstrate that our GWN method is robust to complex trimming geometry in a CAD model, and is accurate up to arbitrary precision at arbitrary distances from the surface. The derived containment query is therefore robust to model non-watertightness while respecting all curved features of the input shape.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11435v3</guid>
      <category>cs.GR</category>
      <category>cs.CG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3797957</arxiv:DOI>
      <dc:creator>Jacob Spainhour, Kenneth Weiss</dc:creator>
    </item>
    <item>
      <title>Composable and adaptive design of machine learning interatomic potentials guided by Fisher-information analysis</title>
      <link>https://arxiv.org/abs/2504.19372</link>
      <description>arXiv:2504.19372v2 Announce Type: replace-cross 
Abstract: An adaptive physics-inspired model design strategy for machine-learning interatomic potentials (MLIPs) is proposed. This strategy relies on iterative reconfigurations of composite models from single-term models, followed by a unified training procedure. A model evaluation method based on the Fisher information matrix (FIM) and multiple-property error metrics is also proposed to guide the model reconfiguration and hyperparameter optimization. By combining the reconfiguration and the evaluation subroutines, we provide an adaptive MLIP design strategy that balances flexibility and extensibility. In a case study of designing models against a structurally diverse niobium dataset, we managed to obtain an optimal model configuration with 75 parameters generated by our framework that achieved a force RMSE of 0.172 eV/{\AA} and an energy RMSE of 0.013 eV/atom.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19372v2</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.app-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Weishi Wang, Mark K. Transtrum, Vincenzo Lordi, Vasily V. Bulatov, Amit Samanta</dc:creator>
    </item>
    <item>
      <title>An RBF-based method for computational electromagnetics with reduced numerical dispersion</title>
      <link>https://arxiv.org/abs/2508.18205</link>
      <description>arXiv:2508.18205v3 Announce Type: replace-cross 
Abstract: The finite difference time domain method is one of the simplest and most popular methods in computational electromagnetics. This work considers two possible ways of generalising it to a meshless setting by employing local radial basis function interpolation. The resulting methods remain fully explicit and are convergent if properly chosen hyperviscosity terms are added to the update equations. We demonstrate that increasing the stencil size of the approximation has a desirable effect on numerical dispersion. Furthermore, our proposed methods can exhibit a decreased dispersion anisotropy compared to the finite difference time domain method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18205v3</guid>
      <category>physics.comp-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.cma.2026.118865</arxiv:DOI>
      <arxiv:journal_reference>Computer Methods in Applied Mechanics and Engineering (CMAME), Volume 454, 1 june 2026, 118865</arxiv:journal_reference>
      <dc:creator>Andrej Kolar-Po\v{z}un, Gregor Kosec</dc:creator>
    </item>
    <item>
      <title>Media Coverage of War Victims: Journalistic Biases in Reporting on Israel and Gaza</title>
      <link>https://arxiv.org/abs/2510.06453</link>
      <description>arXiv:2510.06453v3 Announce Type: replace-cross 
Abstract: October 7, 2023 marked the start of a war against Gaza, one of the most devastating conflicts in modern history, which quickly produced a stark global attitudinal divide. To examine the role of media bias in shaping public understanding of this asymmetrical war, we analyzed more than 14,000 news articles published during its first year across three major Western outlets (The New York Times, BBC, CNN) and one non-Western English-language outlet (Al Jazeera English). Focusing on media narratives surrounding Israeli and Palestinian victims, we identify three systematic biases in Western coverage: (1) Identifiable Victim Reporting: Israeli victims were substantially more likely to be depicted as identifiable individuals, whereas Palestinian victims were predominantly represented as undifferentiated collectives. (2) Equalization Bias: Despite the profound asymmetry in casualties, displacement, and other forms of suffering, Western reporting repeatedly invoked the October 7 attacks to equalize Israeli and Palestinian victimhood, even in the absence of new Israeli-casualty events. (3) One-sided Doubt Casting: Journalists disproportionately used language that casts doubt on the credibility of casualty figures and the reliability of sources when reporting Palestinian (vs. Israeli) victim counts, selectively undermining trust in information about Palestinian suffering. Across all three phenomena, these patterns were either absent or greatly attenuated in Al Jazeera English. Taken together, our analysis uncovers a coherent set of systematic biases in high-profile Western media coverage of the Gaza war, with implications for how global audiences come to understand and morally evaluate the conflict.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06453v3</guid>
      <category>cs.SI</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bedoor AlShebli, Bruno Gabriel Salvador Casara, Anne Maass</dc:creator>
    </item>
    <item>
      <title>DeepMartingale: Duality of the Optimal Stopping Problem with Expressivity and High-Dimensional Hedging</title>
      <link>https://arxiv.org/abs/2510.13868</link>
      <description>arXiv:2510.13868v2 Announce Type: replace-cross 
Abstract: We propose \textit{DeepMartingale}, a deep-learning framework for the dual formulation of discrete-monitoring optimal stopping problems under continuous-time models. Leveraging a martingale representation, our method implements a \emph{pure-dual} procedure that directly optimizes over a parameterized class of martingales, producing computable and tight \emph{dual upper bounds} for the value function in high-dimensional settings without requiring any primal information or Snell-envelope approximation. We prove convergence of the resulting upper bounds under mild assumptions for both first- and second-moment losses. A key contribution is an expressivity theorem showing that \textit{DeepMartingale} can approximate the true value function to any prescribed accuracy $\varepsilon$ using neural networks of size at most $\tilde{c} d^{\tilde{q}}\varepsilon^{-\tilde{r}}$, with constants independent of the dimension $d$ and accuracy $\varepsilon$, thereby avoiding the curse of dimensionality. Since expressivity in this setting translates into scalability, our theory also motivates estimating the dimension scaling law to guide architecture design and the training setup in deep learning-based numerical computation and the choice of rebalancing frequency for the related hedging strategy. The learned martingale representation further yields a practical and dimension-scalable \emph{deep delta hedging strategy}. Numerical experiments on high-dimensional Bermudan option benchmarks confirm convergence, expressivity, scalable training, and the stability of the resulting upper bounds and hedging performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13868v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Junyan Ye, Hoi Ying Wong</dc:creator>
    </item>
    <item>
      <title>An initial-boundary value problem describing moisture transport in porous media: existence of strong solutions and an error estimate for a finite volume scheme</title>
      <link>https://arxiv.org/abs/2511.10378</link>
      <description>arXiv:2511.10378v2 Announce Type: replace-cross 
Abstract: We consider an initial-boundary value problem motivated by a mathematical model of moisture transport in porous media. We establish the existence of strong solutions and provide an error estimate for the approximate solutions constructed by the finite volume method. In the proof of the error estimate, the Gagliardo--Nirenberg type inequality for the difference between a continuous function and a piecewise constant function plays an important role.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.10378v2</guid>
      <category>math.AP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Akiko Morimura, Toyohiko Aiki</dc:creator>
    </item>
  </channel>
</rss>
