<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 03 Dec 2025 05:01:51 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Semiparametric Robust Estimation of Population Location</title>
      <link>https://arxiv.org/abs/2512.03021</link>
      <description>arXiv:2512.03021v1 Announce Type: new 
Abstract: Real-world measurements often comprise a dominant signal contaminated by a noisy background. Robustly estimating the dominant signal in practice has been a fundamental statistical problem. Classically, mixture models have been used to cluster the heterogeneous population into homogeneous components. Modeling such data with fully parametric models risks bias under misspecification, while fully nonparametric approaches can dissipate power and computational resources. We propose a middle path: a semiparametric method that models only the dominant component parametrically and leaves the background completely nonparametric, yet remains computationally scalable and statistically robust. So instead of outlier downweighting, traditionally done in robust statistics literature, we maximize the observed likelihood such that the noisy background is absorbed by the nonparametric component. Computationally, we propose a new approximate FFT-accelerated likelihood maximization algorithm. Empirically, this FFT plug-in achieves order-of-magnitude speedups over vanilla weighted EM while preserving statistical accuracy and large sample properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.03021v1</guid>
      <category>stat.CO</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ananyabrata Barua, Ayanendranath Basu</dc:creator>
    </item>
    <item>
      <title>Tolerance Intervals Using Dirichlet Processes</title>
      <link>https://arxiv.org/abs/2512.02178</link>
      <description>arXiv:2512.02178v1 Announce Type: cross 
Abstract: In nonclinical pharmaceutical development, tolerance intervals are critical in ensuring product and process quality. They are statistical intervals designed to contain a specified proportion of the population with a given confidence level. Parametric and non-parametric methods have been developed to obtain tolerance intervals. The former work with small samples but can be affected by distribution misspecification. The latter offer larger flexibility but require large sample sizes. As an alternative, we propose Dirichlet process-based Bayesian nonparametric tolerance intervals to overcome the limitations. We develop a computationally efficient tolerance interval construction algorithm based on the analytically tractable quantile process of the Dirichlet process. Simulation studies show that our new approach is very robust to distributional assumptions and performs as efficiently as existing tolerance interval methods. To illustrate how the model works in practice, we apply our method to the tolerance interval estimation for potency data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02178v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Seokjun Choi, Tony Pourmohamad, Bruno Sans\'o</dc:creator>
    </item>
    <item>
      <title>Simulation and inference methods for non-Markovian stochastic biochemical reaction networks</title>
      <link>https://arxiv.org/abs/2512.02478</link>
      <description>arXiv:2512.02478v1 Announce Type: cross 
Abstract: Stochastic models of biochemical reaction networks are widely used to capture intrinsic noise in cellular systems. The typical formulation of these models are based on Markov processes for which there is extensive research on efficient simulation and inference. However, there are biological processes, such as gene transcription and translation, that introduce history dependent dynamics requiring non-Markovian processes to accurately capture the stochastic dynamics of the system. This greater realism comes with additional computational challenges for simulation and parameter inference. We develop efficient stochastic simulation algorithms for well-mixed non-Markovian stochastic biochemical reaction networks with delays that depend on system state and time. Our methods generalize the next reaction method and $\tau$-leaping method to support arbitrary inter-event time distributions while preserving computational scalability. We also introduce a coupling scheme to generate exact non-Markovian sample paths that are positively correlated to an approximate non-Markovian $\tau$-leaping sample path. This enables substantial computational gains for Bayesian inference of model parameters though multifidelity simulation-based inference schemes. We demonstrate the effectiveness of our approach on a gene regulation model with delayed auto-inhibition, showing substantial gains in both simulation accuracy and inference efficiency of two orders of magnitude. These results extend the practical applicability of non-Markovian models in systems biology and beyond.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02478v1</guid>
      <category>q-bio.MN</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.CO</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thomas P. Steele, David J. Warne</dc:creator>
    </item>
    <item>
      <title>Optimised Annealed Sequential Monte Carlo Samplers</title>
      <link>https://arxiv.org/abs/2408.12057</link>
      <description>arXiv:2408.12057v2 Announce Type: replace 
Abstract: Annealed Sequential Monte Carlo (ASMC) samplers are special cases of SMC samplers where the sequence of distributions can be embedded in a smooth path of distributions. Using this underlying path and a performance model based on the variance of the normalising constant estimator, we systematically study dense-schedule limits. From our theory emerges a notion of global barrier, capturing the inherent complexity of normalising constant approximation under our performance model. We then turn the resulting approximations into surrogate objective functions of algorithm performance, using them to guide method development. This leads to novel adaptive methods, Optimised Annealed SMC (OASMC), which address practical difficulties inherent in previous adaptive SMC methods. First, our OASMC algorithms are predictable: they produce a sequence of increasingly precise estimates at deterministic, known times. Second, Optimised Annealed Importance Sampling (OAIS), a special case of OASMC, enables schedule adaptation at a memory cost constant in the number of particles, requiring significantly less communication. Finally, these characteristics make OAIS highly efficient on GPUs. We provide an open-source, high-performance GPU implementation of our method and demonstrate up to a hundred-fold speed improvement compared to state-of-the-art adaptive AIS methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12057v2</guid>
      <category>stat.CO</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Saifuddin Syed, Alexandre Bouchard-C\^ot\'e, Kevin Chern, Arnaud Doucet</dc:creator>
    </item>
    <item>
      <title>Parallelizing MCMC Across the Sequence Length</title>
      <link>https://arxiv.org/abs/2508.18413</link>
      <description>arXiv:2508.18413v2 Announce Type: replace 
Abstract: Markov chain Monte Carlo (MCMC) methods are foundational algorithms for Bayesian inference and probabilistic modeling. However, most MCMC algorithms are inherently sequential and their time complexity scales linearly with the sequence length. Previous work on adapting MCMC to modern hardware has therefore focused on running many independent chains in parallel. Here, we take an alternative approach: we propose algorithms to evaluate MCMC samplers in parallel across the chain length. To do this, we build on recent methods for parallel evaluation of nonlinear recursions that formulate the state sequence as a solution to a fixed-point problem and solve for the fixed-point using a parallel form of Newton's method. We show how this approach can be used to parallelize Gibbs, Metropolis-adjusted Langevin, and Hamiltonian Monte Carlo sampling across the sequence length. In several examples, we demonstrate the simulation of up to hundreds of thousands of MCMC samples with only tens of parallel Newton iterations. Additionally, we develop two new parallel quasi-Newton methods to evaluate nonlinear recursions with lower memory costs and reduced runtime. We find that the proposed parallel algorithms accelerate MCMC sampling across multiple examples, in some cases by more than an order of magnitude compared to sequential evaluation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18413v2</guid>
      <category>stat.CO</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David M. Zoltowski, Skyler Wu, Xavier Gonzalez, Leo Kozachkov, Scott W. Linderman</dc:creator>
    </item>
    <item>
      <title>SVEMnet: An R package for Self-Validated Elastic-Net Ensembles and Multi-Response Optimization in Small-Sample Mixture--Process Experiments</title>
      <link>https://arxiv.org/abs/2511.20968</link>
      <description>arXiv:2511.20968v2 Announce Type: replace 
Abstract: SVEMnet is an R package for fitting Self-Validated Ensemble Models (SVEM) with elastic-net base learners and performing multi-response optimization in small-sample mixture-process design-of-experiments (DOE) studies with numeric, categorical, and mixture factors. SVEMnet wraps elastic-net and relaxed elastic-net models for Gaussian and binomial responses from glmnet in a fractional random-weight (FRW) resampling scheme with anti-correlated train/validation weights; penalties are selected by validation-weighted AIC- and BIC-type criteria, and predictions are averaged across replicates to stabilize fits near the interpolation boundary. In addition to the core SVEM engine, the package provides deterministic high-order formula expansion, a permutation-based whole-model test heuristic, and a mixture-constrained random-search optimizer that combines Derringer-Suich desirability functions, bootstrap-based uncertainty summaries, and optional mean-level specification-limit probabilities to generate scored candidate tables and diverse exploitation and exploration medoids for sequential fit--score--run--refit workflows. A simulated lipid nanoparticle (LNP) formulation study illustrates these tools in a small-sample mixture-process DOE setting, and simulation experiments based on sparse quadratic response surfaces benchmark SVEMnet against repeated cross-validated elastic-net baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.20968v2</guid>
      <category>stat.CO</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Andrew T. Karl</dc:creator>
    </item>
  </channel>
</rss>
