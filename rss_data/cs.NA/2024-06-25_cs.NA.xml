<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NA</link>
    <description>cs.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 26 Jun 2024 01:48:16 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 25 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Marrying Compressed Sensing and Deep Signal Separation</title>
      <link>https://arxiv.org/abs/2406.15623</link>
      <description>arXiv:2406.15623v1 Announce Type: new 
Abstract: Blind signal separation (BSS) is an important and challenging signal processing task. Given an observed signal which is a superposition of a collection of unknown (hidden/latent) signals, BSS aims at recovering the separate, underlying signals from only the observed mixed signal. As an underdetermined problem, BSS is notoriously difficult to solve in general, and modern deep learning has provided engineers with an effective set of tools to solve this problem. For example, autoencoders learn a low-dimensional hidden encoding of the input data which can then be used to perform signal separation. In real-time systems, a common bottleneck is the transmission of data (communications) to a central command in order to await decisions. Bandwidth limits dictate the frequency and resolution of the data being transmitted. To overcome this, compressed sensing (CS) technology allows for the direct acquisition of compressed data with a near optimal reconstruction guarantee. This paper addresses the question: can compressive acquisition be combined with deep learning for BSS to provide a complete acquire-separate-predict pipeline? In other words, the aim is to perform BSS on a compressively acquired signal directly without ever having to decompress the signal. We consider image data (MNIST and E-MNIST) and show how our compressive autoencoder approach solves the problem of compressive BSS. We also provide some theoretical insights into the problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15623v1</guid>
      <category>math.NA</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Truman Hickok, Sriram Nagaraj</dc:creator>
    </item>
    <item>
      <title>Discontinuous Galerkin schemes for hyperbolic systems in non-conservative variables: quasi-conservative formulation with subcell finite volume corrections</title>
      <link>https://arxiv.org/abs/2406.15644</link>
      <description>arXiv:2406.15644v1 Announce Type: new 
Abstract: We present a novel quasi-conservative arbitrary high order accurate ADER discontinuous Galerkin (DG) method allowing to efficiently use a non-conservative form of the considered partial differential system, so that the governing equations can be solved directly in the most physically relevant set of variables. This is particularly interesting for multi-material flows with moving interfaces and steep, large magnitude contact discontinuities, as well as in presence of highly non-linear thermodynamics. However, the non-conservative formulation of course introduces a conservation error which would normally lead to a wrong approximation of shock waves. Hence, from the theoretical point of view, we give a formal definition of the conservation defect of non-conservative schemes and we analyze this defect providing a local quasi-conservation condition, which allows us to prove a modified Lax-Wendroff theorem. Then, to deal with shock waves in practice, we exploit the framework of the so-called a posteriori subcell finite volume (FV) limiter, so that, in troubled cells appropriately detected, we can incorporate a local conservation correction. Our corrected FV update entirely removes the local conservation defect, allowing, at least formally, to fit in the hypotheses of the proposed modified Lax-Wendroff theorem. Here, the shock-triggered troubled cells are detected by combining physical admissibility criteria, a discrete maximum principle and a shock sensor inspired by Lagrangian hydrodynamics.
  To prove the capabilities of our novel approach, first, we show that we are able to recover the same results given by conservative schemes on classical benchmarks for the single-fluid Euler equations. We then conclude by showing the improved reliability of our scheme on the multi-fluid Euler system on examples like the interaction of a shock with a helium bubble.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15644v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Elena Gaburro, Walter Boscheri, Simone Chiocchetti, Mario Ricchiuto</dc:creator>
    </item>
    <item>
      <title>A Nonoverlapping Domain Decomposition Method for Extreme Learning Machines: Elliptic Problems</title>
      <link>https://arxiv.org/abs/2406.15959</link>
      <description>arXiv:2406.15959v1 Announce Type: new 
Abstract: Extreme learning machine (ELM) is a methodology for solving partial differential equations (PDEs) using a single hidden layer feed-forward neural network. It presets the weight/bias coefficients in the hidden layer with random values, which remain fixed throughout the computation, and uses a linear least squares method for training the parameters of the output layer of the neural network. It is known to be much faster than Physics informed neural networks. However, classical ELM is still computationally expensive when a high level of representation is desired in the solution as this requires solving a large least squares system. In this paper, we propose a nonoverlapping domain decomposition method (DDM) for ELMs that not only reduces the training time of ELMs, but is also suitable for parallel computation. In numerical analysis, DDMs have been widely studied to reduce the time to obtain finite element solutions for elliptic PDEs through parallel computation. Among these approaches, nonoverlapping DDMs are attracting the most attention. Motivated by these methods, we introduce local neural networks, which are valid only at corresponding subdomains, and an auxiliary variable at the interface. We construct a system on the variable and the parameters of local neural networks. A Schur complement system on the interface can be derived by eliminating the parameters of the output layer. The auxiliary variable is then directly obtained by solving the reduced system after which the parameters for each local neural network are solved in parallel. A method for initializing the hidden layer parameters suitable for high approximation quality in large systems is also proposed. Numerical results that verify the acceleration performance of the proposed method with respect to the number of subdomains are presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15959v1</guid>
      <category>math.NA</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chang-Ock Lee, Youngkyu Lee, Byungeun Ryoo</dc:creator>
    </item>
    <item>
      <title>A Bayesian framework for spectral reprojection</title>
      <link>https://arxiv.org/abs/2406.15977</link>
      <description>arXiv:2406.15977v1 Announce Type: new 
Abstract: Fourier partial sum approximations yield exponential accuracy for smooth and periodic functions, but produce the infamous Gibbs phenomenon for non-periodic ones. Spectral reprojection resolves the Gibbs phenomenon by projecting the Fourier partial sum onto a Gibbs complementary basis, often prescribed as the Gegenbauer polynomials. Noise in the Fourier data and the Runge phenomenon both degrade the quality of the Gegenbauer reconstruction solution, however. Motivated by its theoretical convergence properties, this paper proposes a new Bayesian framework for spectral reprojection, which allows a greater understanding of the impact of noise on the reprojection method from a statistical point of view. We are also able to improve the robustness with respect to the Gegenbauer polynomials parameters. Finally, the framework provides a mechanism to quantify the uncertainty of the solution estimate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15977v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tongtong Li, Anne Gelb</dc:creator>
    </item>
    <item>
      <title>On Quasi-Interpolation and their associated shift-invariant space using a new class of generalized Thin Plate Splines and Inverse Multiquadrics</title>
      <link>https://arxiv.org/abs/2406.16088</link>
      <description>arXiv:2406.16088v1 Announce Type: new 
Abstract: A new generalization of shifted thin plate splines
  $$\varphi(x)=(c^{2d}+||x||^{2d})\log\left(c^{2d}+||x||^{2d}\right),\qquad x\in\mathbb{R}^n, d\in \mathbb{N}, c&gt;0$$ is presented to increase the accuracy of quasi-interpolation further. With the restriction to Euclidean spaces of even dimensionality, the generalization can be used to generate a quasi-Lagrange operator that reproduces all polynomials of degree $n+2d-1$. It thus complements the case of the newly proposed generalized multiquadric $\varphi(x)=\sqrt{c^{2d}+||x||^{2d}},\quad x\in\mathbb{R}^n, d\in \mathbb{N}, c&gt;0$, which is restricted to odd dimensions \cite{ortmann}. This generalization improves the approximation order by a factor of $\mathcal{O}\left(h^{2(d-1)}\right)$, where $d=1$ represents the classical thin plate spline. The results are then compared with the theoretical optimal approximation from the shift-invariant space generated by these functions. Moreover, we introduce a new class of inverse multiquadrics $$\varphi(x)=\left(c^\lambda +||x||^\lambda\right)^\beta,\qquad x\in\mathbb{R}^n, \lambda \in\mathbb{R},\beta \in \mathbb{R}\backslash\mathbb{N}, c&gt;0. $$ We provide an explicit representation of the generalized Fourier transform and discuss its asymptotic behaviour near the origin. Particular emphasis is placed on the case where $\lambda$ and $\beta$ are both negative. It is demonstrated that, in dimensions $n\geq3$, it is possible to build a quasi-Lagrange operator that reproduces all polynomials of degree $n-3$ when $n$ is even and of degree $\frac{n-1}{2}$ when n is odd. Furthermore, the uniform approximation error is given by $\mathcal{O}\left(h^{n-2}\log(1/h)\right)$ for $n$ even and $\mathcal{O}\left(h^{\frac{n-3}{2}}\right)$ for $n$ odd. Here, $h&gt;0$ denotes the fill distance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16088v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mathis Ortmann, Martin Buhmann</dc:creator>
    </item>
    <item>
      <title>A projected Euler Method for Random Periodic Solutions of Semi-linear SDEs with non-globally Lipschitz coefficients</title>
      <link>https://arxiv.org/abs/2406.16089</link>
      <description>arXiv:2406.16089v1 Announce Type: new 
Abstract: The present work introduces and investigates an explicit time discretization scheme, called the projected Euler method, to numerically approximate random periodic solutions of semi-linear SDEs under non-globally Lipschitz conditions. The existence of the random periodic solution is demonstrated as the limit of the pull-back of the discretized SDE. Without relying on a priori high-order moment bounds of the numerical approximations, the mean square convergence rate is proved to be order 0.5 for SDEs with multiplicative noise and order 1 for SDEs with additive noise. Numerical examples are also provided to validate our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16089v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yujia Guo, Xiaojie Wang, Yue Wu</dc:creator>
    </item>
    <item>
      <title>Greedy randomized Bregman-Kaczmarz method for constrained nonlinear systems of equations</title>
      <link>https://arxiv.org/abs/2406.16112</link>
      <description>arXiv:2406.16112v1 Announce Type: new 
Abstract: A greedy randomized nonlinear Bregman-Kaczmarz method by sampling the working index with residual information is developed for the solution of the constrained nonlinear system of equations. Theoretical analyses prove the convergence of the greedy randomized nonlinear Bregman-Kaczmarz method and its relaxed version. Numerical experiments verify the effectiveness of the proposed method,which converges faster than the existing nonlinear Bregman-Kaczmarz methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16112v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aqin Xiao, Junfeng Yin</dc:creator>
    </item>
    <item>
      <title>A Python Benchmark Functions Framework for Numerical Optimisation Problems</title>
      <link>https://arxiv.org/abs/2406.16195</link>
      <description>arXiv:2406.16195v1 Announce Type: new 
Abstract: This work proposes a framework of benchmark functions designed to facilitate the creation of test cases for numerical optimisation techniques. The framework, written in Python 3, is designed to be easy to install, use, and expand. The collection includes some of the most used multi-modal continuous functions present in literature, which can be instantiated using an arbitrary number of dimensions. Meta-information of each benchmark function, like search boundaries and position of known optima, are included and made easily accessible through class methods. Built-in interactive visualisation capabilities, baseline techniques, and rigorous testing protocols complement the features of the framework. The framework can be found here: \url{https://gitlab.com/luca.baronti/python_benchmark_functions</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16195v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luca Baronti, Marco Castellani</dc:creator>
    </item>
    <item>
      <title>A Predictor-Corrector Algorithm in the Framework of Conformable Fractional Differential Equations</title>
      <link>https://arxiv.org/abs/2406.16216</link>
      <description>arXiv:2406.16216v1 Announce Type: new 
Abstract: This work proposes a conformable fractional predictor-corrector algorithm for solving conformable fractional differential equations. Fractional calculus is finding applications in various scientific fields, but existing numerical methods might have limitations. This work addresses that gap by introducing a new algorithm specifically designed for the conformable fractional derivative using Adams-Bashforth and Adams-Moulton methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16216v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohamed Echchehira, Youness Assebbane, Mustapha Atraoui, Mohamed Bouaouid</dc:creator>
    </item>
    <item>
      <title>Gradient enhanced ADMM Algorithm for dynamic optimal transport on surfaces</title>
      <link>https://arxiv.org/abs/2406.16285</link>
      <description>arXiv:2406.16285v1 Announce Type: new 
Abstract: A gradient enhanced ADMM algorithm for optimal transport on general surfaces is proposed in this paper. Based on Benamou and Brenier's dynamical formulation, we combine gradient recovery techniques on surfaces with the ADMM algorithm, not only improving the computational accuracy, but also providing a novel method to deal with dual variables in the algorithm. This method avoids the use of stagger grids, has better accuracy and is more robust comparing to other averaging techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16285v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guozhi Dong, Hailong Guo, Chengrun Jiang, Zuoqiang Shi</dc:creator>
    </item>
    <item>
      <title>Energetic Spectral-Element Time Marching Methods for Phase-Field Nonlinear Gradient Systems</title>
      <link>https://arxiv.org/abs/2406.16287</link>
      <description>arXiv:2406.16287v1 Announce Type: new 
Abstract: We propose two efficient energetic spectral-element methods in time for marching nonlinear gradient systems with the phase-field Allen--Cahn equation as an example: one fully implicit nonlinear method and one semi-implicit linear method. Different from other spectral methods in time using spectral Petrov-Galerkin or weighted Galerkin approximations, the presented implicit method employs an energetic variational Galerkin form that can maintain the mass conservation and energy dissipation property of the continuous dynamical system. Another advantage of this method is its superconvergence. A high-order extrapolation is adopted for the nonlinear term to get the semi-implicit method. The semi-implicit method does not have superconvergence, but can be improved by a few Picard-like iterations to recover the superconvergence of the implicit method. Numerical experiments verify that the method using Legendre elements of degree three outperforms the 4th-order implicit-explicit backward differentiation formula and the 4th-order exponential time difference Runge-Kutta method, which were known to have best performances in solving phase-field equations. In addition to the standard Allen--Cahn equation, we also apply the method to a conservative Allen--Cahn equation, in which the conservation of discrete total mass is verified. The applications of the proposed methods are not limited to phase-field Allen--Cahn equations. They are suitable for solving general, large-scale nonlinear dynamical systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16287v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Shiqin Liu, Haijun Yu</dc:creator>
    </item>
    <item>
      <title>A variational symplectic scheme based on Simpson's quadrature</title>
      <link>https://arxiv.org/abs/2406.16423</link>
      <description>arXiv:2406.16423v1 Announce Type: new 
Abstract: We propose a variational symplectic numerical method for the time integration of dynamical systems issued from the least action principle. We assume a quadratic internal interpolation of the state and we approximate the action in a small time step by the Simpson's quadrature formula. The resulting scheme is explicited for an elementary harmonic oscillator. It is a stable, explicit, and symplectic scheme satisfying the conservation of an approximate energy. Numerical tests illustrate our theoretical study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16423v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Geometric Science of Information, Saint-Malo (France), Aug 2023, Saint-Malo, France. pp.22-31</arxiv:journal_reference>
      <dc:creator>Fran\c{c}ois Dubois (LMO, LMSSC), Juan Antonio Rojas-Quintero</dc:creator>
    </item>
    <item>
      <title>Mixed precision iterative refinement for least squares with linear equality constraints and generalized least squares problems</title>
      <link>https://arxiv.org/abs/2406.16499</link>
      <description>arXiv:2406.16499v1 Announce Type: new 
Abstract: Recent development on mixed precision techniques has largely enhanced the performance of various linear algebra solvers, one of which being the least squares problem $\min_{x}\lVert b-Ax\rVert_{2}$. By transforming the least squares problem into an augmented linear system, mixed precision techniques are capable of refining the lower precision solution to the working precision. In this paper, we propose mixed precision iterative refinement algorithms for two variants of the least squares problem -- the least squares problem with linear equality constraints (LSE) and the generalized least squares problem (GLS). Both classical and GMRES-based iterative refinement can be applied to augmented systems of these two problems to improve the accuracy of the solution. For reasonably well-conditioned problems our algorithms reduce the execution time by a factor of 40% in average compared to the fixed precision ones from LAPACK on the x86-64 architecture.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16499v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bowen Gao, Yuxin Ma, Meiyue Shao</dc:creator>
    </item>
    <item>
      <title>A Random Integration Algorithm for High-dimensional Function Spaces</title>
      <link>https://arxiv.org/abs/2406.16627</link>
      <description>arXiv:2406.16627v1 Announce Type: new 
Abstract: We introduce a novel random integration algorithm that boasts both high convergence order and polynomial tractability for functions characterized by sparse frequencies or rapidly decaying Fourier coefficients. Specifically, for integration in periodic isotropic Sobolev space and the isotropic Sobolev space with compact support, our approach attains a nearly optimal root mean square error (RMSE) bound. In contrast to previous nearly optimal algorithms, our method exhibits polynomial tractability, ensuring that the number of samples does not scale exponentially with increasing dimensions. Our integration algorithm also enjoys nearly optimal bound for weighted Korobov space. Furthermore, the algorithm can be applied without the need for prior knowledge of weights, distinguishing it from the component-by-component algorithm. For integration in the Wiener algebra, the sample complexity of our algorithm is independent of the decay rate of Fourier coefficients. The effectiveness of the integration is confirmed through numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16627v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liang Chen, Minqiang Xu, Haizhang Zhang</dc:creator>
    </item>
    <item>
      <title>Velocity-vorticity-pressure mixed formulation for the Kelvin-Voigt-Brinkman-Forchheimer equations</title>
      <link>https://arxiv.org/abs/2406.16703</link>
      <description>arXiv:2406.16703v1 Announce Type: new 
Abstract: In this paper, we propose and analyze a mixed formulation for the Kelvin-Voigt-Brinkman-Forchheimer equations for unsteady viscoelastic flows in porous media. Besides the velocity and pressure, our approach introduces the vorticity as a further unknown. Consequently, we obtain a three-field mixed variational formulation, where the aforementioned variables are the main unknowns of the system. We establish the existence and uniqueness of a solution for the weak formulation, and derive the corresponding stability bounds, employing a fixed-point strategy, along with monotone operators theory and Schauder theorem. Afterwards, we introduce a semidiscrete continuous-in-time approximation based on stable Stokes elements for the velocity and pressure, and continuous piecewise polynomial spaces for the vorticity. Additionally, employing backward Euler time discretization, we introduce a fully discrete finite element scheme. We prove well-posedness, derive stability bounds, and establish the corresponding error estimates for both schemes. We provide several numerical results verifying the theoretical rates of convergence and illustrating the performance and flexibility of the method for a range of domain configurations and model parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16703v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sergio Caucao, Ivan Yotov</dc:creator>
    </item>
    <item>
      <title>A Boot-Strapping Technique to Design Dense Output Formulae for Modified Patankar-Runge-Kutta Methods</title>
      <link>https://arxiv.org/abs/2406.16718</link>
      <description>arXiv:2406.16718v1 Announce Type: new 
Abstract: In this work modified Patankar-Runge-Kutta (MPRK) schemes up to order four are considered and equipped with a dense output formula of appropriate accuracy. Since these time integrators are conservative and positivity preserving for any time step size, we impose the same requirements on the corresponding dense output formula. In particular, we discover that there is an explicit first order formula. However, to develop a boot-strapping technique we propose to use implicit formulae which naturally fit into the framework of MPRK schemes. In particular, if lower order MPRK schemes are used to construct methods of higher order, the same can be donw with the dense output formulae we propose in this work. We explicitly construct formulae up to order three and demonstrate how to generalize this approach as long as the underlying Runge-Kutta method possesses a dense output formulae of appropriate accuracy. We also note that even though linear systems have to be solved to compute an approximation for intermediate points in time using these higher order dense output formulae, the overall computational effort is reduced compared to using the scheme with a smaller step size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16718v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Izgin</dc:creator>
    </item>
    <item>
      <title>Convergence analysis of a stochastic heavy-ball method for linear ill-posed problems</title>
      <link>https://arxiv.org/abs/2406.16814</link>
      <description>arXiv:2406.16814v1 Announce Type: new 
Abstract: In this paper we consider a stochastic heavy-ball method for solving linear ill-posed inverse problems. With suitable choices of the step-sizes and the momentum coefficients, we establish the regularization property of the method under {\it a priori} selection of the stopping index and derive the rate of convergence under a benchmark source condition on the sought solution. Numerical results are provided to test the performance of the method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16814v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qinian Jin, Yanjun Liu</dc:creator>
    </item>
    <item>
      <title>Numerical methods for eigenvalues of singular polynomial eigenvalue problems</title>
      <link>https://arxiv.org/abs/2406.16832</link>
      <description>arXiv:2406.16832v1 Announce Type: new 
Abstract: Recently, three numerical methods for the computation of eigenvalues of singular matrix pencils, based on a rank-completing perturbation, a rank-projection, or an augmentation were developed. We show that all three approaches can be generalized to treat singular polynomial eigenvalue problems. The common denominator of all three approaches is a transformation of a singular into a regular matrix polynomial whose eigenvalues are a disjoint union of the eigenvalues of the singular polynomial, called true eigenvalues, and additional fake eigenvalues. The true eigenvalues can then be separated from the fake eigenvalues using information on the corresponding left and right eigenvectors. We illustrate the approaches on several interesting applications, including bivariate polynomial systems and ZGV points.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16832v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michiel E. Hochstenbach, Christian Mehl, Bor Plestenjak</dc:creator>
    </item>
    <item>
      <title>A new engineering theory describing oblique free surface impact by flexible plates</title>
      <link>https://arxiv.org/abs/2103.08012</link>
      <description>arXiv:2103.08012v3 Announce Type: cross 
Abstract: Consideration of slamming loads within the structural design of planning hulls is of critical importance in ensuring adequate structural performance in order to avoid potential catastrophic consequences. However, because of the intricacy in the interplay between complex fluid flows and nonlinear structural deformations that accompany the phenomenology of slamming, a general engineering theory in slamming has yet to be uncovered, and so design relies on specialized theories. In this paper, we propose one such theory for a design case that has, until now, eluded a proper description. In pursuit of this theory, we employ a specialized implicit, partitioned fluid-structural interaction (FSI) simulation approach, in order to study the underlying physical mechanisms accompanying the oblique impact of a flexible plate during water entry. In the present work, we first present validation results from flexible plate water entry experiments, to confirm the veracity of the developed FSI solver. Subsequent to validation, we carry out a series of numerical analyses, in an effort to characterize the regimes in impact force and plate out-of-plane deformations, as a function of impact velocities and plate flexural rigidity. Finally, we use our FSI solver, as a kind of "microscope", to study the mechanistic evolution of fluid flows and elastic plate deformations that occur during slamming. Based on these observations, we propose a novel, but simple engineering theory for flexible plates obliquely impacting the water free surface (e.g. high speed porpoising water craft reentry).</description>
      <guid isPermaLink="false">oai:arXiv.org:2103.08012v3</guid>
      <category>physics.flu-dyn</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Wensi Wu, Christopher Earls</dc:creator>
    </item>
    <item>
      <title>The effects of leaflet material properties on the simulated function of regurgitant mitral valves</title>
      <link>https://arxiv.org/abs/2302.04939</link>
      <description>arXiv:2302.04939v2 Announce Type: cross 
Abstract: Advances in three-dimensional imaging provide the ability to construct and analyze finite element (FE) models to evaluate the biomechanical behavior and function of atrioventricular valves. However, while obtaining patient-specific valve geometry is now possible, non-invasive measurement of patient-specific leaflet material properties remains nearly impossible. Both valve geometry and tissue properties play a significant role in governing valve dynamics, leading to the central question of whether clinically relevant insights can be attained from FE analysis of atrioventricular valves without precise knowledge of tissue properties. As such we investigated 1) the influence of tissue extensibility and 2) the effects of constitutive model parameters and leaflet thickness on simulated valve function and mechanics. We compared metrics of valve function (e.g., leaflet coaptation and regurgitant orifice area) and mechanics (e.g., stress and strain) across one normal and three regurgitant mitral valve (MV) models with common mechanisms of regurgitation (annular dilation, leaflet prolapse, leaflet tethering) of both moderate and severe degree. We developed a novel fully-automated approach to accurately quantify regurgitant orifice areas of complex valve geometries. We found that the relative ordering of the mechanical and functional metrics was maintained across a group of valves using material properties up to 15% softer than the representative adult mitral constitutive model. Our findings suggest that FE simulations can be used to qualitatively compare how differences and alterations in valve structure affect relative atrioventricular valve function even in populations where material properties are not precisely known.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.04939v2</guid>
      <category>physics.med-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>q-bio.TO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.jmbbm.2023.105858</arxiv:DOI>
      <dc:creator>Wensi Wu, Stephen Ching, Patricia Sabin, Devin W. Laurence, Steve A. Maas, Andras Lasso, Jeffrey A. Weiss, Matthew A. Jolley</dc:creator>
    </item>
    <item>
      <title>BrowNNe: Brownian Nonlocal Neurons &amp; Activation Functions</title>
      <link>https://arxiv.org/abs/2406.15617</link>
      <description>arXiv:2406.15617v1 Announce Type: cross 
Abstract: It is generally thought that the use of stochastic activation functions in deep learning architectures yield models with superior generalization abilities. However, a sufficiently rigorous statement and theoretical proof of this heuristic is lacking in the literature. In this paper, we provide several novel contributions to the literature in this regard. Defining a new notion of nonlocal directional derivative, we analyze its theoretical properties (existence and convergence). Second, using a probabilistic reformulation, we show that nonlocal derivatives are epsilon-sub gradients, and derive sample complexity results for convergence of stochastic gradient descent-like methods using nonlocal derivatives. Finally, using our analysis of the nonlocal gradient of Holder continuous functions, we observe that sample paths of Brownian motion admit nonlocal directional derivatives, and the nonlocal derivatives of Brownian motion are seen to be Gaussian processes with computable mean and standard deviation. Using the theory of nonlocal directional derivatives, we solve a highly nondifferentiable and nonconvex model problem of parameter estimation on image articulation manifolds. Using Brownian motion infused ReLU activation functions with the nonlocal gradient in place of the usual gradient during backpropagation, we also perform experiments on multiple well-studied deep learning architectures. Our experiments indicate the superior generalization capabilities of Brownian neural activation functions in low-training data regimes, where the use of stochastic neurons beats the deterministic ReLU counterpart.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15617v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sriram Nagaraj, Truman Hickok</dc:creator>
    </item>
    <item>
      <title>Physics Informed Machine Learning (PIML) methods for estimating the remaining useful lifetime (RUL) of aircraft engines</title>
      <link>https://arxiv.org/abs/2406.15619</link>
      <description>arXiv:2406.15619v1 Announce Type: cross 
Abstract: This paper is aimed at using the newly developing field of physics informed machine learning (PIML) to develop models for predicting the remaining useful lifetime (RUL) aircraft engines. We consider the well-known benchmark NASA Commercial Modular Aero-Propulsion System Simulation (C-MAPSS) data as the main data for this paper, which consists of sensor outputs in a variety of different operating modes. C-MAPSS is a well-studied dataset with much existing work in the literature that address RUL prediction with classical and deep learning methods. In the absence of published empirical physical laws governing the C-MAPSS data, our approach first uses stochastic methods to estimate the governing physics models from the noisy time series data. In our approach, we model the various sensor readings as being governed by stochastic differential equations, and we estimate the corresponding transition density mean and variance functions of the underlying processes. We then augment LSTM (long-short term memory) models with the learned mean and variance functions during training and inferencing. Our PIML based approach is different from previous methods, and we use the data to first learn the physics. Our results indicate that PIML discovery and solutions methods are well suited for this problem and outperform previous data-only deep learning methods for this data set and task. Moreover, the framework developed herein is flexible, and can be adapted to other situations (other sensor modalities or combined multi-physics environments), including cases where the underlying physics is only partially observed or known.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15619v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sriram Nagaraj, Truman Hickok</dc:creator>
    </item>
    <item>
      <title>Construction and Accuracy of Electronic Continuum Models of Incommensurate Bilayer 2D Materials</title>
      <link>https://arxiv.org/abs/2406.15712</link>
      <description>arXiv:2406.15712v1 Announce Type: cross 
Abstract: Single-particle continuum models such as the popular Bistritzer-MacDonald model have become powerful tools for predicting electronic phenomena of incommensurate 2D materials and the development of many-body models aimed to model unconventional superconductivity and correlated insulators. In this work, we introduce a procedure to construct continuum models of arbitrary accuracy relative to tight-binding models for moir\'{e} incommensurate bilayers. This is done by recognizing the continuum model as arising from Taylor expansions of a high accuracy momentum space approximation of the tight-binding model. We apply our procedure in full detail to two models of twisted bilayer graphene and demonstrate both admit the Bistritzer-MacDonald model as the leading order continuum model, while higher order expansions reveal qualitative spectral differences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15712v1</guid>
      <category>math-ph</category>
      <category>cs.NA</category>
      <category>math.MP</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xue Quan, Alex Watson, Daniel Massatt</dc:creator>
    </item>
    <item>
      <title>High order discontinuous Galerkin schemes with subcell finite volume limiter and AMR for a monolithic first--order BSSNOK formulation of the Einstein--Euler equations</title>
      <link>https://arxiv.org/abs/2406.15798</link>
      <description>arXiv:2406.15798v1 Announce Type: cross 
Abstract: We propose a high order discontinuous Galerkin (DG) scheme with subcell finite volume (FV) limiter to solve a monolithic first--order hyperbolic BSSNOK formulation of the coupled Einstein--Euler equations. The numerical scheme runs with adaptive mesh refinement (AMR) in three space dimensions, is endowed with time-accurate local time stepping (LTS) and is able to deal with both conservative and non-conservative hyperbolic systems. The system of governing partial differential equations was shown to be strongly hyperbolic and is solved in a monolithic fashion with one numerical framework that can be simultaneously applied to both the conservative matter subsystem as well as the non-conservative subsystem for the spacetime. Since high order unlimited DG schemes are well-known to produce spurious oscillations in the presence of discontinuities and singularities, our subcell finite volume limiter is crucial for the robust discretization of shock waves arising in the matter as well as for the stable treatment of puncture black holes. We test the new method on a set of classical test problems of numerical general relativity, showing good agreement with available exact or numerical reference solutions. In particular, we perform the first long term evolution of the inspiralling merger of two puncture black holes with a high order ADER-DG scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15798v1</guid>
      <category>gr-qc</category>
      <category>astro-ph.HE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Dumbser, Olindo Zanotti, Ilya Peshkov</dc:creator>
    </item>
    <item>
      <title>Automating Variational Differentiation</title>
      <link>https://arxiv.org/abs/2406.16154</link>
      <description>arXiv:2406.16154v1 Announce Type: cross 
Abstract: Many problems in Physics and Chemistry are formulated as the minimization of a functional. Therefore, methods for solving these problems typically require differentiating maps whose input and/or output are functions -- commonly referred to as variational differentiation. Such maps are not addressed at the mathematical level by the chain rule, which underlies modern symbolic and algorithmic differentiation (AD) systems. Although there are algorithmic solutions such as tracing and reverse accumulation, they do not provide human readability and introduce strict programming constraints that bottleneck performance, especially in high-performance computing (HPC) environments. In this manuscript, we propose a new computer theoretic model of differentiation by combining the pullback of the $\mathbf{B}$ and $\mathbf{C}$ combinators from the combinatory logic. Unlike frameworks based on the chain rule, this model differentiates a minimal complete basis for the space of computable functions. Consequently, the model is capable of analytic backpropagation and variational differentiation while supporting complex numbers. To demonstrate the generality of this approach we build a system named CombDiff, which can differentiate nontrivial variational problems such as Hartree-Fock (HF) theory and multilayer perceptrons.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16154v1</guid>
      <category>cs.MS</category>
      <category>cs.NA</category>
      <category>cs.PL</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kangbo Li, Anil Damle</dc:creator>
    </item>
    <item>
      <title>Accelerating Matrix Diagonalization through Decision Transformers with Epsilon-Greedy Optimization</title>
      <link>https://arxiv.org/abs/2406.16191</link>
      <description>arXiv:2406.16191v1 Announce Type: cross 
Abstract: This paper introduces a novel framework for matrix diagonalization, recasting it as a sequential decision-making problem and applying the power of Decision Transformers (DTs). Our approach determines optimal pivot selection during diagonalization with the Jacobi algorithm, leading to significant speedups compared to the traditional max-element Jacobi method. To bolster robustness, we integrate an epsilon-greedy strategy, enabling success in scenarios where deterministic approaches fail. This work demonstrates the effectiveness of DTs in complex computational tasks and highlights the potential of reimagining mathematical operations through a machine learning lens. Furthermore, we establish the generalizability of our method by using transfer learning to diagonalize matrices of smaller sizes than those trained.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16191v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kshitij Bhatta, Geigh Zollicoffer, Manish Bhattarai, Phil Romero, Christian F. A. Negre, Anders M. N. Niklasson, Adetokunbo Adedoyin</dc:creator>
    </item>
    <item>
      <title>Transient Evaluation of Non-Markovian Models by Stochastic State Classes and Simulation</title>
      <link>https://arxiv.org/abs/2406.16447</link>
      <description>arXiv:2406.16447v1 Announce Type: cross 
Abstract: Non-Markovian models have great expressive power, at the cost of complex analysis of the stochastic process. The method of Stochastic State Classes (SSCs) derives closed-form analytical expressions for the joint Probability Density Functions (PDFs) of the active timers with marginal expolynomial PDF, though being hindered by the number of concurrent non-exponential timers and of discrete events between regenerations. Simulation is an alternative capable of handling the large class of PDFs samplable via inverse transform, which however suffers from rare events. We combine these approaches to analyze time-bounded transient properties of non-Markovian models. We enumerate SSCs near the root of the state-space tree and then rely on simulation to reach the target, affording transient evaluation of models for which the method of SSCs is not viable while reducing computational time and variance of the estimator of transient probabilities with respect to simulation. Promising results are observed in the estimation of rare event probabilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16447v1</guid>
      <category>cs.LO</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Gabriel Dengler, Laura Carnevali, Carlos E. Budde, Enrico Vicario</dc:creator>
    </item>
    <item>
      <title>Cubic regularized subspace Newton for non-convex optimization</title>
      <link>https://arxiv.org/abs/2406.16666</link>
      <description>arXiv:2406.16666v1 Announce Type: cross 
Abstract: This paper addresses the optimization problem of minimizing non-convex continuous functions, which is relevant in the context of high-dimensional machine learning applications characterized by over-parametrization. We analyze a randomized coordinate second-order method named SSCN which can be interpreted as applying cubic regularization in random subspaces. This approach effectively reduces the computational complexity associated with utilizing second-order information, rendering it applicable in higher-dimensional scenarios. Theoretically, we establish convergence guarantees for non-convex functions, with interpolating rates for arbitrary subspace sizes and allowing inexact curvature estimation. When increasing subspace size, our complexity matches $\mathcal{O}(\epsilon^{-3/2})$ of the cubic regularization (CR) rate. Additionally, we propose an adaptive sampling scheme ensuring exact convergence rate of $\mathcal{O}(\epsilon^{-3/2}, \epsilon^{-3})$ to a second-order stationary point, even without sampling all coordinates. Experimental results demonstrate substantial speed-ups achieved by SSCN compared to conventional first-order methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16666v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jim Zhao, Aurelien Lucchi, Nikita Doikov</dc:creator>
    </item>
    <item>
      <title>Learning the boundary-to-domain mapping using Lifting Product Fourier Neural Operators for partial differential equations</title>
      <link>https://arxiv.org/abs/2406.16740</link>
      <description>arXiv:2406.16740v1 Announce Type: cross 
Abstract: Neural operators such as the Fourier Neural Operator (FNO) have been shown to provide resolution-independent deep learning models that can learn mappings between function spaces. For example, an initial condition can be mapped to the solution of a partial differential equation (PDE) at a future time-step using a neural operator. Despite the popularity of neural operators, their use to predict solution functions over a domain given only data over the boundary (such as a spatially varying Dirichlet boundary condition) remains unexplored. In this paper, we refer to such problems as boundary-to-domain problems; they have a wide range of applications in areas such as fluid mechanics, solid mechanics, heat transfer etc. We present a novel FNO-based architecture, named Lifting Product FNO (or LP-FNO) which can map arbitrary boundary functions defined on the lower-dimensional boundary to a solution in the entire domain. Specifically, two FNOs defined on the lower-dimensional boundary are lifted into the higher dimensional domain using our proposed lifting product layer. We demonstrate the efficacy and resolution independence of the proposed LP-FNO for the 2D Poisson equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16740v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Aditya Kashi, Arka Daw, Muralikrishnan Gopalakrishnan Meena, Hao Lu</dc:creator>
    </item>
    <item>
      <title>Algebraic compressed sensing</title>
      <link>https://arxiv.org/abs/2108.13208</link>
      <description>arXiv:2108.13208v2 Announce Type: replace 
Abstract: We introduce the broad subclass of algebraic compressed sensing problems, where structured signals are modeled either explicitly or implicitly via polynomials. This includes, for instance, low-rank matrix and tensor recovery. We employ powerful techniques from algebraic geometry to study well-posedness of sufficiently general compressed sensing problems, including existence, local recoverability, global uniqueness, and local smoothness. Our main results are summarized in thirteen questions and answers in algebraic compressed sensing. Most of our answers concerning the minimum number of required measurements for existence, recoverability, and uniqueness of algebraic compressed sensing problems are optimal and depend only on the dimension of the model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2108.13208v2</guid>
      <category>math.NA</category>
      <category>cs.IT</category>
      <category>cs.NA</category>
      <category>math.AG</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.acha.2023.03.006</arxiv:DOI>
      <dc:creator>Paul Breiding, Fulvio Gesmundo, Mateusz Micha{\l}ek, Nick Vannieuwenhoven</dc:creator>
    </item>
    <item>
      <title>Linear-Complexity Black-Box Randomized Compression of Rank-Structured Matrices</title>
      <link>https://arxiv.org/abs/2205.02990</link>
      <description>arXiv:2205.02990v3 Announce Type: replace 
Abstract: A randomized algorithm for computing a compressed representation of a given rank-structured matrix $A \in \mathbb{R}^{N\times N}$ is presented. The algorithm interacts with $A$ only through its action on vectors. Specifically, it draws two tall thin matrices $\Omega,\,\Psi \in \mathbb{R}^{N\times s}$ from a suitable distribution, and then reconstructs $A$ from the information contained in the set $\{A\Omega,\,\Omega,\,A^{*}\Psi,\,\Psi\}$. For the specific case of a "Hierarchically Block Separable (HBS)" matrix (a.k.a. Hierarchically Semi-Separable matrix) of block rank $k$, the number of samples $s$ required satisfies $s = O(k)$, with $s \approx 3k$ being representative. While a number of randomized algorithms for compressing rank-structured matrices have previously been published, the current algorithm appears to be the first that is both of truly linear complexity (no $N\log(N)$ factors in the complexity bound) and fully "black box" in the sense that no matrix entry evaluation is required. Further, all samples can be extracted in parallel, enabling the algorithm to work in a "streaming" or "single view" mode.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.02990v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1137/22M1528574</arxiv:DOI>
      <arxiv:journal_reference>SIAM Journal on Scientific Computing 46.3 (2024): A1747-A1763</arxiv:journal_reference>
      <dc:creator>James Levitt, Per-Gunnar Martinsson</dc:creator>
    </item>
    <item>
      <title>Randomized Compression of Rank-Structured Matrices Accelerated with Graph Coloring</title>
      <link>https://arxiv.org/abs/2205.03406</link>
      <description>arXiv:2205.03406v2 Announce Type: replace 
Abstract: A randomized algorithm for computing a data sparse representation of a given rank structured matrix $A$ (a.k.a. an $H$-matrix) is presented. The algorithm draws on the randomized singular value decomposition (RSVD), and operates under the assumption that algorithms for rapidly applying $A$ and $A^{*}$ to vectors are available. The algorithm analyzes the hierarchical tree that defines the rank structure using graph coloring algorithms to generate a set of random test vectors. The matrix is then applied to the test vectors, and in a final step the matrix itself is reconstructed by the observed input-output pairs. The method presented is an evolution of the "peeling algorithm" of L. Lin, J. Lu, and L. Ying, "Fast construction of hierarchical matrix representation from matrix-vector multiplication," JCP, 230(10), 2011. For the case of uniform trees, the new method substantially reduces the pre-factor of the original peeling algorithm. More significantly, the new technique leads to dramatic acceleration for many non-uniform trees since it constructs sample vectors that are optimized for a given tree. The algorithm is particularly effective for kernel matrices involving a set of points restricted to a lower dimensional object than the ambient space, such as a boundary integral equation defined on a surface in three dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.03406v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.cam.2024.116044</arxiv:DOI>
      <arxiv:journal_reference>Journal of Computational and Applied Mathematics (2024): 116044</arxiv:journal_reference>
      <dc:creator>James Levitt, Per-Gunnar Martinsson</dc:creator>
    </item>
    <item>
      <title>Corner cases of the tau method: symmetrically imposing boundary conditions on hypercubes</title>
      <link>https://arxiv.org/abs/2211.17259</link>
      <description>arXiv:2211.17259v2 Announce Type: replace 
Abstract: Polynomial spectral methods produce fast, accurate, and flexible solvers for broad ranges of PDEs with one bounded dimension, where the incorporation of general boundary conditions is well understood. However, automating extensions to domains with multiple bounded dimensions is challenging because of difficulties in imposing boundary conditions at shared edges and corners. Past work has included various workarounds, such as the anisotropic inclusion of partial boundary data at shared edges or approaches that only work for specific boundary conditions. Here we present a general system for imposing boundary conditions for elliptic equations on hypercubes. We take an approach based on the generalized tau method, which allows for a wide range of boundary conditions for many different spectral schemes. The generalized tau method has the distinct advantage that the specified polynomial residual determines the exact algebraic solution; afterwards, any stable numerical scheme will find the same result. We can, therefore, provide one-to-one comparisons to traditional collocation and Galerkin methods within the tau framework. As an essential requirement, we add specific tau corrections to the boundary conditions, in addition to the bulk PDE, which produce a unique set of compatible boundary data at shared subsurfaces. Our approach works with general boundary conditions that commute on intersecting subsurfaces, including Dirichlet, Neumann, Robin, and any combination of these on all boundaries. The boundary tau corrections can be made hyperoctahedrally symmetric and easily incorporated into existing solvers. We present the method explicitly for the Poisson equation in two and three dimensions and describe its extension to arbitrary elliptic equations (e.g. biharmonic) in any dimension.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.17259v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Keaton J. Burns, Daniel Fortunato, Keith Julien, Geoffrey M. Vasil</dc:creator>
    </item>
    <item>
      <title>Optimising seismic imaging design parameters via bilevel learning</title>
      <link>https://arxiv.org/abs/2301.10762</link>
      <description>arXiv:2301.10762v3 Announce Type: replace 
Abstract: Full Waveform Inversion (FWI) is a standard algorithm in seismic imaging. Its implementation requires the a priori choice of a number of "design parameters", such as the positions of sensors for the actual measurements and one (or more) regularisation weights. In this paper we describe a novel algorithm for determining these design parameters automatically from a set of training images, using a (supervised) bilevel learning approach. In our algorithm, the upper level objective function measures the quality of the reconstructions of the training images, where the reconstructions are obtained by solving the lower level optimisation problem -- in this case FWI. Our algorithm employs (variants of) the BFGS quasi-Newton method to perform the optimisation at each level, and thus requires the repeated solution of the forward problem -- here taken to be the Helmholtz equation.
  This paper focuses on the implementation of the algorithm. The novel contributions are: (i) an adjoint-state method for the efficient computation of the upper-level gradient; (ii) a complexity analysis for the bilevel algorithm, which counts the number of Helmholtz solves needed and shows this number is independent of the number of design parameters optimised; (iii) an effective preconditioning strategy for iteratively solving the linear systems required at each step of the bilevel algorithm; (iv) a smoothed extraction process for point values of the discretised wavefield, necessary for ensuring a smooth upper level objective function. The algorithm also uses an extension to the bilevel setting of classical frequency-continuation strategies, helping avoid convergence to spurious stationary points. The advantage of our algorithm is demonstrated on a problem derived from the standard Marmousi test problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.10762v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shaunagh Downing, Silvia Gazzola, Ivan G. Graham, Euan A. Spence</dc:creator>
    </item>
    <item>
      <title>Semilinear fractional elliptic PDEs with gradient nonlinearities on open balls: existence of solutions and probabilistic representation</title>
      <link>https://arxiv.org/abs/2306.10913</link>
      <description>arXiv:2306.10913v3 Announce Type: replace 
Abstract: We provide sufficient conditions for the existence of viscosity solutions of fractional semilinear elliptic PDEs of index $\alpha \in (1,2)$ with polynomial gradient nonlinearities on $d$-dimensional balls, $d\geq 2$. Our approach uses a tree-based probabilistic representation of solutions and their partial derivatives using $\alpha$-stable branching processes, and allows us to take into account gradient nonlinearities not covered by deterministic finite difference methods so far. In comparison with the existing literature on the regularity of solutions, no polynomial order condition is imposed on gradient nonlinearities. Numerical illustrations demonstrate the accuracy of the method in dimension $d=10$, solving a challenge encountered with the use of deterministic finite difference methods in high-dimensional settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.10913v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guillaume Penent, Nicolas Privault</dc:creator>
    </item>
    <item>
      <title>Dimension-free Ergodicity of Path Integral Molecular Dynamics</title>
      <link>https://arxiv.org/abs/2307.06510</link>
      <description>arXiv:2307.06510v4 Announce Type: replace 
Abstract: The quantum thermal average plays a central role in describing the thermodynamic properties of a quantum system. Path integral molecular dynamics (PIMD) is a prevailing approach for computing quantum thermal averages by approximating the quantum partition function as a classical isomorphism on an augmented space, enabling efficient classical sampling, but the theoretical knowledge of the ergodicity of the sampling is lacking. Parallel to the standard PIMD with $N$ ring polymer beads, we also study the Matsubara mode PIMD, where the ring polymer is replaced by a continuous loop composed of $N$ Matsubara modes. Utilizing the generalized $\Gamma$ calculus, we prove that both the Matsubara mode PIMD and the standard PIMD have uniform-in-$N$ ergodicity, i.e., the convergence rate towards the invariant distribution does not depend on the number of modes or beads $N$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.06510v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.PR</category>
      <category>physics.comp-ph</category>
      <category>quant-ph</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xuda Ye, Zhennan Zhou</dc:creator>
    </item>
    <item>
      <title>A moment approach for entropy solutions of parameter-dependent hyperbolic conservation laws</title>
      <link>https://arxiv.org/abs/2307.10043</link>
      <description>arXiv:2307.10043v3 Announce Type: replace 
Abstract: We propose a numerical method to solve parameter-dependent hyperbolic partial differential equations (PDEs) with a moment approach, based on a previous work from Marx et al. (2020). This approach relies on a very weak notion of solution of nonlinear equations, namely parametric entropy measure-valued (MV) solutions, satisfying linear equations in the space of Borel measures. The infinite-dimensional linear problem is approximated by a hierarchy of convex, finite-dimensional, semidefinite programming problems, called Lasserre's hierarchy. This gives us a sequence of approximations of the moments of the occupation measure associated with the parametric entropy MV solution, which is proved to converge. In the end, several post-treatments can be performed from this approximate moments sequence. In particular, the graph of the solution can be reconstructed from an optimization of the Christoffel-Darboux kernel associated with the approximate measure, that is a powerful approximation tool able to capture a large class of irregular functions. Also, for uncertainty quantification problems, several quantities of interest can be estimated, sometimes directly such as the expectation of smooth functionals of the solutions. The performance of our approach is evaluated through numerical experiments on the inviscid Burgers equation with parametrised initial conditions or parametrised flux function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.10043v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cl\'ement Cardoen, Swann Marx, Anthony Nouy, Nicolas Seguin</dc:creator>
    </item>
    <item>
      <title>The $\omega$-Condition Number for Optimal Preconditioning and Low Rank Generalized Jacobian Updating</title>
      <link>https://arxiv.org/abs/2308.13195</link>
      <description>arXiv:2308.13195v2 Announce Type: replace 
Abstract: Preconditioning is essential in iterative methods for solving linear systems. It is also the implicit objective in updating approximations of Jacobians in optimization methods, e.g., in quasi-Newton methods. Motivated by the latter, we study a nonclassic matrix condition number, the $\omega$-condition number. We do this in the context of optimal conditioning for: (i) our application to low rank updating of generalized Jacobians; (ii) iterative methods for linear systems: (iia) clustering of eigenvalues and (iib) convergence rates.
  For a positive definite matrix, the $\omega$-condition measure is the ratio of the arithmetic and geometric means of the eigenvalues. In particular, our applications concentrate on linear systems with low rank updates of ill-conditioned positive definite matrices. These systems arise in the context of nonsmooth Newton methods using generalized Jacobians. We are able to use optimality conditions and derive explicit formulae for $\omega$-optimal preconditioners and preconditioned updates. Connections to partial Cholesky sparse preconditioners are made.
  Evaluating or estimating the classical condition number $\kappa$ can be expensive. We show that the $\omega$-condition number can be evaluated explicitly following a Cholesky or LU factorization. Moreover, the simplicity of $\omega$ allows for the derivation of formulae for optimal preconditioning in various scenarios, i.e., this avoids the need for expensive algorithmic calculations. Our empirics show that $\omega$ estimates the actual condition of a linear system significantly better. Moreover, our empirical results show a significant decrease in the number of iterations required for a requested accuracy in the residual during an iterative method, i.e., these results confirm the efficacy of using the $\omega$-condition number compared to the classical condition number.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.13195v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Woosuk L. Jung, David Torregrosa-Bel\'en, Henry Wolkowicz</dc:creator>
    </item>
    <item>
      <title>A DEIM-CUR factorization with iterative SVDs</title>
      <link>https://arxiv.org/abs/2310.00636</link>
      <description>arXiv:2310.00636v3 Announce Type: replace 
Abstract: A CUR factorization is often utilized as a substitute for the singular value decomposition (SVD), especially when a concrete interpretation of the singular vectors is challenging. Moreover, if the original data matrix possesses properties like nonnegativity and sparsity, a CUR decomposition can better preserve them compared to the SVD. An essential aspect of this approach is the methodology used for selecting a subset of columns and rows from the original matrix. This study investigates the effectiveness of \emph{one-round sampling} and iterative subselection techniques and introduces new iterative subselection strategies based on iterative SVDs. One provably appropriate technique for index selection in constructing a CUR factorization is the discrete empirical interpolation method (DEIM). Our contribution aims to improve the approximation quality of the DEIM scheme by iteratively invoking it in several rounds, in the sense that we select subsequent columns and rows based on the previously selected ones. Thus, we modify $A$ after each iteration by removing the information that has been captured by the previously selected columns and rows. We also discuss how iterative procedures for computing a few singular vectors of large data matrices can be integrated with the new iterative subselection strategies. We present the results of numerical experiments, providing a comparison of one-round sampling and iterative subselection techniques, and demonstrating the improved approximation quality associated with using the latter.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.00636v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Perfect Y. Gidisu, Michiel E. Hochstenbach</dc:creator>
    </item>
    <item>
      <title>Error analysis for empirical risk minimization over clipped ReLU networks in solving linear Kolmogorov partial differential equations</title>
      <link>https://arxiv.org/abs/2310.12582</link>
      <description>arXiv:2310.12582v2 Announce Type: replace 
Abstract: Deep learning algorithms have been successfully applied to numerically solve linear Kolmogorov partial differential equations~(PDEs). A recent research shows that if the initial functions are bounded, the empirical risk minimization (ERM) over clipped ReLU networks generalizes well for solving the linear Kolmogorov PDE. In this paper, we propose to use a truncation technique to extend the generalization results for polynomially growing initial functions. Specifically, we prove that under an assumption, the sample size required to achieve an generalization error within $\varepsilon$ with a confidence level $\varrho$ grows polynomially in the size of the clipped neural networks and $(\varepsilon^{-1},\varrho^{-1})$, which means that the curse of dimensionality is broken. Moreover, we verify that the required assumptions hold for Black-Scholes PDEs and heat equations which are two important cases of linear Kolmogorov PDEs. For the approximation error, under certain assumptions, we establish approximation results for clipped ReLU neural networks when approximating the solution of Kolmogorov PDEs. Consequently, we establish that the ERM over artificial neural networks indeed overcomes the curse of dimensionality for a larger class of linear Kolmogorov PDEs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.12582v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jichang Xiao, Xiaoqun Wang</dc:creator>
    </item>
    <item>
      <title>Deep Learning Based on Randomized Quasi-Monte Carlo Method for Solving Linear Kolmogorov Partial Differential Equation</title>
      <link>https://arxiv.org/abs/2310.18100</link>
      <description>arXiv:2310.18100v2 Announce Type: replace 
Abstract: Deep learning algorithms have been widely used to solve linear Kolmogorov partial differential equations~(PDEs) in high dimensions, where the loss function is defined as a mathematical expectation. We propose to use the randomized quasi-Monte Carlo (RQMC) method instead of the Monte Carlo (MC) method for computing the loss function. In theory, we decompose the error from empirical risk minimization~(ERM) into the generalization error and the approximation error. Notably, the approximation error is independent of the sampling methods. We prove that the convergence order of the mean generalization error for the RQMC method is $O(n^{-1+\epsilon})$ for arbitrarily small $\epsilon&gt;0$, while for the MC method it is $O(n^{-1/2+\epsilon})$ for arbitrarily small $\epsilon&gt;0$. Consequently, we find that the overall error for the RQMC method is asymptotically smaller than that for the MC method as $n$ increases. Our numerical experiments show that the algorithm based on the RQMC method consistently achieves smaller relative $L^{2}$ error than that based on the MC method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.18100v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jichang Xiao, Fengjiang Fu, Xiaoqun Wang</dc:creator>
    </item>
    <item>
      <title>Explicit stabilized multirate methods for the monodomain model in cardiac electrophysiology</title>
      <link>https://arxiv.org/abs/2401.01745</link>
      <description>arXiv:2401.01745v3 Announce Type: replace 
Abstract: Fully explicit stabilized multirate (mRKC) methods are well-suited for the numerical solution of large multiscale systems of stiff ordinary differential equations thanks to their improved stability properties. To demonstrate their efficiency for the numerical solution of stiff, multiscale, nonlinear parabolic PDE's, we apply mRKC methods to the monodomain equation from cardiac electrophysiology. In doing so, we propose an improved version, specifically tailored to the monodomain model, which leads to the explicit exponential multirate stabilized (emRKC) method. Several numerical experiments are conducted to evaluate the efficiency of both mRKC and emRKC, while taking into account different finite element meshes (structured and unstructured) and realistic ionic models. The new emRKC method typically outperforms a standard implicit-explicit baseline method for cardiac electrophysiology. Code profiling and strong scalability results further demonstrate that emRKC is faster and inherently parallel without sacrificing accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.01745v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giacomo Rosilho de Souza, Marcus J. Grote, Simone Pezzuto, Rolf Krause</dc:creator>
    </item>
    <item>
      <title>A practical existence theorem for reduced order models based on convolutional autoencoders</title>
      <link>https://arxiv.org/abs/2402.00435</link>
      <description>arXiv:2402.00435v2 Announce Type: replace 
Abstract: In recent years, deep learning has gained increasing popularity in the fields of Partial Differential Equations (PDEs) and Reduced Order Modeling (ROM), providing domain practitioners with new powerful data-driven techniques such as Physics-Informed Neural Networks (PINNs), Neural Operators, Deep Operator Networks (DeepONets) and Deep-Learning based ROMs (DL-ROMs). In this context, deep autoencoders based on Convolutional Neural Networks (CNNs) have proven extremely effective, outperforming established techniques, such as the reduced basis method, when dealing with complex nonlinear problems. However, despite the empirical success of CNN-based autoencoders, there are only a few theoretical results supporting these architectures, usually stated in the form of universal approximation theorems. In particular, although the existing literature provides users with guidelines for designing convolutional autoencoders, the subsequent challenge of learning the latent features has been barely investigated. Furthermore, many practical questions remain unanswered, e.g., the number of snapshots needed for convergence or the neural network training strategy. In this work, using recent techniques from sparse high-dimensional function approximation, we fill some of these gaps by providing a new practical existence theorem for CNN-based autoencoders when the parameter-to-solution map is holomorphic. This regularity assumption arises in many relevant classes of parametric PDEs, such as the parametric diffusion equation, for which we discuss an explicit application of our general theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.00435v2</guid>
      <category>math.NA</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicola Rares Franco, Simone Brugiapaglia</dc:creator>
    </item>
    <item>
      <title>Multi-Derivative Runge-Kutta Flux Reconstruction for hyperbolic conservation laws</title>
      <link>https://arxiv.org/abs/2403.02141</link>
      <description>arXiv:2403.02141v2 Announce Type: replace 
Abstract: We extend the fourth order, two stage Multi-Derivative Runge Kutta (MDRK) scheme to the Flux Reconstruction (FR) framework by writing both stages in terms of a time averaged flux and then using the approximate Lax-Wendroff procedure to compute the time averaged flux. Numerical flux is carefully constructed to enhance Fourier CFL stability and accuracy. A subcell based blending limiter is developed for the MDRK scheme which ensures that the limited scheme is provably admissibility preserving. Along with being admissibility preserving, the blending scheme is constructed to minimize dissipation errors by using Gauss-Legendre solution points and performing MUSCL-Hancock reconstruction on subcells. The accuracy enhancement of the blending scheme is numerically verified on compressible Euler's equations, with test cases involving shocks and small-scale structures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02141v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arpit Babbar, Praveen Chandrashekar</dc:creator>
    </item>
    <item>
      <title>A global approach for the inverse scattering problem using a Carleman contraction map</title>
      <link>https://arxiv.org/abs/2404.04145</link>
      <description>arXiv:2404.04145v2 Announce Type: replace 
Abstract: This paper addresses the inverse scattering problem in the domain Omega. The input data, measured outside Omega, involve the waves generated by the interaction of plane waves with various directions and unknown scatterers fully occluded inside Omega. The output of this problem is the spatially dielectric constant of these scatterers. Our approach to solving this problem consists of two primary stages. Initially, we eliminate the unknown dielectric constant from the governing equation, resulting in a system of partial differential equations. Subsequently, we develop the Carleman contraction mapping method to effectively tackle this system. It is noteworthy to highlight this method's robustness. It does not request a precise initial guess of the true solution, and its computational cost is not expensive. Some numerical examples are presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04145v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Phuong M. Nguyen, Loc H. Nguyen, Huong T. T. Vu</dc:creator>
    </item>
    <item>
      <title>Randomized Quaternion UTV Decomposition and Randomized Quaternion Tensor UTV Decomposition</title>
      <link>https://arxiv.org/abs/2406.05734</link>
      <description>arXiv:2406.05734v2 Announce Type: replace 
Abstract: In this paper, the quaternion matrix UTV (QUTV) decomposition and quaternion tensor UTV (QTUTV) decomposition are proposed. To begin, the terms QUTV and QTUTV are defined, followed by the algorithms. Subsequently, by employing random sampling from the quaternion normal distribution, randomized QUTV and randomized QTUTV are generated to provide enhanced algorithmic efficiency. These techniques produce decompositions that are straightforward 9 to understand and require minimal cost. Furthermore, theoretical analysis is discussed. Specifically, the upper bounds for approximating QUTV on the rank-K and QTUTV on the TQt-rank K errors are provided, followed by deterministic error bounds and average-case error bounds for the randomized situations, which demonstrate the correlation between the accuracy of the low-rank approximation and the singular values. Finally, numerous numerical experiments are presented to verify that the proposed algorithms work more efficiently and with similar relative errors compared to other comparable decomposition methods. For the novel decompositions, the theory analysis offers a solid theoretical basis and the experiments show significant potential for the associated processing tasks of color images and color videos.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05734v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liqiao Yang, Jifei Miao, Tai-Xiang Jiang, Yanlin Zhang, Kit Ian Kou</dc:creator>
    </item>
    <item>
      <title>Approximation Theory of Tree Tensor Networks: Tensorized Multivariate Functions</title>
      <link>https://arxiv.org/abs/2101.11932</link>
      <description>arXiv:2101.11932v5 Announce Type: replace-cross 
Abstract: We study the approximation of multivariate functions with tensor networks (TNs). The main conclusion of this work is an answer to the following two questions: ``What are the approximation capabilities of TNs?" and "What is an appropriate model class of functions that can be approximated with TNs?"
  To answer the former, we show that TNs can (near to) optimally replicate $h$-uniform and $h$-adaptive approximation, for any smoothness order of the target function. Tensor networks thus exhibit universal expressivity w.r.t. isotropic, anisotropic and mixed smoothness spaces that is comparable with more general neural networks families such as deep rectified linear unit (ReLU) networks. Put differently, TNs have the capacity to (near to) optimally approximate many function classes -- without being adapted to the particular class in question.
  To answer the latter, as a candidate model class we consider approximation classes of TNs and show that these are (quasi-)Banach spaces, that many types of classical smoothness spaces are continuously embedded into said approximation classes and that TN approximation classes are themselves not embedded in any classical smoothness space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2101.11932v5</guid>
      <category>math.FA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mazen Ali, Anthony Nouy</dc:creator>
    </item>
    <item>
      <title>Improving physics-informed DeepONets with hard constraints</title>
      <link>https://arxiv.org/abs/2309.07899</link>
      <description>arXiv:2309.07899v2 Announce Type: replace-cross 
Abstract: Current physics-informed (standard or deep operator) neural networks still rely on accurately learning the initial and/or boundary conditions of the system of differential equations they are solving. In contrast, standard numerical methods involve such conditions in computations without needing to learn them. In this study, we propose to improve current physics-informed deep learning strategies such that initial and/or boundary conditions do not need to be learned and are represented exactly in the predicted solution. Moreover, this method guarantees that when a deep operator network is applied multiple times to time-step a solution of an initial value problem, the resulting function is at least continuous.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.07899v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>R\"udiger Brecht, Dmytro R. Popovych, Alex Bihlo, Roman O. Popovych</dc:creator>
    </item>
    <item>
      <title>Consensus-based construction of high-dimensional free energy surface</title>
      <link>https://arxiv.org/abs/2311.05009</link>
      <description>arXiv:2311.05009v3 Announce Type: replace-cross 
Abstract: One essential problem in quantifying the collective behaviors of molecular systems lies in the accurate construction of free energy surfaces (FESs). The main challenges arise from the prevalence of energy barriers and the high dimensionality. Existing approaches are often based on sophisticated enhanced sampling methods to establish efficient exploration of the full-phase space. On the other hand, the collection of optimal sample points for the numerical approximation of FESs remains largely under-explored, where the discretization error could become dominant for systems with a large number of collective variables (CVs). We propose a consensus sampling-based approach by reformulating the construction as a minimax problem which simultaneously optimizes the function representation and the training set. In particular, the maximization step establishes a stochastic interacting particle system to achieve the adaptive sampling of the max-residue regime by modulating the exploitation of the Laplace approximation of the current loss function and the exploration of the uncharted phase space; the minimization step updates the FES approximation with the new training set. By iteratively solving the minimax problem, the present method essentially achieves an adversarial learning of the FESs with unified tasks for both phase space exploration and posterior error-enhanced sampling. We demonstrate the method by constructing the FESs of molecular systems with a number of CVs up to 30.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.05009v3</guid>
      <category>physics.comp-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liyao Lyu, Huan Lei</dc:creator>
    </item>
    <item>
      <title>An unstructured geometrical un-split VOF method for viscoelastic two-phase flows</title>
      <link>https://arxiv.org/abs/2311.10872</link>
      <description>arXiv:2311.10872v2 Announce Type: replace-cross 
Abstract: Since viscoelastic two-phase flows arise in various industrial and natural processes, developing accurate and efficient software for their detailed numerical simulation is a highly relevant and challenging research task. We present a geometrical unstructured Volume-of-Fluid (VOF) method for handling two-phase flows with viscoelastic liquid phase, where the latter is modeled via generic rate-type constitutive equations and a one-field description is derived by conditional volume averaging of the local instantaneous bulk equations and interface jump conditions. The method builds on the plicRDF-isoAdvector geometrical VOF solver that is extended and combined with the modular framework DeboRheo for viscoelastic computational fluid dynamics (CFD). A piecewise-linear geometrical interface reconstruction technique on general unstructured meshes is employed for discretizing the viscoelastic stresses across the fluid interface. DeboRheo facilitates a flexible combination of different rheological models with appropriate stabilization methods to address the high Weissenberg number problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.10872v2</guid>
      <category>physics.flu-dyn</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthias Niethammer, Muhammad Hassan Asghar, Tomislav Maric, Dieter Bothe</dc:creator>
    </item>
    <item>
      <title>Enhancing Scalability of Quantum Eigenvalue Transformation of Unitary Matrices for Ground State Preparation through Adaptive Finer Filtering</title>
      <link>https://arxiv.org/abs/2401.09091</link>
      <description>arXiv:2401.09091v3 Announce Type: replace-cross 
Abstract: Hamiltonian simulation is a domain where quantum computers have the potential to outperform their classical counterparts due to their inherent quantum behavior. One of the main challenges of such quantum algorithms is up-scaling the system size, which is necessary to achieve meaningful quantum advantage. In this work, we present an approach to improve the scalability of eigenspace filtering for the ground state preparation of a given Hamiltonian. Our method aims to tackle limitations introduced by a small spectral gap and high degeneracy of low energy states. It is based on an adaptive sequence of eigenspace filtering through Quantum Eigenvalue Transformation of Unitary Matrices (QETU) followed by spectrum profiling. By combining our proposed algorithm with state-of-the-art phase estimation methods, we achieved good approximations for the ground state energy with local, two-qubit gate depolarizing probability up to $10^{-4}$. To demonstrate the key results in this work, we ran simulations with the transverse-field Ising Model on classical computers using Qiskit. We compare the performance of our approach with the static implementation of QETU and show that we can consistently achieve three to four orders of magnitude improvement in the absolute error rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.09091v3</guid>
      <category>quant-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Erenay Karacan, Yanbin Chen, Christian B. Mendl</dc:creator>
    </item>
    <item>
      <title>Stabler Neo-Hookean Simulation: Absolute Eigenvalue Filtering for Projected Newton</title>
      <link>https://arxiv.org/abs/2406.05928</link>
      <description>arXiv:2406.05928v3 Announce Type: replace-cross 
Abstract: Volume-preserving hyperelastic materials are widely used to model near-incompressible materials such as rubber and soft tissues. However, the numerical simulation of volume-preserving hyperelastic materials is notoriously challenging within this regime due to the non-convexity of the energy function. In this work, we identify the pitfalls of the popular eigenvalue clamping strategy for projecting Hessian matrices to positive semi-definiteness during Newton's method. We introduce a novel eigenvalue filtering strategy for projected Newton's method to stabilize the optimization of Neo-Hookean energy and other volume-preserving variants under high Poisson's ratio (near 0.5) and large initial volume change. Our method only requires a single line of code change in the existing projected Newton framework, while achieving significant improvement in both stability and convergence speed. We demonstrate the effectiveness and efficiency of our eigenvalue projection scheme on a variety of challenging examples and over different deformations on a large dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05928v3</guid>
      <category>cs.GR</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Honglin Chen, Hsueh-Ti Derek Liu, David I. W. Levin, Changxi Zheng, Alec Jacobson</dc:creator>
    </item>
  </channel>
</rss>
