<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.HC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.HC</link>
    <description>cs.HC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.HC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 06 Sep 2024 04:00:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Design and Evaluation of Camera-Centric Mobile Crowdsourcing Applications</title>
      <link>https://arxiv.org/abs/2409.03012</link>
      <description>arXiv:2409.03012v1 Announce Type: new 
Abstract: The data that underlies automated methods in computer vision and machine learning, such as image retrieval and fine-grained recognition, often comes from crowdsourcing. In contexts that rely on the intrinsic motivation of users, we seek to understand how the application design affects a user's willingness to contribute and the quantity and quality of the data they capture. In this project, we designed three versions of a camera-based mobile crowdsourcing application, which varied in the amount of labeling effort requested of the user and conducted a user study to evaluate the trade-off between the level of user-contributed information requested and the quantity and quality of labeled images collected. The results suggest that higher levels of user labeling do not lead to reduced contribution. Users collected and annotated the most images using the application version with the highest requested level of labeling with no decrease in user satisfaction. In preliminary experiments, the additional labeled data supported increased performance on an image retrieval task.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03012v1</guid>
      <category>cs.HC</category>
      <category>cs.CV</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abby Stylianou, Michelle Brachman, Albatool Wazzan, Samuel Black, Richard Souvenir</dc:creator>
    </item>
    <item>
      <title>A Large-Scale Survey of Password Entry Practices on Non-Desktop Devices</title>
      <link>https://arxiv.org/abs/2409.03044</link>
      <description>arXiv:2409.03044v1 Announce Type: new 
Abstract: Password managers encourage users to generate passwords to improve their security. However, research has shown that users avoid generating passwords, often giving the rationale that it is difficult to enter generated passwords on devices without a password manager. In this paper, we conduct a survey ($n=999$) of individuals from the US, UK, and Europe, exploring the range of devices on which they enter passwords and the challenges associated with password entry on those devices. We find that password entry on devices without password managers is a common occurrence and comes with significant usability challenges. These usability challenges lead users to weaken their passwords to increase the ease of entry. We conclude this paper with a discussion of how future research could address these challenges and encourage users to adopt generated passwords.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03044v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>John Sadik, Scott Ruoti</dc:creator>
    </item>
    <item>
      <title>Context-Aware Image Descriptions for Web Accessibility</title>
      <link>https://arxiv.org/abs/2409.03054</link>
      <description>arXiv:2409.03054v1 Announce Type: new 
Abstract: Blind and low vision (BLV) internet users access images on the web via text descriptions. New vision-to-language models such as GPT-V, Gemini, and LLaVa can now provide detailed image descriptions on-demand. While prior research and guidelines state that BLV audiences' information preferences depend on the context of the image, existing tools for accessing vision-to-language models provide only context-free image descriptions by generating descriptions for the image alone without considering the surrounding webpage context. To explore how to integrate image context into image descriptions, we designed a Chrome Extension that automatically extracts webpage context to inform GPT-4V-generated image descriptions. We gained feedback from 12 BLV participants in a user study comparing typical context-free image descriptions to context-aware image descriptions. We then further evaluated our context-informed image descriptions with a technical evaluation. Our user evaluation demonstrated that BLV participants frequently prefer context-aware descriptions to context-free descriptions. BLV participants also rated context-aware descriptions significantly higher in quality, imaginability, relevance, and plausibility. All participants shared that they wanted to use context-aware descriptions in the future and highlighted the potential for use in online shopping, social media, news, and personal interest blogs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03054v1</guid>
      <category>cs.HC</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3663548.3675658</arxiv:DOI>
      <dc:creator>Ananya Gubbi Mohanbabu, Amy Pavel</dc:creator>
    </item>
    <item>
      <title>Space to Teach: Content-Rich Canvases for Visually-Intensive Education</title>
      <link>https://arxiv.org/abs/2409.03072</link>
      <description>arXiv:2409.03072v1 Announce Type: new 
Abstract: With the decreasing cost of consumer display technologies making it easier for universities to have larger displays in classrooms, and the ubiquitous use of online tools such as collaborative whiteboards for remote learning during the COVID-19 pandemic, combining the two can be useful in higher education. This is especially true in visually intensive classes, such as data visualization courses, that can benefit from additional "space to teach," coined after the "space to think" sense-making idiom. In this paper, we reflect on our approach to using SAGE3, a collaborative whiteboard with advanced features, in higher education to teach visually intensive classes, provide examples of activities from our own visually-intensive courses, and present student feedback. We gather our observations into usage patterns for using content-rich canvases in education.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03072v1</guid>
      <category>cs.HC</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jesse Harden, Nurit Kirshenbaum, Roderick Tabalba, Ryan Theriot, Michael Rogers, Mahdi Belcaid, Chris North, Luc Renambot, Lance Long, Andrew Johnson, Jason Leigh</dc:creator>
    </item>
    <item>
      <title>Intersecting Liminality: Acquiring a Smartphone as a Blind or Low Vision Older Adult</title>
      <link>https://arxiv.org/abs/2409.03086</link>
      <description>arXiv:2409.03086v1 Announce Type: new 
Abstract: Older adults are increasingly acquiring smartphones. But acquiring smartphones can be difficult, and little is known about the particular challenges of older adults who are additionally blind or losing their vision. We shed light on the social and technical aspects of acquiring smartphones with vision loss, based on deep qualitative interviews with 22 blind or low vision (BLV) older adults aged 60 and over. Through our grounded theory analysis, we found that BLV older adults experience liminality as they acquire smartphones and transition through re-acquiring smartphones as they become blind, and they can transition through liminality by participating in mutual aid within the blind community. We contribute the notion of "Intersecting Liminality," which explains the marginalizing experience of simultaneously transitioning through vision loss, aging, and technology acquisition. We contend that Intersecting Liminality can serve as a framework that centers the dynamic nature of disability to help our community generate a more nuanced understanding of technology acquisition and more effective assistive interventions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03086v1</guid>
      <category>cs.HC</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3663548.3675622</arxiv:DOI>
      <dc:creator>Isabela Figueira, Yoonha Cha, Stacy M. Branham</dc:creator>
    </item>
    <item>
      <title>Can we enhance prosocial behavior? Using post-ride feedback to improve micromobility interactions</title>
      <link>https://arxiv.org/abs/2409.03153</link>
      <description>arXiv:2409.03153v1 Announce Type: new 
Abstract: Micromobility devices, such as e-scooters and delivery robots, hold promise for eco-friendly and cost-effective alternatives for future urban transportation. However, their lack of societal acceptance remains a challenge. Therefore, we must consider ways to promote prosocial behavior in micromobility interactions. We investigate how post-ride feedback can encourage the prosocial behavior of e-scooter riders while interacting with sidewalk users, including pedestrians and delivery robots. Using a web-based platform, we measure the prosocial behavior of e-scooter riders. Results found that post-ride feedback can successfully promote prosocial behavior, and objective measures indicated better gap behavior, lower speeds at interaction, and longer stopping time around other sidewalk actors. The findings of this study demonstrate the efficacy of post-ride feedback and provide a step toward designing methodologies to improve the prosocial behavior of mobility users.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03153v1</guid>
      <category>cs.HC</category>
      <category>cs.RO</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3640792.3675739</arxiv:DOI>
      <dc:creator>Sidney T. Scott-Sharoni, Shashank Mehrotra, Kevin Salubre, Miao Song, Teruhisa Misu, Kumar Akash</dc:creator>
    </item>
    <item>
      <title>End User Authoring of Personalized Content Classifiers: Comparing Example Labeling, Rule Writing, and LLM Prompting</title>
      <link>https://arxiv.org/abs/2409.03247</link>
      <description>arXiv:2409.03247v1 Announce Type: new 
Abstract: Existing tools for laypeople to create personal classifiers often assume a motivated user working uninterrupted in a single, lengthy session. However, users tend to engage with social media casually, with many short sessions on an ongoing, daily basis. To make creating personal classifiers for content curation easier for such users, tools should support rapid initialization and iterative refinement. In this work, we compare three strategies -- (1) example labeling, (2) rule writing, and (3) large language model (LLM) prompting -- for end users to build personal content classifiers. From an experiment with 37 non-programmers tasked with creating personalized comment moderation filters, we found that with LLM prompting, participants reached 95\% of peak performance in 5 minutes, beating other strategies due to higher recall, but all strategies struggled with iterative refinement. Despite LLM prompting's better performance, participants preferred different strategies in different contexts and, even when prompting, provided examples or wrote rule-like prompts, suggesting hybrid approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03247v1</guid>
      <category>cs.HC</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Leijie Wang, Kathryn Yurechko, Pranati Dani, Quan Ze Chen, Amy X. Zhang</dc:creator>
    </item>
    <item>
      <title>Dual-TSST: A Dual-Branch Temporal-Spectral-Spatial Transformer Model for EEG Decoding</title>
      <link>https://arxiv.org/abs/2409.03251</link>
      <description>arXiv:2409.03251v1 Announce Type: new 
Abstract: The decoding of electroencephalography (EEG) signals allows access to user intentions conveniently, which plays an important role in the fields of human-machine interaction. To effectively extract sufficient characteristics of the multichannel EEG, a novel decoding architecture network with a dual-branch temporal-spectral-spatial transformer (Dual-TSST) is proposed in this study. Specifically, by utilizing convolutional neural networks (CNNs) on different branches, the proposed processing network first extracts the temporal-spatial features of the original EEG and the temporal-spectral-spatial features of time-frequency domain data converted by wavelet transformation, respectively. These perceived features are then integrated by a feature fusion block, serving as the input of the transformer to capture the global long-range dependencies entailed in the non-stationary EEG, and being classified via the global average pooling and multi-layer perceptron blocks. To evaluate the efficacy of the proposed approach, the competitive experiments are conducted on three publicly available datasets of BCI IV 2a, BCI IV 2b, and SEED, with the head-to-head comparison of more than ten other state-of-the-art methods. As a result, our proposed Dual-TSST performs superiorly in various tasks, which achieves the promising EEG classification performance of average accuracy of 80.67% in BCI IV 2a, 88.64% in BCI IV 2b, and 96.65% in SEED, respectively. Extensive ablation experiments conducted between the Dual-TSST and comparative baseline model also reveal the enhanced decoding performance with each module of our proposed method. This study provides a new approach to high-performance EEG decoding, and has great potential for future CNN-Transformer based applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03251v1</guid>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongqi Li, Haodong Zhang, Yitong Chen</dc:creator>
    </item>
    <item>
      <title>Reimagining Data Visualization to Address Sustainability Goals</title>
      <link>https://arxiv.org/abs/2409.03611</link>
      <description>arXiv:2409.03611v1 Announce Type: new 
Abstract: Information visualization holds significant potential to support sustainability goals such as environmental stewardship, and climate resilience by transforming complex data into accessible visual formats that enhance public understanding of complex climate change data and drive actionable insights. While the field has predominantly focused on analytical orientation of visualization, challenging traditional visualization techniques and goals, through critical visualization research expands existing assumptions and conventions in the field. In this paper, I explore how reimagining overlooked aspects of data visualization, such as engagement, emotional resonance, communication, and community empowerment, can contribute to achieving sustainability objectives. I argue that by focusing on inclusive data visualization that promotes clarity, understandability, and public participation, we can make complex data more relatable and actionable, fostering broader connections and mobilizing collective action on critical issues like climate change. Moreover, I discuss the role of emotional receptivity in environmental data communication, stressing the need for visualizations that respect diverse cultural perspectives and emotional responses to achieve impactful outcomes. Drawing on insights from a decade of research in public participation and community engagement, I aim to highlight how data visualization can democratize data access and increase public involvement in order to contribute to a more sustainable and resilient future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03611v1</guid>
      <category>cs.HC</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Narges Mahyar</dc:creator>
    </item>
    <item>
      <title>Discovering Cyclists' Street Visual Preferences Through Multi-Source Big Data Using Deep Inverse Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2409.03148</link>
      <description>arXiv:2409.03148v1 Announce Type: cross 
Abstract: Cycling has gained global popularity for its health benefits and positive urban impacts. To effectively promote cycling, early studies have extensively investigated the relationship between cycling behaviors and environmental factors, especially cyclists' preferences when making route decisions. However, these studies often struggle to comprehensively describe detailed cycling procedures at a large scale due to data limitations, and they tend to overlook the complex nature of cyclists' preferences. To address these issues, we propose a novel framework aimed to quantify and interpret cyclists' complicated street visual preferences from cycling records by leveraging maximum entropy deep inverse reinforcement learning (MEDIRL) and explainable artificial intelligence (XAI). Implemented in Bantian Sub-district, Shenzhen, we adapt MEDIRL model for efficient estimation of cycling reward function by integrating dockless-bike-sharing (DBS) trajectory and street view images (SVIs), which serves as a representation of cyclists' preferences for street visual environments during routing. In addition, we demonstrate the feasibility and reliability of MEDIRL in discovering cyclists' street visual preferences. Further analysis reveals the nonlinear and interactive effects of street visual elements on cyclists' preferences, offering a holistic perspective on streetscape design. Our proposed framework advances the understanding of individual cycling behaviors and provides actionable insights for urban planners to design bicycle-friendly streetscapes that prioritize cyclists' preferences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03148v1</guid>
      <category>cs.LG</category>
      <category>cs.HC</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ren Kezhou, Gong Yongxi</dc:creator>
    </item>
    <item>
      <title>Content Moderation by LLM: From Accuracy to Legitimacy</title>
      <link>https://arxiv.org/abs/2409.03219</link>
      <description>arXiv:2409.03219v1 Announce Type: cross 
Abstract: One trending application of LLM (large language model) is to use it for content moderation in online platforms. Most current studies on this application have focused on the metric of accuracy - the extent to which LLM makes correct decisions about content. This article argues that accuracy is insufficient and misleading, because it fails to grasp the distinction between easy cases and hard cases as well as the inevitable trade-offs in achieving higher accuracy. Closer examination reveals that content moderation is a constitutive part of platform governance, the key of which is to gain and enhance legitimacy. Instead of making moderation decisions correct, the chief goal of LLM is to make them legitimate. In this regard, this article proposes a paradigm shift from the single benchmark of accuracy towards a legitimacy-based framework of evaluating the performance of LLM moderators. The framework suggests that for easy cases, the key is to ensure accuracy, speed and transparency, while for hard cases, what matters is reasoned justification and user participation. Examined under this framework, LLM's real potential in moderation is not accuracy improvement. Rather, LLM can better contribute in four other aspects: to conduct screening of hard cases from easy cases, to provide quality explanations for moderation decisions, to assist human reviewers in getting more contextual information, and to facilitate user participation in a more interactive way. Using normative theories from law and social sciences to critically assess the new technological application, this article seeks to redefine LLM's role in content moderation and redirect relevant research in this field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03219v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Tao Huang</dc:creator>
    </item>
    <item>
      <title>Strategic Chain-of-Thought: Guiding Accurate Reasoning in LLMs through Strategy Elicitation</title>
      <link>https://arxiv.org/abs/2409.03271</link>
      <description>arXiv:2409.03271v1 Announce Type: cross 
Abstract: The Chain-of-Thought (CoT) paradigm has emerged as a critical approach for enhancing the reasoning capabilities of large language models (LLMs). However, despite their widespread adoption and success, CoT methods often exhibit instability due to their inability to consistently ensure the quality of generated reasoning paths, leading to sub-optimal reasoning performance. To address this challenge, we propose the \textbf{Strategic Chain-of-Thought} (SCoT), a novel methodology designed to refine LLM performance by integrating strategic knowledge prior to generating intermediate reasoning steps. SCoT employs a two-stage approach within a single prompt: first eliciting an effective problem-solving strategy, which is then used to guide the generation of high-quality CoT paths and final answers. Our experiments across eight challenging reasoning datasets demonstrate significant improvements, including a 21.05\% increase on the GSM8K dataset and 24.13\% on the Tracking\_Objects dataset, respectively, using the Llama3-8b model. Additionally, we extend the SCoT framework to develop a few-shot method with automatically matched demonstrations, yielding even stronger results. These findings underscore the efficacy of SCoT, highlighting its potential to substantially enhance LLM performance in complex reasoning tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03271v1</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.HC</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu Wang, Shiwan Zhao, Zhihu Wang, Heyuan Huang, Ming Fan, Yubo Zhang, Zhixing Wang, Haijun Wang, Ting Liu</dc:creator>
    </item>
    <item>
      <title>Improving Uncertainty-Error Correspondence in Deep Bayesian Medical Image Segmentation</title>
      <link>https://arxiv.org/abs/2409.03470</link>
      <description>arXiv:2409.03470v1 Announce Type: cross 
Abstract: Increased usage of automated tools like deep learning in medical image segmentation has alleviated the bottleneck of manual contouring. This has shifted manual labour to quality assessment (QA) of automated contours which involves detecting errors and correcting them. A potential solution to semi-automated QA is to use deep Bayesian uncertainty to recommend potentially erroneous regions, thus reducing time spent on error detection. Previous work has investigated the correspondence between uncertainty and error, however, no work has been done on improving the "utility" of Bayesian uncertainty maps such that it is only present in inaccurate regions and not in the accurate ones. Our work trains the FlipOut model with the Accuracy-vs-Uncertainty (AvU) loss which promotes uncertainty to be present only in inaccurate regions. We apply this method on datasets of two radiotherapy body sites, c.f. head-and-neck CT and prostate MR scans. Uncertainty heatmaps (i.e. predictive entropy) are evaluated against voxel inaccuracies using Receiver Operating Characteristic (ROC) and Precision-Recall (PR) curves. Numerical results show that when compared to the Bayesian baseline the proposed method successfully suppresses uncertainty for accurate voxels, with similar presence of uncertainty for inaccurate voxels. Code to reproduce experiments is available at https://github.com/prerakmody/bayesuncertainty-error-correspondence</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03470v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.59275/j.melba.2024-5gc8</arxiv:DOI>
      <arxiv:journal_reference>Machine.Learning.for.Biomedical.Imaging. 2 (2024)</arxiv:journal_reference>
      <dc:creator>Prerak Mody, Nicolas F. Chaves-de-Plaza, Chinmay Rao, Eleftheria Astrenidou, Mischa de Ridder, Nienke Hoekstra, Klaus Hildebrandt, Marius Staring</dc:creator>
    </item>
    <item>
      <title>Limited but consistent gains in adversarial robustness by co-training object recognition models with human EEG</title>
      <link>https://arxiv.org/abs/2409.03646</link>
      <description>arXiv:2409.03646v1 Announce Type: cross 
Abstract: In contrast to human vision, artificial neural networks (ANNs) remain relatively susceptible to adversarial attacks. To address this vulnerability, efforts have been made to transfer inductive bias from human brains to ANNs, often by training the ANN representations to match their biological counterparts. Previous works relied on brain data acquired in rodents or primates using invasive techniques, from specific regions of the brain, under non-natural conditions (anesthetized animals), and with stimulus datasets lacking diversity and naturalness. In this work, we explored whether aligning model representations to human EEG responses to a rich set of real-world images increases robustness to ANNs. Specifically, we trained ResNet50-backbone models on a dual task of classification and EEG prediction; and evaluated their EEG prediction accuracy and robustness to adversarial attacks. We observed significant correlation between the networks' EEG prediction accuracy, often highest around 100 ms post stimulus onset, and their gains in adversarial robustness. Although effect size was limited, effects were consistent across different random initializations and robust for architectural variants. We further teased apart the data from individual EEG channels and observed strongest contribution from electrodes in the parieto-occipital regions. The demonstrated utility of human EEG for such tasks opens up avenues for future efforts that scale to larger datasets under diverse stimuli conditions with the promise of stronger effects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03646v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Manshan Guo, Bhavin Choksi, Sari Sadiya, Alessandro T. Gifford, Martina G. Vilas, Radoslaw M. Cichy, Gemma Roig</dc:creator>
    </item>
    <item>
      <title>WildVis: Open Source Visualizer for Million-Scale Chat Logs in the Wild</title>
      <link>https://arxiv.org/abs/2409.03753</link>
      <description>arXiv:2409.03753v1 Announce Type: cross 
Abstract: The increasing availability of real-world conversation data offers exciting opportunities for researchers to study user-chatbot interactions. However, the sheer volume of this data makes manually examining individual conversations impractical. To overcome this challenge, we introduce WildVis, an interactive tool that enables fast, versatile, and large-scale conversation analysis. WildVis provides search and visualization capabilities in the text and embedding spaces based on a list of criteria. To manage million-scale datasets, we implemented optimizations including search index construction, embedding precomputation and compression, and caching to ensure responsive user interactions within seconds. We demonstrate WildVis's utility through three case studies: facilitating chatbot misuse research, visualizing and comparing topic distributions across datasets, and characterizing user-specific conversation patterns. WildVis is open-source and designed to be extendable, supporting additional datasets and customized search and visualization functionalities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03753v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.IR</category>
      <category>cs.LG</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuntian Deng, Wenting Zhao, Jack Hessel, Xiang Ren, Claire Cardie, Yejin Choi</dc:creator>
    </item>
    <item>
      <title>Decision Theoretic Foundations for Experiments Evaluating Human Decisions</title>
      <link>https://arxiv.org/abs/2401.15106</link>
      <description>arXiv:2401.15106v3 Announce Type: replace 
Abstract: DeHow well people use information displays to make decisions is of primary interest in human-centered AI, model explainability, data visualization, and related areas. However, what constitutes a decision problem, and what is required for a study to establish that human decisions could be improved remain open to speculation. We propose a widely applicable definition of a decision problem synthesized from statistical decision theory and information economics as a standard for establishing when human decisions can be improved in HCI. We argue that to attribute loss in human performance to forms of bias, an experiment must provide participants with the information that a rational agent would need to identify the utility-maximizing decision. As a demonstration, we evaluate the extent to which recent evaluations of decision-making from the literature on AI-assisted decisions achieve these criteria. We find that only 10 (26\%) of 39 studies that claim to identify biased behavior present participants with sufficient information to characterize their behavior as deviating from good decision-making in at least one treatment condition. We motivate the value of studying well-defined decision problems by describing a characterization of performance losses they allow us to conceive. In contrast, the ambiguities of a poorly communicated decision problem preclude normative interpretation. We conclude with recommendations for practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.15106v3</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jessica Hullman, Alex Kale, Jason Hartline</dc:creator>
    </item>
    <item>
      <title>An empirical study to understand how students use ChatGPT for writing essays and how it affects their ownership</title>
      <link>https://arxiv.org/abs/2405.13890</link>
      <description>arXiv:2405.13890v2 Announce Type: replace 
Abstract: As large language models (LLMs) become more powerful and ubiquitous, systems like ChatGPT are increasingly used by students to help them with writing tasks. To better understand how these tools are used, we investigate how students might use an LLM for essay writing, for example, to study the queries asked to ChatGPT and the responses that ChatGPT gives. To that end, we plan to conduct a user study that will record the user writing process and present them with the opportunity to use ChatGPT as an AI assistant. This study's findings will help us understand how these tools are used and how practitioners -- such as educators and essay readers -- should consider writing education and evaluation based on essay writing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13890v2</guid>
      <category>cs.HC</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrew Jelson, Sang Won Lee</dc:creator>
    </item>
    <item>
      <title>Promises and challenges of generative artificial intelligence for human learning</title>
      <link>https://arxiv.org/abs/2408.12143</link>
      <description>arXiv:2408.12143v3 Announce Type: replace 
Abstract: Generative artificial intelligence (GenAI) holds the potential to transform the delivery, cultivation, and evaluation of human learning. This Perspective examines the integration of GenAI as a tool for human learning, addressing its promises and challenges from a holistic viewpoint that integrates insights from learning sciences, educational technology, and human-computer interaction. GenAI promises to enhance learning experiences by scaling personalised support, diversifying learning materials, enabling timely feedback, and innovating assessment methods. However, it also presents critical issues such as model imperfections, ethical dilemmas, and the disruption of traditional assessments. Cultivating AI literacy and adaptive skills is imperative for facilitating informed engagement with GenAI technologies. Rigorous research across learning contexts is essential to evaluate GenAI's impact on human cognition, metacognition, and creativity. Humanity must learn with and about GenAI, ensuring it becomes a powerful ally in the pursuit of knowledge and innovation, rather than a crutch that undermines our intellectual abilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12143v3</guid>
      <category>cs.HC</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lixiang Yan, Samuel Greiff, Ziwen Teuber, Dragan Ga\v{s}evi\'c</dc:creator>
    </item>
    <item>
      <title>Assembling the Puzzle: Exploring Collaboration and Data Sensemaking in Nursing Practices for Remote Patient Monitoring</title>
      <link>https://arxiv.org/abs/2409.02579</link>
      <description>arXiv:2409.02579v2 Announce Type: replace 
Abstract: Remote patient monitoring (RPM) involves the remote collection and transmission of patient health data, serving as a notable application of data-driven healthcare. This technology facilitates clinical monitoring and decision-making, offering benefits like reduced healthcare costs and improved patient outcomes. However, RPM also introduces challenges common to data-driven healthcare, such as additional data work that can disrupt clinician's workflow. This study explores the daily practices, collaboration mechanisms, and sensemaking processes of nurses in RPM through field observations and interviews with six stakeholders. Preliminary results indicate that RPM's scale-up pushes clinicians toward asynchronous collaboration. Data sensemaking is crucial for this type of collaboration, but existing technologies often create friction rather than support. This work provides empirical insights into clinical workflow in nursing practice, especially RPM. We suggest recognizing data sensemaking as a distinct nursing practice within data work and recommend further investigation into its role in the workflow of nurses in RPM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02579v2</guid>
      <category>cs.HC</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3678884.3681866</arxiv:DOI>
      <dc:creator>Mihnea Calota, Janet Yi-Ching Huang, Lin-Lin Chen, Mathias Funk</dc:creator>
    </item>
    <item>
      <title>FRAC-Q-Learning: A Reinforcement Learning with Boredom Avoidance Processes for Social Robots</title>
      <link>https://arxiv.org/abs/2311.15327</link>
      <description>arXiv:2311.15327v4 Announce Type: replace-cross 
Abstract: The reinforcement learning algorithms have often been applied to social robots. However, most reinforcement learning algorithms were not optimized for the use of social robots, and consequently they may bore users. We proposed a new reinforcement learning method specialized for the social robot, the FRAC-Q-learning, that can avoid user boredom. The proposed algorithm consists of a forgetting process in addition to randomizing and categorizing processes. This study evaluated interest and boredom hardness scores of the FRAC-Q-learning by a comparison with the traditional Q-learning. The FRAC-Q-learning showed significantly higher trend of interest score, and indicated significantly harder to bore users compared to the traditional Q-learning. Therefore, the FRAC-Q-learning can contribute to develop a social robot that will not bore users. The proposed algorithm has a potential to apply for Web-based communication and educational systems. This paper presents the entire process, detailed implementation and a detailed evaluation method of the of the FRAC-Q-learning for the first time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.15327v4</guid>
      <category>cs.RO</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Akinari Onishi</dc:creator>
    </item>
    <item>
      <title>Online Advertising is a Regrettable Necessity: On the Dangers of Pay-Walling the Web</title>
      <link>https://arxiv.org/abs/2409.00026</link>
      <description>arXiv:2409.00026v2 Announce Type: replace-cross 
Abstract: The exponential growth of the web and its benefits can be attributed largely to its open model where anyone with internet connection can access information on the web for free. This has created unprecedented opportunities for various members of society including the most vulnerable, as recognized by organizations such as the UN. This again can be attributed to online advertising, which has been the main financier to the open web. However, recent trends of paywalling information and services on the web are creating imminent dangers to such open model of the web, inhibiting access for the economically vulnerable, and eventually creating digital segregation. In this paper, we argue that this emerging model lacks sustainability, exacerbates digital divide, and might lead to collapse of online advertising. We revisit the ad-supported open web business model and demonstrate how global users actually pay for the ads they see. Using data on GNI (gross national income) per capita and average paywall access costs, we established a simple income-paywall expenditure gap baseline. With this baseline we show that 135 countries with a total population estimate of 6.56 billion people cannot afford a scenario of a fully paywalled web. We further discuss how a mixed model of the so-called "premium services" creates digital segregation and poses danger to online advertising ecosystem. Finally, we call for further research and policy initiatives to keep the web open and more inclusive with a sustainable business model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00026v2</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yonas Kassa</dc:creator>
    </item>
    <item>
      <title>Trustworthy Human-AI Collaboration: Reinforcement Learning with Human Feedback and Physics Knowledge for Safe Autonomous Driving</title>
      <link>https://arxiv.org/abs/2409.00858</link>
      <description>arXiv:2409.00858v2 Announce Type: replace-cross 
Abstract: In the field of autonomous driving, developing safe and trustworthy autonomous driving policies remains a significant challenge. Recently, Reinforcement Learning with Human Feedback (RLHF) has attracted substantial attention due to its potential to enhance training safety and sampling efficiency. Nevertheless, existing RLHF-enabled methods often falter when faced with imperfect human demonstrations, potentially leading to training oscillations or even worse performance than rule-based approaches. Inspired by the human learning process, we propose Physics-enhanced Reinforcement Learning with Human Feedback (PE-RLHF). This novel framework synergistically integrates human feedback (e.g., human intervention and demonstration) and physics knowledge (e.g., traffic flow model) into the training loop of reinforcement learning. The key advantage of PE-RLHF is its guarantee that the learned policy will perform at least as well as the given physics-based policy, even when human feedback quality deteriorates, thus ensuring trustworthy safety improvements. PE-RLHF introduces a Physics-enhanced Human-AI (PE-HAI) collaborative paradigm for dynamic action selection between human and physics-based actions, employs a reward-free approach with a proxy value function to capture human preferences, and incorporates a minimal intervention mechanism to reduce the cognitive load on human mentors. Extensive experiments across diverse driving scenarios demonstrate that PE-RLHF significantly outperforms traditional methods, achieving state-of-the-art (SOTA) performance in safety, efficiency, and generalizability, even with varying quality of human feedback. The philosophy behind PE-RLHF not only advances autonomous driving technology but can also offer valuable insights for other safety-critical domains. Demo video and code are available at: \https://zilin-huang.github.io/PE-RLHF-website/</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00858v2</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zilin Huang, Zihao Sheng, Sikai Chen</dc:creator>
    </item>
  </channel>
</rss>
