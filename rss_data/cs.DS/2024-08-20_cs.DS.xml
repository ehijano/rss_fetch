<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 21 Aug 2024 01:47:52 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 20 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Quantum Algorithm for Jaccard Similarity</title>
      <link>https://arxiv.org/abs/2408.08940</link>
      <description>arXiv:2408.08940v1 Announce Type: new 
Abstract: Jaccard Similarity is a very common proximity measurement used to compute the similarity between two asymmetric binary vectors. Jaccard Similarity is the ratio between the 1s (Intersection of two vectors) to 1s (Union of two vectors). This paper introduces a quantum algorithm for finding the Jaccard Similarity 1s, in the Intersection and Union of two binary vectors. There are two sub-algorithms one for each. Measuring the register for respective algorithm gives count of number of 1 s in binary format. Implementation on IBM composer is also included.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08940v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Varun Puram, Ruthvik Rao Bobbili, Johnson P Thomas</dc:creator>
    </item>
    <item>
      <title>Unbreakable Decomposition in Close-to-Linear Time</title>
      <link>https://arxiv.org/abs/2408.09368</link>
      <description>arXiv:2408.09368v1 Announce Type: new 
Abstract: Unbreakable decomposition, introduced by Cygan et al. (SICOMP'19) and Cygan et al. (TALG'20), has proven to be one of the most powerful tools for parameterized graph cut problems in recent years. Unfortunately, all known constructions require at least $\Omega_k\left(mn^2\right)$ time, given an undirected graph with $n$ vertices, $m$ edges, and cut-size parameter $k$. In this work, we show the first close-to-linear time parameterized algorithm that computes an unbreakable decomposition. More precisely, for any $0&lt;\epsilon\leq 1$, our algorithm runs in time $2^{O(\frac{k}{\epsilon} \log \frac{k}{\epsilon})}m^{1 + \epsilon}$ and computes a $(O(k/\epsilon), k)$ unbreakable tree decomposition of $G$, where each bag has adhesion at most $O(k/\epsilon)$.
  This immediately opens up possibilities for obtaining close-to-linear time algorithms for numerous problems whose only known solution is based on unbreakable decomposition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09368v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aditya Anand, Euiwoong Lee, Jason Li, Yaowei Long, Thatchaphol Saranurak</dc:creator>
    </item>
    <item>
      <title>Parallel Sampling via Counting</title>
      <link>https://arxiv.org/abs/2408.09442</link>
      <description>arXiv:2408.09442v1 Announce Type: new 
Abstract: We show how to use parallelization to speed up sampling from an arbitrary distribution $\mu$ on a product space $[q]^n$, given oracle access to counting queries: $\mathbb{P}_{X\sim \mu}[X_S=\sigma_S]$ for any $S\subseteq [n]$ and $\sigma_S \in [q]^S$. Our algorithm takes $O({n^{2/3}\cdot \operatorname{polylog}(n,q)})$ parallel time, to the best of our knowledge, the first sublinear in $n$ runtime for arbitrary distributions. Our results have implications for sampling in autoregressive models. Our algorithm directly works with an equivalent oracle that answers conditional marginal queries $\mathbb{P}_{X\sim \mu}[X_i=\sigma_i\;\vert\; X_S=\sigma_S]$, whose role is played by a trained neural network in autoregressive models. This suggests a roughly $n^{1/3}$-factor speedup is possible for sampling in any-order autoregressive models. We complement our positive result by showing a lower bound of $\widetilde{\Omega}(n^{1/3})$ for the runtime of any parallel sampling algorithm making at most $\operatorname{poly}(n)$ queries to the counting oracle, even for $q=2$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09442v1</guid>
      <category>cs.DS</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nima Anari, Ruiquan Gao, Aviad Rubinstein</dc:creator>
    </item>
    <item>
      <title>Efficient Online Sensitivity Analysis For The Injective Bottleneck Path Problem</title>
      <link>https://arxiv.org/abs/2408.09443</link>
      <description>arXiv:2408.09443v1 Announce Type: new 
Abstract: The tolerance of an element of a combinatorial optimization problem with respect to a given optimal solution is the maximum change, i.e., decrease or increase, of its cost, such that this solution remains optimal. The bottleneck path problem, for given an edge-capacitated graph, a source, and a target, is to find the $\max$-$\min$ value of edge capacities on paths between the source and the target. For this problem and a network with $n$ vertices and $m$ edges, there is known the Ramaswamy-Orlin-Chakravarty's algorithm to compute all tolerances in $O(m+n\log n)$ time. In this paper, for any in advance given sample of the problem with pairwise distinct edge capacities, we present a constant-time algorithm for computing both tolerances of an arbitrary edge with a preprocessing time $O\big(m \alpha(m,n)\big)$, where $\alpha(\cdot,\cdot)$ is the inverse Ackermann function. For given $k$ source-target pairs, our solution yields an $O\big((\alpha(m,n)+k)m\big)$-time algorithm to find tolerances of all edges with respect to optimal paths between the sources and targets, while the known algorithm takes $O\big(k(m+n\log n)\big)$ time to find them.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09443v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kirill V. Kaymakov, Dmitry S. Malyshev</dc:creator>
    </item>
    <item>
      <title>Pre-assignment problem for unique minimum vertex cover on bounded clique-width graphs</title>
      <link>https://arxiv.org/abs/2408.09591</link>
      <description>arXiv:2408.09591v1 Announce Type: new 
Abstract: Horiyama et al. (AAAI 2024) considered the problem of generating instances with a unique minimum vertex cover under certain conditions. The Pre-assignment for Uniquification of Minimum Vertex Cover problem (shortly PAU-VC) is the problem, for given a graph $G$, to find a minimum set $S$ of vertices in $G$ such that there is a unique minimum vertex cover of $G$ containing $S$. We show that PAU-VC is fixed-parameter tractable parameterized by clique-width, which improves an exponential algorithm for trees given by Horiyama et al. Among natural graph classes with unbounded clique-width, we show that the problem can be solved in linear time on split graphs and unit interval graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09591v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shinwoo Ahn, Yeonsu Chang, Kyungjin Cho, O-joung Kwon, Myounghwan Lee, Eunjin Oh, Hyeonjun Shin</dc:creator>
    </item>
    <item>
      <title>Work-Efficient Parallel Counting via Sampling</title>
      <link>https://arxiv.org/abs/2408.09719</link>
      <description>arXiv:2408.09719v1 Announce Type: new 
Abstract: We study the problem of estimating the partition function $Z(\beta) = \sum_{x \in \Omega} \exp[-\beta \cdot H(x)]$ of a Gibbs distribution defined by a Hamiltonian $H(\cdot)$. It is well known that the partition function $Z(\beta)$ can be well approximated by the simulated annealing method, assuming a sampling oracle that can generate samples according to the Gibbs distribution of any given inverse temperature $\beta$. This method yields the most efficient reductions from counting to sampling, including:
  $\bullet$ classic non-adaptive (parallel) algorithms with sub-optimal cost [DFK89; Bez+08];
  $\bullet$ adaptive (sequential) algorithms with near-optimal cost [SVV09; Hub15; Kol18; HK23].
  In this paper, we give an algorithm that achieves efficiency in both parallelism and total work. Specifically, it provides a reduction from counting to sampling using near-optimal total work and logarithmic depth of computation. Consequently, it gives work-efficient parallel counting algorithms for several important models, including the hardcore and Ising models in the uniqueness regime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09719v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.DC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hongyang Liu, Yitong Yin, Yiyao Zhang</dc:creator>
    </item>
    <item>
      <title>Improved Distance (Sensitivity) Oracles with Subquadratic Space</title>
      <link>https://arxiv.org/abs/2408.10014</link>
      <description>arXiv:2408.10014v2 Announce Type: new 
Abstract: A distance oracle (DO) with stretch $(\alpha, \beta)$ for a graph $G$ is a data structure that, when queried with vertices $s$ and $t$, returns a value $\widehat{d}(s,t)$ such that $d(s,t) \le \widehat{d}(s,t) \le \alpha \cdot d(s,t) + \beta$. An $f$-edge fault-tolerant distance sensitivity oracle ($f$-DSO) additionally receives a set $F$ of up to $f$ edges and estimates the $s$-$t$-distance in $G{-}F$. Our first contribution is a new distance oracle with subquadratic space for undirected graphs. Introducing a small additive stretch $\beta &gt; 0$ allows us to make the multiplicative stretch $\alpha$ arbitrarily small. This sidesteps a known lower bound of $\alpha \ge 3$ (for $\beta = 0$ and subquadratic space) [Thorup &amp; Zwick, JACM 2005]. We present a DO for graphs with edge weights in $[0,W]$ that, for any positive integer $t$ and any $c \in (0, \ell/2]$, has stretch $(1{+}\frac{1}{\ell}, 2W)$, space $\widetilde{O}(n^{2-\frac{c}{t}})$, and query time $O(n^c)$. These are the first subquadratic-space DOs with $(1+\epsilon, O(1))$-stretch generalizing Agarwal and Godfrey's results for sparse graphs [SODA 2013] to general undirected graphs. Our second contribution is a framework that turns a $(\alpha,\beta)$-stretch DO for unweighted graphs into an $(\alpha (1{+}\varepsilon),\beta)$-stretch $f$-DSO with sensitivity $f = o(\log(n)/\log\log n)$ and retains subquadratic space. This generalizes a result by Bil\`o, Chechik, Choudhary, Cohen, Friedrich, Krogmann, and Schirneck [STOC 2023, TheoretiCS 2024] for the special case of stretch $(3,0)$ and $f = O(1)$. By combining the framework with our new distance oracle, we obtain an $f$-DSO that, for any $\gamma \in (0, (\ell{+}1)/2]$, has stretch $((1{+}\frac{1}{\ell}) (1{+}\varepsilon), 2)$, space $n^{ 2- \frac{\gamma}{(\ell+1)(f+1)} + o(1)}/\varepsilon^{f+2}$, and query time $\widetilde{O}(n^{\gamma} /{\varepsilon}^2)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10014v2</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Davide Bil\`o, Shiri Chechik, Keerti Choudhary, Sarel Cohen, Tobias Friedrich, Martin Schirneck</dc:creator>
    </item>
    <item>
      <title>Eulerian Graph Sparsification by Effective Resistance Decomposition</title>
      <link>https://arxiv.org/abs/2408.10172</link>
      <description>arXiv:2408.10172v1 Announce Type: new 
Abstract: We provide an algorithm that, given an $n$-vertex $m$-edge Eulerian graph with polynomially bounded weights, computes an $\breve{O}(n\log^{2} n \cdot \varepsilon^{-2})$-edge $\varepsilon$-approximate Eulerian sparsifier with high probability in $\breve{O}(m\log^3 n)$ time (where $\breve{O}(\cdot)$ hides $\text{polyloglog}(n)$ factors). Due to a reduction from [Peng-Song, STOC '22], this yields an $\breve{O}(m\log^3 n + n\log^6 n)$-time algorithm for solving $n$-vertex $m$-edge Eulerian Laplacian systems with polynomially-bounded weights with high probability, improving upon the previous state-of-the-art runtime of $\Omega(m\log^8 n + n\log^{23} n)$. We also give a polynomial-time algorithm that computes $O(\min(n\log n \cdot \varepsilon^{-2} + n\log^{5/3} n \cdot \varepsilon^{-4/3}, n\log^{3/2} n \cdot \varepsilon^{-2}))$-edge sparsifiers, improving the best such sparsity bound of $O(n\log^2 n \cdot \varepsilon^{-2} + n\log^{8/3} n \cdot \varepsilon^{-4/3})$ [Sachdeva-Thudi-Zhao, ICALP '24]. Finally, we show that our techniques extend to yield the first $O(m\cdot\text{polylog}(n))$ time algorithm for computing $O(n\varepsilon^{-1}\cdot\text{polylog}(n))$-edge graphical spectral sketches, as well as a natural Eulerian generalization we introduce.
  In contrast to prior Eulerian graph sparsification algorithms which used either short cycle or expander decompositions, our algorithms use a simple efficient effective resistance decomposition scheme we introduce. Our algorithms apply a natural sampling scheme and electrical routing (to achieve degree balance) to such decompositions. Our analysis leverages new asymmetric variance bounds specialized to Eulerian Laplacians and tools from discrepancy theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10172v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arun Jambulapati, Sushant Sachdeva, Aaron Sidford, Kevin Tian, Yibin Zhao</dc:creator>
    </item>
    <item>
      <title>kendallknight: Efficient Implementation of Kendall's Correlation Coefficient Computation</title>
      <link>https://arxiv.org/abs/2408.09618</link>
      <description>arXiv:2408.09618v1 Announce Type: cross 
Abstract: The kendallknight package introduces an efficient implementation of Kendall's correlation coefficient computation, significantly improving the processing time for large datasets without sacrificing accuracy. The kendallknight package, following Knight (1966) and posterior literature, reduces the computational complexity resulting in drastic reductions in computation time, transforming operations that would take minutes or hours into milliseconds or minutes, while maintaining precision and correctly handling edge cases and errors. The package is particularly advantageous in econometric and statistical contexts where rapid and accurate calculation of Kendall's correlation coefficient is desirable. Benchmarks demonstrate substantial performance gains over the base R implementation, especially for large datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09618v1</guid>
      <category>stat.CO</category>
      <category>cs.DS</category>
      <category>econ.EM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mauricio Vargas Sep\'ulveda</dc:creator>
    </item>
    <item>
      <title>Differential Private Stochastic Optimization with Heavy-tailed Data: Towards Optimal Rates</title>
      <link>https://arxiv.org/abs/2408.09891</link>
      <description>arXiv:2408.09891v1 Announce Type: cross 
Abstract: We study convex optimization problems under differential privacy (DP). With heavy-tailed gradients, existing works achieve suboptimal rates. The main obstacle is that existing gradient estimators have suboptimal tail properties, resulting in a superfluous factor of $d$ in the union bound. In this paper, we explore algorithms achieving optimal rates of DP optimization with heavy-tailed gradients. Our first method is a simple clipping approach. Under bounded $p$-th order moments of gradients, with $n$ samples, it achieves $\tilde{O}(\sqrt{d/n}+\sqrt{d}(\sqrt{d}/n\epsilon)^{1-1/p})$ population risk with $\epsilon\leq 1/\sqrt{d}$. We then propose an iterative updating method, which is more complex but achieves this rate for all $\epsilon\leq 1$. The results significantly improve over existing methods. Such improvement relies on a careful treatment of the tail behavior of gradient estimators. Our results match the minimax lower bound in \cite{kamath2022improved}, indicating that the theoretical limit of stochastic convex optimization under DP is achievable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09891v1</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Puning Zhao, Jiafei Wu, Zhe Liu, Chong Wang, Rongfei Fan, Qingming Li</dc:creator>
    </item>
    <item>
      <title>Efficient Inference of Sub-Item Id-based Sequential Recommendation Models with Millions of Items</title>
      <link>https://arxiv.org/abs/2408.09992</link>
      <description>arXiv:2408.09992v1 Announce Type: cross 
Abstract: Transformer-based recommender systems, such as BERT4Rec or SASRec, achieve state-of-the-art results in sequential recommendation. However, it is challenging to use these models in production environments with catalogues of millions of items: scaling Transformers beyond a few thousand items is problematic for several reasons, including high model memory consumption and slow inference. In this respect, RecJPQ is a state-of-the-art method of reducing the models' memory consumption; RecJPQ compresses item catalogues by decomposing item IDs into a small number of shared sub-item IDs. Despite reporting the reduction of memory consumption by a factor of up to 50x, the original RecJPQ paper did not report inference efficiency improvements over the baseline Transformer-based models. Upon analysing RecJPQ's scoring algorithm, we find that its efficiency is limited by its use of score accumulators for each item, which prevents parallelisation. In contrast, LightRec (a non-sequential method that uses a similar idea of sub-ids) reported large inference efficiency improvements using an algorithm we call PQTopK. We show that it is also possible to improve RecJPQ-based models' inference efficiency using the PQTopK algorithm. In particular, we speed up RecJPQ-enhanced SASRec by a factor of 4.5 x compared to the original SASRec's inference method and by a factor of 1.56 x compared to the method implemented in RecJPQ code on a large-scale Gowalla dataset with more than a million items. Further, using simulated data, we show that PQTopK remains efficient with catalogues of up to tens of millions of items, removing one of the last obstacles to using Transformer-based models in production environments with large catalogues.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09992v1</guid>
      <category>cs.IR</category>
      <category>cs.DS</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3640457.3688168</arxiv:DOI>
      <dc:creator>Aleksandr V. Petrov, Craig Macdonald, Nicola Tonellotto</dc:creator>
    </item>
    <item>
      <title>Improved Bounds for Online Facility Location with Predictions</title>
      <link>https://arxiv.org/abs/2107.08277</link>
      <description>arXiv:2107.08277v4 Announce Type: replace 
Abstract: We consider Online Facility Location in the framework of learning-augmented online algorithms. In Online Facility Location (OFL), demands arrive one-by-one in a metric space and must be (irrevocably) assigned to an open facility upon arrival, without any knowledge about future demands. We focus on uniform facility opening costs and present an online algorithm for OFL that exploits potentially imperfect predictions on the locations of the optimal facilities. We prove that the competitive ratio decreases from sublogarithmic in the number of demands $n$ to constant as the so-called $\eta_1$ error, i.e., the sum of distances of the predicted locations to the optimal facility locations, decreases. E.g., our analysis implies that if for some $\varepsilon &gt; 0$, $\eta_1 = \mathrm{OPT} / n^\varepsilon$, where $\mathrm{OPT}$ is the cost of the optimal solution, the competitive ratio becomes $O(1/\varepsilon)$. We complement our analysis with a matching lower bound establishing that the dependence of the algorithm's competitive ratio on the $\eta_1$ error is optimal, up to constant factors. Finally, we evaluate our algorithm on real world data and compare the performance of our learning-augmented approach against the performance of the best known algorithm for OFL without predictions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2107.08277v4</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dimitris Fotakis, Evangelia Gergatsouli, Themis Gouleakis, Nikolas Patris, Thanos Tolias</dc:creator>
    </item>
    <item>
      <title>Best of Both Worlds: Practical and Theoretically Optimal Submodular Maximization in Parallel</title>
      <link>https://arxiv.org/abs/2111.07917</link>
      <description>arXiv:2111.07917v3 Announce Type: replace 
Abstract: For the problem of maximizing a monotone, submodular function with respect to a cardinality constraint $k$ on a ground set of size $n$, we provide an algorithm that achieves the state-of-the-art in both its empirical performance and its theoretical properties, in terms of adaptive complexity, query complexity, and approximation ratio; that is, it obtains, with high probability, query complexity of $O(n)$ in expectation, adaptivity of $O(\log(n))$, and approximation ratio of nearly $1-1/e$. The main algorithm is assembled from two components which may be of independent interest. The first component of our algorithm, LINEARSEQ, is useful as a preprocessing algorithm to improve the query complexity of many algorithms. Moreover, a variant of LINEARSEQ is shown to have adaptive complexity of $O( \log (n / k) )$ which is smaller than that of any previous algorithm in the literature. The second component is a parallelizable thresholding procedure THRESHOLDSEQ for adding elements with gain above a constant threshold. Finally, we demonstrate that our main algorithm empirically outperforms, in terms of runtime, adaptive rounds, total queries, and objective values, the previous state-of-the-art algorithm FAST in a comprehensive evaluation with six submodular objective functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2111.07917v3</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Advances in Neural Information Processing Systems 34 (2021): 25528-25539</arxiv:journal_reference>
      <dc:creator>Yixin Chen, Tonmoy Dey, Alan Kuhnle</dc:creator>
    </item>
    <item>
      <title>Algorithms for the ferromagnetic Potts model on expanders</title>
      <link>https://arxiv.org/abs/2204.01923</link>
      <description>arXiv:2204.01923v3 Announce Type: replace 
Abstract: We give algorithms for approximating the partition function of the ferromagnetic $q$-color Potts model on graphs of maximum degree $d$. Our primary contribution is a fully polynomial-time approximation scheme for $d$-regular graphs with an expansion condition at low temperatures (that is, bounded away from the order-disorder threshold). The expansion condition is much weaker than in previous works; for example, the expansion exhibited by the hypercube suffices. The main improvements come from a significantly sharper analysis of standard polymer models; we use extremal graph theory and applications of Karger's algorithm to count cuts that may be of independent interest. It is \#BIS-hard to approximate the partition function at low temperatures on bounded-degree graphs, so our algorithm can be seen as evidence that hard instances of \#BIS are rare. We also obtain efficient algorithms in the Gibbs uniqueness region for bounded-degree graphs. While our high temperature proof follows more standard polymer model analysis, our result holds in the largest known range of parameters $d$ and $q$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2204.01923v3</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1017/S0963548324000087</arxiv:DOI>
      <dc:creator>Charlie Carlson, Ewan Davies, Nicolas Fraiman, Alexandra Kolla, Aditya Potukuchi, Corrine Yap</dc:creator>
    </item>
    <item>
      <title>Space-time Trade-offs for the LCP Array of Wheeler DFAs</title>
      <link>https://arxiv.org/abs/2306.05684</link>
      <description>arXiv:2306.05684v2 Announce Type: replace 
Abstract: Recently, Conte et al. generalized the longest-common prefix (LCP) array from strings to Wheeler DFAs, and they showed that it can be used to efficiently determine matching statistics on a Wheeler DFA [DCC 2023]. However, storing the LCP array requires $ O(n \log n) $ bits, $ n $ being the number of states, while the compact representation of Wheeler DFAs often requires much less space. In particular, the BOSS representation of a de Bruijn graph only requires a linear number of bits, if the size of alphabet is constant.
  In this paper, we propose a sampling technique that allows to access an entry of the LCP array in logarithmic time by only storing a linear number of bits. We use our technique to provide a space-time trade-off to compute matching statistics on a Wheeler DFA. In addition, we show that by augmenting the BOSS representation of a $ k $-th order de Bruijn graph with a linear number of bits we can navigate the underlying variable-order de Bruijn graph in time logarithmic in $ k $, thus improving a previous bound by Boucher et al. which was linear in $ k $ [DCC 2015].</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.05684v2</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Nicola Cotumaccio, Travis Gagie, Dominik K\"oppl, Nicola Prezza</dc:creator>
    </item>
    <item>
      <title>Sketching and Streaming for Dictionary Compression</title>
      <link>https://arxiv.org/abs/2310.17980</link>
      <description>arXiv:2310.17980v3 Announce Type: replace 
Abstract: We initiate the study of sub-linear sketching and streaming techniques for estimating the output size of common dictionary compressors such as Lempel-Ziv '77, the run-length Burrows-Wheeler transform, and grammar compression. To this end, we focus on a measure that has recently gained much attention in the information-theoretic community and which approximates up to a polylogarithmic multiplicative factor the output sizes of those compressors: the normalized substring complexity function $\delta$.
  We present a data sketch of $O(\epsilon^{-3}\log n + \epsilon^{-1}\log^2 n)$ words that allows computing a multiplicative $(1\pm \epsilon)$-approximation of $\delta$ with high probability, where $n$ is the string length. The sketches of two strings $S_1,S_2$ can be merged in $O(\epsilon^{-1}\log^2 n)$ time to yield the sketch of $\{S_1,S_2\}$, speeding up by orders of magnitude tasks such as the computation of all-pairs \emph{Normalized Compression Distances} (NCD). If random access is available on the input, our sketch can be updated in $O(\epsilon^{-1}\log^2 n)$ time for each character right-extension of the string. This yields a polylogarithmic-space algorithm for approximating $\delta$, improving exponentially over the working space of the state-of-the-art algorithms running in nearly-linear time. Motivated by the fact that random access is not always available on the input data, we then present a streaming algorithm computing our sketch in $O(\sqrt n \cdot \log n)$ working space and $O(\epsilon^{-1}\log^2 n)$ worst-case delay per character. We show that an implementation of our streaming algorithm can estimate {\delta} on a dataset of 189GB with a throughput of 203MB per minute while using only 5MB of RAM, and that our sketch speeds up the computation of all-pairs NCD distances by one order of magnitude, with applications to phylogenetic tree reconstruction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.17980v3</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ruben Becker, Matteo Canton, Davide Cenzato, Sung-Hwan Kim, Bojana Kodric, Nicola Prezza</dc:creator>
    </item>
    <item>
      <title>Improved Evolutionary Algorithms for Submodular Maximization with Cost Constraints</title>
      <link>https://arxiv.org/abs/2405.05942</link>
      <description>arXiv:2405.05942v2 Announce Type: replace 
Abstract: We present an evolutionary algorithm evo-SMC for the problem of Submodular Maximization under Cost constraints (SMC). Our algorithm achieves $1/2$-approximation with a high probability $1-1/n$ within $\mathcal{O}(n^2K_{\beta})$ iterations, where $K_{\beta}$ denotes the maximum size of a feasible solution set with cost constraint $\beta$. To the best of our knowledge, this is the best approximation guarantee offered by evolutionary algorithms for this problem. We further refine evo-SMC, and develop st-evo-SMC. This stochastic version yields a significantly faster algorithm while maintaining the approximation ratio of $1/2$, with probability $1-\epsilon$. The required number of iterations reduces to $\mathcal{O}(nK_{\beta}\log{(1/\epsilon)}/p)$, where the user defined parameters $p \in (0,1]$ represents the stochasticity probability, and $\epsilon \in (0,1]$ denotes the error threshold. Finally, the empirical evaluations carried out through extensive experimentation substantiate the efficiency and effectiveness of our proposed algorithms. Our algorithms consistently outperform existing methods, producing higher-quality solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.05942v2</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.24963/ijcai.2024/783</arxiv:DOI>
      <arxiv:journal_reference>Proceedings of the Thirty-Third International Joint Conference on Artificial Intelligence (IJCAI-2024)</arxiv:journal_reference>
      <dc:creator>Yanhui Zhu, Samik Basu, A Pavan</dc:creator>
    </item>
    <item>
      <title>Bijective BWT based compression schemes</title>
      <link>https://arxiv.org/abs/2406.16475</link>
      <description>arXiv:2406.16475v2 Announce Type: replace 
Abstract: We investigate properties of the bijective Burrows-Wheeler transform (BBWT). We show that for any string $w$, a bidirectional macro scheme of size $O(r_B)$ can be induced from the BBWT of $w$, where $r_B$ is the number of maximal character runs in the BBWT. We also show that $r_B = O(z\log^2 n)$, where $n$ is the length of $w$ and $z$ is the number of Lempel-Ziv 77 factors of $w$. Then, we show a separation between BBWT and BWT by a family of strings with $r_B = \Omega(\log n)$ but having only $r=2$ maximal character runs in the standard Burrows--Wheeler transform (BWT). However, we observe that the smallest $r_B$ among all cyclic rotations of $w$ is always at most $r$. While an $o(n^2)$ algorithm for computing an optimal rotation giving the smallest $r_B$ is still open, we show how to compute the Lyndon factorizations -- a component for computing BBWT -- of all cyclic rotations in $O(n)$ time. Furthermore, we conjecture that we can transform two strings having the same Parikh vector to each other by BBWT and rotation operations, and prove this conjecture for the case of binary alphabets and permutations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16475v2</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Golnaz Badkobeh, Hideo Bannai, Dominik K\"oppl</dc:creator>
    </item>
    <item>
      <title>Regularized Unconstrained Weakly Submodular Maximization</title>
      <link>https://arxiv.org/abs/2408.04620</link>
      <description>arXiv:2408.04620v2 Announce Type: replace 
Abstract: Submodular optimization finds applications in machine learning and data mining. In this paper, we study the problem of maximizing functions of the form $h = f-c$, where $f$ is a monotone, non-negative, weakly submodular set function and $c$ is a modular function. We design a deterministic approximation algorithm that runs with ${{O}}(\frac{n}{\epsilon}\log \frac{n}{\gamma \epsilon})$ oracle calls to function $h$, and outputs a set ${S}$ such that $h({S}) \geq \gamma(1-\epsilon)f(OPT)-c(OPT)-\frac{c(OPT)}{\gamma(1-\epsilon)}\log\frac{f(OPT)}{c(OPT)}$, where $\gamma$ is the submodularity ratio of $f$. Existing algorithms for this problem either admit a worse approximation ratio or have quadratic runtime. We also present an approximation ratio of our algorithm for this problem with an approximate oracle of $f$. We validate our theoretical results through extensive empirical evaluations on real-world applications, including vertex cover and influence diffusion problems for submodular utility function $f$, and Bayesian A-Optimal design for weakly submodular $f$. Our experimental results demonstrate that our algorithms efficiently achieve high-quality solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04620v2</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3627673.3679651</arxiv:DOI>
      <arxiv:journal_reference>Proceedings of the 33rd ACM International Conference on Information and Knowledge Management (CIKM 2024)</arxiv:journal_reference>
      <dc:creator>Yanhui Zhu, Samik Basu, A. Pavan</dc:creator>
    </item>
    <item>
      <title>Coupling without Communication and Drafter-Invariant Speculative Decoding</title>
      <link>https://arxiv.org/abs/2408.07978</link>
      <description>arXiv:2408.07978v2 Announce Type: replace 
Abstract: Suppose Alice has a distribution $P$ and Bob has a distribution $Q$. Alice wants to generate a sample $a\sim P$ and Bob a sample $b \sim Q$ such that $a = b$ with has as high of probability as possible. It is well-known that, by sampling from an optimal coupling between the distributions, Alice and Bob can achieve $Pr[a = b] = 1 - D_{TV}(P,Q)$, where $D_{TV}(P,Q)$ is the total variation distance. What if Alice and Bob must solve this same problem without communicating at all? Perhaps surprisingly, with access to public randomness, they can still achieve $Pr[a=b] \geq \frac{1-D_{TV}(P,Q)}{1+D_{TV}(P,Q)} \geq 1-2D_{TV}(P,Q)$. In fact, this bound can be obtained using a simple protocol based on the Weighted MinHash algorithm. In this work, we explore the communication-free coupling problem in greater depth. First, we show that an equally simple protocol based on Gumbel sampling matches the worst-case guarantees of the Weighted MinHash approach, but tends to perform better in practice. Conversely, we prove that both approaches are actually sharp: no communication-free protocol can achieve $Pr[a=b]&gt;\frac{1-D_{TV}(P,Q)}{1+D_{TV}(P,Q)}$ in the worst-case. Finally, we prove that, for distributions over $n$ items, there exists a scheme that uses just $O(\log(n/\epsilon))$ bits of communication to achieve $Pr[a = b] = 1 - D_{TV}(P,Q) - \epsilon$, i.e. to essentially match optimal coupling. Beyond our theoretical results, we demonstrate an application of communication-free coupling to speculative decoding, a recent method for accelerating autoregressive large language models [Leviathan, Kalman, Matias, ICML 2023]. We show that communication-free protocols yield a variant of speculative decoding that we call Drafter-Invariant Speculative Decoding, which has the desirable property that the output of the method is fixed given a fixed random seed, regardless of what drafter is used for speculation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07978v2</guid>
      <category>cs.DS</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Majid Daliri, Christopher Musco, Ananda Theertha Suresh</dc:creator>
    </item>
    <item>
      <title>Edge Multiway Cut and Node Multiway Cut are NP-complete on subcubic graphs</title>
      <link>https://arxiv.org/abs/2211.12203</link>
      <description>arXiv:2211.12203v3 Announce Type: replace-cross 
Abstract: We show that Edge Multiway Cut (also called Multiterminal Cut) and Node Multiway Cut are NP-complete on graphs of maximum degree $3$ (also known as subcubic graphs). This improves on a previous degree bound of $11$. Our NP-completeness result holds even for subcubic graphs that are planar.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.12203v3</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4230/LIPIcs.SWAT.2024.29</arxiv:DOI>
      <dc:creator>Matthew Johnson, Barnaby Martin, Siani Smith, Sukanya Pandey, Daniel Paulusma, Erik Jan van Leeuwen</dc:creator>
    </item>
    <item>
      <title>The Overlap Gap Property limits limit swapping in QAOA</title>
      <link>https://arxiv.org/abs/2404.06087</link>
      <description>arXiv:2404.06087v3 Announce Type: replace-cross 
Abstract: The Quantum Approximate Optimization Algorithm (QAOA) is a quantum algorithm designed for Combinatorial Optimization Problem (COP). We show that if a COP with an underlying Erd\"os--R\'enyi hypergraph exhibits the Overlap Gap Property (OGP), then a random regular hypergraph exhibits it as well. Given that Max-$q$-XORSAT on an Erd\"os--R\'enyi hypergraph is known to exhibit the OGP, and since the performance of QAOA for the pure $q$-spin model matches asymptotically for Max-$q$-XORSAT on large-girth regular hypergraph, we show that the average-case value obtained by QAOA for the pure $q$-spin model for even $q\ge 4$ is bounded away from optimality even when the algorithm runs indefinitely. This suggests that a necessary condition for the validity of limit swapping in QAOA is the absence of OGP in a given combinatorial optimization problem. Furthermore, the results suggests that even when sub-optimised, the performance of QAOA on spin glass is equal in performance to classical algorithms in solving the mean field spin glass problem providing further evidence that the conjecture of getting the exact solution under limit swapping for the Sherrington--Kirkpatrick model to be true.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06087v3</guid>
      <category>quant-ph</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.DS</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mark Xin Hong Goh</dc:creator>
    </item>
  </channel>
</rss>
