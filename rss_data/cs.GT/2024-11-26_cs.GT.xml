<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 27 Nov 2024 02:57:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Revenue Maximization in Choice-Based Matching Markets</title>
      <link>https://arxiv.org/abs/2411.15727</link>
      <description>arXiv:2411.15727v1 Announce Type: new 
Abstract: The primary contribution of this paper resides in devising constant-factor approximation guarantees for revenue maximization in two-sided matching markets, under general pairwise rewards. A major distinction between our work and state-of-the-art results in this context (Ashlagi et al., 2022; Torrico et al., 2023) is that, for the first time, we are able to address reward maximization, reflected by assigning each customer-supplier pair an arbitrarily-valued reward. The specific type of performance guarantees we attain depends on whether one considers the customized model or the inclusive model. The fundamental difference between these settings lies in whether the platform should display to each supplier all selecting customers, as in the inclusive model, or whether the platform can further personalize this set, as in the customized model. Technically speaking, our algorithmic approach and its analysis revolve around presenting novel linear relaxations, leveraging convex stochastic orders, employing approximate dynamic programming, and developing tailor-made analytical ideas. In both models considered, these ingredients allow us to overcome the lack of submodularity and subadditivity that stems from pairwise rewards, plaguing the applicability of existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15727v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Dan Nissim, Danny Segev, Alfredo Torrico</dc:creator>
    </item>
    <item>
      <title>Leakage-Robust Bayesian Persuasion</title>
      <link>https://arxiv.org/abs/2411.16624</link>
      <description>arXiv:2411.16624v1 Announce Type: new 
Abstract: We introduce the concept of leakage-robust Bayesian persuasion. Situated between public persuasion [KG11, CCG23, Xu20] and private persuasion [AB19], leakage-robust persuasion considers a setting where one or more signals privately sent by a sender to the receivers may be leaked. We study the design of leakage-robust persuasion schemes and quantify the price of robustness using two formalisms:
  - The first notion, $k$-worst-case persuasiveness, requires a scheme to remain persuasive as long as each receiver observes at most $k$ leaked signals. We quantify the Price of Worst-case Robustness (PoWR$_k$) -- i.e., the gap in sender's utility as compared to the optimal private scheme -- as $\Theta(\min\{2^k,n\})$ for supermodular sender utilities and $\Theta(k)$ for submodular or XOS utilities, where $n$ is the number of receivers. This result also establishes that in some instances, $\Theta(\log k)$ leakages are sufficient for the utility of the optimal leakage-robust persuasion to degenerate to that of public persuasion.
  - The second notion, expected downstream utility robustness, relaxes the persuasiveness and considers the impact on sender's utility when receivers best respond to their observations. By quantifying the Price of Downstream Robustness (PoDR) as the gap between the sender's expected utility over random leakage patterns as compared to private persuasion, we show that over several natural and structured distributions of leakage patterns, PoDR improves PoWR to $\Theta(k)$ or even $\Theta(1)$, where $k$ is the maximum number of leaked signals observable to each receiver across leakage patterns in the distribution.
  En route to these results, we show that subsampling and masking are general-purpose algorithmic paradigms for transforming private persuasion signaling schemes to leakage-robust ones, with minmax optimal loss in the sender's utility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16624v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <category>cs.MA</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nika Haghtalab, Mingda Qiao, Kunhe Yang</dc:creator>
    </item>
    <item>
      <title>Learning-Enabled Adaptive Voltage Protection Against Load Alteration Attacks On Smart Grids</title>
      <link>https://arxiv.org/abs/2411.15229</link>
      <description>arXiv:2411.15229v1 Announce Type: cross 
Abstract: Smart grids are designed to efficiently handle variable power demands, especially for large loads, by real-time monitoring, distributed generation and distribution of electricity. However, the grid's distributed nature and the internet connectivity of large loads like Heating Ventilation, and Air Conditioning (HVAC) systems introduce vulnerabilities in the system that cyber-attackers can exploit, potentially leading to grid instability and blackouts. Traditional protection strategies, primarily designed to handle transmission line faults are often inadequate against such threats, emphasising the need for enhanced grid security. In this work, we propose a Deep Reinforcement Learning (DRL)-based protection system that learns to differentiate any stealthy load alterations from normal grid operations and adaptively adjusts activation thresholds of the protection schemes. We train this adaptive protection scheme against an optimal and stealthy load alteration attack model that manipulates the power demands of HVACs at the most unstable grid buses to induce blackouts. We theoretically prove that the adaptive protection system trained in this competitive game setting can effectively mitigate any stealthy load alteration-based attack. To corroborate this, we also demonstrate the method's success in several real-world grid scenarios by implementing it in a hardware-in-loop setup.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15229v1</guid>
      <category>eess.SY</category>
      <category>cs.CR</category>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anjana B., Suman Maiti, Sunandan Adhikary, Soumyajit Dey, Ashish R. Hota</dc:creator>
    </item>
    <item>
      <title>Imperfect-Information Games on Quantum Computers: A Case Study in Skat</title>
      <link>https://arxiv.org/abs/2411.15294</link>
      <description>arXiv:2411.15294v1 Announce Type: cross 
Abstract: For decades it is known that Quantum Computers might serve as a tool to solve a very specific kind of problems that have long thought to be incalculable. Some of those problems are of a combinatorial nature, with the quantum advantage arising from the exploding size of a huge decision tree. Although this is of high interest as well, there are more opportunities to make use of the quantum advantage among non-perfect information games with a limited amount of steps within the game. Even though it is not possible to answer the question for the winning move in a specific situation, people are rather interested in what choice gives the best outcome in the long run. This leads us to the search for the highest number of paths within the game's decision tree despite the lack of information and, thus, to a maximum of the payoff-function. We want to illustrate on how Quantum Computers can play a significant role in solving these kind of games, using an example of the most popular German card game Skat. Therefore we use quantum registers to encode the game's information properly and construct the corresponding quantum gates in order to model the game progress and obey the rules. Finally, we use a score operator to project the quantum state onto the winning subspace and therefore evaluate the winning probability for each alternative decision by the player to be made by using quantum algorithms, such as quantum counting of the winning paths to gain a possible advantage in computation speed over classical approaches. Thus, we get a reasonable recommendation of how to act at the table due to the payoff-function maximization. This approach is clearly not doable on a classical computer due to the huge tree-search problem and we discuss peculiarities of the problem that may lead to a quantum advantage when exceeding a certain problem size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15294v1</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <category>cs.GT</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Erik Schulze, Ulrich Armbr\"uster, Gabriel Maresch, Stefan Edelkamp</dc:creator>
    </item>
    <item>
      <title>Naive Algorithmic Collusion: When Do Bandit Learners Cooperate and When Do They Compete?</title>
      <link>https://arxiv.org/abs/2411.16574</link>
      <description>arXiv:2411.16574v1 Announce Type: cross 
Abstract: Algorithmic agents are used in a variety of competitive decision settings, notably in making pricing decisions in contexts that range from online retail to residential home rentals. Business managers, algorithm designers, legal scholars, and regulators alike are all starting to consider the ramifications of "algorithmic collusion." We study the emergent behavior of multi-armed bandit machine learning algorithms used in situations where agents are competing, but they have no information about the strategic interaction they are engaged in. Using a general-form repeated Prisoner's Dilemma game, agents engage in online learning with no prior model of game structure and no knowledge of competitors' states or actions (e.g., no observation of competing prices). We show that these context-free bandits, with no knowledge of opponents' choices or outcomes, still will consistently learn collusive behavior - what we call "naive collusion." We primarily study this system through an analytical model and examine perturbations to the model through simulations.
  Our findings have several notable implications for regulators. First, calls to limit algorithms from conditioning on competitors' prices are insufficient to prevent algorithmic collusion. This is a direct result of collusion arising even in the naive setting. Second, symmetry in algorithms can increase collusion potential. This highlights a new, simple mechanism for "hub-and-spoke" algorithmic collusion. A central distributor need not imbue its algorithm with supra-competitive tendencies for apparent collusion to arise; it can simply arise by using certain (common) machine learning algorithms. Finally, we highlight that collusive outcomes depend starkly on the specific algorithm being used, and we highlight market and algorithmic conditions under which it will be unknown a priori whether collusion occurs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16574v1</guid>
      <category>econ.GN</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Connor Douglas, Foster Provost, Arun Sundararajan</dc:creator>
    </item>
    <item>
      <title>Decidability of One-Clock Weighted Timed Games with Arbitrary Weights</title>
      <link>https://arxiv.org/abs/2207.01608</link>
      <description>arXiv:2207.01608v4 Announce Type: replace 
Abstract: Weighted Timed Games (WTG for short) are the most widely used model to describe controller synthesis problems involving real-time issues. Unfortunately, they are notoriously difficult, and undecidable in general. As a consequence, one-clock WTGs have attracted a lot of attention, especially because they are known to be decidable when only non-negative weights are allowed. However, when arbitrary weights are considered, despite several recent works, their decidability status was still unknown. In this paper, we solve this problem positively and show that the value function can be computed in exponential time (if weights are encoded in unary).</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.01608v4</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Benjamin Monmege, Julie Parreaux, Pierre-Alain Reynier</dc:creator>
    </item>
    <item>
      <title>Autobidders with Budget and ROI Constraints: Efficiency, Regret, and Pacing Dynamics</title>
      <link>https://arxiv.org/abs/2301.13306</link>
      <description>arXiv:2301.13306v5 Announce Type: replace 
Abstract: We study a game between autobidding algorithms that compete in an online advertising platform. Each autobidder is tasked with maximizing its advertiser's total value over multiple rounds of a repeated auction, subject to budget and return-on-investment constraints. We propose a gradient-based learning algorithm that is guaranteed to satisfy all constraints and achieves vanishing individual regret. Our algorithm uses only bandit feedback and can be used with the first- or second-price auction, as well as with any "intermediate" auction format. Our main result is that when these autobidders play against each other, the resulting expected liquid welfare over all rounds is at least half of the expected optimal liquid welfare achieved by any allocation. This holds whether or not the bidding dynamics converges to an equilibrium.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.13306v5</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Brendan Lucier, Sarath Pattathil, Aleksandrs Slivkins, Mengxiao Zhang</dc:creator>
    </item>
    <item>
      <title>Understanding Model Selection For Learning In Strategic Environments</title>
      <link>https://arxiv.org/abs/2402.07588</link>
      <description>arXiv:2402.07588v4 Announce Type: replace 
Abstract: The deployment of ever-larger machine learning models reflects a growing consensus that the more expressive the model class one optimizes over$\unicode{x2013}$and the more data one has access to$\unicode{x2013}$the more one can improve performance. As models get deployed in a variety of real-world scenarios, they inevitably face strategic environments. In this work, we consider the natural question of how the interplay of models and strategic interactions affects the relationship between performance at equilibrium and the expressivity of model classes. We find that strategic interactions can break the conventional view$\unicode{x2013}$meaning that performance does not necessarily monotonically improve as model classes get larger or more expressive (even with infinite data). We show the implications of this result in several contexts including strategic regression, strategic classification, and multi-agent reinforcement learning. In particular, we show that each of these settings admits a Braess' paradox-like phenomenon in which optimizing over less expressive model classes allows one to achieve strictly better equilibrium outcomes. Motivated by these examples, we then propose a new paradigm for model selection in games wherein an agent seeks to choose amongst different model classes to use as their action set in a game.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.07588v4</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tinashe Handina, Eric Mazumdar</dc:creator>
    </item>
    <item>
      <title>Generalized Principal-Agent Problem with a Learning Agent</title>
      <link>https://arxiv.org/abs/2402.09721</link>
      <description>arXiv:2402.09721v5 Announce Type: replace 
Abstract: Classic principal-agent problems such as Stackelberg games, contract design, and Bayesian persuasion, often assume that the agent is able to best respond to the principal's committed strategy. We study repeated generalized principal-agent problems under the assumption that the principal does not have commitment power and the agent uses algorithms to learn to respond to the principal. We reduce this problem to a one-shot generalized principal-agent problem where the agent approximately best responds. Using this reduction, we show that: (1) If the agent uses contextual no-regret learning algorithms with regret $\mathrm{Reg}(T)$, then the principal can guarantee utility at least $U^* - \Theta\big(\sqrt{\tfrac{\mathrm{Reg}(T)}{T}}\big)$, where $U^*$ is the principal's optimal utility in the classic model with a best-responding agent. (2) If the agent uses contextual no-swap-regret learning algorithms with swap-regret $\mathrm{SReg}(T)$, then the principal cannot obtain utility more than $U^* + O(\frac{\mathrm{SReg(T)}}{T})$. But (3) if the agent uses mean-based learning algorithms (which can be no-regret but not no-swap-regret), then the principal can sometimes do significantly better than $U^*$. These results not only refine previous results in Stackelberg games and contract design, but also lead to new results for Bayesian persuasion with a learning agent and all generalized principal-agent problems where the agent does not have private information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.09721v5</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>econ.TH</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tao Lin, Yiling Chen</dc:creator>
    </item>
    <item>
      <title>Equitable Core Imputations via a New Adaptation of The Primal-Dual Framework</title>
      <link>https://arxiv.org/abs/2402.11437</link>
      <description>arXiv:2402.11437v3 Announce Type: replace 
Abstract: The classic paper of Shapley and Shubik \cite{Shapley1971assignment} characterized the core of the assignment game. We observe that a sub-coalition consisting of one player (or a set of players from the same side of the bipartition) can make zero profit, and therefore its profit under a core imputation can be an arbitrary amount. Hence an arbitrary core imputation makes {\em no fairness guarantee at the level of individual agents}. Can this deficiency be addressed by picking a ``good'' core imputation?
  To arrive at an appropriate solution concept, we give specific criteria for picking a special core imputation, and we undertake a detailed comparison of four solution concepts. Leximin and leximax core imputations come out as clear winners; we define these to be {\em equitable core imputations}. These imputations achieve ``fairness'' in different ways: whereas leximin tries to make poor agents more rich, leximax tries to make rich agents less rich.
  We give combinatorial strongly polynomial algorithms for computing these imputations via a novel adaptation of the classical primal-dual paradigm. The ``engine'' driving them involves insights into core imputations obtained via complementarity. It will not be surprising if our work leads to new uses of this powerful technique. Furthermore, we expect more work on computing the leximin and leximax core imputations of other natural games, in addition to the recent follow-up work \cite{Leximin-max}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.11437v3</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vijay V. Vazirani</dc:creator>
    </item>
    <item>
      <title>A Simplified Analysis of the Ascending Auction to Sell a Matroid Base</title>
      <link>https://arxiv.org/abs/2404.12121</link>
      <description>arXiv:2404.12121v2 Announce Type: replace 
Abstract: We give a simpler analysis of the ascending auction of Bikhchandani, de Vries, Schummer, and Vohra to sell a welfare-maximizing base of a matroid at Vickrey prices. The new proofs for economic efficiency and the charge of Vickrey prices only require a few matroid folklore theorems, therefore shortening the analysis of the design goals of the auction significantly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12121v2</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Britta Peis, Niklas Rieken</dc:creator>
    </item>
    <item>
      <title>GPU-Accelerated Counterfactual Regret Minimization</title>
      <link>https://arxiv.org/abs/2408.14778</link>
      <description>arXiv:2408.14778v4 Announce Type: replace 
Abstract: Counterfactual regret minimization is a family of algorithms of no-regret learning dynamics capable of solving large-scale imperfect information games. We propose implementing this algorithm as a series of dense and sparse matrix and vector operations, thereby making it highly parallelizable for a graphical processing unit, at a cost of higher memory usage. Our experiments show that our implementation performs up to about 244.5 times faster than OpenSpiel's Python implementation and, on an expanded set of games, up to about 114.2 times faster than OpenSpiel's C++ implementation and the speedup becomes more pronounced as the size of the game being solved grows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.14778v4</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Juho Kim</dc:creator>
    </item>
    <item>
      <title>A Stable-Set Bound and Maximal Numbers of Nash Equilibria in Bimatrix Games</title>
      <link>https://arxiv.org/abs/2411.12385</link>
      <description>arXiv:2411.12385v2 Announce Type: replace 
Abstract: Quint and Shubik (1997) conjectured that a non-degenerate n-by-n game has at most 2^n-1 Nash equilibria in mixed strategies. The conjecture is true for n at most 4 but false for n=6 or larger. We answer it positively for the remaining case n=5, which had been open since 1999. The problem can be translated to a combinatorial question about the vertices of a pair of simple n-polytopes with 2n facets. We introduce a novel obstruction based on the index of an equilibrium, which states that equilibrium vertices belong to two equal-sized disjoint stable sets of the graph of the polytope. This bound is verified directly using the known classification of the 159,375 combinatorial types of dual neighborly polytopes in dimension 5 with 10 facets. Non-neighborly polytopes are analyzed with additional combinatorial techniques where the bound is used for their disjoint facets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12385v2</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Constantin Ickstadt, Thorsten Theobald, Bernhard von Stengel</dc:creator>
    </item>
    <item>
      <title>Constant Inapproximability for PPA</title>
      <link>https://arxiv.org/abs/2201.10011</link>
      <description>arXiv:2201.10011v2 Announce Type: replace-cross 
Abstract: In the $\varepsilon$-Consensus-Halving problem, we are given $n$ probability measures $v_1, \dots, v_n$ on the interval $R = [0,1]$, and the goal is to partition $R$ into two parts $R^+$ and $R^-$ using at most $n$ cuts, so that $|v_i(R^+) - v_i(R^-)| \leq \varepsilon$ for all $i$. This fundamental fair division problem was the first natural problem shown to be complete for the class PPA, and all subsequent PPA-completeness results for other natural problems have been obtained by reducing from it.
  We show that $\varepsilon$-Consensus-Halving is PPA-complete even when the parameter $\varepsilon$ is a constant. In fact, we prove that this holds for any constant $\varepsilon &lt; 1/5$. As a result, we obtain constant inapproximability results for all known natural PPA-complete problems, including Necklace-Splitting, the Discrete-Ham-Sandwich problem, two variants of the pizza sharing problem, and for finding fair independent sets in cycles and paths.</description>
      <guid isPermaLink="false">oai:arXiv.org:2201.10011v2</guid>
      <category>cs.CC</category>
      <category>cs.GT</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Argyrios Deligkas, John Fearnley, Alexandros Hollender, Themistoklis Melissourgos</dc:creator>
    </item>
    <item>
      <title>Game-Theoretic Neyman-Pearson Detection to Combat Strategic Evasion</title>
      <link>https://arxiv.org/abs/2206.05276</link>
      <description>arXiv:2206.05276v4 Announce Type: replace-cross 
Abstract: The security in networked systems depends greatly on recognizing and identifying adversarial behaviors. Traditional detection methods focus on specific categories of attacks and have become inadequate for increasingly stealthy and deceptive attacks that are designed to bypass detection strategically. This work aims to develop a holistic theory to countermeasure such evasive attacks. We focus on extending a fundamental class of statistical-based detection methods based on Neyman-Pearson's (NP) hypothesis testing formulation. We propose game-theoretic frameworks to capture the conflicting relationship between a strategic evasive attacker and an evasion-aware NP detector. By analyzing both the equilibrium behaviors of the attacker and the NP detector, we characterize their performance using Equilibrium Receiver-Operational-Characteristic (EROC) curves. We show that the evasion-aware NP detectors outperform the passive ones in the way that the former can act strategically against the attacker's behavior and adaptively modify their decision rules based on the received messages. In addition, we extend our framework to a sequential setting where the user sends out identically distributed messages. We corroborate the analytical results with a case study of anomaly detection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.05276v4</guid>
      <category>cs.CR</category>
      <category>cs.GT</category>
      <category>cs.IT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yinan Hu, Juntao Chen, Quanyan Zhu</dc:creator>
    </item>
    <item>
      <title>Structural and Algorithmic Results for Stable Cycles and Partitions in the Roommates Problem</title>
      <link>https://arxiv.org/abs/2406.00437</link>
      <description>arXiv:2406.00437v3 Announce Type: replace-cross 
Abstract: In the Stable Roommates problem, we seek a stable matching of the agents into pairs, in which no two agents have an incentive to deviate from their assignment. It is well known that a stable matching is unlikely to exist, but a stable partition always does and provides a succinct certificate for the unsolvability of an instance. Furthermore, apart from being a useful structural tool to study the problem, every stable partition corresponds to a stable half-matching, which has applications, for example, in sports scheduling and time-sharing.
  We establish new structural results for stable partitions and show how to enumerate all stable partitions and the cycles included in such structures efficiently. We also adapt optimality criteria from stable matchings to stable partitions and give complexity and approximability results for the problems of computing such "fair" and "optimal" stable partitions.
  Through this research, we contribute to a deeper understanding of stable partitions from a combinatorial point of view, as well as the computational complexity of computing "fair" or "optimal" stable half-matchings in practice, closing the gap between integral and fractional stable matchings and paving the way for further applications of stable partitions to unsolvable instances and computationally hard stable matching problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00437v3</guid>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Frederik Glitzner, David Manlove</dc:creator>
    </item>
    <item>
      <title>Incentivizing Information Acquisition</title>
      <link>https://arxiv.org/abs/2410.13978</link>
      <description>arXiv:2410.13978v2 Announce Type: replace-cross 
Abstract: I study a principal-agent model in which a principal hires an agent to collect information about an unknown continuous state. The agent acquires a signal whose distribution is centered around the state, controlling the signal's precision at a cost. The principal observes neither the precision nor the signal, but rather, using transfers that can depend on the state, incentivizes the agent to choose high precision and report the signal truthfully. I identify a sufficient and necessary condition on the agent's information structure which ensures that there exists an optimal transfer with a simple cutoff structure: the agent receives a fixed prize when his prediction is close enough to the state and receives nothing otherwise. This condition is mild and applies to all signal distributions commonly used in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13978v2</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fan Wu</dc:creator>
    </item>
  </channel>
</rss>
