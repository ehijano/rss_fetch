<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.BM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.BM</link>
    <description>q-bio.BM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.BM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 22 Oct 2024 04:03:52 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Proteins with alternative folds reveal blind spots in AlphaFold-based protein structure prediction</title>
      <link>https://arxiv.org/abs/2410.14898</link>
      <description>arXiv:2410.14898v1 Announce Type: new 
Abstract: In recent years, advances in artificial intelligence (AI) have transformed structural biology, particularly protein structure prediction. Though AI-based methods, such as AlphaFold (AF), often predict single conformations of proteins with high accuracy and confidence, predictions of alternative folds are often inaccurate, low-confidence, or simply not predicted at all. Here, we review three blind spots that alternative conformations reveal about AF-based protein structure prediction. First, proteins that assume conformations distinct from their training-set homologs can be mispredicted. Second, AF overrelies on its training set to predict alternative conformations. Third, degeneracies in pairwise representations can lead to high-confidence predictions inconsistent with experiment. These weaknesses suggest approaches to predict alternative folds more reliably.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14898v1</guid>
      <category>q-bio.BM</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Devlina Chakravarty, Myeongsang Lee, Lauren L. Porter</dc:creator>
    </item>
    <item>
      <title>Mimicking the Gas-Phase to Transport Odorants through the Nasal Mucus: Functional Insights into Odorant Binding Proteins</title>
      <link>https://arxiv.org/abs/2410.15141</link>
      <description>arXiv:2410.15141v1 Announce Type: new 
Abstract: Mammalian odorant binding proteins (OBPs) have long been suggested to transport hydrophobic odorant molecules through the aqueous environment of the nasal mucus. While the function of OBPs as odorant transporters is supported by their hydrophobic beta-barrel structure, no rationale has been provided on why and how these proteins facilitate the uptake of odorants from the gas phase. Here, a multi-scale computational approach validated through available high-resolution spectroscopy experiments reveals that the conformational space explored by carvone inside the binding cavity of porcine OBP (pOBP) is much closer to the gas than the aqueous phase, and that pOBP effectively manages to transport odorants by lowering the free energy barrier of odorant uptake. Understanding such perireceptor events is crucial to fully unravel the molecular processes underlying the olfactory sense, and move towards the development of protein-based biomimetic sensor units that can serve as artificial noses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15141v1</guid>
      <category>q-bio.BM</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Massimiliano Paesani, Arthur G. Goetzee, Sanne Abeln, Halima Mouhib</dc:creator>
    </item>
    <item>
      <title>Optimizing adaptive sampling via Policy Ranking</title>
      <link>https://arxiv.org/abs/2410.15259</link>
      <description>arXiv:2410.15259v1 Announce Type: new 
Abstract: Efficient sampling in biomolecular simulations is critical for accurately capturing the complex dynamical behaviors of biological systems. Adaptive sampling techniques aim to improve efficiency by focusing computational resources on the most relevant regions of phase space. In this work, we present a framework for identifying the optimal sampling policy through metric driven ranking. Our approach systematically evaluates the policy ensemble and ranks the policies based on their ability to explore the conformational space effectively. Through a series of biomolecular simulation case studies, we demonstrate that choice of a different adaptive sampling policy at each round significantly outperforms single policy sampling, leading to faster convergence and improved sampling performance. This approach takes an ensemble of adaptive sampling policies and identifies the optimal policy for the next round based on current data. Beyond presenting this ensemble view of adaptive sampling, we also propose two sampling algorithms that approximate this ranking framework on the fly. The modularity of this framework allows incorporation of any adaptive sampling policy making it versatile and suitable as a comprehensive adaptive sampling scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15259v1</guid>
      <category>q-bio.BM</category>
      <category>physics.bio-ph</category>
      <category>physics.chem-ph</category>
      <category>stat.ML</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hassan Nadeem, Diwakar Shukla</dc:creator>
    </item>
    <item>
      <title>CPE-Pro: A Structure-Sensitive Deep Learning Model for Protein Representation and Origin Evaluation</title>
      <link>https://arxiv.org/abs/2410.15592</link>
      <description>arXiv:2410.15592v1 Announce Type: new 
Abstract: Protein structures are important for understanding their functions and interactions. Currently, many protein structure prediction methods are enriching the structure database. Discriminating the origin of structures is crucial for distinguishing between experimentally resolved and computationally predicted structures, evaluating the reliability of prediction methods, and guiding downstream biological studies. Building on works in structure prediction, We developed a structure-sensitive supervised deep learning model, Crystal vs Predicted Evaluator for Protein Structure (CPE-Pro), to represent and discriminate the origin of protein structures. CPE-Pro learns the structural information of proteins and captures inter-structural differences to achieve accurate traceability on four data classes, and is expected to be extended to more. Simultaneously, we utilized Foldseek to encode protein structures into "structure-sequence" and trained a protein Structural Sequence Language Model, SSLM. Preliminary experiments demonstrated that, compared to large-scale protein language models pre-trained on vast amounts of amino acid sequences, the "structure-sequences" enable the language model to learn more informative protein features, enhancing and optimizing structural representations. We have provided the code, model weights, and all related materials on https://github.com/GouWenrui/CPE-Pro-main.git.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15592v1</guid>
      <category>q-bio.BM</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenrui Gou, Wenhui Ge,  YangTan, Guisheng Fan, Mingchen Li, Huiqun Yu</dc:creator>
    </item>
    <item>
      <title>Machine learning methods to study disordered proteins</title>
      <link>https://arxiv.org/abs/2410.15940</link>
      <description>arXiv:2410.15940v1 Announce Type: new 
Abstract: Recent years have seen tremendous developments in the use of machine learning models to link amino acid sequence, structure and function of folded proteins. These methods are, however, rarely applicable to the wide range of proteins and sequences that comprise intrinsically disordered regions. We here review developments in the study of disordered proteins that exploit or are used to train machine learning models. These include methods for generating conformational ensembles and designing new sequences, and for linking sequences to biophysical properties and biological functions. We highlight how these developments are built on a tight integration between experiment, theory and simulations, and account for evolutionary constraints, which operate on sequences of disordered regions differently than on those of folded domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15940v1</guid>
      <category>q-bio.BM</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>S\"oren von B\"ulow, Giulio Tesei, Kresten Lindorff-Larsen</dc:creator>
    </item>
    <item>
      <title>Characterizing RNA oligomers using Stochastic Titration Constant-pH Metadynamics simulations</title>
      <link>https://arxiv.org/abs/2410.16064</link>
      <description>arXiv:2410.16064v1 Announce Type: new 
Abstract: RNA molecules exhibit various biological functions intrinsically dependent on their diverse ecosystem of highly flexible structures. This flexibility arises from complex hydrogen-bonding networks defined by canonical and non-canonical base pairs that require protonation events to stabilize or perturb these interactions. Constant pH molecular dynamics (CpHMD) methods provide a reliable framework to explore the conformational and protonation space of dynamic structures and for robust calculations of pH-dependent properties, such as the pK$_\mathrm{a}$ of titrable sites. Despite growing biological evidence concerning pH regulation of certain motifs and in biotechnological applications, pH-sensitive in silico methods have rarely been applied to nucleic acids. In this work, we extended the stochastic titration CpHMD method to include RNA parameters from the standard $\chi$OL3 AMBER force field and highlighted its capability to depict titration events of nucleotides in single-stranded RNAs. We validated the method using trimers and pentamers with a single central titrable site while integrating a well-tempered metadynamics approach into the st-CpHMD methodology (CpH-MetaD) using PLUMED. This approach enhanced the convergence of the conformational landscape and enabled more efficient sampling of protonation-conformation coupling. Our pK$_\mathrm{a}$ estimates agree with experimental data, validating the method's ability to reproduce electrostatic changes around a titrable nucleobase in single-stranded RNA. These findings provided molecular insight into intramolecular phenomena, such as nucleobase stacking and phosphate interactions, that dictate the experimentally observed pK$_\mathrm{a}$ shifts between different strands. Overall, this work validates both the st-CpHMD and the metadynamics integration as reliable tools for studying biologically relevant RNA systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16064v1</guid>
      <category>q-bio.BM</category>
      <category>physics.bio-ph</category>
      <category>physics.chem-ph</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tomas F. D. Silva, Giovanni Bussi</dc:creator>
    </item>
    <item>
      <title>REBIND: Enhancing ground-state molecular conformation via force-based graph rewiring</title>
      <link>https://arxiv.org/abs/2410.14696</link>
      <description>arXiv:2410.14696v1 Announce Type: cross 
Abstract: Predicting the ground-state 3D molecular conformations from 2D molecular graphs is critical in computational chemistry due to its profound impact on molecular properties. Deep learning (DL) approaches have recently emerged as promising alternatives to computationally-heavy classical methods such as density functional theory (DFT). However, we discover that existing DL methods inadequately model inter-atomic forces, particularly for non-bonded atomic pairs, due to their naive usage of bonds and pairwise distances. Consequently, significant prediction errors occur for atoms with low degree (i.e., low coordination numbers) whose conformations are primarily influenced by non-bonded interactions. To address this, we propose REBIND, a novel framework that rewires molecular graphs by adding edges based on the Lennard-Jones potential to capture non-bonded interactions for low-degree atoms. Experimental results demonstrate that REBIND significantly outperforms state-of-the-art methods across various molecular sizes, achieving up to a 20\% reduction in prediction error.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14696v1</guid>
      <category>physics.chem-ph</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>q-bio.BM</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Taewon Kim, Hyunjin Seo, Sungsoo Ahn, Eunho Yang</dc:creator>
    </item>
    <item>
      <title>A Transformer Based Generative Chemical Language AI Model for Structural Elucidation of Organic Compounds</title>
      <link>https://arxiv.org/abs/2410.14719</link>
      <description>arXiv:2410.14719v1 Announce Type: cross 
Abstract: For over half a century, computer-aided structural elucidation systems (CASE) for organic compounds have relied on complex expert systems with explicitly programmed algorithms. These systems are often computationally inefficient for complex compounds due to the vast chemical structural space that must be explored and filtered. In this study, we present a transformer based generative chemical language artificial intelligence (AI) model, an innovative end-to-end architecture designed to replace the logic and workflow of the classic CASE framework for ultra-fast and accurate spectroscopic-based structural elucidation. Our model employs an encoder-decoder architecture and self-attention mechanisms, similar to those in large language models, to directly generate the most probable chemical structures that match the input spectroscopic data. This approach demonstrates the potential of transformer based generative AI to accelerate traditional scientific problem-solving processes. The model's ability to iterate quickly based on new data highlights its potential for rapid advancements in structural elucidation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14719v1</guid>
      <category>physics.chem-ph</category>
      <category>cs.LG</category>
      <category>physics.comp-ph</category>
      <category>q-bio.BM</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Xiaofeng Tan</dc:creator>
    </item>
    <item>
      <title>DEL-Ranking: Ranking-Correction Denoising Framework for Elucidating Molecular Affinities in DNA-Encoded Libraries</title>
      <link>https://arxiv.org/abs/2410.14946</link>
      <description>arXiv:2410.14946v1 Announce Type: cross 
Abstract: DNA-encoded library (DEL) screening has revolutionized the detection of protein-ligand interactions through read counts, enabling rapid exploration of vast chemical spaces. However, noise in read counts, stemming from nonspecific interactions, can mislead this exploration process. We present DEL-Ranking, a novel distribution-correction denoising framework that addresses these challenges. Our approach introduces two key innovations: (1) a novel ranking loss that rectifies relative magnitude relationships between read counts, enabling the learning of causal features determining activity levels, and (2) an iterative algorithm employing self-training and consistency loss to establish model coherence between activity label and read count predictions. Furthermore, we contribute three new DEL screening datasets, the first to comprehensively include multi-dimensional molecular representations, protein-ligand enrichment values, and their activity labels. These datasets mitigate data scarcity issues in AI-driven DEL screening research. Rigorous evaluation on diverse DEL datasets demonstrates DEL-Ranking's superior performance across multiple correlation metrics, with significant improvements in binding affinity prediction accuracy. Our model exhibits zero-shot generalization ability across different protein targets and successfully identifies potential motifs determining compound binding affinity. This work advances DEL screening analysis and provides valuable resources for future research in this area.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14946v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>q-bio.BM</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hanqun Cao, Chunbin Gu, Mutian He, Ning Ma, Chang-yu Hsieh, Pheng-Ann Heng</dc:creator>
    </item>
    <item>
      <title>Explaining Graph Neural Networks with Large Language Models: A Counterfactual Perspective for Molecular Property Prediction</title>
      <link>https://arxiv.org/abs/2410.15165</link>
      <description>arXiv:2410.15165v1 Announce Type: cross 
Abstract: In recent years, Graph Neural Networks (GNNs) have become successful in molecular property prediction tasks such as toxicity analysis. However, due to the black-box nature of GNNs, their outputs can be concerning in high-stakes decision-making scenarios, e.g., drug discovery. Facing such an issue, Graph Counterfactual Explanation (GCE) has emerged as a promising approach to improve GNN transparency. However, current GCE methods usually fail to take domain-specific knowledge into consideration, which can result in outputs that are not easily comprehensible by humans. To address this challenge, we propose a novel GCE method, LLM-GCE, to unleash the power of large language models (LLMs) in explaining GNNs for molecular property prediction. Specifically, we utilize an autoencoder to generate the counterfactual graph topology from a set of counterfactual text pairs (CTPs) based on an input graph. Meanwhile, we also incorporate a CTP dynamic feedback module to mitigate LLM hallucination, which provides intermediate feedback derived from the generated counterfactuals as an attempt to give more faithful guidance. Extensive experiments demonstrate the superior performance of LLM-GCE. Our code is released on https://github.com/YinhanHe123/new\_LLM4GNNExplanation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15165v1</guid>
      <category>cs.LG</category>
      <category>cs.CL</category>
      <category>q-bio.BM</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>EMNLP 2024 (Findings)</arxiv:journal_reference>
      <dc:creator>Yinhan He, Zaiyi Zheng, Patrick Soga, Yaozhen Zhu, yushun Dong, Jundong Li</dc:creator>
    </item>
    <item>
      <title>Simulation-based inference of single-molecule experiments</title>
      <link>https://arxiv.org/abs/2410.15896</link>
      <description>arXiv:2410.15896v1 Announce Type: cross 
Abstract: Single-molecule experiments are a unique tool to characterize the structural dynamics of biomolecules. However, reconstructing molecular details from noisy single-molecule data is challenging. Simulation-based inference (SBI) integrates statistical inference, physics-based simulators, and machine learning and is emerging as a powerful framework for analysing complex experimental data. Recent advances in deep learning have accelerated the development of new SBI methods, enabling the application of Bayesian inference to an ever-increasing number of scientific problems. Here, we review the nascent application of SBI to the analysis of single-molecule experiments. We introduce parametric Bayesian inference and discuss its limitations. We then overview emerging deep-learning-based SBI methods to perform Bayesian inference for complex models encoded in computer simulators. We illustrate the first applications of SBI to single-molecule force-spectroscopy and cryo-electron microscopy experiments. SBI allows us to leverage powerful computer algorithms modeling complex biomolecular phenomena to connect scientific models and experiments in a principled way.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15896v1</guid>
      <category>physics.chem-ph</category>
      <category>q-bio.BM</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Lars Dingeldein, Pilar Cossio, Roberto Covino</dc:creator>
    </item>
    <item>
      <title>Comprehensive benchmarking of large language models for RNA secondary structure prediction</title>
      <link>https://arxiv.org/abs/2410.16212</link>
      <description>arXiv:2410.16212v1 Announce Type: cross 
Abstract: Inspired by the success of large language models (LLM) for DNA and proteins, several LLM for RNA have been developed recently. RNA-LLM uses large datasets of RNA sequences to learn, in a self-supervised way, how to represent each RNA base with a semantically rich numerical vector. This is done under the hypothesis that obtaining high-quality RNA representations can enhance data-costly downstream tasks. Among them, predicting the secondary structure is a fundamental task for uncovering RNA functional mechanisms. In this work we present a comprehensive experimental analysis of several pre-trained RNA-LLM, comparing them for the RNA secondary structure prediction task in an unified deep learning framework. The RNA-LLM were assessed with increasing generalization difficulty on benchmark datasets. Results showed that two LLM clearly outperform the other models, and revealed significant challenges for generalization in low-homology scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16212v1</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>q-bio.BM</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>L. I. Zablocki, L. A. Bugnon, M. Gerard, L. Di Persia, G. Stegmayer, D. H. Milone</dc:creator>
    </item>
    <item>
      <title>Geometric Self-Supervised Pretraining on 3D Protein Structures using Subgraphs</title>
      <link>https://arxiv.org/abs/2406.14142</link>
      <description>arXiv:2406.14142v3 Announce Type: replace-cross 
Abstract: Protein representation learning aims to learn informative protein embeddings capable of addressing crucial biological questions, such as protein function prediction. Although sequence-based transformer models have shown promising results by leveraging the vast amount of protein sequence data in a self-supervised way, there is still a gap in exploiting the available 3D protein structures. In this work, we propose a pre-training scheme going beyond trivial masking methods leveraging 3D and hierarchical structures of proteins. We propose a novel self-supervised method to pretrain 3D graph neural networks on 3D protein structures, by predicting the distances between local geometric centroids of protein subgraphs and the global geometric centroid of the protein. By considering subgraphs and their relationships to the global protein structure, our model can better learn the geometric properties of the protein structure. We experimentally show that our proposed pertaining strategy leads to significant improvements up to 6\%, in the performance of 3D GNNs in various protein classification tasks. Our work opens new possibilities in unsupervised learning for protein graph models while eliminating the need for multiple views, augmentations, or masking strategies which are currently used so far.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14142v3</guid>
      <category>q-bio.QM</category>
      <category>cs.LG</category>
      <category>q-bio.BM</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Michail Chatzianastasis, Yang Zhang, George Dasoulas, Michalis Vazirgiannis</dc:creator>
    </item>
  </channel>
</rss>
