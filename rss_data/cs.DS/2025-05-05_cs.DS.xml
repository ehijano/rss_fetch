<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 06 May 2025 04:00:03 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A Matrix Product State Representation of Boolean Functions</title>
      <link>https://arxiv.org/abs/2505.01930</link>
      <description>arXiv:2505.01930v1 Announce Type: new 
Abstract: We introduce a novel normal form representation of Boolean functions in terms of products of binary matrices, hereafter referred to as the Binary Matrix Product (BMP) representation. BMPs are analogous to the Tensor-Trains (TT) and Matrix Product States (MPS) used, respectively, in applied mathematics and in quantum many-body physics to accelerate computations that are usually inaccessible by more traditional approaches. BMPs turn out to be closely related to Binary Decision Diagrams (BDDs), a powerful compressed representation of Boolean functions invented in the late 80s by Bryant that has found a broad range of applications in many areas of computer science and engineering. We present a direct and natural translation of BMPs into Binary Decision Diagrams (BDDs), and derive an elementary set of operations used to manipulate and combine BMPs that are analogous to those introduced by Bryant for BDDs. Both BDDs and BMPs are practical tools when the complexity of these representations, as measured by the maximum bond dimension of a BMP (or the accumulated bond dimension across the BMP matrix train) and the number of nodes of a BDD, remains polynomial in the number of bits.. In both cases, controlling the complexity hinges on optimizing the order of the Boolean variables. BMPs offer the advantage that their construction and manipulation rely on simple linear algebra -- a compelling feature that can facilitate the development of open-source libraries that are both more flexible and easier to use than those currently available for BDDs. An initial implementation of a BMP library is available on GitHub, with the expectation that the close conceptual connection to TT and MPS techniques will motivate further development of BMP methods by researchers in these fields, potentially enabling novel applications to classical and quantum computing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01930v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Umut Eren Usturali, Claudio Chamon, Andrei E. Ruckenstein, Eduardo R. Mucciolo</dc:creator>
    </item>
    <item>
      <title>Faster logconcave sampling from a cold start in high dimension</title>
      <link>https://arxiv.org/abs/2505.01937</link>
      <description>arXiv:2505.01937v1 Announce Type: new 
Abstract: We present a faster algorithm to generate a warm start for sampling an arbitrary logconcave density specified by an evaluation oracle, leading to the first sub-cubic sampling algorithms for inputs in (near-)isotropic position. A long line of prior work incurred a warm-start penalty of at least linear in the dimension, hitting a cubic barrier, even for the special case of uniform sampling from convex bodies.
  Our improvement relies on two key ingredients of independent interest. (1) We show how to sample given a warm start in weaker notions of distance, in particular $q$-R\'enyi divergence for $q=\widetilde{\mathcal{O}}(1)$, whereas previous analyses required stringent $\infty$-R\'enyi divergence (with the exception of Hit-and-Run, whose known mixing time is higher). This marks the first improvement in the required warmness since Lov\'asz and Simonovits (1991). (2) We refine and generalize the log-Sobolev inequality of Lee and Vempala (2018), originally established for isotropic logconcave distributions in terms of the diameter of the support, to logconcave distributions in terms of a geometric average of the support diameter and the largest eigenvalue of the covariance matrix.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01937v1</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.FA</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yunbum Kook, Santosh S. Vempala</dc:creator>
    </item>
    <item>
      <title>Exact Set Packing in Multimodal Transportation with Ridesharing System for First/Last Mile</title>
      <link>https://arxiv.org/abs/2505.01989</link>
      <description>arXiv:2505.01989v1 Announce Type: new 
Abstract: We propose a centralized transportation system that integrates public transit with ridesharing to provide multimodal transportation. At each time interval, the system receives a set of personal drivers, designated drivers, and public transit riders. It then assigns all riders to drivers, ensuring that pick-ups and drop-offs occur at designated transit stations. This effectively replaces first-mile/last-mile (FM/LM) segments with a ridesharing alternative, reducing overall commuting time. We study two optimization problems: (1) minimizing the total travel distances of drivers and (2) minimizing the number of designated drivers required to serve all riders. We show the optimization problems are NP-hard and give hypergraph-based integer linear programming exact algorithm and approximation algorithms. To enhance computational efficiency, we introduce a clustering heuristic that utilizes both spatial and temporal aspects of the input data to accelerate rider-to-driver assignments. Finally, we conduct an extensive computational study using real-world datasets and surveys from Chicago to evaluate our model and algorithms at a city-wide scale.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01989v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Qian-Ping Gu, Jiajian Leo Liang</dc:creator>
    </item>
    <item>
      <title>Unifying Laplace Mechanism with Instance Optimality in Differential Privacy</title>
      <link>https://arxiv.org/abs/2505.02798</link>
      <description>arXiv:2505.02798v1 Announce Type: new 
Abstract: We adapt the canonical Laplace mechanism, widely used in differentially private data analysis, to achieve near instance optimality with respect to the hardness of the underlying dataset. In particular, we construct a piecewise Laplace distribution whereby we defy traditional assumptions and show that Laplace noise can in fact be drawn proportional to the local sensitivity when done in a piecewise manner. While it may initially seem counterintuitive that this satisfies (pure) differential privacy and can be sampled, we provide both through a simple connection to the exponential mechanism and inverse sensitivity along with the fact that the Laplace distribution is a two-sided exponential distribution. As a result, we prove that in the continuous setting our \textit{piecewise Laplace mechanism} strictly dominates the inverse sensitivity mechanism, which was previously shown to both be nearly instance optimal and uniformly outperform the smooth sensitivity framework. Furthermore, in the worst-case where all local sensitivities equal the global sensitivity, our method simply reduces to a Laplace mechanism. We also complement this with an approximate local sensitivity variant to potentially ease the computational cost, which can also extend to higher dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02798v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Durfee</dc:creator>
    </item>
    <item>
      <title>On Solving Simple Curved Nonograms</title>
      <link>https://arxiv.org/abs/2505.01554</link>
      <description>arXiv:2505.01554v1 Announce Type: cross 
Abstract: Nonograms are a popular type of puzzle, where an arrangement of curves in the plane (in the classic version, a rectangular grid) is given together with a series of hints, indicating which cells of the subdivision are to be colored. The colored cells yield an image. Curved nonograms use a curve arrangement rather than a grid, leading to a closer approximation of an arbitrary solution image. While there is a considerable amount of previous work on the natural question of the hardness of solving a classic nonogram, research on curved nonograms has so far focused on their creation, which is already highly non-trivial. We address this gap by providing algorithmic and hardness results for curved nonograms of varying complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01554v1</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maarten L\"offler, G\"unter Rote, Soeren Terziadis, Alexandra Weinberger</dc:creator>
    </item>
    <item>
      <title>Quantum Speedup for Hypergraph Sparsification</title>
      <link>https://arxiv.org/abs/2505.01763</link>
      <description>arXiv:2505.01763v1 Announce Type: cross 
Abstract: Graph sparsification serves as a foundation for many algorithms, such as approximation algorithms for graph cuts and Laplacian system solvers. As its natural generalization, hypergraph sparsification has recently gained increasing attention, with broad applications in graph machine learning and other areas. In this work, we propose the first quantum algorithm for hypergraph sparsification, addressing an open problem proposed by Apers and de Wolf (FOCS'20). For a weighted hypergraph with $n$ vertices, $m$ hyperedges, and rank $r$, our algorithm outputs a near-linear size $\varepsilon$-spectral sparsifier in time $\widetilde O(r\sqrt{mn}/\varepsilon)$. This algorithm matches the quantum lower bound for constant $r$ and demonstrates quantum speedup when compared with the state-of-the-art $\widetilde O(mr)$-time classical algorithm. As applications, our algorithm implies quantum speedups for computing hypergraph cut sparsifiers, approximating hypergraph mincuts and hypergraph $s$-$t$ mincuts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01763v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chenghua Liu, Minbo Gao, Zhengfeng Ji, Mingsheng Ying</dc:creator>
    </item>
    <item>
      <title>On optimal distinguishers for Planted Clique</title>
      <link>https://arxiv.org/abs/2505.01990</link>
      <description>arXiv:2505.01990v1 Announce Type: cross 
Abstract: In a distinguishing problem, the input is a sample drawn from one of two distributions and the algorithm is tasked with identifying the source distribution. The performance of a distinguishing algorithm is measured by its advantage, i.e., its incremental probability of success over a random guess. A classic example of a distinguishing problem is the Planted Clique problem, where the input is a graph sampled from either $G(n,1/2)$ -- the standard Erd\H{o}s-R\'{e}nyi model, or $G(n,1/2,k)$ -- the Erd\H{o}s-R\'{e}nyi model with a clique planted on a random subset of $k$ vertices. The Planted Clique Hypothesis asserts that efficient algorithms cannot achieve advantage better than some absolute constant, say $1/4$, whenever $k=n^{1/2-\Omega(1)}$. In this work, we aim to precisely understand the optimal distinguishing advantage achievable by efficient algorithms on Planted Clique. We show the following results under the Planted Clique hypothesis:
  1. Optimality of low-degree polynomials: The optimal advantage achievable by any efficient algorithm is bounded by the low-degree advantage, which is the advantage achievable by low-degree polynomials of the input. The low-degree advantage is roughly $k^2/(\sqrt{2}n)$. Conversely, a simple edge-counting algorithm achieves advantage $k^2/(\sqrt{\pi}n)$, showing that our bound is tight up to a small constant factor.
  2. Harder planted distributions: There is an efficiently sampleable distribution $\mathcal{P}^*$ supported on graphs containing $k$-cliques such that no efficient algorithm can distinguish $\mathcal{P}^*$ from $G(n,1/2)$ with advantage $n^{-d}$ for an arbitrarily large constant $d$. In other words, there exist alternate planted distributions that are much harder than $G(n,1/2,k)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01990v1</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ansh Nagda, Prasad Raghavendra</dc:creator>
    </item>
    <item>
      <title>Efficient Classical Algorithms for Simulating Gaussian Boson Sampling on Graphs</title>
      <link>https://arxiv.org/abs/2505.02445</link>
      <description>arXiv:2505.02445v1 Announce Type: cross 
Abstract: Gaussian Boson Sampling (GBS) is a promising candidate for demonstrating quantum computational advantage and can be applied to solving graph-related problems. In this work, we propose Markov chain Monte Carlo-based algorithms to simulate GBS on undirected, unweighted graphs. Our main contribution is a double-loop variant of Glauber dynamics, whose stationary distribution matches the GBS distribution. We further prove that it mixes in polynomial time for dense graphs using a refined canonical path argument. Numerically, we conduct experiments on graphs with 256 vertices, larger than the scales in former GBS experiments as well as classical simulations. In particular, we show that both the single-loop and double-loop Glauber dynamics improve the performance of original random search and simulated annealing algorithms for the max-Hafnian and densest $k$-subgraph problems up to 10x. Overall, our approach offers both theoretical guarantees and practical advantages for classical simulations of GBS on graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02445v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yexin Zhang, Shuo Zhou, Xinzhao Wang, Ziruo Wang, Ziyi Yang, Rui Yang, Yecheng Xue, Tongyang Li</dc:creator>
    </item>
    <item>
      <title>Bandwidth Parameterized by Cluster Vertex Deletion Number</title>
      <link>https://arxiv.org/abs/2309.17204</link>
      <description>arXiv:2309.17204v3 Announce Type: replace 
Abstract: Given a graph $G$ and an integer $b$, Bandwidth asks whether there exists a bijection $\pi$ from $V(G)$ to $\{1, \ldots, |V(G)|\}$ such that $\max_{\{u, v \} \in E(G)} | \pi(u) - \pi(v) | \leq b$. This is a classical NP-complete problem, known to remain NP-complete even on very restricted classes of graphs, such as trees of maximum degree 3 and caterpillars of hair length 3. In the realm of parameterized complexity, these results imply that the problem remains NP-hard on graphs of bounded pathwidth, while it is additionally known to be W[1]-hard when parameterized by the tree-depth of the input graph. In contrast, the problem does become FPT when parameterized by the vertex cover number. In this paper we make progress in understanding the parameterized (in)tractability of Bandwidth. We first show that it is FPT when parameterized by the cluster vertex deletion number cvd plus the clique number $\omega$, thus significantly strengthening the previously mentioned result for vertex cover number. On the other hand, we show that Bandwidth is W[1]-hard when parameterized only by cvd. Our results develop and generalize some of the methods of argumentation of the previous results and narrow some of the complexity gaps.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.17204v3</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s00453-025-01315-x</arxiv:DOI>
      <dc:creator>Tatsuya Gima, Eun Jung Kim, Noleen K\"ohler, Nikolaos Melissinos, Manolis Vasilakis</dc:creator>
    </item>
    <item>
      <title>Scalable and Interpretable Identification of Minimal Undesignable RNA Structure Motifs with Rotational Invariance</title>
      <link>https://arxiv.org/abs/2402.17206</link>
      <description>arXiv:2402.17206v4 Announce Type: replace 
Abstract: RNA design aims to find a sequence that folds with highest probability into a designated target structure. However, certain structures are undesignable, meaning no sequence can fold into the target structure under the default (Turner) RNA folding model. Understanding the specific local structures (i.e., "motifs") that contribute to undesignability is crucial for refining RNA folding models and determining the limits of RNA designability. Despite its importance, this problem has received very little attention, and previous efforts are neither scalable nor interpretable. We develop a new theoretical framework for motif (un-)designability, and design scalable and interpretable algorithms to identify minimal undesignable motifs within a given RNA secondary structure. Our approach establishes motif undesignability by searching for rival motifs, rather than exhaustively enumerating all (partial) sequences that could potentially fold into the motif. Furthermore, we exploit rotational invariance in RNA structures to detect, group, and reuse equivalent motifs and to construct a database of unique minimal undesignable motifs. To achieve that, we propose a loop-pair graph representation for motifs and a recursive graph isomorphism algorithm for motif equivalence. Our algorithms successfully identify 24 unique minimal undesignable motifs among 18 undesignable puzzles from the Eterna100 benchmark. Surprisingly, we also find over 350 unique minimal undesignable motifs and 663 undesignable native structures in the ArchiveII dataset, drawn from a diverse set of RNA families. Our source code is available at https://github.com/shanry/RNA-Undesign and our web server is available at http://linearfold.org/motifs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.17206v4</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-031-90252-9_10</arxiv:DOI>
      <dc:creator>Tianshuo Zhou, Wei Yu Tang, Apoorv Malik, David H. Mathews, Liang Huang</dc:creator>
    </item>
    <item>
      <title>Optimizing Inventory Placement for a Downstream Online Matching Problem</title>
      <link>https://arxiv.org/abs/2403.04598</link>
      <description>arXiv:2403.04598v3 Announce Type: replace 
Abstract: We study the inventory placement problem of splitting $Q$ units of a single item across warehouses in advance of a downstream online matching problem that represents the dynamic fulfillment decisions of an e-commerce retailer. This is a challenging problem both theoretically, due to the computational complexity of the downstream matching problem, and practically, as the fulfillment team continuously updates its algorithm while the placement team lacks direct evaluation of placement decisions.
  We compare the performance of three placement procedures based on optimizing surrogate functions that have been studied and applied: Offline, Myopic, and Fluid placement. On the theory side, we show that optimizing inventory placement for the Offline surrogate leads to an $\alpha (1-(1-1/d)^d)$-approximation for the joint placement and fulfillment problem under any demand model that admits an $\alpha$-competitive fulfillment policy. We assume $d$ is an upper bound on how many warehouses can serve any demand location. The crux of our theoretical contribution is to use randomized rounding to derive a tight $(1-(1-1/d)^d)$-approximation for the integer programming problem of optimizing the Offline surrogate. We further show how to extend this result to a multi-SKU setting, improving upon the best known approximation of $1/2$. We use statistical learning to show that rounding after optimizing a sample-average Offline surrogate, which is necessary due to the exponentially-sized support, indeed has vanishing loss. On the experimental side, we evaluate how different combinations of placement and fulfillment procedures perform on a wide array of synthetic instances. When coupled with a good fulfillment procedure, optimizing the Offline surrogate performs best even compared to computationally-intensive simulation procedures, corroborating our theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.04598v3</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Boris Epstein (Columbia University), Will Ma (Columbia University)</dc:creator>
    </item>
    <item>
      <title>Maximum And- vs. Even-SAT</title>
      <link>https://arxiv.org/abs/2409.07837</link>
      <description>arXiv:2409.07837v2 Announce Type: replace 
Abstract: A (multi)set of literals, called a clause, is strongly satisfied by an assignment if no literal evaluates to false. Finding an assignment that maximises the number of strongly satisfied clauses is NP-hard. We present a simple algorithm that finds, given a set of clauses that admits an assignment that strongly satisfies a $\rho$-fraction of the clauses, an assignment in which at least a $\rho$-fraction of the clauses is weakly satisfied, in the sense that an even number of literals evaluates to false. In particular, this implies an efficient algorithm for finding an undirected cut of value $\rho$ in a graph $G$ given that a directed cut of value $\rho$ in $G$ is promised to exist. A similar argument also gives an efficient algorithm for finding an acyclic subgraph of $G$ with $\rho$ edges under the same promise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07837v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tamio-Vesa Nakajima, Stanislav \v{Z}ivn\'y</dc:creator>
    </item>
    <item>
      <title>Robust-Sorting and Applications to Ulam-Median</title>
      <link>https://arxiv.org/abs/2502.07653</link>
      <description>arXiv:2502.07653v2 Announce Type: replace 
Abstract: Sorting is one of the most basic primitives in many algorithms and data analysis tasks. Comparison-based sorting algorithms, like quick-sort and merge-sort, are known to be optimal when the outcome of each comparison is error-free. However, many real-world sorting applications operate in scenarios where the outcome of each comparison can be noisy. In this work, we explore settings where a bounded number of comparisons are potentially corrupted by erroneous agents, resulting in arbitrary, adversarial outcomes.
  We model the sorting problem as a query-limited tournament graph where edges involving erroneous nodes may yield arbitrary results. Our primary contribution is a randomized algorithm inspired by quick-sort that, in expectation, produces an ordering close to the true total order while only querying $\tilde{O}(n)$ edges. We achieve a distance from the target order $\pi$ within $(3 + \epsilon)|B|$, where $B$ is the set of erroneous nodes, balancing the competing objectives of minimizing both query complexity and misalignment with $\pi$. Our algorithm needs to carefully balance two aspects: identify a pivot that partitions the vertex set evenly and ensure that this partition is "truthful" and yet query as few "triangles" in the graph $G$ as possible. Since the nodes in $B$ can potentially hide in an intricate manner, our algorithm requires several technical steps.
  Additionally, we demonstrate significant implications for the Ulam-$k$-Median problem, a classical clustering problem where the metric is defined on the set of permutations on a set of $d$ elements. Chakraborty, Das, and Krauthgamer gave a $(2-\varepsilon)$ FPT approximation algorithm for this problem, where the running time is super-linear in both $n$ and $d$. We use our robust sorting framework to give the first $(2-\varepsilon)$ FPT linear time approximation algorithm for this problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07653v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ragesh Jaiswal, Amit Kumar, Jatin Yadav</dc:creator>
    </item>
    <item>
      <title>Simple Sublinear Algorithms for $(\Delta+1)$ Vertex Coloring via Asymmetric Palette Sparsification</title>
      <link>https://arxiv.org/abs/2502.17629</link>
      <description>arXiv:2502.17629v2 Announce Type: replace 
Abstract: The palette sparsification theorem (PST) of Assadi, Chen, and Khanna (SODA 2019) states that in every graph $G$ with maximum degree $\Delta$, sampling a list of $O(\log{n})$ colors from $\{1,\ldots,\Delta+1\}$ for every vertex independently and uniformly, with high probability, allows for finding a $(\Delta+1)$ vertex coloring of $G$ by coloring each vertex only from its sampled list. PST naturally leads to a host of sublinear algorithms for $(\Delta+1)$ vertex coloring, including in semi-streaming, sublinear time, and MPC models, which are all proven to be nearly optimal, and in the case of the former two are the only known sublinear algorithms for this problem.
  While being a quite natural and simple-to-state theorem, PST suffers from two drawbacks. Firstly, all its known proofs require technical arguments that rely on sophisticated graph decompositions and probabilistic arguments. Secondly, finding the coloring of the graph from the sampled lists in an efficient manner requires a considerably complicated algorithm.
  We show that a natural weakening of PST addresses both these drawbacks while still leading to sublinear algorithms of similar quality (up to polylog factors). In particular, we prove an asymmetric palette sparsification theorem (APST) that allows for list sizes of the vertices to have different sizes and only bounds the average size of these lists. The benefit of this weaker requirement is that we can now easily show the graph can be $(\Delta+1)$ colored from the sampled lists using the standard greedy coloring algorithm. This way, we can recover nearly-optimal bounds for $(\Delta+1)$ vertex coloring in all the aforementioned models using algorithms that are much simpler to implement and analyze.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.17629v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sepehr Assadi, Helia Yazdanyar</dc:creator>
    </item>
    <item>
      <title>PHast -- Perfect Hashing with fast evaluation</title>
      <link>https://arxiv.org/abs/2504.17918</link>
      <description>arXiv:2504.17918v2 Announce Type: replace 
Abstract: Perfect hash functions give unique "names" to arbitrary keys requiring only a few bits per key. This is an essential building block in applications like static hash tables, databases, or bioinformatics. This paper introduces the PHast approach that has the currently fastest query time with competitive construction time and space consumption. PHast improves bucket-placement which first hashes each key k to a bucket, and then looks for the bucket seed s such that a secondary hash function maps pairs (s,k) in a collision-free way. PHast can use small-range primary hash functions with linear mapping, fixed-width encoding of seeds, and parallel construction. This is achieved using small overlapping slices of allowed values and bumping to handle unsuccessful seed assignment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17918v2</guid>
      <category>cs.DS</category>
      <category>cs.DB</category>
      <category>cs.PF</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Piotr Beling, Peter Sanders</dc:creator>
    </item>
    <item>
      <title>Delta-modular ILP Problems of Bounded Codimension, Discrepancy, and Convolution (new version)</title>
      <link>https://arxiv.org/abs/2405.17001</link>
      <description>arXiv:2405.17001v3 Announce Type: replace-cross 
Abstract: For integers $k,n \geq 0$ and a cost vector $c \in Z^n$, we study two fundamental integer linear programming (ILP) problems: \[
  \text{(Standard Form)} \quad \max\bigl\{c^\top x \colon Ax = b,\ x \in Z^n_{\geq 0}\bigr\} \text{ with } A \in Z^{k \times n}, \text{rank}(A) = k, b \in Z^k, \] \[
  \text{(Canonical Form)} \quad \max\bigl\{c^\top x \colon Ax \leq b,\ x \in Z^n\bigr\} \text{ with } A \in Z^{(n+k) \times n}, \text{rank}(A) = n, b \in Z^{n+k}. \] We present improved algorithms for both problems and their feasibility versions, parameterized by $k$ and $\Delta$, where $\Delta$ denotes the maximum absolute value of $\text{rank}(A) \times \text{rank}(A)$ subdeterminants of $A$. Our main complexity results, stated in terms of required arithmetic operations, are: \[ \text{Optimization:}\quad O(\log k)^{2k} \cdot \Delta^2 / 2^{\Omega(\sqrt{\log \Delta})} + 2^{O(k)} \cdot \text{poly}(\varphi), \] \[ \text{Feasibility:} \quad O(\log k)^k \cdot \Delta \cdot (\log \Delta)^3 + 2^{O(k)} \cdot \text{poly}(\varphi), \] where $\varphi$ represents the input size measured by the bit-encoding length of $(A,b,c)$. We also examine several special cases when $k \in \{0,1\}$, which have important applications in: expected computational complexity of ILP with varying right-hand side $b$, ILP problems with generic constraint matrices, ILP problems on simplices. Our results yield improved complexity bounds for these specific scenarios.
  As independent contributions, we present: An $n^2/2^{\Omega(\sqrt{\log n})}$-time algorithm for the tropical convolution problem on sequences indexed by elements of a finite Abelian group of order $n$; A complete and self-contained error analysis of the generalized DFT over Abelian groups in the Word-RAM model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17001v3</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>math.AC</category>
      <category>math.OC</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>D. Gribanov, D. Malyshev, P. M. Pardalos</dc:creator>
    </item>
    <item>
      <title>Distributed Maximum Flow in Planar Graphs</title>
      <link>https://arxiv.org/abs/2411.11718</link>
      <description>arXiv:2411.11718v3 Announce Type: replace-cross 
Abstract: The dual of a planar graph $G$ is a planar graph $G^*$ that has a vertex for each face of $G$ and an edge for each pair of adjacent faces of $G$. The profound relationship between a planar graph and its dual has been the algorithmic basis for solving numerous (centralized) classical problems on planar graphs. In the distributed setting however, the only use of planar duality is for finding a recursive decomposition of $G$ [DISC 2017, STOC 2019].
  We extend the distributed algorithmic toolkit to work on the dual graph $G^*$. These tools can then facilitate various algorithms on $G$ by solving a suitable dual problem on $G^*$.
  Given a directed planar graph $G$ with positive and negative edge-lengths and hop-diameter $D$, our key result is an $\tilde{O}(D^2)$-round algorithm for Single Source Shortest Paths on $G^*$, which then implies $\tilde{O}(D^2)$-round algorithms for Maximum $st$-Flow and Directed Global Min-Cut on $G$. Prior to our work, no $\tilde{O}(\text{poly}(D))$-round algorithm was known for those problems. We further obtain a $D\cdot n^{o(1)}$-rounds $(1-\epsilon)$-approximation algorithm for Maximum $st$-Flow on $G$ when $G$ is undirected and $st$-planar. Finally, we give a near optimal $\tilde O(D)$-round algorithm for computing the weighted girth of $G$. The main challenges in our work are that $G^*$ is not the communication graph (e.g., a vertex of $G$ is mapped to multiple vertices of $G^*$), and that the diameter of $G^*$ can be much larger than $D$ (i.e., possibly by a linear factor). We overcome these challenges by carefully defining and maintaining subgraphs of the dual graph $G^*$ while applying the recursive decomposition on the primal graph $G$. The main technical difficulty, is that along the recursive decomposition, a face of $G$ gets shattered into (disconnected) components yet we still need to treat it as a dual node.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11718v3</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yaseen Abd-Elhaleem (University of Haifa), Michal Dory (University of Haifa), Merav Parter (Weizmann Institute of Science), Oren Weimann (University of Haifa)</dc:creator>
    </item>
    <item>
      <title>On the Robustness of the Successive Projection Algorithm</title>
      <link>https://arxiv.org/abs/2411.16195</link>
      <description>arXiv:2411.16195v2 Announce Type: replace-cross 
Abstract: The successive projection algorithm (SPA) is a workhorse algorithm to learn the $r$ vertices of the convex hull of a set of $(r-1)$-dimensional data points, a.k.a. a latent simplex, which has numerous applications in data science. In this paper, we revisit the robustness to noise of SPA and several of its variants. In particular, when $r \geq 3$, we prove the tightness of the existing error bounds for SPA and for two more robust preconditioned variants of SPA. We also provide significantly improved error bounds for SPA, by a factor proportional to the conditioning of the $r$ vertices, in two special cases: for the first extracted vertex, and when $r \leq 2$. We then provide further improvements for the error bounds of a translated version of SPA proposed by Arora et al. (''A practical algorithm for topic modeling with provable guarantees'', ICML, 2013) in two special cases: for the first two extracted vertices, and when $r \leq 3$. Finally, we propose a new more robust variant of SPA that first shifts and lifts the data points in order to minimize the conditioning of the problem. We illustrate our results on synthetic data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16195v2</guid>
      <category>math.NA</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>stat.ML</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giovanni Barbarino, Nicolas Gillis</dc:creator>
    </item>
    <item>
      <title>PAC Learning is just Bipartite Matching (Sort of)</title>
      <link>https://arxiv.org/abs/2502.00607</link>
      <description>arXiv:2502.00607v3 Announce Type: replace-cross 
Abstract: The main goal of this article is to convince you, the reader, that supervised learning in the Probably Approximately Correct (PAC) model is closely related to -- of all things -- bipartite matching! En-route from PAC learning to bipartite matching, I will overview a particular transductive model of learning, and associated one-inclusion graphs, which can be viewed as a generalization of some of the hat puzzles that are popular in recreational mathematics. Whereas this transductive model is far from new, it has recently seen a resurgence of interest as a tool for tackling deep questions in learning theory. A secondary purpose of this article could be as a (biased) tutorial on the connections between the PAC and transductive models of learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00607v3</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>stat.ML</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shaddin Dughmi</dc:creator>
    </item>
    <item>
      <title>A Theoretical Model for Grit in Pursuing Ambitious Ends</title>
      <link>https://arxiv.org/abs/2503.02952</link>
      <description>arXiv:2503.02952v2 Announce Type: replace-cross 
Abstract: Ambition and risk-taking have been heralded as important ways for marginalized communities to get out of cycles of poverty. As a result, educational messaging often encourages individuals to strengthen their personal resolve and develop characteristics such as discipline and grit to succeed in ambitious ends. However, recent work in philosophy and sociology highlights that this messaging often does more harm than good for students in these situations. We study similar questions using a different epistemic approach and in simple theoretical models -- we provide a quantitative model of decision-making between stable and risky choices in the improving multi-armed bandits framework. We use this model to first study how individuals' "strategies" are affected by their level of grittiness and how this affects their accrued rewards. Then, we study the impact of various interventions, such as increasing grit or providing a financial safety net. Our investigation of rational decision making involves two different formal models of rationality, the competitive ratio between the accrued reward and the optimal reward and Bayesian quantification of uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02952v2</guid>
      <category>cs.CY</category>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <category>stat.AP</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Avrim Blum, Emily Diana, Kavya Ravichandran, Alexander Williams Tolbert</dc:creator>
    </item>
    <item>
      <title>Fast Computation of the Discrete Fourier Transform Rectangular Index Coefficients</title>
      <link>https://arxiv.org/abs/2504.12551</link>
      <description>arXiv:2504.12551v2 Announce Type: replace-cross 
Abstract: In~\cite{sic-magazine-2025}, the authors show that the square index coefficients (SICs) of the $N$-point discrete Fourier transform (DFT) -- that is, the coefficients $X_{k\sqrt{N}}$ for $k = 0, 1, \ldots, \sqrt{N} - 1$ -- can be losslessly compressed from $N$ to $\sqrt{N}$ points, thereby accelerating the computation of these specific DFT coefficients accordingly. Following up on that, in this article we generalize SICs into what we refer to as rectangular index coefficients (RICs) of the DFT, formalized as $X_{kL}, k=0,1,\cdots,C-1$, in which the integers $C$ and $L$ are generic roots of $N$ such that $N=LC$. We present an algorithm to compress the $N$-point input signal $\mathbf{x}$ into a $C$-point signal $\mathbf{\hat{x}}$ at the expense of $\mathcal{O}(N)$ complex sums and no complex multiplication. We show that a DFT on $\mathbf{\hat{x}}$ is equivalent to a DFT on the RICs of $\mathbf{x}$. In cases where specific frequencies of $\mathbf{x}$ are of interest -- as in harmonic analysis -- one can conveniently adjust the signal parameters (e.g., frequency resolution) to align the RICs with those frequencies, and use the proposed algorithm to compute them significantly faster. If $N$ is a power of two -- as required by the fast Fourier transform (FFT) algorithm -- then $C$ can be any power of two in the range $[2, N/2]$ and one can use our algorithm along with FFT to compute all RICs in $\mathcal{O}(C\log C)$ time complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.12551v2</guid>
      <category>eess.SP</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Saulo Queiroz, Jo\~ao P. Vilela, Benjamin Koon Kei Ng, Chan-Tong Lam, Edmundo Monteiro</dc:creator>
    </item>
    <item>
      <title>Approximately Dominating Sets in Elections</title>
      <link>https://arxiv.org/abs/2504.20372</link>
      <description>arXiv:2504.20372v2 Announce Type: replace-cross 
Abstract: Condorcet's paradox is a fundamental result in social choice theory which states that there exist elections in which, no matter which candidate wins, a majority of voters prefer a different candidate. In fact, even if we can select any $k$ winners, there still may exist another candidate that would beat each of the winners in a majority vote. That is, elections may require arbitrarily large dominating sets.
  We show that approximately dominating sets of constant size always exist. In particular, for every $\varepsilon &gt; 0$, every election (irrespective of the number of voters or candidates) can select $O(\frac{1}{\varepsilon ^2})$ winners such that no other candidate beats each of the winners by a margin of more than $\varepsilon$ fraction of voters.
  Our proof uses a simple probabilistic construction using samples from a maximal lottery, a well-studied distribution over candidates derived from the Nash equilibrium of a two-player game. In stark contrast to general approximate equilibria, which may require support logarithmic in the number of pure strategies, we show that maximal lotteries can be approximated with constant support size. These approximate maximal lotteries may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.20372v2</guid>
      <category>cs.GT</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Moses Charikar, Prasanna Ramakrishnan, Kangning Wang</dc:creator>
    </item>
    <item>
      <title>Efficient Decomposition of Forman-Ricci Curvature on Vietoris-Rips Complexes and Data Applications</title>
      <link>https://arxiv.org/abs/2504.21601</link>
      <description>arXiv:2504.21601v2 Announce Type: replace-cross 
Abstract: Discrete Forman-Ricci curvature (FRC) is an efficient tool that characterizes essential geometrical features and associated transitions of real-world networks, extending seamlessly to higher-dimensional computations in simplicial complexes. In this article, we provide two major advancements: First, we give a decomposition for FRC, enabling local computations of FRC. Second, we construct a set-theoretical proof enabling an efficient algorithm for the local computation of FRC in Vietoris-Rips (VR) complexes.Strikingly, this approach reveals critical information and geometric insights often overlooked by conventional classification techniques. Our findings open new avenues for geometric computations in VR complexes and highlight an essential yet under-explored aspect of data classification: the geometry underpinning statistical patterns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.21601v2</guid>
      <category>math.GT</category>
      <category>cs.CG</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Danillo Barros de Souza, Jonatas Teodomiro, Fernando A. N. Santos, Mengjun Ding, Weiqiang Sun, Mathieu Desroches, J\"urgen Jost, Serafim Rodrigues</dc:creator>
    </item>
  </channel>
</rss>
