<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.HC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.HC</link>
    <description>cs.HC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.HC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 27 Aug 2025 04:00:03 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Technology-assisted Personalized Yoga for Better Health - Challenges and Outlook</title>
      <link>https://arxiv.org/abs/2508.18283</link>
      <description>arXiv:2508.18283v1 Announce Type: new 
Abstract: Yoga is a discipline of physical postures, breathing techniques, and meditative practices rooted in ancient Indian traditions, now embraced worldwide for promoting overall well-being and inner balance. The practices are a large set of items, our term for executable actions like physical poses or breath exercises, to offer for a person's well-being. However, to get benefits of Yoga tailored to a person's unique needs, a person needs to (a) discover their subset from the large and seemingly complex set with inter-dependencies, (b) continue to follow them with interest adjusted to their changing abilities and near-term objectives, and (c) as appropriate, adapt to alternative items based on changing environment and the person's health conditions. In this vision paper, we describe the challenges for the Yoga personalization problem. Next, we sketch a preliminary approach and use the experience to provide an outlook on solving the challenging problem using existing and novel techniques from a multidisciplinary computing perspective. To the best of our knowledge, this is the first paper that comprehensively examines decision support issues around Yoga personalization, from pose sensing to recommendation of corrections for a complete regimen, and illustrates with a case study of Surya Namaskar -- a set of 12 choreographed poses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18283v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vivek Kumar, Himanshu Sahu, Hari Prabhat Gupta, Biplav Srivastava</dc:creator>
    </item>
    <item>
      <title>Does Calibration Affect Human Actions?</title>
      <link>https://arxiv.org/abs/2508.18317</link>
      <description>arXiv:2508.18317v1 Announce Type: new 
Abstract: Calibration has been proposed as a way to enhance the reliability and adoption of machine learning classifiers. We study a particular aspect of this proposal: how does calibrating a classification model affect the decisions made by non-expert humans consuming the model's predictions? We perform a Human-Computer-Interaction (HCI) experiment to ascertain the effect of calibration on (i) trust in the model, and (ii) the correlation between decisions and predictions. We also propose further corrections to the reported calibrated scores based on Kahneman and Tversky's prospect theory from behavioral economics, and study the effect of these corrections on trust and decision-making. We find that calibration is not sufficient on its own; the prospect theory correction is crucial for increasing the correlation between human decisions and the model's predictions. While this increased correlation suggests higher trust in the model, responses to ``Do you trust the model more?" are unaffected by the method used.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18317v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Meir Nizri, Amos Azaria, Chirag Gupta, Noam Hazon</dc:creator>
    </item>
    <item>
      <title>Impact of Target and Tool Visualization on Depth Perception and Usability in Optical See-Through AR</title>
      <link>https://arxiv.org/abs/2508.18481</link>
      <description>arXiv:2508.18481v1 Announce Type: new 
Abstract: Optical see-through augmented reality (OST-AR) systems like Microsoft HoloLens 2 hold promise for arm's distance guidance (e.g., surgery), but depth perception of the hologram and occlusion of real instruments remain challenging. We present an evaluation of how visualizing the target object with different transparencies and visualizing a tracked tool (virtual proxy vs. real tool vs. no tool tracking) affects depth perception and system usability. Ten participants performed two experiments on HoloLens 2. In Experiment 1, we compared high-transparency vs. low-transparency target rendering in a depth matching task at arm's length. In Experiment 2, participants performed a simulated surgical pinpoint task on a frontal bone target under six visualization conditions ($2 \times 3$: two target transparencies and three tool visualization modes: virtual tool hologram, real tool, or no tool tracking). We collected data on depth matching error, target localization error, system usability, task workload, and qualitative feedback. Results show that a more opaque target yields significantly lower depth estimation error than a highly transparent target at arm's distance. Moreover, showing the real tool (occluding the virtual target) led to the highest accuracy and usability with the lowest workload, while not tracking the tool yielded the worst performance and user ratings. However, making the target highly transparent, while allowing the real tool to remain visible, slightly impaired depth cues and did not improve usability. Our findings underscore that correct occlusion cues, rendering virtual content opaque and occluding it with real tools in real time, are critical for depth perception and precision in OST-AR. Designers of arm-distance AR systems should prioritize robust tool tracking and occlusion handling; if unavailable, cautiously use transparency to balance depth perception and tool visibility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18481v1</guid>
      <category>cs.HC</category>
      <category>cs.CV</category>
      <category>cs.GR</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yue Yang, Xue Xie, Xinkai Wang, Hui Zhang, Chiming Yu, Xiaoxian Xiong, Lifeng Zhu, Yuanyi Zheng, Jue Cen, Bruce Daniel, Fred Baik</dc:creator>
    </item>
    <item>
      <title>Skeptik: A Hybrid Framework for Combating Potential Misinformation in Journalism</title>
      <link>https://arxiv.org/abs/2508.18499</link>
      <description>arXiv:2508.18499v1 Announce Type: new 
Abstract: The proliferation of misinformation in journalism, often stemming from flawed reasoning and logical fallacies, poses significant challenges to public understanding and trust in news media. Traditional fact-checking methods, while valuable, are insufficient for detecting the subtle logical inconsistencies that can mislead readers within seemingly factual content. To address this gap, we introduce Skeptik, a hybrid framework that integrates Large Language Models (LLMs) with heuristic approaches to analyze and annotate potential logical fallacies and reasoning errors in online news articles. Operating as a web browser extension, Skeptik automatically highlights sentences that may contain logical fallacies, provides detailed explanations, and offers multi-layered interventions to help readers critically assess the information presented. The system is designed to be extensible, accommodating a wide range of fallacy types and adapting to evolving misinformation tactics. Through comprehensive case studies, quantitative analyses, usability experiments, and expert evaluations, we demonstrate the effectiveness of Skeptik in enhancing readers' critical examination of news content and promoting media literacy. Our contributions include the development of an expandable classification system for logical fallacies, the innovative integration of LLMs for real-time analysis and annotation, and the creation of an interactive user interface that fosters user engagement and close reading. By emphasizing the logical integrity of textual content rather than relying solely on factual accuracy, Skeptik offers a comprehensive solution to combat potential misinformation in journalism. Ultimately, our framework aims to improve critical reading and protect the public from deceptive information online and enhance the overall credibility of news media.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18499v1</guid>
      <category>cs.HC</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arlen Fan, Fan Lei, Steven R. Corman, Ross Maciejewski</dc:creator>
    </item>
    <item>
      <title>Beyond prior knowledge: The predictive role of knowledge-building in Tutor Learning</title>
      <link>https://arxiv.org/abs/2508.18545</link>
      <description>arXiv:2508.18545v1 Announce Type: new 
Abstract: When adopting the role of a teacher in learning-by-teaching environments, students often struggle to engage in knowledge-building activities, such as providing explanations and addressing misconceptions. Instead, they frequently default to knowledge-telling behaviors, where they simply dictate what they already know or what to do without deeper reflection, thereby limiting learning. Teachable agents, particularly those capable of posing persistent follow-up questions, have been shown to encourage students (tutors) to shift from knowledge-telling to knowledge-building and enhance tutor learning. Tutor learning encompasses two interrelated types of knowledge: conceptual and procedural knowledge. Research has established a bidirectional relationship between these knowledge types, where improvements in one reinforce the other. This study investigates the role of knowledge-building in mediating the bidirectional relationship between procedural and conceptual learning. Our findings revealed a stable bidirectional relationship between procedural and conceptual knowledge, with higher post-test scores observed among students who engaged in knowledge-building, regardless of their procedural and conceptual pre-test performance. This suggests that knowledge-building serves as a crucial mechanism bridging the gap between students with low prior knowledge and higher conceptual and procedural learning gain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18545v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tasmia Shahriar, Mia Ameen, Aditi Mallavarapu, Shiyan Jiang, Noboru Matsuda</dc:creator>
    </item>
    <item>
      <title>Gamification of Immersive Cervical Rehabilitation Exercises in VR: An Exploratory Study on Chin Tuck and Range of Motion Exercises</title>
      <link>https://arxiv.org/abs/2508.18580</link>
      <description>arXiv:2508.18580v1 Announce Type: new 
Abstract: Chronic neck pain is a prevalent condition that affects millions of individuals worldwide, causing significant individual suffering and socioeconomic burdens. Although exercise rehabilitation is a staple in relieving pain and improving muscle function for the condition, traditional one-on-one rehabilitation sessions are costly and suffer from poor adherence and accessibility for the patients. Thanks to the increasing accessibility and recent advancements in sensing and display technology, virtual reality (VR) offers the potential to tackle the challenges in traditional exercise rehabilitation, particularly through gamification. However, still in its infancy, VR-based neck exercise rehabilitation lacks exploration in effective gamification strategies and existing prototypes. To address the knowledge gap, we conduct an exploratory study on the gamification strategies for VR-based cervical rehabilitation exercises by using chin tuck and neck range of motion exercises as examples. Specifically, with different game themes, we investigate a survival and level progression strategy for muscle strengthening (chin tuck) exercise for the first time, and the suitability of ambient reward for a neck range of motion exercise. Through a preliminary user study, we assess the proposed novel VR neck rehabilitation games and they demonstrate excellent usability, engagement, and perceived health value.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18580v1</guid>
      <category>cs.HC</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Haitham Abdelsalam, Chanelle Montpetit, Arash Harirpoush, Maryse Fortin, Yiming Xiao</dc:creator>
    </item>
    <item>
      <title>Portable Silent Room: Exploring VR Design for Anxiety and Emotion Regulation for Neurodivergent Women and Non-Binary Individuals</title>
      <link>https://arxiv.org/abs/2508.18591</link>
      <description>arXiv:2508.18591v1 Announce Type: new 
Abstract: Neurodivergent individuals, particularly those with Autism and Attention Deficit Hyperactivity Disorder (ADHD), frequently experience anxiety, panic attacks, meltdowns, and emotional dysregulation due to societal pressures and inadequate accommodations. These challenges are especially pronounced for neurodivergent women and non-binary individuals navigating intersecting barriers of neurological differences and gender expectations. This research investigates virtual reality (VR) as a portable safe space for emotional regulation, addressing challenges of sensory overload and motion sickness while enhancing relaxation capabilities. Our mixed-methods approach included an online survey (N=223) and an ideation workshop (N=32), which provided key design elements for creating effective calming VR environments. Based on these findings, we developed and iteratively tested VR prototypes with neurodivergent women and non-binary participants (N=12), leading to a final version offering enhanced adaptability to individual sensory needs. This final prototype underwent a comprehensive evaluation with 25 neurodivergent participants to assess its effectiveness as a regulatory tool. This research contributes to the development of inclusive, adaptive VR environments that function as personalized "portable silent rooms" offering neurodivergent individuals on-demand access to sensory regulation regardless of physical location.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18591v1</guid>
      <category>cs.HC</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kinga Skiers, Yun Suen Pai, Marina Nakagawa, Kouta Minamizawa, Giulia Barbareschi</dc:creator>
    </item>
    <item>
      <title>Enhancing XAI Interpretation through a Reverse Mapping from Insights to Visualizations</title>
      <link>https://arxiv.org/abs/2508.18640</link>
      <description>arXiv:2508.18640v1 Announce Type: new 
Abstract: As AI systems become increasingly integrated into high-stakes domains, enabling users to accurately interpret model behavior is critical. While AI explanations can be provided, users often struggle to reason effectively with these explanations, limiting their ability to validate or learn from AI decisions. To address this gap, we introduce Reverse Mapping, a novel approach that enhances visual explanations by incorporating user-derived insights back into the explanation workflow. Our system extracts structured insights from free-form user interpretations using a large language model and maps them back onto visual explanations through interactive annotations and coordinated multi-view visualizations. Inspired by the verification loop in the visualization knowledge generation model, this design aims to foster more deliberate, reflective interaction with AI explanations. We demonstrate our approach in a prototype system with two use cases and qualitative user feedback.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18640v1</guid>
      <category>cs.HC</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aniket Nuthalapati, Nicholas Hinds, Brian Y. Lim, Qianwen Wang</dc:creator>
    </item>
    <item>
      <title>R\'ECITKIT: A Spatial Toolkit for Designing and Evaluating Human-Centered Immersive Data Narratives</title>
      <link>https://arxiv.org/abs/2508.18670</link>
      <description>arXiv:2508.18670v1 Announce Type: new 
Abstract: Spatial computing presents new opportunities for immersive data storytelling, yet there is limited guidance on how to build such experiences or adapt traditional narrative visualizations to this medium. We introduce a toolkit, R\'ECITKIT for supporting spatial data narratives in head-mounted display (HMD) environments. The toolkit allows developers to create interactive dashboards, tag data attributes as spatial assets to 3D models and immersive scenes, generate text and audio narratives, enabling dynamic filtering, and hierarchical drill-down data discoverability. To demonstrate the utility of the toolkit, we developed Charles Minard's historical flow map of Napoleon's 1812 campaign in Russia as an immersive experience on Apple Vision Pro. We conducted a preliminary evaluation with 21 participants that comprised two groups: developers, who evaluated the toolkit by authoring spatial stories and consumers, who provided feedback on the Minard app's narrative clarity, interaction design, and engagement. Feedback highlighted how spatial interactions and guided narration enhanced insight formation, with participants emphasizing the benefits of physical manipulation (e.g., gaze, pinch, navigation) for understanding temporal and geographic data. Participants also identified opportunities for future enhancement, including improved interaction affordance visibility, customizable storytelling logic, and integration of contextual assets to support user orientation. These findings contribute to the broader discourse on toolkit-driven approaches to immersive data storytelling across domains such as education, decision support, and exploratory analytics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18670v1</guid>
      <category>cs.HC</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vidya Setlur, Samuel Ridet</dc:creator>
    </item>
    <item>
      <title>Long-Term Variability in Physiological-Arousal Relationships for Robust Emotion Estimation</title>
      <link>https://arxiv.org/abs/2508.18782</link>
      <description>arXiv:2508.18782v1 Announce Type: new 
Abstract: Estimating emotional states from physiological signals is a central topic in affective computing and psychophysiology. While many emotion estimation systems implicitly assume a stable relationship between physiological features and subjective affect, this assumption has rarely been tested over long timeframes. This study investigates whether such relationships remain consistent across several months within individuals. We developed a custom measurement system and constructed a longitudinal dataset by collecting physiological signals--including blood volume pulse, electrodermal activity (EDA), skin temperature, and acceleration--along with self-reported emotional states from 24 participants over two three-month periods. Data were collected in naturalistic working environments, allowing analysis of the relationship between physiological features and subjective arousal in everyday contexts. We examined how physiological--arousal relationships evolve over time by using Explainable Boosting Machines (EBMs) to ensure model interpretability. A model trained on 1st-period data showed a 5\% decrease in accuracy when tested on 2nd-period data, indicating long-term variability in physiological--arousal associations. EBM-based comparisons further revealed that while heart rate remained a relatively stable predictor, minimum EDA exhibited substantial individual-level fluctuations between periods. While the number of participants is limited, these findings highlight the need to account for temporal variability in physiological--arousal relationships and suggest that emotion estimation models should be periodically updated -- e.g., every five months -- based on observed shift trends to maintain robust performance over time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18782v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hiroto Sakimura, Takayuki Nagaya, Tomoki Nishi, Tetsuo Kurahashi, Katsunori Kohda, Nobuhiko Muramoto</dc:creator>
    </item>
    <item>
      <title>Insights into User Interface Innovations from a Design Thinking Workshop at deRSE25</title>
      <link>https://arxiv.org/abs/2508.18784</link>
      <description>arXiv:2508.18784v1 Announce Type: new 
Abstract: Large Language Models have become widely adopted tools due to their versatile capabilities, yet their user interfaces remain limited, often following rigid, linear interaction paradigms. In this paper, we present insights from a design thinking workshop held at the deRSE25 conference aiming at collaboratively developing innovative user interface concepts for LLMs. During the workshop, participants identified common use cases, evaluated the strengths and shortcomings of current LLM interfaces, and created visualizations of new interaction concepts emphasizing flexible context management, dynamic conversation branching, and enhanced mechanisms for user control. We describe how these participant-generated ideas advanced our own whiteboard-based UI approach. The ongoing development of this interface is guided by the human-centered design process - an iterative, user-focused methodology that emphasizes continuous refinement through user feedback. Broader implications for future LLM interface development are discussed, advocating for increased attention to UI innovation grounded in user-centered design principles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18784v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Maximilian Frank, Simon Lund</dc:creator>
    </item>
    <item>
      <title>PRIMMDebug: A Debugging Teaching Aid For Secondary Students</title>
      <link>https://arxiv.org/abs/2508.18875</link>
      <description>arXiv:2508.18875v1 Announce Type: new 
Abstract: Debugging is often a challenging and infuriating experience for secondary school students learning their first text-based programming language. Many students resort to ineffective debugging strategies, making success with solving errors unlikely and emotional distress common. Developing tools that encourage students to adopt a more systematic and reflective approach to debugging is therefore an important, but lacking, area of research. This paper presents PRIMMDebug, a debugging teaching aid for secondary school students learning text-based programming. The aid consists of an online tool that takes students through the steps of a systematic debugging process based on PRIMM, a framework for teaching programming. The tool promotes a reflective approach to debugging by heavily encouraging students to articulate their thoughts throughout the PRIMMDebug process while simultaneously limiting their ability to run and edit code. To evaluate the tool, a set of students from four secondary schools were taught with PRIMMDebug over several lessons. Survey results and log data analysis show that students were generally reluctant to engage with the systematicity and reflection that the tool encourages. Given that related work on systematic debugging has reported similar challenges, we end by considering how these approaches could be refined to help more students benefit from them.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18875v1</guid>
      <category>cs.HC</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Laurie Gale, Sue Sentance</dc:creator>
    </item>
    <item>
      <title>DESAMO: A Device for Elder-Friendly Smart Homes Powered by Embedded LLM with Audio Modality</title>
      <link>https://arxiv.org/abs/2508.18918</link>
      <description>arXiv:2508.18918v1 Announce Type: new 
Abstract: We present DESAMO, an on-device smart home system for elder-friendly use powered by Audio LLM, that supports natural and private interactions. While conventional voice assistants rely on ASR-based pipelines or ASR-LLM cascades, often struggling with the unclear speech common among elderly users and unable to handle non-speech audio, DESAMO leverages an Audio LLM to process raw audio input directly, enabling a robust understanding of user intent and critical events, such as falls or calls for help.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18918v1</guid>
      <category>cs.HC</category>
      <category>cs.SD</category>
      <category>eess.AS</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Youngwon Choi, Donghyuk Jung, Hwayeon Kim</dc:creator>
    </item>
    <item>
      <title>Impact Assessment Card: Communicating Risks and Benefits of AI Uses</title>
      <link>https://arxiv.org/abs/2508.18919</link>
      <description>arXiv:2508.18919v1 Announce Type: new 
Abstract: Communicating the risks and benefits of AI is important for regulation and public understanding. Yet current methods such as technical reports often exclude people without technical expertise. Drawing on HCI research, we developed an Impact Assessment Card to present this information more clearly. We held three focus groups with a total of 12 participants who helped identify design requirements and create early versions of the card. We then tested a refined version in an online study with 235 participants, including AI developers, compliance experts, and members of the public selected to reflect the U.S. population by age, sex, and race. Participants used either the card or a full impact assessment report to write an email supporting or opposing a proposed AI system. The card led to faster task completion and higher-quality emails across all groups. We discuss how design choices can improve accessibility and support AI governance. Examples of cards are available at: https://social-dynamics.net/ai-risks/impact-card/.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18919v1</guid>
      <category>cs.HC</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3757482</arxiv:DOI>
      <dc:creator>Edyta Bogucka, Marios Constantinides, Sanja \v{S}\'cepanovi\'c, Daniele Quercia</dc:creator>
    </item>
    <item>
      <title>Reading minds on the road: decoding perceived risk in automated vehicles through 140K+ ratings</title>
      <link>https://arxiv.org/abs/2508.19121</link>
      <description>arXiv:2508.19121v1 Announce Type: new 
Abstract: Perceived risk in automated vehicles (AVs) can create the very danger that automation is meant to prevent: a frightened rider may hesitate when seconds matter, misjudge hazards, or disengage. However, measuring how perceived risk evolves in real time during driving remains challenging, leaving a gap in decoding such hidden psychological states. Here, we present a novel method to time-continuously measure and decode perceived risk. We conducted a controlled experiment where 2,164 participants viewed high-fidelity videos of common highway driving scenes and provided 141,628 discrete safety ratings. Through continuous-signal reconstruction of the discrete ratings, we obtained 236 hours of time-continuous perceived risk data - the largest perceived risk dataset to date. Leveraging this dataset, we trained deep neural networks that predict moment-by-moment perceived risk from vehicle kinematics with a mean relative error below $3\%$. Explainable AI analysis uncovers which factors determine perceived risk in real time. Our findings demonstrate a new paradigm for quantifying dynamic passenger experience and psychological constructs in real time. These findings can guide the design of AVs and other machines that operate in close proximity to people, adjusting behaviour before trust erodes, and help realise automation's benefits in transport, healthcare, and service robotics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.19121v1</guid>
      <category>cs.HC</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaolin He, Zirui Li, Xinwei Wang, Riender Happee, Meng Wang</dc:creator>
    </item>
    <item>
      <title>Beyond Competitive Gaming: How Casual Players Evaluate and Respond to Teammate Performance</title>
      <link>https://arxiv.org/abs/2508.19230</link>
      <description>arXiv:2508.19230v1 Announce Type: new 
Abstract: Teammate performance evaluation fundamentally shapes intervention design in video games. However, our current understanding stems primarily from competitive E-Sports contexts where individual performance directly impacts outcomes. This research addresses whether performance evaluation mechanisms and behavioural responses identified in competitive games generalize to casual cooperative games. We investigated how casual players evaluate teammate competence and respond behaviourally in a controlled between-subjects experiment (N=23). We manipulated confederate performance in Overcooked 2, combining observations, NASA TLX self-reports, and interviews. We present two key findings. (1) Observations revealed frustration behaviours completely absent in self-report data. Thus, these instruments assess fundamentally distinct constructs. (2) Participants consistently evaluated teammate performance through relative comparison rather than absolute metrics. This contradicts task-performance operationalizations dominant in competitive gaming research. Hence, performance evaluation frameworks from competitive contexts cannot be directly applied to casual cooperative games. We provide empirical evidence that performance evaluation in casual games requires a comparative operationalization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.19230v1</guid>
      <category>cs.HC</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3744736.3749343</arxiv:DOI>
      <dc:creator>Kaushall Senthil Nathan, Jieun Lee, Derrick M. Wang, Geneva M. Smith, Eugene Kukshinov, Daniel Harley, Lennart E. Nacke</dc:creator>
    </item>
    <item>
      <title>A Fast and Minimal System to Identify Depression Using Smartphones: Explainable Machine Learning-Based Approach</title>
      <link>https://arxiv.org/abs/2508.18301</link>
      <description>arXiv:2508.18301v1 Announce Type: cross 
Abstract: Background: Existing robust, pervasive device-based systems developed in recent years to detect depression require data collected over a long period and may not be effective in cases where early detection is crucial.
  Objective: Our main objective was to develop a minimalistic system to identify depression using data retrieved in the fastest possible time.
  Methods: We developed a fast tool that retrieves the past 7 days' app usage data in 1 second (mean 0.31, SD 1.10 seconds). A total of 100 students from Bangladesh participated in our study, and our tool collected their app usage data. To identify depressed and nondepressed students, we developed a diverse set of ML models. We selected important features using the stable approach, along with 3 main types of feature selection (FS) approaches.
  Results: Leveraging only the app usage data retrieved in 1 second, our light gradient boosting machine model used the important features selected by the stable FS approach and correctly identified 82.4% (n=42) of depressed students (precision=75%, F1-score=78.5%). Moreover, after comprehensive exploration, we presented a parsimonious stacking model where around 5 features selected by the all-relevant FS approach Boruta were used in each iteration of validation and showed a maximum precision of 77.4% (balanced accuracy=77.9%). A SHAP analysis of our best models presented behavioral markers that were related to depression.
  Conclusions: Due to our system's fast and minimalistic nature, it may make a worthwhile contribution to identifying depression in underdeveloped and developing regions. In addition, our detailed discussion about the implication of our findings can facilitate the development of less resource-intensive systems to better understand students who are depressed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18301v1</guid>
      <category>cs.LG</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.2196/28848</arxiv:DOI>
      <dc:creator>Md Sabbir Ahmed, Nova Ahmed</dc:creator>
    </item>
    <item>
      <title>Toward Generalized Autonomous Agents: A Neuro-Symbolic AI Framework for Integrating Social and Technical Support in Education</title>
      <link>https://arxiv.org/abs/2508.18406</link>
      <description>arXiv:2508.18406v1 Announce Type: cross 
Abstract: One of the enduring challenges in education is how to empower students to take ownership of their learning by setting meaningful goals, tracking their progress, and adapting their strategies when faced with setbacks. Research has shown that this form of leaner-centered learning is best cultivated through structured, supportive environments that promote guided practice, scaffolded inquiry, and collaborative dialogue. In response, educational efforts have increasingly embraced artificial-intelligence (AI)-powered digital learning environments, ranging from educational apps and virtual labs to serious games. Recent advances in large language models (LLMs) and neuro-symbolic systems, meanwhile, offer a transformative opportunity to reimagine how support is delivered in digital learning environments. LLMs are enabling socially interactive learning experiences and scalable, cross-domain learning support that can adapt instructional strategies across varied subjects and contexts. In parallel, neuro-symbolic AI provides new avenues for designing these agents that are not only adaptive but also scalable across domains. Based on these remarks, this paper presents a multi-agent, neuro-symbolic framework designed to resolve the aforementioned challenges. The framework assigns distinct pedagogical roles to specialized agents: an RL-based 'tutor' agent provides authoritative, non-verbal scaffolding, while a proactive, LLM-powered 'peer' agent facilitates the social dimensions of learning. While prior work has explored such agents in isolation, our framework's novelty lies in unifying them through a central educational ontology. Through case studies in both college-level and middle school settings, we demonstrate the framework's adaptability across domains. We conclude by outlining key insights and future directions for advancing AI-driven learning environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18406v1</guid>
      <category>cs.MA</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ryan Hare, Ying Tang</dc:creator>
    </item>
    <item>
      <title>DTInsight: A Tool for Explicit, Interactive, and Continuous Digital Twin Reporting</title>
      <link>https://arxiv.org/abs/2508.18431</link>
      <description>arXiv:2508.18431v1 Announce Type: cross 
Abstract: With Digital Twin (DT) construction and evolution occurring over time, stakeholders require tools to understand the current characteristics and conceptual architecture of the system at any time. We introduce DTInsight, a systematic and automated tool and methodology for producing continuous reporting for DTs. DTInsight offers three key features: (a) an interactive conceptual architecture visualization of DTs; (b) generation of summaries of DT characteristics based on ontological data; and (c) integration of these outputs into a reporting page within a continuous integration and continuous deployment (CI/CD) pipeline. Given a modeled description of the DT aligning to our DT Description Framework (DTDF), DTInsight enables up-to-date and detailed reports for enhanced stakeholder understanding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18431v1</guid>
      <category>cs.SE</category>
      <category>cs.ET</category>
      <category>cs.HC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>K\'erian Fiter, Louis Malassign\'e-Onfroy, Bentley Oakes</dc:creator>
    </item>
    <item>
      <title>The Accessibility Paradox: How Blind and Low Vision Employees Experience and Negotiate Accessibility in the Technology Industry</title>
      <link>https://arxiv.org/abs/2508.18492</link>
      <description>arXiv:2508.18492v1 Announce Type: cross 
Abstract: Many technology companies aim to improve access and inclusion not only by making their products accessible but also by bringing people with disabilities into the tech workforce. We know less about how accessibility is experienced and negotiated by disabled workers within these organizations. Through interviews with 20 BLV workers across various tech companies, we uncover a persistent misalignment between organizational attempts at accessibility and the current realities of these employees. We introduce the concept of the accessibility paradox, which we define as the inherent tension between the productivity- and profit-driven nature of tech companies and their desire to hire and retain disabled workers. Focusing on the experiences of BLV workers, we show how the accessibility paradox manifests in their everyday workplace interactions, including digital infrastructure, accommodations processes and policies, ability assumptions, and competing priorities. We offer recommendations for future research and practice to understand and improve workplace accessibility and inclusion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18492v1</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3757666</arxiv:DOI>
      <dc:creator>Aparajita Marathe, Anne Marie Piper</dc:creator>
    </item>
    <item>
      <title>MATRIX: Multi-Agent simulaTion fRamework for safe Interactions and conteXtual clinical conversational evaluation</title>
      <link>https://arxiv.org/abs/2508.19163</link>
      <description>arXiv:2508.19163v1 Announce Type: cross 
Abstract: Despite the growing use of large language models (LLMs) in clinical dialogue systems, existing evaluations focus on task completion or fluency, offering little insight into the behavioral and risk management requirements essential for safety-critical systems. This paper presents MATRIX (Multi-Agent simulaTion fRamework for safe Interactions and conteXtual clinical conversational evaluation), a structured, extensible framework for safety-oriented evaluation of clinical dialogue agents.
  MATRIX integrates three components: (1) a safety-aligned taxonomy of clinical scenarios, expected system behaviors and failure modes derived through structured safety engineering methods; (2) BehvJudge, an LLM-based evaluator for detecting safety-relevant dialogue failures, validated against expert clinician annotations; and (3) PatBot, a simulated patient agent capable of producing diverse, scenario-conditioned responses, evaluated for realism and behavioral fidelity with human factors expertise, and a patient-preference study.
  Across three experiments, we show that MATRIX enables systematic, scalable safety evaluation. BehvJudge with Gemini 2.5-Pro achieves expert-level hazard detection (F1 0.96, sensitivity 0.999), outperforming clinicians in a blinded assessment of 240 dialogues. We also conducted one of the first realism analyses of LLM-based patient simulation, showing that PatBot reliably simulates realistic patient behavior in quantitative and qualitative evaluations. Using MATRIX, we demonstrate its effectiveness in benchmarking five LLM agents across 2,100 simulated dialogues spanning 14 hazard scenarios and 10 clinical domains.
  MATRIX is the first framework to unify structured safety engineering with scalable, validated conversational AI evaluation, enabling regulator-aligned safety auditing. We release all evaluation tools, prompts, structured scenarios, and datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.19163v1</guid>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.MA</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ernest Lim, Yajie Vera He, Jared Joselowitz, Kate Preston, Mohita Chowdhury, Louis Williams, Aisling Higham, Katrina Mason, Mariane Melo, Tom Lawton, Yan Jia, Ibrahim Habli</dc:creator>
    </item>
    <item>
      <title>Generative Interfaces for Language Models</title>
      <link>https://arxiv.org/abs/2508.19227</link>
      <description>arXiv:2508.19227v1 Announce Type: cross 
Abstract: Large language models (LLMs) are increasingly seen as assistants, copilots, and consultants, capable of supporting a wide range of tasks through natural conversation. However, most systems remain constrained by a linear request-response format that often makes interactions inefficient in multi-turn, information-dense, and exploratory tasks. To address these limitations, we propose Generative Interfaces for Language Models, a paradigm in which LLMs respond to user queries by proactively generating user interfaces (UIs) that enable more adaptive and interactive engagement. Our framework leverages structured interface-specific representations and iterative refinements to translate user queries into task-specific UIs. For systematic evaluation, we introduce a multidimensional assessment framework that compares generative interfaces with traditional chat-based ones across diverse tasks, interaction patterns, and query types, capturing functional, interactive, and emotional aspects of user experience. Results show that generative interfaces consistently outperform conversational ones, with humans preferring them in over 70% of cases. These findings clarify when and why users favor generative interfaces, paving the way for future advancements in human-AI interaction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.19227v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiaqi Chen, Yanzhe Zhang, Yutong Zhang, Yijia Shao, Diyi Yang</dc:creator>
    </item>
    <item>
      <title>Cluster-Aware Grid Layout</title>
      <link>https://arxiv.org/abs/2308.03651</link>
      <description>arXiv:2308.03651v2 Announce Type: replace 
Abstract: Grid visualizations are widely used in many applications to visually explain a set of data and their proximity relationships. However, existing layout methods face difficulties when dealing with the inherent cluster structures within the data. To address this issue, we propose a cluster-aware grid layout method that aims to better preserve cluster structures by simultaneously considering proximity, compactness, and convexity in the optimization process. Our method utilizes a hybrid optimization strategy that consists of two phases. The global phase aims to balance proximity and compactness within each cluster, while the local phase ensures the convexity of cluster shapes. We evaluate the proposed grid layout method through a series of quantitative experiments and two use cases, demonstrating its effectiveness in preserving cluster structures and facilitating analysis tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.03651v2</guid>
      <category>cs.HC</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TVCG.2023.3326934</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Visualization and Computer Graphics, vol. 3o, no. 1, pp. 240-250, 2024</arxiv:journal_reference>
      <dc:creator>Yuxing Zhou, Weikai Yang, Jiashu Chen, Changjian Chen, Zhiyang Shen, Xiaonan Luo, Lingyun Yu, Shixia Liu</dc:creator>
    </item>
    <item>
      <title>VR MRI Training for Adolescents: A Comparative Study of Gamified VR, Passive VR, 360{\deg} Video, and Traditional Educational Video</title>
      <link>https://arxiv.org/abs/2504.09955</link>
      <description>arXiv:2504.09955v2 Announce Type: replace 
Abstract: Meta Quest Store: https://www.meta.com/experiences/stanford-mri-simulator/8205539289482347/ Magnetic Resonance Imaging (MRI) can be a stressful experience for pediatric patients due to the loud acoustic environment, enclosed scanner bore, and a prolonged requirement to remain still. While sedation is commonly used to manage anxiety and motion, it carries clinical risks and logistical burdens. Traditional preparatory approaches, such as instructional videos and mock scans, often lack engagement for older children and adolescents. In this study, we present a comparative evaluation of four MRI preparation modalities: (1) a gamified virtual reality (VR) simulation that trains stillness through real-time feedback; (2) a passive VR experience replicating the MRI environment without interactivity; (3) a 360{\deg} first-person video of a real MRI procedure; and (4) a standard 2D educational video. Using a within-subjects design (N = 11, ages 10-16), we assess each method's impact on head motion data, anxiety reduction, procedural preparedness, usability, cognitive workload, and subjective preference. Results show that the gamified VR condition has significantly lower head motion (p &lt; 0.001) and yielded the highest preparedness scores (p &lt; 0.05). Head motion data were significantly correlated with learning outcomes (p &lt; 0.01), suggesting that behavioral performance in VR strongly indicates procedural readiness. While all modalities reduced anxiety and were rated usable, interactive VR was preferred by most participants and demonstrated unique advantages in promoting engagement and behavioral rehearsal. We conclude with design recommendations for designing immersive simulations and integrating VR training into pediatric imaging workflows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.09955v2</guid>
      <category>cs.HC</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yue Yang, Mengyao Guo, Yuxuan Wu, Wally Niu, Emmanuel A Corona, Bruce Daniel, Christoph Leuze, Fred Baik</dc:creator>
    </item>
    <item>
      <title>A Taxonomy of Questions for Critical Reflection in Machine-Assisted Decision-Making</title>
      <link>https://arxiv.org/abs/2504.12830</link>
      <description>arXiv:2504.12830v3 Announce Type: replace 
Abstract: Decision-makers run the risk of relying too much on machine recommendations, which is associated with lower cognitive engagement. Reflection has been shown to increase cognitive engagement and improve critical thinking and therefore decision-making. Questions are a means to stimulate reflection, but there is a research gap regarding the systematic creation and use of relevant questions for machine-assisted decision-making. We therefore present a taxonomy of questions aimed at promoting reflection and cognitive engagement in order to stimulate a deliberate decision-making process. Our taxonomy builds on the Socratic questioning method and a question bank for explainable AI. As a starting point, we focus on clinical decision-making. Brief discussions with two medical and three educational researchers provide feedback on the relevance and expected benefits of our taxonomy. Our work contributes to research on mitigating overreliance in human-AI interactions and aims to support effective human oversight as required by the European AI Act.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.12830v3</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Simon W. S. Fischer, Hanna Schraffenberger, Serge Thill, Pim Haselager</dc:creator>
    </item>
    <item>
      <title>New Kid in the Classroom: Exploring Student Perceptions of AI Coding Assistants</title>
      <link>https://arxiv.org/abs/2507.22900</link>
      <description>arXiv:2507.22900v2 Announce Type: replace 
Abstract: The arrival of AI coding assistants in educational settings presents a paradigm shift, introducing a "new kid in the classroom" for both students and instructors. This exploratory study addresses how these tools are shaping the experiences of novice programmers in an introductory programming course. Through a two-part exam, we investigated student perceptions by first providing access to AI support for a programming task and then requiring an extension of the solution without it. We collected Likert-scale and open-ended responses from 20 students to understand their perceptions on the challenges they faced. Our findings reveal that students perceived AI tools as helpful for grasping code concepts and boosting their confidence during the initial development phase. However, a noticeable difficulty emerged when students were asked to work unaided, pointing to potential overreliance and gaps in foundational knowledge transfer. These insights highlight a critical need for new pedagogical approaches that integrate AI effectively while effectively enhancing core programming skills, rather than impersonating them.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.22900v2</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sergio Rojas-Galeano</dc:creator>
    </item>
    <item>
      <title>Prompting with Sign Parameters for Low-resource Sign Language Instruction Generation</title>
      <link>https://arxiv.org/abs/2508.16076</link>
      <description>arXiv:2508.16076v2 Announce Type: replace 
Abstract: Sign Language (SL) enables two-way communication for the deaf and hard-of-hearing community, yet many sign languages remain under-resourced in the AI space. Sign Language Instruction Generation (SLIG) produces step-by-step textual instructions that enable non-SL users to imitate and learn SL gestures, promoting two-way interaction. We introduce BdSLIG, the first Bengali SLIG dataset, used to evaluate Vision Language Models (VLMs) (i) on under-resourced SLIG tasks, and (ii) on long-tail visual concepts, as Bengali SL is unlikely to appear in the VLM pre-training data. To enhance zero-shot performance, we introduce Sign Parameter-Infused (SPI) prompting, which integrates standard SL parameters, like hand shape, motion, and orientation, directly into the textual prompts. Subsuming standard sign parameters into the prompt makes the instructions more structured and reproducible than free-form natural text from vanilla prompting. We envision that our work would promote inclusivity and advancement in SL learning systems for the under-resourced communities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16076v2</guid>
      <category>cs.HC</category>
      <category>cs.CV</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Md Tariquzzaman, Md Farhan Ishmam, Saiyma Sittul Muna, Md Kamrul Hasan, Hasan Mahmud</dc:creator>
    </item>
    <item>
      <title>Benchmarking XAI Explanations with Human-Aligned Evaluations</title>
      <link>https://arxiv.org/abs/2411.02470</link>
      <description>arXiv:2411.02470v2 Announce Type: replace-cross 
Abstract: We introduce PASTA (Perceptual Assessment System for explanaTion of Artificial Intelligence), a novel human-centric framework for evaluating eXplainable AI (XAI) techniques in computer vision. Our first contribution is the creation of the PASTA-dataset, the first large-scale benchmark that spans a diverse set of models and both saliency-based and concept-based explanation methods. This dataset enables robust, comparative analysis of XAI techniques based on human judgment. Our second contribution is an automated, data-driven benchmark that predicts human preferences using the PASTA-dataset. This scoring called PASTA-score method offers scalable, reliable, and consistent evaluation aligned with human perception. Additionally, our benchmark allows for comparisons between explanations across different modalities, an aspect previously unaddressed. We then propose to apply our scoring method to probe the interpretability of existing models and to build more human interpretable XAI methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02470v2</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>R\'emi Kazmierczak, Steve Azzolin, Elo\"ise Berthier, Anna Hedstr\"om, Patricia Delhomme, David Filliat, Nicolas Bousquet, Goran Frehse, Massimiliano Mancini, Baptiste Caramiaux, Andrea Passerini, Gianni Franchi</dc:creator>
    </item>
    <item>
      <title>Perception Gaps in Risk, Benefit, and Value Between Experts and Public Challenge Socially Accepted AI</title>
      <link>https://arxiv.org/abs/2412.01459</link>
      <description>arXiv:2412.01459v2 Announce Type: replace-cross 
Abstract: Artificial Intelligence (AI) is reshaping many societal domains, raising critical questions about its risks, benefits, and the potential misalignment between public and academic perspectives. This study examines how the general public (N=1110) -- individuals who interact with or are impacted by AI technologies -- and academic AI experts (N=119) -- those elites shaping AI development -- perceive AI's capabilities and impact across 71 scenarios. These scenarios span domains such as sustainability, healthcare, job performance, societal inequality, art, and warfare. Participants evaluated these scenarios across four dimensions using the psychometric model: likelihood, perceived risk and benefit, and overall value (or sentiment). The results suggest significant differences: experts consistently anticipate higher probabilities, perceive lower risks, report greater benefits, and express more positive sentiment toward AI compared to the non-experts. Moreover, both groups apply different weighting schemes: experts discount risk more heavily relative to benefit than non-experts. Visual mappings of these evaluations uncover areas convergent evaluations (e.g., AI performing medical diagnoses or criminal use) as well as tension points (e.g., decision of legal cases, political decision making), highlighting areas where communication and policy interventions may be needed. These findings underscore a critical translational challenge: if AI research and deployment are to align with societal priorities, the perception gap between developers and the public must be better understood and addressed. Our results provide an empirical foundation for value-sensitive AI governance and trust-building strategies across stakeholder groups.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01459v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Philipp Brauner, Felix Glawe, Gian Luca Liehner, Luisa Vervier, Martina Ziefle</dc:creator>
    </item>
    <item>
      <title>Cultural Dimensions of AI Perception: Charting Expectations, Risks, Benefits, Tradeoffs, and Value in Germany and China</title>
      <link>https://arxiv.org/abs/2412.13841</link>
      <description>arXiv:2412.13841v2 Announce Type: replace-cross 
Abstract: As artificial intelligence (AI) continues to advance, understanding public perceptions -- including biases, risks, and benefits -- is essential for guiding research priorities and AI alignment, shaping public discourse, and informing policy. This exploratory study investigates cultural differences in mental models of AI using 71 imaginaries of AI's potential futures. Drawing on cross-cultural convenience samples from Germany (N=52) and China (N=60), we identify significant differences in expectations, evaluations, and risk-benefit tradeoffs. Participants from Germany generally provided more cautious assessments, whereas participants from China expressed greater optimism regarding AI's societal benefits. Chinese participants exhibited relatively balanced risk-benefit tradeoffs ($\beta=-0.463$ for risk and $\beta=+0.484$ for benefit, $r^2=.630$). In contrast, German participants placed greater emphasis on AI's benefits and comparatively less on risks ($\beta=-0.337$ for risk and $\beta=+0.715$ for benefit, $r^2=.839$). Visual cognitive maps illustrate these contrasts, offering new perspectives on how cultural contexts shape AI acceptance. Our findings highlight key factors influencing public perception and provide insights for aligning AI with societal values and promoting equitable and culturally sensitive integration of AI technologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13841v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Philipp Brauner, Felix Glawe, Gian Luca Liehner, Luisa Vervier, Martina Ziefle</dc:creator>
    </item>
    <item>
      <title>TableTalk: Scaffolding Spreadsheet Development with a Language Agent</title>
      <link>https://arxiv.org/abs/2502.09787</link>
      <description>arXiv:2502.09787v2 Announce Type: replace-cross 
Abstract: Spreadsheet programming is challenging. Programmers use spreadsheet programming knowledge (e.g., formulas) and problem-solving skills to combine actions into complex tasks. Advancements in large language models have introduced language agents that observe, plan, and perform tasks, showing promise for spreadsheet creation. We present TableTalk, a spreadsheet programming agent embodying three design principles -- scaffolding, flexibility, and incrementality -- derived from studies with seven spreadsheet programmers and 85 Excel templates. TableTalk guides programmers through structured plans based on professional workflows, generating three potential next steps to adapt plans to programmer needs. It uses pre-defined tools to generate spreadsheet components and incrementally build spreadsheets. In a study with 20 programmers, TableTalk produced higher-quality spreadsheets 2.3 times more likely to be preferred than the baseline. It reduced cognitive load and thinking time by 12.6%. From this, we derive design guidelines for agentic spreadsheet programming tools and discuss implications on spreadsheet programming, end-user programming, AI-assisted programming, and human-agent collaboration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09787v2</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jenny T. Liang, Aayush Kumar, Yasharth Bajpai, Sumit Gulwani, Vu Le, Chris Parnin, Arjun Radhakrishna, Ashish Tiwari, Emerson Murphy-Hill, Guastavo Soares</dc:creator>
    </item>
    <item>
      <title>Collaborative Evaluation of Deepfake Text with Deliberation-Enhancing Dialogue Systems</title>
      <link>https://arxiv.org/abs/2503.04945</link>
      <description>arXiv:2503.04945v2 Announce Type: replace-cross 
Abstract: The proliferation of generative models has presented significant challenges in distinguishing authentic human-authored content from deepfake content. Collaborative human efforts, augmented by AI tools, present a promising solution. In this study, we explore the potential of DeepFakeDeLiBot, a deliberation-enhancing chatbot, to support groups in detecting deepfake text. Our findings reveal that group-based problem-solving significantly improves the accuracy of identifying machine-generated paragraphs compared to individual efforts. While engagement with DeepFakeDeLiBot does not yield substantial performance gains overall, it enhances group dynamics by fostering greater participant engagement, consensus building, and the frequency and diversity of reasoning-based utterances. Additionally, participants with higher perceived effectiveness of group collaboration exhibited performance benefits from DeepFakeDeLiBot. These findings underscore the potential of deliberative chatbots in fostering interactive and productive group dynamics while ensuring accuracy in collaborative deepfake text detection. \textit{Dataset and source code used in this study will be made publicly available upon acceptance of the manuscript.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.04945v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jooyoung Lee, Xiaochen Zhu, Georgi Karadzhov, Tom Stafford, Andreas Vlachos, Dongwon Lee</dc:creator>
    </item>
    <item>
      <title>Investigating VR Accessibility Reviews for Users with Disabilities: A Qualitative Analysis</title>
      <link>https://arxiv.org/abs/2508.13051</link>
      <description>arXiv:2508.13051v2 Announce Type: replace-cross 
Abstract: Accessibility reviews provide valuable insights into both the limitations and benefits experienced by users with disabilities when using virtual reality (VR) applications. However, a comprehensive investigation into VR accessibility for users with disabilities is still lacking. To fill this gap, this study analyzes user reviews from the Meta and Steam stores of VR apps, focusing on the reported issues affecting users with disabilities. We applied selection criteria to 1,367,419 reviews from the top 40, the 20 most popular, and the 40 lowest-rated VR applications on both platforms. In total, 1,076 (0.078%) VR accessibility reviews referenced various disabilities across 100 VR applications. These applications were categorized into Action, Sports, Social, Puzzle, Horror, and Simulation, with Action receiving the highest number of accessibility related-reviews. We identified 16 different types of disabilities across six categories. Furthermore, we examined the causes of accessibility issues as reported by users with disabilities. Overall, VR accessibility reviews were predominantly under-supported.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13051v2</guid>
      <category>cs.SE</category>
      <category>cs.HC</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yi Wang, Chetan Arora, Xiao Liu, Thuong Hoang, ZHengxin Zhang, Henry Been Lirn Duh, John Grundy</dc:creator>
    </item>
    <item>
      <title>adder-viz: Real-Time Visualization Software for Transcoding Event Video</title>
      <link>https://arxiv.org/abs/2508.14996</link>
      <description>arXiv:2508.14996v2 Announce Type: replace-cross 
Abstract: Recent years have brought about a surge in neuromorphic ``event'' video research, primarily targeting computer vision applications. Event video eschews video frames in favor of asynchronous, per-pixel intensity samples. While much work has focused on a handful of representations for specific event cameras, these representations have shown limitations in flexibility, speed, and compressibility. We previously proposed the unified ADDER representation to address these concerns. This paper introduces numerous improvements to the adder-viz software for visualizing real-time event transcode processes and applications in-the-loop. The MIT-licensed software is available from a centralized repository at https://github.com/ac-freeman/adder-codec-rs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.14996v2</guid>
      <category>cs.MM</category>
      <category>cs.CV</category>
      <category>cs.HC</category>
      <category>eess.IV</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3746027.3756867</arxiv:DOI>
      <dc:creator>Andrew C. Freeman, Luke Reinkensmeyer</dc:creator>
    </item>
  </channel>
</rss>
