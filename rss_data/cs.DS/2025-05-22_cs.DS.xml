<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 23 May 2025 04:00:07 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 23 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Capacitated Fair-Range Clustering: Hardness and Approximation Algorithms</title>
      <link>https://arxiv.org/abs/2505.15905</link>
      <description>arXiv:2505.15905v1 Announce Type: new 
Abstract: Capacitated fair-range $k$-clustering generalizes classical $k$-clustering by incorporating both capacity constraints and demographic fairness. In this setting, each facility has a capacity limit and may belong to one or more demographic groups. The task is to select $k$ facilities as centers and assign each client to a center such that: ($a$) no center exceeds its capacity, ($b$) the number of centers selected from each group lies within specified lower and upper bounds (fair-range constraints), and ($c$) the clustering cost (e.g., $k$-median or $k$-means) is minimized.
  Prior work by Thejaswi et al. (KDD 2022) showed that satisfying fair-range constraints is NP-hard, making the problem inapproximable to any polynomial factor. We strengthen this result by showing that inapproximability persists even when the fair-range constraints are trivially satisfiable, highlighting the intrinsic computational complexity of the clustering task itself. Assuming standard complexity conjectures, we show that no non-trivial approximation is possible without exhaustively enumerating all $k$-subsets of the facility set. Notably, our inapproximability results hold even on tree metrics and when the number of groups is logarithmic in the size of the facility set.
  In light of these strong inapproximability results, we focus on a more practical setting where the number of groups is constant. In this regime, we design two approximation algorithms: ($i$) a polynomial-time $O(\log k)$- and $O(\log^2 k)$-approximation algorithm for the $k$-median and $k$-means objectives, and ($ii$) a fixed-parameter tractable algorithm parameterized by $k$, achieving $(3+\epsilon)$- and $(9 + \epsilon)$-approximation, respectively. These results match the best-known approximation guarantees for capacitated clustering without fair-range constraints and resolves an open question posed by Zang et al. (NeurIPS 2024).</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.15905v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Fri, 23 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ameet Gadekar, Suhas Thejaswi</dc:creator>
    </item>
    <item>
      <title>On the Complexity of Finding Approximate LCS of Multiple Strings</title>
      <link>https://arxiv.org/abs/2505.15992</link>
      <description>arXiv:2505.15992v1 Announce Type: new 
Abstract: Finding an Approximate Longest Common Substring (ALCS) within a given set $S=\{s_1,s_2,\ldots,s_m\}$ of $m \ge 2$ strings is a problem of particular importance in computational biology (e.g., identifying related mutations across multiple genetic sequences). In this paper, we study several ALCS problems that, for given integers $k$ and $t \le m$, require finding a longest string $u$ -- or a longest substring $u$ of any string in $S$ -- that lies within distance $k$ of at least one substring in $t$ distinct strings of $S$. Although two of these problems, denoted $k$-LCS and \textit{k-t} LCS, are NP-hard, nevertheless restricted variations of them under Hamming and edit distance can be solved in $O(N^2)$ and $O(k\ell N^2)$ time, respectively, where $\ell$ is the length of each string and $N=m\ell$. Further, we show that using the $k$-errata tree data structure, a restricted variation of the ALCS problem under both Hamming and edit distance can be computed in $O(mN\log^k \ell)$ time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.15992v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 23 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Hamed Hasibi, Neerja Mhaskar, W. F. Smyth</dc:creator>
    </item>
    <item>
      <title>Three Algorithms for Merging Hierarchical Navigable Small World Graphs</title>
      <link>https://arxiv.org/abs/2505.16064</link>
      <description>arXiv:2505.16064v1 Announce Type: new 
Abstract: This paper addresses the challenge of merging hierarchical navigable small world (HNSW) graphs, a critical operation for distributed systems, incremental indexing, and database compaction. We propose three algorithms for this task: Naive Graph Merge (NGM), Intra Graph Traversal Merge (IGTM), and Cross Graph Traversal Merge (CGTM). These algorithms differ in their approach to vertex selection and candidate collection during the merge process. We conceptualize graph merging as an iterative process with four key steps: processing vertex selection, candidate collection, neighborhood construction, and information propagation. Our experimental evaluation on the SIFT1M dataset demonstrates that IGTM and CGTM significantly reduce computational costs compared to naive approaches, requiring up to 70\% fewer distance computations while maintaining comparable search accuracy. Surprisingly, IGTM outperforms CGTM in efficiency, contrary to our initial expectations. The proposed algorithms enable efficient consolidation of separately constructed indices, supporting critical operations in modern vector databases and retrieval systems that rely on HNSW for similarity search.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.16064v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 23 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Ponomarenko</dc:creator>
    </item>
    <item>
      <title>On the Two Paths Theorem and the Two Disjoint Paths Problem</title>
      <link>https://arxiv.org/abs/2505.16431</link>
      <description>arXiv:2505.16431v1 Announce Type: new 
Abstract: A tuple (s1,t1,s2,t2) of vertices in a simple undirected graph is 2-linked when there are two vertex-disjoint paths respectively from s1 to t1 and s2 to t2. A graph is 2-linked when all such tuples are 2-linked. We give a new and simple proof of the ``two paths theorem'', a characterisation of edge-maximal graphs which are not 2-linked as webs: particular near triangulations filled with cliques. Our proof works by generalising the theorem, replacing the four vertices above by an arbitrary tuple; it does not require major theorems such as Kuratowski's or Menger's theorems. Instead it follows an inductive characterisation of generalised webs via parallel composition, a graph operation consisting in taking a disjoint union before identifying some pairs of vertices. We use the insights provided by this proof to design a simple O(nm) recursive algorithm for the ``two vertex-disjoint paths'' problem. This algorithm is constructive in that it returns either two disjoint paths, or an embedding of the input graph into a web.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.16431v1</guid>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Fri, 23 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Samuel Humeau (ENS de Lyon, LIP, PLUME), Damien Pous (PLUME, LIP, ENS de Lyon)</dc:creator>
    </item>
    <item>
      <title>Streaming Diameter of High-Dimensional Points</title>
      <link>https://arxiv.org/abs/2505.16720</link>
      <description>arXiv:2505.16720v1 Announce Type: new 
Abstract: We improve the space bound for streaming approximation of Diameter but also of Farthest Neighbor queries, Minimum Enclosing Ball and its Coreset, in high-dimensional Euclidean spaces. In particular, our deterministic streaming algorithms store $\mathcal{O}(\varepsilon^{-2}\log(\frac{1}{\varepsilon}))$ points. This improves by a factor of $\varepsilon^{-1}$ the previous space bound of Agarwal and Sharathkumar (SODA 2010), while offering a simpler and more complete argument. We also show that storing $\Omega(\varepsilon^{-1})$ points is necessary for a $(\sqrt{2}+\varepsilon)$-approximation of Farthest Pair or Farthest Neighbor queries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.16720v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 23 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Magn\'us M. Halld\'orsson, Nicolaos Matsakis, Pavel Vesel\'y</dc:creator>
    </item>
    <item>
      <title>Multi-Unit Combinatorial Prophet Inequalities</title>
      <link>https://arxiv.org/abs/2505.16054</link>
      <description>arXiv:2505.16054v1 Announce Type: cross 
Abstract: We consider a combinatorial auction setting where buyers have fractionally subadditive (XOS) valuations over the items and the seller's objective is to maximize the social welfare. A prophet inequality in this setting bounds the competitive ratio of sequential allocation (often using item pricing) against the hindsight optimum. We study the dependence of the competitive ratio on the number of copies, $k$, of each item.
  We show that the multi-unit combinatorial setting is strictly harder than its single-item counterpart in that there is a gap between the competitive ratios achieved by static item pricings in the two settings. However, if the seller is allowed to change item prices dynamically, it becomes possible to asymptotically match the competitive ratio of a single-item static pricing. We also develop a new non-adaptive anonymous multi-unit combinatorial prophet inequality where the item prices are determined up front but increase as the item supply decreases. Setting the item prices in our prophet inequality requires minimal information about the buyers' value distributions -- merely (an estimate of) the expected social welfare accrued by each item in the hindsight optimal solution suffices. Our non-adaptive pricing achieves a competitive ratio that increases strictly as a function of the item supply $k$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.16054v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Fri, 23 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shuchi Chawla, Trung Dang, Zhiyi Huang, Yifan Wang</dc:creator>
    </item>
    <item>
      <title>Contextual Learning for Stochastic Optimization</title>
      <link>https://arxiv.org/abs/2505.16829</link>
      <description>arXiv:2505.16829v1 Announce Type: cross 
Abstract: Motivated by stochastic optimization, we introduce the problem of learning from samples of contextual value distributions. A contextual value distribution can be understood as a family of real-valued distributions, where each sample consists of a context $x$ and a random variable drawn from the corresponding real-valued distribution $D_x$. By minimizing a convex surrogate loss, we learn an empirical distribution $D'_x$ for each context, ensuring a small L\'evy distance to $D_x$. We apply this result to obtain the sample complexity bounds for the learning of an $\epsilon$-optimal policy for stochastic optimization problems defined on an unknown contextual value distribution. The sample complexity is shown to be polynomial for the general case of strongly monotone and stable optimization problems, including Single-item Revenue Maximization, Pandora's Box and Optimal Stopping.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.16829v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <pubDate>Fri, 23 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anna Heuser, Thomas Kesselheim</dc:creator>
    </item>
    <item>
      <title>Quasi-optimal hierarchically semi-separable matrix approximation</title>
      <link>https://arxiv.org/abs/2505.16937</link>
      <description>arXiv:2505.16937v1 Announce Type: cross 
Abstract: We present a randomized algorithm for producing a quasi-optimal hierarchically semi-separable (HSS) approximation to an $N\times N$ matrix $A$ using only matrix-vector products with $A$ and $A^T$. We prove that, using $O(k \log(N/k))$ matrix-vector products and ${O}(N k^2 \log(N/k))$ additional runtime, the algorithm returns an HSS matrix $B$ with rank-$k$ blocks whose expected Frobenius norm error $\mathbb{E}[\|A - B\|_F^2]$ is at most $O(\log(N/k))$ times worse than the best possible approximation error by an HSS rank-$k$ matrix. In fact, the algorithm we analyze in a simple modification of an empirically effective method proposed by [Levitt &amp; Martinsson, SISC 2024]. As a stepping stone towards our main result, we prove two results that are of independent interest: a similar guarantee for a variant of the algorithm which accesses $A$'s entries directly, and explicit error bounds for near-optimal subspace approximation using projection-cost-preserving sketches. To the best of our knowledge, our analysis constitutes the first polynomial-time quasi-optimality result for HSS matrix approximation, both in the explicit access model and the matrix-vector product query model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.16937v1</guid>
      <category>math.NA</category>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <pubDate>Fri, 23 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Noah Amsel, Tyler Chen, Feyza Duman Keles, Diana Halikias, Cameron Musco, Christopher Musco, David Persson</dc:creator>
    </item>
    <item>
      <title>Longest Common Extensions with Wildcards: Trade-off and Applications</title>
      <link>https://arxiv.org/abs/2408.03610</link>
      <description>arXiv:2408.03610v2 Announce Type: replace 
Abstract: We study the Longest Common Extension (LCE) problem in a string containing wildcards. Wildcards (also called "don't cares" or "holes") are special characters that match any other character in the alphabet, similar to the character "?" in Unix commands or "." in regular expression engines.
  We consider the problem parametrized by $G$, the number of maximal contiguous groups of wildcards in the input string. Our main contribution is a simple data structure for this problem that can be built in $O(n (G/t) \log n)$ time, occupies $O(nG/t)$ space, and answers queries in $O(t)$ time, for any $t \in [1, G]$. Up to the $O(\log n)$ factor, this interpolates smoothly between the data structure of Crochemore et al. [JDA 2015], which has $O(nG)$ preprocessing time and space, and $O(1)$ query time, and a simple solution based on the "kangaroo jumping" technique [Landau and Vishkin, STOC 1986], which has $O(n)$ preprocessing time and space, and $O(G)$ query time.
  By establishing a connection between this problem and Boolean matrix multiplication, we show that our solution is optimal, up to subpolynomial factors, among combinatorial data structures when $G = \Omega(n^\epsilon)$ under a widely believed hypothesis. In addition, we develop a simple deterministic combinatorial algorithm for sparse Boolean matrix multiplication. We further establish a conditional lower bound for non-combinatorial data structures, stating that $O(nG/t^4)$ preprocessing time (resp. space) is optimal, up to subpolynomial factors, for any data structure with query time $t$ for a wide range of $t$ and $G$, assuming the well-established $\textsf{3SUM}$ (resp. $\textsf{Set-Disjointness}$) conjecture.
  Finally, we show that our data structure can be used to obtain efficient algorithms for approximate pattern matching and structural analysis of strings with wildcards.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.03610v2</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 23 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gabriel Bathie, Itai Boneh, Panagiotis Charalampopoulos, Jonas Ellert, Tatiana Starikovskaya</dc:creator>
    </item>
    <item>
      <title>Linear-space LCS enumeration with quadratic-time delay for two strings</title>
      <link>https://arxiv.org/abs/2504.05742</link>
      <description>arXiv:2504.05742v2 Announce Type: replace 
Abstract: Suppose we want to seek the longest common subsequences (LCSs) of two strings as informative patterns that explain the relationship between the strings. The dynamic programming algorithm gives us a table from which all LCSs can be extracted by traceback. However, the need for quadratic space to hold this table can be an obstacle when dealing with long strings. A question that naturally arises in this situation would be whether it is possible to exhaustively search for all LCSs one by one in a time-efficient manner using only a space linear in the LCS length, where we treat read-only memory for storing the strings as excluded from the space consumed. As a part of the answer to this question, we propose an $O(L)$-space algorithm that outputs all distinct LCSs of the strings one by one each in $O(n^2)$ time, where the strings are both of length $n$ and $L$ is the LCS length of the strings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05742v2</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 23 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yoshifumi Sakai</dc:creator>
    </item>
    <item>
      <title>Bandwidth vs BFS Width in Matrix Reordering, Graph Reconstruction, and Graph Drawing</title>
      <link>https://arxiv.org/abs/2505.10789</link>
      <description>arXiv:2505.10789v2 Announce Type: replace 
Abstract: We provide the first approximation quality guarantees for the Cuthull-McKee heuristic for reordering symmetric matrices to have low bandwidth, and we provide an algorithm for reconstructing bounded-bandwidth graphs from distance oracles with near-linear query complexity. To prove these results we introduce a new width parameter, BFS width, and we prove polylogarithmic upper and lower bounds on the BFS width of graphs of bounded bandwidth. Unlike other width parameters, such as bandwidth, pathwidth, and treewidth, BFS width can easily be computed in polynomial time. Bounded BFS width implies bounded bandwidth, pathwidth, and treewidth, which in turn imply fixed-parameter tractable algorithms for many problems that are NP-hard for general graphs. In addition to their applications to matrix ordering, we also provide applications of BFS width to graph reconstruction, to reconstruct graphs from distance queries, and graph drawing, to construct arc diagrams of small height.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.10789v2</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 23 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David Eppstein, Michael T. Goodrich, Songyu Liu</dc:creator>
    </item>
  </channel>
</rss>
