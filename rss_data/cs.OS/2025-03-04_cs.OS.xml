<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.OS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.OS</link>
    <description>cs.OS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.OS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 05 Mar 2025 03:02:56 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Scalable and Accurate Application-Level Crash-Consistency Testing via Representative Testing</title>
      <link>https://arxiv.org/abs/2503.01390</link>
      <description>arXiv:2503.01390v1 Announce Type: new 
Abstract: Crash consistency is essential for applications that must persist data. Crash-consistency testing has been commonly applied to find crash-consistency bugs in applications. The crash-state space grows exponentially as the number of operations in the program increases, necessitating techniques for pruning the search space. However, state-of-the-art crash-state space pruning is far from ideal. Some techniques look for known buggy patterns or bound the exploration for efficiency, but they sacrifice coverage and may miss bugs lodged deep within applications. Other techniques eliminate redundancy in the search space by skipping identical crash states, but they still fail to scale to larger applications.
  In this work, we propose representative testing: a new crash-state space reduction strategy that achieves high scalability and high coverage. Our key observation is that the consistency of crash states is often correlated, even if those crash states are not identical. We build Pathfinder, a crash-consistency testing tool that implements an update behaviors-based heuristic to approximate a small set of representative crash states.
  We evaluate Pathfinder on POSIX-based and MMIO-based applications, where it finds 18 (7 new) bugs across 8 production-ready systems. Pathfinder scales more effectively to large applications than prior works and finds 4x more bugs in POSIX-based applications and 8x more bugs in MMIO-based applications compared to state-of-the-art systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01390v1</guid>
      <category>cs.OS</category>
      <category>cs.PL</category>
      <category>cs.SE</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3720431</arxiv:DOI>
      <dc:creator>Yile Gu, Ian Neal, Jiexiao Xu, Shaun Christopher Lee, Ayman Said, Musa Haydar, Jacob Van Geffen, Rohan Kadekodi, Andrew Quinn, Baris Kasikci</dc:creator>
    </item>
    <item>
      <title>CHRONOS: Compensating Hardware Related Overheads with Native Multi Timer Support for Real-Time Operating Systems</title>
      <link>https://arxiv.org/abs/2503.01444</link>
      <description>arXiv:2503.01444v1 Announce Type: new 
Abstract: The management of timing constraints in a real-time operating system (RTOS) is usually realized through a global tick counter. This counter acts as the foundational time unit for all tasks in the systems. In order to establish a connection between a tick and an amount of elapsed time in the real world, often this tick counter is periodically incremented by a hardware timer. At a fixed interval, this timer generates an interrupt that increments the counter. In an RTOS, jobs can only become ready upon a timer tick. That means, during a tick interrupt, the tick counter will be incremented, jobs will be released, and potentially, a scheduling decision will be conducted to select a new job to be run. As this process naturally uses some processing time, it is beneficial regarding the system utilization to minimize the time spent in tick interrupts. In modern microcontrollers, multiple hardware timers are often available. To utilize multiple timers to reduce the overhead caused by tick interrupts, multiple methods are introduced in this paper. The number of interrupts that are triggered by these timers can then be reduced by mapping tasks to timers in such a manner that the greatest common divisor (GCD) of all task periods in a subset is maximized, and the GCD is adopted as the interrupt interval of the timer. To find an optimal mapping of tasks to timers, an MIQCP-model is presented that minimizes the overall number of tick interrupts that occur in a system, while ensuring a correct task release behavior. The presented methods are implemented in FreeRTOS and evaluated on an embedded system. The evaluation of the methods show, that compared to the baseline implementation in FreeRTOS that uses a single timer with a fixed period, the presented methods can provide a significant reduction in overhead of up to $\approx10\times$ in peak and up to $\approx 6\times$ in average.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01444v1</guid>
      <category>cs.OS</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kay Heider, Christian Hakert, Kuan-Hsun Chen, Jian-Jia Chen</dc:creator>
    </item>
    <item>
      <title>TUNA: Tuning Unstable and Noisy Cloud Applications</title>
      <link>https://arxiv.org/abs/2503.01801</link>
      <description>arXiv:2503.01801v1 Announce Type: new 
Abstract: Autotuning plays a pivotal role in optimizing the performance of systems, particularly in large-scale cloud deployments. One of the main challenges in performing autotuning in the cloud arises from performance variability. We first investigate the extent to which noise slows autotuning and find that as little as $5\%$ noise can lead to a $2.5$x slowdown in converging to the best-performing configuration. We measure the magnitude of noise in cloud computing settings and find that while some components (CPU, disk) have almost no performance variability, there are still sources of significant variability (caches, memory). Furthermore, variability leads to autotuning finding \emph{unstable} configurations. As many as $63.3\%$ of the configurations selected as "best" during tuning can have their performance degrade by $30\%$ or more when deployed. Using this as motivation, we propose a novel approach to improve the efficiency of autotuning systems by (a) detecting and removing outlier configurations and (b) using ML-based approaches to provide a more stable \emph{true} signal of de-noised experiment results to the optimizer. The resulting system, TUNA (\underline{T}uning \underline{U}nstable and \underline{N}oisy Cloud \underline{A}pplications) enables faster convergence and robust configurations. Tuning postgres running \texttt{mssales}, an enterprise production workload, we find that TUNA can lead to $1.88$x lower running time on average with $2.58x$ lower standard deviation compared to traditional sampling methodologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01801v1</guid>
      <category>cs.OS</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3689031.3717480</arxiv:DOI>
      <dc:creator>Johannes Freischuetz, Konstantinos Kanellis, Brian Kroth, Shivaram Venkataraman</dc:creator>
    </item>
    <item>
      <title>Boosting File Systems Elegantly: A Transparent NVM Write-ahead Log for Disk File Systems</title>
      <link>https://arxiv.org/abs/2408.02911</link>
      <description>arXiv:2408.02911v2 Announce Type: replace 
Abstract: We propose NVLog, an NVM-based write-ahead log for disk file systems, designed to transparently harness the high performance of NVM within the legacy storage stack. NVLog provides on-demand byte-granularity sync absorption, reserving the fast DRAM path for asynchronous operations, meanwhile occupying NVM space only temporarily. To accomplish this, we designed a highly efficient log structure, developed mechanisms to address heterogeneous crash consistency, optimized for small writes, and implemented robust crash recovery and garbage collection methods. Compared to previous solutions, NVLog is lighter, more stable, and delivers higher performance, all while leveraging the mature kernel software stack and avoiding data migration overhead. Experimental results demonstrate that NVLog can accelerate disk file systems by up to 15.09x and outperform NOVA and SPFS in various scenarios by up to 3.72x and 324.11x, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02911v2</guid>
      <category>cs.OS</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guoyu Wang, Xilong Che, Haoyang Wei, Shuo Chen, Puyi He, Juncheng Hu</dc:creator>
    </item>
  </channel>
</rss>
