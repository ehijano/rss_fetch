<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.TH</link>
    <description>econ.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 28 Mar 2025 04:00:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Doing Less for More: Consumer Search and Undertreatment in Credence Service Markets</title>
      <link>https://arxiv.org/abs/2503.21175</link>
      <description>arXiv:2503.21175v1 Announce Type: new 
Abstract: In many service markets, expert providers possess an information advantage over consumers regarding the necessary services, creating opportunities for fraudulent practices. These may involve overtreatment through unnecessary services or undertreatment with ineffective solutions that fail to address consumers' problems. When issues are resolved, consumers exit the market; when unresolved, they must decide whether to revisit the initial provider or seek a new one. Little is known about how repeated interactions and the consumer search process influence expert fraud and consumer welfare in such markets. We develop a dynamic game-theoretic model to examine the role of consumer search behavior and repeated interactions between consumers and service providers. We find that overtreatment and undertreatment can arise simultaneously in equilibrium. Interestingly, undertreatment-being less costly for the consumer-can initially act as a "hook" to induce acceptance of a minor treatment recommendation. When this minor treatment fails to resolve the issue, it can generate additional demand for a more expensive and serious treatment. This would arise when the cost of revisiting the initial provider is lower than that of searching for a new one. The extent of undertreatment exhibits a non-monotonic relationship with consumers' ex ante belief about the nature of their problems and the market's ethical level. Our results can shed light on how market ethical levels, provider capabilities and capacities, and consumer privacy protection policies interact with undertreatment and affect consumer welfare. Specifically, consumer welfare can decrease as the market becomes more ethical. Enhancing providers' diagnostic capabilities and capacities can exacerbate undertreatment. Providing access to consumers' diagnosis histories can help mitigate the undertreatment issue and improve consumer welfare.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21175v1</guid>
      <category>econ.TH</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaoyan Xu, Weishi Lim, Xing Zhang, Jeff Cai</dc:creator>
    </item>
    <item>
      <title>The Backfiring Effect of Weak AI Safety Regulation</title>
      <link>https://arxiv.org/abs/2503.20848</link>
      <description>arXiv:2503.20848v1 Announce Type: cross 
Abstract: Recent policy proposals aim to improve the safety of general-purpose AI, but there is little understanding of the efficacy of different regulatory approaches to AI safety. We present a strategic model that explores the interactions between the regulator, the general-purpose AI technology creators, and domain specialists--those who adapt the AI for specific applications. Our analysis examines how different regulatory measures, targeting different parts of the development chain, affect the outcome of the development process. In particular, we assume AI technology is described by two key attributes: safety and performance. The regulator first sets a minimum safety standard that applies to one or both players, with strict penalties for non-compliance. The general-purpose creator then develops the technology, establishing its initial safety and performance levels. Next, domain specialists refine the AI for their specific use cases, and the resulting revenue is distributed between the specialist and generalist through an ex-ante bargaining process. Our analysis of this game reveals two key insights: First, weak safety regulation imposed only on the domain specialists can backfire. While it might seem logical to regulate use cases (as opposed to the general-purpose technology), our analysis shows that weak regulations targeting domain specialists alone can unintentionally reduce safety. This effect persists across a wide range of settings. Second, in sharp contrast to the previous finding, we observe that stronger, well-placed regulation can in fact benefit all players subjected to it. When regulators impose appropriate safety standards on both AI creators and domain specialists, the regulation functions as a commitment mechanism, leading to safety and performance gains, surpassing what is achieved under no regulation or regulating one player only.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.20848v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>econ.TH</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Benjamin Laufer, Jon Kleinberg, Hoda Heidari</dc:creator>
    </item>
    <item>
      <title>Musical Chairs: A new benchmark to evaluate AI</title>
      <link>https://arxiv.org/abs/2503.20986</link>
      <description>arXiv:2503.20986v1 Announce Type: cross 
Abstract: This paper presents a new contribution to the growing set of benchmarks used to prune potential AI designs. Much as one might evaluate a machine in terms of its performance at chess, this benchmark involves testing a machine in terms of its performance at a game called "Musical Chairs." At the time of writing, Claude, ChatGPT, and Qwen each failed this test, so the test could aid in their ongoing improvement. Furthermore, this paper sets a stage for future innovation in game theory and AI safety by providing an example of success with non-standard approaches to each: studying a game beyond the scope of previous game theoretic tools and mitigating a serious AI safety risk in a way that requires neither determination of values nor their enforcement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.20986v1</guid>
      <category>cs.CY</category>
      <category>econ.TH</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chris Santos-Lang, Christopher M. Homan</dc:creator>
    </item>
    <item>
      <title>Irrelevance of personalized pricing under strategic market segmentation</title>
      <link>https://arxiv.org/abs/2303.13295</link>
      <description>arXiv:2303.13295v3 Announce Type: replace 
Abstract: A multiproduct seller is more informed than consumers about the value of her products to consumers. The seller posts a price list and segments the market through cheap-talk communication. We find that when both seller's and consumers' incentive-compatibility constraints are satisfied, the seller cannot benefit from personalized pricing (i.e., third-degree price discrimination). Based on that observation, we provide a tractable characterization of seller's maximum equilibrium profits. We apply our analysis to a credence-good setup and discuss when the credence goods seller benefits from communication. The irrelevance result breaks down when we relax seller's incentive-compatibility constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.13295v3</guid>
      <category>econ.TH</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaoxiao Hu, Haoran Lei</dc:creator>
    </item>
    <item>
      <title>Degree-Weighted DeGroot Learning</title>
      <link>https://arxiv.org/abs/2311.07010</link>
      <description>arXiv:2311.07010v2 Announce Type: replace 
Abstract: We examine belief formation in large stochastic networks under a degree-weighted DeGroot learning process. In many social settings, agents may place more trust in well-connected individuals or, conversely, discount their influence. Existing research on random networks primarily assumes that agents assign equal weights to their neighbors' opinions. We relax this assumption by allowing agents to weight neighbors based on their degree. Our main technical contribution is to derive the asymptotic properties of learning outcomes, particularly the consensus belief and convergence speed, under this degree-weighted framework. Using this result, we analyze how the weighting rule affects consensus beliefs, societal wisdom, and convergence speed. We find that a more popularity-favoring rule -- i.e., assigning greater weight to higher-degree neighbors -- harms wisdom but has a non-monotonic effect on convergence speed. Whether it accelerates or slows convergence depends on the diversity of views within high- and low-degree groups. This highlights a potential tradeoff between faster convergence and an unwise consensus in networks where agents favor highly connected neighbors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.07010v2</guid>
      <category>econ.TH</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chen Cheng, Xiao Han, Xin Tong, Yusheng Wu, Yiqing Xing</dc:creator>
    </item>
    <item>
      <title>Host Community Respecting Refugee Housing</title>
      <link>https://arxiv.org/abs/2302.13997</link>
      <description>arXiv:2302.13997v3 Announce Type: replace-cross 
Abstract: We propose a novel model for refugee housing respecting the preferences of the accepting community and refugees themselves. In particular, we are given a topology representing the local community, a set of inhabitants occupying some vertices of the topology, and a set of refugees that should be housed on the empty vertices of the graph. Both the inhabitants and the refugees have preferences over the structure of their neighborhood.
  We are specifically interested in the problem of finding housing such that the preferences of every individual are met; using game-theoretical words, we are looking for housing that is stable with respect to some well-defined notion of stability. We investigate conditions under which the existence of equilibria is guaranteed and study the computational complexity of finding such a stable outcome. As the problem is NP-hard even in very simple settings, we employ the parameterized complexity framework to give a finer-grained view of the problem's complexity with respect to natural parameters and structural restrictions of the given topology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.13997v3</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <category>econ.TH</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Du\v{s}an Knop, \v{S}imon Schierreich</dc:creator>
    </item>
  </channel>
</rss>
