<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.OT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.OT</link>
    <description>stat.OT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.OT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 04 Nov 2025 05:01:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>The Neutrality Boundary Framework: Quantifying Statistical Robustness Geometrically</title>
      <link>https://arxiv.org/abs/2511.00982</link>
      <description>arXiv:2511.00982v1 Announce Type: new 
Abstract: We introduce the Neutrality Boundary Framework (NBF), a set of geometric metrics for quantifying statistical robustness and fragility as the normalized distance from the neutrality boundary, the manifold where the effect equals zero. The neutrality boundary value nb in [0,1) provides a threshold-free, sample-size invariant measure of stability that complements traditional effect sizes and p-values. We derive the general form nb = |Delta - Delta_0| / (|Delta - Delta_0| + S), where S&gt;0 is a scale parameter for normalization; we prove boundedness and monotonicity, and provide domain-specific implementations: Risk Quotient (binary outcomes), partial eta^2 (ANOVA), and Fisher z-based measures (correlation). Unlike threshold-dependent fragility indices, NBF quantifies robustness geometrically across arbitrary significance levels and statistical contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00982v1</guid>
      <category>stat.OT</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thomas F. Heston</dc:creator>
    </item>
    <item>
      <title>From Path Coefficients to Targeted Estimands: A Comparison of Structural Equation Models (SEM) and Targeted Maximum Likelihood Estimation (TMLE)</title>
      <link>https://arxiv.org/abs/2511.01040</link>
      <description>arXiv:2511.01040v1 Announce Type: new 
Abstract: Structural Equation Modeling (SEM) has gained popularity in the social sciences and causal inference due to its flexibility in modeling complex relationships between variables and its availability in modern statistical software. To move beyond the parametric assumptions of SEM, this paper reviews targeted maximum likelihood estimation (TMLE), a doubly robust, machine learning-based approach that builds on nonparametric SEM. We demonstrate that both TMLE and SEM can be used to estimate standard causal effects and show that TMLE is robust to model misspecification. We conducted simulation studies under both correct and misspecified model conditions, implementing SEM and TMLE to estimate these causal effects. The simulations confirm that TMLE consistently outperforms SEM under misspecification in terms of bias, mean squared error, and the validity of confidence intervals. We applied both approaches to a real-world dataset to analyze the mediation effects of poverty on access to high school, revealing that the direct effect is no longer significant under TMLE, whereas SEM indicates significance. We conclude with practical guidance on using SEM and TMLE in light of recent developments in targeted learning for causal inference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01040v1</guid>
      <category>stat.OT</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junjie Ma, Xiaoya Zhang, Guangye He, Yuting Han, Ting Ge, Feng Ji</dc:creator>
    </item>
    <item>
      <title>Geometric Modeling of Hippocampal Tau Deposition: A Surface-Based Framework for Covariate Analysis and Off-Target Contamination Detection</title>
      <link>https://arxiv.org/abs/2511.01732</link>
      <description>arXiv:2511.01732v1 Announce Type: cross 
Abstract: We introduce a framework combining geometric modeling with disease progression analysis to investigate tau deposition in Alzheimer's disease (AD) using positron emission tomography (PET) data. Focusing on the hippocampus, we construct a principal surface that captures the spatial distribution and morphological changes of tau pathology. By projecting voxels onto this surface, we quantify tau coverage, intensity, and thickness through bidirectional projection distances and interpolated standardized uptake value ratios (SUVR). This low-dimensional embedding preserves spatial specificity while mitigating multiple comparison issues. Covariate effects are analyzed using a two-stage regression model with inverse probability weighting to adjust for signal sparsity and selection bias. Using the SuStaIn model, we identify subtypes and stages of AD, revealing distinct tau dynamics: the limbic-predominant subtype shows age-related nonlinear accumulation in coverage and thickness, whereas the posterior subtype exhibits uniform SUVR increases across disease progression. Model-based predictions show that hippocampal tau deposition follows a structured spatial trajectory expanding bidirectionally with increasing thickness, while subtype differences highlight posterior hippocampal involvement consistent with whole-brain patterns. Finally, directional signal patterns on the principal surface reveal contamination from the choroid plexus, demonstrating the broader applicability of the proposed framework across modalities including amyloid PET.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01732v1</guid>
      <category>stat.AP</category>
      <category>q-bio.QM</category>
      <category>stat.OT</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liangkang Wang, Akhil Ambekar, Ani Eloyan</dc:creator>
    </item>
    <item>
      <title>How causal perspectives can inform neuroscience data analysis</title>
      <link>https://arxiv.org/abs/2503.10710</link>
      <description>arXiv:2503.10710v3 Announce Type: replace-cross 
Abstract: Over the past two decades, considerable strides have been made in advancing neuroscientific techniques, yet challenges remain in attributing causality to observed associations. This review addresses a fundamental issue in observational neuroscience studies and advocates for incorporating causal inference frameworks into standard practice. We systematically introduce necessary definitions and concepts, emphasizing how causal assumptions underlie statistical analyses even when not explicitly stated. Through a running example on sleep quality and white matter integrity, we illustrate how persistent challenges, including confounding and selection biases, can be conceptualized and addressed using causal frameworks. We demonstrate practical approaches for making assumption violations transparent through hands-on examples: supplementary case studies using multi-site harmonization and head motion exclusion procedures provide step-by-step diagnostic techniques for checking covariate overlap and identifying selection bias through exclusion pattern analysis. We explore how these causal perspectives can inform both experimental design and analytical choices, particularly for observational studies where traditional randomization is infeasible. Together, we believe this framework offers concrete tools for strengthening causal interpretations and inspiring more robust approaches to problems in neuroscience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10710v3</guid>
      <category>q-bio.OT</category>
      <category>stat.OT</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Eric W. Bridgeford, Brian S. Caffo, Maya B. Mathur, Russell A. Poldrack</dc:creator>
    </item>
    <item>
      <title>Understanding and Using the Relative Importance Measures Based on Orthogonalization and Reallocation</title>
      <link>https://arxiv.org/abs/2510.13389</link>
      <description>arXiv:2510.13389v2 Announce Type: replace-cross 
Abstract: A class of relative importance measures based on orthogonalization and reallocation, ORMs, has been found to effectively approximate the General Dominance index (GD). In particular, Johnson's Relative Weight (RW) has been deemed the most successful ORM in the literature. Nevertheless, the theoretical foundation of the ORMs remains unclear. To further understand the ORMs, we provide a generalized framework that breaks down the ORM into two functional steps: orthogonalization and reallocation. To assess the impact of each step on the performance of ORMs, we conduct extensive Monte Carlo simulations under various predictors' correlation structures and response variable distributions. Our findings reveal that Johnson's minimal transformation consistently outperforms other common orthogonalization methods. We also summarize the performance of reallocation methods under four scenarios of predictors' correlation structures in terms of the first principal component and the variance inflation factor (VIF). This analysis provides guidelines for selecting appropriate reallocation methods in different scenarios, illustrated with real-world dataset examples. Our research offers a deeper understanding of ORMs and provides valuable insights for practitioners seeking to accurately measure variable importance in various modeling contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13389v2</guid>
      <category>stat.ME</category>
      <category>stat.OT</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tien-En Chang, Argon Chen</dc:creator>
    </item>
  </channel>
</rss>
