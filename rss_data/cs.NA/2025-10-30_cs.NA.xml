<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NA</link>
    <description>cs.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 31 Oct 2025 01:48:45 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A Semi-Lagrangian Adaptive Rank (SLAR) Method for High-Dimensional Vlasov Dynamics</title>
      <link>https://arxiv.org/abs/2510.24861</link>
      <description>arXiv:2510.24861v1 Announce Type: new 
Abstract: We extend our previous work on a semi-Lagrangian adaptive rank (SLAR) integrator, in the finite difference framework for nonlinear Vlasov-Poisson systems, to the general high-order tensor setting. The proposed scheme retains the high-order accuracy of semi-Lagrangian methods, ensuring stability for large time steps and avoiding dimensional splitting errors. The primary contribution of this paper is the novel extension of the algorithm from the matrix to the high-dimensional tensor setting, which enables the simulation of Vlasov models in up to six dimensions. The key technical components include (1) a third-order high-dimensional polynomial reconstruction that scales as $O(d^2)$, providing a point-wise approximation of the solution at the foot of characteristics in a semi-Lagrangian scheme; (2) a recursive hierarchical adaptive cross approximation of high-order tensors in a hierarchical Tucker format, characterized by a tensor tree; (3) a low-complexity Poisson solver in the hierarchical Tucker format that leverages the FFT for efficiency. The computed adaptive rank kinetic solutions exhibit low-rank structures within branches of the tensor tree resulting in substantial computational savings in both storage and time. The resulting algorithm achieves a computational complexity of $O(d^4 N r^{3+\lceil\log_2d\rceil})$, where $N$ is the number of grid points per dimension, $d$ is the problem dimension, and $r$ is the maximum rank in the tensor tree, overcoming the curse of dimensionality. Through extensive numerical tests, we demonstrate the efficiency of the proposed algorithm and highlight its ability to capture complex solution structures while maintaining a computational complexity that scales linearly with $N$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.24861v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <category>physics.plasm-ph</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nanyi Zheng, William A. Sands, Daniel Hayes, Andrew J. Christlieb, Jing-Mei Qiu</dc:creator>
    </item>
    <item>
      <title>Interpolated Discrepancy Data Assimilation for PDEs with Sparse Observations</title>
      <link>https://arxiv.org/abs/2510.24944</link>
      <description>arXiv:2510.24944v1 Announce Type: new 
Abstract: Sparse sensor networks in weather and ocean modeling observe only a small fraction of the system state, which destabilizes standard nudging-based data assimilation. We introduce Interpolated Discrepancy Data Assimilation (IDDA), which modifies how discrepancies enter the governing equations. Rather than adding observations as a forcing term alone, IDDA also adjusts the nonlinear operator using interpolated observational information. This structural change suppresses error amplification when nonlinear effects dominate. We prove exponential convergence under explicit conditions linking error decay to observation spacing, nudging strength, and diffusion coefficient. The key requirement establishes bounds on nudging strength relative to observation spacing and diffusion, giving practitioners a clear operating window. When observations resolve the relevant scales, error decays at a user-specified rate. Critically, the error bound scales with the square of observation spacing rather than through hard-to-estimate nonlinear growth rates. We validate IDDA on Burgers flow, Kuramoto-Sivashinsky dynamics, and two-dimensional Navier-Stokes turbulence. Across these tests, IDDA reaches target accuracy faster than standard interpolated nudging, remains stable in chaotic regimes, avoids non-monotone transients, and requires minimal parameter tuning. Because IDDA uses standard explicit time integration, it fits readily into existing simulation pipelines without specialized solvers. These properties make IDDA a practical upgrade for operational systems constrained by sparse sensor coverage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.24944v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tong Wu, Humberto Godinez, Vitaliy Gyrya, James M. Hyman</dc:creator>
    </item>
    <item>
      <title>The B-spline collocation method for solving Cauchy singular integral equations with piecewise Holder continuous coefficients</title>
      <link>https://arxiv.org/abs/2510.24984</link>
      <description>arXiv:2510.24984v1 Announce Type: new 
Abstract: In this paper, we propose a numerical method for approximating the solution of a Cauchy singular integral equation defined on a closed, smooth contour in the complex plane. The coefficients and the right-hand side of the equation are piecewise Holder continuous functions that may have a finite number of jump discontinuities, and are given numerically at a finite set of points on the contour. We introduce an efficient approximation scheme for piecewise Holder continuous functions based on linear combinations of B-spline functions and Heaviside step functions, which serves as the foundation for the proposed collocation algorithm. We then establish the convergence of the sequence of the constructed approximations to the exact solution of the equation in the norm of piecewise Holder spaces and derive estimates for the convergence rate of the method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.24984v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maria Capcelea, Titu Capcelea</dc:creator>
    </item>
    <item>
      <title>Cluster Formation in Diffusive Systems</title>
      <link>https://arxiv.org/abs/2510.25034</link>
      <description>arXiv:2510.25034v1 Announce Type: new 
Abstract: In this paper, we study the formation of clusters for stochastic interacting particle systems (SIPS) that interact through short-range attractive potentials in a periodic domain. We consider kinetic (underdamped) Langevin dynamics and focus on the low-friction regime. Employing a linear stability analysis for the kinetic McKean-Vlasov equation, we show that, at sufficiently low temperatures, and for sufficiently short-ranged interactions, the particles form clusters that correspond to metastable states of the mean-field dynamics. We derive the friction and particle-count dependent cluster-formation time and numerically measure the friction-dependent times to reach a stationary state (given by a state in which all particles are bound in a single cluster). By providing both theory and numerical methods in the inertial stochastic setting, this work acts as a bridge between cluster formation studies in overdamped Langevin dynamics and the Hamiltonian (microcanonical) limit.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25034v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.AP</category>
      <category>math.MP</category>
      <category>math.PR</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Benedict Leimkuhler, Ren\'e Lohmann, Grigorios A. Pavliotis, Peter A. Whalley</dc:creator>
    </item>
    <item>
      <title>Learning Hamiltonian flows from numerical integrators and examples</title>
      <link>https://arxiv.org/abs/2510.25107</link>
      <description>arXiv:2510.25107v1 Announce Type: new 
Abstract: Hamiltonian systems with multiple timescales arise in molecular dynamics, classical mechanics, and theoretical physics. Long-time numerical integration of such systems requires resolving fast dynamics with very small time steps, which incurs a high computational cost - especially in ensemble simulations for uncertainty quantification, sensitivity analysis, or varying initial conditions. We present a Deep Learning framework that learns the flow maps of Hamiltonian systems to accelerate long-time and ensemble simulations. Neural networks are trained, according to a chosen numerical scheme, either entirely without data to approximate flows over large time intervals or with data to learn flows in intervals far from the initial time. For the latter, we propose a Hamiltonian Monte Carlo-based data generator. The architecture consists of simple feedforward networks that incorporate truncated Taylor expansions of the flow map, with a neural network remainder capturing unresolved effects. Applied to benchmark non-integrable and non-canonical systems, the method achieves substantial speedups while preserving accuracy, enabling scalable simulation of complex Hamiltonian dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25107v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rui Fang, Richard Tsai</dc:creator>
    </item>
    <item>
      <title>Energy Approach from $\varepsilon$-Graph to Continuum Diffusion Model with Connectivity Functional</title>
      <link>https://arxiv.org/abs/2510.25114</link>
      <description>arXiv:2510.25114v2 Announce Type: new 
Abstract: We derive an energy-based continuum limit for $\varepsilon$-graphs endowed with a general connectivity functional. We prove that the discrete energy and its continuum counterpart differ by at most $O(\varepsilon)$; the prefactor involves only the $W^{1,1}$-norm of the connectivity density as $\varepsilon\to0$, so the error bound remains valid even when that density has strong local fluctuations. As an application, we introduce a neural-network procedure that reconstructs the connectivity density from edge-weight data and then embeds the resulting continuum model into a brain-dynamics framework. In this setting, the usual constant diffusion coefficient is replaced by the spatially varying coefficient produced by the learned density, yielding dynamics that differ significantly from those obtained with conventional constant-diffusion models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25114v2</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>stat.ML</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yahong Yang, Sun Lee, Jeff Calder, Wenrui Hao</dc:creator>
    </item>
    <item>
      <title>Error Analysis of Third-Order in Time and Fourth-Order Linear Finite Difference Scheme for Landau-Lifshitz-Gilbert Equation under Large Damping Parameters</title>
      <link>https://arxiv.org/abs/2510.25172</link>
      <description>arXiv:2510.25172v1 Announce Type: new 
Abstract: This work proposes and analyzes a fully discrete numerical scheme for solving the Landau-Lifshitz-Gilbert (LLG) equation, which achieves fourth-order spatial accuracy and third-order temporal accuracy.Spatially, fourth-order accuracy is attained through the adoption of a long-stencil finite difference method, while boundary extrapolation is executed by leveraging a higher-order Taylor expansion to ensure consistency at domain boundaries. Temporally, the scheme is constructed based on the third-order backward differentiation formula (BDF3), with implicit discretization applied to the linear diffusion term for numerical stability and explicit extrapolation employed for nonlinear terms to balance computational efficiency. Notably, this numerical method inherently preserves the normalization constraint of the LLG equation, a key physical property of the system.Theoretical analysis confirms that the proposed scheme exhibits optimal convergence rates under the \(\ell^{\infty}([0,T],\ell^2)\) and \(\ell^2([0,T],H_h^1)\) norms. Finally, numerical experiments are conducted to validate the correctness of the theoretical convergence results, demonstrating good agreement between numerical observations and analytical conclusions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25172v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Changjian Xie, Cheng Wang</dc:creator>
    </item>
    <item>
      <title>Spectral analysis of the stiffness matrix sequence in the approximated Stokes equation</title>
      <link>https://arxiv.org/abs/2510.25252</link>
      <description>arXiv:2510.25252v1 Announce Type: new 
Abstract: In the present paper, we analyze in detail the spectral features of the matrix sequences arising from the Taylor-Hood $\mathbb{P}_2$-$\mathbb{P}_1$ approximation of variable viscosity for $2d$ Stokes problem under weak assumptions on the regularity of the diffusion. Localization and distributional spectral results are provided, accompanied by numerical tests and visualizations. A preliminary study of the impact of our findings on the preconditioning problem is also presented. A final section with concluding remarks and open problems ends the current work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25252v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Samuele Ferri, Chiara Giraudo, Valerio Loi, Miroslav Kuchta, Stefano Serra-Capizzano</dc:creator>
    </item>
    <item>
      <title>Identifying Kronecker product factorizations</title>
      <link>https://arxiv.org/abs/2510.25292</link>
      <description>arXiv:2510.25292v1 Announce Type: new 
Abstract: The Kronecker product is an invaluable tool for data-sparse representations of large networks and matrices with countless applications in machine learning, graph theory and numerical linear algebra. In some instances, the sparsity pattern of large matrices may already hide a Kronecker product. Similarly, a large network, represented by its adjacency matrix, may sometimes be factorized as a Kronecker product of smaller adjacency matrices. In this article, we determine all possible Kronecker factorizations of a binary matrix and visualize them through its decomposition graph. Such sparsity-informed factorizations may later enable good (approximate) Kronecker factorizations of real matrices or reveal the latent structure of a network. The latter also suggests a natural visualization of Kronecker graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25292v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yannis Voet, Leonardo De Novellis</dc:creator>
    </item>
    <item>
      <title>A virtual element approximation for the modified transmission eigenvalues for natural materials</title>
      <link>https://arxiv.org/abs/2510.25298</link>
      <description>arXiv:2510.25298v1 Announce Type: new 
Abstract: In this paper, we discuss a virtual element approximation for the modified transmission eigenvalue problem in inverse scattering for natural materials. In this case, due to the positive artificial diffusivity parameter in the considered problem, the sesquilinear form at the left end of the variational form is not coercive. We first demonstrate the well-posedness of the discrete source problem using the $\mathds{T}$-coercivity property, then provide the a priori error estimates for the approximate eigenspaces and eigenvalues, and finally reports several numerical examples. The numerical experiments show that the proposed method is effective</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25298v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liangkun Xu, Shixi Wang, Hai Bi</dc:creator>
    </item>
    <item>
      <title>A structure-preserving Lagrangian discontinuous Galerkin method using flux and slope limiting</title>
      <link>https://arxiv.org/abs/2510.25395</link>
      <description>arXiv:2510.25395v1 Announce Type: new 
Abstract: We introduce a Lagrangian nodal discontinuous Galerkin (DG) cell-centered hydrodynamics method for solving multi-dimensional hyperbolic systems. By incorporating an adaptation of Zalesak's flux-corrected transport algorithm, we combine a first-order positivity-preserving scheme with a higher-order target discretization. This results in a flux-corrected Lagrangian DG scheme that ensures both global positivity preservation and second-order accuracy for the cell averages of specific volume. The correction factors for flux limiting are derived from specific volume and applied to all components of the solution vector. We algebraically evolve the volumes of mesh cells using a discrete version of the geometric conservation law (GCL). The application of a limiter to the GCL fluxes is equivalent to moving the mesh using limited nodal velocities. Additionally, we equip our method with a locally bound-preserving slope limiter to effectively suppress spurious oscillations. Nodal velocity and external forces are computed using a multidirectional approximate Riemann solver to maintain conservation of momentum and total energy in vertex neighborhoods. Employing linear finite elements and a second-order accurate time integrator guarantees GCL consistency. The results for standard test problems demonstrate the stability and superb shock-capturing capabilities of our scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25395v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joshua Vedral, Nathaniel Morgan, Dmitri Kuzmin, Jacob Moore</dc:creator>
    </item>
    <item>
      <title>Nonparametric estimation of homogenized invariant measures from multiscale data via Hermite expansion</title>
      <link>https://arxiv.org/abs/2510.25521</link>
      <description>arXiv:2510.25521v1 Announce Type: new 
Abstract: We consider the problem of density estimation in the context of multiscale Langevin diffusion processes, where a single-scale homogenized surrogate model can be derived. In particular, our aim is to learn the density of the invariant measure of the homogenized dynamics from a continuous-time trajectory generated by the full multiscale system. We propose a spectral method based on a truncated Fourier expansion with Hermite functions as orthonormal basis. The Fourier coefficients are computed directly from the data owing to the ergodic theorem. We prove that the resulting density estimator is robust and converges to the invariant density of the homogenized model as the scale separation parameter vanishes, provided the time horizon and the number of Fourier modes are suitably chosen in relation to the multiscale parameter. The accuracy and reliability of this methodology is further demonstrated through a series of numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25521v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jaroslav I. Borodavka, Max Hirsch, Sebastian Krumscheid, Andrea Zanoni</dc:creator>
    </item>
    <item>
      <title>3-Dimensional Adaptive Unstructured Tessellated Look-up Tables for the Approximation of Compton Form Factors</title>
      <link>https://arxiv.org/abs/2510.25699</link>
      <description>arXiv:2510.25699v1 Announce Type: new 
Abstract: We describe an iterative algorithm to construct an unstructured tessellation of simplices (irregular tetrahedra in 3-dimensions) to approximate an arbitrary function to a desired precision by interpolation. The method is applied to the generation of Compton Form Factors for simulation and analysis of nuclear femtography, as enabled by high energy exclusive processes such as electron-proton scattering producing just an electron, proton, and gamma-ray in the final state. While producing tessellations with only a 1% mean interpolation error, our results show that the use of such tessellations can significantly decrease the computation time for Monte Carlo event generation by $\sim23$ times for $10^{7}$ events (and using extrapolation, by $\sim955$ times for $10^{10}$ events).</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25699v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Charles Hyde, Mitch Kerver, Christos Tsolakis, Polykarpos Thomadakis, Spiros Tsalikis, Kevin Garner, Angelos Angelopoulos, Wirawan Purwanto, Gagik Gavalian, Christian Weiss, Nikos Chrisochoides</dc:creator>
    </item>
    <item>
      <title>Meshless solutions of PDE inverse problems on irregular geometries</title>
      <link>https://arxiv.org/abs/2510.25752</link>
      <description>arXiv:2510.25752v1 Announce Type: new 
Abstract: Solving inverse and optimization problems over solutions of nonlinear partial differential equations (PDEs) on complex spatial domains is a long-standing challenge. Here we introduce a method that parameterizes the solution using spectral bases on arbitrary spatiotemporal domains, whereby the basis is defined on a hyperrectangle containing the true domain. We find the coefficients of the basis expansion by solving an optimization problem whereby both the equations, the boundary conditions and any optimization targets are enforced by a loss function, building on a key idea from Physics-Informed Neural Networks (PINNs). Since the representation of the function natively has exponential convergence, so does the solution of the optimization problem, as long as it can be solved efficiently. We find empirically that the optimization protocols developed for machine learning find solutions with exponential convergence on a wide range of equations. The method naturally allows for the incorporation of data assimilation by including additional terms in the loss function, and for the efficient solution of optimization problems over the PDE solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25752v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>James V. Roggeveen, Michael P. Brenner</dc:creator>
    </item>
    <item>
      <title>Convergence analysis for an implementable scheme to solve the linear-quadratic stochastic optimal control problem with stochastic wave equation</title>
      <link>https://arxiv.org/abs/2510.24876</link>
      <description>arXiv:2510.24876v1 Announce Type: cross 
Abstract: We study an optimal control problem for the stochastic wave equation driven by affine multiplicative noise, formulated as a stochastic linear-quadratic (SLQ) problem. By applying a stochastic Pontryagin's maximum principle, we characterize the optimal state-control pair via a coupled forward-backward SPDE system. We propose an implementable discretization using conforming finite elements in space and an implicit midpoint rule in time. By a new technical approach we obtain strong convergence rates for the discrete state-control pair without relying on Malliavin calculus. For the practical computation we develop a gradient-descent algorithm based on artificial iterates that employs an exact computation for the arising conditional expectations, thereby eliminating costly Monte Carlo sampling. Consequently, each iteration has a computational cost that is proportional to the number of spatial degrees of freedom, producing a scalable method that preserves the established strong convergence rates. Numerical results validate its efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.24876v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Abhishek Chaudhary</dc:creator>
    </item>
    <item>
      <title>KAN-GCN: Combining Kolmogorov-Arnold Network with Graph Convolution Network for an Accurate Ice Sheet Emulator</title>
      <link>https://arxiv.org/abs/2510.24926</link>
      <description>arXiv:2510.24926v1 Announce Type: cross 
Abstract: We introduce KAN-GCN, a fast and accurate emulator for ice sheet modeling that places a Kolmogorov-Arnold Network (KAN) as a feature-wise calibrator before graph convolution networks (GCNs). The KAN front end applies learnable one-dimensional warps and a linear mixing step, improving feature conditioning and nonlinear encoding without increasing message-passing depth. We employ this architecture to improve the performance of emulators for numerical ice sheet models. Our emulator is trained and tested using 36 melting-rate simulations with 3 mesh-size settings for Pine Island Glacier, Antarctica. Across 2- to 5-layer architectures, KAN-GCN matches or exceeds the accuracy of pure GCN and MLP-GCN baselines. Despite a small parameter overhead, KAN-GCN improves inference throughput on coarser meshes by replacing one edge-wise message-passing layer with a node-wise transform; only the finest mesh shows a modest cost. Overall, KAN-first designs offer a favorable accuracy vs. efficiency trade-off for large transient scenario sweeps.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.24926v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zesheng Liu, YoungHyun Koo, Maryam Rahnemoonfar</dc:creator>
    </item>
    <item>
      <title>Adaptive Multilevel Newton: A Quadratically Convergent Optimization Method</title>
      <link>https://arxiv.org/abs/2510.24967</link>
      <description>arXiv:2510.24967v1 Announce Type: cross 
Abstract: Newton's method may exhibit slower convergence than vanilla Gradient Descent in its initial phase on strongly convex problems. Classical Newton-type multilevel methods mitigate this but, like Gradient Descent, achieve only linear convergence near the minimizer. We introduce an adaptive multilevel Newton-type method with a principled automatic switch to full Newton once its quadratic phase is reached. The local quadratic convergence for strongly convex functions with Lipschitz continuous Hessians and for self-concordant functions is established and confirmed empirically. Although per-iteration cost can exceed that of classical multilevel schemes, the method is efficient and consistently outperforms Newton's method, Gradient Descent, and the multilevel Newton method, indicating that second-order methods can outperform first-order methods even when Newton's method is initially slow.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.24967v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nick Tsipinakis, Panos Parpas, Matthias Voigt</dc:creator>
    </item>
    <item>
      <title>Learning Low Rank Neural Representations of Hyperbolic Wave Dynamics from Data</title>
      <link>https://arxiv.org/abs/2510.25123</link>
      <description>arXiv:2510.25123v1 Announce Type: cross 
Abstract: We present a data-driven dimensionality reduction method that is well-suited for physics-based data representing hyperbolic wave propagation. The method utilizes a specialized neural network architecture called low rank neural representation (LRNR) inside a hypernetwork framework. The architecture is motivated by theoretical results that rigorously prove the existence of efficient representations for this wave class. We illustrate through archetypal examples that such an efficient low-dimensional representation of propagating waves can be learned directly from data through a combination of deep learning techniques. We observe that a low rank tensor representation arises naturally in the trained LRNRs, and that this reveals a new decomposition of wave propagation where each decomposed mode corresponds to interpretable physical features. Furthermore, we demonstrate that the LRNR architecture enables efficient inference via a compression scheme, which is a potentially important feature when deploying LRNRs in demanding performance regimes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25123v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Woojin Cho, Kookjin Lee, Noseong Park, Donsub Rim, Gerrit Welper</dc:creator>
    </item>
    <item>
      <title>Model-Adaptive Simulation of Hierarchical Shallow Water Moment Equations in One Dimension</title>
      <link>https://arxiv.org/abs/2510.25351</link>
      <description>arXiv:2510.25351v1 Announce Type: cross 
Abstract: Shallow free surface flows are often characterized by both subdomains that require high modeling complexity and subdomains that can be sufficiently accurately modeled with low modeling complexity. Moreover, these subdomains may change in time as the water flows through the domain. This motivates the need for space and time adaptivity in the simulation of shallow free surface flows. In this paper, we develop the first adaptive simulations using the recently developed Shallow Water Moment Equations, which are an extension of the standard Shallow Water Equations that allow for vertically changing velocity profiles by including additional variables and equations. The model-specific modeling complexity of a shallow water moment model is determined by its order. The higher the order of the model, the more variables and equations are included in the model. Shallow water moment models are ideally suited for adaptivity because they are hierarchical such that low-order models and high-order models share the same structure. To enable adaptive simulations, we propose two approaches for the coupling of the varying-order shallow water moment equations at their boundary interfaces. The first approach dynamically updates padded state variables but cannot be written in conservative form, while the second approach uses fixed padded state variable values of zero and reduces to conservative form for conservative moment equations. The switching procedure between high-order models and low-order models is based on a new set of model error estimators, originating from a decomposition of the high-order models. Numerical results of the collision of a dam-break wave with a smooth wave yield accurate results, while achieving speedups up to 60 percent compared to a non-adaptive model with fixed modeling complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25351v1</guid>
      <category>physics.flu-dyn</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Rik Verbiest, Julian Koellermeier</dc:creator>
    </item>
    <item>
      <title>A Deep Learning Framework for Multi-Operator Learning: Architectures and Approximation Theory</title>
      <link>https://arxiv.org/abs/2510.25379</link>
      <description>arXiv:2510.25379v1 Announce Type: cross 
Abstract: While many problems in machine learning focus on learning mappings between finite-dimensional spaces, scientific applications require approximating mappings between function spaces, i.e., operators. We study the problem of learning collections of operators and provide both theoretical and empirical advances. We distinguish between two regimes: (i) multiple operator learning, where a single network represents a continuum of operators parameterized by a parametric function, and (ii) learning several distinct single operators, where each operator is learned independently. For the multiple operator case, we introduce two new architectures, $\mathrm{MNO}$ and $\mathrm{MONet}$, and establish universal approximation results in three settings: continuous, integrable, or Lipschitz operators. For the latter, we further derive explicit scaling laws that quantify how the network size must grow to achieve a target approximation accuracy. For learning several single operators, we develop a framework for balancing architectural complexity across subnetworks and show how approximation order determines computational efficiency. Empirical experiments on parametric PDE benchmarks confirm the strong expressive power and efficiency of the proposed architectures. Overall, this work establishes a unified theoretical and practical foundation for scalable neural operator learning across multiple operators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25379v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adrien Weihs, Jingmin Sun, Zecheng Zhang, Hayden Schaeffer</dc:creator>
    </item>
    <item>
      <title>Minimizing point configurations for tensor product energies on the torus</title>
      <link>https://arxiv.org/abs/2510.25442</link>
      <description>arXiv:2510.25442v1 Announce Type: cross 
Abstract: We study point configurations on the torus $\mathbb T^d$ that minimize interaction energies with tensor product structure which arise naturally in the context of discrepancy theory and quasi-Monte Carlo integration. Permutation sets on $\mathbb T^2$ and Latin hypercube sets in higher dimensions (i.e. sets whose projections onto coordinate axes are equispaced points) are natural candidates to be energy minimizers. We show that such point configurations that have only one distance in the vector sense minimize the energy for a wide range of potentials, in other words, such sets satisfy a tensor product version of universal optimality. This applies, in particular, to three- and five-point Fibonacci lattices. We also characterize all lattices with this property and exhibit some non-lattice sets of this type. In addition, we obtain several further structural results about global and local minimizers of tensor product energies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25442v1</guid>
      <category>math.MG</category>
      <category>cs.NA</category>
      <category>math.CO</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dmitriy Bilyk, Nicolas Nagel, Ian Ruohoniemi</dc:creator>
    </item>
    <item>
      <title>Perturbation Bounds for Low-Rank Inverse Approximations under Noise</title>
      <link>https://arxiv.org/abs/2510.25571</link>
      <description>arXiv:2510.25571v1 Announce Type: cross 
Abstract: Low-rank pseudoinverses are widely used to approximate matrix inverses in scalable machine learning, optimization, and scientific computing. However, real-world matrices are often observed with noise, arising from sampling, sketching, and quantization. The spectral-norm robustness of low-rank inverse approximations remains poorly understood. We systematically study the spectral-norm error $\| (\tilde{A}^{-1})_p - A_p^{-1} \|$ for an $n\times n$ symmetric matrix $A$, where $A_p^{-1}$ denotes the best rank-\(p\) approximation of $A^{-1}$, and $\tilde{A} = A + E$ is a noisy observation. Under mild assumptions on the noise, we derive sharp non-asymptotic perturbation bounds that reveal how the error scales with the eigengap, spectral decay, and noise alignment with low-curvature directions of $A$. Our analysis introduces a novel application of contour integral techniques to the \emph{non-entire} function $f(z) = 1/z$, yielding bounds that improve over naive adaptations of classical full-inverse bounds by up to a factor of $\sqrt{n}$. Empirically, our bounds closely track the true perturbation error across a variety of real-world and synthetic matrices, while estimates based on classical results tend to significantly overpredict. These findings offer practical, spectrum-aware guarantees for low-rank inverse approximations in noisy computational environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25571v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.SP</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Phuc Tran, Nisheeth K. Vishnoi</dc:creator>
    </item>
    <item>
      <title>Spectral Perturbation Bounds for Low-Rank Approximation with Applications to Privacy</title>
      <link>https://arxiv.org/abs/2510.25670</link>
      <description>arXiv:2510.25670v1 Announce Type: cross 
Abstract: A central challenge in machine learning is to understand how noise or measurement errors affect low-rank approximations, particularly in the spectral norm. This question is especially important in differentially private low-rank approximation, where one aims to preserve the top-$p$ structure of a data-derived matrix while ensuring privacy. Prior work often analyzes Frobenius norm error or changes in reconstruction quality, but these metrics can over- or under-estimate true subspace distortion. The spectral norm, by contrast, captures worst-case directional error and provides the strongest utility guarantees. We establish new high-probability spectral-norm perturbation bounds for symmetric matrices that refine the classical Eckart--Young--Mirsky theorem and explicitly capture interactions between a matrix $A \in \mathbb{R}^{n \times n}$ and an arbitrary symmetric perturbation $E$. Under mild eigengap and norm conditions, our bounds yield sharp estimates for $\|(A + E)_p - A_p\|$, where $A_p$ is the best rank-$p$ approximation of $A$, with improvements of up to a factor of $\sqrt{n}$. As an application, we derive improved utility guarantees for differentially private PCA, resolving an open problem in the literature. Our analysis relies on a novel contour bootstrapping method from complex analysis and extends it to a broad class of spectral functionals, including polynomials and matrix exponentials. Empirical results on real-world datasets confirm that our bounds closely track the actual spectral error under diverse perturbation regimes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25670v1</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.SP</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Phuc Tran, Nisheeth K. Vishnoi, Van H. Vu</dc:creator>
    </item>
    <item>
      <title>LieSolver: A PDE-constrained solver for IBVPs using Lie symmetries</title>
      <link>https://arxiv.org/abs/2510.25731</link>
      <description>arXiv:2510.25731v1 Announce Type: cross 
Abstract: We introduce a method for efficiently solving initial-boundary value problems (IBVPs) that uses Lie symmetries to enforce the associated partial differential equation (PDE) exactly by construction. By leveraging symmetry transformations, the model inherently incorporates the physical laws and learns solutions from initial and boundary data. As a result, the loss directly measures the model's accuracy, leading to improved convergence. Moreover, for well-posed IBVPs, our method enables rigorous error estimation. The approach yields compact models, facilitating an efficient optimization. We implement LieSolver and demonstrate its application to linear homogeneous PDEs with a range of initial conditions, showing that it is faster and more accurate than physics-informed neural networks (PINNs). Overall, our method improves both computational efficiency and the reliability of predictions for PDE-constrained problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25731v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ren\'e P. Klausen, Ivan Timofeev, Johannes Frank, Jonas Naujoks, Thomas Wiegand, Sebastian Lapuschkin, Wojciech Samek</dc:creator>
    </item>
    <item>
      <title>MP-FVM: Enhancing Finite Volume Method for Water Infiltration Modeling in Unsaturated Soils via Message-passing Encoder-decoder Network</title>
      <link>https://arxiv.org/abs/2310.02806</link>
      <description>arXiv:2310.02806v3 Announce Type: replace 
Abstract: The spatiotemporal water flow dynamics in unsaturated soils can generally be modeled by the Richards equation. To overcome the computational challenges associated with solving this highly nonlinear partial differential equation (PDE), we present a novel solution algorithm, which we name as the MP-FVM (Message Passing-Finite Volume Method), to holistically integrate adaptive fixed-point iteration scheme, encoder-decoder neural network architecture, Sobolev training, and message passing mechanism in a finite volume discretization framework. We thoroughly discuss the need and benefits of introducing these components to achieve synergistic improvements in accuracy and stability of the solution. We also show that our MP-FVM algorithm can accurately solve the mixed-form $n$-dimensional Richards equation with guaranteed convergence under reasonable assumptions. Through several illustrative examples, we demonstrate that our MP-FVM algorithm not only achieves superior accuracy, but also better preserves the underlying physical laws and mass conservation of the Richards equation compared to state-of-the-art solution algorithms and the commercial HYDRUS solver.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.02806v3</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Zeyuan Song, Zheyu Jiang</dc:creator>
    </item>
    <item>
      <title>Scaling Optimized Hermite Approximation Methods</title>
      <link>https://arxiv.org/abs/2412.08044</link>
      <description>arXiv:2412.08044v3 Announce Type: replace 
Abstract: Hermite polynomials and functions have extensive applications in scientific and engineering problems. Although it is recognized that employing the scaled Hermite functions rather than the standard ones can remarkably enhance the approximation performance, the understanding of the scaling factor remains insufficient. Due to the lack of theoretical analysis, recent publications still cast doubt on whether the Hermite spectral method is inferior to other methods. To dispel this doubt, we show in this article that the inefficiency of the Hermite spectral method comes from the imbalance in the decay speed of the objective function within the spatial and frequency domains. Proper scaling can render the Hermite spectral methods comparable to other methods. To make it solid, we propose a novel error analysis framework for the scaled Hermite approximation. Taking the $L^2$ projection error as an example, our framework illustrates that there are three different components of errors: the spatial truncation error, the frequency truncation error, and the Hermite spectral approximation error. Through this perspective, finding the optimal scaling factor is equivalent to balancing the spatial and frequency truncation errors. As applications, we show that geometric convergence can be recovered by proper scaling for a class of functions. Furthermore, we show that proper scaling can double the convergence order for smooth functions with algebraic decay. The perplexing pre-asymptotic sub-geometric convergence when approximating algebraic decay functions can be perfectly explained by this framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.08044v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Hao Hu, Haijun Yu</dc:creator>
    </item>
    <item>
      <title>Asymptotic uniform estimate of random batch method with replacement for the Cucker-Smale model</title>
      <link>https://arxiv.org/abs/2501.15152</link>
      <description>arXiv:2501.15152v3 Announce Type: replace 
Abstract: The Random Batch Method (RBM) [S. Jin, L. Li and J.-G. Liu, Random Batch Methods (RBM) for interacting particle systems, J. Comput. Phys. 400 (2020) 108877] is not only an efficient algorithm for simulating interacting particle systems, but also a randomly switching networked model for interacting particle system. This work investigates two RBM variants (RBM-r and RBM-1) applied to the Cucker-Smale flocking model. We establish the asymptotic emergence of global flocking and derive corresponding error estimates. By introducing a crucial auxiliary system and leveraging the intrinsic characteristics of the Cucker-Smale model, and under suitable conditions on the force, our estimates are uniform in both time and particle numbers. In the case of RBM-1, our estimates are sharper than those in Ha et al. (2021). Additionally, we provide numerical simulations to validate our analytical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.15152v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shi Jin, Yuelin Wang, Yuliang Wang</dc:creator>
    </item>
    <item>
      <title>Optimal morphings for model-order reduction for poorly reducible problems with geometric variability</title>
      <link>https://arxiv.org/abs/2502.11632</link>
      <description>arXiv:2502.11632v2 Announce Type: replace 
Abstract: We propose a new model-order reduction framework to poorly reducible problems arising from parametric partial differential equations with geometric variability. In such problems, the solution manifold exhibits a slowly decaying Kolmogorov $N$-width, so that standard projection-based model order reduction techniques based on linear subspace approximations become ineffective. To overcome this difficulty, we introduce an optimal morphing strategy: For each solution sample, we compute a bijective morphing from a reference domain to the sample domain such that, when all the solution fields are pulled back to the reference domain, their variability is reduced. We formulate a global optimization problem on the morphings that maximizes the energy captured by the first $r$ modes of the mapped fields obtained from Proper Orthogonal Decomposition, thus maximizing the reducibility of the dataset. Finally, using a non-intrusive Gaussian Process regression on the reduced coordinates, we build a fast surrogate model that can accurately predict new solutions, highlighting the practical benefits of the proposed approach for many-query applications. The framework is general, independent of the underlying partial differential equation, and applies to scenarios with either parameterized or non-parameterized geometries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11632v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abbas Kabalan, Fabien Casenave, Felipe Bordeu, Virginie Ehrlacher, Alexandre Ern</dc:creator>
    </item>
    <item>
      <title>Polynomial Inequalities and Optimal Stability of Numerical Integrators</title>
      <link>https://arxiv.org/abs/2503.24232</link>
      <description>arXiv:2503.24232v2 Announce Type: replace 
Abstract: A numerical integrator for $\dot{x}=f(x)$ is called \emph{stable} if, when applied to the 1D Dahlquist test equation $\dot{x}=\lambda x,\lambda\in\mathbb{C}$ with fixed timestep $h&gt;0$, the numerical solution remains bounded as the number of steps tends to infinity. It is well known that no explicit integrator may remain stable beyond certain limits in $\lambda$. Furthermore, these stability limits are only tight for certain specific integrators (different in each case), which may then be called `optimally stable'. Such optimal stability results are typically proven using sophisticated techniques from complex analysis, leading to rather abstruse proofs. In this article, we pursue an alternative approach, exploiting connections with the Bernstein and Markov brothers inequalities for polynomials. This simplifies the proofs greatly and offers a framework which unifies the diverse results that have been obtained.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.24232v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.HO</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luke Shaw</dc:creator>
    </item>
    <item>
      <title>A variational symplectic scheme based on Lobatto's quadrature</title>
      <link>https://arxiv.org/abs/2504.00560</link>
      <description>arXiv:2504.00560v3 Announce Type: replace 
Abstract: We present a variational integrator based on the Lobatto quadrature for the time integration of dynamical systems issued from the least action principle. This numerical method uses a cubic interpolation of the states and the action is approximated at each time step by Lobatto's formula. Numerical analysis is performed on both a harmonic oscillator and a nonlinear pendulum. The geometric scheme is conditionally stable, sixth-order accurate, and symplectic. It preserves an approximate energy quantity. Simulation results illustrate the performance and the superconvergence of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.00560v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>7th International Conference on Geometric Science of Information, Oct 2025, Saint-Malo, France. pp.332-342</arxiv:journal_reference>
      <dc:creator>Fran\c{c}ois Dubois (LMSSC, LMO), Juan Antonio Rojas-Quintero (TecNM)</dc:creator>
    </item>
    <item>
      <title>Partial integration based regularization in BEM for 3D elastostatic problems: The role of line integrals</title>
      <link>https://arxiv.org/abs/2505.00713</link>
      <description>arXiv:2505.00713v2 Announce Type: replace 
Abstract: The Boundary Element Method (BEM) is a powerful numerical approach for solving 3D elastostatic problems, particularly useful for crack propagation in fracture mechanics and half-space problems. A key challenge in BEM lies in handling singular integral kernels. Various analytical and numerical integration or regularization techniques address this, including one that combines partial integration with Stokes' theorem to reduce hyper-singular and strong singular kernels to weakly singular ones. This approach typically assumes a closed surface, omitting the boundary integrals from Stokes' theorem. In this paper, these usually neglected boundary line integrals are introduced and their significance is demonstrated, first in a pure half-space problem, and then shown to be redundant in fast multipole method (FMM) based BEM, where geometry partitioning produces pseudo open surfaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00713v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.enganabound.2025.106513</arxiv:DOI>
      <arxiv:journal_reference>Engineering Analysis with Boundary Elements, 181, 106513, 2025</arxiv:journal_reference>
      <dc:creator>Vibudha Lakshmi Keshava, Martin Schanz</dc:creator>
    </item>
    <item>
      <title>Efficient Krylov methods for linear response in plane-wave electronic structure calculations</title>
      <link>https://arxiv.org/abs/2505.02319</link>
      <description>arXiv:2505.02319v2 Announce Type: replace 
Abstract: We propose a novel algorithm based on inexact GMRES methods for linear response calculations in density functional theory. Such calculations require iteratively solving a nested linear problem $\mathcal{E} \delta\rho = b$ to obtain the variation of the electron density $\delta \rho$. Notably each application of the dielectric operator $\mathcal{E}$ in turn requires the iterative solution of multiple linear systems, the Sternheimer equations. We develop computable bounds to estimate the accuracy of the density variation given the tolerances to which the Sternheimer equations have been solved. Based on this result we suggest reliable strategies for adaptively selecting the convergence tolerances of the Sternheimer equations, such that each application of $\mathcal{E}$ is no more accurate than needed. Experiments on challenging materials systems of practical relevance demonstrate our strategies to achieve superlinear convergence as well as a reduction of computational time by about 40% while preserving the accuracy of the returned response solution. Our algorithm seamlessly combines with standard preconditioning approaches known from the context of self-consistent field problems making it a promising framework for efficient response solvers based on Krylov subspace techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02319v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael F. Herbst, Bonan Sun</dc:creator>
    </item>
    <item>
      <title>Embedding General Conservation Constraints in Discretizations of Hyperbolic Systems on Arbitrary Meshes: A Multidimensional Framework</title>
      <link>https://arxiv.org/abs/2509.25967</link>
      <description>arXiv:2509.25967v2 Announce Type: replace 
Abstract: The purpose of this review is to discuss the notion of conservation in hyperbolic systems and how one can formulate it at the discrete level depending on the solution representation of the solution. A general theory is difficult. We discuss several possibilities: if the solution is represented by average in volumes; if the mesh is staggerred; if the solution is solely represented by point values and an example where all the previous options are mixed.
  We show how each configuration can provide, or not, enough flexibility. The discussion could be adapted to any hyperbolic system endowed with an entropy, but we focus on compressible fluid mechanics, in its Eulerian and Lagrangian formulations. The unifying element is that we systematically express the update of conserved variables as $u^{n+1}=u^n- \Delta t\; \delta u$, where the functional $\delta u$ depends on the value of $u$ in the stencil of the scheme. Then, one can naturally define a graph connecting the states defining $\delta u$. The notion of local conservation can be defined from this graph. We are aware of only two possible situations: either the graph is constructed from the faces of the mesh elements (or the dual mesh), or it is defined from the mesh itself. Two notions of local conservation then emerge: either we define a numerical flux, or we define a "residual" attached to elements and the degrees of freedom within the element. We show that this two notions are in a way equivalent, but the one with residual allows much more flexibility, especially if additional algebraic constraints must be satisfied. Examples of specific additional conservation constraints are provided to illustrate this. We also show that this notion of conservation gives a very clear framework for the design of scheme in the Lagrangian framework. We end by providing a number of ongoing research questions, and highlight some open questions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.25967v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>R\'emi Abgrall, Pierre-Henri Maire, Mario Ricchiuto</dc:creator>
    </item>
    <item>
      <title>Auto-Adaptive PINNs with Applications to Phase Transitions</title>
      <link>https://arxiv.org/abs/2510.23999</link>
      <description>arXiv:2510.23999v2 Announce Type: replace 
Abstract: We propose an adaptive sampling method for the training of Physics Informed Neural Networks (PINNs) which allows for sampling based on an arbitrary problem-specific heuristic which may depend on the network and its gradients. In particular we focus our analysis on the Allen-Cahn equations, attempting to accurately resolve the characteristic interfacial regions using a PINN without any post-hoc resampling. In experiments, we show the effectiveness of these methods over residual-adaptive frameworks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.23999v2</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kevin Buck, Woojeong Kim</dc:creator>
    </item>
    <item>
      <title>Hadamard-Hitchcock decompositions: identifiability and computation</title>
      <link>https://arxiv.org/abs/2308.06597</link>
      <description>arXiv:2308.06597v2 Announce Type: replace-cross 
Abstract: A Hadamard-Hitchcock decomposition of a multidimensional array is a decomposition that expresses the latter as a Hadamard product of several tensor rank decompositions. Such decompositions can encode probability distributions that arise from statistical graphical models associated to complete bipartite graphs with one layer of observed random variables and one layer of hidden ones, usually called restricted Boltzmann machines. We establish generic identifiability of Hadamard-Hitchcock decompositions by exploiting the reshaped Kruskal criterion for tensor rank decompositions. A flexible algorithm leveraging existing decomposition algorithms for tensor rank decomposition is introduced for computing a Hadamard-Hitchcock decomposition. Numerical experiments illustrate its computational performance and numerical accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.06597v2</guid>
      <category>math.AG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alessandro Oneto, Nick Vannieuwenhoven</dc:creator>
    </item>
    <item>
      <title>A linear, unconditionally stable, second order decoupled method for the Ericksen-Leslie model with SAV approach</title>
      <link>https://arxiv.org/abs/2503.19424</link>
      <description>arXiv:2503.19424v3 Announce Type: replace-cross 
Abstract: In this paper, we present a second order, linear, fully decoupled, and unconditionally energy stable scheme for solving the Erickson-Leslie model. This approach integrates the pressure correction method with a scalar auxiliary variable technique. We rigorously demonstrate the unconditional energy stability of the proposed scheme. Furthermore, we present several numerical experiments to validate its convergence order, stability, and computational efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.19424v3</guid>
      <category>math.AP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ruonan Cao, Nianyu Yi</dc:creator>
    </item>
    <item>
      <title>UGM2N: An Unsupervised and Generalizable Mesh Movement Network via M-Uniform Loss</title>
      <link>https://arxiv.org/abs/2508.08615</link>
      <description>arXiv:2508.08615v2 Announce Type: replace-cross 
Abstract: Partial differential equations (PDEs) form the mathematical foundation for modeling physical systems in science and engineering, where numerical solutions demand rigorous accuracy-efficiency tradeoffs. Mesh movement techniques address this challenge by dynamically relocating mesh nodes to rapidly-varying regions, enhancing both simulation accuracy and computational efficiency. However, traditional approaches suffer from high computational complexity and geometric inflexibility, limiting their applicability, and existing supervised learning-based approaches face challenges in zero-shot generalization across diverse PDEs and mesh topologies.In this paper, we present an Unsupervised and Generalizable Mesh Movement Network (UGM2N). We first introduce unsupervised mesh adaptation through localized geometric feature learning, eliminating the dependency on pre-adapted meshes. We then develop a physics-constrained loss function, M-Uniform loss, that enforces mesh equidistribution at the nodal level.Experimental results demonstrate that the proposed network exhibits equation-agnostic generalization and geometric independence in efficient mesh adaptation. It demonstrates consistent superiority over existing methods, including robust performance across diverse PDEs and mesh geometries, scalability to multi-scale resolutions and guaranteed error reduction without mesh tangling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08615v2</guid>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhichao Wang, Xinhai Chen, Qinglin Wang, Xiang Gao, Qingyang Zhang, Menghan Jia, Xiang Zhang, Jie Liu</dc:creator>
    </item>
    <item>
      <title>The exterior derivative and the mean value equality in $\mathbb{R}^n$</title>
      <link>https://arxiv.org/abs/2510.00999</link>
      <description>arXiv:2510.00999v2 Announce Type: replace-cross 
Abstract: This survey revisits classical results in vector calculus and analysis by exploring a generalised perspective on the exterior derivative, interpreting it as a measure of "infinitesimal flux". This viewpoint leads to a higher-dimensional analogue of the Mean Value Theorem, valid for differential $k$-forms, and provides a natural formulation of Stokes' theorem that mirrors the exact hypotheses of the Fundamental Theorem of Calculus -- without requiring full $C^1$ smoothness of the differential form.
  As a numerical application, we propose an algorithm for exterior differentiation in $\mathbb{R}^n$ that relies solely on black-box access to the differential form, offering a practical tool for computation without the need for mesh discretization or explicit symbolic expressions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00999v2</guid>
      <category>math.DG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Fadel, Henrique N. S\'a Earp, Tom\'as S. R. Silva</dc:creator>
    </item>
    <item>
      <title>Quantitative Hypocoercivity and Lifting of Classical and Quantum Dynamics</title>
      <link>https://arxiv.org/abs/2510.22305</link>
      <description>arXiv:2510.22305v2 Announce Type: replace-cross 
Abstract: We consider quantitative convergence analysis for hypocoercive dynamics such as Langevin and Lindblad equations describing classical and quantum open systems. Our goal is to provide an overview of recent results of hypocoercivity estimates based on space-time Poincare inequality, providing a unified treatment for classical and quantum dynamics. Furthermore, we also present a unified lifting framework for accelerating both classical and quantum Markov semigroups, which leads to upper and lower bounds of convergence rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22305v2</guid>
      <category>math.AP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jianfeng Lu</dc:creator>
    </item>
  </channel>
</rss>
