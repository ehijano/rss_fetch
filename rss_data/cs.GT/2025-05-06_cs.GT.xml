<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 07 May 2025 01:46:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>When is Truthfully Allocating Chores no Harder than Goods?</title>
      <link>https://arxiv.org/abs/2505.01629</link>
      <description>arXiv:2505.01629v1 Announce Type: new 
Abstract: We study the problem of fairly and efficiently allocating a set of items among strategic agents with additive valuations, where items are either all indivisible or all divisible. When items are \emph{goods}, numerous positive and negative results are known regarding the fairness and efficiency guarantees achievable by \emph{truthful} mechanisms, whereas our understanding of truthful mechanisms for \emph{chores} remains considerably more limited. In this paper, we discover various connections between truthful good and chore allocations, greatly enhancing our understanding of the latter via tools from the former.
  For indivisible chores with two agents, we observe that a simple bundle-swapping operation transforms several properties for goods including truthfulness to the corresponding properties for chores, which enables us to characterize truthful mechanisms and derive the tight guarantees of various fairness notions achieved by truthful mechanisms. Moreover, for divisible chores, by generalizing the above transformation to an arbitrary number of agents, we characterize truthful mechanisms with two agents, show that every truthful mechanism with two agents admits an \emph{efficiency ratio} of $0$, and derive a large family of \emph{strictly truthful}, \emph{envy-free (EF)}, and \emph{proportional} mechanisms for an arbitrary number of agents. Finally, for indivisible chores with an arbitrary number of agents having \emph{bi-valued} cost functions, we give an \emph{ex-ante} truthful, ex-ante \emph{Pareto optimal}, ex-ante EF, and \emph{ex-post envy-free up to one item} mechanism, improving the best guarantees for bi-valued instances by prior works.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01629v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bo Li, Biaoshuai Tao, Fangxiao Wang, Xiaowei Wu, Mingwei Yang, Shengwei Zhou</dc:creator>
    </item>
    <item>
      <title>Stochastic Games with Limited Public Memory</title>
      <link>https://arxiv.org/abs/2505.02623</link>
      <description>arXiv:2505.02623v1 Announce Type: new 
Abstract: We study the memory resources required for near-optimal play in two-player zero-sum stochastic games with the long-run average payoff. Although optimal strategies may not exist in such games, near-optimal strategies always do.
  Mertens and Neyman (1981) proved that in any stochastic game, for any $\varepsilon&gt;0$, there exist uniform $\varepsilon$-optimal memory-based strategies -- i.e., strategies that are $\varepsilon$-optimal in all sufficiently long $n$-stage games -- that use at most $O(n)$ memory states within the first $n$ stages. We improve this bound on the number of memory states by proving that in any stochastic game, for any $\varepsilon&gt;0$, there exist uniform $\varepsilon$-optimal memory-based strategies that use at most $O(\log n)$ memory states in the first $n$ stages. Moreover, we establish the existence of uniform $\varepsilon$-optimal memory-based strategies whose memory updating and action selection are time-independent and such that, with probability close to 1, for all $n$, the number of memory states used up to stage $n$ is at most $O(\log n)$.
  This result cannot be extended to strategies with bounded public memory -- even if time-dependent memory updating and action selection are allowed. This impossibility is illustrated in the Big Match -- a well-known stochastic game where the stage payoffs to Player 1 are 0 or 1. Although for any $\varepsilon &gt; 0$, there exist strategies of Player 1 that guarantee a payoff {exceeding} $1/2 - \varepsilon$ in all sufficiently long $n$-stage games, we show that any strategy of Player 1 that uses a finite public memory fails to guarantee a payoff greater than $\varepsilon$ in any sufficiently long $n$-stage game.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02623v1</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kristoffer Arnsfelt Hansen, Rasmus Ibsen-Jensen, Abraham Neyman</dc:creator>
    </item>
    <item>
      <title>Adaptive Bidding Policies for First-Price Auctions with Budget Constraints under Non-stationarity</title>
      <link>https://arxiv.org/abs/2505.02796</link>
      <description>arXiv:2505.02796v1 Announce Type: new 
Abstract: We study how a budget-constrained bidder should learn to adaptively bid in repeated first-price auctions to maximize her cumulative payoff. This problem arose due to an industry-wide shift from second-price auctions to first-price auctions in display advertising recently, which renders truthful bidding (i.e., always bidding one's private value) no longer optimal. We propose a simple dual-gradient-descent-based bidding policy that maintains a dual variable for budget constraint as the bidder consumes her budget. In analysis, we consider two settings regarding the bidder's knowledge of her private values in the future: (i) an uninformative setting where all the distributional knowledge (can be non-stationary) is entirely unknown to the bidder, and (ii) an informative setting where a prediction of the budget allocation in advance. We characterize the performance loss (or regret) relative to an optimal policy with complete information on the stochasticity. For uninformative setting, We show that the regret is \tilde{O}(\sqrt{T}) plus a variation term that reflects the non-stationarity of the value distributions, and this is of optimal order. We then show that we can get rid of the variation term with the help of the prediction; specifically, the regret is \tilde{O}(\sqrt{T}) plus the prediction error term in the informative setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02796v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yige Wang, Jiashuo Jiang</dc:creator>
    </item>
    <item>
      <title>Incentivizing Inclusive Contributions in Model Sharing Markets</title>
      <link>https://arxiv.org/abs/2505.02462</link>
      <description>arXiv:2505.02462v1 Announce Type: cross 
Abstract: While data plays a crucial role in training contemporary AI models, it is acknowledged that valuable public data will be exhausted in a few years, directing the world's attention towards the massive decentralized private data. However, the privacy-sensitive nature of raw data and lack of incentive mechanism prevent these valuable data from being fully exploited. Addressing these challenges, this paper proposes inclusive and incentivized personalized federated learning (iPFL), which incentivizes data holders with diverse purposes to collaboratively train personalized models without revealing raw data. iPFL constructs a model-sharing market by solving a graph-based training optimization and incorporates an incentive mechanism based on game theory principles. Theoretical analysis shows that iPFL adheres to two key incentive properties: individual rationality and truthfulness. Empirical studies on eleven AI tasks (e.g., large language models' instruction-following tasks) demonstrate that iPFL consistently achieves the highest economic utility, and better or comparable model performance compared to baseline methods. We anticipate that our iPFL can serve as a valuable technique for boosting future AI models on decentralized private data while making everyone satisfied.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02462v1</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.GT</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Enpei Zhang, Jingyi Chai, Rui Ye, Yanfeng Wang, Siheng Chen</dc:creator>
    </item>
    <item>
      <title>Approximately Dominating Sets in Elections</title>
      <link>https://arxiv.org/abs/2504.20372</link>
      <description>arXiv:2504.20372v2 Announce Type: replace 
Abstract: Condorcet's paradox is a fundamental result in social choice theory which states that there exist elections in which, no matter which candidate wins, a majority of voters prefer a different candidate. In fact, even if we can select any $k$ winners, there still may exist another candidate that would beat each of the winners in a majority vote. That is, elections may require arbitrarily large dominating sets.
  We show that approximately dominating sets of constant size always exist. In particular, for every $\varepsilon &gt; 0$, every election (irrespective of the number of voters or candidates) can select $O(\frac{1}{\varepsilon ^2})$ winners such that no other candidate beats each of the winners by a margin of more than $\varepsilon$ fraction of voters.
  Our proof uses a simple probabilistic construction using samples from a maximal lottery, a well-studied distribution over candidates derived from the Nash equilibrium of a two-player game. In stark contrast to general approximate equilibria, which may require support logarithmic in the number of pure strategies, we show that maximal lotteries can be approximated with constant support size. These approximate maximal lotteries may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.20372v2</guid>
      <category>cs.GT</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Moses Charikar, Prasanna Ramakrishnan, Kangning Wang</dc:creator>
    </item>
    <item>
      <title>Truthful mechanisms for linear bandit games with private contexts</title>
      <link>https://arxiv.org/abs/2501.03865</link>
      <description>arXiv:2501.03865v3 Announce Type: replace-cross 
Abstract: The contextual bandit problem, where agents arrive sequentially with personal contexts and the system adapts its arm allocation decisions accordingly, has recently garnered increasing attention for enabling more personalized outcomes. However, in many healthcare and recommendation applications, agents have private profiles and may misreport their contexts to gain from the system. For example, in adaptive clinical trials, where hospitals sequentially recruit volunteers to test multiple new treatments and adjust plans based on volunteers' reported profiles such as symptoms and interim data, participants may misreport severe side effects like allergy and nausea to avoid perceived suboptimal treatments. We are the first to study this issue of private context misreporting in a stochastic contextual bandit game between the system and non-repeated agents. We show that traditional low-regret algorithms, such as UCB family algorithms and Thompson sampling, fail to ensure truthful reporting and can result in linear regret in the worst case, while traditional truthful algorithms like explore-then-commit (ETC) and $\epsilon$-greedy algorithm incur sublinear but high regret. We propose a mechanism that uses a linear program to ensure truthfulness while minimizing deviation from Thompson sampling, yielding an $O(\ln T)$ frequentist regret. Our numerical experiments further demonstrate strong performance in multiple contexts and across other distribution families.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03865v3</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiting Hu, Lingjie Duan</dc:creator>
    </item>
    <item>
      <title>A Theoretical Model for Grit in Pursuing Ambitious Ends</title>
      <link>https://arxiv.org/abs/2503.02952</link>
      <description>arXiv:2503.02952v2 Announce Type: replace-cross 
Abstract: Ambition and risk-taking have been heralded as important ways for marginalized communities to get out of cycles of poverty. As a result, educational messaging often encourages individuals to strengthen their personal resolve and develop characteristics such as discipline and grit to succeed in ambitious ends. However, recent work in philosophy and sociology highlights that this messaging often does more harm than good for students in these situations. We study similar questions using a different epistemic approach and in simple theoretical models -- we provide a quantitative model of decision-making between stable and risky choices in the improving multi-armed bandits framework. We use this model to first study how individuals' "strategies" are affected by their level of grittiness and how this affects their accrued rewards. Then, we study the impact of various interventions, such as increasing grit or providing a financial safety net. Our investigation of rational decision making involves two different formal models of rationality, the competitive ratio between the accrued reward and the optimal reward and Bayesian quantification of uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02952v2</guid>
      <category>cs.CY</category>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <category>stat.AP</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Avrim Blum, Emily Diana, Kavya Ravichandran, Alexander Williams Tolbert</dc:creator>
    </item>
  </channel>
</rss>
