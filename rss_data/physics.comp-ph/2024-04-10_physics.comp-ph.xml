<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.comp-ph updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.comp-ph</link>
    <description>physics.comp-ph updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.comp-ph" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 10 Apr 2024 04:01:07 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 10 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Computing Transition Pathways for the Study of Rare Events Using Deep Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2404.05905</link>
      <description>arXiv:2404.05905v1 Announce Type: new 
Abstract: Understanding the transition events between metastable states in complex systems is an important subject in the fields of computational physics, chemistry and biology. The transition pathway plays an important role in characterizing the mechanism underlying the transition, for example, in the study of conformational changes of bio-molecules. In fact, computing the transition pathway is a challenging task for complex and high-dimensional systems. In this work, we formulate the path-finding task as a cost minimization problem over a particular path space. The cost function is adapted from the Freidlin-Wentzell action functional so that it is able to deal with rough potential landscapes. The path-finding problem is then solved using a actor-critic method based on the deep deterministic policy gradient algorithm (DDPG). The method incorporates the potential force of the system in the policy for generating episodes and combines physical properties of the system with the learning process for molecular systems. The exploitation and exploration nature of reinforcement learning enables the method to efficiently sample the transition events and compute the globally optimal transition pathway. We illustrate the effectiveness of the proposed method using three benchmark systems including an extended Mueller system and the Lennard-Jones system of seven particles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05905v1</guid>
      <category>physics.comp-ph</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bo Lin, Yangzheng Zhong, Weiqing Ren</dc:creator>
    </item>
    <item>
      <title>Deep Learning Method for Computing Committor Functions with Adaptive Sampling</title>
      <link>https://arxiv.org/abs/2404.06206</link>
      <description>arXiv:2404.06206v1 Announce Type: new 
Abstract: The committor function is a central object for quantifying the transitions between metastable states of dynamical systems. Recently, a number of computational methods based on deep neural networks have been developed for computing the high-dimensional committor function. The success of the methods relies on sampling adequate data for the transition, which still is a challenging task for complex systems at low temperatures. In this work, we propose a deep learning method with two novel adaptive sampling schemes (I and II). In the two schemes, the data are generated actively with a modified potential where the bias potential is constructed from the learned committor function. We theoretically demonstrate the advantages of the sampling schemes and show that the data in sampling scheme II are uniformly distributed along the transition tube. This makes a promising method for studying the transition of complex systems. The efficiency of the method is illustrated in high-dimensional systems including the alanine dipeptide and a solvated dimer system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06206v1</guid>
      <category>physics.comp-ph</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bo Lin, Weiqing Ren</dc:creator>
    </item>
    <item>
      <title>Facilities and practices for linear response Hubbard parameters U and J in Abinit</title>
      <link>https://arxiv.org/abs/2404.06284</link>
      <description>arXiv:2404.06284v1 Announce Type: new 
Abstract: Members of the DFT+U family of functionals are increasingly prevalent methods of addressing errors intrinsic to (semi-) local exchange-correlation functionals at minimum computational cost, but require their parameters U and J to be calculated in situ for a given system of interest, simulation scheme, and runtime parameters. The SCF linear response approach offers ab initio acquisition of the U and has recently been extended to compute the J analogously, which measures localized errors related to exchange-like effects. We introduce a renovated post-processor, the lrUJ utility, together with this detailed best-practices guide, to enable users of the popular, open-source Abinit first-principles simulation suite to engage easily with in situ Hubbard parameters and streamline their incorporation into material simulations of interest. Features of this utility, which may also interest users and developers of other DFT codes, include $n$-degree polynomial regression, error analysis, Python plotting facilities, didactic documentation, and avenues for further developments. In this technical introduction and guide, we place particular emphasis on the intricacies and potential pitfalls introduced by the projector augmented wave (PAW) method, SCF mixing schemes, and non-linear response, several of which are translatable to DFT+U(+J) implementations in other packages.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06284v1</guid>
      <category>physics.comp-ph</category>
      <category>cond-mat.mtrl-sci</category>
      <category>cond-mat.str-el</category>
      <category>physics.chem-ph</category>
      <category>quant-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>L\'orien MacEnulty, Matteo Giantomassi, Bernard Amadon, Gian-Marco Rignanese, David D. O'Regan</dc:creator>
    </item>
    <item>
      <title>Quantum-inspired activation functions in the convolutional neural network</title>
      <link>https://arxiv.org/abs/2404.05901</link>
      <description>arXiv:2404.05901v1 Announce Type: cross 
Abstract: Driven by the significant advantages offered by quantum computing, research in quantum machine learning has increased in recent years. While quantum speed-up has been demonstrated in some applications of quantum machine learning, a comprehensive understanding of its underlying mechanisms for improved performance remains elusive. Our study fills this gap by examining the expressibility of quantum circuits integrated within a convolutional neural network (CNN). Through numerical training on the MNIST dataset, our hybrid quantum-classical CNN model exhibited superior feature selection capabilities and significantly reduced the required training steps compared to the classical CNN. To understand the root of this enhanced performance, we conducted an analytical investigation of the functional expressibility of quantum circuits and derived a quantum activation function. We demonstrated that this quantum activation is more efficient in selecting important features and discarding unimportant information of input images. These findings not only deepen our comprehension of quantum-enhanced machine-learning models but also advance the classical machine-learning technique by introducing the quantum-inspired activation function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05901v1</guid>
      <category>quant-ph</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Shaozhi Li, M Sabbir Salek, Yao Wang, Mashrur Chowdhury</dc:creator>
    </item>
    <item>
      <title>Complete Active Space Iterative Coupled Cluster Theory</title>
      <link>https://arxiv.org/abs/2404.06070</link>
      <description>arXiv:2404.06070v1 Announce Type: cross 
Abstract: In this work, we investigate the possibility of improving multireference-driven coupled cluster (CC) approaches with an algorithm that iteratively combines complete active space (CAS) calculations with tailored CC and externally corrected CC. This is accomplished by establishing a feedback loop between the CC and CAS parts of a calculation through similarity transformation of the Hamiltonian with those CC amplitudes that are not encompassed by the active space. We denote this approach the complete active space iterative coupled cluster (CASiCC) ansatz. We investigate its efficiency and accuracy in the singles and doubles approximation by studying the prototypical molecules H4, H8, H2O, and N2. Our results demonstrate that CASiCC systematically improves on the single-reference CCSD and the ecCCSD methods across entire potential energy curves, while retaining modest computational costs. However, the tailored coupled cluster method shows superior performance in the strong correlation regime suggesting that its accuracy is based on error compensation. We find that the iterative version of externally corrected and tailored coupled cluster methods converge to the same results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06070v1</guid>
      <category>physics.chem-ph</category>
      <category>cond-mat.str-el</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Robin Feldmann, Max M\"orchen, Jakub Lang, Micha\l\ Lesiuk, Markus Reiher</dc:creator>
    </item>
    <item>
      <title>Dynamic Deep Learning Based Super-Resolution For The Shallow Water Equations</title>
      <link>https://arxiv.org/abs/2404.06400</link>
      <description>arXiv:2404.06400v1 Announce Type: cross 
Abstract: Using the nonlinear shallow water equations as benchmark, we demonstrate that a simulation with the ICON-O ocean model with a 20km resolution that is frequently corrected by a U-net-type neural network can achieve discretization errors of a simulation with 10km resolution. The network, originally developed for image-based super-resolution in post-processing, is trained to compute the difference between solutions on both meshes and is used to correct the coarse mesh every 12h. Our setup is the Galewsky test case, modeling transition of a barotropic instability into turbulent flow. We show that the ML-corrected coarse resolution run correctly maintains a balance flow and captures the transition to turbulence in line with the higher resolution simulation. After 8 day of simulation, the $L_2$-error of the corrected run is similar to a simulation run on the finer mesh. While mass is conserved in the corrected runs, we observe some spurious generation of kinetic energy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06400v1</guid>
      <category>cs.LG</category>
      <category>physics.comp-ph</category>
      <category>physics.flu-dyn</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maximilian Witte, Fabricio Rodrigues Lapolli, Philip Freese, Sebastian G\"otschel, Daniel Ruprecht, Peter Korn, Christopher Kadow</dc:creator>
    </item>
    <item>
      <title>Thermodynamics-inspired Explanations of Artificial Intelligence</title>
      <link>https://arxiv.org/abs/2206.13475</link>
      <description>arXiv:2206.13475v3 Announce Type: replace-cross 
Abstract: In recent years, predictive machine learning methods have gained prominence in various scientific domains. However, due to their black-box nature, it is essential to establish trust in these models before accepting them as accurate. One promising strategy for assigning trust involves employing explanation techniques that elucidate the rationale behind a black-box model's predictions in a manner that humans can understand. However, assessing the degree of human interpretability of the rationale generated by such methods is a nontrivial challenge. In this work, we introduce interpretation entropy as a universal solution for assessing the degree of human interpretability associated with any linear model. Using this concept and drawing inspiration from classical thermodynamics, we present Thermodynamics-inspired Explainable Representations of AI and other black-box Paradigms (TERP), a method for generating accurate, and human-interpretable explanations for black-box predictions in a model-agnostic manner. To demonstrate the wide-ranging applicability of TERP, we successfully employ it to explain various black-box model architectures, including deep learning Autoencoders, Recurrent Neural Networks, and Convolutional Neural Networks, across diverse domains such as molecular simulations, text, and image classification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.13475v3</guid>
      <category>cond-mat.stat-mech</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.LG</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shams Mehdi, Pratyush Tiwary</dc:creator>
    </item>
    <item>
      <title>EPR-Net: Constructing non-equilibrium potential landscape via a variational force projection formulation</title>
      <link>https://arxiv.org/abs/2301.01946</link>
      <description>arXiv:2301.01946v3 Announce Type: replace-cross 
Abstract: We present EPR-Net, a novel and effective deep learning approach that tackles a crucial challenge in biophysics: constructing potential landscapes for high-dimensional non-equilibrium steady-state (NESS) systems. EPR-Net leverages a nice mathematical fact that the desired negative potential gradient is simply the orthogonal projection of the driving force of the underlying dynamics in a weighted inner-product space. Remarkably, our loss function has an intimate connection with the steady entropy production rate (EPR), enabling simultaneous landscape construction and EPR estimation. We introduce an enhanced learning strategy for systems with small noise, and extend our framework to include dimensionality reduction and state-dependent diffusion coefficient case in a unified fashion. Comparative evaluations on benchmark problems demonstrate the superior accuracy, effectiveness, and robustness of EPR-Net compared to existing methods. We apply our approach to challenging biophysical problems, such as an 8D limit cycle and a 52D multi-stability problem, which provide accurate solutions and interesting insights on constructed landscapes. With its versatility and power, EPR-Net offers a promising solution for diverse landscape construction problems in biophysics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.01946v3</guid>
      <category>physics.bio-ph</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.AI</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1093/nsr/nwae052</arxiv:DOI>
      <dc:creator>Yue Zhao, Wei Zhang, Tiejun Li</dc:creator>
    </item>
    <item>
      <title>Strongly stable dual-pairing summation by parts finite difference schemes for the vector invariant nonlinear shallow water equations -- I: Numerical scheme and validation on the plane</title>
      <link>https://arxiv.org/abs/2310.12739</link>
      <description>arXiv:2310.12739v2 Announce Type: replace-cross 
Abstract: We present an energy/entropy stable and high order accurate finite difference method for solving the nonlinear (rotating) shallow water equations (SWE) in vector invariant form using the newly developed dual-pairing and dispersion-relation preserving summation-by-parts finite difference operators. We derive new well-posed boundary conditions for the SWE in one space dimension, formulated in terms of fluxes and applicable to linear and nonlinear SWEs. For the nonlinear SWE, entropy stability ensures the boundedness of numerical solution but does not guarantee convergence. Adequate amount of numerical dissipation is necessary to control high frequency errors which could negatively impact accuracy in the numerical simulations. Using the dual-pairing summation by parts framework, we derive high order accurate and nonlinear hyper-viscosity operator which dissipates entropy and enstrophy. The hyper-viscosity operator effectively minimises oscillations from shocks and discontinuities, and eliminates high frequency grid-scale errors. The numerical method is most suitable for the simulations of subcritical flows typically observed in atmospheric and geostrophic flow problems. We prove a priori error estimates for the semi-discrete approximations of both linear and nonlinear SWE. Convergence, accuracy, and well-balanced properties are verified via the method of manufactured solutions and canonical test problems such as the dam break and lake at rest. Numerical simulations in two-dimensions are presented which include the rotating and merging vortex problem and barotropic shear instability, with fully developed turbulence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.12739v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>physics.ao-ph</category>
      <category>physics.comp-ph</category>
      <category>physics.flu-dyn</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Justin Kin Jun Hew, Kenneth Duru, Stephen Roberts, Christopher Zoppou, Kieran Ricardo</dc:creator>
    </item>
  </channel>
</rss>
