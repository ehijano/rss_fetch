<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SC</link>
    <description>cs.SC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 18 Feb 2025 05:01:17 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Modular Algorithms For Computing Gr\"obner Bases in Free Algebras</title>
      <link>https://arxiv.org/abs/2502.11606</link>
      <description>arXiv:2502.11606v1 Announce Type: new 
Abstract: In this work, we extend modular techniques for computing Gr\"obner bases involving rational coefficients to (two-sided) ideals in free algebras. We show that the infinite nature of Gr\"obner bases in this setting renders the classical approach infeasible. Therefore, we propose a new method that relies on signature-based algorithms. Using the data of signatures, we can overcome the limitations of the classical approach and obtain a practical modular algorithm. Moreover, the final verification test in this setting is both more general and more efficient than the classical one. We provide a first implementation of our modular algorithm in SageMath. Initial experiments show that the new algorithm can yield significant speedups over the non-modular approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11606v1</guid>
      <category>cs.SC</category>
      <category>math.RA</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Clemens Hofstadler, Viktor Levandovskyy</dc:creator>
    </item>
    <item>
      <title>A Shape Lemma for Ideals of Differential Operators</title>
      <link>https://arxiv.org/abs/2502.11787</link>
      <description>arXiv:2502.11787v1 Announce Type: new 
Abstract: We propose a version of the classical shape lemma for zero-dimensional ideals of a commutative multivariate polynomial ring to the noncommutative setting of zero-dimensional ideals in an algebra of differential operators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11787v1</guid>
      <category>cs.SC</category>
      <category>math.AC</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Manuel Kauers, Christoph Koutschan, Thibaut Verron</dc:creator>
    </item>
    <item>
      <title>Unlocking the Potential of Generative AI through Neuro-Symbolic Architectures: Benefits and Limitations</title>
      <link>https://arxiv.org/abs/2502.11269</link>
      <description>arXiv:2502.11269v1 Announce Type: cross 
Abstract: Neuro-symbolic artificial intelligence (NSAI) represents a transformative approach in artificial intelligence (AI) by combining deep learning's ability to handle large-scale and unstructured data with the structured reasoning of symbolic methods. By leveraging their complementary strengths, NSAI enhances generalization, reasoning, and scalability while addressing key challenges such as transparency and data efficiency. This paper systematically studies diverse NSAI architectures, highlighting their unique approaches to integrating neural and symbolic components. It examines the alignment of contemporary AI techniques such as retrieval-augmented generation, graph neural networks, reinforcement learning, and multi-agent systems with NSAI paradigms. This study then evaluates these architectures against comprehensive set of criteria, including generalization, reasoning capabilities, transferability, and interpretability, therefore providing a comparative analysis of their respective strengths and limitations. Notably, the Neuro &gt; Symbolic &lt; Neuro model consistently outperforms its counterparts across all evaluation metrics. This result aligns with state-of-the-art research that highlight the efficacy of such architectures in harnessing advanced technologies like multi-agent systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11269v1</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SC</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Oualid Bougzime, Samir Jabbar, Christophe Cruz, Fr\'ed\'eric Demoly</dc:creator>
    </item>
    <item>
      <title>$\texttt{FORM}$: Learning Expressive and Transferable First-Order Logic Reward Machines</title>
      <link>https://arxiv.org/abs/2501.00364</link>
      <description>arXiv:2501.00364v2 Announce Type: replace-cross 
Abstract: Reward machines (RMs) are an effective approach for addressing non-Markovian rewards in reinforcement learning (RL) through finite-state machines. Traditional RMs, which label edges with propositional logic formulae, inherit the limited expressivity of propositional logic. This limitation hinders the learnability and transferability of RMs since complex tasks will require numerous states and edges. To overcome these challenges, we propose First-Order Reward Machines ($\texttt{FORM}$s), which use first-order logic to label edges, resulting in more compact and transferable RMs. We introduce a novel method for $\textbf{learning}$ $\texttt{FORM}$s and a multi-agent formulation for $\textbf{exploiting}$ them and facilitate their transferability, where multiple agents collaboratively learn policies for a shared $\texttt{FORM}$. Our experimental results demonstrate the scalability of $\texttt{FORM}$s with respect to traditional RMs. Specifically, we show that $\texttt{FORM}$s can be effectively learnt for tasks where traditional RM learning approaches fail. We also show significant improvements in learning speed and task transferability thanks to the multi-agent learning framework and the abstraction provided by the first-order language.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.00364v2</guid>
      <category>cs.AI</category>
      <category>cs.FL</category>
      <category>cs.LO</category>
      <category>cs.SC</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Leo Ardon, Daniel Furelos-Blanco, Roko Parac, Alessandra Russo</dc:creator>
    </item>
  </channel>
</rss>
