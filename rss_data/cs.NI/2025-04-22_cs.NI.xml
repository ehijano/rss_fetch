<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 23 Apr 2025 01:48:48 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Statistical Analysis and End-to-End Performance Evaluation of Traffic Models for Automotive Data</title>
      <link>https://arxiv.org/abs/2504.14017</link>
      <description>arXiv:2504.14017v1 Announce Type: new 
Abstract: Autonomous driving is a major paradigm shift in transportation, with the potential to enhance safety, optimize traffic congestion, and reduce fuel consumption. Although autonomous vehicles rely on advanced sensors and on-board computing systems to navigate without human control, full awareness of the driving environment also requires a cooperative effort via Vehicle-To-Everything (V2X) communication. Specifically, vehicles send and receive sensor perceptions to/from other vehicles to extend perception beyond their own sensing range. However, transmitting large volumes of data can be challenging for current V2X communication technologies, so data compression represents a crucial solution to reduce the message size and link congestion. In this paper, we present a statistical characterization of automotive data, focusing on LiDAR sensors. Notably, we provide models for the size of both raw and compressed point clouds. The use of statistical traffic models offers several advantages compared to using real data, such as faster simulations, reduced storage requirements, and greater flexibility in the application design. Furthermore, statistical models can be used for understanding traffic patterns and analyzing statistics, which is crucial to design and optimize wireless networks. We validate our statistical models via a Kolmogorov-Smirnoff test implementing a Bootstrap Resampling scheme. Moreover, we show via ns-3 simulations that using statistical models yields comparable results in terms of latency and throughput compared to real data, which also demonstrates the accuracy of the models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14017v1</guid>
      <category>cs.NI</category>
      <category>stat.AP</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marcello Bullo, Amir Ashtari Gargari, Paolo Testolina, Michele Zorzi, Marco Giordani</dc:creator>
    </item>
    <item>
      <title>The Effect of the Network in Cutting Carbon for Geo-shifted Workloads</title>
      <link>https://arxiv.org/abs/2504.14022</link>
      <description>arXiv:2504.14022v1 Announce Type: new 
Abstract: Organizations are increasingly offloading their workloads to cloud platforms. For workloads with relaxed deadlines, this presents an opportunity to reduce the total carbon footprint of these computations by moving workloads to datacenters with access to low-carbon power. Recently published results have shown that the carbon footprint of the wide-area network (WAN) can be a significant share of the total carbon output of executing the workload itself, and so careful selection of the time and place where these computations are offloaded is critical. In this paper, we propose an approach to geographic workload migration that uses high-fidelity maps of physical Internet infrastructure to better estimate the carbon costs of WAN transfers. Our findings show that space-shifting workloads can achieve much higher carbon savings than time-shifting alone, if accurate estimates of WAN carbon costs are taken into account.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14022v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yibo Guo, Amanda Tomlinson, Runlong Su, George Porter</dc:creator>
    </item>
    <item>
      <title>5Guard: Isolation-aware End-to-End Slicing of 5G Networks</title>
      <link>https://arxiv.org/abs/2504.14088</link>
      <description>arXiv:2504.14088v1 Announce Type: new 
Abstract: Network slicing logically partitions the 5G infrastructure to cater to diverse verticals with varying requirements. However, resource sharing exposes the slices to threats and performance degradation, making slice isolation essential. Fully isolating slices is resource-prohibitive, prompting the need for isolation-aware network slicing, where each slice is assigned a tailored isolation level to balance security, usability, and overhead. This paper investigates end-to-end 5G network slicing with resource isolation from the perspective of the infrastructure provider, ensuring compliance with the customers' service-level agreements. We formulate the online 5G isolation-aware network slicing (5G-INS) as a mixed-integer programming problem, modeling realistic slice isolation levels and integrating slice prioritization. To solve 5G-INS, we propose 5Guard, a novel adaptive framework that leverages an ensemble of custom optimization algorithms to achieve the best solution within resource budget and time constraints. Our results show that 5Guard increases profit by up to 10.1% in resource-constrained environments and up to 25.4% in a real-world large-scale network compared to the best-performing individual algorithm. Furthermore, we analyze the trade-offs between isolation levels, their impact on resource utilization, and the effects of slice placement, demonstrating significant advantages over baseline approaches that enforce uniform isolation policies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14088v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Mehdi Bolourian, Noura Limam, Mohammad Ali Salahuddin, Raouf Boutaba</dc:creator>
    </item>
    <item>
      <title>Diffusion-based Dynamic Contract for Federated AI Agent Construction in Mobile Metaverses</title>
      <link>https://arxiv.org/abs/2504.14326</link>
      <description>arXiv:2504.14326v1 Announce Type: new 
Abstract: Mobile metaverses have attracted significant attention from both academia and industry, which are envisioned as the next-generation Internet, providing users with immersive and ubiquitous metaverse services through mobile devices. Driven by Large Language Models (LLMs) and Vision-Language Models (VLMs), Artificial Intelligence (AI) agents hold the potential to empower the creation, maintenance, and evolution of mobile metaverses. Currently, AI agents are primarily constructed using cloud-based LLMs and VLMs. However, several challenges hinder their effective implementation, including high service latency and potential sensitive data leakage during perception and processing. In this paper, we develop an edge-cloud collaboration-based federated AI agent construction framework in mobile metaverses. Specifically, Edge Servers (ESs), acting as agent infrastructures, collaboratively create agent modules in a distributed manner. The cloud server then integrates these modules into AI agents and deploys them at the edge, thereby enabling low-latency AI agent services for users. Considering that ESs may exhibit dynamic levels of willingness to participate in federated AI agent construction, we design a two-period dynamic contract model to continuously motivate ESs to participate in agent module creation, effectively addressing the dynamic information asymmetry between the cloud server and the ESs. Furthermore, we propose an Enhanced Diffusion Model-based Soft Actor-Critic (EDMSAC) algorithm to efficiently generate optimal dynamic contracts, in which dynamic structured pruning is applied to DM-based actor networks to enhance denoising efficiency and policy learning performance. Extensive simulations demonstrate the effectiveness and superiority of the EDMSAC algorithm and the proposed contract model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14326v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinbo Wen, Jiawen Kang, Yang Zhang, Yue Zhong, Dusit Niyato, Jie Xu, Jianhang Tang, Chau Yuen</dc:creator>
    </item>
    <item>
      <title>Planet as a Brain: Towards Internet of AgentSites based on AIOS Server</title>
      <link>https://arxiv.org/abs/2504.14411</link>
      <description>arXiv:2504.14411v2 Announce Type: new 
Abstract: The internet is undergoing a historical transformation from the "Internet of Websites" to the "Internet of AgentSites." While traditional Websites served as the foundation for information hosting and dissemination, a new frontier is emerging where AgentSites serve as the hubs of the internet, where each AgentSite hosts one or more AI agents that receive tasks, address them, and deliver actionable solutions, marking a significant shift in the digital landscape and representing the next generation of online ecosystems. Under this vision, AIOS, the AI Agent Operating System, serves as the server for the development, deployment and execution of AI agents, which is a fundamental infrastructure for the Internet of Agentsites.
  In this paper, we introduce AIOS Server, a runtime framework to host agents and enable global-scale collaboration among decentralized agents. AIOS Server provides a communication protocol leveraging the Model Context Protocol (MCP) and JSON-RPC to enable agent-agent or human-agent interactions. Each AIOS node operates as a server to host and execute agents, while supporting peer-to-peer coordination without reliance on centralized orchestration. Based on AIOS Server, we further present the world's first practically deployed Internet of Agentsites (AIOS-IoA), including AgentHub for agent registration and discovery and AgentChat for interactive communication, at https://planet.aios.foundation. The agent discovery mechanism based on Distributed Hash Tables (DHT) and a Gossip protocol serves as the search engine for the internet of agentsites. This work provides a practical foundation for building the Internet of Agentsites-a new paradigm where autonomous agents become first-class citizens of the web. The implementation is available at https://github.com/agiresearch/AIOS.Server and will be integrated into the AIOS main branch at https://github.com/agiresearch/AIOS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14411v2</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiang Zhang, Yongfeng Zhang</dc:creator>
    </item>
    <item>
      <title>Admission Control with Reconfigurable Intelligent Surfaces for 6G Mobile Edge Computing</title>
      <link>https://arxiv.org/abs/2504.14430</link>
      <description>arXiv:2504.14430v1 Announce Type: new 
Abstract: As 6G networks must support diverse applications with heterogeneous quality-of-service requirements, efficient allocation of limited network resources becomes important. This paper addresses the critical challenge of user admission control in 6G networks enhanced by Reconfigurable Intelligent Surfaces (RIS) and Mobile Edge Computing (MEC). We propose an optimization framework that leverages RIS technology to enhance user admission based on spatial characteristics, priority levels, and resource constraints. Our approach first filters users based on angular alignment with RIS reflection directions, then constructs priority queues considering service requirements and arrival times, and finally performs user grouping to maximize RIS resource utilization. The proposed algorithm incorporates a utility function that balances Quality of Service (QoS) performance, RIS utilization, and MEC efficiency in admission decisions. Simulation results demonstrate that our approach significantly improves system performance with RIS-enhanced configurations. For high-priority eURLLC services, our method maintains over 90% admission rates even at maximum load, ensuring mission-critical applications receive guaranteed service quality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14430v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ye Zhang, Baiyun Xiao, Jyoti Sahni, Alvin Valera, Wuyungerile Li, Winston K. G. Seah</dc:creator>
    </item>
    <item>
      <title>SkyNetPredictor: Network Performance Prediction in Avionic Communication using AI</title>
      <link>https://arxiv.org/abs/2504.14443</link>
      <description>arXiv:2504.14443v1 Announce Type: new 
Abstract: Satellite-based communication systems are integral to delivering high-speed data services in aviation, particularly for business aviation operations requiring global connectivity. These systems, however, are challenged by a multitude of interdependent factors such as satellite handovers, congestion, flight maneuvers and seasonal trends, making network performance prediction a complex task. No established methodologies currently exist for network performance prediction in avionic communication systems. This paper addresses the gap by proposing machine learning (ML)-based approaches for pre-flight network performance predictions. The proposed models predict performance along a given flight path, taking as input positional and network-related information and outputting the predicted performance for each position. In business aviation, flight crews typically have multiple flight plans to choose from for each city pair, allowing them to select the most optimal option. This approach enables proactive decision-making, such as selecting optimal flight paths prior to departure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14443v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hind Mukhtar, Raymond Schaub, Melike Erol-Kantarci</dc:creator>
    </item>
    <item>
      <title>Uncovering Issues in the Radio Access Network by Looking at the Neighbors</title>
      <link>https://arxiv.org/abs/2504.14686</link>
      <description>arXiv:2504.14686v1 Announce Type: new 
Abstract: Mobile network operators (MNOs) manage Radio Access Networks (RANs) with massive amounts of cells over multiple radio generations (2G-5G). To handle such complexity, operations teams rely on monitoring systems, including anomaly detection tools that identify unexpected behaviors. In this paper, we present c-ANEMON, a Contextual ANomaly dEtection MONitor for the RAN based on Graph Neural Networks (GNNs). Our solution captures spatio-temporal variations by analyzing the behavior of individual cells in relation to their local neighborhoods, enabling the detection of anomalies that are independent of external mobility factors. This, in turn, allows focusing on anomalies associated with network issues (e.g., misconfigurations, equipment failures). We evaluate c-ANEMON using real-world data from a large European metropolitan area (7,890 cells; 3 months). First, we show that the GNN model within our solution generalizes effectively to cells from previously unseen areas, suggesting the possibility of using a single model across extensive deployment regions. Then, we analyze the anomalies detected by c-ANEMON through manual inspection and define several categories of long-lasting anomalies (6+ hours). Notably, 45.95% of these anomalies fall into a category that is more likely to require intervention by operations teams.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14686v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>IEEE International Conference on Machine Learning for Communication and Networking, 2025</arxiv:journal_reference>
      <dc:creator>Jos\'e Su\'arez-Varela, Andra Lutu</dc:creator>
    </item>
    <item>
      <title>Video QoE Metrics from Encrypted Traffic: Application-agnostic Methodology</title>
      <link>https://arxiv.org/abs/2504.14720</link>
      <description>arXiv:2504.14720v1 Announce Type: new 
Abstract: Instant Messaging-Based Video Call Applications (IMVCAs) and Video Conferencing Applications (VCAs) have become integral to modern communication. Ensuring a high Quality of Experience (QoE) for users in this context is critical for network operators, as network conditions significantly impact user QoE. However, network operators lack access to end-device QoE metrics due to encrypted traffic. Existing solutions estimate QoE metrics from encrypted traffic traversing the network, with the most advanced approaches leveraging machine learning models. Subsequently, the need for ground truth QoE metrics for training and validation poses a challenge, as not all video applications provide these metrics. To address this challenge, we propose an application-agnostic approach for objective QoE estimation from encrypted traffic. Independent of the video application, we obtained key video QoE metrics, enabling broad applicability to various proprietary IMVCAs and VCAs. To validate our solution, we created a diverse dataset from WhatsApp video sessions under various network conditions, comprising 25,680 seconds of traffic data and QoE metrics. Our evaluation shows high performance across the entire dataset, with 85.2% accuracy for FPS predictions within an error margin of two FPS, and 90.2% accuracy for PIQE-based quality rating classification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14720v1</guid>
      <category>cs.NI</category>
      <category>cs.LG</category>
      <category>cs.MM</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tamir Berger, Jonathan Sterenson, Raz Birman, Ofer Hadar</dc:creator>
    </item>
    <item>
      <title>Interference-Aware PMI selection for MIMO systems in an O-RAN scenario</title>
      <link>https://arxiv.org/abs/2504.14745</link>
      <description>arXiv:2504.14745v1 Announce Type: new 
Abstract: The optimization of Precoding Matrix Indicators (PMIs) is crucial for enhancing the performance of 5G networks, particularly in dense deployments where inter-cell interference is a significant challenge. Some approaches have leveraged AI/ML techniques for beamforming and beam selection, however, these methods often overlook the multi-objective nature of PMI selection, which requires balancing spectral efficiency (SE) and interference reduction. This paper proposes an interference-aware PMI selection method using an Advantage Actor-Critic (A2C) reinforcement learning model, designed for deployment within an O-RAN framework as an xApp. The proposed model prioritizes user equipment (UE) based on a novel strategy and adjusts PMI values accordingly, with interference management and efficient resource utilization. Experimental results in an O-RAN environment demonstrate the approach's effectiveness in improving network performance metrics, including SE and interference mitigation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14745v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rawlings Ntassah, Gian Michele Dell'Aera, Fabrizio Granelli</dc:creator>
    </item>
    <item>
      <title>PPO-EPO: Energy and Performance Optimization for O-RAN Using Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2504.14749</link>
      <description>arXiv:2504.14749v1 Announce Type: new 
Abstract: Energy consumption in mobile communication networks has become a significant challenge due to its direct impact on Capital Expenditure (CAPEX) and Operational Expenditure (OPEX). The introduction of Open RAN (O-RAN) enables telecommunication providers to leverage network intelligence to optimize energy efficiency while maintaining Quality of Service (QoS). One promising approach involves traffic-aware cell shutdown strategies, where underutilized cells are selectively deactivated without compromising overall network performance. However, achieving this balance requires precise traffic steering mechanisms that account for throughput performance, power efficiency, and network interference constraints.
  This work proposes a reinforcement learning (RL) model based on the Proximal Policy Optimization (PPO) algorithm to optimize traffic steering and energy efficiency. The objective is to maximize energy efficiency and performance gains while strategically shutting down underutilized cells. The proposed RL model learns adaptive policies to make optimal shutdown decisions by considering throughput degradation constraints, interference thresholds, and PRB utilization balance. Experimental validation using TeraVM Viavi RIC tester data demonstrates that our method significantly improves the network's energy efficiency and downlink throughput.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14749v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rawlings Ntassah, Gian Michele Dell'Aera, Fabrizio Granelli</dc:creator>
    </item>
    <item>
      <title>IoT-AMLHP: Aligned Multimodal Learning of Header-Payload Representations for Resource-Efficient Malicious IoT Traffic Classification</title>
      <link>https://arxiv.org/abs/2504.14833</link>
      <description>arXiv:2504.14833v1 Announce Type: new 
Abstract: Traffic classification is crucial for securing Internet of Things (IoT) networks. Deep learning-based methods can autonomously extract latent patterns from massive network traffic, demonstrating significant potential for IoT traffic classification tasks. However, the limited computational and spatial resources of IoT devices pose challenges for deploying more complex deep learning models. Existing methods rely heavily on either flow-level features or raw packet byte features. Flow-level features often require inspecting entire or most of the traffic flow, leading to excessive resource consumption, while raw packet byte features fail to distinguish between headers and payloads, overlooking semantic differences and introducing noise from feature misalignment. Therefore, this paper proposes IoT-AMLHP, an aligned multimodal learning framework for resource-efficient malicious IoT traffic classification. Firstly, the framework constructs a packet-wise header-payload representation by parsing packet headers and payload bytes, resulting in an aligned and standardized multimodal traffic representation that enhances the characterization of heterogeneous IoT traffic. Subsequently, the traffic representation is fed into a resource-efficient neural network comprising a multimodal feature extraction module and a multimodal fusion module. The extraction module employs efficient depthwise separable convolutions to capture multi-scale features from different modalities while maintaining a lightweight architecture. The fusion module adaptively captures complementary features from different modalities and effectively fuses multimodal features.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14833v1</guid>
      <category>cs.NI</category>
      <category>cs.CR</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fengyuan Nie, Guangjie Liu, Weiwei Liu, Jianan Huang, Bo Gao</dc:creator>
    </item>
    <item>
      <title>ScaleGuard: Rational and Scalable Configuration Privacy Protection with Topology Expansion</title>
      <link>https://arxiv.org/abs/2504.14959</link>
      <description>arXiv:2504.14959v1 Announce Type: new 
Abstract: As networks grow in size and complexity, safeguarding sensitive data while sharing configuration files is critical for network management and research. Existing anonymization tools primarily hide fields like IP addresses or AS numbers to mitigate direct data exposure. However, they often lack mechanisms to preserve privacy around network scale, an increasingly sensitive aspect that can reveal organizational size or resource distribution. We propose ScaleGuard, which preserves network functional equivalence while adding fake routers and hosts to conceal network scale, and generating complete router configurations that resemble the originals. Our system introduces a graph embedding-based expansion method and k-degree mapping anonymity, reducing unnecessary topology modifications when adversaries only know the original degree sequence. For routing repair, ScaleGuard designs a network repair framework combining SMT and iterative methods, delivering stable performance under randomized link costs and complex cross-protocol routing. Experiment results show that ScaleGuard expands network scale effectively, providing consistent anonymization of topology, scale, and routing, while achieving strong topological rationality, configuration fidelity, and repairing efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14959v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qianye Wang, Yuejie Wang, Yongting Chen, Guyue Liu</dc:creator>
    </item>
    <item>
      <title>Direct Search Algorithm for Clock Skew Compensation Immune to Floating-Point Precision Loss</title>
      <link>https://arxiv.org/abs/2504.15039</link>
      <description>arXiv:2504.15039v2 Announce Type: new 
Abstract: We have been investigating clock skew compensation immune to floating-point precision loss by taking into account the discrete nature of clocks in digital communication systems; extending Bresenham's line drawing algorithm, we constructed an incremental error algorithm using only integer addition/subtraction and comparison. Still, bounding the initial value of the clock remains a challenge, which determines the initial condition of the algorithm and thereby its number of iterations. In this letter, we propose a new incremental error algorithm for clock skew compensation, called direct search, which no longer relies on the bounds on the initial value of the clock. The numerical examples demonstrate that the proposed algorithm can significantly reduce the number of iterations in comparison to the prior work while eliminating the effect of floating-point precision loss on clock skew compensation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15039v2</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kyeong Soo Kim</dc:creator>
    </item>
    <item>
      <title>Generative Artificial Intelligence for Beamforming in Low-Altitude Economy</title>
      <link>https://arxiv.org/abs/2504.15079</link>
      <description>arXiv:2504.15079v1 Announce Type: new 
Abstract: The growth of low-altitude economy (LAE) has driven a rising demand for efficient and secure communication. However, conventional beamforming optimization techniques struggle in the complex LAE environments. In this context, generative artificial intelligence (GenAI) methods provide a promising solution. In this article, we first introduce the core concepts of LAE and the roles of beamforming in advanced communication technologies for LAE. We then examine their interrelation, followed by an analysis of the limitations of conventional beamforming methods. Next, we provide an overview of how GenAI methods enhance the process of beamforming, with a focus on its applications in LAE. Furthermore, we present a case study using a generative diffusion model (GDM)-based algorithm to enhance the performance of aerial collaborative beamforming-enabled remote secure communications in LAE and simulation results verified the effectiveness of the proposed algorithms. Finally, promising research opportunities are identified.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15079v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Geng Sun, Jia Qi, Chuang Zhang, Xuejie Liu, Jiacheng Wang, Dusit Niyato, Yuanwei Liu, Dong In Kim</dc:creator>
    </item>
    <item>
      <title>The Future of Internet of Things and Multimodal Language Models in 6G Networks: Opportunities and Challenges</title>
      <link>https://arxiv.org/abs/2504.13971</link>
      <description>arXiv:2504.13971v1 Announce Type: cross 
Abstract: Based on recent trends in artificial intelligence and IoT research. The cooperative potential of integrating the Internet of Things (IoT) and Multimodal Language Models (MLLMs) is presented in this survey paper for future 6G systems. It focuses on the applications of this integration in different fields, such as healthcare, agriculture, and smart cities, and investigates the four pillars of IoT integration, such as sensors, communication, processing, and security. The paper provides a comprehensive description of IoT and MLLM technologies and applications, addresses the role of multimodality in each pillar, and concludes with an overview of the most significant challenges and directions for future research. The general survey is a roadmap for researchers interested in tracing the application areas of MLLMs and IoT, highlighting the potential and challenges in this rapidly growing field. The survey recognizes the need to deal with data availability, computational expense, privacy, and real-time processing to harness the complete potential of IoT, MLLM, and 6G technology</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.13971v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.NI</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Abdelrahman Soliman</dc:creator>
    </item>
    <item>
      <title>Efficient Federated Split Learning for Large Language Models over Communication Networks</title>
      <link>https://arxiv.org/abs/2504.14667</link>
      <description>arXiv:2504.14667v1 Announce Type: cross 
Abstract: Fine-tuning pre-trained large language models (LLM) in a distributed manner poses significant challenges on resource-constrained edge devices. To address this challenge, we propose FedsLLM, a novel framework that integrates split federated learning with parameter-efficient fine-tuning techniques. By leveraging model splitting and Low-Rank Adaptation (LoRA), FedsLLM reduces the computational burden on edge devices. Furthermore, the introduction of a federated server facilitates parallel training and enhances privacy. To accommodate heterogeneous communication conditions and diverse computational capabilities of edge devices, as well as the impact of LoRA rank selection on model convergence and training cost, we formulate a joint optimization problem. The formulated problem jointly optimizes subchannel allocation, power control, model splitting point selection, and LoRA rank configuration, all aimed at minimizing total training delay. An alternating optimization algorithm is developed to efficiently solve this problem and accelerate the training process. Simulation results demonstrate that the proposed FedsLLM framework achieves comparable model accuracy while significantly reducing client-side computational requirements. Furthermore, the proposed resource allocation scheme and adaptive LoRA rank selection strategy notably reduce the training latency compared to conventional approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14667v1</guid>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kai Zhao, Zhaohui Yang</dc:creator>
    </item>
    <item>
      <title>System-Level Experimental Evaluation of Reconfigurable Intelligent Surfaces for NextG Communication Systems</title>
      <link>https://arxiv.org/abs/2412.12969</link>
      <description>arXiv:2412.12969v2 Announce Type: replace 
Abstract: Reconfigurable Intelligent Surfaces (RISs) are a promising technique for enhancing the performance of Next Generation (NextG) wireless communication systems in terms of both spectral and energy efficiency, as well as resource utilization. However, current RIS research has primarily focused on theoretical modeling and Physical (PHY) layer considerations only. Full protocol stack emulation and accurate modeling of the propagation characteristics of the wireless channel are necessary for studying the benefits introduced by RIS technology across various spectrum bands and use-cases. In this paper, we propose, for the first time: (i) accurate PHY layer RIS-enabled channel modeling through Geometry-Based Stochastic Models (GBSMs), leveraging the QUAsi Deterministic RadIo channel GenerAtor (QuaDRiGa) open-source statistical ray-tracer; (ii) optimized resource allocation with RISs by comprehensively studying energy efficiency and power control on different portions of the spectrum through a single-leader multiple-followers Stackelberg game theoretical approach; (iii) full-stack emulation and performance evaluation of RIS-assisted channels with SCOPE/srsRAN for Enhanced Mobile Broadband (eMBB) and Ultra Reliable and Low Latency Communications (URLLC) applications in the worlds largest emulator of wireless systems with hardware-in-the-loop, namely Colosseum. Our findings indicate (i) the significant power savings in terms of energy efficiency achieved with RIS-assisted topologies, especially in the millimeter wave (mmWave) band; and (ii) the benefits introduced for Sub-6 GHz band User Equipments (UEs), where the deployment of a relatively small RIS (e.g., in the order of 100 RIS elements) can result in decreased levels of latency for URLLC services in resource-constrained environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12969v2</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maria Tsampazi, Tommaso Melodia</dc:creator>
    </item>
    <item>
      <title>Driving Innovation in 6G Wireless Technologies: The OpenAirInterface Approach</title>
      <link>https://arxiv.org/abs/2412.13295</link>
      <description>arXiv:2412.13295v3 Announce Type: replace 
Abstract: The development of 6G wireless technologies is rapidly advancing, with the 3rd Generation Partnership Project (3GPP) entering the pre-standardization phase and aiming to deliver the first specifications by 2028. This paper explores the OpenAirInterface (OAI) project, an open-source initiative that plays a crucial role in the evolution of 5G and future 6G networks. OAI provides a comprehensive implementation of 3GPP and O-RAN compliant networks, including Radio Access Network (RAN), Core Network (CN), and software-defined User Equipment (UE) components. This paper details the history and evolution of OAI, its licensing model, and the various projects under its umbrella, such as RAN, the CN, and the Operations, Administration and Maintenance (OAM) projects. It also highlights the development methodology, Continuous Integration/Continuous Delivery (CI/CD) processes, and end-to-end systems powered by OAI. Furthermore, the paper discusses the potential of OAI for 6G research, focusing on spectrum, reflective intelligent surfaces, and Artificial Intelligence (AI)/Machine Learning (ML) integration. The open-source approach of OAI is emphasized as essential for tackling the challenges of 6G, fostering community collaboration, and driving innovation in next-generation wireless technologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13295v3</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Florian Kaltenberger, Tommaso Melodia, Irfan Ghauri, Michele Polese, Raymond Knopp, Tien Thinh Nguyen, Sakthivel Velumani, Davide Villa, Leonardo Bonati, Robert Schmidt, Sagar Arora, Mikel Irazabal, Navid Nikaein</dc:creator>
    </item>
    <item>
      <title>A Mathematical Framework of Semantic Communication based on Category Theory</title>
      <link>https://arxiv.org/abs/2504.11334</link>
      <description>arXiv:2504.11334v2 Announce Type: replace 
Abstract: While semantic communication (SemCom) has recently demonstrated great potential to enhance transmission efficiency and reliability by leveraging machine learning (ML) and knowledge base (KB), there is a lack of mathematical modeling to rigorously characterize SemCom system and quantify the performance gain obtained from ML and KB. In this paper, we develop a mathematical framework for SemCom based on category theory, rigorously modeling the concepts of semantic entities and semantic probability space. Within this framework, we introduce the semantic entropy to quantify the uncertainty of semantic entities. We theoretically prove that semantic entropy can be effectively reduced by exploiting KBs, which capture semantic dependencies. Within the formulated semantic space, semantic entities can be combined according to the required semantic ambiguity, and the combined entities can be encoded based on semantic dependencies obtained from KB. Then, we derive semantic channel capacity modeling, which incorporates the mutual information obtained in KB to accurately measure the transmission efficiency of SemCom. Numerical simulations validate the effectiveness of the proposed framework, showing that SemCom with KB integration outperforms traditional communication in both entropy reduction and coding efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11334v2</guid>
      <category>cs.NI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuheng Hua, Yao Sun, Kairong Ma, Dusit Niyato, Muhammad Ali Imran</dc:creator>
    </item>
    <item>
      <title>Communication Optimization for Decentralized Learning atop Bandwidth-limited Edge Networks</title>
      <link>https://arxiv.org/abs/2504.12210</link>
      <description>arXiv:2504.12210v2 Announce Type: replace 
Abstract: Decentralized federated learning (DFL) is a promising machine learning paradigm for bringing artificial intelligence (AI) capabilities to the network edge. Running DFL on top of edge networks, however, faces severe performance challenges due to the extensive parameter exchanges between agents. Most existing solutions for these challenges were based on simplistic communication models, which cannot capture the case of learning over a multi-hop bandwidth-limited network. In this work, we address this problem by jointly designing the communication scheme for the overlay network formed by the agents and the mixing matrix that controls the communication demands between the agents. By carefully analyzing the properties of our problem, we cast each design problem into a tractable optimization and develop an efficient algorithm with guaranteed performance. Our evaluations based on real topology and data show that the proposed algorithm can reduce the total training time by over $80\%$ compared to the baseline without sacrificing accuracy, while significantly improving the computational efficiency over the state of the art.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.12210v2</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tingyang Sun, Tuan Nguyen, Ting He</dc:creator>
    </item>
    <item>
      <title>Progressive Pruning: Analyzing the Impact of Intersection Attacks</title>
      <link>https://arxiv.org/abs/2410.08700</link>
      <description>arXiv:2410.08700v2 Announce Type: replace-cross 
Abstract: Stream-based communication dominates today's Internet, posing unique challenges for anonymous communication networks (ACNs). Traditionally designed for independent messages, ACNs struggle to account for the inherent vulnerabilities of streams, such as susceptibility to intersection attacks. In this work, we address this gap and introduce progressive pruning, a novel methodology for quantifying the susceptibility to intersection attacks. Progressive pruning quantifies and monitors anonymity sets over time, providing an assessment of an adversary's success in correlating senders and receivers. We leverage this methodology to analyze synthetic scenarios and large-scale simulations of the Tor network using our newly developed TorFS simulator. Our findings reveal that anonymity is significantly influenced by stream length, user population, and stream distribution across the network. These insights highlight critical design challenges for future ACNs seeking to safeguard stream-based communication against traffic analysis attacks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08700v2</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christoph D\"opmann, Maximilian Weisenseel, Florian Tschorsch</dc:creator>
    </item>
    <item>
      <title>Hierarchical Split Federated Learning: Convergence Analysis and System Optimization</title>
      <link>https://arxiv.org/abs/2412.07197</link>
      <description>arXiv:2412.07197v2 Announce Type: replace-cross 
Abstract: As AI models expand in size, it has become increasingly challenging to deploy federated learning (FL) on resource-constrained edge devices. To tackle this issue, split federated learning (SFL) has emerged as an FL framework with reduced workload on edge devices via model splitting; it has received extensive attention from the research community in recent years. Nevertheless, most prior works on SFL focus only on a two-tier architecture without harnessing multi-tier cloudedge computing resources. In this paper, we intend to analyze and optimize the learning performance of SFL under multi-tier systems. Specifically, we propose the hierarchical SFL (HSFL) framework and derive its convergence bound. Based on the theoretical results, we formulate a joint optimization problem for model splitting (MS) and model aggregation (MA). To solve this rather hard problem, we then decompose it into MS and MA subproblems that can be solved via an iterative descending algorithm. Simulation results demonstrate that the tailored algorithm can effectively optimize MS and MA for SFL within virtually any multi-tier system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.07197v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zheng Lin, Wei Wei, Zhe Chen, Chan-Tong Lam, Xianhao Chen, Yue Gao, Jun Luo</dc:creator>
    </item>
    <item>
      <title>Grassroots Platforms with Atomic Transactions: Social Networks, Cryptocurrencies, and Democratic Federations</title>
      <link>https://arxiv.org/abs/2502.11299</link>
      <description>arXiv:2502.11299v4 Announce Type: replace-cross 
Abstract: Grassroots platforms aim to offer an egalitarian alternative to global platforms. Whereas global platforms can have only a single instance, grassroots platforms can have multiple instances that emerge and operate independently of each other and of any global resource except the network, and can interoperate and coalesce into ever-larger instances once interconnected. Key grassroots platforms include grassroots social networks, grassroots cryptocurrencies, and grassroots democratic federations. Previously, grassroots platforms were defined formally and proven grassroots using unary distributed transition systems, in which each transition is carried out by a single agent. However, grassroots platforms cater for a more abstract specification using transactions carried out atomically by multiple agents, something that cannot be expressed by unary transition systems. As a result, their original specifications and proofs were unnecessarily cumbersome and opaque.
  We enhance the notion of a distributed transition system to include atomic transactions and revisit the notion of grassroots platforms within this new foundation; present crisp specifications of key grassroots platforms using atomic transactions: befriending and defriending for grassroots social networks, coin swaps for grassroots cryptocurrencies, and communities forming, joining, and leaving a federation for grassroots democratic federations; prove a general theorem that a platform specified by atomic transactions that are so-called interactive is grassroots; show that the atomic transactions used to specify all three platforms are interactive; and conclude that the platforms thus specified are indeed grassroots. We thus provide a crisp mathematical foundation for grassroots platforms and a solid and clear starting point from which their implementation can commence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11299v4</guid>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <category>cs.SI</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ehud Shapiro</dc:creator>
    </item>
    <item>
      <title>Satellite Federated Fine-Tuning for Foundation Models in Space Computing Power Networks</title>
      <link>https://arxiv.org/abs/2504.10403</link>
      <description>arXiv:2504.10403v2 Announce Type: replace-cross 
Abstract: Advancements in artificial intelligence (AI) and low-earth orbit (LEO) satellites have promoted the application of large remote sensing foundation models for various downstream tasks. However, direct downloading of these models for fine-tuning on the ground is impeded by privacy concerns and limited bandwidth. Satellite federated learning (FL) offers a solution by enabling model fine-tuning directly on-board satellites and aggregating model updates without data downloading. Nevertheless, for large foundation models, the computational capacity of satellites is insufficient to support effective on-board fine-tuning in traditional satellite FL frameworks. To address these challenges, we propose a satellite-ground collaborative federated fine-tuning framework. The key of the framework lies in how to reasonably decompose and allocate model components to alleviate insufficient on-board computation capabilities. During fine-tuning, satellites exchange intermediate results with ground stations or other satellites for forward propagation and back propagation, which brings communication challenges due to the special communication topology of space transmission networks, such as intermittent satellite-ground communication, short duration of satellite-ground communication windows, and unstable inter-orbit inter-satellite links (ISLs). To reduce transmission delays, we further introduce tailored communication strategies that integrate both communication and computing resources. Specifically, we propose a parallel intra-orbit communication strategy, a topology-aware satellite-ground communication strategy, and a latency-minimalization inter-orbit communication strategy to reduce space communication costs. Simulation results demonstrate significant reductions in training time with improvements of approximately 33%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10403v2</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yan Zhu, Jingyang Zhu, Ting Wang, Yuanming Shi, Chunxiao Jiang, Khaled Ben Letaief</dc:creator>
    </item>
  </channel>
</rss>
