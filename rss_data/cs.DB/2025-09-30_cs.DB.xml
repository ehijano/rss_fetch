<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DB updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DB</link>
    <description>cs.DB updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DB" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 01 Oct 2025 04:00:34 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>From NL2SQL to NL2GeoSQL: GeoSQL-Eval for automated evaluation of LLMs on PostGIS queries</title>
      <link>https://arxiv.org/abs/2509.25264</link>
      <description>arXiv:2509.25264v1 Announce Type: new 
Abstract: In recent years, large language models (LLMs) have achieved remarkable progress in natural language understanding and structured query generation (NL2SQL). However, extending these advances to GeoSQL tasks in the PostGIS environment remains challenging due to the complexity of spatial functions, geometric data types, and execution semantics. Existing evaluations primarily focus on general relational databases or Google Earth Engine code generation, leaving a lack of systematic benchmarks tailored to spatial databases. To address this gap, this study introduces GeoSQL-Eval, the first end-to-end automated evaluation framework for PostGIS query generation. Built upon Webb's Depth of Knowledge (DOK) model, the framework encompasses four cognitive dimensions, five proficiency levels, and twenty task categories, providing a comprehensive assessment of model performance in terms of knowledge acquisition, syntactic generation, semantic alignment, execution accuracy, and robustness. In parallel, we developed GeoSQL-Bench, a benchmark dataset comprising 14178 questions that span three task types, 340 PostGIS functions, and 82 domain-specific databases. Leveraging this framework, we systematically evaluated 24 representative models across six categories, applying entropy-weighting and statistical analyses to reveal differences in performance, error distributions, and resource consumption patterns. Furthermore, we established a public GeoSQL-Eval leaderboard that enables global research teams to conduct ongoing testing and comparison. These contributions not only extend the boundaries of NL2SQL applications but also provide a standardized, interpretable, and scalable framework for evaluating LLM performance in spatial database contexts, offering valuable insights for model optimization and applications in geographic information science, urban studies, and spatial analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.25264v1</guid>
      <category>cs.DB</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SE</category>
      <pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Shuyang Hou, Haoyue Jiao, Ziqi Liu, Lutong Xie, Guanyu Chen, Shaowen Wu, Xuefeng Guan, Huayi Wu</dc:creator>
    </item>
    <item>
      <title>ActorDB: A Unified Database Model Integrating Single-Writer Actors, Incremental View Maintenance, and Zero-Trust Messaging</title>
      <link>https://arxiv.org/abs/2509.25285</link>
      <description>arXiv:2509.25285v1 Announce Type: new 
Abstract: This paper presents ActorDB ( Dekigoto ) , a novel database architecture that tightly integrates a single-writer actor model for writes, Incremental View Maintenance (IVM), and a zero-trust security model as a core component. The primary contribution of this work is the unification of these powerful but complex concepts into a single, cohesive system designed to reduce architectural complexity for developers of modern, data-intensive applications. We argue that by providing these capabilities out-of-the-box, ActorDB can offer a more robust, secure, and developer-friendly platform compared to solutions that require manual integration of separate systems for actor persistence, stream processing, and security. We present the core architecture, discuss the critical trade-offs in its design, and define the performance criteria for a Minimum Viable Product (MVP) to validate our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.25285v1</guid>
      <category>cs.DB</category>
      <category>cs.CL</category>
      <category>cs.DC</category>
      <pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Jun Kawasaki</dc:creator>
    </item>
    <item>
      <title>PAT: Pattern-Perceptive Transformer for Error Detection in Relational Databases</title>
      <link>https://arxiv.org/abs/2509.25907</link>
      <description>arXiv:2509.25907v1 Announce Type: new 
Abstract: Error detection in relational databases is critical for maintaining data quality and is fundamental to tasks such as data cleaning and assessment. Current error detection studies mostly employ the multi-detector approach to handle heterogeneous attributes in databases, incurring high costs. Additionally, their data preprocessing strategies fail to leverage the variable-length characteristic of data sequences, resulting in reduced accuracy. In this paper, we propose an attribute-wise PAttern-perceptive Transformer (PAT) framework for error detection in relational databases. First, PAT introduces a learned pattern module that captures attribute-specific data distributions through learned embeddings during model training. Second, the Quasi-Tokens Arrangement (QTA) tokenizer is designed to divide the cell sequence based on its length and word types, and then generate the word-adaptive data tokens, meanwhile providing compact hyperparameters to ensure efficiency. By interleaving data tokens with the attribute-specific pattern tokens, PAT jointly learns shared data features across different attributes and pattern features that are distinguishable and unique in each specified attribute. Third, PAT visualizes the attention map to interpret its error detection mechanism. Extensive experiments show that PAT achieves excellent F1 scores compared to state-of-the-art data error detection methods. Moreover, PAT significantly reduces the model parameters and FLOPs when applying the compact QTA tokenizer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.25907v1</guid>
      <category>cs.DB</category>
      <pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jian Fu, Xixian Han, Xiaolong Wan, Wenjian Wang</dc:creator>
    </item>
    <item>
      <title>Experiversum: an Ecosystem for Curating and Enhancing Data-Driven Experimental Science</title>
      <link>https://arxiv.org/abs/2509.26102</link>
      <description>arXiv:2509.26102v1 Announce Type: new 
Abstract: This paper introduces Experiversum, a lakehouse-based ecosystem that supports the curation, documentation and reproducibility of exploratory experiments. Experiversum enables structured research through iterative data cycles, while capturing metadata and collaborative decisions. Demonstrated through case studies in Earth, Life and Political Sciences, Experiversum promotes transparent workflows and multi-perspective result interpretation. Experiversum bridges exploratory and reproducible research, encouraging accountable and robust data-driven practices across disciplines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.26102v1</guid>
      <category>cs.DB</category>
      <pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>29th European Conference on Advances in Databases and Information Systems, Sep 2025, Tempere, Finland. pp.98-107</arxiv:journal_reference>
      <dc:creator>Genoveva Vargas-Solar (LIRIS), Umberto Costa (ERIC, UL2), J\'er\^ome Darmont (ERIC, UL2), Javier Espinosa-Oviedo (ERIC, UCBL), Carmem Hara (ERIC, UL2), Sabine Loudcher (ERIC, UL2), Regina Motz, Martin A. Musicante, Jos\'e-Luis Zechinelli-Martini</dc:creator>
    </item>
    <item>
      <title>The Grammar of FAIR: A Granular Architecture of Semantic Units for FAIR Semantics, Inspired by Biology and Linguistics</title>
      <link>https://arxiv.org/abs/2509.26434</link>
      <description>arXiv:2509.26434v1 Announce Type: new 
Abstract: The FAIR Principles aim to make data and knowledge Findable, Accessible, Interoperable, and Reusable, yet current digital infrastructures often lack a unifying semantic framework that bridges human cognition and machine-actionability. In this paper, we introduce the Grammar of FAIR: a granular and modular architecture for FAIR semantics built on the concept of semantic units. Semantic units, comprising atomic statement units and composite compound units, implement the principle of semantic modularisation, decomposing data and knowledge into independently identifiable, semantically meaningful, and machine-actionable units. A central metaphor guiding our approach is the analogy between the hierarchy of level of organisation in biological systems and the hierarchy of levels of organisation in information systems: both are structured by granular building blocks that mediate across multiple perspectives while preserving functional unity. Drawing further inspiration from concept formation and natural language grammar, we show how these building blocks map to FAIR Digitial Objects (FDOs), enabling format-agnostic semantic transitivity from natural language token models to schema-based representations. This dual biological-linguistic analogy provides a semantics-first foundation for evolving cross-ecosystem infrastructures, paving the way for the Internet of FAIR Data and Services (IFDS) and a future of modular, AI-ready, and citation-granular scholarly communication.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.26434v1</guid>
      <category>cs.DB</category>
      <pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lars Vogt, Barend Mons</dc:creator>
    </item>
    <item>
      <title>Scalable Disk-Based Approximate Nearest Neighbor Search with Page-Aligned Graph</title>
      <link>https://arxiv.org/abs/2509.25487</link>
      <description>arXiv:2509.25487v1 Announce Type: cross 
Abstract: Approximate Nearest Neighbor Search (ANNS), as the core of vector databases (VectorDBs), has become widely used in modern AI and ML systems, powering applications from information retrieval to bio-informatics. While graph-based ANNS methods achieve high query efficiency, their scalability is constrained by the available host memory. Recent disk-based ANNS approaches mitigate memory usage by offloading data to Solid-State Drives (SSDs). However, they still suffer from issues such as long I/O traversal path, misalignment with storage I/O granularity, and high in-memory indexing overhead, leading to significant I/O latency and ultimately limiting scalability for large-scale vector search.
  In this paper, we propose PageANN, a disk-based approximate nearest neighbor search (ANNS) framework designed for high performance and scalability. PageANN introduces a page-node graph structure that aligns logical graph nodes with physical SSD pages, thereby shortening I/O traversal paths and reducing I/O operations. Specifically, similar vectors are clustered into page nodes, and a co-designed disk data layout leverages this structure with a merging technique to store only representative vectors and topology information, avoiding unnecessary reads. To further improve efficiency, we design a memory management strategy that combines lightweight indexing with coordinated memory-disk data allocation, maximizing host memory utilization while minimizing query latency and storage overhead. Experimental results show that PageANN significantly outperforms state-of-the-art (SOTA) disk-based ANNS methods, achieving 1.85x-10.83x higher throughput and 51.7%-91.9% lower latency across different datasets and memory budgets, while maintaining comparable high recall accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.25487v1</guid>
      <category>cs.LG</category>
      <category>cs.DB</category>
      <category>cs.IR</category>
      <pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dingyi Kang, Dongming Jiang, Hanshen Yang, Hang Liu, Bingzhe Li</dc:creator>
    </item>
    <item>
      <title>SING-SQL: A Synthetic Data Generation Framework for In-Domain Text-to-SQL Translation</title>
      <link>https://arxiv.org/abs/2509.25672</link>
      <description>arXiv:2509.25672v1 Announce Type: cross 
Abstract: Translating natural language questions into SQL has become a core challenge in enabling non-technical users to query databases. While recent work has explored large-scale synthetic data generation to improve model performance through post-training, most efforts emphasize cross-domain generalization. This leaves a gap for real-world enterprise scenarios, where models need to specialize to a single database schema and organizations require to be able to evaluate their Text-to-SQL systems on their own databases. To address this, we introduce SING-SQL, a fully automated two-stage framework for generating high-quality, high-coverage synthetic Text-to-SQL data for any target database, without relying on SQL logs or manual annotations. Our approach hierarchically partitions a database schema into sub-schemas, synthesizes SQL queries across multiple complexity levels, and applies a quality-aware pipeline that includes LLM-as-a-judge validation, executability checks, automatic repair, and column balancing. We further release SingSQL-LM, a family of compact language models fine-tuned on the synthetic data, achieving strong in-domain generalization. On the subset of the BIRD benchmark, SingSQL-LM-3B-R64 reaches 82.87% Soft F1 and 73.03% EX upper bound with 32 candidates, outperforming the best 3B-scale baseline by +16.21 in Soft F1 and +12.36 in EX. At the 1.5B scale, SingSQL-LM-1.5B-R64 improves over prior systems by +9.30 in Soft F1 and +4.49 in EX. On synthetic evaluation sets, SingSQL-LMs exceed prior systems by wide margins, establishing state-of-the-art performance among open models at comparable scales. Our study of context management strategies reveals that schema-free fine-tuning combined with schema-only inference provides the most robust results. These findings establish SING-SQL as a scalable, database-agnostic paradigm for producing and evaluating enterprise-grade Text-to-SQL systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.25672v1</guid>
      <category>cs.AI</category>
      <category>cs.DB</category>
      <pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Hasan Alp Cafero\u{g}lu, Mehmet Serhat \c{C}elik, \"Ozg\"ur Ulusoy</dc:creator>
    </item>
    <item>
      <title>RAE: A Neural Network Dimensionality Reduction Method for Nearest Neighbors Preservation in Vector Search</title>
      <link>https://arxiv.org/abs/2509.25839</link>
      <description>arXiv:2509.25839v1 Announce Type: cross 
Abstract: While high-dimensional embedding vectors are being increasingly employed in various tasks like Retrieval-Augmented Generation and Recommendation Systems, popular dimensionality reduction (DR) methods such as PCA and UMAP have rarely been adopted for accelerating the retrieval process due to their inability of preserving the nearest neighbor (NN) relationship among vectors. Empowered by neural networks' optimization capability and the bounding effect of Rayleigh quotient, we propose a Regularized Auto-Encoder (RAE) for k-NN preserving dimensionality reduction. RAE constrains the network parameter variation through regularization terms, adjusting singular values to control embedding magnitude changes during reduction, thus preserving k-NN relationships. We provide a rigorous mathematical analysis demonstrating that regularization establishes an upper bound on the norm distortion rate of transformed vectors, thereby offering provable guarantees for k-NN preservation. With modest training overhead, RAE achieves superior k-NN recall compared to existing DR approaches while maintaining fast retrieval efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.25839v1</guid>
      <category>cs.IR</category>
      <category>cs.AI</category>
      <category>cs.DB</category>
      <pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Han Zhang, Dongfang Zhao</dc:creator>
    </item>
    <item>
      <title>KVzip: Query-Agnostic KV Cache Compression with Context Reconstruction</title>
      <link>https://arxiv.org/abs/2505.23416</link>
      <description>arXiv:2505.23416v2 Announce Type: replace 
Abstract: Transformer-based large language models (LLMs) cache context as key-value (KV) pairs during inference. As context length grows, KV cache sizes expand, leading to substantial memory overhead and increased attention latency. This paper introduces KVzip, a query-agnostic KV cache eviction method enabling effective reuse of compressed KV caches across diverse queries. KVzip quantifies the importance of a KV pair using the underlying LLM to reconstruct original contexts from cached KV pairs, subsequently evicting pairs with lower importance. Extensive empirical evaluations demonstrate that KVzip reduces KV cache size by $3$-$4\times$ and FlashAttention decoding latency by approximately $2\times$, with negligible performance loss in question-answering, retrieval, reasoning, and code comprehension tasks. Evaluations include various models such as LLaMA3.1, Qwen2.5, and Gemma3, with context lengths reaching up to 170K tokens. KVzip significantly outperforms existing query-aware KV eviction methods, which suffer from performance degradation even at a 90% cache budget ratio under multi-query scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.23416v2</guid>
      <category>cs.DB</category>
      <category>cs.LG</category>
      <pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jang-Hyun Kim, Jinuk Kim, Sangwoo Kwon, Jae W. Lee, Sangdoo Yun, Hyun Oh Song</dc:creator>
    </item>
    <item>
      <title>Condensed Representation of RDF and its Application on Graph Versioning</title>
      <link>https://arxiv.org/abs/2506.21203</link>
      <description>arXiv:2506.21203v4 Announce Type: replace 
Abstract: Evolving phenomena, often complex, can be represented using knowledge graphs, which have the capability to model heterogeneous data from multiple sources. Nowadays, a considerable amount of sources delivering periodic updates to knowledge graphs in various domains is openly available. The evolution of data is of interest to knowledge graph management systems, and therefore it is crucial to organize these constantly evolving data to make them easily accessible and exploitable for analysis. In this article, we will present and formalize the condensed representation of these evolving graphs and propose a new solution called QuaQue that allows querying across multiple versions of graphs and we also present the results of our benchmark comparing our solution against existing approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.21203v4</guid>
      <category>cs.DB</category>
      <pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jey Puget Gil, Emmanuel Coquery, John Samuel, Gilles Gesquiere</dc:creator>
    </item>
    <item>
      <title>Efficient Forkless Blockchain Databases</title>
      <link>https://arxiv.org/abs/2508.20686</link>
      <description>arXiv:2508.20686v2 Announce Type: replace 
Abstract: Operating nodes in an L1 blockchain remains costly despite recent advances in blockchain technology. One of the most resource-intensive components of a node is the blockchain database, also known as StateDB, that manages balances, nonce, code, and the persistent storage of accounts/smart contracts. Although the blockchain industry has transitioned from forking to forkless chains due to improved consensus protocols, forkless blockchains still rely on legacy forking databases that are suboptimal for their purposes. In this paper, we propose a forkless blockchain database, showing a 100x improvement in storage and a 10x improvement in throughput compared to the geth-based Fantom Blockchain client.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.20686v2</guid>
      <category>cs.DB</category>
      <pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Herbert Jordan, Kamil Jezek, Pavle Subotic, Bernhard Scholz</dc:creator>
    </item>
    <item>
      <title>From Source to Target: Leveraging Transfer Learning for Predictive Process Monitoring in Organizations</title>
      <link>https://arxiv.org/abs/2508.08061</link>
      <description>arXiv:2508.08061v2 Announce Type: replace-cross 
Abstract: Event logs reflect the behavior of business processes that are mapped in organizational information systems. Predictive process monitoring (PPM) transforms these data into value by creating process-related predictions that provide the insights required for proactive interventions at process runtime. Existing PPM techniques require sufficient amounts of event data or other relevant resources that might not be readily available, which prevents some organizations from utilizing PPM. The transfer learning-based PPM technique presented in this paper allows organizations without suitable event data or other relevant resources to implement PPM for effective decision support. This technique is instantiated in both a real-life intra- and an inter-organizational use case, based on which numerical experiments are performed using event logs for IT service management processes. The results of the experiments suggest that knowledge of one business process can be transferred to a similar business process in the same or a different organization to enable effective PPM in the target context. The proposed technique allows organizations to benefit from transfer learning in intra- and inter-organizational settings by transferring resources such as pre-trained models within and across organizational boundaries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08061v2</guid>
      <category>cs.LG</category>
      <category>cs.CL</category>
      <category>cs.DB</category>
      <pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Sven Weinzierl, Sandra Zilker, Annina Liessmann, Martin K\"appel, Weixin Wang, Martin Matzner</dc:creator>
    </item>
    <item>
      <title>Agentar-Scale-SQL: Advancing Text-to-SQL through Orchestrated Test-Time Scaling</title>
      <link>https://arxiv.org/abs/2509.24403</link>
      <description>arXiv:2509.24403v2 Announce Type: replace-cross 
Abstract: State-of-the-art (SOTA) Text-to-SQL methods still lag significantly behind human experts on challenging benchmarks like BIRD. Current approaches that explore test-time scaling lack an orchestrated strategy and neglect the model's internal reasoning process. To bridge this gap, we introduce Agentar-Scale-SQL, a novel framework leveraging scalable computation to improve performance. Agentar-Scale-SQL implements an Orchestrated Test-Time Scaling strategy that synergistically combines three distinct perspectives: i) Internal Scaling via RL-enhanced Intrinsic Reasoning, ii) Sequential Scaling through Iterative Refinement, and iii) Parallel Scaling using Diverse Synthesis and Tournament Selection. Agentar-Scale-SQL is a general-purpose framework designed for easy adaptation to new databases and more powerful language models. Extensive experiments show that Agentar-Scale-SQL achieves SOTA performance on the BIRD benchmark, reaching 81.67\% execution accuracy on the test set and ranking first on the official leaderboard, demonstrating an effective path toward human-level performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24403v2</guid>
      <category>cs.CL</category>
      <category>cs.DB</category>
      <pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pengfei Wang, Baolin Sun, Xuemei Dong, Yaxun Dai, Hongwei Yuan, Mengdie Chu, Yingqi Gao, Xiang Qi, Peng Zhang, Ying Yan</dc:creator>
    </item>
  </channel>
</rss>
