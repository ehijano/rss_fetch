<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 04 Oct 2024 02:08:25 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Learning grid cells by predictive coding</title>
      <link>https://arxiv.org/abs/2410.01022</link>
      <description>arXiv:2410.01022v1 Announce Type: new 
Abstract: Grid cells in the medial entorhinal cortex (MEC) of the mammalian brain exhibit a strikingly regular hexagonal firing field over space. These cells are learned after birth and are thought to support spatial navigation but also more abstract computations. Although various computational models, including those based on artificial neural networks, have been proposed to explain the formation of grid cells, the process through which the MEC circuit ${\it learns}$ to develop grid cells remains unclear. In this study, we argue that predictive coding, a biologically plausible plasticity rule known to learn visual representations, can also train neural networks to develop hexagonal grid representations from spatial inputs. We demonstrate that grid cells emerge robustly through predictive coding in both static and dynamic environments, and we develop an understanding of this grid cell learning capability by analytically comparing predictive coding with existing models. Our work therefore offers a novel and biologically plausible perspective on the learning mechanisms underlying grid cells. Moreover, it extends the predictive coding theory to the hippocampal formation, suggesting a unified learning algorithm for diverse cortical representations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01022v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mufeng Tang, Helen Barron, Rafal Bogacz</dc:creator>
    </item>
    <item>
      <title>The exponential distance rule based network model predicts topology and reveals functionally relevant properties of the Drosophila projectome</title>
      <link>https://arxiv.org/abs/2410.01269</link>
      <description>arXiv:2410.01269v1 Announce Type: new 
Abstract: Studying structural brain networks has witnessed significant advancement in recent decades. Findings have revealed a geometric principle, the exponential distance rule (EDR) showing that the number of neurons decreases exponentially with the length of their axons. An EDR based network model explained various characteristics of inter-areal cortical networks in macaques, mice, and rats. The complete connectome of the Drosophila fruit fly has recently been mapped at the neuronal level. Our study demonstrates that the EDR holds true in Drosophila, and the EDR model effectively accounts for numerous binary and weighted properties of neuropil networks, also called projectome. Our study illustrates that the EDR model is a suitable null model for analyzing networks of brain regions, as it captures geometric and physical constraints in very different species. The importance of the null model lies in its ability to facilitate the identification of functionally significant features that are not caused by inevitable geometric constraints, as we illustrate with the pronounced asymmetry of connection weights important for functional hierarchy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01269v1</guid>
      <category>q-bio.NC</category>
      <category>physics.bio-ph</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Balazs Pentek, Maria Ercsey-Ravasz</dc:creator>
    </item>
    <item>
      <title>GAMMA-PD: Graph-based Analysis of Multi-Modal Motor Impairment Assessments in Parkinson's Disease</title>
      <link>https://arxiv.org/abs/2410.00944</link>
      <description>arXiv:2410.00944v1 Announce Type: cross 
Abstract: The rapid advancement of medical technology has led to an exponential increase in multi-modal medical data, including imaging, genomics, and electronic health records (EHRs). Graph neural networks (GNNs) have been widely used to represent this data due to their prominent performance in capturing pairwise relationships. However, the heterogeneity and complexity of multi-modal medical data still pose significant challenges for standard GNNs, which struggle with learning higher-order, non-pairwise relationships. This paper proposes GAMMA-PD (Graph-based Analysis of Multi-modal Motor Impairment Assessments in Parkinson's Disease), a novel heterogeneous hypergraph fusion framework for multi-modal clinical data analysis. GAMMA-PD integrates imaging and non-imaging data into a "hypernetwork" (patient population graph) by preserving higher-order information and similarity between patient profiles and symptom subtypes. We also design a feature-based attention-weighted mechanism to interpret feature-level contributions towards downstream decision tasks. We evaluate our approach with clinical data from the Parkinson's Progression Markers Initiative (PPMI) and a private dataset. We demonstrate gains in predicting motor impairment symptoms in Parkinson's disease. Our end-to-end framework also learns associations between subsets of patient characteristics to generate clinically relevant explanations for disease and symptom profiles. The source code is available at https://github.com/favour-nerrise/GAMMA-PD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00944v1</guid>
      <category>q-bio.QM</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>eess.IV</category>
      <category>q-bio.NC</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Favour Nerrise (Department of Electrical Engineering, Stanford University, Stanford, CA, USA), Alice Louise Heiman (Department of Computer Science, Stanford University, Stanford, CA, USA), Ehsan Adeli (Department of Computer Science, Stanford University, Stanford, CA, USA, Department of Psychiatry and Behavioral Sciences, Stanford University, Stanford, CA, USA)</dc:creator>
    </item>
    <item>
      <title>Reproducibility via neural fields of visual illusions induced by localized stimuli</title>
      <link>https://arxiv.org/abs/2401.09108</link>
      <description>arXiv:2401.09108v2 Announce Type: replace 
Abstract: This paper focuses on the modeling of experiments conducted by Billock and Tsou [V. A. Billock and B. H. Tsou, Proc. Natl. Acad. Sci. USA, 104 (2007), pp. 8490--8495] using an Amari-type neural field that models the average membrane potential of neuronal activity in the primary visual cortex (V1). The study specifically focuses on a regular funnel pattern localized in the fovea or the peripheral visual field. It aims to comprehend and model the visual phenomena induced by this pattern, emphasizing their nonlinear nature. The research involves designing sensory inputs that mimic the visual stimuli from Billock and Tsou's experiments. The cortical outputs induced by these sensory inputs are then theoretically and numerically studied to assess their ability to model the experimentally observed visual effects at the V1 level. A crucial aspect of this study is the exploration of the effects induced by the nonlinear nature of neural responses. By highlighting the significance of excitatory and inhibitory neurons in the emergence of these visual phenomena, the research suggests that an interplay of both types of neuronal activities plays a crucial role in visual processes, challenging the assumption that the latter is primarily driven by excitatory activities alone.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.09108v2</guid>
      <category>q-bio.NC</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.NA</category>
      <category>nlin.PS</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cyprien Tamekue, Dario Prandi, Yacine Chitour</dc:creator>
    </item>
    <item>
      <title>Generating synthetic light-adapted electroretinogram waveforms using Artificial Intelligence to improve classification of retinal conditions in under-represented populations</title>
      <link>https://arxiv.org/abs/2404.11842</link>
      <description>arXiv:2404.11842v3 Announce Type: replace 
Abstract: Visual electrophysiology is often used clinically to determine functional changes associated with retinal or neurological conditions. The full-field flash electroretinogram (ERG) assesses the global contribution of the outer and inner retinal layers initiated by the rods and cone pathways depending on the state of retinal adaptation. Within clinical centers reference normative data are used to compare with clinical cases that may be rare or underpowered within a specific demographic. To bolster either reference or case datasets the application of synthetic ERG waveforms may offer benefits to disease classification and case-control studies. In this study and as a proof of concept, artificial intelligence (AI) to generate synthetic signals using Generative Adversarial Networks is deployed to up-scale male participants within an ISCEV reference dataset containing 68 participants, with waveforms from the right and left eye. Random Forest Classifiers further improved classification for sex within the group from a balanced accuracy of 0.72 to 0.83 with the added synthetic male waveforms. This is the first study to demonstrate the generation of synthetic ERG waveforms to improve machine learning classification modelling with electroretinogram waveforms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11842v3</guid>
      <category>q-bio.NC</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1155/2024/1990419</arxiv:DOI>
      <dc:creator>Mikhail Kulyabin, Aleksei Zhdanov, Andreas Maier, Lynne Loh, Jose J. Estevez, Paul A. Constable</dc:creator>
    </item>
    <item>
      <title>Time-Dependent VAE for Building Latent Representations from Visual Neural Activity with Complex Dynamics</title>
      <link>https://arxiv.org/abs/2408.07908</link>
      <description>arXiv:2408.07908v2 Announce Type: replace-cross 
Abstract: Seeking high-quality representations with latent variable models (LVMs) to reveal the intrinsic correlation between neural activity and behavior or sensory stimuli has attracted much interest. Most work has focused on analyzing motor neural activity that controls clear behavioral traces and has modeled neural temporal relationships in a way that does not conform to natural reality. For studies of visual brain regions, naturalistic visual stimuli are high-dimensional and time-dependent, making neural activity exhibit intricate dynamics. To cope with such conditions, we propose Time-Dependent Split VAE (TiDeSPL-VAE), a sequential LVM that decomposes visual neural activity into two latent representations while considering time dependence. We specify content latent representations corresponding to the component of neural activity driven by the current visual stimulus, and style latent representations corresponding to the neural dynamics influenced by the organism's internal state. To progressively generate the two latent representations over time, we introduce state factors to construct conditional distributions with time dependence and apply self-supervised contrastive learning to shape them. By this means, TiDeSPL-VAE can effectively analyze complex visual neural activity and model temporal relationships in a natural way. We compare our model with alternative approaches on synthetic data and neural data from the mouse visual cortex. The results show that our model not only yields the best decoding performance on naturalistic scenes/movies but also extracts explicit neural dynamics, demonstrating that it builds latent representations more relevant to visual stimuli.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07908v2</guid>
      <category>cs.NE</category>
      <category>q-bio.NC</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liwei Huang, ZhengYu Ma, Liutao Yu, Huihui Zhou, Yonghong Tian</dc:creator>
    </item>
  </channel>
</rss>
