<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 06 Feb 2025 05:00:35 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Investigation on the Shooting Method Ability to Solve Different Mooring Lines Boundary Condition Types</title>
      <link>https://arxiv.org/abs/2502.02591</link>
      <description>arXiv:2502.02591v1 Announce Type: new 
Abstract: The study of undersea cables and mooring lines statics remains an unavoidable subject of simulation in offshore field for either steady-state analysis or dynamic simulation initialization. Whether the study concerns mooring systems pinned both at seabed and floating platform, cables towed by a moving underwater system or when special links such as stiffeners are needed, the ability to model every combination is a key point. To do so the authors propose to investigate the use of the shooting method to solve the two point boundary value problem (TPBVP) associated with Dirichlet, Robin or mixed boundary conditions representing respectively, displacement, force and force/displacement boundary conditions. 3D nonlinear static string calculations are confronted to a semi-analytic formulation established from the catenary closed form equations. The comparisons are performed on various pairs of boundary conditions developed in five configurations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02591v1</guid>
      <category>cs.CE</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1115/OMAE2018-77563</arxiv:DOI>
      <dc:creator>Florian Surmont, Damien Coache</dc:creator>
    </item>
    <item>
      <title>A Paradigm Shift to Assembly-like Finite Element Model Updating</title>
      <link>https://arxiv.org/abs/2502.02592</link>
      <description>arXiv:2502.02592v1 Announce Type: new 
Abstract: In general, there is a mismatch between a finite element model of a structure and its real behaviour. In aeronautics, this mismatch must be small because finite element models are a fundamental part of the development of an aircraft and of increasing importance with the trend to more flexible wings in modern designs. Finite element model updating can be computationally expensive for complex structures and surrogate models can be employed to reduce the computational burden. A novel approach for finite element model updating, namely assembly-like, is proposed and validated using real experimental data. The assembly-like model updating framework implies that the model is updated as parts are assembled. Benchmarking against the classical global, or one-shot, approach demonstrates that the proposed method is more computationally efficient since it takes 20% fewer iterations to obtain convergence, also using fewer parameters for the model evaluations. Despite the increase in computational performance, the new approach retains the fidelity of the global approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02592v1</guid>
      <category>cs.CE</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gabriele Dessena, Alessandro Pontillo, Dmitry I. Ignatyev, James F. Whidborne, Luca Zanotti Fragonara</dc:creator>
    </item>
    <item>
      <title>Reconstructing 3D Flow from 2D Data with Diffusion Transformer</title>
      <link>https://arxiv.org/abs/2502.02593</link>
      <description>arXiv:2502.02593v1 Announce Type: new 
Abstract: Fluid flow is a widely applied physical problem, crucial in various fields. Due to the highly nonlinear and chaotic nature of fluids, analyzing fluid-related problems is exceptionally challenging. Computational fluid dynamics (CFD) is the best tool for this analysis but involves significant computational resources, especially for 3D simulations, which are slow and resource-intensive. In experimental fluid dynamics, PIV cost increases with dimensionality. Reconstructing 3D flow fields from 2D PIV data could reduce costs and expand application scenarios. Here, We propose a Diffusion Transformer-based method for reconstructing 3D flow fields from 2D flow data. By embedding the positional information of 2D planes into the model, we enable the reconstruction of 3D flow fields from any combination of 2D slices, enhancing flexibility. We replace global attention with window and plane attention to reduce computational costs associated with higher dimensions without compromising performance. Our experiments demonstrate that our model can efficiently and accurately reconstruct 3D flow fields from 2D data, producing realistic results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02593v1</guid>
      <category>cs.CE</category>
      <category>cs.AI</category>
      <category>physics.flu-dyn</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fan Lei</dc:creator>
    </item>
    <item>
      <title>Offshore Wind Turbine Tower Design and Optimization: A Review and AI-Driven Future Directions</title>
      <link>https://arxiv.org/abs/2502.02594</link>
      <description>arXiv:2502.02594v1 Announce Type: new 
Abstract: Offshore wind energy leverages the high intensity and consistency of oceanic winds, playing a key role in the transition to renewable energy. As energy demands grow, larger turbines are required to optimize power generation and reduce the Levelized Cost of Energy (LCoE), which represents the average cost of electricity over a project's lifetime. However, upscaling turbines introduces engineering challenges, particularly in the design of supporting structures, especially towers. These towers must support increased loads while maintaining structural integrity, cost-efficiency, and transportability, making them essential to offshore wind projects' success. This paper presents a comprehensive review of the latest advancements, challenges, and future directions driven by Artificial Intelligence (AI) in the design optimization of Offshore Wind Turbine (OWT) structures, with a focus on towers. It provides an in-depth background on key areas such as design types, load types, analysis methods, design processes, monitoring systems, Digital Twin (DT), software, standards, reference turbines, economic factors, and optimization techniques. Additionally, it includes a state-of-the-art review of optimization studies related to tower design optimization, presenting a detailed examination of turbine, software, loads, optimization method, design variables and constraints, analysis, and findings, motivating future research to refine design approaches for effective turbine upscaling and improved efficiency. Lastly, the paper explores future directions where AI can revolutionize tower design optimization, enabling the development of efficient, scalable, and sustainable structures. By addressing the upscaling challenges and supporting the growth of renewable energy, this work contributes to shaping the future of offshore wind turbine towers and others supporting structures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02594v1</guid>
      <category>cs.CE</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jo\~ao Alves Ribeiro, Bruno Alves Ribeiro, Francisco Pimenta, S\'ergio M. O. Tavares, Jie Zhang, Faez Ahmed</dc:creator>
    </item>
    <item>
      <title>A Quasi-Optimal Shape Design Method for Lattice Structure Construction</title>
      <link>https://arxiv.org/abs/2502.02602</link>
      <description>arXiv:2502.02602v1 Announce Type: new 
Abstract: Lattice structures, known for their superior mechanical properties, are widely used in industries such as aerospace, automotive, and biomedical. Their advantages primarily lie in the interconnected struts at the micro-scale. The robust construction of these struts is crucial for downstream design and manufacturing applications, as it provides a detailed shape description necessary for precise simulation and fabrication. However, constructing lattice structures presents significant challenges, particularly at nodes where multiple struts intersect. The complexity of these intersections can lead to robustness issues. To address this challenge, this paper presents an optimization-based approach that simplifies the construction of lattice structures by cutting struts and connecting them to optimized node shapes. By utilizing the recent Grey Wolf optimization method -- a type of meta-heuristic method -- for node shape design, the approach ensures robust model construction and optimal shape design. Its effectiveness has been validated through a series of case studies with increasing topological and geometric complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02602v1</guid>
      <category>cs.CE</category>
      <category>math.OC</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sifan Chen, Yuan Kong, Qiang Zou</dc:creator>
    </item>
    <item>
      <title>Physically Interpretable Representation and Controlled Generation for Turbulence Data</title>
      <link>https://arxiv.org/abs/2502.02605</link>
      <description>arXiv:2502.02605v1 Announce Type: new 
Abstract: Computational Fluid Dynamics (CFD) plays a pivotal role in fluid mechanics, enabling precise simulations of fluid behavior through partial differential equations (PDEs). However, traditional CFD methods are resource-intensive, particularly for high-fidelity simulations of complex flows, which are further complicated by high dimensionality, inherent stochasticity, and limited data availability. This paper addresses these challenges by proposing a data-driven approach that leverages a Gaussian Mixture Variational Autoencoder (GMVAE) to encode high-dimensional scientific data into low-dimensional, physically meaningful representations. The GMVAE learns a structured latent space where data can be categorized based on physical properties such as the Reynolds number while maintaining global physical consistency. To assess the interpretability of the learned representations, we introduce a novel metric based on graph spectral theory, quantifying the smoothness of physical quantities along the latent manifold. We validate our approach using 2D Navier-Stokes simulations of flow past a cylinder over a range of Reynolds numbers. Our results demonstrate that the GMVAE provides improved clustering, meaningful latent structure, and robust generative capabilities compared to baseline dimensionality reduction methods. This framework offers a promising direction for data-driven turbulence modeling and broader applications in computational fluid dynamics and engineering systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02605v1</guid>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>physics.comp-ph</category>
      <category>physics.flu-dyn</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Tiffany Fan, Murray Cutforth, Marta D'Elia, Alexandre Cortiella, Alireza Doostan, Eric Darve</dc:creator>
    </item>
    <item>
      <title>Tensor Network Structure Search Using Program Synthesis</title>
      <link>https://arxiv.org/abs/2502.02711</link>
      <description>arXiv:2502.02711v1 Announce Type: new 
Abstract: Tensor networks provide a powerful framework for compressing multi-dimensional data. The optimal tensor network structure for a given data tensor depends on both the inherent data properties and the specific optimality criteria, making tensor network structure search a crucial research problem. Existing solutions typically involve sampling and validating numerous candidate structures; this is computationally expensive, limiting their practical applications. We address this challenge by formulating tensor network structure search as a program synthesis problem and proposing a highly efficient validation method that is based on constraint solving. Specifically, we design a domain specific language: it builds the correspondence between programs and network structures, and uses a novel idea of output-directed splits to compress the search space without hindering the expressiveness. We then propose a synthesis algorithm that can prioritize promising candidates through constraint solving. % Experimental results show that our approach improves search speed by $10\times$ and achieves compression ratios by $1.5\times$ to $3\times$ better than state-of-the-art. Notably, our approach scales to larger tensors that are out of reach by prior work. Finally, we demonstrate that the discovered topologies generalize to data from the same source, achieving compression ratios up to $ 2.4\times$ better than hierarchical Tuckers while maintaining the runtime around $110$ seconds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02711v1</guid>
      <category>cs.CE</category>
      <category>cs.PL</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zheng Guo, Aditya Deshpande, Brian Kiedrowski, Xinyu Wang, Alex Gorodetsky</dc:creator>
    </item>
    <item>
      <title>An efficient end-to-end computational framework for the generation of ECG calibrated volumetric models of human atrial electrophysiology</title>
      <link>https://arxiv.org/abs/2502.03322</link>
      <description>arXiv:2502.03322v1 Announce Type: cross 
Abstract: Computational models of atrial electrophysiology (EP) are increasingly utilized for applications such as the development of advanced mapping systems, personalized clinical therapy planning, and the generation of virtual cohorts and digital twins. These models have the potential to establish robust causal links between simulated in silico behaviors and observed human atrial EP, enabling safer, cost-effective, and comprehensive exploration of atrial dynamics. However, current state-of-the-art approaches lack the fidelity and scalability required for regulatory-grade applications, particularly in creating high-quality virtual cohorts or patient-specific digital twins. Challenges include anatomically accurate model generation, calibration to sparse and uncertain clinical data, and computational efficiency within a streamlined workflow. This study addresses these limitations by introducing novel methodologies integrated into an automated end-to-end workflow for generating high-fidelity digital twin snapshots and virtual cohorts of atrial EP. These innovations include: (i) automated multi-scale generation of volumetric biatrial models with detailed anatomical structures and fiber architecture; (ii) a robust method for defining space-varying atrial parameter fields; (iii) a parametric approach for modeling inter-atrial conduction pathways; and (iv) an efficient forward EP model for high-fidelity electrocardiogram computation. We evaluated this workflow on a cohort of 50 atrial fibrillation patients, producing high-quality meshes suitable for reaction-eikonal and reaction-diffusion models and demonstrating the ability to simulate atrial ECGs under parametrically controlled conditions. These advancements represent a critical step toward scalable, precise, and clinically applicable digital twin models and virtual cohorts, enabling enhanced patient-specific predictions and therapeutic planning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03322v1</guid>
      <category>math.NA</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>q-bio.TO</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Elena Zappon, Luca Azzolin, Matthias A. F. Gsell, Franz Thaler, Anton J. Prassl, Robert Arnold, Karli Gillette, Mohammadreza Kariman, Martin Manninger-W\"unscher, Daniel Scherr, Aurel Neic, Martin Urschler, Christoph M. Augustin, Edward J. Vigmond, Gernot Plank</dc:creator>
    </item>
    <item>
      <title>Multi-objective Optimisation Framework for Blue-Green Infrastructure Placement Using Detailed Flood Model</title>
      <link>https://arxiv.org/abs/2310.13989</link>
      <description>arXiv:2310.13989v2 Announce Type: replace 
Abstract: This study aims to find a cost-effective Blue-Green Infrastructure placement scheme by developing an improved approach called the Cost Optimization Framework for Implementing blue-Green infrastructure (CONFIGURE). The optimisation framework integrates a detailed hydrodynamic flood simulation model with a multi-objective optimisation algorithm (Non-dominated Sorting Genetic Algorithm II). The use of a high-resolution flood simulation model ensures the explicit representation of BGI and other land use features to simulate flow pathways and surface flood risk accurately, while the optimisation algorithm guarantees achieving the best cost-benefit trade-offs for given BGI options. The current study uses the advanced CityCAT hydrodynamic flood model to evaluate the efficiency of the optimisation framework and the impact of location and size of permeable interventions on the optimisation process and subsequent cost-benefit trade-offs. This is achieved by dividing permeable surface areas into intervention zones of varying size and quantity. Furthermore, rainstorm events with 100-year and 30-year return periods are analysed to identify any common optimal solutions for different rainfall intensities. Depending on the number of intervention locations, the automated framework reliably achieves optimal BGI implementation solutions in a fraction of the time required to find the best solutions by trialling all possible options. Designing and optimising interventions with smaller sizes but many permeable zones saves a good fraction of investment. However, such a design scheme requires more computational time to find optimal options. Furthermore, the optimal spatial configuration of BGI varies with different rainstorm severities, suggesting a need for careful selection of the rainstorm return period.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.13989v2</guid>
      <category>cs.CE</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.jhydrol.2024.131571</arxiv:DOI>
      <arxiv:journal_reference>Journal of Hydrology, 638, 131571 (2024)</arxiv:journal_reference>
      <dc:creator>Asid Ur Rehman, Vassilis Glenis, Elizabeth Lewis, Chris Kilsby</dc:creator>
    </item>
    <item>
      <title>A physics-encoded Fourier neural operator approach for surrogate modeling of divergence-free stress fields in solids</title>
      <link>https://arxiv.org/abs/2408.15408</link>
      <description>arXiv:2408.15408v2 Announce Type: replace 
Abstract: The purpose of the current work is the development of a so-called physics-encoded Fourier neural operator (PeFNO) for surrogate modeling of the quasi-static equilibrium stress field in solids. Rather than accounting for constraints from physics in the loss function as done in the (now standard) physics-informed approach, the physics-encoded approach incorporates or "encodes" such constraints directly into the network or operator architecture. As a result, in contrast to the physics-informed approach in which only training is physically constrained, both training and output are physically constrained in the physics-encoded approach. For the current constraint of divergence-free stress, a novel encoding approach based on a stress potential is proposed.
  As a "proof-of-concept" example application of the proposed PeFNO, a heterogeneous polycrystalline material consisting of isotropic elastic grains subject to uniaxial extension is considered. Stress field data for training are obtained from the numerical solution of a corresponding boundary-value problem for quasi-static mechanical equilibrium. This data is also employed to train an analogous physics-guided FNO (PgFNO) and physics-informed FNO (PiFNO) for comparison. As confirmed by this comparison and as expected on the basis of their differences, the output of the trained PeFNO is significantly more accurate in satisfying mechanical equilibrium than the output of either the trained PgFNO or the trained PiFNO.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.15408v2</guid>
      <category>cs.CE</category>
      <category>cond-mat.mtrl-sci</category>
      <category>cs.LG</category>
      <category>math.AP</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammad S. Khorrami, Pawan Goyal, Jaber R. Mianroodi, Bob Svendsen, Peter Benner, Dierk Raabe</dc:creator>
    </item>
    <item>
      <title>TwinMarket: A Scalable Behavioral and Social Simulation for Financial Markets</title>
      <link>https://arxiv.org/abs/2502.01506</link>
      <description>arXiv:2502.01506v2 Announce Type: replace 
Abstract: The study of social emergence has long been a central focus in social science. Traditional modeling approaches, such as rule-based Agent-Based Models (ABMs), struggle to capture the diversity and complexity of human behavior, particularly the irrational factors emphasized in behavioral economics. Recently, large language model (LLM) agents have gained traction as simulation tools for modeling human behavior in social science and role-playing applications. Studies suggest that LLMs can account for cognitive biases, emotional fluctuations, and other non-rational influences, enabling more realistic simulations of socio-economic dynamics. In this work, we introduce TwinMarket, a novel multi-agent framework that leverages LLMs to simulate socio-economic systems. Specifically, we examine how individual behaviors, through interactions and feedback mechanisms, give rise to collective dynamics and emergent phenomena. Through experiments in a simulated stock market environment, we demonstrate how individual actions can trigger group behaviors, leading to emergent outcomes such as financial bubbles and recessions. Our approach provides valuable insights into the complex interplay between individual decision-making and collective socio-economic patterns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01506v2</guid>
      <category>cs.CE</category>
      <category>cs.CY</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuzhe Yang, Yifei Zhang, Minghao Wu, Kaidi Zhang, Yunmiao Zhang, Honghai Yu, Yan Hu, Benyou Wang</dc:creator>
    </item>
    <item>
      <title>An Exposition of Pathfinding Strategies Within Lightning Network Clients</title>
      <link>https://arxiv.org/abs/2410.13784</link>
      <description>arXiv:2410.13784v2 Announce Type: replace-cross 
Abstract: The Lightning Network is a peer-to-peer network designed to address Bitcoin's scalability challenges, facilitating rapid, cost-effective, and instantaneous transactions through bidirectional, blockchain-backed payment channels among network peers. Due to a source-based routing of payments, different pathfinding strategies are used in practice, trading off different objectives for each other such as payment reliability and routing fees. This paper explores differences within pathfinding strategies used by prominent Lightning Network node implementations, which include different underlying cost functions and different constraints, as well as different greedy algorithms of shortest path-type. Surprisingly, we observe that the pathfinding problems that most LN node implementations attempt to solve are NP-complete, and cannot be guaranteed to be optimally solved by the variants of Dijkstra's algorithm currently deployed in production. Through comparative analysis and simulations, we evaluate efficacy of different pathfinding strategies across metrics such as success rate, fees, path length, and timelock. Our experiments indicate that the strategies used by Eclair are advantageous in terms of payment reliability and result in paths with low fees. LND exhibits moderate success rates, while LDK results in paths with higher fee levels for smaller payment amounts; furthermore, CLN stands out for its minimal timelock paths. Additionally, we investigate the impact of Lightning node connectivity levels on routing efficiency. The findings of our analysis provide insights towards future improvements of pathfinding strategies and algorithms used within the Lightning Network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13784v2</guid>
      <category>cs.NI</category>
      <category>cs.CE</category>
      <category>cs.CR</category>
      <category>cs.SI</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Sindura Saraswathi, Christian K\"ummerle</dc:creator>
    </item>
    <item>
      <title>Physics-Informed Deep Learning Model for Line-integral Diagnostics Across Fusion Devices</title>
      <link>https://arxiv.org/abs/2412.00087</link>
      <description>arXiv:2412.00087v2 Announce Type: replace-cross 
Abstract: Rapid reconstruction of 2D plasma profiles from line-integral measurements is important in nuclear fusion. This paper introduces a physics-informed model architecture called Onion, that can enhance the performance of models and be adapted to various backbone networks. The model under Onion incorporates physical information by a multiplication process and applies the physics-informed loss function according to the principle of line integration. Experimental results demonstrate that the additional input of physical information improves the model's ability, leading to a reduction in the average relative error E_1 between the reconstruction profiles and the target profiles by approximately 52% on synthetic datasets and about 15% on experimental datasets. Furthermore, the implementation of the Softplus activation function in the final two fully connected layers improves model performance. This enhancement results in a reduction in the E_1 by approximately 71% on synthetic datasets and about 27% on experimental datasets. The incorporation of the physics-informed loss function has been shown to correct the model's predictions, bringing the back-projections closer to the actual inputs and reducing the errors associated with inversion algorithms. Besides, we have developed a synthetic data model to generate customized line-integral diagnostic datasets and have also collected soft x-ray diagnostic datasets from EAST and HL-2A. This study achieves reductions in reconstruction errors, and accelerates the development of diagnostic surrogate models in fusion research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00087v2</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cong Wang, Weizhe Yang, Haiping Wang, Renjie Yang, Jing Li, Zhijun Wang, Xinyao Yu, Yixiong Wei, Xianli Huang, Chenshu Hu, Zhaoyang Liu, Changqing Zou, Zhifeng Zhao</dc:creator>
    </item>
  </channel>
</rss>
