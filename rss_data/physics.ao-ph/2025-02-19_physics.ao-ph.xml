<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.ao-ph updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.ao-ph</link>
    <description>physics.ao-ph updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.ao-ph" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 19 Feb 2025 05:00:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A thermal Green-Naghdi model with time dependent bathymetry and complete Coriolis force</title>
      <link>https://arxiv.org/abs/2502.12220</link>
      <description>arXiv:2502.12220v1 Announce Type: new 
Abstract: This paper extends the theoretical Euler-Poincar\'e framework for modelling ocean mixed layer dynamics. Through a symmetry-broken Lie group invariant variational principle, we derive a generalised Green-Naghdi equation with time dependent bathymetry, a complete Coriolis force, and inhomogeneity of the thermal buoyancy. The nature of the model derived here lends it a potential future application to wave dynamics generated by changes to the bathymetry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12220v1</guid>
      <category>physics.ao-ph</category>
      <category>physics.flu-dyn</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Darryl D. Holm, Oliver D. Street</dc:creator>
    </item>
    <item>
      <title>Ensemble Kalman filter in latent space using a variational autoencoder pair</title>
      <link>https://arxiv.org/abs/2502.12987</link>
      <description>arXiv:2502.12987v1 Announce Type: cross 
Abstract: Popular (ensemble) Kalman filter data assimilation (DA) approaches assume that the errors in both the a priori estimate of the state and those in the observations are Gaussian. For constrained variables, e.g. sea ice concentration or stress, such an assumption does not hold. The variational autoencoder (VAE) is a machine learning (ML) technique that allows to map an arbitrary distribution to/from a latent space in which the distribution is supposedly closer to a Gaussian. We propose a novel hybrid DA-ML approach in which VAEs are incorporated in the DA procedure. Specifically, we introduce a variant of the popular ensemble transform Kalman filter (ETKF) in which the analysis is applied in the latent space of a single VAE or a pair of VAEs. In twin experiments with a simple circular model, whereby the circle represents an underlying submanifold to be respected, we find that the use of a VAE ensures that a posteri ensemble members lie close to the manifold containing the truth. Furthermore, online updating of the VAE is necessary and achievable when this manifold varies in time, i.e. when it is non-stationary. We demonstrate that introducing an additional second latent space for the observational innovations improves robustness against detrimental effects of non-Gaussianity and bias in the observational errors but it slightly lessens the performance if observational errors are strictly Gaussian.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12987v1</guid>
      <category>cs.LG</category>
      <category>physics.ao-ph</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ivo Pasmans, Yumeng Chen, Tobias Sebastian Finn, Marc Bocquet, Alberto Carrassi</dc:creator>
    </item>
    <item>
      <title>On the attribution of weather events to climate change using a fit to extreme value distributions</title>
      <link>https://arxiv.org/abs/2308.07560</link>
      <description>arXiv:2308.07560v4 Announce Type: replace 
Abstract: Changes in extreme weather events are a potentially important aspect of anthropogenic climate change (ACC), yet, are difficult to attribute to ACC because the record length is often similar to, or shorter than, extreme-event return periods. This study is motivated by the ``World Weather Attribution'' initiative (WWA) and, specifically, their approach of fitting extreme value distribution functions to local observations. They calculate the dependence of distribution parameters on global mean surface temperature (GMST) and use this dependence to attribute extreme events to ACC. Applying this method to preindustrial climate simulations with no time-varying greenhouse gas forcing, we still find a strong dependence of distribution parameters on GMST. This dependence results from internal climate variability (e.g., ENSO) affecting both extreme events and GMST. Therefore, dependence on GMST does not necessarily imply an effect of ACC on extremes. We further consider whether an extreme value, normal, or log-normal distribution better represents the data; if a GMST-dependence of distribution parameters is justified using a likelihood ratio test; and if a meaningful attribution is possible given uncertainties in GMST dependence. We find, for example, that an attribution of Australia's 2020--2021 Bushfires to ACC is difficult due to the effects of internal variability. For the 2019--2021 drought in Madagascar we find that the small number of available data points precludes a meaningful attribution analysis. Overall, we find that the effects of internal climate variability on GMST and the uncertain relationship between GMST and regional extremes may lead to inaccurate attribution conclusions using the part of the WWA approach examined here.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.07560v4</guid>
      <category>physics.ao-ph</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Peter Sherman, Peter Huybers, Eli Tziperman</dc:creator>
    </item>
    <item>
      <title>Simulating Atmospheric Processes in Earth System Models and Quantifying Uncertainties with Deep Learning Multi-Member and Stochastic Parameterizations</title>
      <link>https://arxiv.org/abs/2402.03079</link>
      <description>arXiv:2402.03079v3 Announce Type: replace 
Abstract: Deep learning is a powerful tool to represent subgrid processes in climate models, but many application cases have so far used idealized settings and deterministic approaches. Here, we develop stochastic parameterizations with calibrated uncertainty quantification to learn subgrid convective and turbulent processes and surface radiative fluxes of a superparameterization (SP) embedded in an Earth System Model (ESM). We explore three methods to construct stochastic parameterizations: 1) a single Deep Neural Network (DNN) with Monte Carlo Dropout; 2) a multi-member parameterization; and 3) a Variational Encoder Decoder with latent space perturbation. We show that the multi-member (MM) parameterization improves the representation of convective processes, especially in the planetary boundary layer, compared to individual DNNs. The respective uncertainty quantification illustrates that methods 2) and 3) are advantageous compared to a dropout-based DNN parameterization regarding the spread of convective processes. Hybrid simulations with our best-performing MM parameterizations remained challenging and crash within the first days. Therefore, we develop a pragmatic partial coupling strategy relying on the SP for condensate emulation. Partial coupling reduces the computational efficiency of hybrid Earth-like simulations but enables model stability over 5 months with our MM parameterizations. However, our hybrid simulations exhibit biases in thermodynamic fields and differences in precipitation patterns. Despite this, the MM parameterizations enable improvements in reproducing tropical extreme precipitation compared to a traditional convection parameterization. Despite these challenges, our results indicate the potential of a new generation of MM machine learning parameterizations leveraging uncertainty quantification to improve the representation of stochasticity of subgrid effects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.03079v3</guid>
      <category>physics.ao-ph</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gunnar Behrens, Tom Beucler, Fernando Iglesias-Suarez, Sungduk Yu, Pierre Gentine, Michael Pritchard, Mierk Schwabe, Veronika Eyring</dc:creator>
    </item>
    <item>
      <title>Huge Ensembles Part I: Design of Ensemble Weather Forecasts using Spherical Fourier Neural Operators</title>
      <link>https://arxiv.org/abs/2408.03100</link>
      <description>arXiv:2408.03100v2 Announce Type: replace 
Abstract: Studying low-likelihood high-impact extreme weather events in a warming world is a significant and challenging task for current ensemble forecasting systems. While these systems presently use up to 100 members, larger ensembles could enrich the sampling of internal variability. They may capture the long tails associated with climate hazards better than traditional ensemble sizes. Due to computational constraints, it is infeasible to generate huge ensembles (comprised of 1,000-10,000 members) with traditional, physics-based numerical models. In this two-part paper, we replace traditional numerical simulations with machine learning (ML) to generate hindcasts of huge ensembles. In Part I, we construct an ensemble weather forecasting system based on Spherical Fourier Neural Operators (SFNO), and we discuss important design decisions for constructing such an ensemble. The ensemble represents model uncertainty through perturbed-parameter techniques, and it represents initial condition uncertainty through bred vectors, which sample the fastest growing modes of the forecast. Using the European Centre for Medium-Range Weather Forecasts Integrated Forecasting System (IFS) as a baseline, we develop an evaluation pipeline composed of mean, spectral, and extreme diagnostics. Using large-scale, distributed SFNOs with 1.1 billion learned parameters, we achieve calibrated probabilistic forecasts. As the trajectories of the individual members diverge, the ML ensemble mean spectra degrade with lead time, consistent with physical expectations. However, the individual ensemble members' spectra stay constant with lead time. Therefore, these members simulate realistic weather states, and the ML ensemble thus passes a crucial spectral test in the literature. The IFS and ML ensembles have similar Extreme Forecast Indices, and we show that the ML extreme weather forecasts are reliable and discriminating.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.03100v2</guid>
      <category>physics.ao-ph</category>
      <category>cs.LG</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ankur Mahesh, William Collins, Boris Bonev, Noah Brenowitz, Yair Cohen, Joshua Elms, Peter Harrington, Karthik Kashinath, Thorsten Kurth, Joshua North, Travis OBrien, Michael Pritchard, David Pruitt, Mark Risser, Shashank Subramanian, Jared Willard</dc:creator>
    </item>
    <item>
      <title>Huge Ensembles Part II: Properties of a Huge Ensemble of Hindcasts Generated with Spherical Fourier Neural Operators</title>
      <link>https://arxiv.org/abs/2408.01581</link>
      <description>arXiv:2408.01581v2 Announce Type: replace-cross 
Abstract: In Part I, we created an ensemble based on Spherical Fourier Neural Operators. As initial condition perturbations, we used bred vectors, and as model perturbations, we used multiple checkpoints trained independently from scratch. Based on diagnostics that assess the ensemble's physical fidelity, our ensemble has comparable performance to operational weather forecasting systems. However, it requires several orders of magnitude fewer computational resources. Here in Part II, we generate a huge ensemble (HENS), with 7,424 members initialized each day of summer 2023. We enumerate the technical requirements for running huge ensembles at this scale. HENS precisely samples the tails of the forecast distribution and presents a detailed sampling of internal variability. For extreme climate statistics, HENS samples events 4$\sigma$ away from the ensemble mean. At each grid cell, HENS improves the skill of the most accurate ensemble member and enhances coverage of possible future trajectories. As a weather forecasting model, HENS issues extreme weather forecasts with better uncertainty quantification. It also reduces the probability of outlier events, in which the verification value lies outside the ensemble forecast distribution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01581v2</guid>
      <category>cs.LG</category>
      <category>physics.ao-ph</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ankur Mahesh, William Collins, Boris Bonev, Noah Brenowitz, Yair Cohen, Peter Harrington, Karthik Kashinath, Thorsten Kurth, Joshua North, Travis OBrien, Michael Pritchard, David Pruitt, Mark Risser, Shashank Subramanian, Jared Willard</dc:creator>
    </item>
  </channel>
</rss>
