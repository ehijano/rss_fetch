<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.TH</link>
    <description>stat.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 14 Jan 2026 05:00:38 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>The exact region determined by Spearman's footrule, Gini's gamma and Kendall's tau</title>
      <link>https://arxiv.org/abs/2601.07993</link>
      <description>arXiv:2601.07993v1 Announce Type: new 
Abstract: Concordance measures are used to express the degree of association between random variables. Practitioners may use several distinct concordance measures to narrow the space of possible dependence structures. Consequently, the relations between different (weak) concordance measures have been extensively studied in recent years. The goal of this paper is to study the relation between Kendall's tau, Gini's gamma and Spearman's footrule. In particular, we describe the exact region determined by these three measures, using shuffles of $M$ and ordinal sums of copulas. We also provide the formulas for five main (weak) concordance measures and Chatterjee's xi of ordinal sums of copulas.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07993v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Damjana Kokol Bukov\v{s}ek, Petra Lazi\'c, Bla\v{z} Moj\v{s}kerc, Nik Stopar</dc:creator>
    </item>
    <item>
      <title>Rank tests for time-varying covariance matrices observed under noise</title>
      <link>https://arxiv.org/abs/2601.08353</link>
      <description>arXiv:2601.08353v1 Announce Type: new 
Abstract: We consider a $d$-dimensional continuous martingale $X(t)$ with quadratic variation matrix $\langle X\rangle_t=\int_0^t \Sigma(s)\,ds$ and develop tests for the rank of its spot covariance matrix $\Sigma(t)$, $t\in[0,1]$. The process $X$ is observed under observational noise, as is standard for microstructure noise models in high-frequency finance. We test the null hypothesis ${\mathcal H}_0:rank(\Sigma(t))\le r$ against local alternatives ${\mathcal H}_{1,n}:\lambda_{r+1}(\Sigma(t))\ge v_n$, where $\lambda_{r+1}$ denotes the $(r+1)$st eigenvalue and $v_n\downarrow 0$ as the sample size $n\to\infty$. We construct test statistics based on eigenvalues of carefully calibrated localized spectral covariance matrix estimates. Critical values are provided non-asymptotically as well as asymptotically via maximal eigenvalues of Gaussian orthogonal ensembles. The power analysis establishes asymptotic consistency for a separation rate $v_n\thicksim (\underline\lambda_r^{-1/(\beta+1)}n^{-\beta/(\beta+1)})\wedge n^{-\beta/(\beta+2)}$, depending on the H\"older-regularity $\beta$ of $\Sigma$ and a possible spectral gap $\underline\lambda_r\ge 0$ under ${\mathcal H}_0$. A lower bound shows the optimality of this rate. We discuss why the rate is much faster than conventional estimation rates. The theory is illustrated by simulations and a real data example with German government bonds of varying maturity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08353v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Markus Rei{\ss}, Lars Winkelmann</dc:creator>
    </item>
    <item>
      <title>A Langevin sampler for quantum tomography</title>
      <link>https://arxiv.org/abs/2601.08775</link>
      <description>arXiv:2601.08775v1 Announce Type: new 
Abstract: Quantum tomography involves obtaining a full classical description of a prepared quantum state from experimental results. We propose a Langevin sampler for quantum tomography, that relies on a new formulation of Bayesian quantum tomography exploiting the Burer-Monteiro factorization of Hermitian positive-semidefinite matrices. If the rank of the target density matrix is known, this formulation allows us to define a posterior distribution that is only supported on matrices whose rank is upper-bounded by the rank of the target density matrix. Conversely, if the target rank is unknown, any upper bound on the rank can be used by our algorithm, and the rank of the resulting posterior mean estimator is further reduced by the use of a low-rank promoting prior density. This prior density is a complex extension of the one proposed in (Annales de l'Institut Henri Poincare Probability and Statistics, 56(2):1465-1483, 2020). We derive a PAC-Bayesian bound on our proposed estimator that matches the best bounds available in the literature, and we show numerically that it leads to strong scalability improvements compared to existing techniques when the rank of the density matrix is known to be small.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08775v1</guid>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tameem Adel, Abhishek Agarwal, St\'ephane Chr\'etien, Estelle Massart, Danila Mokeev, Ivan Rungger, Andrew Thompson</dc:creator>
    </item>
    <item>
      <title>Inference for Multiple Change-points in Piecewise Locally Stationary Time Series</title>
      <link>https://arxiv.org/abs/2601.07400</link>
      <description>arXiv:2601.07400v1 Announce Type: cross 
Abstract: Change-point detection and locally stationary time series modeling are two major approaches for the analysis of non-stationary data. The former aims to identify stationary phases by detecting abrupt changes in the dynamics of a time series model, while the latter employs (locally) time-varying models to describe smooth changes in dependence structure of a time series. However, in some applications, abrupt and smooth changes can co-exist, and neither of the two approaches alone can model the data adequately. In this paper, we propose a novel likelihood-based procedure for the inference of multiple change-points in locally stationary time series. In contrast to traditional change-point analysis where an abrupt change occurs in a real-valued parameter, a change in locally stationary time series occurs in a parameter curve, and can be classified as a jump or a kink depending on whether the curve is discontinuous or not. We show that the proposed method can consistently estimate the number, locations, and the types of change-points. Two different asymptotic distributions corresponding respectively to jump and kink estimators are also established.Extensive simulation studies and a real data application to financial time series are provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07400v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wai Leong Ng, Xinyi Tang, Mun Lau Cheung, Jiacheng Gao, Chun Yip Yau, Holger Dette</dc:creator>
    </item>
    <item>
      <title>Likelihood ratio for a binary Bayesian classifier under a noise-exclusion model</title>
      <link>https://arxiv.org/abs/2601.07982</link>
      <description>arXiv:2601.07982v1 Announce Type: cross 
Abstract: We develop a new statistical ideal observer model that performs holistic visual search (or gist) processing in part by placing thresholds on minimum extractable image features. In this model, the ideal observer reduces the number of free parameters thereby shrinking down the system. The applications of this novel framework is in medical image perception (for optimizing imaging systems and algorithms), computer vision, benchmarking performance and enabling feature selection/evaluations. Other applications are in target detection and recognition in defense/security as well as evaluating sensors and detectors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07982v1</guid>
      <category>cs.CV</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Howard C. Gifford</dc:creator>
    </item>
    <item>
      <title>Kantorovich Distance via Spanning Trees: Properties and Algorithms</title>
      <link>https://arxiv.org/abs/2601.08396</link>
      <description>arXiv:2601.08396v1 Announce Type: cross 
Abstract: We study optimal transport between probability measures supported on the same finite metric space, where the ground cost is a distance induced by a weighted connected graph. Building on recent work showing that the resulting Kantorovich distance can be expressed as a minimization problem over the set of spanning trees of this underlying graph, we investigate the implications of this reformulation on the construction of an optimal transport plan and a dual potential based on the solution of such an optimization problem. In this setting, we derive an explicit formula for the Kantorovich potential in terms of the imbalanced cumulative mass (a generalization of the cumulative distribution in R) along an optimal spanning tree solving such a minimization problem, under a weak non-degeneracy condition on the pair of measures that guarantees the uniqueness of a dual potential. Our second contribution establishes the existence of an optimal transport plan that can be computed efficiently by a dynamic programming procedure once an optimal spanning tree is known. Finally, we propose a stochastic algorithm based on simulated annealing on the space of spanning trees to compute such an optimal spanning tree. Numerical experiments illustrate the theoretical results and demonstrate the practical relevance of the proposed approach for optimal transport on finite metric spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08396v1</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>J\'er\'emie Bigot, Luis Fredes</dc:creator>
    </item>
    <item>
      <title>Beta distribution and associated Stirling numbers of the second kind</title>
      <link>https://arxiv.org/abs/2601.08453</link>
      <description>arXiv:2601.08453v1 Announce Type: cross 
Abstract: This article gives a formula for associated Stirling numbers of the second kind based on the moment of a sum of independent random variables having a beta distribution. From this formula we deduce, using probabilistic approaches, lower and upper bounds for these numbers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08453v1</guid>
      <category>math.PR</category>
      <category>math.CO</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.37190/0208-4147.00156</arxiv:DOI>
      <arxiv:journal_reference>Probability and Mathematical Statistics, 2024, Vol. 44, Fasc. 1, 119--132</arxiv:journal_reference>
      <dc:creator>Jakub Gismatullin, Patrick Tardivel</dc:creator>
    </item>
    <item>
      <title>Sample Complexity of Composite Quantum Hypothesis Testing</title>
      <link>https://arxiv.org/abs/2601.08588</link>
      <description>arXiv:2601.08588v1 Announce Type: cross 
Abstract: This paper investigates symmetric composite binary quantum hypothesis testing (QHT), where the goal is to determine which of two uncertainty sets contains an unknown quantum state. While asymptotic error exponents for this problem are well-studied, the finite-sample regime remains poorly understood. We bridge this gap by characterizing the sample complexity -- the minimum number of state copies required to achieve a target error level. Specifically, we derive lower bounds that generalize the sample complexity of simple QHT and introduce new upper bounds for various uncertainty sets, including of both finite and infinite cardinalities. Notably, our upper and lower bounds match up to universal constants, providing a tight characterization of the sample complexity. Finally, we extend our analysis to the differentially private setting, establishing the sample complexity for privacy-preserving composite QHT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08588v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jacob Paul Simpson, Efstratios Palias, Sharu Theresa Jose</dc:creator>
    </item>
    <item>
      <title>Permutation Inference under Multi-way Clustering and Missing Data</title>
      <link>https://arxiv.org/abs/2601.08610</link>
      <description>arXiv:2601.08610v1 Announce Type: cross 
Abstract: Econometric applications with multi-way clustering often feature a small number of effective clusters or heavy-tailed data, making standard cluster-robust and bootstrap inference unreliable in finite samples. In this paper, we develop a framework for finite-sample valid permutation inference in linear regression with multi-way clustering under an assumption of conditional exchangeability of the errors. Our assumption is closely related to the notion of separate exchangeability studied in earlier work, but can be more realistic in many economic settings as it imposes minimal restrictions on the covariate distribution. We construct permutation tests of significance that are valid in finite samples and establish theoretical power guarantees, in contrast to existing methods that are justified only asymptotically. We also extend our methodology to settings with missing data and derive power results that reveal phase transitions in detectability. Through simulation studies, we demonstrate that the proposed tests maintain correct size and competitive power, while standard cluster-robust and bootstrap procedures can exhibit substantial size distortions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08610v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wenxuan Guo, Panos Toulis, Yuhao Wang</dc:creator>
    </item>
    <item>
      <title>Semiparametric Efficient Data Integration Using the Dual-Frame Sampling Framework</title>
      <link>https://arxiv.org/abs/2601.08707</link>
      <description>arXiv:2601.08707v1 Announce Type: cross 
Abstract: Integrating probability and non-probability samples is increasingly important, yet unknown sampling mechanisms in non-probability sources complicate identification and efficient estimation. We develop semiparametric theory for dual-frame data integration and propose two complementary estimators. The first models the non-probability inclusion probability parametrically and attains the semiparametric efficiency bound. We introduce an identifiability condition based on strong monotonicity that identifies sampling-model parameters without instrumental variables, even under informative (non-ignorable) selection, using auxiliary information from the probability sample; it remains valid without record linkage between samples. The second estimator, motivated by a two-stage sampling approximation, avoids explicit modeling of the non-probability mechanism; though not fully efficient, it is efficient within a restricted augmentation class and is robust to misspecification. Simulations and an application to the Culture and Community in a Time of Crisis public simulation dataset show efficiency gains under correct specification and stable performance under misspecification and weak identification. Methods are implemented in the R package \texttt{dfSEDI}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08707v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kosuke Morikawa, Jae Kwang Kim</dc:creator>
    </item>
    <item>
      <title>The radius of statistical efficiency</title>
      <link>https://arxiv.org/abs/2405.09676</link>
      <description>arXiv:2405.09676v2 Announce Type: replace 
Abstract: Classical results in asymptotic statistics show that the Fisher information matrix controls the difficulty of estimating a statistical model from observed data. In this work, we introduce a companion measure of robustness of an estimation problem: the radius of statistical efficiency (RSE) is the size of the smallest perturbation to the problem data that renders the Fisher information matrix singular. We compute RSE up to numerical constants for a variety of testbed problems, including principal component analysis, generalized linear models, phase retrieval, bilinear sensing, and matrix completion. Interestingly, we observe a precise reciprocal relationship between RSE and the intrinsic complexity/sensitivity of the problem instance, paralleling the classical Eckart-Young theorem in numerical analysis. To establish our results, we develop theory for spectral functions of measures that extends well-known results from matrix analysis and eigenvalue optimization$-$a contribution that may be of interest beyond our immediate findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.09676v2</guid>
      <category>math.ST</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joshua Cutler, Mateo D\'iaz, Dmitriy Drusvyatskiy</dc:creator>
    </item>
    <item>
      <title>Berry-Esseen theorems for the asymptotic normality of incomplete U-statistics with Bernoulli sampling</title>
      <link>https://arxiv.org/abs/2406.05394</link>
      <description>arXiv:2406.05394v4 Announce Type: replace 
Abstract: There has been a resurgence of interest in incomplete U-statistics that only sum over a subset of kernel evaluations, due to their computational efficiency and asymptotic normality which can be leveraged to quantify the uncertainty of ensemble predictions in machine learning. In this paper, we study the weak convergences to normality of one such construction, the incomplete U-statistic with Bernoulli sampling, under three different regimes on the relative sizes of the raw sample and the computational budget. Under minimalistic moment assumptions, we establish accompanying Berry-Esseen bounds with the natural rates that characterize the accuracy of these normal approximations. The key ingredients in our proofs include a variable censoring technique and a methodology for establishing Berry-Esseen bounds for the so-called Studentized nonlinear statistics recently formalized in the Stein's method literature, as well as an exponential lower tail bound for non-negative kernel U-statistics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05394v4</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dennis Leung</dc:creator>
    </item>
    <item>
      <title>Sequential Eigenvalue Statistics for Change-Point Detection in Covariance Matrices</title>
      <link>https://arxiv.org/abs/2409.15588</link>
      <description>arXiv:2409.15588v2 Announce Type: replace 
Abstract: Testing for change points in sequences of covariance matrices is an important and equally challenging problem in statistical methodology with applications in various fields. Motivated by the observation that even in cases where the ratio between dimension and sample size is as small as $0.05$, tests based on a fixed-dimension asymptotics do not keep their preassigned level, we propose to derive critical values of test statistics using an asymptotic regime where the dimension diverges at the same rate as the sample size.
  This paper introduces a novel and well-founded statistical methodology for detecting change points in a sequence of moderately dimensional covariance matrices. Our approach utilizes a min-type statistic based on a sequential process of likelihood ratio statistics. This is used to construct a test for the hypothesis of the existence of a change point with a corresponding estimator for its location. We provide theoretical guarantees by thoroughly analyzing the asymptotic properties of the sequential process of likelihood ratio statistics. In particular, we prove weak convergence towards a Gaussian process under the null hypothesis of no change. To identify the challenging dependency structure between consecutive test statistics, we employ tools from random matrix theory and stochastic processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.15588v2</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nina D\"ornemann, Holger Dette</dc:creator>
    </item>
    <item>
      <title>A new measure of dependence: Integrated $R^2$</title>
      <link>https://arxiv.org/abs/2505.18146</link>
      <description>arXiv:2505.18146v5 Announce Type: replace 
Abstract: We introduce a novel measure of dependence that captures the extent to which a random variable $Y$ is determined by a random vector $X$. The measure equals zero precisely when $Y$ and $X$ are independent, and it attains one exactly when $Y$ is almost surely a measurable function of $X$. We further extend this framework to define a measure of conditional dependence between $Y$ and $X$ given $Z$. We propose a simple and interpretable estimator with computational complexity comparable to classical correlation coefficients, including those of Pearson, Spearman, and Chatterjee. Leveraging this dependence measure, we develop a tuning-free, model-agnostic variable selection procedure and establish its consistency under appropriate sparsity conditions. Extensive experiments on synthetic and real datasets highlight the strong empirical performance of our methodology and demonstrate substantial gains over existing approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18146v5</guid>
      <category>math.ST</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mona Azadkia, Pouya Roudaki</dc:creator>
    </item>
    <item>
      <title>Statistical learning on measures: an application to persistence diagrams</title>
      <link>https://arxiv.org/abs/2303.08456</link>
      <description>arXiv:2303.08456v3 Announce Type: replace-cross 
Abstract: We consider a binary supervised learning classification problem where instead of having data in a finite-dimensional Euclidean space, we observe measures on a compact space $\mathcal{X}$. Formally, we observe data $D_N = (\mu_1, Y_1), \ldots, (\mu_N, Y_N)$ where $\mu_i$ is a measure on $\mathcal{X}$ and $Y_i$ is a label in $\{0, 1\}$. Given a set $\mathcal{F}$ of base-classifiers on $\mathcal{X}$, we build corresponding classifiers in the space of measures. We provide upper and lower bounds on the Rademacher complexity of this new class of classifiers that can be expressed simply in terms of corresponding quantities for the class $\mathcal{F}$. If the measures $\mu_i$ are uniform over a finite set, this classification task boils down to a multi-instance learning problem. However, our approach allows more flexibility and diversity in the input data we can deal with. While such a framework has many possible applications, this work strongly emphasizes on classifying data via topological descriptors called persistence diagrams. These objects are discrete measures on $\mathbb{R}^2$, where the coordinates of each point correspond to the range of scales at which a topological feature exists. We will present several classifiers on measures and show how they can heuristically and theoretically enable a good classification performance in various settings in the case of persistence diagrams.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.08456v3</guid>
      <category>cs.CG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Olympio Hacquard (LMO, DATASHAPE), Gilles Blanchard (LMO, DATASHAPE), Cl\'ement Levrard (LPSM)</dc:creator>
    </item>
    <item>
      <title>The Conflict Graph Design: Estimating Causal Effects under Arbitrary Neighborhood Interference</title>
      <link>https://arxiv.org/abs/2411.10908</link>
      <description>arXiv:2411.10908v3 Announce Type: replace-cross 
Abstract: A fundamental problem in network experiments is selecting an appropriate experimental design in order to precisely estimate a given causal effect of interest. In this work, we propose the Conflict Graph Design, a general approach for constructing experiment designs under network interference with the goal of precisely estimating a pre-specified causal effect. A central aspect of our approach is the notion of a conflict graph, which captures the fundamental unobservability associated with the causal effect and the underlying network. In order to estimate effects, we propose a modified Horvitz--Thompson estimator. We show that its variance under the Conflict Graph Design is bounded as $O(\lambda(H) / n )$, where $\lambda(H)$ is the largest eigenvalue of the adjacency matrix of the conflict graph. These rates depend on both the underlying network and the particular causal effect under investigation. Not only does this yield the best known rates of estimation for several well-studied causal effects (e.g. the global and direct effects) but it also provides new methods for effects which have received less attention from the perspective of experiment design (e.g. spill-over effects). Finally, we construct conservative variance estimators which facilitate asymptotically valid confidence intervals for the causal effect of interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10908v3</guid>
      <category>stat.ME</category>
      <category>cs.DS</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vardis Kandiros, Charilaos Pipis, Constantinos Daskalakis, Christopher Harshaw</dc:creator>
    </item>
    <item>
      <title>Spike-timing-dependent Hebbian learning as noisy gradient descent</title>
      <link>https://arxiv.org/abs/2505.10272</link>
      <description>arXiv:2505.10272v3 Announce Type: replace-cross 
Abstract: Hebbian learning is a key principle underlying learning in biological neural networks. We relate a Hebbian spike-timing-dependent plasticity rule to noisy gradient descent with respect to a non-convex loss function on the probability simplex. Despite the constant injection of noise and the non-convexity of the underlying optimization problem, one can rigorously prove that the considered Hebbian learning dynamic identifies the presynaptic neuron with the highest activity and that the convergence is exponentially fast in the number of iterations. This is non-standard and surprising as typically noisy gradient descent with fixed noise level only converges to a stationary regime where the noise causes the dynamic to fluctuate around a minimiser.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.10272v3</guid>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Niklas Dexheimer, Sascha Gaudlitz, Johannes Schmidt-Hieber</dc:creator>
    </item>
    <item>
      <title>Nonparametric inference for ratios of densities via uniformly valid and powerful permutation tests</title>
      <link>https://arxiv.org/abs/2505.24529</link>
      <description>arXiv:2505.24529v2 Announce Type: replace-cross 
Abstract: We propose the density ratio permutation test, a hypothesis test that assesses whether the ratio between two densities is proportional to a known function based on independent samples from each distribution. The test uses an efficient Markov Chain Monte Carlo scheme to draw weighted permutations of the pooled data, yielding exchangeable samples and finite sample validity. For power, if the statistic is an integral probability metric, our procedure is consistent under mild assumptions on the defining function class; specializing to a reproducing kernel Hilbert space, we introduce the shifted maximum mean discrepancy and prove minimax optimality of our test when a normalized difference between the densities lies in a Sobolev ball. We extend to the case of an unknown density ratio by estimating it on an independent training sample and derive type~I error bounds in terms of the estimation error as well as power results. This allows adapting our method to conditional two sample testing, making it a versatile tool for assessing covariate-shift and related assumptions, which frequently arise in transfer learning and causal inference. Finally, we validate our theoretical findings through experiments on both simulated and real-world datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.24529v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alberto Bordino, Thomas B. Berrett</dc:creator>
    </item>
  </channel>
</rss>
