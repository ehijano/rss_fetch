<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.FL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.FL</link>
    <description>cs.FL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.FL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 23 Oct 2024 02:08:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A positional $\mathbf{\Pi}^0_3$-complete objective</title>
      <link>https://arxiv.org/abs/2410.14688</link>
      <description>arXiv:2410.14688v1 Announce Type: cross 
Abstract: We study zero-sum turn-based games on graphs. In this note, we show the existence of a game objective that is $\mathbf{\Pi}^0_3$-complete for the Borel hierarchy and that is positional, i.e., for which positional strategies suffice for the first player to win over arenas of arbitrary cardinality. To the best of our knowledge, this is the first known such objective; all previously known positional objectives are in $\mathbf{\Sigma}^0_3$. The objective in question is a qualitative variant of the well-studied total-payoff objective, where the goal is to maximise the sum of weights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14688v1</guid>
      <category>cs.CC</category>
      <category>cs.FL</category>
      <category>cs.GT</category>
      <category>cs.LO</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Antonio Casares, Pierre Ohlmann, Pierre Vandenhove</dc:creator>
    </item>
    <item>
      <title>Joint Verification and Refinement of Language Models for Safety-Constrained Planning</title>
      <link>https://arxiv.org/abs/2410.14865</link>
      <description>arXiv:2410.14865v1 Announce Type: cross 
Abstract: Although pre-trained language models can generate executable plans (e.g., programmatic policies) for solving robot tasks, the generated plans may violate task-relevant logical specifications due to the models' black-box nature. A significant gap remains between the language models' outputs and verifiable executions of plans. We develop a method to generate executable plans and formally verify them against task-relevant safety specifications. Given a high-level task description in natural language, the proposed method queries a language model to generate plans in the form of executable robot programs. It then converts the generated plan into an automaton-based representation, allowing formal verification of the automaton against the specifications. We prove that given a set of verified plans, the composition of these plans also satisfies the safety specifications. This proof ensures the safety of complex, multi-component plans, obviating the computation complexity of verifying the composed plan. We then propose an automated fine-tuning process that refines the language model to generate specification-compliant plans without the need for human labeling. The empirical results show a 30 percent improvement in the probability of generating plans that meet task specifications after fine-tuning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14865v1</guid>
      <category>cs.AI</category>
      <category>cs.FL</category>
      <category>cs.RO</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yunhao Yang, William Ward, Zichao Hu, Joydeep Biswas, Ufuk Topcu</dc:creator>
    </item>
    <item>
      <title>Automated Formal Verification of a Highly-Configurable Register Generator</title>
      <link>https://arxiv.org/abs/2410.15479</link>
      <description>arXiv:2410.15479v1 Announce Type: cross 
Abstract: Registers in IP blocks of an SoC perform a variety of functions, most of which are essential to the SoC operation. The complexity of register implementation is relatively low when compared with other design blocks. However, the extensive number of registers, combined with the various potential functions they can perform, necessitates considerable effort during implementation, especially when using a manual approach. Therefore, an in-house register generator was proposed by the design team to reduce the manual effort in the register implementation. This in-house register generator supports not only the generation of register blocks but also bus-related blocks. Meanwhile, to support various requirements, 41 generation options are used for this generator, which is highly-configurable. From the verification perspective, it is infeasible to achieve complete verification results with a manual approach for all options combinations. Besides the complexity caused by configurability, the register verification is still time-consuming due to two widely recognized issues: the unreliability of specifications and the complexity arising from diverse access policies. To deal with the highly-configurable feature and both register verification issues, we propose an automated register verification framework using formal methods following the Model Driven Architecture (MDA). Based on our results, the human effort in the register verification can be reduced significantly, from 20Person-Day (20PD) to 3PD for each configuration, and 100\% code coverage can be achieved. During the project execution, eleven new design bugs were found with the proposed verification framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15479v1</guid>
      <category>cs.AR</category>
      <category>cs.FL</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuhang Zhang, Bryan Olmos, Basavaraj Naik</dc:creator>
    </item>
    <item>
      <title>Tokenization as Finite-State Transduction</title>
      <link>https://arxiv.org/abs/2410.15696</link>
      <description>arXiv:2410.15696v1 Announce Type: cross 
Abstract: Tokenization is the first step in modern neural language model pipelines where an input text is converted to a sequence of subword tokens. We introduce from first principles a finite-state transduction framework which can efficiently encode all possible tokenizations of a regular language. We then constructively show that Byte-Pair Encoding (BPE) and MaxMatch (WordPiece), two popular tokenization schemes, fit within this framework. For BPE, this is particularly surprising given its resemblance to context-free grammar and the fact that it does not tokenize strings from left to right.
  An application of this is to guided generation, where the outputs of a language model are constrained to match some pattern. Here, patterns are encoded at the character level, which creates a mismatch between the constraints and the model's subword vocabulary. While past work has focused only on constraining outputs without regard to the underlying tokenization algorithm, our framework allows for simultaneously constraining the model outputs to match a specified pattern while also adhering to the underlying tokenizer's canonical tokenization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15696v1</guid>
      <category>cs.CL</category>
      <category>cs.FL</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marco Cognetta, Naoaki Okazaki</dc:creator>
    </item>
    <item>
      <title>CoT-TL: Low-Resource Temporal Knowledge Representation of Planning Instructions Using Chain-of-Thought Reasoning</title>
      <link>https://arxiv.org/abs/2410.16207</link>
      <description>arXiv:2410.16207v1 Announce Type: cross 
Abstract: Autonomous agents often face the challenge of interpreting uncertain natural language instructions for planning tasks. Representing these instructions as Linear Temporal Logic (LTL) enables planners to synthesize actionable plans. We introduce CoT-TL, a data-efficient in-context learning framework for translating natural language specifications into LTL representations. CoT-TL addresses the limitations of large language models, which typically rely on extensive fine-tuning data, by extending chain-of-thought reasoning and semantic roles to align with the requirements of formal logic creation. This approach enhances the transparency and rationale behind LTL generation, fostering user trust. CoT-TL achieves state-of-the-art accuracy across three diverse datasets in low-data scenarios, outperforming existing methods without fine-tuning or intermediate translations. To improve reliability and minimize hallucinations, we incorporate model checking to validate the syntax of the generated LTL output. We further demonstrate CoT-TL's effectiveness through ablation studies and evaluations on unseen LTL structures and formulas in a new dataset. Finally, we validate CoT-TL's practicality by integrating it into a QuadCopter for multi-step drone planning based on natural language instructions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16207v1</guid>
      <category>cs.RO</category>
      <category>cs.CL</category>
      <category>cs.FL</category>
      <category>cs.LG</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kumar Manas, Stefan Zwicklbauer, Adrian Paschke</dc:creator>
    </item>
  </channel>
</rss>
