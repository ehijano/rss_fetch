<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 29 Jan 2026 05:00:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Randomized Feasibility Methods for Constrained Optimization with Adaptive Step Sizes</title>
      <link>https://arxiv.org/abs/2601.20076</link>
      <description>arXiv:2601.20076v1 Announce Type: new 
Abstract: We consider minimizing an objective function subject to constraints defined by the intersection of lower-level sets of convex functions. We study two cases: (i) strongly convex and Lipschitz-smooth objective function and (ii) convex but possibly nonsmooth objective function. To deal with the constraints that are not easy to project on, we use a randomized feasibility algorithm with Polyak steps and a random number of sampled constraints per iteration, while taking (sub)gradient steps to minimize the objective function. For case (i), we prove linear convergence in expectation of the objective function values to any prescribed tolerance using an adaptive stepsize. For case (ii), we develop a fully problem parameter-free and adaptive stepsize scheme that yields an $O(1/\sqrt{T})$ worst-case rate in expectation. The infeasibility of the iterates decreases geometrically with the number of feasibility updates almost surely, while for the averaged iterates, we establish an expected lower bound on the function values relative to the optimal value that depends on the distribution for the random number of sampled constraints. For certain choices of sample-size growth, optimal rates are achieved. Finally, simulations on a Quadratically Constrained Quadratic Programming (QCQP) problem and Support Vector Machines (SVM) demonstrate the computational efficiency of our algorithm compared to other state-of-the-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20076v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abhishek Chakraborty, Angelia Nedi\'c</dc:creator>
    </item>
    <item>
      <title>A Fokker-Planck Framework for Control of Epidemics</title>
      <link>https://arxiv.org/abs/2601.20181</link>
      <description>arXiv:2601.20181v1 Announce Type: new 
Abstract: We present a control framework for stochastic compartmental models in epidemiology. In this framework, rather than directly controlling the stochastic system, we perform optimal control of an associated Fokker-Planck equation, with the goal of steering the distribution of possible solutions of the stochastic system to some desirable state. In particular, this allows for robust control mechanism with uncertainty not only in the dynamics, but also in the initial data. We formulate and fully analyze a partial differential equation constrained optimization problem, including a proof of existence of optimal controls via analysis of the control-to-state map, and a characterization of optimal controls via the Pontryagin minimum principle. We describe the application of the sequential quadratic Hamiltonian method to our problem, which provides numerical approximations of optimal control maps. We demonstrate our method using a minimal stochastic susceptible-infected-recovered model with different choices of cost functionals that represent different policy-maker concerns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20181v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christian Parkinson, Souvik Roy</dc:creator>
    </item>
    <item>
      <title>Improved Global Landscape Guarantees for Low-rank Factorization in Synchronization</title>
      <link>https://arxiv.org/abs/2601.20292</link>
      <description>arXiv:2601.20292v1 Announce Type: new 
Abstract: The orthogonal group synchronization problem, which aims to recover a set of $d \times d$ orthogonal matrices from their pairwise noisy products, plays a fundamental role in signal processing, computer vision, and network analysis. In recent years, numerous optimization techniques, such as semidefinite relaxation (SDR) and low-rank (Burer-Monteiro) factorization, have been proposed to address this problem and their theoretical guarantees have been extensively studied. While SDR is provably powerful and exact in recovering the least-squares estimator under certain mild conditions, it is not scalable. In contrast, the low-rank factorization is highly efficient but nonconvex, meaning its iterates may get trapped in local minima. To close the gap, we analyze the low-rank approach and focus on understanding when the associated nonconvex optimization landscape is benign, i.e., free of spurious local minima. Recent works suggest that the benignness depends on the condition number of the Hessian at the global minimizer, but it remains unclear whether sharp guarantees can be achieved. In this work, we consider the low-rank approach which corresponds to an optimization problem over the Stiefel manifold ${\rm St}(p,d)^{\otimes n}$. By formulating the landscape analysis into another convex optimization problem, we provide a unified characterization of the optimization landscape for all parameter pairs $(p,d)$ with $p \geq d+2$ for $d\geq 1$ and $p = d+1$ for $1\leq d\leq 3$ which gives a much improved dependence on the condition number of the Hessian. Our results recover the known sharp state-of-the-art bound for $d=1$ which is extremely useful for characterizing the Kuramoto synchronization, and significantly improved the guarantees for the general case $d \geq 2$ with $p \geq d+2$ over the existing results. The theoretical results are versatile and applicable to a wide range of examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20292v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuyang Ling</dc:creator>
    </item>
    <item>
      <title>A novel neural network with predefined-time stability for solving generalized monotone inclusion problems with applications</title>
      <link>https://arxiv.org/abs/2601.20338</link>
      <description>arXiv:2601.20338v1 Announce Type: new 
Abstract: We propose a novel dynamical framework for solving inclusion
  problems of the form \(0 \in F(x) + G(x)\) in Hilbert spaces, where \(F\) is a
  maximal set-valued operator and \(G\) is a single-valued mapping. The analysis is
  conducted under a generalized monotonicity assumption, which relaxes the
  classical monotonicity conditions commonly imposed in the literature and thereby
  extends the applicability of the proposed approach.
  Under mild conditions on the system parameters, we establish both fixed-time and
  predefined-time stability of the resulting dynamical system. The fixed-time
  stability guarantees a uniform upper bound on the settling time that is
  independent of the initial condition, whereas the predefined-time stability
  framework allows the system parameters to be selected \emph{a priori} in order
  to ensure convergence within a user-specified time horizon.
  Moreover, we investigate an explicit forward Euler discretization of the
  continuous-time dynamics, leading to a novel forward--backward iterative
  algorithm. A rigorous convergence analysis of the resulting discrete scheme is
  provided. Finally, the effectiveness and versatility of the proposed method are
  illustrated through several classes of problems, including constrained
  optimization problems, mixed variational inequalities, and variational
  inequalities, together with numerical experiments that corroborate the
  theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20338v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nam Van Tran</dc:creator>
    </item>
    <item>
      <title>Data-Driven Structured Control for Continuous-Time LTI Systems</title>
      <link>https://arxiv.org/abs/2601.20340</link>
      <description>arXiv:2601.20340v1 Announce Type: new 
Abstract: This paper addresses the data-driven structured controller design problem for continuous-time linear time-invariant (LTI) systems. We consider three control objectives, including stabilization, $H_2$ performance, and $H_\infty$ performance. Using the collected data, we construct a minimal matrix ellipsoid that contains all admissible system matrices. We propose some linearization techniques that enable us to incorporate the structural constraint on the controller, which motivates an iterative algorithm for each control objective. Finally, we provide some numerical examples to demonstrate the effectiveness of the proposed methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20340v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaohua Yang, Yuxing Zhong, Ling Shi</dc:creator>
    </item>
    <item>
      <title>Decentralized Stochastic Constrained Optimization via Prox-Linearization</title>
      <link>https://arxiv.org/abs/2601.20345</link>
      <description>arXiv:2601.20345v1 Announce Type: new 
Abstract: This paper studies consensus-based decentralized stochastic optimization for minimizing possibly non-convex expected objectives with convex non-smooth regularizers and nonlinear functional inequality constraints. We reformulate the constrained problem using the exact-penalty model and develop two algorithms that require only local stochastic gradients and first-order constraint information. The first method, Decentralized Stochastic Momentum-based Prox-Linear Algorithm (D-SMPL), combines constraint linearization with a prox-linear step, resulting in a linearly constrained quadratic subproblem per iteration. Building on this approach, we propose a successive convex approximation (SCA) variant, Decentralized SCA Momentum-based Prox-Linear (D-SCAMPL), which handles additional objective structure through strongly convex surrogate subproblems while still allowing infeasible initialization. Both methods incorporate recursive momentum-based gradient estimators and a consensus mechanism requiring only two communication rounds per iteration. Under standard smoothness and regularity assumptions, both algorithms achieve an oracle complexity of $\mathcal{O}(\epsilon^{-3/2})$, matching the optimal rate known for unconstrained centralized stochastic non-convex optimization. Numerical experiments on energy-optimal ocean trajectory planning corroborate the theory and demonstrate improved performance over existing decentralized baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20345v1</guid>
      <category>math.OC</category>
      <category>eess.SP</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shivangi Dubey Sharma, Basil M. Idrees, Lavish Arora, Ketan Rajawat</dc:creator>
    </item>
    <item>
      <title>Reinforcement Learning for Dividend Optimization in Partially Observed Regime-Switching Diffusion Model</title>
      <link>https://arxiv.org/abs/2601.20387</link>
      <description>arXiv:2601.20387v1 Announce Type: new 
Abstract: This paper studies the optimal dividend problem with a bounded payout rate in a partially observed regime-switching diffusion model, where, in practice, the market regime is unobserved and key model parameters are unknown. To address this partial-information setting, we propose a continuous-time reinforcement learning (RL) approach within an exploratory (entropy-regularized) stochastic control framework for discounted dividends under regime switching. The associated exploratory Hamilton-Jacobi-Bellman (HJB) system admits semi-analytical characterizations of the value function and the optimal exploratory dividend policy, determined by two unknown functions solving two ordinary differential equations (ODEs) together with positive real roots of the induced quadratic equations. Exploiting this structure, we introduce parametric families for both the value function and the policy, using low-degree polynomial approximations to the ODE solutions. We then develop an actor-critic RL algorithm to learn the optimal exploratory policy through interactions with the market environment: it performs belief-state filtering from observed data and iterates policy evaluation and policy improvement online to refine the policy. Numerical experiments demonstrate strong out-of-sample performance of the learned dividend policies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20387v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhongqin Gao, Yan Lv, Jingmin He</dc:creator>
    </item>
    <item>
      <title>Convergence Analysis of Randomized Subspace Normalized SGD under Heavy-Tailed Noise</title>
      <link>https://arxiv.org/abs/2601.20399</link>
      <description>arXiv:2601.20399v1 Announce Type: new 
Abstract: Randomized subspace methods reduce per-iteration cost; however, in nonconvex optimization, most analyses are expectation-based, and high-probability bounds remain scarce even under sub-Gaussian noise. We first prove that randomized subspace SGD (RS-SGD) admits a high-probability convergence bound under sub-Gaussian noise, achieving the same order of oracle complexity as prior in-expectation results. Motivated by the prevalence of heavy-tailed gradients in modern machine learning, we then propose randomized subspace normalized SGD (RS-NSGD), which integrates direction normalization into subspace updates. Assuming the noise has bounded $p$-th moments, we establish both in-expectation and high-probability convergence guarantees, and show that RS-NSGD can achieve better oracle complexity than full-dimensional normalized SGD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20399v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gaku Omiya, Pierre-Louis Poirion, Akiko Takeda</dc:creator>
    </item>
    <item>
      <title>Sufficiently Regularized Nonnegative Quartic Polynomials are Sum-of-Squares</title>
      <link>https://arxiv.org/abs/2601.20418</link>
      <description>arXiv:2601.20418v1 Announce Type: new 
Abstract: Hilbert's 17th problem famously established that not all nonnegative polynomials admit a sum-of-squares (SoS) representation. Hilbert also identified a few special classes in which nonnegativity and SoS are equivalent, such as univariate polynomials, quadratic polynomials, and bivariate quartic polynomials. In this paper, we extend this equivalence to several new subclasses of multivariate quartically regularized polynomials and characterize the NP-hardness boundary of these special-structure polynomials. Specifically, we consider the global optimization of multivariate symmetric cubic polynomials regularized by weighted quartic powers of the Euclidean norm. These special-structure polynomials arise as iterative subproblems in high-order tensor methods for nonconvex optimization problems. We consider shifting these polynomials by their global optimum so as to make them nonnegative, and show that for sufficiently large regularization parameters and under mild assumptions, these polynomials admit a sum-of-squares representation. We also identify several structured subclasses of quartically regularized cubic polynomials for which global optimality of the model implies that nonnegativity is certified by a sum-of-squares decomposition for all values of the regularization parameter, including quadratic-quartic polynomials and quartic polynomials containing a special cubic term that can be decomposed as the product of a quadratic norm and a linear form. We provide counterexamples based on quartic separable norms that demonstrate the crucial role of the Euclidean norm in these representations. Finally, we illustrate how these SoS-based certificates can be used for Taylor subproblems arising in high-order tensor methods for nonconvex optimization, with encouraging numerical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20418v1</guid>
      <category>math.OC</category>
      <category>math.AG</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Wenqi Zhu, Coralia Cartis</dc:creator>
    </item>
    <item>
      <title>Adaptive Conditional Gradient Sliding: Projection-Free and Line-Search-Free Acceleration</title>
      <link>https://arxiv.org/abs/2601.20443</link>
      <description>arXiv:2601.20443v1 Announce Type: new 
Abstract: We study convex optimization problems over a compact convex set where projections are expensive but a linear minimization oracle (LMO) is available. We propose the adaptive conditional gradient sliding method (AdCGS), a projection-free and line-search-free method that retains Nesterov's acceleration with adaptive stepsizes based on local Lipschitz estimates. AdCGS combines an accelerated outer scheme with an LMO-based inner routine. It reuses gradients across multiple LMO calls to reduce gradient evaluations, while controlling the subproblem inexactness via a prescribed accuracy level coupled with adaptive stepsizes. We prove accelerated convergence rates for convex objective functions matching those of projection-based accelerated methods, while requiring no projection oracle. For strongly convex objective functions, we further establish linear convergence without additional geometric assumptions on the constraint set, such as polytopes or strongly convex sets. Experiments on constrained $\ell_p$ regression, logistic regression with real-world datasets, and least-squares problems demonstrate improvements over both projection-free and projection-based baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20443v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shota Takahashi</dc:creator>
    </item>
    <item>
      <title>On controllability, observability and stabilizability of the heat equation on discrete graphs</title>
      <link>https://arxiv.org/abs/2601.20594</link>
      <description>arXiv:2601.20594v1 Announce Type: new 
Abstract: We consider linear control problems for the heat equation of the form $\dot f (t) = -Hf (t) + \mathbf{1}_D u (t)$, $f (0) \in \ell_2 (X,m)$, where $H$ is the weighted Laplacian on a discrete graph $(X,b,m)$, and where $D \subseteq X$ is relatively dense. We show cost-uniform $\alpha$-controllability by means of a weak observability estimate for the corresponding dual observation problem. We discuss optimality of our result as well as consequences on stabilizability properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20594v1</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Florentin M\"unch, Christian Seifert, Peter Stollmann, Martin Tautenhahn</dc:creator>
    </item>
    <item>
      <title>Drone-Aided Blood Collection Routing Problem: A Column Generation Approach</title>
      <link>https://arxiv.org/abs/2601.20693</link>
      <description>arXiv:2601.20693v1 Announce Type: new 
Abstract: Platelet extraction requires whole blood to be processed within six hours of donation. To meet this deadline, blood collection organizations must optimally route a fleet of vehicles to pick up blood units from donation sites and deliver them to a processing center. This paper introduces a drone-aided blood collection routing problem in which a fleet of trucks, each equipped with a drone, operates in a synchronized manner to collect blood units before their processing time limit expires. Each truck-drone tandem can perform multiple trips throughout the planning horizon, allowing donation sites to be visited repeatedly as new blood units become available over time. We formulate this problem as a mixed-integer linear program that jointly optimizes the routing of trucks and drones, pickup schedules, and timing decisions to maximize the total number of viable blood units collected. We also develop a column generation approach that decomposes the problem into a master problem to select the optimal set of truck-drone tours and a pricing subproblem, which is solved using a tailored memetic algorithm to generate promising new columns. Through a comprehensive computational study, we show the operational benefits of integrating drones into the blood collection system. In addition, we demonstrate the superior performance of the proposed algorithm over Gurobi and two metaheuristics from the literature, namely the hybrid genetic algorithm and the invasive weed optimization, in both the drone-aided and truck-only settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20693v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amirhossein Abbaszadeh, Hossein Hashemi Doulabi</dc:creator>
    </item>
    <item>
      <title>Adaptive Dimension Reduction for Overlapping Group Sparsity</title>
      <link>https://arxiv.org/abs/2601.20697</link>
      <description>arXiv:2601.20697v1 Announce Type: new 
Abstract: Typical dimension reduction techniques for nonoverlapping sparse optimization involve screening or sieving strategies based on a dual certificate derived from the first-order optimality condition, approximating the gradients or exploiting certain inherent low-dimensional structure of the sparse solution. In comparison, dimension reduction rules for overlapping group sparsity are generally less developed because the subgradient structure is more complex, making the link between sparsity pattern and the dual variable indirect due to the non-separability. In this work, we propose new dual certificates for overlapping group sparsity and a novel adaptive scheme for identifying the support of the overlapping group LASSO. We demonstrate how this scheme can be integrated into and significantly accelerate existing algorithms, including Primal-Dual splitting method, alternating direction method of multipliers and a recently developed variable projection scheme based on over-parameterization. We provide convergence analysis of the method and verify its practical effectiveness through experiments on standard datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20697v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yifan Bai, Clarice Poon, Jingwei Liang</dc:creator>
    </item>
    <item>
      <title>A penalty-interior point method combined with MADS for equality and inequality constrained optimization</title>
      <link>https://arxiv.org/abs/2601.20811</link>
      <description>arXiv:2601.20811v1 Announce Type: new 
Abstract: This work introduces MADS-PIP, an efficient framework that integrates a penalty-interior point strategy into the mesh adaptive direct search (MADS) algorithm for solving nonsmooth blackbox optimization problems with general inequality and equality constraints. Inequality constraints are partitioned into two subsets: one treated via a logarithmic barrier applied to an aggregated interior constraint violation, and the other handled through an exterior quadratic penalty. All equality constraints are treated by the exterior penalty. A merit function defines a sequence of unconstrained subproblems, which are solved approximately using MADS, while a carefully designed update rule drives the penalty-barrier parameter to zero. In the nonsmooth setting, we establish convergence results ensuring feasibility for general constraints as well as Clarke stationarity for inequality-constrained problems. Computational experiments on both analytical test sets and challenging blackbox problems demonstrate that the proposed MADS-PIP algorithm is competitive with, and often outperforms, MADS with the progressive barrier strategy, particularly in the presence of equality constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20811v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Charles Audet, Andrea Brilli, Youssef Diouane, S\'ebastien Le Digabel, Everton J. Silva, Christophe Tribes</dc:creator>
    </item>
    <item>
      <title>Model Risk Static-Hedging a Constrained Distributionally Robust Optimization approach</title>
      <link>https://arxiv.org/abs/2601.20139</link>
      <description>arXiv:2601.20139v1 Announce Type: cross 
Abstract: We investigate model risk and distributionally robust optimization (DRO) under marginal and martingale constraints. Building on our previous work, we address the previously open case of static hedging with second-period maturity vanilla options and hedging strategies involving a vanilla payoff. We also extend recent sensitivity results to settings where admissible models must satisfy a martingale coupling constraint. Our approach relies on a weak implicit function theorem argument to construct families of measures satisfying the prescribed constraints. We derive closed-form sensitivity formulas and characterize the corresponding hedging strategies when the underlying process is real-valued.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20139v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nathan Sauldubois</dc:creator>
    </item>
    <item>
      <title>Error estimates of $hp$-finite element method for elliptic optimal control problems with robin boundary</title>
      <link>https://arxiv.org/abs/2601.20145</link>
      <description>arXiv:2601.20145v1 Announce Type: cross 
Abstract: A priori and a posteriori error analysis of $hp$ finite element method for elliptic control problem with Robin boundary condition and boundary observation are presented. are presented. Through the Cl\'ement-type approach and the construction of an auxiliary system, we derived a priori error estimates for the elliptic optimal control problem. Residual-based a posteriori error estimates are derived based on the well-known Scott-Zhang-type quasi-interpolation and coupled state-control approximations, thus establishing an a posteriori error estimator for the $hp$ finite element method. The numerical example demonstrates the accuracy of error estimation for the elliptic optimal control problems with Robin boundary.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20145v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xingyuan Lin, Xiuxiu Lin, Xuesong Chen</dc:creator>
    </item>
    <item>
      <title>SA-PEF: Step-Ahead Partial Error Feedback for Efficient Federated Learning</title>
      <link>https://arxiv.org/abs/2601.20738</link>
      <description>arXiv:2601.20738v1 Announce Type: cross 
Abstract: Biased gradient compression with error feedback (EF) reduces communication in federated learning (FL), but under non-IID data, the residual error can decay slowly, causing gradient mismatch and stalled progress in the early rounds. We propose step-ahead partial error feedback (SA-PEF), which integrates step-ahead (SA) correction with partial error feedback (PEF). SA-PEF recovers EF when the step-ahead coefficient $\alpha=0$ and step-ahead EF (SAEF) when $\alpha=1$. For non-convex objectives and $\delta$-contractive compressors, we establish a second-moment bound and a residual recursion that guarantee convergence to stationarity under heterogeneous data and partial client participation. The resulting rates match standard non-convex Fed-SGD guarantees up to constant factors, achieving $O((\eta,\eta_0TR)^{-1})$ convergence to a variance/heterogeneity floor with a fixed inner step size. Our analysis reveals a step-ahead-controlled residual contraction $\rho_r$ that explains the observed acceleration in the early training phase. To balance SAEF's rapid warm-up with EF's long-term stability, we select $\alpha$ near its theory-predicted optimum. Experiments across diverse architectures and datasets show that SA-PEF consistently reaches target accuracy faster than EF.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20738v1</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dawit Kiros Redie, Reza Arablouei, Stefan Werner</dc:creator>
    </item>
    <item>
      <title>Equitable Routing--Rethinking the Multiple Traveling Salesman Problem</title>
      <link>https://arxiv.org/abs/2404.08157</link>
      <description>arXiv:2404.08157v5 Announce Type: replace 
Abstract: The Multiple Traveling Salesman Problem (MTSP) extends the traveling salesman problem by assigning multiple salesmen to visit a set of targets from a common depot, with each target visited exactly once while minimizing total tour length. A common variant, the min-max MTSP, focuses on workload balance by minimizing the longest tour, but it is difficult to solve optimally due to weak linear relaxation bounds. This paper introduces two new parametric fairness-driven variants of the MTSP: the $\varepsilon$-Fair-MTSP and the $\Delta$-Fair-MTSP, which promote equitable distribution of tour lengths while controlling overall cost. The $\varepsilon$-Fair-MTSP is formulated as a mixed-integer second-order cone program, while the $\Delta$-Fair-MTSP is modeled as a mixed-integer linear program. We develop algorithms that guarantee global optimality for both formulations. Computational experiments on benchmark instances and real-world applications, including electric vehicle fleet routing, demonstrate their effectiveness. Furthermore, we show that the algorithms presented for the fairness-constrained MTSP variants can be used to obtain the pareto-front of a bi-objective optimization problem where one objective focuses on minimizing the total tour length and the other focuses on balancing the tour lengths of the individual tours. Overall, these fairness-constrained MTSP variants provide a practical and flexible alternative to the min-max MTSP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08157v5</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abhay Singh Bhadoriya, Deepjyoti Deka, Kaarthik Sundar</dc:creator>
    </item>
    <item>
      <title>Constrained Optimization From a Control Perspective via Feedback Linearization</title>
      <link>https://arxiv.org/abs/2503.12665</link>
      <description>arXiv:2503.12665v3 Announce Type: replace 
Abstract: Tools from control and dynamical systems have proven valuable for analyzing and developing optimization methods. In this paper, we establish rigorous theoretical foundations for using feedback linearization (FL) -- a well-established nonlinear control technique -- to solve constrained optimization problems. For equality-constrained optimization, we establish global convergence rates to first-order Karush-Kuhn-Tucker (KKT) points and uncover the close connection between the FL method and the Sequential Quadratic Programming (SQP) algorithm. Building on this relationship, we extend the FL approach to handle inequality-constrained problems. Furthermore, we introduce a momentum-accelerated feedback linearization algorithm and provide a rigorous convergence guarantee.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.12665v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Runyu Zhang, Arvind Raghunathan, Jeff Shamma, Na Li</dc:creator>
    </item>
    <item>
      <title>A Partially Derivative-Free Proximal Method for Composite Multiobjective Optimization in the H\"older Setting</title>
      <link>https://arxiv.org/abs/2508.20071</link>
      <description>arXiv:2508.20071v2 Announce Type: replace 
Abstract: This paper presents an algorithm for solving multiobjective optimization problems involving composite functions, where we minimize a quadratic model that approximates $F(x) - F(x^k)$ and that can be derivative-free. We establish theoretical assumptions about the component functions of the composition and provide comprehensive convergence and complexity analysis. Specifically, we prove that the proposed method converges to a weakly $\varepsilon$-approximate Pareto point in at most $\mathcal{O}\left(\varepsilon^{-\frac{\beta+1}{\beta}}\right)$ iterations, where $\beta$ denotes the H\"{o}lder exponent of the gradient. The algorithm incorporates gradient approximations and a scaling matrix $B_k$ to achieve an optimal balance between computational accuracy and efficiency. Numerical experiments on a collection of benchmark problems are presented, illustrating the practical behavior of the proposed approach and its competitiveness with existing composite algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.20071v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>V. S. Amaral, P. B. Assun\c{c}\~ao, D. R. Souza</dc:creator>
    </item>
    <item>
      <title>Optimal Dividend Control with Transaction Costs under Exponential Parisian Ruin for a Refracted Levy Risk Model</title>
      <link>https://arxiv.org/abs/2509.03068</link>
      <description>arXiv:2509.03068v2 Announce Type: replace 
Abstract: This paper concerns an optimal impulse control problem associated with a refracted L\'{e}vy process, involving the reduction of reserves to a predetermined level whenever they exceed a specified threshold. The ruin time is determined by Parisian exponential delays and limited by a lower ultimate bankrupt barrier. We initially obtained the necessary and sufficient conditions for the value function and the optimal impulse control policy. Given a candidate for the optimal strategy, the corresponding expected discounted dividend function is subsequently formulated in terms of the Parisian refracted scale function, which is employed to measure the expected discounted utility of the impulse control. Then, the optimality of the proposed impulse control is verified using the HJB inequalities, and a monotonicity-based criterion is established to identify the admissible region of optimal thresholds, which serves as the basis for the numerical computation of their optimal levels. Finally, we present applications and numerical examples related to Brownian risk process and Cram\'{e}r-Lundberg process with exponential claims, demonstrating the uniqueness of the optimal impulse strategy and exploring its sensitivity to parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03068v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhongqin Gao, Yan Lv, Jingmin He</dc:creator>
    </item>
    <item>
      <title>Cyber Risk Management and Mitigation via Controlled Stochastic SIS Dynamics: An Optimal Control Approach</title>
      <link>https://arxiv.org/abs/2509.23116</link>
      <description>arXiv:2509.23116v2 Announce Type: replace 
Abstract: In this paper, we formulate cyber risk management and mitigation as a stochastic optimal control problem under a stochastic Susceptible-Infected-Susceptible (SIS) epidemic model. To capture the dynamics and interplay of management and mitigation strategies, we introduce two stochastic controls: (i) a proactive risk management control to reduce external cyber attacks and internal contagion effects, and (ii) a reactive mitigation control to accelerate system recovery from cyber infection. The interplay between these controls is modeled by minimizing the expected discounted running costs, which balance proactive management expenses against reactive mitigation expenditures. We derive the associated Hamilton-Jacobi-Bellman (HJB) equation and characterize the value function as its unique viscosity solution. For numerical solutions, we propose a Policy Improvement Algorithm (PIA) and prove its convergence via Backward Stochastic Differential Equations (BSDEs). Finally, we present a comprehensive numerical analysis through a benchmark example, suboptimal control analysis, sensitivity analysis, and comparative statics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23116v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shize Na, Zhuo Jin, Ran Xu, Hailiang Yang</dc:creator>
    </item>
    <item>
      <title>Zeroth-Order Constrained Optimization from a Control Perspective via Feedback Linearization</title>
      <link>https://arxiv.org/abs/2509.24056</link>
      <description>arXiv:2509.24056v2 Announce Type: replace 
Abstract: Safe derivative-free optimization under unknown constraints is a fundamental challenge in modern learning and control. Existing zeroth-order (ZO) methods typically still assume access to a first-order oracle of the constraint functions or restrict attention to convex settings, leaving nonconvex optimization with black-box constraints largely unexplored. We propose the zeroth-order feedback-linearization (ZOFL) algorithm for ZO constrained optimization that enforces feasibility without access to the first-order oracle of the constraint functions and applies to both equality and inequality constraints. The proposed approach relies only on noisy, sample-based gradient estimates obtained via two-point estimators, yet provably guarantees constraint satisfaction under mild regularity conditions. It adopts a control-theoretic perspective on ZO constrained optimization and leverages feedback linearization, a nonlinear control technique, to enforce feasibility. Finite-time bounds on constraint violation and asymptotic global convergence guarantees are established for the ZOFL algorithm. A midpoint discretization variant is further developed to improve feasibility without sacrificing optimality. Empirical results demonstrate that ZOFL consistently outperforms standard ZO baselines, achieving competitive objective values while maintaining feasibility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24056v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Runyu Zhang, Gioele Zardini, Asuman Ozdaglar, Jeff Shamma, Na Li</dc:creator>
    </item>
    <item>
      <title>QUASAR: An Evolutionary Algorithm to Accelerate High-Dimensional Optimization</title>
      <link>https://arxiv.org/abs/2511.13843</link>
      <description>arXiv:2511.13843v3 Announce Type: replace 
Abstract: High-dimensional numerical optimization presents a persistent challenge in computational science. This paper introduces Quasi-Adaptive Search with Asymptotic Reinitialization (QUASAR), an evolutionary algorithm to accelerate convergence in complex, non-differentiable problems afflicted by the curse of dimensionality. QUASAR expands upon the core principles of Differential Evolution (DE), introducing quasi-adaptive mechanisms to dynamically balance exploration and exploitation in its search. Inspired by the behavior of quantum particles, the algorithm utilizes three highly stochastic mechanisms that augment standard DE: 1) probabilistic mutation strategies and scaling factors; 2) rank-based crossover rates; 3) asymptotically decaying covariance reinitializations.
  Evaluated on the notoriously difficult CEC2017 benchmark suite of 29 test functions, QUASAR achieved the lowest overall rank sum (367) using the Friedman test, outperforming DE (735) and L-SHADE (452). Geometric mean comparisons show average final solution quality improvements of $3.85 \times$ and $2.07 \times$ compared to DE and L-SHADE, respectively ($p \ll 0.001$), with average optimization speed averaging $1.40 \times$ and $5.16 \times$ faster. QUASAR's performance establishes it as an effective, efficient, and user-friendly evolutionary algorithm for complex high-dimensional problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13843v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julian Soltes</dc:creator>
    </item>
    <item>
      <title>Supporting Lemmas for RISE-based Control Methods</title>
      <link>https://arxiv.org/abs/1306.3432</link>
      <description>arXiv:1306.3432v5 Announce Type: replace-cross 
Abstract: A class of continuous controllers termed Robust Integral of the Signum of the Error (RISE) have been published over the last decade as a means to yield asymptotic convergence of the tracking error for classes of nonlinear systems that are subject to exogenous disturbances and/or modeling uncertainties. The development of this class of controllers relies on a property related to the integral of the signum of an error signal. A proof for this property is not available in previous literature. The stability of some RISE controllers is analyzed using differential inclusions. Such results rely on the hypothesis that a set of points is Lebesgue negligible. This paper states and proves two lemmas related to the properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:1306.3432v5</guid>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rushikesh Kamalapurkar, Joel A. Rosenfeld, Justin Klotz, Ryan J. Downey, Warren E. Dixon</dc:creator>
    </item>
    <item>
      <title>Existence of minimizers for the SDRI model in $\mathbb{R}^n$: Wetting and dewetting regimes with mismatch strain</title>
      <link>https://arxiv.org/abs/2305.10304</link>
      <description>arXiv:2305.10304v2 Announce Type: replace-cross 
Abstract: The existence and the regularity results obtained in [37] for the variational model introduced in [36] to study the optimal shape of crystalline materials in the setting of stress-driven rearrangement instabilities (SDRI) are extended from two dimensions to any dimensions $n\geq2$. The energy is the sum of the elastic and the surface energy contributions, which cannot be decoupled, and depend on configurational pairs consisting of a set and a function that model the region occupied by the crystal and the bulk displacement field, respectively. By following the physical literature, the ``driving stress'' due to the mismatch between the ideal free-standing equilibrium lattice of the crystal with respect to adjacent materials is included in the model by considering a discontinuous mismatch strain in the elastic energy. Since two-dimensional methods and the methods used in the previous literature where Dirichlet boundary conditions instead of the mismatch strain and only the wetting regime were considered, cannot be employed in this setting, we proceed differently, by including in the analysis the dewetting regime and carefully analyzing the fine properties of energy-equibounded sequences. This analysis allows to establish both a compactness property in the family of admissible configurations and the lower-semicontinuity of the energy with respect to the topology induced by the $L^1$-convergence of sets and a.e.\ convergence of displacement fields, so that the direct method can be applied. We also prove that our arguments work as well in the setting with Dirichlet boundary conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.10304v2</guid>
      <category>math.AP</category>
      <category>math.CA</category>
      <category>math.OC</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shokhrukh Kholmatov, Paolo Piovano</dc:creator>
    </item>
    <item>
      <title>De Finetti's Control for Refracted Skew Brownian Motion</title>
      <link>https://arxiv.org/abs/2402.11471</link>
      <description>arXiv:2402.11471v4 Announce Type: replace-cross 
Abstract: In this paper we propose a refracted skew Brownian motion as a risk model with endogenous regime switching, which generalizes the refracted diffusion risk process introduced by Gerber and Shiu. We consider an optimal dividend problem for the refracted skew Brownian risk model and identify sufficient conditions, respectively, for barrier strategy, band strategy and their variants to be optimal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.11471v4</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhongqin Gao, Yan Lv, Xiaowen Zhou</dc:creator>
    </item>
    <item>
      <title>Equilibrium Selection for Multi-agent Reinforcement Learning: A Unified Framework</title>
      <link>https://arxiv.org/abs/2406.08844</link>
      <description>arXiv:2406.08844v2 Announce Type: replace-cross 
Abstract: While multi-agent reinforcement learning (MARL) has produced numerous algorithms that converge to Nash or related equilibria, such equilibria are often non-unique and can exhibit widely varying efficiency.
  This raises a fundamental question: how can one design learning dynamics that not only converge to equilibrium but also select equilibria with desirable performance, such as high social welfare? In contrast to the MARL literature, equilibrium selection has been extensively studied in normal-form games, where decentralized dynamics are known to converge to potential-maximizing or Pareto-optimal Nash equilibria (NEs). Motivated by these results, we study equilibrium selection in finite-horizon stochastic games. We propose a unified actor-critic framework in which a critic learns state-action value functions, and an actor applies a classical equilibrium-selection rule state-wise, treating learned values as stage-game payoffs. We show that, under standard stochastic stability assumptions, the stochastically stable policies of the resulting dynamics inherit the equilibrium selection properties of the underlying normal-form learning rule. As consequences, we obtain potential-maximizing policies in Markov potential games and Pareto-optimal (Markov perfect) equilibria in general-sum stochastic games, together with sample-based implementation of the framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.08844v2</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Runyu Zhang, Gioele Zardini, Asuman Ozdaglar, Jeff Shamma, Na Li</dc:creator>
    </item>
    <item>
      <title>BAGEL: Projection-Free Algorithm for Adversarially Constrained Online Convex Optimization</title>
      <link>https://arxiv.org/abs/2502.16744</link>
      <description>arXiv:2502.16744v2 Announce Type: replace-cross 
Abstract: Projection-based algorithms for Constrained Online Convex Optimization (COCO) achieve optimal $\mathcal{O}(T^{1/2})$ regret guarantees but face scalability challenges due to the computational complexity of projections. To circumvent this, projection-free methods utilizing Linear Optimization Oracles (LOO) have been proposed, albeit typically achieving slower $\mathcal{O}(T^{3/4})$ regret rates. In this work, we examine whether the $\mathcal{O}(T^{1/2})$ rate can be recovered in the projection-free setting by strengthening the oracle assumption. We introduce BAGEL, an algorithm utilizing a Separation Oracle (SO) that achieves $\mathcal{O}(T^{1/2})$ regret and $\tilde{\mathcal{O}}(T^{1/2})$ cumulative constraint violation (CCV) for convex cost functions. Our analysis shows that by leveraging an infeasible projection via SO, we can match the time-horizon dependence of projection-based methods with $\tilde{\mathcal{O}}(T)$ oracle calls, provided dependence on the geometry of the action set. This establishes a specific regime where projection-free methods can attain the same convergence rates as projection-based counterparts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16744v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiyang Lu, Mohammad Pedramfar, Vaneet Aggarwal</dc:creator>
    </item>
    <item>
      <title>Sufficient Decision Proxies for Decision-Focused Learning</title>
      <link>https://arxiv.org/abs/2505.03953</link>
      <description>arXiv:2505.03953v2 Announce Type: replace-cross 
Abstract: When solving optimization problems under uncertainty with contextual data, utilizing machine learning to predict the uncertain parameters' values is a popular and effective approach. Decision-focused learning (DFL) aims at learning a predictive model such that decision quality, instead of prediction accuracy, is maximized. Common practice is to predict a single scenario representing the uncertain parameters, implicitly assuming that there exists a deterministic problem approximation (proxy) that allows for optimal decision-making. The opposite has also been considered, where the underlying distribution is estimated with a parameterized distribution. However, little is known about when either choice is valid. This paper investigates for the first time problem properties that justify using a certain decision proxy. Using this, we present alternative decision proxies for DFL, with little or no compromise on the complexity of the learning task. We show the effectiveness of presented approaches in experiments on continuous and discrete problems, as well as problems with uncertainty in the objective function and in the constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03953v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Noah Schutte, Grigorii Veviurko, Krzysztof Postek, Neil Yorke-Smith</dc:creator>
    </item>
    <item>
      <title>Resolvent Compositions for Positive Linear Operators</title>
      <link>https://arxiv.org/abs/2509.07251</link>
      <description>arXiv:2509.07251v3 Announce Type: replace-cross 
Abstract: Resolvent compositions were recently introduced as monotonicity-preserving operations that combine a set-valued monotone operator and a bounded linear operator. They generalize in particular the notion of a resolvent average. We analyze the resolvent compositions when the monotone operator is a positive linear operator. We establish several new properties, including L\"owner partial order relations, concavity, and asymptotic behavior. In addition, we show that the resolvent composition operations are nonexpansive with respect to the Thompson metric. We also introduce a new form of geometric interpolation and explore its connections to resolvent compositions. Finally, we study two nonlinear equations based on resolvent compositions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.07251v3</guid>
      <category>math.FA</category>
      <category>math.OC</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Diego J. Cornejo</dc:creator>
    </item>
    <item>
      <title>Diagonal Linear Networks and the Lasso Regularization Path</title>
      <link>https://arxiv.org/abs/2509.18766</link>
      <description>arXiv:2509.18766v2 Announce Type: replace-cross 
Abstract: Diagonal linear networks are neural networks with linear activation and diagonal weight matrices. Their theoretical interest is that their implicit regularization can be rigorously analyzed: from a small initialization, the training of diagonal linear networks converges to the linear predictor with minimal 1-norm among minimizers of the training loss. In this paper, we deepen this analysis showing that the full training trajectory of diagonal linear networks is closely related to the lasso regularization path. In this connection, the training time plays the role of an inverse regularization parameter. Both rigorous results and simulations are provided to illustrate this conclusion. Under a monotonicity assumption on the lasso regularization path, the connection is exact while in the general case, we show an approximate connection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.18766v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rapha\"el Berthier</dc:creator>
    </item>
    <item>
      <title>Sharpness of Minima in Deep Matrix Factorization</title>
      <link>https://arxiv.org/abs/2509.25783</link>
      <description>arXiv:2509.25783v5 Announce Type: replace-cross 
Abstract: Understanding the geometry of the loss landscape near a minimum is key to explaining the implicit bias of gradient-based methods in non-convex optimization problems such as deep neural network training and deep matrix factorization. A central quantity to characterize this geometry is the maximum eigenvalue of the Hessian of the loss. Currently, its precise role has been obfuscated because no exact expressions for this sharpness measure were known in general settings. In this paper, we present the first exact expression for the maximum eigenvalue of the Hessian of the squared-error loss at any minimizer in deep matrix factorization/deep linear neural network training problems, resolving an open question posed by Mulayoff &amp; Michaeli (2020). This expression reveals a fundamental property of the loss landscape in deep matrix factorization: Having a constant product of the spectral norms of the left and right intermediate factors across layers is a sufficient condition for flatness. Most notably, in both depth-$2$ matrix and deep overparameterized scalar factorization, we show that this condition is both necessary and sufficient for flatness, which implies that flat minima are spectral-norm balanced even though they are not necessarily Frobenius-norm balanced. To complement our theory, we provide the first empirical characterization of an escape phenomenon during gradient-based training near a minimizer of a deep matrix factorization problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.25783v5</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anil Kamber, Rahul Parhi</dc:creator>
    </item>
    <item>
      <title>Efficient Group Lasso Regularized Rank Regression with Data-Driven Parameter Determination</title>
      <link>https://arxiv.org/abs/2510.11546</link>
      <description>arXiv:2510.11546v2 Announce Type: replace-cross 
Abstract: High-dimensional regression often suffers from heavy-tailed noise and outliers, which can severely undermine the reliability of least-squares based methods. To improve robustness, we adopt a non-smooth Wilcoxon score based rank objective and incorporate structured group sparsity regularization, a natural generalization of the lasso, yielding a group lasso regularized rank regression method. By extending the tuning-free parameter selection scheme originally developed for the lasso, we introduce a data-driven, simulation-based tuning rule and further establish a finite-sample error bound for the resulting estimator. On the computational side, we develop a proximal augmented Lagrangian method for solving the associated optimization problem, which eliminates the singularity issues encountered in existing methods, thereby enabling efficient semismooth Newton updates for the subproblems. Extensive numerical experiments demonstrate the robustness and effectiveness of our proposed estimator against alternatives, and showcase the scalability of the algorithm across both simulated and real-data settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.11546v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Meixia Lin, Meijiao Shi, Yunhai Xiao, Qian Zhang</dc:creator>
    </item>
    <item>
      <title>Refined thresholds for inconsistency: The effect of the graph associated with incomplete pairwise comparisons</title>
      <link>https://arxiv.org/abs/2510.27011</link>
      <description>arXiv:2510.27011v2 Announce Type: replace-cross 
Abstract: The inconsistency of pairwise comparisons remains difficult to interpret in the absence of acceptability thresholds. The popular 10% cut-off rule proposed by Saaty has recently been applied to incomplete pairwise comparison matrices, which contain some unknown comparisons. This paper refines these inconsistency thresholds: we uncover that they depend not only on the size of the matrix and the number of missing entries, but also on the undirected graph whose edges represent the known pairwise comparisons. Therefore, using our exact thresholds is especially important if the filling in patterns coincide for a large number of matrices, as has been recommended in the literature. The strong association between the new threshold values and the spectral radius of the representing graph is also demonstrated. Our results can be integrated into software to continuously monitor inconsistency during the collection of pairwise comparisons and immediately detect potential errors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.27011v2</guid>
      <category>stat.ME</category>
      <category>math.OC</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kolos Csaba \'Agoston, L\'aszl\'o Csat\'o</dc:creator>
    </item>
    <item>
      <title>A probabilistic match classification model for sports tournaments</title>
      <link>https://arxiv.org/abs/2601.09673</link>
      <description>arXiv:2601.09673v2 Announce Type: replace-cross 
Abstract: Existing match classification models in the tournament design literature have two major limitations: a contestant is considered indifferent only if uncertain future results do never affect its prize, and competitive matches are not distinguished with respect to the incentives of the contestants. We propose a probabilistic framework to address both issues. For each match, our approach relies on simulating all other matches played simultaneously or later to compute the qualifying probabilities under the three main outcomes (win, draw, loss), which allows the classification of each match into six different categories. The suggested model is applied to the previous group stage and the new incomplete round-robin league, introduced in the 2024/25 season of UEFA club competitions. An incomplete round-robin tournament is found to contain fewer stakeless matches where both contestants are indifferent, and substantially more matches where both contestants should play offensively. However, the robustly higher proportion of potentially collusive matches can threaten with serious scandals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09673v2</guid>
      <category>physics.soc-ph</category>
      <category>econ.GN</category>
      <category>math.OC</category>
      <category>q-fin.EC</category>
      <category>stat.AP</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>L\'aszl\'o Csat\'o, Andr\'as Gyimesi</dc:creator>
    </item>
    <item>
      <title>A New Convergence Analysis of Plug-and-Play Proximal Gradient Descent Under Prior Mismatch</title>
      <link>https://arxiv.org/abs/2601.09831</link>
      <description>arXiv:2601.09831v2 Announce Type: replace-cross 
Abstract: In this work, we provide a new convergence theory for plug-and-play proximal gradient descent (PnP-PGD) under prior mismatch where the denoiser is trained on a different data distribution to the inference task at hand. To the best of our knowledge, this is the first convergence proof of PnP-PGD under prior mismatch. Compared with the existing theoretical results for PnP algorithms, our new results removed the need for several restrictive and unverifiable assumptions. Moreover, we derive the convergence theory for equivariant PnP (EPnP) under the prior mismatch setting, proving that EPnP reduces error variance and explicitly tightens the convergence bound.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09831v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guixian Xu, Jinglai Li, Junqi Tang</dc:creator>
    </item>
  </channel>
</rss>
