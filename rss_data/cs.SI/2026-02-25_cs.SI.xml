<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SI</link>
    <description>cs.SI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 26 Feb 2026 02:54:00 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 25 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Modelling Interaction Duration in Relational Event Models</title>
      <link>https://arxiv.org/abs/2602.21000</link>
      <description>arXiv:2602.21000v1 Announce Type: new 
Abstract: The study of relational events, which are interactions occurring between actors over time, has gained significant traction recently. Traditional relational event models typically focus on modelling the occurrence and sequence of events without considering their duration even though duration information is frequently available in empirical relational event data. We introduce a novel Duration Relational Event Model (DuREM) that incorporates the temporal duration of events into the analysis. The proposed model extends the existing framework by (i) allowing the inclusion of past event durations in the endogenous statistics to account for how the duration of past events affects the rate of future interactions, and (ii) extending the traditional relational event model by also modelling when events will end based on past event history and covariates. This is achieved by extending the risk set to include both ongoing events at risk of ending and idle dyads at risk of starting new events. The methodology is implemented in a new R package `durem'. Two case studies concerning team dynamics and inter-personal violence are presented to illustrate the applicability of the model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21000v1</guid>
      <category>cs.SI</category>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rumana Lakdawala, Roger Leenders, Peter Ejbye-Ernst, Joris Mulder</dc:creator>
    </item>
    <item>
      <title>Some Simple Economics of AGI</title>
      <link>https://arxiv.org/abs/2602.20946</link>
      <description>arXiv:2602.20946v2 Announce Type: cross 
Abstract: For millennia, human cognition was the primary engine of progress on Earth. As AI decouples cognition from biology, the marginal cost of measurable execution falls to zero, absorbing any labor capturable by metrics--including creative, analytical, and innovative work. The binding constraint on growth is no longer intelligence but human verification bandwidth: the capacity to validate, audit, and underwrite responsibility when execution is abundant. We model the AGI transition as the collision of two racing cost curves: an exponentially decaying Cost to Automate and a biologically bottlenecked Cost to Verify. This structural asymmetry widens a Measurability Gap between what agents can execute and what humans can afford to verify. It also drives a shift from skill-biased to measurability-biased technical change. Rents migrate to verification-grade ground truth, cryptographic provenance, and liability underwriting--the ability to insure outcomes rather than merely generate them. The current human-in-the-loop equilibrium is unstable: eroded from below as apprenticeship collapses (Missing Junior Loop) and from within as experts codify their obsolescence (Codifier's Curse). Unverified deployment becomes privately rational--a Trojan Horse externality. Unmanaged, these forces pull toward a Hollow Economy. Yet by scaling verification alongside agentic capabilities, the forces that threaten collapse become the catalyst for unbounded discovery and experimentation--an Augmented Economy. We derive a practical playbook for individuals, companies, investors, and policymakers. Today's defining challenge is not the race to deploy the most autonomous systems; it is the race to secure the foundations of their oversight. Only by scaling our bandwidth for verification alongside our capacity for execution can we ensure that the intelligence we have summoned preserves the humanity that initiated it.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.20946v2</guid>
      <category>econ.GN</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christian Catalini, Xiang Hui, Jane Wu</dc:creator>
    </item>
    <item>
      <title>"Are You Sure?": An Empirical Study of Human Perception Vulnerability in LLM-Driven Agentic Systems</title>
      <link>https://arxiv.org/abs/2602.21127</link>
      <description>arXiv:2602.21127v1 Announce Type: cross 
Abstract: Large language model (LLM) agents are rapidly becoming trusted copilots in high-stakes domains like software development and healthcare. However, this deepening trust introduces a novel attack surface: Agent-Mediated Deception (AMD), where compromised agents are weaponized against their human users. While extensive research focuses on agent-centric threats, human susceptibility to deception by a compromised agent remains unexplored. We present the first large-scale empirical study with 303 participants to measure human susceptibility to AMD. This is based on HAT-Lab (Human-Agent Trust Laboratory), a high-fidelity research platform we develop, featuring nine carefully crafted scenarios spanning everyday and professional domains (e.g., healthcare, software development, human resources). Our 10 key findings reveal significant vulnerabilities and provide future defense perspectives. Specifically, only 8.6% of participants perceive AMD attacks, while domain experts show increased susceptibility in certain scenarios. We identify six cognitive failure modes in users and find that their risk awareness often fails to translate to protective behavior. The defense analysis reveals that effective warnings should interrupt workflows with low verification costs. With experiential learning based on HAT-Lab, over 90% of users who perceive risks report increased caution against AMD. This work provides empirical evidence and a platform for human-centric agent security research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21127v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CR</category>
      <category>cs.SI</category>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinfeng Li, Shenyu Dai, Kelong Zheng, Yue Xiao, Gelei Deng, Wei Dong, Xiaofeng Wang</dc:creator>
    </item>
    <item>
      <title>Optimal Verification of (Mis)Information in Networks</title>
      <link>https://arxiv.org/abs/2207.01830</link>
      <description>arXiv:2207.01830v3 Announce Type: replace-cross 
Abstract: We study the diffusion of a true and a false message (misinformation) when agents are biased and able to verify messages. As a recipient of a false message who verifies it becomes informed of the truth, a higher prevalence of misinformation can increase the prevalence of the truth. We uncover conditions such that this happens and discuss policy implications. Specifically, a planner aiming to maximize the prevalence of the truth should allow misinformation to circulate if: non-verified messages may be ignored, transmission of information is relatively low, and the planner's budget to induce verification is neither too low nor too high. Homophily increases the spread of misinformation, but also facilitates diffusion of truth, and leads to similar results on the effect of verification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.01830v3</guid>
      <category>econ.TH</category>
      <category>cs.SI</category>
      <category>physics.soc-ph</category>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Luca Paolo Merlino, Nicole Tabasso</dc:creator>
    </item>
    <item>
      <title>Causal Claims in Economics</title>
      <link>https://arxiv.org/abs/2501.06873</link>
      <description>arXiv:2501.06873v2 Announce Type: replace-cross 
Abstract: As economics scales, a key bottleneck is representing what papers claim in a comparable, aggregable form. We introduce evidence-annotated claim graphs that map each paper into a directed network of standardized economic concepts (nodes) and stated relationships (edges), with each edge labeled by evidentiary basis, including whether it is supported by causal inference designs or by non-causal evidence. Using a structured multi-stage AI workflow, we construct claim graphs for 44,852 economics papers from 1980-2023. The share of causal edges rises from 7.7% in 1990 to 31.7% in 2020. Measures of causal narrative structure and causal novelty are positively associated with top-five publication and long-run citations, whereas non-causal counterparts are weakly related or negative.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.06873v2</guid>
      <category>econ.GN</category>
      <category>cs.CL</category>
      <category>cs.IR</category>
      <category>cs.SI</category>
      <category>q-fin.EC</category>
      <category>stat.ME</category>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Prashant Garg, Thiemo Fetzer</dc:creator>
    </item>
  </channel>
</rss>
