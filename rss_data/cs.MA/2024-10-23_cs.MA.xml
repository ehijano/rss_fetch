<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.MA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.MA</link>
    <description>cs.MA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.MA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 24 Oct 2024 01:56:46 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Scalable spectral representations for network multiagent control</title>
      <link>https://arxiv.org/abs/2410.17221</link>
      <description>arXiv:2410.17221v1 Announce Type: new 
Abstract: Network Markov Decision Processes (MDPs), a popular model for multi-agent control, pose a significant challenge to efficient learning due to the exponential growth of the global state-action space with the number of agents. In this work, utilizing the exponential decay property of network dynamics, we first derive scalable spectral local representations for network MDPs, which induces a network linear subspace for the local $Q$-function of each agent. Building on these local spectral representations, we design a scalable algorithmic framework for continuous state-action network MDPs, and provide end-to-end guarantees for the convergence of our algorithm. Empirically, we validate the effectiveness of our scalable representation-based approach on two benchmark problems, and demonstrate the advantages of our approach over generic function approximation approaches to representing the local $Q$-functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.17221v1</guid>
      <category>cs.MA</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaolin Ren (Cathy),  Runyu (Cathy),  Zhang, Bo Dai, Na Li</dc:creator>
    </item>
    <item>
      <title>Policies with Sparse Inter-Agent Dependencies in Dynamic Games: A Dynamic Programming Approach</title>
      <link>https://arxiv.org/abs/2410.16441</link>
      <description>arXiv:2410.16441v1 Announce Type: cross 
Abstract: Common feedback strategies in multi-agent dynamic games require all players' state information to compute control strategies. However, in real-world scenarios, sensing and communication limitations between agents make full state feedback expensive or impractical, and such strategies can become fragile when state information from other agents is inaccurate. To this end, we propose a regularized dynamic programming approach for finding sparse feedback policies that selectively depend on the states of a subset of agents in dynamic games. The proposed approach solves convex adaptive group Lasso problems to compute sparse policies approximating Nash equilibrium solutions. We prove the regularized solutions' asymptotic convergence to a neighborhood of Nash equilibrium policies in linear-quadratic (LQ) games. We extend the proposed approach to general non-LQ games via an iterative algorithm. Empirical results in multi-robot interaction scenarios show that the proposed approach effectively computes feedback policies with varying sparsity levels. When agents have noisy observations of other agents' states, simulation results indicate that the proposed regularized policies consistently achieve lower costs than standard Nash equilibrium policies by up to 77% for all interacting agents whose costs are coupled with other agents' states.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16441v1</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinjie Liu, Jingqi Li, Filippos Fotiadis, Mustafa O. Karabag, Jesse Milzman, David Fridovich-Keil, Ufuk Topcu</dc:creator>
    </item>
    <item>
      <title>Beyond Browsing: API-Based Web Agents</title>
      <link>https://arxiv.org/abs/2410.16464</link>
      <description>arXiv:2410.16464v1 Announce Type: cross 
Abstract: Web browsers are a portal to the internet, where much of human activity is undertaken. Thus, there has been significant research work in AI agents that interact with the internet through web browsing. However, there is also another interface designed specifically for machine interaction with online content: application programming interfaces (APIs). In this paper we ask -- what if we were to take tasks traditionally tackled by browsing agents, and give AI agents access to APIs? To do so, we propose two varieties of agents: (1) an API-calling agent that attempts to perform online tasks through APIs only, similar to traditional coding agents, and (2) a Hybrid Agent that can interact with online data through both web browsing and APIs. In experiments on WebArena, a widely-used and realistic benchmark for web navigation tasks, we find that API-based agents outperform web browsing agents. Hybrid Agents out-perform both others nearly uniformly across tasks, resulting in a more than 20.0% absolute improvement over web browsing alone, achieving a success rate of 35.8%, achiving the SOTA performance among task-agnostic agents. These results strongly suggest that when APIs are available, they present an attractive alternative to relying on web browsing alone.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16464v1</guid>
      <category>cs.CL</category>
      <category>cs.MA</category>
      <pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yueqi Song, Frank Xu, Shuyan Zhou, Graham Neubig</dc:creator>
    </item>
    <item>
      <title>Distributed Online Life-Long Learning (DOL3) for Multi-agent Trust and Reputation Assessment in E-commerce</title>
      <link>https://arxiv.org/abs/2410.16529</link>
      <description>arXiv:2410.16529v1 Announce Type: cross 
Abstract: Trust and Reputation Assessment of service providers in citizen-focused environments like e-commerce is vital to maintain the integrity of the interactions among agents. The goals and objectives of both the service provider and service consumer agents are relevant to the goals of the respective citizens (end users). The provider agents often pursue selfish goals that can make the service quality highly volatile, contributing towards the non-stationary nature of the environment. The number of active service providers tends to change over time resulting in an open environment. This necessitates a rapid and continual assessment of the Trust and Reputation. A large number of service providers in the environment require a distributed multi-agent Trust and Reputation assessment. This paper addresses the problem of multi-agent Trust and Reputation Assessment in a non-stationary environment involving transactions between providers and consumers. In this setting, the observer agents carry out the assessment and communicate their assessed trust scores with each other over a network. We propose a novel Distributed Online Life-Long Learning (DOL3) algorithm that involves real-time rapid learning of trust and reputation scores of providers. Each observer carries out an adaptive learning and weighted fusion process combining their own assessment along with that of their neighbour in the communication network. Simulation studies reveal that the state-of-the-art methods, which usually involve training a model to assess an agent's trust and reputation, do not work well in such an environment. The simulation results show that the proposed DOL3 algorithm outperforms these methods and effectively handles the volatility in such environments. From the statistical evaluation, it is evident that DOL3 performs better compared to other models in 90% of the cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16529v1</guid>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.6084/m9.figshare.25719180.v1</arxiv:DOI>
      <dc:creator>Hariprasauth Ramamoorthy, Shubhankar Gupta, Suresh Sundaram</dc:creator>
    </item>
    <item>
      <title>Convex Markov Games: A Framework for Fairness, Imitation, and Creativity in Multi-Agent Learning</title>
      <link>https://arxiv.org/abs/2410.16600</link>
      <description>arXiv:2410.16600v1 Announce Type: cross 
Abstract: Expert imitation, behavioral diversity, and fairness preferences give rise to preferences in sequential decision making domains that do not decompose additively across time. We introduce the class of convex Markov games that allow general convex preferences over occupancy measures. Despite infinite time horizon and strictly higher generality than Markov games, pure strategy Nash equilibria exist under strict convexity. Furthermore, equilibria can be approximated efficiently by performing gradient descent on an upper bound of exploitability. Our experiments imitate human choices in ultimatum games, reveal novel solutions to the repeated prisoner's dilemma, and find fair solutions in a repeated asymmetric coordination game. In the prisoner's dilemma, our algorithm finds a policy profile that deviates from observed human play only slightly, yet achieves higher per-player utility while also being three orders of magnitude less exploitable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16600v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ian Gemp, Andreas Haupt, Luke Marris, Siqi Liu, Georgios Piliouras</dc:creator>
    </item>
    <item>
      <title>Cutting Through the Confusion and Hype: Understanding the True Potential of Generative AI</title>
      <link>https://arxiv.org/abs/2410.16629</link>
      <description>arXiv:2410.16629v1 Announce Type: cross 
Abstract: This paper explores the nuanced landscape of generative AI (genAI), particularly focusing on neural network-based models like Large Language Models (LLMs). While genAI garners both optimistic enthusiasm and sceptical criticism, this work seeks to provide a balanced examination of its capabilities, limitations, and the profound impact it may have on societal functions and personal interactions. The first section demystifies language-based genAI through detailed discussions on how LLMs learn, their computational needs, distinguishing features from supporting technologies, and the inherent limitations in their accuracy and reliability. Real-world examples illustrate the practical applications and implications of these technologies. The latter part of the paper adopts a systems perspective, evaluating how the integration of LLMs with existing technologies can enhance productivity and address emerging concerns. It highlights the need for significant investment to understand the implications of recent advancements, advocating for a well-informed dialogue to ethically and responsibly integrate genAI into diverse sectors. The paper concludes with prospective developments and recommendations, emphasizing a forward-looking approach to harnessing genAI`s potential while mitigating its risks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16629v1</guid>
      <category>cs.CY</category>
      <category>cs.IR</category>
      <category>cs.MA</category>
      <pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ante Prodan, Jo-An Occhipinti, Rehez Ahlip, Goran Ujdur, Harris A. Eyre, Kyle Goosen, Luke Penza, Mark Heffernan</dc:creator>
    </item>
    <item>
      <title>SERN: Simulation-Enhanced Realistic Navigation for Multi-Agent Robotic Systems in Contested Environments</title>
      <link>https://arxiv.org/abs/2410.16686</link>
      <description>arXiv:2410.16686v1 Announce Type: cross 
Abstract: The increasing deployment of autonomous systems in complex environments necessitates efficient communication and task completion among multiple agents. This paper presents SERN (Simulation-Enhanced Realistic Navigation), a novel framework integrating virtual and physical environments for real-time collaborative decision-making in multi-robot systems. SERN addresses key challenges in asset deployment and coordination through a bi-directional communication framework using the AuroraXR ROS Bridge. Our approach advances the SOTA through accurate real-world representation in virtual environments using Unity high-fidelity simulator; synchronization of physical and virtual robot movements; efficient ROS data distribution between remote locations; and integration of SOTA semantic segmentation for enhanced environmental perception. Our evaluations show a 15% to 24% improvement in latency and up to a 15% increase in processing efficiency compared to traditional ROS setups. Real-world and virtual simulation experiments with multiple robots demonstrate synchronization accuracy, achieving less than 5 cm positional error and under 2-degree rotational error. These results highlight SERN's potential to enhance situational awareness and multi-agent coordination in diverse, contested environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16686v1</guid>
      <category>cs.RO</category>
      <category>cs.MA</category>
      <pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jumman Hossain, Emon Dey, Snehalraj Chugh, Masud Ahmed, MS Anwar, Abu-Zaher Faridee, Jason Hoppes, Theron Trout, Anjon Basak, Rafidh Chowdhury, Rishabh Mistry, Hyun Kim, Jade Freeman, Niranjan Suri, Adrienne Raglin, Carl Busart, Timothy Gregory, Anuradha Ravi, Nirmalya Roy</dc:creator>
    </item>
    <item>
      <title>Delay-Constrained Grant-Free Random Access in MIMO Systems: Distributed Pilot Allocation and Power Control</title>
      <link>https://arxiv.org/abs/2410.17068</link>
      <description>arXiv:2410.17068v1 Announce Type: cross 
Abstract: We study a delay-constrained grant-free random access system with a multi-antenna base station. The users randomly generate data packets with expiration deadlines, which are then transmitted from data queues on a first-in first-out basis. To deliver a packet, a user needs to succeed in both random access phase (sending a pilot without collision) and data transmission phase (achieving a required data rate with imperfect channel information) before the packet expires. We develop a distributed, cross-layer policy that allows the users to dynamically and independently choose their pilots and transmit powers to achieve a high effective sum throughput with fairness consideration. Our policy design involves three key components: 1) a proxy of the instantaneous data rate that depends only on macroscopic environment variables and transmission decisions, considering pilot collisions and imperfect channel estimation; 2) a quantitative, instantaneous measure of fairness within each communication round; and 3) a deep learning-based, multi-agent control framework with centralized training and distributed execution. The proposed framework benefits from an accurate, differentiable objective function for training, thereby achieving a higher sample efficiency compared with a conventional application of model-free, multi-agent reinforcement learning algorithms. The performance of the proposed approach is verified by simulations under highly dynamic and heterogeneous scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.17068v1</guid>
      <category>cs.IT</category>
      <category>cs.MA</category>
      <category>math.IT</category>
      <pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianan Bai, Zheng Chen, Erik. G. Larsson</dc:creator>
    </item>
    <item>
      <title>MARLadona -- Towards Cooperative Team Play Using Multi-Agent Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2409.20326</link>
      <description>arXiv:2409.20326v2 Announce Type: replace 
Abstract: Robot soccer, in its full complexity, poses an unsolved research challenge. Current solutions heavily rely on engineered heuristic strategies, which lack robustness and adaptability. Deep reinforcement learning has gained significant traction in various complex robotics tasks such as locomotion, manipulation, and competitive games (e.g., AlphaZero, OpenAI Five), making it a promising solution to the robot soccer problem. This paper introduces MARLadona. A decentralized multi-agent reinforcement learning (MARL) training pipeline capable of producing agents with sophisticated team play behavior, bridging the shortcomings of heuristic methods. Further, we created an open-source multi-agent soccer environment based on Isaac Gym. Utilizing our MARL framework and a modified a global entity encoder as our core architecture, our approach achieves a 66.8% win rate against HELIOS agent, which employs a state-of-the-art heuristic strategy. Furthermore, we provided an in-depth analysis of the policy behavior and interpreted the agent's intention using the critic network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.20326v2</guid>
      <category>cs.MA</category>
      <pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zichong Li, Filip Bjelonic, Victor Klemm, Marco Hutter</dc:creator>
    </item>
    <item>
      <title>Persistent synchronization of heterogeneous networks with time-dependent linear diffusive coupling</title>
      <link>https://arxiv.org/abs/2305.05747</link>
      <description>arXiv:2305.05747v2 Announce Type: replace-cross 
Abstract: We study synchronization for linearly coupled temporal networks of heterogeneous time-dependent nonlinear agents via the convergence of attracting trajectories of each node. The results are obtained by constructing and studying the stability of a suitable linear nonautonomous problem bounding the evolution of the synchronization errors. Both, the case of the entire network and only a cluster, are addressed and the persistence of the obtained synchronization against perturbation is also discussed. Furthermore, a sufficient condition for the existence of attracting trajectories of each node is given. In all cases, the considered dependence on time requires only local integrability, which is a very mild regularity assumption. Moreover, our results mainly depend on the network structure and its properties, and achieve synchronization up to a constant in finite time. Hence they are quite suitable for applications. The applicability of the results is showcased via several examples: coupled van-der-Pol/FitzHugh-Nagumo oscillators, weighted/signed opinion dynamics, and coupled Lorenz systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.05747v2</guid>
      <category>math.DS</category>
      <category>cs.MA</category>
      <pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hildeberto Jard\'on-Kojakhmetov, Christian Kuehn, Iacopo P. Longo</dc:creator>
    </item>
    <item>
      <title>Simulating the Economic Impact of Rationality through Reinforcement Learning and Agent-Based Modelling</title>
      <link>https://arxiv.org/abs/2405.02161</link>
      <description>arXiv:2405.02161v2 Announce Type: replace-cross 
Abstract: Agent-based models (ABMs) are simulation models used in economics to overcome some of the limitations of traditional frameworks based on general equilibrium assumptions. However, agents within an ABM follow predetermined 'bounded rational' behavioural rules which can be cumbersome to design and difficult to justify. Here we leverage multi-agent reinforcement learning (RL) to expand the capabilities of ABMs with the introduction of 'fully rational' agents that learn their policy by interacting with the environment and maximising a reward function. Specifically, we propose a 'Rational macro ABM' (R-MABM) framework by extending a paradigmatic macro ABM from the economic literature. We show that gradually substituting ABM firms in the model with RL agents, trained to maximise profits, allows for studying the impact of rationality on the economy. We find that RL agents spontaneously learn three distinct strategies for maximising profits, with the optimal strategy depending on the level of market competition and rationality. We also find that RL agents with independent policies, and without the ability to communicate with each other, spontaneously learn to segregate into different strategic groups, thus increasing market power and overall profits. Finally, we find that a higher number of rational (RL) agents in the economy always improves the macroeconomic environment as measured by total output. Depending on the specific rational policy, this can come at the cost of higher instability. Our R-MABM framework allows for stable multi-agent learning, is available in open source, and represents a principled and robust direction to extend economic simulators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02161v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.MA</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3677052.3698621</arxiv:DOI>
      <arxiv:journal_reference>Proceedings of the Fifth ACM International Conference on AI in Finance (ICAIF 2024, https://ai-finance.org/)</arxiv:journal_reference>
      <dc:creator>Simone Brusatin, Tommaso Padoan, Andrea Coletta, Domenico Delli Gatti, Aldo Glielmo</dc:creator>
    </item>
    <item>
      <title>Dynamic Intelligence Assessment: Benchmarking LLMs on the Road to AGI with a Focus on Model Confidence</title>
      <link>https://arxiv.org/abs/2410.15490</link>
      <description>arXiv:2410.15490v2 Announce Type: replace-cross 
Abstract: As machine intelligence evolves, the need to test and compare the problem-solving abilities of different AI models grows. However, current benchmarks are often overly simplistic, allowing models to perform uniformly well, making it difficult to distinguish their capabilities. Additionally, benchmarks typically rely on static question-answer pairs, which models might memorize or guess. To address these limitations, we introduce the Dynamic Intelligence Assessment (DIA), a novel methodology for testing AI models using dynamic question templates and improved metrics across multiple disciplines such as mathematics, cryptography, cybersecurity, and computer science. The accompanying DIA-Bench dataset, which includes 150 diverse and challenging task templates with mutable parameters, is presented in various formats such as text, PDFs, compiled binaries, and visual puzzles. Our framework introduces four new metrics to assess a model's reliability and confidence across multiple attempts. These metrics revealed that even simple questions are frequently answered incorrectly when posed in varying forms, highlighting significant gaps in models' reliability. Notably, models like GPT-4o tended to overestimate their mathematical abilities, while ChatGPT-4o demonstrated better decision-making and performance through effective tool usage. We evaluated eight state-of-the-art large language models (LLMs) using DIA-Bench, showing that current models struggle with complex tasks and often display unexpectedly low confidence, even with simpler questions. The DIA framework sets a new standard for assessing not only problem-solving but also a model's adaptive intelligence and ability to assess its own limitations. The dataset is publicly available on our project's website.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15490v2</guid>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Norbert Tihanyi, Tamas Bisztray, Richard A. Dubniczky, Rebeka Toth, Bertalan Borsos, Bilel Cherif, Mohamed Amine Ferrag, Lajos Muzsai, Ridhi Jain, Ryan Marinelli, Lucas C. Cordeiro, Merouane Debbah</dc:creator>
    </item>
    <item>
      <title>LASER: Script Execution by Autonomous Agents for On-demand Traffic Simulation</title>
      <link>https://arxiv.org/abs/2410.16197</link>
      <description>arXiv:2410.16197v2 Announce Type: replace-cross 
Abstract: Autonomous Driving Systems (ADS) require diverse and safety-critical traffic scenarios for effective training and testing, but the existing data generation methods struggle to provide flexibility and scalability. We propose LASER, a novel frame-work that leverage large language models (LLMs) to conduct traffic simulations based on natural language inputs. The framework operates in two stages: it first generates scripts from user-provided descriptions and then executes them using autonomous agents in real time. Validated in the CARLA simulator, LASER successfully generates complex, on-demand driving scenarios, significantly improving ADS training and testing data generation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16197v2</guid>
      <category>cs.RO</category>
      <category>cs.MA</category>
      <pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Gao, Jingyue Wang, Wenyang Fang, Jingwei Xu, Yunpeng Huang, Taolue Chen, Xiaoxing Ma</dc:creator>
    </item>
  </channel>
</rss>
