<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>nlin.CD updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/nlin.CD</link>
    <description>nlin.CD updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/nlin.CD" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 15 May 2024 04:10:24 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 15 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Noise-induced degeneration in online learning</title>
      <link>https://arxiv.org/abs/2008.10498</link>
      <description>arXiv:2008.10498v5 Announce Type: cross 
Abstract: In order to elucidate the plateau phenomena caused by vanishing gradient, we herein analyse stability of stochastic gradient descent near degenerated subspaces in a multi-layer perceptron. In stochastic gradient descent for Fukumizu-Amari model, which is the minimal multi-layer perceptron showing non-trivial plateau phenomena, we show that (1) attracting regions exist in multiply degenerated subspaces, (2) a strong plateau phenomenon emerges as a noise-induced synchronisation, which is not observed in deterministic gradient descent, (3) an optimal fluctuation exists to minimise the escape time from the degenerated subspace. The noise-induced degeneration observed herein is expected to be found in a broad class of machine learning via neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2008.10498v5</guid>
      <category>nlin.AO</category>
      <category>cs.LG</category>
      <category>math.DS</category>
      <category>nlin.CD</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuzuru Sato, Daiji Tsutsui, Akio Fujiwara</dc:creator>
    </item>
    <item>
      <title>ICO learning as a measure of transient chaos in PT-symmetric Li\'enard systems</title>
      <link>https://arxiv.org/abs/2405.08414</link>
      <description>arXiv:2405.08414v1 Announce Type: cross 
Abstract: In this article, we investigate the implications of the unsupervised learning rule known as Input-Correlations (ICO) learning in the nonlinear dynamics of two linearly coupled PT-symmetric Li\'enard oscillators. The fixed points of the oscillator have been evaluated analytically and the Jacobian linearization is employed to study their stability. We find that on increasing the amplitude of the external periodic drive, the system exhibits period-doubling cascade to chaos within a specific parametric regime wherein we observe emergent chaotic dynamics. We further notice that the system indicates an intermittency route to chaos in the chaotic regime. Finally, in the period-4 regime of our bifurcation analysis, we predict the emergence of transient chaos which eventually settles down to a period-2 oscillator response which has been further validated by both the maximal Finite-Time Lyapunov Exponent (FTLE) using the well-known Gram-Schmidt orthogonalization technique and the Hilbert Transform of the time-series. In the transiently chaotic regime, we deploy the ICO learning to analyze the time-series from which we identify that when the chaotic evolution transforms into periodic dynamics, the synaptic weight associated with the time-series of the loss oscillator exhibits stationary temporal evolution. This signifies that in the periodic regime, there is no overlap between the filtered signals obtained from the time-series of the coupled PT-symmetric oscillators. In addition, the temporal evolution of the weight associated with the stimulus mimics the behaviour of the Hilbert transform of the time-series.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.08414v1</guid>
      <category>nlin.AO</category>
      <category>nlin.CD</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>J. P. Deka, A. Govindarajan, A. K. Sarma</dc:creator>
    </item>
    <item>
      <title>Universal replication of chaotic characteristics by classical and quantum machine learning</title>
      <link>https://arxiv.org/abs/2405.08484</link>
      <description>arXiv:2405.08484v1 Announce Type: cross 
Abstract: Replicating chaotic characteristics of non-linear dynamics by machine learning (ML) has recently drawn wide attentions. In this work, we propose that a ML model, trained to predict the state one-step-ahead from several latest historic states, can accurately replicate the bifurcation diagram and the Lyapunov exponents of discrete dynamic systems. The characteristics for different values of the hyper-parameters are captured universally by a single ML model, while the previous works considered training the ML model independently by fixing the hyper-parameters to be specific values. Our benchmarks on the one- and two-dimensional Logistic maps show that variational quantum circuit can reproduce the long-term characteristics with higher accuracy than the long short-term memory (a well-recognized classical ML model). Our work reveals an essential difference between the ML for the chaotic characteristics and that for standard tasks, from the perspective of the relation between performance and model complexity. Our results suggest that quantum circuit model exhibits potential advantages on mitigating over-fitting, achieving higher accuracy and stability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.08484v1</guid>
      <category>quant-ph</category>
      <category>cs.LG</category>
      <category>nlin.CD</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sheng-Chen Bai, Shi-Ju Ran</dc:creator>
    </item>
    <item>
      <title>Minimal Model for Reservoir Computing</title>
      <link>https://arxiv.org/abs/2312.01089</link>
      <description>arXiv:2312.01089v3 Announce Type: replace-cross 
Abstract: A minimal model for reservoir computing is studied. We demonstrate that a reservoir computer exists that emulates given coupled maps by constructing a modularized network. We describe a possible mechanism for collapses of the emulation in the reservoir computing by introducing a measure of finite scale deviation. Such transitory behaviour is caused by either (i) an escape from a finite-time stagnation near an unstable chaotic set, or (ii) a critical transition driven by the effective parameter drift. Our approach reveals the essential mechanism for reservoir computing and provides insights into the design of reservoir computer for practical applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.01089v3</guid>
      <category>nlin.AO</category>
      <category>nlin.CD</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuzuru Sato, Miki Kobayashi</dc:creator>
    </item>
  </channel>
</rss>
