<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 27 May 2025 04:02:46 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Closed Bounded Rational Framing Motions</title>
      <link>https://arxiv.org/abs/2505.18199</link>
      <description>arXiv:2505.18199v1 Announce Type: new 
Abstract: We present a method for constructing all bounded rational motions that frame a space curve $\mathbf{r}(t)$. This means that the motion guides an orthogonal frame along the curve such that one frame axis is in direction of the curve tangent. Existence of (bounded) framing motions is equivalent to $\mathbf{r}(t)$ being a (bounded) rational Pythagorean Hodograph curve. In contrast to previous constructions that rely on polynomial curves with smooth self-intersection, our motions and curves are infinitely differentiable. To this end, we develop the theory of Pythagorean hodograph curves parameterized over the projective line. We also provide a simple geometric necessary and sufficient condition on the spherical part of the motion, given by the homogeneous quaternionic preimage of the Pythagorean hodograph curve, that ensures the existence of a corresponding bounded, rational, and even regular framing motion. The translation part comes from the speed distribution, which must be a special positive rational function. This can in practice be ensured by semidefinite optimization methods. We illustrate our findings with a number of examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18199v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hans-Peter Schr\"ocker, Zbyn\v{e}k \v{S}\'ir</dc:creator>
    </item>
    <item>
      <title>Departure time choice user equilibrium for public transport demand management</title>
      <link>https://arxiv.org/abs/2505.18202</link>
      <description>arXiv:2505.18202v1 Announce Type: new 
Abstract: Departure time management is an efficient way in addressing the peak-hour crowding in public transport by reducing the temporal imbalance between service supply and travel demand. From the demand management perspective, the problem is to determine an equilibrium distribution of departure times for which no user can reduce their generalized cost by changing their departure times unilaterally. This study introduces the departure time choice user equilibrium problem in public transport (DTUE-PT) for multi-line, schedule-based networks with hard train capacity constraints. We model the DTUE-PT problem as a Non-linear Mathematical Program problem (NMP) (minimizing the system gap) with a simulation model describing the complex system dynamics and passenger interactions. We develop an efficient, adaptive gap-based descent direction (AdaGDD) solution algorithm to solve the NMP problem. We validate the methodology on a multi-line public transport network with transfers by comparing with classical public transport assignment benchmark models, including Method of Successive Average (MSA) and day-to-day learning methods. The results show that the model can achieve a system gap ratio (the solution gap relative to the ideal least cost of an origin-destination option) of 0.1926, which significantly improves the solution performance from day-to-day learning (85%) and MSA (76%) algorithms. The sensitivity analysis highlights the solution stability of AdaGDD method over initial solution settings. The potential use of DTUE-PT model is demonstrated for evaluating the network design of Hong Kong mass transit railway network and can be easily extended to incorporate the route choice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18202v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xia Zhou, Zhenliang Ma, Mark Wallace, Daniel D. Harabor</dc:creator>
    </item>
    <item>
      <title>Stationary Solution of p-Order Cloud Model via Stochastic Recurrence Equation</title>
      <link>https://arxiv.org/abs/2505.18203</link>
      <description>arXiv:2505.18203v1 Announce Type: new 
Abstract: This paper investigates the generative mechanism of the p-order cloud model, which is a mathematical framework for representing uncertainty with applications in image processing, evaluation, and decision-making systems. By employing a reparameterization technique, we reformulate the cloud model as a stochastic recurrence equation (SRE) with a nonlinear transformation involving an absolute value. Under standard assumptions of stationarity, ergodicity, and an appropriate integrability condition, we establish the existence and uniqueness of a stationary solution. In particular, we demonstrate that the logarithmic moment of the model's coefficient, modeled as a standard normal random variable, is negative, thereby ensuring almost sure convergence. These results provide new insights into the stochastic stability of cloud models and offer a rigorous foundation for further theoretical and practical developments in uncertainty quantification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18203v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Biao Hu, Minyue Wang</dc:creator>
    </item>
    <item>
      <title>Source identification via pathwise gradient estimation</title>
      <link>https://arxiv.org/abs/2505.18205</link>
      <description>arXiv:2505.18205v1 Announce Type: new 
Abstract: In the context of PDE-constrained optimization theory, source identification problems traditionally entail particles emerging from an unknown source distribution inside a domain, moving according to a prescribed stochastic process, e.g.~Brownian motion, and then exiting through the boundary of a compact domain. Given information about the flux of particles through the boundary of the domain, the challenge is to infer as much as possible about the source.
  In the PDE setting, it is usually assumed that the flux can be observed without error and at all points on the boundary. Here we consider a different, more statistical presentation of the model, in which the data has the form of discrete counts of particles arriving at a set of disjoint detectors whose union is a strict subset of the boundary. In keeping with the primacy of the stochastic processes in the generation of the model, we present a gradient descent algorithm in which exit rates and parameter sensitivities are computed by simulations of particle paths. We present examples for both It\^o diffusion and piecewise-deterministic Markov processes, noting that the form of the sensitivities depends only on the parameterization of the source distribution and is universal among a large class of Markov processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18205v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Richard B. Lehoucq, Scott A. McKinley, Petr Plech\'a\v{c}</dc:creator>
    </item>
    <item>
      <title>Optimal Control of Covid-19 Interventions in Public Health Management</title>
      <link>https://arxiv.org/abs/2505.18209</link>
      <description>arXiv:2505.18209v1 Announce Type: new 
Abstract: This study explores the application of Pontryagin's Maximum Principle to derive optimal strategies for controlling the spread of COVID-19, leveraging a novel compartmental model to capture the disease dynamics. We prioritize three key criteria: cost, effectiveness, and feasibility, each examined independently to evaluate their unique contributions to pandemic management. By addressing these criteria, this study aims to design intervention strategies that are scientifically robust, practical, and economically sustainable. Furthermore, the focus on cost, effectiveness and feasibility seeks to provide policymakers with actionable insights for implementing interventions that maximize public health benefits while remaining feasible under real-world conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18209v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Isabella Kemajou-Brown, Romario Gildas Foko Tiomela, Olawale Nasiru Lawal, Samson Adekola Alagbe, Serges Love Teutu Talla</dc:creator>
    </item>
    <item>
      <title>Hamiltonian Theory and Computation of Optimal Probability Density Control in High Dimensions</title>
      <link>https://arxiv.org/abs/2505.18362</link>
      <description>arXiv:2505.18362v1 Announce Type: new 
Abstract: We develop a general theoretical framework for optimal probability density control and propose a numerical algorithm that is scalable to solve the control problem in high dimensions. Specifically, we establish the Pontryagin Maximum Principle (PMP) for optimal density control and construct the Hamilton-Jacobi-Bellman (HJB) equation of the value functional through rigorous derivations without any concept from Wasserstein theory. To solve the density control problem numerically, we propose to use reduced-order models, such as deep neural networks (DNNs), to parameterize the control vector-field and the adjoint function, which allows us to tackle problems defined on high-dimensional state spaces. We also prove several convergence properties of the proposed algorithm. Numerical results demonstrate promising performances of our algorithm on a variety of density control problems with obstacles and nonlinear interaction challenges in high dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18362v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nathan Gaby, Xiaojing Ye</dc:creator>
    </item>
    <item>
      <title>Convergence of Proximal Policy Gradient Method for Problems with Control Dependent Diffusion Coefficients</title>
      <link>https://arxiv.org/abs/2505.18379</link>
      <description>arXiv:2505.18379v1 Announce Type: new 
Abstract: We prove convergence of the proximal policy gradient method for a class of constrained stochastic control problems with control in both the drift and diffusion of the state process. The problem requires either the running or terminal cost to be strongly convex, but other terms may be non-convex. The inclusion of control-dependent diffusion introduces additional complexity in regularity analysis of the associated backward stochastic differential equation. We provide sufficient conditions under which the control iterates converge linearly to the optimal control, by deriving representations and estimates of solutions to the adjoint backward stochastic differential equations. We introduce numerical algorithms that implement this method using deep learning and ordinary differential equation based techniques. These approaches enable high accuracy and scalability for stochastic control problems in higher dimensions. We provide numerical examples to demonstrate the accuracy and validate the theoretical convergence guarantees of the algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18379v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ashley Davey, Harry Zheng</dc:creator>
    </item>
    <item>
      <title>Infrastructure Planning for Inductive Charging in Electrified Shuttle Systems</title>
      <link>https://arxiv.org/abs/2505.18403</link>
      <description>arXiv:2505.18403v1 Announce Type: new 
Abstract: In response to climate goals, growing environmental awareness, and financial incentives, municipalities increasingly seek to electrify public transportation networks. We study the problem of locating stationary and dynamic inductive charging stations for electric vehicles (EVs), allowing detours from fixed transit routes and schedules. Dynamic charging, which enables energy transfer while driving, reduces space usage in dense urban areas and lowers vehicle idle times. We formulate a cost-minimization problem that considers both infrastructure and operational costs and propose an Iterated Local Search (ILS) algorithm to solve instances of realistic size. Each configuration requires solving a decomposed subproblem comprising multiple resource-constrained shortest-path problems. For this, we employ a bi-directional label-setting algorithm with lazy dominance checks based on local bounds. On adapted benchmark instances, our approach outperforms a commercial solver by up to 60% in solution quality. We further apply our method to a real-world case study in Hof, Germany. Results indicate that, under current cost structures calibrated from a test track in Bad Staffelstein, dynamic inductive charging is not yet cost-competitive with stationary alternatives. We quantify the value of allowing detours at up to 3.5% of the total system cost and show that integrating photovoltaics with decentralized energy storage can yield savings exceeding 20%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18403v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paul Bischoff, Salma Hammani, Maximilian Schiffer</dc:creator>
    </item>
    <item>
      <title>Scalable Global Optimization for AC-OPF via Quadratic Convex Relaxation and Branch-and-Bound</title>
      <link>https://arxiv.org/abs/2505.18435</link>
      <description>arXiv:2505.18435v1 Announce Type: new 
Abstract: The Optimal Power Flow (OPF) problem is central to the reliable and efficient operation of power systems, yet its non-convex nature poses significant challenges for finding globally optimal solutions. While convex relaxation techniques such as Quadratic Convex (QC) relaxation have shown promise in providing tight lower bounds, they typically do not guarantee global optimality. Conversely, global optimization methods like the Branch and Bound (B\&amp;B) algorithm can ensure optimality but often suffer from high computational costs due to the large search space involved. This paper proposes a novel B\&amp;B-assisted QC relaxation framework for solving the AC-OPF problem that leverages the strengths of both approaches. The method systematically partitions the domains of key OPF variables, specifically, voltage magnitudes and voltage angle differences, into two equal subintervals at each iteration. The QC relaxation is then applied to each subregion to compute a valid lower bound. These bounds are compared against an upper bound obtained from a feasible AC-OPF solution identified at the outset. Subregions that yield lower bounds exceeding the upper bound are pruned from the search, eliminating non-promising portions of the feasible space. By integrating the efficiency of the QC relaxation with the global search structure of the B\&amp;B algorithm, the proposed method significantly reduces the number of subproblems explored while preserving the potential to reach the global optimum. The algorithm is implemented using the PowerModels.jl package and evaluated on a range of PGLib-OPF benchmark cases. Results demonstrate that this hybrid strategy improves computational tractability and solution quality, particularly for large OPF instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18435v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammadreza Iranpour, Mohammad Rasoul Narimani</dc:creator>
    </item>
    <item>
      <title>PDPO: Parametric Density Path Optimization</title>
      <link>https://arxiv.org/abs/2505.18473</link>
      <description>arXiv:2505.18473v1 Announce Type: new 
Abstract: We introduce Parametric Density Path Optimization (PDPO), a novel method for computing action-minimizing paths between probability densities. The core idea is to represent the target probability path as the pushforward of a reference density through a parametric map, transforming the original infinite-dimensional optimization over densities to a finite-dimensional one over the parameters of the map. We derive a static formulation of the dynamic problem of action minimization and propose cubic spline interpolation of the path in parameter space to solve the static problem. Theoretically, we establish an error bound of the action under proper assumptions on the regularity of the parameter path. Empirically, we find that using 3-5 control points of the spline interpolation suffices to accurately resolve both multimodal and high-dimensional problems. We demonstrate that PDPO can flexibly accommodate a wide range of potential terms, including those modeling obstacles, mean-field interactions, stochastic control, and higher-order dynamics. Our method outperforms existing state-of-the-art approaches in benchmark tasks, demonstrating superior computational efficiency and solution quality. The source code will be publically available after the revision process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18473v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sebastian Gutierrez Hernandez, Peng Chen, Haomin Zhou</dc:creator>
    </item>
    <item>
      <title>Convergence rate of vanishing viscosity approximations to mean field games with non-separable Hamiltonians</title>
      <link>https://arxiv.org/abs/2505.18529</link>
      <description>arXiv:2505.18529v1 Announce Type: new 
Abstract: This paper studies the vanishing viscosity approximation to mean field games (MFGs) in $\mathbb{R}^d$ with a nonlocal and possibly non-separable Hamiltonian. We prove that the value function converges at a rate of $\mathcal{O}(\beta)$, where $\beta^2$ is the diffusivity constant, which matches the classical convergence rate of vanishing viscosity for Hamilton-Jacobi (HJ) equations. The same rate is also obtained for the approximation of the distribution of players as well as for the gradient of the value function. The proof is a combination of probabilistic and analytical arguments by first analyzing the forward-backward stochastic differential equation associated with the MFG, and then applying a general stability result for HJ equations. Applications of our result to $N$-player games, mean field control, and policy iteration for solving MFGs are also presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18529v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <category>math.PR</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Winston Yu, Qiang Du, Wenpin Tang</dc:creator>
    </item>
    <item>
      <title>Convergence rates for polynomial optimization on set products</title>
      <link>https://arxiv.org/abs/2505.18580</link>
      <description>arXiv:2505.18580v1 Announce Type: new 
Abstract: We consider polynomial optimization problems on Cartesian products of basic compact semialgebraic sets. The solution of such problems can be approximated as closely as desired by hierarchies of semidefinite programming relaxations, based on classical sums of squares certificates due to Putinar and Schm\"udgen. When the feasible set is the bi-sphere, i.e., the Cartesian product of two unit spheres, we show that the hierarchies based on the Schm\"udgen-type certificates converge to the global minimum of the objective polynomial at a rate in $O(1/t^2)$, where $t$ is the relaxation order. Our proof is based on the polynomial kernel method. We extend this result to arbitrary sphere products and give a general recipe to obtain convergence rates for polynomial optimization over products of distinct sets. Eventually, we rely on our results for the bi-sphere to analyze the speed of convergence of a semidefinite programming hierarchy approximating the order $2$ quantum Wasserstein distance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18580v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Victor Magron</dc:creator>
    </item>
    <item>
      <title>The Optimal Ratio of a Generalized Chaos Game in Regular Polytopes</title>
      <link>https://arxiv.org/abs/2505.18669</link>
      <description>arXiv:2505.18669v1 Announce Type: new 
Abstract: This paper investigates the concept of an optimal ratio for regular polytopes in $n$-dimensional space within the framework of the Generalized Chaos Game. The optimal ratio, $r_{\text{opt}}$, is defined as the value at which the self-similar regions of the resulting fractal touch but do not overlap. Using a series of Python simulations, we explore how the optimal ratio varies across different polytopes, from two-dimensional polygons to three-dimensional polyhedra and beyond. The results, visualized through plots generated for various polytopes and values of the scaling factor $r$, demonstrate that the optimal ratio is not universal but rather depends on each polytope's specific properties. A formula is then derived for determining the optimal ratio for any regular polytope in any dimension. The formula is then experimentally verified using multiple Python programs designed to search and find the optimal ratio iteratively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18669v1</guid>
      <category>math.OC</category>
      <category>math.MG</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christoffer Tarmet</dc:creator>
    </item>
    <item>
      <title>Asymptotic Efficiency Analysis of the Recursive Least-Squares Algorithm for ARX Systems Without Projection</title>
      <link>https://arxiv.org/abs/2505.19124</link>
      <description>arXiv:2505.19124v1 Announce Type: new 
Abstract: This paper investigates the optimality analysis of the recursive least-squares (RLS) algorithm for autoregressive systems with exogenous inputs (ARX systems). A key challenge in analyzing is managing the potential unboundedness of the parameter estimates, which may diverge to infinity. Previous approaches addressed this issue by assuming that both the true parameter and the RLS estimates remain confined within a known compact set, thereby ensuring uniform boundedness throughout the analysis. In contrast, we propose a new analytical framework that eliminates the need for such a boundness assumption. Specifically, we establish a quantitative relationship between the bounded moment conditions of quasi-stationary input/output signals and the convergence rate of the tail probability of the RLS estimation error. Based on this technique, we prove that when system inputs/outputs have bounded twentieth-order moments, the RLS algorithm achieves asymptotic normality and the covariance matrix of the RLS algorithm converges to the Cram\'er-Rao lower bound (CRLB), confirming its asymptotic efficiency. These results demonstrate that the RLS algorithm is an asymptotically optimal identification algorithm for ARX systems, even without the projection operators to ensure that parameter estimates reside within a prior known compact set.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19124v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xingrui Liu, Jieming Ke, Yanlong Zhao</dc:creator>
    </item>
    <item>
      <title>Two-component controller design to safeguard data-driven predictive control</title>
      <link>https://arxiv.org/abs/2505.19131</link>
      <description>arXiv:2505.19131v1 Announce Type: new 
Abstract: We design a two-component controller to achieve reference tracking with output constraints - exemplified on systems of relative degree two. One component is a data-driven or learning-based predictive controller, which uses data samples to learn a model and predict the future behavior of the system. We exemplify this component concisely by data-enabled predictive control (DeePC) and by model predictive control based on extended dynamic mode decomposition (EDMD). The second component is a model-free high-gain feedback controller, which ensures satisfaction of the output constraints if that cannot be guaranteed by the predictive controller. This may be the case, for example, if too little data has been collected for learning or no (sufficient) guarantees on the approximation accuracy derived. In particular, the reactive/adaptive feedback controller can be used to support the learning process by leading safely through the state space to collect suitable data, e.g., to ensure a sufficiently-small fill distance. Numerical examples are provided to illustrate the combination of EDMD-based model predictive control and a safeguarding feedback for the set-point transitions including the transition between the set points within prescribed bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19131v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Lea Bold, Lukas Lanza, Karl Worthmann</dc:creator>
    </item>
    <item>
      <title>Moment Relaxations for Data-Driven Wasserstein Distributionally Robust Optimization</title>
      <link>https://arxiv.org/abs/2505.19278</link>
      <description>arXiv:2505.19278v1 Announce Type: new 
Abstract: We propose moment relaxations for data-driven Wasserstein distributionally robust optimization problems. Conditions are identified to ensure asymptotic consistency of such relaxations for both single-stage and two-stage problems, together with examples that illustrate their necessity. Numerical experiments are also included to illustrate the proposed relaxations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19278v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shixuan Zhang, Suhan Zhong</dc:creator>
    </item>
    <item>
      <title>Fractional-Boundary-Regularized Deep Galerkin Method for Variational Inequalities in Mixed Optimal Stopping and Control</title>
      <link>https://arxiv.org/abs/2505.19309</link>
      <description>arXiv:2505.19309v1 Announce Type: new 
Abstract: Mixed optimal stopping and stochastic control problems define variational inequalities with non-linear Hamilton-Jacobi-Bellman (HJB) operators, whose numerical solution is notoriously difficult and lack of reliable benchmarks. We first use the dual approach to transform it into a linear operator, and then introduce a Fractional-Boundary-Regularized Deep Galerkin Method (FBR-DGM) that augments the classical $L^2$ loss with Sobolev-Slobodeckij norms on the parabolic boundary, enforcing regularity and yielding consistent improvements in the network approximation and its derivatives. The improved accuracy allows the network to be converted back to the original solution using the dual transform. The self-consistency and stability of the network can be tested by checking the primal-dual relationship among optimal value, optimal wealth, and optimal control, offering innovative benchmarks in the absence of analytical solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19309v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yun Zhao, Harry Zheng</dc:creator>
    </item>
    <item>
      <title>Retrospective Approximation Sequential Quadratic Programming for Stochastic Optimization with General Deterministic Nonlinear Constraints</title>
      <link>https://arxiv.org/abs/2505.19382</link>
      <description>arXiv:2505.19382v1 Announce Type: new 
Abstract: In this paper, we propose a framework based on the Retrospective Approximation (RA) paradigm to solve optimization problems with a stochastic objective function and general nonlinear deterministic constraints. This framework sequentially constructs increasingly accurate approximations of the true problems which are solved to a specified accuracy via a deterministic solver, thereby decoupling the uncertainty from the optimization. Such frameworks retain the advantages of deterministic optimization methods, such as fast convergence, while achieving the optimal performance of stochastic methods without the need to redesign algorithmic components. For problems with general nonlinear equality constraints, we present a framework that can employ any deterministic solver and analyze its theoretical work complexity. We then present an instance of the framework that employs a deterministic Sequential Quadratic Programming (SQP) method and that achieves optimal complexity in terms of gradient evaluations and linear system solves for this class of problems. For problems with general nonlinear constraints, we present an RA-based algorithm that employs an SQP method with robust subproblems. Finally, we demonstrate the empirical performance of the proposed framework on multi-class logistic regression problems and benchmark instances from the CUTEst test set, comparing its results to established methods from the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19382v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Albert S. Berahas, Raghu Bollapragada, Shagun Gupta</dc:creator>
    </item>
    <item>
      <title>Split-as-a-Pro: behavioral control via operator splitting and alternating projections</title>
      <link>https://arxiv.org/abs/2505.19411</link>
      <description>arXiv:2505.19411v1 Announce Type: new 
Abstract: The paper introduces Split-as-a-Pro, a control framework that integrates behavioral systems theory, operator splitting methods, and alternating projection algorithms. The framework reduces dynamic optimization problems - arising in both control and estimation - to efficient projection computations. Split-as-a-Pro builds on a non-parametric formulation that exploits system structure to separate dynamic constraints imposed by individual subsystems from external ones, such as interconnection constraints and input/output constraints. This enables the use of arbitrary system representations, as long as the associated projection is efficiently computable, thereby enhancing scalability and compatibility with gray-box modeling. We demonstrate the effectiveness of Split-as-a-Pro by developing a distributed algorithm for solving finite-horizon linear quadratic control problems and illustrate its use in predictive control. Our numerical case studies show that algorithms obtained using Split-as-a-Pro significantly outperform their centralized counterparts in runtime and scalability across various standard graph topologies, while seamlessly leveraging both model-based and data-driven system representations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19411v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yu Tang, Carlo Cenedese, Alessio Rimoldi, Florian D\'orfler, John Lygeros, Alberto Padoan</dc:creator>
    </item>
    <item>
      <title>Direct Pseudospectral Optimal Control by Orthogonal Polynomial Integral Collocation</title>
      <link>https://arxiv.org/abs/2505.19454</link>
      <description>arXiv:2505.19454v1 Announce Type: new 
Abstract: This paper details a methodology to transcribe an optimal control problem into a nonlinear program for generation of the trajectories that optimize a given functional by approximating only the highest order derivatives of a given system's dynamics. The underlying method uses orthogonal polynomial integral collocation by which successive integrals are taken to approximate all lower order states. Hence, one set of polynomial coefficients can represent an entire coordinate's degree of freedom. Specifically, Chebyshev polynomials of the first and second kind and Legendre polynomials are used over their associated common interpolating grids derived from the bases' roots and extrema. Simple example problems compare different polynomial bases' performance to analytical solutions. The planar circular orbit raising problem is used to verify the method with solutions obtained by other pseudospectral methods in literature. Finally, a rocket landing flip maneuver problem is solved to demonstrate the ability to solve complex problems with multiple states and control variables with constraints. Simulations establish this method's performance, and reveal that the polynomial/node choice for a given problem notably affects the performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19454v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas L. Ahrens, Ian M. Down, Manoranjan Majji</dc:creator>
    </item>
    <item>
      <title>A Path Planning Algorithm for a Hybrid UAV Traveling in Noise Restricted Zones</title>
      <link>https://arxiv.org/abs/2505.19506</link>
      <description>arXiv:2505.19506v1 Announce Type: new 
Abstract: This paper presents an integrated approach for efficient path planning and energy management in hybrid unmanned aerial vehicles (HUAVs) equipped with dual fuel-electric propulsion systems. These HUAVs operate in environments that include noise-restricted zones, referred to as quiet zones, where only electric mode is permitted. We address the problem by parameterizing the position of a point along the side of the quiet zone using its endpoints and a scalar parameter, transforming the problem into a variant of finding the shortest path over a graph of convex sets. We formulate this problem as a mixed-integer convex program (MICP), which can be efficiently solved using commercial solvers. Additionally, a tight lower bound can be obtained by relaxing the path-selection variable. Through extensive computations across 200 instances over four maps, we show a substantial improvement in computational efficiency over a state-of-the-art method, achieving up to a 100-fold and 10-fold decrease in computation time for calculating the lower bound and the exact solution, respectively. Moreover, the average gap between the exact cost and the lower bound was approximately 0.24%, and the exact cost was 1.05% lower than the feasible solution from the state-of-the-art approach on average, highlighting the effectiveness of our method. We also extend our approach to plan the HUAV route to visit a set of targets and return to its starting location in environments with quiet zones, yielding a Traveling Salesman Problem (TSP). We employ two methodologies to solve the TSP: one where the SOC at each target is discretized, and another where it is assumed to be the minimum allowable level upon departure. A comparative analysis reveals the second method achieves a cost within 1.02% of the first on average while requiring significantly less computational time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19506v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Saurabh Belgaonkar, Deepak Prakash Kumar, Sivakumar Rathinam, Swaroop Darbha, Trevor Bihl</dc:creator>
    </item>
    <item>
      <title>Probabilistic Analysis of Graphon Mean Field Control</title>
      <link>https://arxiv.org/abs/2505.19664</link>
      <description>arXiv:2505.19664v1 Announce Type: new 
Abstract: Motivated by recent interest in graphon mean field games and their applications, this paper provides a comprehensive probabilistic analysis of graphon mean field control (GMFC) problems, where the controlled dynamics are governed by a graphon mean field stochastic differential equation with heterogeneous mean field interactions. We formulate the GMFC problem with general graphon mean field dependence and establish the existence and uniqueness of the associated graphon mean field forward-backward stochastic differential equations (FBSDEs). We then derive a version of the Pontryagin stochastic maximum principle tailored to GMFC problems. Furthermore, we analyze the solvability of the GMFC problem for linear dynamics and study the continuity and stability of the graphon mean field FBSDEs under the optimal control profile. Finally, we show that the solution to the GMFC problem provides an approximately optimal solution for large systems with heterogeneous mean field interactions, based on a propagation of chaos result.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19664v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhongyuan Cao, Mathieu Lauri\`ere</dc:creator>
    </item>
    <item>
      <title>Model Predictive Online Monitoring of Dynamical Systems for Nested Signal Temporal Logic Specifications</title>
      <link>https://arxiv.org/abs/2505.19703</link>
      <description>arXiv:2505.19703v1 Announce Type: new 
Abstract: This paper investigates the online monitoring problem for cyber-physical systems under signal temporal logic (STL) specifications. The objective is to design an online monitor that evaluates system correctness at runtime based on partial signal observations up to the current time so that alarms can be issued whenever the specification is violated or will inevitably be violated in the future. We consider a model-predictive setting where the system's dynamic model is available and can be leveraged to enhance monitoring accuracy. However, existing approaches are limited to a restricted class of STL formulae, permitting only a single application of temporal operators. This work addresses the challenge of nested temporal operators in the design of model-predictive monitors. Our method utilizes syntax tree structures to resolve dependencies between temporal operators and introduces the concept of basic satisfaction vectors. A new model-predictive monitoring algorithm is proposed by recursively updating these vectors online while incorporating pre-computed satisfaction regions derived from offline model analysis. We prove that the proposed approach is both sound and complete, ensuring no false alarms or missed alarms. Case studies are provided to demonstrate the effectiveness of our method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19703v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tao Han, Shaoyuan Li, Xiang Yin</dc:creator>
    </item>
    <item>
      <title>Efficient globalization of heavy-ball type methods for unconstrained optimization based on curve searches</title>
      <link>https://arxiv.org/abs/2505.19705</link>
      <description>arXiv:2505.19705v1 Announce Type: new 
Abstract: In this work, we deal with unconstrained nonlinear optimization problems. Specifically, we are interested in methods carrying out updates possibly along directions not of descent, like Polyak's heavy-ball algorithm. Instead of enforcing convergence properties through line searches and modifications of search direction when suitable safeguards are not satisfied, we propose a strategy based on searches along curve paths: a curve search starting from the first tentative update allows to smoothly revert towards a gradient-related direction if a sufficient decrease condition is not met. The resulting algorithm provably possesses global convergence guarantees, even with a nonmonotone decrease condition. While the presented framework is rather general, particularly of interest is the case of parabolic searches; in this case, under reasonable assumptions, the resulting algorithm can be shown to possess optimal worst case complexity bounds for reaching approximate stationarity in nonconvex settings. Practically, we show that the proposed globalization strategy allows to consistently accept (optimal) pure heavy-ball steps in the strongly convex case, while standard globalization approaches would at times negate them before even evaluating the objective function. Preliminary computational experiments also suggest that the proposed framework might be more convenient than classical safeguard based approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19705v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Federica Donnini, Matteo Lapucci, Pierluigi Mansueto</dc:creator>
    </item>
    <item>
      <title>A Structured Tour of Optimization with Finite Differences</title>
      <link>https://arxiv.org/abs/2505.19720</link>
      <description>arXiv:2505.19720v1 Announce Type: new 
Abstract: Finite-difference methods are widely used for zeroth-order optimization in settings where gradient information is unavailable or expensive to compute. These procedures mimic first-order strategies by approximating gradients through function evaluations along a set of random directions. From a theoretical perspective, recent studies indicate that imposing structure (such as orthogonality) on the chosen directions allows for the derivation of convergence rates comparable to those achieved with unstructured random directions (i.e., directions sampled independently from a distribution). Empirically, although structured directions are expected to enhance performance, they often introduce additional computational costs, which can limit their applicability in high-dimensional settings. In this work, we examine the impact of structured direction selection in finite-difference methods. We review and extend several strategies for constructing structured direction matrices and compare them with unstructured approaches in terms of computational cost, gradient approximation quality, and convergence behavior. Our evaluation spans both synthetic tasks and real-world applications such as adversarial perturbation. The results demonstrate that structured directions can be generated with computational costs comparable to unstructured ones while significantly improving gradient estimation accuracy and optimization performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19720v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marco Rando, Cesare Molinari, Lorenzo Rosasco, Silvia Villa</dc:creator>
    </item>
    <item>
      <title>Local near-quadratic convergence of Riemannian interior point methods</title>
      <link>https://arxiv.org/abs/2505.19724</link>
      <description>arXiv:2505.19724v1 Announce Type: new 
Abstract: We consider Riemannian optimization problems with inequality and equality constraints and analyze a class of Riemannian interior point methods for solving them. The algorithm of interest consists of outer and inner iterations. We show that, under standard assumptions, the algorithm achieves local superlinear convergence by solving a linear system at each outer iteration, removing the need for further computations in the inner iterations. We also provide a specific update for the barrier parameters that achieves local near-quadratic convergence of the algorithm. We apply our results to the method proposed by Obara, Okuno, and Takeda (2025) and show its local superlinear and near-quadratic convergence with an analysis of the second-order stationarity. To our knowledge, this is the first algorithm for constrained optimization on Riemannian manifolds that achieves both local convergence and global convergence to a second-order stationary point.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19724v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mitsuaki Obara, Takayuki Okuno, Akiko Takeda</dc:creator>
    </item>
    <item>
      <title>Signed Angle Rigid Graphs for Network Localization and Formation Control</title>
      <link>https://arxiv.org/abs/2505.19945</link>
      <description>arXiv:2505.19945v1 Announce Type: new 
Abstract: Graph rigidity theory studies the capability of a graph embedded in the Euclidean space to constrain its global geometric shape via local constraints among nodes and edges, and has been widely exploited in network localization and formation control. In recent years, the traditional rigidity theory has been extended by considering new types of local constraints such as bearing, angle, ratio of distance, etc. Among them, the signed angle constraint received extensive attention since it is practically measurable and independent of the global coordinate frame. However, existing studies on signed angle rigidity always consider special graph structures, which are actually not necessary. This paper presents a comprehensive combinatorial analysis in terms of graphs and angle index sets for signed angle rigidity. We show that Laman graphs equivalently characterize minimally signed angle rigid graphs. Moreover, we propose a method to construct the minimal set of signed angle constraints in a Laman graph to effectively ensure signed angle rigidity. These results are finally applied to distributed network localization and formation stabilization problems, respectively, where each agent only has access to signed angle measurements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19945v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinpeng Huang, Gangshan Jing</dc:creator>
    </item>
    <item>
      <title>Investment Decisions for Perfect and Imperfect Competition in Ireland's Electricity Market</title>
      <link>https://arxiv.org/abs/2505.20077</link>
      <description>arXiv:2505.20077v1 Announce Type: new 
Abstract: This paper employs a game-theoretic approach to analyze investment decisions in Ireland's electricity market. It compares optimal electricity investment strategies among energy generators under a perfect competition framework with an imperfect Nash-Cournot competition. The model incorporates market price based on competition among generators while accounting for the supply capacity of each firm and each technology, along with the System Non-Synchronous Penetration (SNSP) constraint to reflect operational limitations in renewable energy contribution to the power system. Both models are formulated as single-objective function optimization problems. Furthermore, unit commitment constraints are introduced to the perfect competition model, allowing the model to incorporate binary decision variables to capture energy unit scheduling decisions of online status, startup, and shutdown costs. The proposed models are evaluated under three different demand test cases, using Ireland's electricity generation projections for 2023 to 2033. The results highlight key differences in investment decisions, carbon emissions, and the contribution of renewable technologies in perfect and imperfect competition structures. The findings provide managerial insights for policymakers and stakeholders, supporting optimal investment decisions and generation capacity planning to achieve Ireland's long-term energy objectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20077v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Davoud Hosseinnezhad, Mel T. Devine, Se\'an McGarraghy</dc:creator>
    </item>
    <item>
      <title>On Model Predictive Funnel Control with Equilibrium Endpoint Constraints</title>
      <link>https://arxiv.org/abs/2505.20090</link>
      <description>arXiv:2505.20090v1 Announce Type: new 
Abstract: We propose model predictive funnel control, a novel model predictive control (MPC) scheme building upon recent results in funnel control. The latter is a high-gain feedback methodology that achieves evolution of the measured output within predefined error margins. The proposed method dynamically optimizes a parameter-dependent error boundary in a receding-horizon manner, thereby combining prescribed error guarantees from funnel control with the predictive advantages of MPC. On the one hand, this approach promises faster optimization times due to a reduced number of decision variables, whose number does not depend on the horizon length. On the other hand, the continuous feedback law improves the robustness and also explicitly takes care of the inter-sampling behavior. We focus on proving stability by leveraging results from MPC stability theory with terminal equality constraints. Moreover, we rigorously show initial and recursive feasibility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20090v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jens G\"obel, Dario Dennst\"adt, Lukas Lanza, Karl Worthmann, Thomas Berger, Tobias Damm</dc:creator>
    </item>
    <item>
      <title>Preference Disaggregation Analysis with Criteria Selection in a Regularization Framework</title>
      <link>https://arxiv.org/abs/2505.20111</link>
      <description>arXiv:2505.20111v1 Announce Type: new 
Abstract: Limited by cognitive abilities, decision-makers (DMs) may struggle to evaluate decision alternatives based on all criteria in multiple criteria decision-making problems. This paper proposes an embedded criteria selection method derived from preference disaggregation technique and regularization theory. The method aims to infer the criteria and value functions used by the DM to evaluate decision alternatives. It measures the quality of criteria subsets by investigating both the empirical error (fitting ability of value functions to preference information) and generalization error (complexity of value functions). Unlike existing approaches that consider only the deviation from linearity as a measure of complexity, we argue that the number of marginal value functions also affects complexity. To address this, we use 0-1 variables to indicate whether a criterion is selected in the value function or not, and construct a criteria selection model with the trade-off between empirical and generalization errors as the objective function. If the criteria are sufficiently discriminative, we identify all supporting criteria sets that can restore preference information without unnecessary criteria. We further analyze the likelihood of criteria being selected by the DM. Finally, the effectiveness of the proposed method is demonstrated by applying it to an example of the green supplier selection problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20111v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kun Zhou, Zaiwu Gong, Guo Wei, Roman Slowinski</dc:creator>
    </item>
    <item>
      <title>New Perspectives on the Polyak Stepsize: Surrogate Functions and Negative Results</title>
      <link>https://arxiv.org/abs/2505.20219</link>
      <description>arXiv:2505.20219v1 Announce Type: new 
Abstract: The Polyak stepsize has been proven to be a fundamental stepsize in convex optimization, giving near optimal gradient descent rates across a wide range of assumptions. The universality of the Polyak stepsize has also inspired many stochastic variants, with theoretical guarantees and strong empirical performance. Despite the many theoretical results, our understanding of the convergence properties and shortcomings of the Polyak stepsize or its variants is both incomplete and fractured across different analyses. We propose a new, unified, and simple perspective for the Polyak stepsize and its variants as gradient descent on a surrogate loss. We show that each variant is equivalent to minimize a surrogate function with stepsizes that adapt to a guaranteed local curvature. Our general surrogate loss perspective is then used to provide a unified analysis of existing variants across different assumptions. Moreover, we show a number of negative results proving that the non-convergence results in some of the upper bounds is indeed real.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20219v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Francesco Orabona, Ryan D'Orazio</dc:creator>
    </item>
    <item>
      <title>Representative Action Selection for Large Action-Space Meta-Bandits</title>
      <link>https://arxiv.org/abs/2505.18269</link>
      <description>arXiv:2505.18269v1 Announce Type: cross 
Abstract: We study the problem of selecting a subset from a large action space shared by a family of bandits, with the goal of achieving performance nearly matching that of using the full action space. We assume that similar actions tend to have related payoffs, modeled by a Gaussian process. To exploit this structure, we propose a simple epsilon-net algorithm to select a representative subset. We provide theoretical guarantees for its performance and compare it empirically to Thompson Sampling and Upper Confidence Bound.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18269v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Quan Zhou, Mark Kozdoba, Shie Mannor</dc:creator>
    </item>
    <item>
      <title>Online Statistical Inference of Constrained Stochastic Optimization via Random Scaling</title>
      <link>https://arxiv.org/abs/2505.18327</link>
      <description>arXiv:2505.18327v1 Announce Type: cross 
Abstract: Constrained stochastic nonlinear optimization problems have attracted significant attention for their ability to model complex real-world scenarios in physics, economics, and biology. As datasets continue to grow, online inference methods have become crucial for enabling real-time decision-making without the need to store historical data. In this work, we develop an online inference procedure for constrained stochastic optimization by leveraging a method called Sketched Stochastic Sequential Quadratic Programming (SSQP). As a direct generalization of sketched Newton methods, SSQP approximates the objective with a quadratic model and the constraints with a linear model at each step, then applies a sketching solver to inexactly solve the resulting subproblem. Building on this design, we propose a new online inference procedure called random scaling. In particular, we construct a test statistic based on SSQP iterates whose limiting distribution is free of any unknown parameters. Compared to existing online inference procedures, our approach offers two key advantages: (i) it enables the construction of asymptotically valid confidence intervals; and (ii) it is matrix-free, i.e. the computation involves only primal-dual SSQP iterates $(\boldsymbol{x}_t, \boldsymbol{\lambda}_t)$ without requiring any matrix inversions. We validate our theory through numerical experiments on nonlinearly constrained regression problems and demonstrate the superior performance of our random scaling method over existing inference procedures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18327v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xinchen Du, Wanrong Zhu, Wei Biao Wu, Sen Na</dc:creator>
    </item>
    <item>
      <title>Sampled-data Systems: Stability, Contractivity and Single-iteration Suboptimal MPC</title>
      <link>https://arxiv.org/abs/2505.18336</link>
      <description>arXiv:2505.18336v1 Announce Type: cross 
Abstract: This paper analyzes the stability of interconnected continuous-time (CT) and discrete-time (DT) systems coupled through sampling and zero-order hold mechanisms. The DT system updates its output at regular intervals $T&gt;0$ by applying an $n$-fold composition of a given map. This setup is motivated by online and sampled-data implementations of optimization-based controllers - particularly model predictive control (MPC) - where the DT system models $n$ iterations of an algorithm approximating the solution of an optimization problem.
  We introduce the concept of a reduced model, defined as the limiting behavior of the sampled-data system as $T \to 0^+$ and $n \to +\infty$. Our main theoretical contribution establishes that when the reduced model is contractive, there exists a threshold duration $T(n)$ for each iteration count $n$ such that the CT-DT interconnection achieves exponential stability for all sampling periods $T &lt; T(n)$. Finally, under the stronger condition that both the CT and DT systems are contractive, we show exponential stability of their interconnection using a small-gain argument. Our theoretical results provide new insights into suboptimal MPC stability, showing that convergence guarantees hold even when using a single iteration of the optimization algorithm - a practically significant finding for real-time control applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18336v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yiting Chen, Francesco Bullo, Emiliano Dall'Anese</dc:creator>
    </item>
    <item>
      <title>A Dual Basis Approach for Structured Robust Euclidean Distance Geometry</title>
      <link>https://arxiv.org/abs/2505.18414</link>
      <description>arXiv:2505.18414v1 Announce Type: cross 
Abstract: Euclidean Distance Matrix (EDM), which consists of pairwise squared Euclidean distances of a given point configuration, finds many applications in modern machine learning. This paper considers the setting where only a set of anchor nodes is used to collect the distances between themselves and the rest. In the presence of potential outliers, it results in a structured partial observation on EDM with partial corruptions. Note that an EDM can be connected to a positive semi-definite Gram matrix via a non-orthogonal dual basis. Inspired by recent development of non-orthogonal dual basis in optimization, we propose a novel algorithmic framework, dubbed Robust Euclidean Distance Geometry via Dual Basis (RoDEoDB), for recovering the Euclidean distance geometry, i.e., the underlying point configuration. The exact recovery guarantees have been established in terms of both the Gram matrix and point configuration, under some mild conditions. Empirical experiments show superior performance of RoDEoDB on sensor localization and molecular conformation datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18414v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chandra Kundu, Abiy Tasissa, HanQin Cai</dc:creator>
    </item>
    <item>
      <title>AMG with Filtering: An Efficient Preconditioner for Interior Point Methods in Large-Scale Contact Mechanics Optimization</title>
      <link>https://arxiv.org/abs/2505.18576</link>
      <description>arXiv:2505.18576v1 Announce Type: cross 
Abstract: Large-scale contact mechanics simulations are crucial in many engineering fields such as structural design and manufacturing. In the frictionless case, contact can be modeled by minimizing an energy functional; however, these problems are often nonlinear, non-convex, and increasingly difficult to solve as mesh resolution increases. In this work, we employ a Newton-based interior-point (IP) filter line-search method; an effective approach for large-scale constrained optimization. While this method converges rapidly, each iteration requires solving a large saddle-point linear system that becomes ill-conditioned as the optimization process converges, largely due to IP treatment of the contact constraints. Such ill-conditioning can hinder solver scalability and increase iteration counts with mesh refinement. To address this, we introduce a novel preconditioner, AMG with Filtering (AMGF), tailored to the Schur complement of the saddle-point system. Building on the classical algebraic multigrid (AMG) solver, commonly used for elasticity, we augment it with a specialized subspace correction that filters near null space components introduced by contact interface constraints. Through theoretical analysis and numerical experiments on a range of linear and nonlinear contact problems, we demonstrate that the proposed solver achieves mesh independent convergence and maintains robustness against the ill-conditioning that notoriously plagues IP methods. These results indicate that AMGF makes contact mechanics simulations more tractable and broadens the applicability of Newton-based IP methods in challenging engineering scenarios. More broadly, AMGF is well suited for problems, optimization or otherwise, where solver performance is limited by a problematic low-dimensional subspace. This makes the method widely applicable beyond contact mechanics and constrained optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18576v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Socratis Petrides, Tucker Hartland, Tzanio Kolev, Chak Shing Lee, Michael Puso, Jerome Solberg, Eric B. Chin, Jingyi Wang, Cosmin Petra</dc:creator>
    </item>
    <item>
      <title>Agent-Based Decentralized Energy Management of EV Charging Station with Solar Photovoltaics via Multi-Agent Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2505.18750</link>
      <description>arXiv:2505.18750v1 Announce Type: cross 
Abstract: In the pursuit of energy net zero within smart cities, transportation electrification plays a pivotal role. The adoption of Electric Vehicles (EVs) keeps increasing, making energy management of EV charging stations critically important. While previous studies have managed to reduce energy cost of EV charging while maintaining grid stability, they often overlook the robustness of EV charging management against uncertainties of various forms, such as varying charging behaviors and possible faults in faults in some chargers. To address the gap, a novel Multi-Agent Reinforcement Learning (MARL) approach is proposed treating each charger to be an agent and coordinate all the agents in the EV charging station with solar photovoltaics in a more realistic scenario, where system faults may occur. A Long Short-Term Memory (LSTM) network is incorporated in the MARL algorithm to extract temporal features from time-series. Additionally, a dense reward mechanism is designed for training the agents in the MARL algorithm to improve EV charging experience. Through validation on a real-world dataset, we show that our approach is robust against system uncertainties and faults and also effective in minimizing EV charging costs and maximizing charging service satisfaction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18750v1</guid>
      <category>eess.SY</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/ISC260477.2024.11004246</arxiv:DOI>
      <dc:creator>Jiarong Fan, Chenghao Huang, Hao Wang</dc:creator>
    </item>
    <item>
      <title>LORE: Lagrangian-Optimized Robust Embeddings for Visual Encoders</title>
      <link>https://arxiv.org/abs/2505.18884</link>
      <description>arXiv:2505.18884v1 Announce Type: cross 
Abstract: Visual encoders have become fundamental components in modern computer vision pipelines. However, ensuring robustness against adversarial perturbations remains a critical challenge. Recent efforts have explored both supervised and unsupervised adversarial fine-tuning strategies. We identify two key limitations in these approaches: (i) they often suffer from instability, especially during the early stages of fine-tuning, resulting in suboptimal convergence and degraded performance on clean data, and (ii) they exhibit a suboptimal trade-off between robustness and clean data accuracy, hindering the simultaneous optimization of both objectives. To overcome these challenges, we propose Lagrangian-Optimized Robust Embeddings (LORE), a novel unsupervised adversarial fine-tuning framework. LORE utilizes constrained optimization, which offers a principled approach to balancing competing goals, such as improving robustness while preserving nominal performance. By enforcing embedding-space proximity constraints, LORE effectively maintains clean data performance throughout adversarial fine-tuning. Extensive experiments show that LORE significantly improves zero-shot adversarial robustness with minimal degradation in clean data accuracy. Furthermore, we demonstrate the effectiveness of the adversarially fine-tuned CLIP image encoder in out-of-distribution generalization and enhancing the interpretability of image embeddings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18884v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Borna Khodabandeh, Amirabbas Afzali, Amirhossein Afsharrad, Seyed Shahabeddin Mousavi, Sanjay Lall, Sajjad Amini, Seyed-Mohsen Moosavi-Dezfooli</dc:creator>
    </item>
    <item>
      <title>Structured Reinforcement Learning for Combinatorial Decision-Making</title>
      <link>https://arxiv.org/abs/2505.19053</link>
      <description>arXiv:2505.19053v1 Announce Type: cross 
Abstract: Reinforcement learning (RL) is increasingly applied to real-world problems involving complex and structured decisions, such as routing, scheduling, and assortment planning. These settings challenge standard RL algorithms, which struggle to scale, generalize, and exploit structure in the presence of combinatorial action spaces. We propose Structured Reinforcement Learning (SRL), a novel actor-critic framework that embeds combinatorial optimization layers into the actor neural network. We enable end-to-end learning of the actor via Fenchel-Young losses and provide a geometric interpretation of SRL as a primal-dual algorithm in the dual of the moment polytope. Across six environments with exogenous and endogenous uncertainty, SRL matches or surpasses the performance of unstructured RL and imitation learning on static tasks and improves over these baselines by up to 92% on dynamic problems, with improved stability and convergence speed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19053v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Heiko Hoppe, L\'eo Baty, Louis Bouvier, Axel Parmentier, Maximilian Schiffer</dc:creator>
    </item>
    <item>
      <title>Distributionally Robust Deep Q-Learning</title>
      <link>https://arxiv.org/abs/2505.19058</link>
      <description>arXiv:2505.19058v1 Announce Type: cross 
Abstract: We propose a novel distributionally robust $Q$-learning algorithm for the non-tabular case accounting for continuous state spaces where the state transition of the underlying Markov decision process is subject to model uncertainty. The uncertainty is taken into account by considering the worst-case transition from a ball around a reference probability measure. To determine the optimal policy under the worst-case state transition, we solve the associated non-linear Bellman equation by dualising and regularising the Bellman operator with the Sinkhorn distance, which is then parameterized with deep neural networks. This approach allows us to modify the Deep Q-Network algorithm to optimise for the worst case state transition.
  We illustrate the tractability and effectiveness of our approach through several applications, including a portfolio optimisation task based on S\&amp;{P}~500 data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19058v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>q-fin.PM</category>
      <category>stat.ML</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chung I Lu, Julian Sester, Aijia Zhang</dc:creator>
    </item>
    <item>
      <title>Statistical inference for Linear Stochastic Approximation with Markovian Noise</title>
      <link>https://arxiv.org/abs/2505.19102</link>
      <description>arXiv:2505.19102v1 Announce Type: cross 
Abstract: In this paper we derive non-asymptotic Berry-Esseen bounds for Polyak-Ruppert averaged iterates of the Linear Stochastic Approximation (LSA) algorithm driven by the Markovian noise. Our analysis yields $\mathcal{O}(n^{-1/4})$ convergence rates to the Gaussian limit in the Kolmogorov distance. We further establish the non-asymptotic validity of a multiplier block bootstrap procedure for constructing the confidence intervals, guaranteeing consistent inference under Markovian sampling. Our work provides the first non-asymptotic guarantees on the rate of convergence of bootstrap-based confidence intervals for stochastic approximation with Markov noise. Moreover, we recover the classical rate of order $\mathcal{O}(n^{-1/8})$ up to logarithmic factors for estimating the asymptotic variance of the iterates of the LSA algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19102v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sergey Samsonov, Marina Sheshukova, Eric Moulines, Alexey Naumov</dc:creator>
    </item>
    <item>
      <title>Computational Inertia as a Conserved Quantity in Frictionless and Damped Learning Dynamics</title>
      <link>https://arxiv.org/abs/2505.19171</link>
      <description>arXiv:2505.19171v1 Announce Type: cross 
Abstract: We identify a conserved quantity in continuous-time optimization dynamics, termed computational inertia. Defined as the sum of kinetic energy (parameter velocity) and potential energy (loss), this scalar remains invariant under idealized, frictionless training. We formalize this conservation law, derive its analytic decay under damping and stochastic perturbations, and demonstrate its behavior in a synthetic system. The invariant offers a compact lens for interpreting learning trajectories, and may inform theoretical tools for analyzing convergence, stability, and training geometry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19171v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Atahan Karagoz</dc:creator>
    </item>
    <item>
      <title>Scaling Laws for Gradient Descent and Sign Descent for Linear Bigram Models under Zipf's Law</title>
      <link>https://arxiv.org/abs/2505.19227</link>
      <description>arXiv:2505.19227v1 Announce Type: cross 
Abstract: Recent works have highlighted optimization difficulties faced by gradient descent in training the first and last layers of transformer-based language models, which are overcome by optimizers such as Adam. These works suggest that the difficulty is linked to the heavy-tailed distribution of words in text data, where the frequency of the $k$th most frequent word $\pi_k$ is proportional to $1/k$, following Zipf's law. To better understand the impact of the data distribution on training performance, we study a linear bigram model for next-token prediction when the tokens follow a power law $\pi_k \propto 1/k^\alpha$ parameterized by the exponent $\alpha &gt; 0$. We derive optimization scaling laws for deterministic gradient descent and sign descent as a proxy for Adam as a function of the exponent $\alpha$. Existing theoretical investigations in scaling laws assume that the eigenvalues of the data decay as a power law with exponent $\alpha &gt; 1$. This assumption effectively makes the problem ``finite dimensional'' as most of the loss comes from a few of the largest eigencomponents. In comparison, we show that the problem is more difficult when the data have heavier tails. The case $\alpha = 1$ as found in text data is ``worst-case'' for gradient descent, in that the number of iterations required to reach a small relative error scales almost linearly with dimension. While the performance of sign descent also depends on the dimension, for Zipf-distributed data the number of iterations scales only with the square-root of the dimension, leading to a large improvement for large vocabularies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19227v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Frederik Kunstner, Francis Bach</dc:creator>
    </item>
    <item>
      <title>Alignment of large language models with constrained learning</title>
      <link>https://arxiv.org/abs/2505.19387</link>
      <description>arXiv:2505.19387v1 Announce Type: cross 
Abstract: We study the problem of computing an optimal large language model (LLM) policy for a constrained alignment problem, where the goal is to maximize a primary reward objective while satisfying constraints on secondary utilities. Despite the popularity of Lagrangian-based LLM policy search in constrained alignment, iterative primal-dual methods often fail to converge, and non-iterative dual-based methods do not achieve optimality in the LLM parameter space. To address these challenges, we employ Lagrangian duality to develop an iterative dual-based alignment method that alternates between updating the LLM policy via Lagrangian maximization and updating the dual variable via dual descent. In theory, we characterize the primal-dual gap between the primal value in the distribution space and the dual value in the LLM parameter space. We further quantify the optimality gap of the learned LLM policies at near-optimal dual variables with respect to both the objective and the constraint functions. These results prove that dual-based alignment methods can find an optimal constrained LLM policy, up to an LLM parametrization gap. We demonstrate the effectiveness and merits of our approach through extensive experiments conducted on the PKU-SafeRLHF dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19387v1</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Botong Zhang, Shuo Li, Ignacio Hounie, Osbert Bastani, Dongsheng Ding, Alejandro Ribeiro</dc:creator>
    </item>
    <item>
      <title>Navigating loss manifolds via rigid body dynamics: A promising avenue for robustness and generalisation</title>
      <link>https://arxiv.org/abs/2505.19527</link>
      <description>arXiv:2505.19527v1 Announce Type: cross 
Abstract: Training large neural networks through gradient-based optimization requires navigating high-dimensional loss landscapes, which often exhibit pathological geometry, leading to undesirable training dynamics. In particular, poor generalization frequently results from convergence to sharp minima that are highly sensitive to input perturbations, causing the model to overfit the training data while failing to generalize to unseen examples. Furthermore, these optimization procedures typically display strong dependence on the fine structure of the loss landscape, leading to unstable training dynamics, due to the fractal-like nature of the loss surface. In this work, we propose an alternative optimizer that simultaneously reduces this dependence, and avoids sharp minima, thereby improving generalization. This is achieved by simulating the motion of the center of a ball rolling on the loss landscape. The degree to which our optimizer departs from the standard gradient descent is controlled by a hyperparameter, representing the radius of the ball. Changing this hyperparameter allows for probing the loss landscape at different scales, making it a valuable tool for understanding its geometry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19527v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammed D. Belgoumri, Mohamed Reda Bouadjenek, Hakim Hacid, Imran Razzak, Sunil Aryal</dc:creator>
    </item>
    <item>
      <title>Situationally-Aware Dynamics Learning</title>
      <link>https://arxiv.org/abs/2505.19574</link>
      <description>arXiv:2505.19574v1 Announce Type: cross 
Abstract: Autonomous robots operating in complex, unstructured environments face significant challenges due to latent, unobserved factors that obscure their understanding of both their internal state and the external world. Addressing this challenge would enable robots to develop a more profound grasp of their operational context. To tackle this, we propose a novel framework for online learning of hidden state representations, with which the robots can adapt in real-time to uncertain and dynamic conditions that would otherwise be ambiguous and result in suboptimal or erroneous behaviors. Our approach is formalized as a Generalized Hidden Parameter Markov Decision Process, which explicitly models the influence of unobserved parameters on both transition dynamics and reward structures. Our core innovation lies in learning online the joint distribution of state transitions, which serves as an expressive representation of latent ego- and environmental-factors. This probabilistic approach supports the identification and adaptation to different operational situations, improving robustness and safety. Through a multivariate extension of Bayesian Online Changepoint Detection, our method segments changes in the underlying data generating process governing the robot's dynamics. The robot's transition model is then informed with a symbolic representation of the current situation derived from the joint distribution of latest state transitions, enabling adaptive and context-aware decision-making. To showcase the real-world effectiveness, we validate our approach in the challenging task of unstructured terrain navigation, where unmodeled and unmeasured terrain characteristics can significantly impact the robot's motion. Extensive experiments in both simulation and real world reveal significant improvements in data efficiency, policy performance, and the emergence of safer, adaptive navigation strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19574v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alejandro Murillo-Gonzalez, Lantao Liu</dc:creator>
    </item>
    <item>
      <title>Solving Implicit Inverse Problems with Homotopy-Based Regularization Path</title>
      <link>https://arxiv.org/abs/2505.19608</link>
      <description>arXiv:2505.19608v1 Announce Type: cross 
Abstract: Implicit inverse problems, in which noisy observations of a physical quantity are used to infer a nonlinear functional applied to an associated function, are inherently ill posed and often exhibit non uniqueness of solutions. Such problems arise in a range of domains, including the identification of systems governed by Ordinary and Partial Differential Equations (ODEs/PDEs), optimal control, and data assimilation. Their solution is complicated by the nonlinear nature of the underlying constraints and the instability introduced by noise. In this paper, we propose a homotopy based optimization method for solving such problems. Beginning with a regularized constrained formulation that includes a sparsity promoting regularization term, we employ a gradient based algorithm in which gradients with respect to the model parameters are efficiently computed using the adjoint state method. Nonlinear constraints are handled through a Newton Raphson procedure. By solving a sequence of problems with decreasing regularization, we trace a solution path that improves stability and enables the exploration of multiple candidate solutions. The method is applied to the latent dynamics discovery problem in simulation, highlighting performance as a function of ground truth sparsity and semi convergence behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19608v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Davide Parodi, Federico Benvenuto, Sara Garbarino, Michele Piana</dc:creator>
    </item>
    <item>
      <title>A Formal Analysis of Algorithms for Matroids and Greedoids</title>
      <link>https://arxiv.org/abs/2505.19816</link>
      <description>arXiv:2505.19816v1 Announce Type: cross 
Abstract: We present a formal analysis, in Isabelle/HOL, of optimisation algorithms for matroids, which are useful generalisations of combinatorial structures that occur in optimisation, and greedoids, which are a generalisation of matroids. Although some formalisation work has been done earlier on matroids, our work here presents the first formalisation of results on greedoids, and many results we formalise in relation to matroids are also formalised for the first time in this work. We formalise the analysis of a number of optimisation algorithms for matroids and greedoids. We also derive from those algorithms executable implementations of Kruskal's algorithm for minimum spanning trees, an algorithm for maximum cardinality matching for bi-partite graphs, and Prim's algorithm for computing minimum weight spanning trees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19816v1</guid>
      <category>cs.LO</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad Abdulaziz, Thomas Ammer, Shriya Meenakshisundaram, Adem Rimpapa</dc:creator>
    </item>
    <item>
      <title>A Theoretical Framework for Grokking: Interpolation followed by Riemannian Norm Minimisation</title>
      <link>https://arxiv.org/abs/2505.20172</link>
      <description>arXiv:2505.20172v1 Announce Type: cross 
Abstract: We study the dynamics of gradient flow with small weight decay on general training losses $F: \mathbb{R}^d \to \mathbb{R}$. Under mild regularity assumptions and assuming convergence of the unregularised gradient flow, we show that the trajectory with weight decay $\lambda$ exhibits a two-phase behaviour as $\lambda \to 0$. During the initial fast phase, the trajectory follows the unregularised gradient flow and converges to a manifold of critical points of $F$. Then, at time of order $1/\lambda$, the trajectory enters a slow drift phase and follows a Riemannian gradient flow minimising the $\ell_2$-norm of the parameters. This purely optimisation-based phenomenon offers a natural explanation for the \textit{grokking} effect observed in deep learning, where the training loss rapidly reaches zero while the test loss plateaus for an extended period before suddenly improving. We argue that this generalisation jump can be attributed to the slow norm reduction induced by weight decay, as explained by our analysis. We validate this mechanism empirically on several synthetic regression tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20172v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Etienne Boursier, Scott Pesme, Radu-Alexandru Dragomir</dc:creator>
    </item>
    <item>
      <title>Stochastic Compositional Optimization with Compositional Constraints</title>
      <link>https://arxiv.org/abs/2209.04086</link>
      <description>arXiv:2209.04086v2 Announce Type: replace 
Abstract: Stochastic compositional optimization (SCO) has attracted considerable attention because of its broad applicability to important real-world problems. However, existing works on SCO assume that the projection within a solution update is simple, which fails to hold for problem instances where the constraints are in the form of expectations, such as empirical conditional value-at-risk constraints. We study a novel model that incorporates single-level expected value and two-level compositional constraints into the current SCO framework. Our model can be applied widely to data-driven optimization and risk management, including risk-averse optimization and high-moment portfolio selection, and can handle multiple constraints. We further propose a class of primal-dual algorithms that generates sequences converging to the optimal solution at the rate of $\cO(\frac{1}{\sqrt{N}})$under both single-level expected value and two-level compositional constraints, where $N$ is the iteration counter, establishing the benchmarks in expected value constrained SCO.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.04086v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuoguang Yang, Wei You, Zhe Zhang, Ethan X. Fang</dc:creator>
    </item>
    <item>
      <title>Feasible approximation of matching equilibria for large-scale matching for teams problems</title>
      <link>https://arxiv.org/abs/2308.03550</link>
      <description>arXiv:2308.03550v3 Announce Type: replace 
Abstract: We propose a numerical algorithm for computing approximately optimal solutions of the matching for teams problem. Our algorithm is efficient for problems involving large number of agent categories and allows for non-discrete agent type measures. Specifically, we parametrize the so-called transfer functions and develop a parametric formulation, which we tackle to produce feasible and approximately optimal primal and dual solutions. These solutions yield upper and lower bounds for the optimal value, and the difference between these bounds provides a sub-optimality estimate of the computed solutions. Moreover, we are able to control the sub-optimality to be arbitrarily close to 0. We subsequently prove that the approximate primal and dual solutions converge when the sub-optimality goes to 0 and their limits constitute a true matching equilibrium. Thus, the outputs of our algorithm are regarded as an approximate matching equilibrium. We also analyze the computational complexity of our approach. In the numerical experiments, we study three matching for teams problems: a business location distribution problem, the Wasserstein barycenter problem, and a large-scale problem involving 100 agent categories. We showcase that the proposed algorithm can produce high-quality approximate matching equilibria, provide quantitative insights about the optimal city structure in the business location distribution problem, and that the sub-optimality estimates computed by our algorithm are much less conservative than theoretical estimates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.03550v3</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ariel Neufeld, Qikun Xiang</dc:creator>
    </item>
    <item>
      <title>An inexact $q$-order regularized proximal Newton method for nonconvex composite optimization</title>
      <link>https://arxiv.org/abs/2311.06871</link>
      <description>arXiv:2311.06871v4 Announce Type: replace 
Abstract: This paper concerns the composite problem of minimizing the sum of a twice continuously differentiable function $f$ and a nonsmooth convex function. For this class of nonconvex and nonsmooth problems, by leveraging a practical inexactness criterion and a novel selection strategy for iterates, we propose an inexact $q$-order regularized proximal Newton method for $q\in[2,3]$, which becomes an inexact cubic regularization (CR) method for $q=3$. We prove that the whole iterate sequence converges to a stationary point for the KL objective function; and when the objective function has the KL property of exponent $\theta\in(0,\frac{q-1}{q})$, the convergence has a local $Q$-superlinear rate of order $\frac{q-1}{\theta q}$. In particular, under a local H\"{o}lderian error bound of order $\gamma\in(\frac{1}{q-1},1]$ on a second-order stationary point set, we show that the iterate and objective value sequences converge to a second-order stationary point and a second-order stationary value, respectively, with a local $Q$-superlinear rate of order $\gamma(q\!-\!1)$, specified as the $Q$-quadratic rate for $q=3$ and $\gamma=1$. This is the first practical inexact CR method with $Q$-quadratic convergence rate for nonconvex composite optimization. We validate the efficiency of the CR method with ZeroFPR as the inner solver by applying it to composite optimization problems with highly nonlinear $f$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.06871v4</guid>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ruyu Liu, Shaohua Pan, Yitian Qian</dc:creator>
    </item>
    <item>
      <title>Accelerated Gradient Methods with Gradient Restart: Global Linear Convergence</title>
      <link>https://arxiv.org/abs/2401.07672</link>
      <description>arXiv:2401.07672v2 Announce Type: replace 
Abstract: Gradient restarting has been shown to improve the numerical performance of accelerated gradient methods. This paper provides a mathematical analysis to understand these advantages. First, we establish global linear convergence guarantees for both the original and gradient restarted accelerated proximal gradient method when solving strongly convex composite optimization problems. Second, through analysis of the corresponding ordinary differential equation model, we prove the continuous trajectory of the gradient restarted Nesterov's accelerated gradient method exhibits global linear convergence for quadratic convex objectives, while the non-restarted version provably lacks this property by [Su, Boyd, and Cand\'es, \textit{J. Mach. Learn. Res.}, 2016, 17(153), 1-43].</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.07672v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chenglong Bao, Liang Chen, Jiahong Li, Zuowei Shen</dc:creator>
    </item>
    <item>
      <title>Scalarisation-based risk concepts for robust multi-objective optimisation</title>
      <link>https://arxiv.org/abs/2405.10221</link>
      <description>arXiv:2405.10221v4 Announce Type: replace 
Abstract: Robust optimisation is a well-established framework for optimising functions in the presence of uncertainty. The inherent goal of this problem is to identify a collection of inputs whose outputs are both desirable for the decision maker, whilst also being robust to the underlying uncertainties in the problem. In this work, we study the multi-objective case of this problem. We identify that the majority of all robust multi-objective algorithms rely on two key operations: robustification and scalarisation. Robustification refers to the strategy that is used to account for the uncertainty in the problem. Scalarisation refers to the procedure that is used to encode the relative importance of each objective to a scalar-valued reward. As these operations are not necessarily commutative, the order that they are performed in has an impact on the resulting solutions that are identified and the final decisions that are made. The purpose of this work is to give a thorough exposition on the effects of these different orderings and in particular highlight when one should opt for one ordering over the other. As part of our analysis, we showcase how many existing risk concepts can be integrated into the specification and solution of a robust multi-objective optimisation problem. Besides this, we also demonstrate how one can principally define the notion of a robust Pareto front and a robust performance metric based on our ``robustify and scalarise'' methodology. To illustrate the efficacy of these new ideas, we present two insightful case studies which are based on real-world data sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10221v4</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ben Tu, Nikolas Kantas, Robert M. Lee, Behrang Shafei</dc:creator>
    </item>
    <item>
      <title>(Un)supervised Learning of Maximal Lyapunov Functions</title>
      <link>https://arxiv.org/abs/2408.17246</link>
      <description>arXiv:2408.17246v2 Announce Type: replace 
Abstract: In this paper, we address the problem of discovering maximal Lyapunov functions, as a means of determining the region of attraction of a dynamical system. To this end, we design a novel neural network architecture, which we prove to be a universal approximator of (maximal) Lyapunov functions. The architecture combines a local quadratic approximation with the output of a neural network, which models global higher-order terms in the Taylor expansion. We formulate the problem of training the Lyapunov function as an unsupervised optimization problem with dynamical constraints, which can be solved leveraging techniques from physics-informed learning. We propose and analyze a tailored training algorithm, based on the primal-dual algorithm, that can efficiently solve the problem. Additionally, we show how the learning problem formulation can be adapted to integrate data, when available. We apply the proposed approach to different classes of systems, showing that it matches or outperforms state-of-the-art alternatives in the accuracy of the approximated regions of attraction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.17246v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matthieu Barreau, Nicola Bastianello</dc:creator>
    </item>
    <item>
      <title>Second-Order Constrained Dynamic Optimization</title>
      <link>https://arxiv.org/abs/2409.11649</link>
      <description>arXiv:2409.11649v3 Announce Type: replace 
Abstract: This paper provides an overview, analysis, and comparison of second-order dynamic optimization algorithms, i.e., constrained Differential Dynamic Programming (DDP) and Sequential Quadratic Programming (SQP). Although a variety of these algorithms have been proposed and used successfully, there exists a gap in understanding the key differences and advantages, which we aim to provide in this work. For constrained DDP, we choose methods that incorporate nonlinear programming techniques to handle state and control constraints, including Augmented Lagrangian (AL), Interior Point, Primal-Dual Augmented Lagrangian (PDAL), and Alternating Direction Method of Multipliers (ADMM). Both DDP and SQP are provided in single- and multiple-shooting formulations, where constraints that arise from dynamics are encoded implicitly and explicitly, respectively. As a byproduct of the review, we propose a single-shooting PDAL DDP that has more favorable properties than the standard AL variant, such as the robustness to the growth of penalty parameters. We perform extensive numerical experiments on a variety of systems with increasing complexity to investigate the quality of the solutions, the levels of constraint violation, and the sensitivity of final solutions with respect to initialization, as well as targets. The results show that single-shooting PDAL DDP and multiple-shooting SQP are the most robust methods. For multiple-shooting formulation, both DDP and SQP can enjoy informed initial guesses, while the latter appears to be more advantageous in complex systems. It is also worth highlighting that DDP provides favorable computational complexity and feedback gains as a byproduct of optimization as is.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.11649v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuichiro Aoyama, Oswin So, Augustinos D. Saravanos, Evangelos A. Theodorou</dc:creator>
    </item>
    <item>
      <title>Non-asymptotic convergence analysis of the stochastic gradient Hamiltonian Monte Carlo algorithm with discontinuous stochastic gradient with applications to training of ReLU neural networks</title>
      <link>https://arxiv.org/abs/2409.17107</link>
      <description>arXiv:2409.17107v2 Announce Type: replace 
Abstract: In this paper, we provide a non-asymptotic analysis of the convergence of the stochastic gradient Hamiltonian Monte Carlo (SGHMC) algorithm to a target measure in Wasserstein-1 and Wasserstein-2 distance. Crucially, compared to the existing literature on SGHMC, we allow its stochastic gradient to be discontinuous. This allows us to provide explicit upper bounds, which can be controlled to be arbitrarily small, for the expected excess risk of non-convex stochastic optimization problems with discontinuous stochastic gradients, including, among others, the training of neural networks with ReLU activation function. To illustrate the applicability of our main results, we consider numerical experiments on quantile estimation and on several optimization problems involving ReLU neural networks relevant in finance and artificial intelligence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.17107v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luxu Liang, Ariel Neufeld, Ying Zhang</dc:creator>
    </item>
    <item>
      <title>Neural Solver Selection for Combinatorial Optimization</title>
      <link>https://arxiv.org/abs/2410.09693</link>
      <description>arXiv:2410.09693v2 Announce Type: replace 
Abstract: Machine learning has increasingly been employed to solve NP-hard combinatorial optimization problems, resulting in the emergence of neural solvers that demonstrate remarkable performance, even with minimal domain-specific knowledge. To date, the community has created numerous open-source neural solvers with distinct motivations and inductive biases. While considerable efforts are devoted to designing powerful single solvers, our findings reveal that existing solvers typically demonstrate complementary performance across different problem instances. This suggests that significant improvements could be achieved through effective coordination of neural solvers at the instance level. In this work, we propose the first general framework to coordinate the neural solvers, which involves feature extraction, selection model, and selection strategy, aiming to allocate each instance to the most suitable solvers. To instantiate, we collect several typical neural solvers with state-of-the-art performance as alternatives, and explore various methods for each component of the framework. We evaluated our framework on two extensively studied combinatorial optimization problems, Traveling Salesman Problem (TSP) and Capacitated Vehicle Routing Problem (CVRP). Experimental results show that the proposed framework can effectively distribute instances and the resulting composite solver can achieve significantly better performance (e.g., reduce the optimality gap by 0.88\% on TSPLIB and 0.71\% on CVRPLIB) than the best individual neural solver with little extra time cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09693v2</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chengrui Gao, Haopu Shang, Ke Xue, Chao Qian</dc:creator>
    </item>
    <item>
      <title>Achieving $\tilde{\mathcal{O}}(1/N)$ Optimality Gap in Restless Bandits through Gaussian Approximation</title>
      <link>https://arxiv.org/abs/2410.15003</link>
      <description>arXiv:2410.15003v2 Announce Type: replace 
Abstract: We study the finite-horizon Restless Multi-Armed Bandit (RMAB) problem with $N$ homogeneous arms. Prior work has shown that when an RMAB satisfies a non-degeneracy condition, Linear-Programming-based (LP-based) policies derived from the fluid approximation, which captures the mean dynamics of the system, achieve an exponentially small optimality gap. However, it is common for RMABs to be degenerate, in which case LP-based policies can result in a $\Theta(1/\sqrt{N})$ optimality gap per arm. In this paper, we propose a novel Stochastic-Programming-based (SP-based) policy that, under a uniqueness assumption, achieves an $\tilde{\mathcal{O}}(1/N)$ optimality gap for degenerate RMABs. Our approach is based on the construction of a Gaussian stochastic system that captures not only the mean but also the variance of the RMAB dynamics, resulting in a more accurate approximation than the fluid approximation. We then solve a stochastic program for this system to obtain our policy. This is the first result to establish an $\tilde{\mathcal{O}}(1/N)$ optimality gap for degenerate RMABs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15003v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chen Yan, Weina Wang, Lei Ying</dc:creator>
    </item>
    <item>
      <title>Exact Verification of First-Order Methods via Mixed-Integer Linear Programming</title>
      <link>https://arxiv.org/abs/2412.11330</link>
      <description>arXiv:2412.11330v4 Announce Type: replace 
Abstract: We present exact mixed-integer linear programming formulations for verifying the performance of first-order methods for parametric quadratic optimization. We formulate the verification problem as a mixed-integer linear program where the objective is to maximize the infinity norm of the fixed-point residual after a given number of iterations. Our approach captures a wide range of gradient, projection, proximal iterations through affine or piecewise affine constraints. We derive tight polyhedral convex hull formulations of the constraints representing the algorithm iterations. To improve the scalability, we develop a custom bound tightening technique combining interval propagation, operator theory, and optimization-based bound tightening. Numerical examples, including linear and quadratic programs from network optimization, sparse coding using Lasso, and optimal control, show that our method provides several orders of magnitude reductions in the worst-case fixed-point residuals, closely matching the true worst-case performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.11330v4</guid>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vinit Ranjan, Jisun Park, Stefano Gualandi, Andrea Lodi, Bartolomeo Stellato</dc:creator>
    </item>
    <item>
      <title>Chance constraints transcription and failure risk estimation for stochastic trajectory optimization</title>
      <link>https://arxiv.org/abs/2502.15949</link>
      <description>arXiv:2502.15949v2 Announce Type: replace 
Abstract: Stochastic trajectory optimization ensures mission success under uncertainty by enforcing chance constraints. Transcription methods convert these into tractable deterministic forms, but existing approaches do not support general multidimensional constraints. We introduce three such methods: spectral radius, first-order, and d-th order with low conservatism. A risk estimation technique and conservatism metric enable systematic evaluation. Applied to aerospace scenarios, our methods outperform existing ones, with the d-th order transcription excelling in high-dimensional settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.15949v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Thomas Caleb, Roberto Armellin, Spencer Boone, St\'ephanie Lizy-Destrez</dc:creator>
    </item>
    <item>
      <title>Chance-Constrained Covariance Steering for Discrete-Time Markov Jump Linear Systems</title>
      <link>https://arxiv.org/abs/2503.13675</link>
      <description>arXiv:2503.13675v3 Announce Type: replace 
Abstract: In this paper, we propose a novel convex optimization framework to solve the optimal covariance steering problem for discrete-time Markov Jump Linear Systems (MJLS) with chance constraints. We derive the analytical expressions for the mean and covariance trajectories of time-varying discrete-time MJLS and show that they cannot be separated even without chance constraints, unlike the single-mode dynamics case. To solve the covariance steering problem, we propose a two-step convex optimization framework, which optimizes the mean and covariance subproblems sequentially. Further, we use Gaussian approximations to incorporate chance constraints and propose an iterative optimization framework to solve the chance-constrained covariance steering problem. Both problems are originally nonconvex, and we derive convex relaxations which are proved to be lossless at optimality using the Karush-Kuhn-Tucker (KKT) conditions. Numerical simulations demonstrate the proposed method by achieving target covariances while respecting chance constraints under Gaussian noise and Markovian jump dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13675v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shaurya Shrivastava, Kenshiro Oguri</dc:creator>
    </item>
    <item>
      <title>Rank-One Modified Value Iteration</title>
      <link>https://arxiv.org/abs/2505.01828</link>
      <description>arXiv:2505.01828v2 Announce Type: replace 
Abstract: In this paper, we provide a novel algorithm for solving planning and learning problems of Markov decision processes. The proposed algorithm follows a policy iteration-type update by using a rank-one approximation of the transition probability matrix in the policy evaluation step. This rank-one approximation is closely related to the stationary distribution of the corresponding transition probability matrix, which is approximated using the power method. We provide theoretical guarantees for the convergence of the proposed algorithm to optimal (action-)value function with the same rate and computational complexity as the value iteration algorithm in the planning problem and as the Q-learning algorithm in the learning problem. Through our extensive numerical simulations, however, we show that the proposed algorithm consistently outperforms first-order algorithms and their accelerated versions for both planning and learning problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01828v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Arman Sharifi Kolarijani, Tolga Ok, Peyman Mohajerin Esfahani, Mohamad Amin Sharif Kolarijani</dc:creator>
    </item>
    <item>
      <title>Dual Acceleration for Minimax Optimization: Linear Convergence Under Relaxed Assumptions</title>
      <link>https://arxiv.org/abs/2505.02115</link>
      <description>arXiv:2505.02115v2 Announce Type: replace 
Abstract: This paper addresses the bilinearly coupled minimax optimization problem: $\min_{x \in \mathbb{R}^{d_x}}\max_{y \in \mathbb{R}^{d_y}} \ f_1(x) + f_2(x) + y^{\top} Bx - g_1(y) - g_2(y)$, where $f_1$ and $g_1$ are smooth convex functions, $f_2$ and $g_2$ are potentially nonsmooth convex functions, and $B$ is a coupling matrix. Existing algorithms for solving this problem achieve linear convergence only under stronger conditions, which may not be met in many scenarios. We first introduce the Primal-Dual Proximal Gradient (PDPG) method and demonstrate that it converges linearly under an assumption where existing algorithms fail to achieve linear convergence. Building on insights gained from analyzing the convergence conditions of existing algorithms and PDPG, we further propose the inexact Dual Accelerated Proximal Gradient (iDAPG) method. This method achieves linear convergence under weaker conditions than those required by existing approaches. Moreover, even in cases where existing methods guarantee linear convergence, iDAPG can still provide superior theoretical performance in certain scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02115v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jingwang Li, Xiao Li</dc:creator>
    </item>
    <item>
      <title>Single-loop $\mathcal{O}(\epsilon^{-3})$ stochastic smoothing algorithms for nonsmooth Riemannian optimization</title>
      <link>https://arxiv.org/abs/2505.09485</link>
      <description>arXiv:2505.09485v2 Announce Type: replace 
Abstract: In this paper, we develop two Riemannian stochastic smoothing algorithms for nonsmooth optimization problems on Riemannian manifolds, addressing distinct forms of the nonsmooth term \( h \). Both methods combine dynamic smoothing with a momentum-based variance reduction scheme in a fully online manner. When \( h \) is Lipschitz continuous, we propose an stochastic algorithm under adaptive parameter that achieves the optimal iteration complexity of \( \mathcal{O}(\epsilon^{-3}) \), improving upon the best-known rates for exist algorithms. When \( h \) is the indicator function of a convex set, we design a new algorithm using truncated momentum, and under a mild error bound condition with parameter \( \theta \geq 1 \), we establish a complexity of \( \tilde{\mathcal{O}}(\epsilon^{-\max\{\theta+2, 2\theta\}}) \), in line with the best-known results in the Euclidean setting. Both algorithms feature a single-loop design with low per-iteration cost and require only \( \mathcal{O}(1) \) samples per iteration, ensuring that sample and iteration complexities coincide. Our framework encompasses a broad class of problems and recovers or matches optimal complexity guarantees in several important settings, including smooth stochastic Riemannian optimization, composite problems in Euclidean space, and constrained optimization via indicator functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09485v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kangkang Deng, Zheng Peng, Weihe Wu</dc:creator>
    </item>
    <item>
      <title>Convex NMPC reformulations for a special class of nonlinear multi-input systems with application to rank-one bilinear networks</title>
      <link>https://arxiv.org/abs/2304.08147</link>
      <description>arXiv:2304.08147v3 Announce Type: replace-cross 
Abstract: We show that a special class of (nonconvex) NMPC problems admits an exact solution by reformulating them as a finite number of convex subproblems, extending previous results to the multi-input case. Our approach is applicable to a special class of input-affine discrete-time systems, which includes a class of bilinear rank-one systems that is considered useful in modeling certain controlled networks. We illustrate our results with two numerical examples, including the aforementioned rank-one bilinear network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.08147v3</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.ifacol.2023.10.1321</arxiv:DOI>
      <dc:creator>Manuel Kl\"adtke, Moritz Schulze Darup</dc:creator>
    </item>
    <item>
      <title>Implicit predictors in regularized data-driven predictive control</title>
      <link>https://arxiv.org/abs/2307.10750</link>
      <description>arXiv:2307.10750v2 Announce Type: replace-cross 
Abstract: We introduce the notion of implicit predictors, which characterize the input-(state)-output prediction behavior underlying a predictive control scheme, even if it is not explicitly enforced as an equality constraint (as in traditional model or subspace predictive control). To demonstrate this concept, we derive and analyze implicit predictors for some basic data-driven predictive control (DPC) schemes, which offers a new perspective on this popular approach that may form the basis for modified DPC schemes and further theoretical insights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.10750v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/LCSYS.2023.3285104</arxiv:DOI>
      <arxiv:journal_reference>in IEEE Control Systems Letters, vol. 7, pp. 2479-2484, 2023</arxiv:journal_reference>
      <dc:creator>Manuel Kl\"adtke, Moritz Schulze Darup</dc:creator>
    </item>
    <item>
      <title>Computing the matrix exponential and the Cholesky factor of a related finite horizon Gramian</title>
      <link>https://arxiv.org/abs/2310.13462</link>
      <description>arXiv:2310.13462v3 Announce Type: replace-cross 
Abstract: In this article, an efficient numerical method for computing both the matrix exponential and a finite horizon controllability Gramian in Cholesky-factored form is proposed. The method is applicable to general dense matrices of moderate size and produces a Cholesky factor of the Gramian without computing the full product. It is a generalization of the scaling-and-squaring approach for approximating the matrix exponential and exploits a similar doubling formula for the Gramian to compute both at once. The required computational effort is thereby kept modest. Most importantly, a rigorous backward error analysis is provided, which guarantees that the approximation is accurate to the round-off error level in double precision. This accuracy is illustrated in practice on a large number of standard test examples. The method has been implemented in the Julia package FiniteHorizonGramians.jl, which is available online under the MIT license. Code for reproducing the experimental results is included in this package, as well as code for determining the optimal method parameters. The analysis can thus easily be adapted to a different finite-precision arithmetic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.13462v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tony Stillfjord, Filip Tronarp</dc:creator>
    </item>
    <item>
      <title>Fast Rerandomization via the BRAIN</title>
      <link>https://arxiv.org/abs/2312.17230</link>
      <description>arXiv:2312.17230v2 Announce Type: replace-cross 
Abstract: Randomized experiments are a crucial tool for causal inference in many different fields. Rerandomization addresses any covariate imbalance in such experiments by resampling treatment assignments until certain balance criteria are satisfied. However, rerandomization based on na\"ive acceptance-rejection sampling is computationally inefficient, especially when numerous independent assignments are required to perform randomization-based statistical inference. Existing acceleration methods are suboptimal and not applicable in structured experiments, including stratified and clustered experiments. Based on metaheuristics in integer programming, we propose BRAIN -- a novel computationally-lightweight methodology that ensures covariate balance in randomized experiments while significantly accelerating the computation. Our BRAIN method provides unbiased treatment effect estimators with reduced variance compared to complete randomization, preserving the desirable statistical properties of traditional rerandomization. Simulation studies and a real data example demonstrate the benefits of our method in fast sampling while retaining the appealing statistical guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.17230v2</guid>
      <category>stat.ME</category>
      <category>math.OC</category>
      <category>stat.CO</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiuyao Lu, Daogao Liu, Zhanran Lin, Xiaomeng Wang</dc:creator>
    </item>
    <item>
      <title>Stochastic Hessian Fittings with Lie Groups</title>
      <link>https://arxiv.org/abs/2402.11858</link>
      <description>arXiv:2402.11858v5 Announce Type: replace-cross 
Abstract: This report investigates the fitting of Hessian or its inverse for stochastic optimizations using a Hessian fitting criterion derived from the preconditioned stochastic gradient descent (PSGD) method. This criterion is closely related to many widely used second-order and adaptive gradient optimization methods, including BFGS, the Gauss-Newton algorithm, natural gradient descent, and AdaGrad. Our analyses reveal the efficiency and reliability differences of a broad range of preconditioner fitting methods, ranging from closed-form to iterative approaches, using Hessian-vector products or stochastic gradients only, with Hessian fittings across various geometric settings (the Euclidean space, the manifold of symmetric positive definite (SPD) matrices and a variety of Lie groups). The most intriguing finding is that the Hessian fitting problem is strongly convex under mild conditions in certain general Lie groups. This result turns the Hessian fitting into a well-behaved Lie group optimization problem and facilitates the designs of highly efficient and elegant Lie group sparse preconditioner fitting methods for large-scale stochastic optimizations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.11858v5</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xi-Lin Li</dc:creator>
    </item>
    <item>
      <title>A fast algorithm to minimize prediction loss of the optimal solution in inverse optimization problem of MILP</title>
      <link>https://arxiv.org/abs/2405.14273</link>
      <description>arXiv:2405.14273v3 Announce Type: replace-cross 
Abstract: We consider the inverse optimization problem of estimating the weights of the objective function such that the given solution is an optimal solution for a mixed integer linear program (MILP). In this inverse optimization problem, the known methods exhibit inefficient convergence. Specifically, if $d$ denotes the dimension of the weights and $k$ the number of iterations, then the error of the weights is bounded by $O(k^{-1/(d-1)})$, leading to slow convergence as $d$ increases. We propose a projected subgradient method with a step size of $k^{-1/2}$ based on suboptimality loss. We theoretically show and demonstrate that the proposed method efficiently learns the weights. In particular, we show that there exists a constant $\gamma &gt; 0$ such that the distance between the learned and true weights is bounded by $ O\left(k^{-1/(1+\gamma)} \exp\left(-\frac{\gamma k^{1/2}}{2+\gamma}\right)\right), $ or the optimal solution is exactly recovered. Furthermore, experiments demonstrate that the proposed method solves the inverse optimization problems of MILP using fewer than $1/7$ the number of MILP calls required by known methods, and converges within a finite number of iterations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14273v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Akira Kitaoka</dc:creator>
    </item>
    <item>
      <title>ScaleBiO: Scalable Bilevel Optimization for LLM Data Reweighting</title>
      <link>https://arxiv.org/abs/2406.19976</link>
      <description>arXiv:2406.19976v2 Announce Type: replace-cross 
Abstract: Bilevel optimization has shown its utility across various machine learning settings, yet most algorithms in practice require second-order information, making it challenging to scale them up. Only recently, a paradigm of first-order algorithms has emerged in the theoretical literature, capable of effectively addressing bilevel optimization problems. Nevertheless, the practical efficiency of this paradigm remains unverified, particularly in the context of large language models (LLMs). This paper introduces the first scalable instantiation of this paradigm called ScaleBiO, focusing on bilevel optimization for large-scale LLM data reweighting. By combining with a recently proposed memory-efficient training technique called LISA, our novel algorithm allows the paradigm to scale to $\sim$30B-sized LLMs on $8\times$H100 GPUs, marking the first successful application of bilevel optimization under practical scenarios for large-sized LLMs. Empirically, extensive experiments on data reweighting verify the effectiveness of ScaleBiO for different-scaled models, including Llama-3-8B, Gemma-2-9B, Qwen-2-7B, and Qwen-2.5-32B, where bilevel optimization succeeds in instruction-following and math reasoning tasks, outperforming several popular baselines, including uniform sampling, influence-aware data filtering, and reference-model-based sampling methods. Theoretically, ScaleBiO ensures the optimality of the learned data weights, along with a convergence guarantee matching the conventional first-order bilevel optimization paradigm on smooth and strongly convex objectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19976v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rui Pan, Dylan Zhang, Hanning Zhang, Xingyuan Pan, Minrui Xu, Jipeng Zhang, Renjie Pi, Xiaoyu Wang, Tong Zhang</dc:creator>
    </item>
    <item>
      <title>HPPP: Halpern-type Preconditioned Proximal Point Algorithms and Applications to Image Restoration</title>
      <link>https://arxiv.org/abs/2407.13120</link>
      <description>arXiv:2407.13120v4 Announce Type: replace-cross 
Abstract: Recently, the degenerate preconditioned proximal point (PPP) method provides a unified and flexible framework for designing and analyzing operator-splitting algorithms such as Douglas-Rachford (DR). However, the degenerate PPP method exhibits weak convergence in the infinite-dimensional Hilbert space and lacks accelerated variants. To address these issues, we propose a Halpern-type PPP (HPPP) algorithm, which leverages the strong convergence and acceleration properties of Halpern's iteration method. Moreover, we propose a novel algorithm for image restoration by combining HPPP with denoiser priors such as Plug-and-Play (PnP) prior, which can be viewed as an accelerated PnP method. Finally, numerical experiments including several toy examples and image restoration validate the effectiveness of our proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13120v4</guid>
      <category>cs.CV</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuchang Zhang, Hui Zhang, Hongxia Wang</dc:creator>
    </item>
    <item>
      <title>Variance-Reduced Cascade Q-learning: Algorithms and Sample Complexity</title>
      <link>https://arxiv.org/abs/2408.06544</link>
      <description>arXiv:2408.06544v2 Announce Type: replace-cross 
Abstract: We study the problem of estimating the optimal Q-function of $\gamma$-discounted Markov decision processes (MDPs) under the synchronous setting, where independent samples for all state-action pairs are drawn from a generative model at each iteration. We introduce and analyze a novel model-free algorithm called Variance-Reduced Cascade Q-learning (VRCQ). VRCQ comprises two key building blocks: (i) the established direct variance reduction technique and (ii) our proposed variance reduction scheme, Cascade Q-learning. By leveraging these techniques, VRCQ provides superior guarantees in the $\ell_\infty$-norm compared with the existing model-free stochastic approximation-type algorithms. Specifically, we demonstrate that VRCQ is minimax optimal. Additionally, when the action set is a singleton (so that the Q-learning problem reduces to policy evaluation), it achieves non-asymptotic instance optimality while requiring the minimum number of samples theoretically possible. Our theoretical results and their practical implications are supported by numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06544v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammad Boveiri, Peyman Mohajerin Esfahani</dc:creator>
    </item>
    <item>
      <title>Quantum algorithms for optimizers</title>
      <link>https://arxiv.org/abs/2408.07086</link>
      <description>arXiv:2408.07086v4 Announce Type: replace-cross 
Abstract: This is a set of lecture notes for a Ph.D.-level course on quantum algorithms, with an emphasis on quantum optimization algorithms. It is developed for applied mathematicians and engineers, and requires no previous background in quantum mechanics. The main topics of this course, in addition to a rigorous introduction to the computational model, are: input/output models, quantum search, the quantum gradient algorithm, matrix manipulation algorithms, the mirror descent framework for semidefinite optimization (including the matrix multiplicative weights update algorithm), adiabatic optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07086v4</guid>
      <category>quant-ph</category>
      <category>cs.DM</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giacomo Nannicini</dc:creator>
    </item>
    <item>
      <title>Solving Hidden Monotone Variational Inequalities with Surrogate Losses</title>
      <link>https://arxiv.org/abs/2411.05228</link>
      <description>arXiv:2411.05228v3 Announce Type: replace-cross 
Abstract: Deep learning has proven to be effective in a wide variety of loss minimization problems. However, many applications of interest, like minimizing projected Bellman error and min-max optimization, cannot be modelled as minimizing a scalar loss function but instead correspond to solving a variational inequality (VI) problem. This difference in setting has caused many practical challenges as naive gradient-based approaches from supervised learning tend to diverge and cycle in the VI case. In this work, we propose a principled surrogate-based approach compatible with deep learning to solve VIs. We show that our surrogate-based approach has three main benefits: (1) under assumptions that are realistic in practice (when hidden monotone structure is present, interpolation, and sufficient optimization of the surrogates), it guarantees convergence, (2) it provides a unifying perspective of existing methods, and (3) is amenable to existing deep learning optimizers like ADAM. Experimentally, we demonstrate our surrogate-based approach is effective in min-max optimization and minimizing projected Bellman error. Furthermore, in the deep reinforcement learning case, we propose a novel variant of TD(0) which is more compute and sample efficient.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05228v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ryan D'Orazio, Danilo Vucetic, Zichu Liu, Junhyung Lyle Kim, Ioannis Mitliagkas, Gauthier Gidel</dc:creator>
    </item>
    <item>
      <title>Lean and Mean Adaptive Optimization via Subset-Norm and Subspace-Momentum with Convergence Guarantees</title>
      <link>https://arxiv.org/abs/2411.07120</link>
      <description>arXiv:2411.07120v2 Announce Type: replace-cross 
Abstract: We introduce two complementary techniques for efficient optimization that reduce memory requirements while accelerating training of large-scale neural networks. The first technique, Subset-Norm step size, generalizes AdaGrad-Norm and AdaGrad(-Coordinate) through step-size sharing. Subset-Norm (SN) reduces AdaGrad's memory footprint from $O(d)$ to $O(\sqrt{d})$, where $d$ is the model size. For non-convex smooth objectives under coordinate-wise sub-gaussian noise, we show a noise-adapted high-probability convergence guarantee with improved dimensional dependence of SN over existing methods. Our second technique, Subspace-Momentum, reduces the momentum state's memory footprint by restricting momentum to a low-dimensional subspace while performing SGD in the orthogonal complement. We prove a high-probability convergence result for Subspace-Momentum under standard assumptions. Empirical evaluation on pre-training and fine-tuning LLMs demonstrates the effectiveness of our methods. For instance, combining Subset-Norm with Subspace-Momentum achieves Adam's validation perplexity for LLaMA 1B in approximately half the training tokens (6.8B vs 13.1B) while reducing Adam's optimizer-states memory footprint by more than 80\% with minimal additional hyperparameter tuning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07120v2</guid>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thien Hang Nguyen, Huy Le Nguyen</dc:creator>
    </item>
    <item>
      <title>Multi-Partite Output Regulation of Multi-Agent Systems</title>
      <link>https://arxiv.org/abs/2503.02313</link>
      <description>arXiv:2503.02313v2 Announce Type: replace-cross 
Abstract: This article proposes a simple, graph-independent perspective on partitioning the node set of a graph and provides multi-agent systems (MASs) with objectives beyond cooperation and bipartition. Specifically, we first introduce the notion of $k$-partition transformation to achieve any desired partition of the nodes. Then, we use this notion to formulate the multi-partite output regulation problem (MORP) of heterogeneous linear MASs, which comprises the existing cooperative output regulation problem (CORP) and bipartite output regulation problem (BORP) as subcases. The goal of the MORP is to design a distributed control law such that each follower that belongs to the same set in the partition asymptotically tracks a scalar multiple of the reference while ensuring the internal stability of the closed-loop system. It is shown that the necessary and sufficient conditions for the solvability of the MORP with a feedforward-based distributed control law follow from the CORP and lead to the first design strategy for the control parameters. However, it has a drawback in terms of scalability due to a partition-dependent condition. We prove that this condition is implied by its partition-independent version under a mild structural condition. This implication yields the second design strategy that is much more scalable than the first one. Finally, an experiment is conducted to demonstrate the MORP's flexibility, and two numerical examples are provided to illustrate its generality and compare both design strategies regarding scalability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02313v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>K\"ur\c{s}ad Metehan G\"ul, Selahattin Burak Sars{\i}lmaz</dc:creator>
    </item>
    <item>
      <title>Stochastic Multigrid Minimization for Ptychographic Phase Retrieval</title>
      <link>https://arxiv.org/abs/2504.10118</link>
      <description>arXiv:2504.10118v3 Announce Type: replace-cross 
Abstract: We propose a novel stochastic multigrid minimization method for ptychographic phase retrieval. In our formulation, the challenging nonconvex and ill-posed inverse problem is recast as the iterative minimization of a quadratic surrogate model that majorizes the original objective function. Our general framework encompasses the Ptychographic Iterative Engine (PIE) family of algorithms. By efficiently solving the surrogate problem using a multigrid method, our approach delivers significant improvements in both convergence speed and reconstruction quality compared with conventional PIE techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10118v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Borong Zhang, Qin Li, Zichao Wendy Di</dc:creator>
    </item>
    <item>
      <title>Autoregressive Stochastic Clock Jitter Compensation in Analog-to-Digital Converters</title>
      <link>https://arxiv.org/abs/2505.05030</link>
      <description>arXiv:2505.05030v2 Announce Type: replace-cross 
Abstract: This paper deals with the mathematical modeling and compensation of stochastic discrete time clock jitter in Analog-to-Digital Converters (ADCs). Two novel, computationally efficient de-jittering sample pilots-based algorithms for baseband signals are proposed: one consisting in solving a sequence of weighted least-squares problems and another that fully leverages the correlated jitter structure in a Kalman filter-type routine. Alongside, a comprehensive and rigorous mathematical analysis of the linearization errors committed is presented, and the work is complemented with extensive synthetic simulations and performance benchmarking with the scope of gauging and stress-testing the techniques in different scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.05030v2</guid>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniele Gerosa, Rui Hou, Vimar Bj\"ork, Ulf Gustavsson, Thomas Eriksson</dc:creator>
    </item>
    <item>
      <title>Birch SGD: A Tree Graph Framework for Local and Asynchronous SGD Methods</title>
      <link>https://arxiv.org/abs/2505.09218</link>
      <description>arXiv:2505.09218v2 Announce Type: replace-cross 
Abstract: We propose a new unifying framework, Birch SGD, for analyzing and designing distributed SGD methods. The central idea is to represent each method as a weighted directed tree, referred to as a computation tree. Leveraging this representation, we introduce a general theoretical result that reduces convergence analysis to studying the geometry of these trees. This perspective yields a purely graph-based interpretation of optimization dynamics, offering a new and intuitive foundation for method development. Using Birch SGD, we design eight new methods and analyze them alongside previously known ones, with at least six of the new methods shown to have optimal computational time complexity. Our research leads to two key insights: (i) all methods share the same "iteration rate" of $O\left(\frac{(R + 1) L \Delta}{\varepsilon} + \frac{\sigma^2 L \Delta}{\varepsilon^2}\right)$, where $R$ the maximum "tree distance" along the main branch of a tree; and (ii) different methods exhibit different trade-offs-for example, some update iterates more frequently, improving practical performance, while others are more communication-efficient or focus on other aspects. Birch SGD serves as a unifying framework for navigating these trade-offs. We believe these results provide a unified foundation for understanding, analyzing, and designing efficient asynchronous and parallel optimization methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09218v2</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Tyurin, Danil Sivtsov</dc:creator>
    </item>
  </channel>
</rss>
