<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.ST updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.ST</link>
    <description>math.ST updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.ST" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 25 Dec 2024 05:00:06 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A mixing time bound for Gibbs sampling from log-smooth log-concave distributions</title>
      <link>https://arxiv.org/abs/2412.17899</link>
      <description>arXiv:2412.17899v1 Announce Type: new 
Abstract: The Gibbs sampler, also known as the coordinate hit-and-run algorithm, is a Markov chain that is widely used to draw samples from probability distributions in arbitrary dimensions. At each iteration of the algorithm, a randomly selected coordinate is resampled from the distribution that results from conditioning on all the other coordinates. We study the behavior of the Gibbs sampler on the class of log-smooth and strongly log-concave target distributions supported on $\mathbb{R}^n$. Assuming the initial distribution is $M$-warm with respect to the target, we show that the Gibbs sampler requires at most $O^{\star}\left(\kappa^2 n^{7.5}\left(\max\left\{1,\sqrt{\frac{1}{n}\log \frac{2M}{\gamma}}\right\}\right)^2\right)$ steps to produce a sample with error no more than $\gamma$ in total variation distance from a distribution with condition number $\kappa$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17899v1</guid>
      <category>math.ST</category>
      <category>cs.DS</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Neha S. Wadia</dc:creator>
    </item>
    <item>
      <title>Functional independent component analysis by choice of norm: a framework for near-perfect classification</title>
      <link>https://arxiv.org/abs/2412.17971</link>
      <description>arXiv:2412.17971v1 Announce Type: new 
Abstract: We develop a theory for functional independent component analysis in an infinite-dimensional framework using Sobolev spaces that accommodate smoother functions. The notion of penalized kurtosis is introduced motivated by Silverman's method for smoothing principal components. This approach allows for a classical definition of independent components obtained via projection onto the eigenfunctions of a smoothed kurtosis operator mapping a whitened functional random variable. We discuss the theoretical properties of this operator in relation to a generalized Fisher discriminant function and the relationship it entails with the Feldman-H\'ajek dichotomy for Gaussian measures, both of which are critical to the principles of functional classification. The proposed estimators are a particularly competitive alternative in binary classification of functional data and can eventually achieve the so-called near-perfect classification, which is a genuine phenomenon of high-dimensional data. Our methods are illustrated through simulations, various real datasets, and used to model electroencephalographic biomarkers for the diagnosis of depressive disorder.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17971v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marc Vidal, Marc Leman, Ana M. Aguilera</dc:creator>
    </item>
    <item>
      <title>Shifted Composition III: Local Error Framework for KL Divergence</title>
      <link>https://arxiv.org/abs/2412.17997</link>
      <description>arXiv:2412.17997v1 Announce Type: new 
Abstract: Coupling arguments are a central tool for bounding the deviation between two stochastic processes, but traditionally have been limited to Wasserstein metrics. In this paper, we apply the shifted composition rule--an information-theoretic principle introduced in our earlier work--in order to adapt coupling arguments to the Kullback-Leibler (KL) divergence. Our framework combine the strengths of two previously disparate approaches: local error analysis and Girsanov's theorem. Akin to the former, it yields tight bounds by incorporating the so-called weak error, and is user-friendly in that it only requires easily verified local assumptions; and akin to the latter, it yields KL divergence guarantees and applies beyond Wasserstein contractivity.
  We apply this framework to the problem of sampling from a target distribution $\pi$. Here, the two stochastic processes are the Langevin diffusion and an algorithmic discretization thereof. Our framework provides a unified analysis when $\pi$ is assumed to be strongly log-concave (SLC), weakly log-concave (WLC), or to satisfy a log-Sobolev inequality (LSI). Among other results, this yields KL guarantees for the randomized midpoint discretization of the Langevin diffusion. Notably, our result: (1) yields the optimal $\tilde O(\sqrt d/\epsilon)$ rate in the SLC and LSI settings; (2) is the first result to hold beyond the 2-Wasserstein metric in the SLC setting; and (3) is the first result to hold in \emph{any} metric in the WLC and LSI settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17997v1</guid>
      <category>math.ST</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jason M. Altschuler, Sinho Chewi</dc:creator>
    </item>
    <item>
      <title>Conditional Influence Functions</title>
      <link>https://arxiv.org/abs/2412.18080</link>
      <description>arXiv:2412.18080v1 Announce Type: new 
Abstract: There are many nonparametric objects of interest that are a function of a conditional distribution. One important example is an average treatment effect conditional on a subset of covariates. Many of these objects have a conditional influence function that generalizes the classical influence function of a functional of a (unconditional) distribution. Conditional influence functions have important uses analogous to those of the classical influence function. They can be used to construct Neyman orthogonal estimating equations for conditional objects of interest that depend on high dimensional regressions. They can be used to formulate local policy effects and describe the effect of local misspecification on conditional objects of interest. We derive conditional influence functions for functionals of conditional means and other features of the conditional distribution of an outcome variable. We show how these can be used for locally linear estimation of conditional objects of interest. We give rate conditions for first step machine learners to have no effect on asymptotic distributions of locally linear estimators. We also give a general construction of Neyman orthogonal estimating equations for conditional objects of interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.18080v1</guid>
      <category>math.ST</category>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Victor Chernozhukov, Whitney K. Newey, Vasilis Syrgkanis</dc:creator>
    </item>
    <item>
      <title>Multivariate extreme value theory</title>
      <link>https://arxiv.org/abs/2412.18477</link>
      <description>arXiv:2412.18477v1 Announce Type: new 
Abstract: When passing from the univariate to the multivariate setting, modelling extremes becomes much more intricate. In this introductory exposition, classical multivariate extreme value theory is presented from the point of view of multivariate excesses over high thresholds as modelled by the family of multivariate generalized Pareto distributions. The formulation in terms of failure sets in the sample space intersecting the sample cloud leads to the over-arching perspective of point processes. Max-stable or generalized extreme value distributions are finally obtained as limits of vectors of componentwise maxima by considering the event that a certain region of the sample space does not contain any observation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.18477v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Philippe Naveau, Johan Segers</dc:creator>
    </item>
    <item>
      <title>Convergence of Statistical Estimators via Mutual Information Bounds</title>
      <link>https://arxiv.org/abs/2412.18539</link>
      <description>arXiv:2412.18539v1 Announce Type: cross 
Abstract: Recent advances in statistical learning theory have revealed profound connections between mutual information (MI) bounds, PAC-Bayesian theory, and Bayesian nonparametrics. This work introduces a novel mutual information bound for statistical models. The derived bound has wide-ranging applications in statistical inference. It yields improved contraction rates for fractional posteriors in Bayesian nonparametrics. It can also be used to study a wide range of estimation methods, such as variational inference or Maximum Likelihood Estimation (MLE). By bridging these diverse areas, this work advances our understanding of the fundamental limits of statistical inference and the role of information in learning from data. We hope that these results will not only clarify connections between statistical inference and information theory but also help to develop a new toolbox to study a wide range of estimators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.18539v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>El Mahdi Khribch, Pierre Alquier</dc:creator>
    </item>
    <item>
      <title>Weak convergence of adaptive Markov chain Monte Carlo</title>
      <link>https://arxiv.org/abs/2406.00820</link>
      <description>arXiv:2406.00820v2 Announce Type: replace 
Abstract: This article develops general conditions for weak convergence of adaptive Markov chain Monte Carlo processes and is shown to imply a weak law of large numbers for bounded Lipschitz continuous functions. This allows an estimation theory for adaptive Markov chain Monte Carlo where previously developed theory in total variation may fail or be difficult to establish. Extensions of weak convergence to general Wasserstein distances are established along with a weak law of large numbers for possibly unbounded Lipschitz functions. Applications are applied to auto-regressive processes in various settings, unadjusted Langevin processes, and adaptive Metropolis-Hastings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00820v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Austin Brown, Jeffrey S. Rosenthal</dc:creator>
    </item>
    <item>
      <title>Optimality of the Right-Invariant Prior</title>
      <link>https://arxiv.org/abs/2412.12054</link>
      <description>arXiv:2412.12054v3 Announce Type: replace 
Abstract: In this paper, we discuss optimal next-sample prediction for families of probability distributions with a locally compact topological group structure. The right-invariant prior was previously shown to yield a posterior predictive distribution minimizing the worst-case Kullback-Leibler risk among all predictive procedures. However, the assumptions for the proof are so strong that they rarely hold in practice and it is unclear when the density functions used in the proof exist. Therefore, we provide a measure-theoretic proof using a more appropriate set of assumptions. As an application, we show a strong optimality result for next-sample prediction for multivariate normal distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12054v3</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jannis Bolik, Thomas Hofmann</dc:creator>
    </item>
    <item>
      <title>Bivariate Matrix-valued Linear Regression (BMLR): Finite-sample performance under Identifiability and Sparsity Assumptions</title>
      <link>https://arxiv.org/abs/2412.17749</link>
      <description>arXiv:2412.17749v2 Announce Type: replace 
Abstract: This study explores the estimation of parameters in a matrix-valued linear regression model, where the $T$ responses $(Y_t)_{t=1}^T \in \mathbb{R}^{n \times p}$ and predictors $(X_t)_{t=1}^T \in \mathbb{R}^{m \times q}$ satisfy the relationship $Y_t = A^* X_t B^* + E_t$ for all $t = 1, \ldots, T$. In this model, $A^* \in \mathbb{R}_+^{n \times m}$ has $L_1$-normalized rows, $B^* \in \mathbb{R}^{q \times p}$, and $(E_t)_{t=1}^T$ are independent noise matrices following a matrix Gaussian distribution. The primary objective is to estimate the unknown parameters $A^*$ and $B^*$ efficiently.
  We propose explicit optimization-free estimators and establish non-asymptotic convergence rates to quantify their performance. Additionally, we extend our analysis to scenarios where $A^*$ and $B^*$ exhibit sparse structures. To support our theoretical findings, we conduct numerical simulations that confirm the behavior of the estimators, particularly with respect to the impact of the dimensions $n, m, p, q$, and the sample size $T$ on finite-sample performances. We complete the simulations by investigating the denoising performances of our estimators on noisy real-world images.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17749v2</guid>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Nayel Bettache</dc:creator>
    </item>
    <item>
      <title>Modelling multivariate extreme value distributions via Markov trees</title>
      <link>https://arxiv.org/abs/2208.02627</link>
      <description>arXiv:2208.02627v2 Announce Type: replace-cross 
Abstract: Multivariate extreme value distributions are a common choice for modelling multivariate extremes. In high dimensions, however, the construction of flexible and parsimonious models is challenging. We propose to combine bivariate max-stable distributions into a Markov random field with respect to a tree. Although in general not max-stable itself, this Markov tree is attracted by a multivariate max-stable distribution. The latter serves as a tree-based approximation to an unknown max-stable distribution with the given bivariate distributions as margins. Given data, we learn an appropriate tree structure by Prim's algorithm with estimated pairwise upper tail dependence coefficients as edge weights. The distributions of pairs of connected variables can be fitted in various ways. The resulting tree-structured max-stable distribution allows for inference on rare event probabilities, as illustrated on river discharge data from the upper Danube basin.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.02627v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1111/sjos.12698</arxiv:DOI>
      <arxiv:journal_reference>Scandinavian Journal of Statistics (2024), volume 51, pages 760-800</arxiv:journal_reference>
      <dc:creator>Shuang Hu, Zuoxiang Peng, Johan Segers</dc:creator>
    </item>
  </channel>
</rss>
