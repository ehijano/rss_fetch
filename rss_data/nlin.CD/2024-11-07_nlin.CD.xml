<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>nlin.CD updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/nlin.CD</link>
    <description>nlin.CD updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/nlin.CD" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 08 Nov 2024 02:48:27 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Holographic deep thermalization</title>
      <link>https://arxiv.org/abs/2411.03587</link>
      <description>arXiv:2411.03587v1 Announce Type: cross 
Abstract: Random quantum states play a critical role in quantum information processing. While random quantum circuits typically provide pseudo-random states, deep thermalization introduces quantum measurement to generate genuinely random states. However, the requirement of large ancillae in conventional deep thermalization poses a challenge to scale up the system size. We introduce holographic deep thermalization to substantially reduce the required ancillae to a system-size independent constant. Our circuit design trades space with time, via adopting a sequential application of an scrambling-measure-reset process on a small number of ancillae. Via tuning the ancilla size and number of time steps, holographic deep thermalization allows a continuous trade-off between the total quantum circuit size and the ancilla size. In the case of finite-size systems, we further enhance the performance of holographic deep thermalization via generative quantum machine learning, which leads to constant-factor advantages in the convergence towards Haar random. The theoretical predictions are verified with IBM Quantum noisy simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03587v1</guid>
      <category>quant-ph</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>nlin.CD</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bingzhi Zhang, Peng Xu, Xiaohui Chen, Quntao Zhuang</dc:creator>
    </item>
    <item>
      <title>Fundamental performance bounds on time-series generation using reservoir computing</title>
      <link>https://arxiv.org/abs/2410.20393</link>
      <description>arXiv:2410.20393v2 Announce Type: replace 
Abstract: Reservoir computing (RC) harnesses the intrinsic dynamics of a chaotic system, called the reservoir, to perform various time-varying functions. An important use-case of RC is the generation of target temporal sequences via a trainable output-to-reservoir feedback loop. Despite the promise of RC in various domains, we lack a theory of performance bounds on RC systems. Here, we formulate an existence condition for a feedback loop that produces the target sequence. We next demonstrate that, given a sufficiently chaotic neural network reservoir, two separate factors are needed for successful training: global network stability of the target orbit, and the ability of the training algorithm to drive the system close enough to the target, which we term `reach'. By computing the training phase diagram over a range of target output amplitudes and periods, we verify that reach-limited failures depend on the training algorithm while stability-limited failures are invariant across different algorithms. We leverage dynamical mean field theory (DMFT) to provide an analytical amplitude-period bound on achievable outputs by RC networks and propose a way of enhancing algorithm reach via forgetting. The resulting mechanistic understanding of RC performance can guide the future design and deployment of reservoir networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20393v2</guid>
      <category>nlin.CD</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daoyuan Qian, Ila Fiete</dc:creator>
    </item>
    <item>
      <title>Normal forms for the Laplace resonance</title>
      <link>https://arxiv.org/abs/2102.07671</link>
      <description>arXiv:2102.07671v3 Announce Type: replace-cross 
Abstract: We describe a comprehensive model for systems locked in the Laplace resonance. The framework is based on the simplest possible dynamical structure provided by the Keplerian problem perturbed by the resonant coupling truncated at second order in the eccentricities. The reduced Hamiltonian, constructed by a transformation to resonant coordinates, is then submitted to a suitable ordering of the terms and to the study of its equilibria. Henceforth, resonant normal forms are computed. The main result is the identification of two different classes of equilibria. In the first class, only one kind of stable equilibrium is present: the paradigmatic case is that of the Galilean system. In the second class, three kinds of stable equilibria are possible and at least one of them is characterised by a high value of the forced eccentricity for the `first planet': here the paradigmatic case is the exo-planetary system GJ-876, in which the combination of libration centers admits triple conjunctions otherwise not possible in the Galilean case. The normal form obtained by averaging with respect to the free eccentricity oscillations, describes the libration of the Laplace argument for arbitrary amplitudes and allows us to determine the libration width of the resonance. The agreement of the analytic predictions with the numerical integration of the toy models is very good.</description>
      <guid isPermaLink="false">oai:arXiv.org:2102.07671v3</guid>
      <category>astro-ph.EP</category>
      <category>nlin.CD</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s10569-021-10008-w</arxiv:DOI>
      <arxiv:journal_reference>Celestial Mechanics and Dynamical Astronomy (2021) 133, 11</arxiv:journal_reference>
      <dc:creator>Giuseppe Pucacco</dc:creator>
    </item>
    <item>
      <title>The low-rank hypothesis of complex systems</title>
      <link>https://arxiv.org/abs/2208.04848</link>
      <description>arXiv:2208.04848v4 Announce Type: replace-cross 
Abstract: Complex systems are high-dimensional nonlinear dynamical systems with intricate interactions among their constituents. To make interpretable predictions about their large-scale behavior, it is typically assumed, without a clear statement, that these dynamics can be reduced to a few number of equations involving a low-rank matrix describing the network of interactions -- what we call the low-rank hypothesis. Our paper sheds light on this assumption and questions its validity. By leveraging fundamental theorems on singular value decomposition, we expose the hypothesis for various random graphs, either by making explicit their low-rank formulation or by demonstrating the exponential decrease of their singular values. Notably, we verify the hypothesis experimentally for real networks by revealing the rapid decrease of their singular values, which has major consequences on their effective ranks. We then evaluate the impact of the low-rank hypothesis for general dynamical systems on networks through an optimal dimension reduction. This allows us to prove that recurrent neural networks can be exactly reduced, and to connect the rapidly decreasing singular values of real networks to the dimension reduction error of the nonlinear dynamics they support, be it microbial, neuronal or epidemiological. Finally, we prove that higher-order interactions naturally emerge from the dimension reduction, thus providing theoretical insights into the origin of higher-order interactions in complex systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.04848v4</guid>
      <category>nlin.AO</category>
      <category>nlin.CD</category>
      <category>physics.bio-ph</category>
      <category>physics.soc-ph</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1038/s41567-023-02303-0</arxiv:DOI>
      <arxiv:journal_reference>Nat. Phys. 20 (2024) 294-302</arxiv:journal_reference>
      <dc:creator>Vincent Thibeault, Antoine Allard, Patrick Desrosiers</dc:creator>
    </item>
    <item>
      <title>Second law of thermodynamics: Spontaneous cold-to-hot heat transfer in a nonchaotic medium</title>
      <link>https://arxiv.org/abs/2312.09161</link>
      <description>arXiv:2312.09161v4 Announce Type: replace-cross 
Abstract: It has long been known that, fundamentally different from a large body of rarefied gas, when a Knudsen gas is immersed in a thermal bath, it may never reach thermal equilibrium. The root cause is nonchaoticity: as the particle-particle collisions are sparse, the particle trajectories tend to be independent of each other. Usually, this counterintuitive phenomenon is studied through kinetic theory and is not considered a thermodynamic problem. In current research, we show that if incorporated in a compound setup, such an intrinsically nonequilibrium behavior has nontrivial consequences and cannot circumvent thermodynamics: cold-to-hot heat transfer may happen spontaneously, either continuously (with an energy barrier) or cyclically (with time-dependent entropy barriers). It allows for production of useful work by absorbing heat from a single thermal reservoir without any other effect. As the system obeys the first law of thermodynamics, it breaks the boundaries of the second law of thermodynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.09161v4</guid>
      <category>cond-mat.stat-mech</category>
      <category>nlin.CD</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yu Qiao, Zhaoru Shang</dc:creator>
    </item>
    <item>
      <title>Informative and non-informative decomposition of turbulent flow fields</title>
      <link>https://arxiv.org/abs/2402.11448</link>
      <description>arXiv:2402.11448v2 Announce Type: replace-cross 
Abstract: Not all the information in a turbulent field is relevant for understanding particular regions or variables in the flow. Here, we present a method for decomposing a source field into its informative $\boldsymbol{\Phi}_I(\boldsymbol{x},t)$ and residual $\boldsymbol{\Phi}_R(\boldsymbol{x},t)$ components relative to another target field. The method is referred to as informative and non-informative decomposition (IND). All the necessary information for physical understanding, reduced-order modelling, and control of the target variable is contained in $\boldsymbol{\Phi}_I(\boldsymbol{x},t)$, whereas $\boldsymbol{\Phi}_R(\boldsymbol{x},t)$ offers no substantial utility in these contexts. The decomposition is formulated as an optimisation problem that seeks to maximise the time-lagged mutual information of the informative component with the target variable while minimising the mutual information with the residual component. The method is applied to extract the informative and residual components of the velocity field in a turbulent channel flow, using the wall-shear stress as the target variable. We demonstrate the utility of IND in three scenarios: (i) physical insight of the effect of the velocity fluctuations on the wall-shear stress, (ii) prediction of the wall-shear stress using velocities far from the wall, and (iii) development of control strategies for drag reduction in a turbulent channel flow using opposition control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.11448v2</guid>
      <category>physics.flu-dyn</category>
      <category>nlin.CD</category>
      <category>physics.comp-ph</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1017/jfm.2024.1007</arxiv:DOI>
      <dc:creator>Gonzalo Arranz, Adrian Lozano-Dur\'an</dc:creator>
    </item>
  </channel>
</rss>
