<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 29 Aug 2024 04:00:18 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 29 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Model-Free Method to Quantify Memory Utilization in Neural Point Processes</title>
      <link>https://arxiv.org/abs/2408.15875</link>
      <description>arXiv:2408.15875v1 Announce Type: new 
Abstract: Quantifying the predictive capacity of a neural system, intended as the capability to store information and actively use it for dynamic system evolution, is a key component of neural information processing. Information storage (IS), the main measure quantifying the active utilization of memory in a dynamic system, is only defined for discrete-time processes. While recent theoretical work laid the foundations for the continuous-time analysis of the predictive capacity stored in a process, methods for the effective computation of the related measures are needed to favor widespread utilization on neural data. This work introduces a method for the model-free estimation of the so-called memory utilization rate (MUR), the continuous-time counterpart of the IS, specifically designed to quantify the predictive capacity stored in neural point processes. The method employs nearest-neighbor entropy estimation applied to the inter-spike intervals measured from point-process realizations to quantify the extent of memory used by a spike train. An empirical procedure based on surrogate data is implemented to compensate the estimation bias and detect statistically significant levels of memory. The method is validated in simulated Poisson processes and in realistic models of coupled cortical dynamics and heartbeat dynamics. It is then applied to real spike trains reflecting central and autonomic nervous system activities: in spontaneously growing cortical neuron cultures, the MUR detected increasing memory utilization across maturation stages, associated to emergent bursting synchronized activity; in the study of the neuro-autonomic modulation of human heartbeats, the MUR reflected the sympathetic activation occurring with postural but not with mental stress. The proposed approach offers a computationally reliable tool to analyze spike train data in computational neuroscience and physiology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.15875v1</guid>
      <category>q-bio.NC</category>
      <category>stat.CO</category>
      <pubDate>Thu, 29 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gorana Mijatovic, Sebastiano Stramaglia, Luca Faes</dc:creator>
    </item>
    <item>
      <title>Thoughtseeds: Evolutionary Priors, Nested Markov Blankets, and the Emergence of Embodied Cognition</title>
      <link>https://arxiv.org/abs/2408.15982</link>
      <description>arXiv:2408.15982v1 Announce Type: new 
Abstract: The emergence of cognition requires a framework that bridges evolutionary principles with neurocomputational mechanisms. This paper introduces the "thoughtseed" framework, proposing that cognition arises from the dynamic interaction of self-organizing units of embodied knowledge called "thoughtseeds." We leverage evolutionary theory, "neuronal packets," and the "Inner Screen" hypothesis within Free Energy Principle, and propose a four-level hierarchical model of the cognitive agent's internal states: Neuronal Packet Domains (NPDs), Knowledge Domains (KDs), thoughtseeds network, and meta-cognition. The dynamic interplay within this hierarchy, mediated by nested Markov blankets and reciprocal message passing, facilitates the emergence of thoughtseeds as coherent patterns of activity that guide perception, action, and learning. The framework further explores the role of the organism's Umwelt and the principles of active inference, especially the generative model at each nested level, in shaping the selection and activation of thoughtseeds, leading to adaptive behavior through surprise minimization. The "Inner Screen" is posited as the locus of conscious experience, where the content of the dominant thoughtseed is projected, maintaining a unitary conscious experience. Active thoughtseeds are proposed as the fundamental units of thought that contribute to the "content of consciousness." We present a mathematical framework grounded in active inference and dynamical systems theory. The thoughtseed framework represents an initial but promising step towards a novel, biologically-grounded model for understanding the organizing principles and emergence of embodied cognition, offering a unified account of cognitive phenomena, from basic physiological regulation to higher-order thought processes, and potentially bridge neuroscience and contemplative traditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.15982v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Thu, 29 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Prakash Chandra Kavi, Gorka Zamora Lopez, Daniel Ari Friedman</dc:creator>
    </item>
    <item>
      <title>Geometric Neural Network based on Phase Space for BCI-EEG decoding</title>
      <link>https://arxiv.org/abs/2403.05645</link>
      <description>arXiv:2403.05645v3 Announce Type: replace-cross 
Abstract: Objective: The integration of Deep Learning (DL) algorithms on brain signal analysis is still in its nascent stages compared to their success in fields like Computer Vision. This is particularly true for BCI, where the brain activity is decoded to control external devices without requiring muscle control. Electroencephalography (EEG) is a widely adopted choice for designing BCI systems due to its non-invasive and cost-effective nature and excellent temporal resolution. Still, it comes at the expense of limited training data, poor signal-to-noise, and a large variability across and within-subject recordings. Finally, setting up a BCI system with many electrodes takes a long time, hindering the widespread adoption of reliable DL architectures in BCIs outside research laboratories. To improve adoption, we need to improve user comfort using, for instance, reliable algorithms that operate with few electrodes. Approach: Our research aims to develop a DL algorithm that delivers effective results with a limited number of electrodes. Taking advantage of the Augmented Covariance Method and the framework of SPDNet, we propose the Phase-SPDNet architecture and analyze its performance and the interpretability of the results. The evaluation is conducted on 5-fold cross-validation, using only three electrodes positioned above the Motor Cortex. The methodology was tested on nearly 100 subjects from several open-source datasets using the Mother Of All BCI Benchmark (MOABB) framework. Main results: The results of our Phase-SPDNet demonstrate that the augmented approach combined with the SPDNet significantly outperforms all the current state-of-the-art DL architecture in MI decoding. Significance: This new architecture is explainable and with a low number of trainable parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05645v3</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Thu, 29 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Igor Carrara, Bruno Aristimunha, Marie-Constance Corsi, Raphael Y. de Camargo, Sylvain Chevallier, Th\'eodore Papadopoulo</dc:creator>
    </item>
    <item>
      <title>Unsupervised discovery of the shared and private geometry in multi-view data</title>
      <link>https://arxiv.org/abs/2408.12091</link>
      <description>arXiv:2408.12091v2 Announce Type: replace-cross 
Abstract: Modern applications often leverage multiple views of a subject of study. Within neuroscience, there is growing interest in large-scale simultaneous recordings across multiple brain regions. Understanding the relationship between views (e.g., the neural activity in each region recorded) can reveal fundamental principles about the characteristics of each representation and about the system. However, existing methods to characterize such relationships either lack the expressivity required to capture complex nonlinearities, describe only sources of variance that are shared between views, or discard geometric information that is crucial to interpreting the data. Here, we develop a nonlinear neural network-based method that, given paired samples of high-dimensional views, disentangles low-dimensional shared and private latent variables underlying these views while preserving intrinsic data geometry. Across multiple simulated and real datasets, we demonstrate that our method outperforms competing methods. Using simulated populations of lateral geniculate nucleus (LGN) and V1 neurons we demonstrate our model's ability to discover interpretable shared and private structure across different noise conditions. On a dataset of unrotated and corresponding but randomly rotated MNIST digits, we recover private latents for the rotated view that encode rotation angle regardless of digit class, and places the angle representation on a 1-d manifold, while shared latents encode digit class but not rotation angle. Applying our method to simultaneous Neuropixels recordings of hippocampus and prefrontal cortex while mice run on a linear track, we discover a low-dimensional shared latent space that encodes the animal's position. We propose our approach as a general-purpose method for finding succinct and interpretable descriptions of paired data sets in terms of disentangled shared and private latent variables.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12091v2</guid>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Thu, 29 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sai Koukuntla, Joshua B. Julian, Jesse C. Kaminsky, Manuel Schottdorf, David W. Tank, Carlos D. Brody, Adam S. Charles</dc:creator>
    </item>
  </channel>
</rss>
