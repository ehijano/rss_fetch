<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.OT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.OT</link>
    <description>stat.OT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.OT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 25 Sep 2024 02:01:16 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Improving the Satterthwaite (1941,1946) Effective Degrees of Freedom Approximation</title>
      <link>https://arxiv.org/abs/2409.14606</link>
      <description>arXiv:2409.14606v1 Announce Type: new 
Abstract: This work develops a correction for the approximation of the effective degrees of freedom provided by Satterthwaite (1941, 1946) for cases where the component degrees of freedom are small. The correction provided in this work is based on analytical results relating to the behavior of random variables with small degrees of freedom when use for approximating higher moments, as required by Satterthwaite. This correction extends the empirically derived correction provided by Johnson &amp; Rust (1993) in that this new result is derived based on theoretical results rather than simulation-derived transformation constants.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.14606v1</guid>
      <category>stat.OT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Matthias von Davier</dc:creator>
    </item>
    <item>
      <title>Adaptive radar detection of subspace-based distributed target in power heterogeneous clutter</title>
      <link>https://arxiv.org/abs/2409.14049</link>
      <description>arXiv:2409.14049v1 Announce Type: cross 
Abstract: This paper investigates the problem of adaptive detection of distributed targets in power heterogeneous clutter. In the considered scenario, all the data share the identical structure of clutter covariance matrix, but with varying and unknown power mismatches. To address this problem, we iteratively estimate all the unknowns, including the coordinate matrix of the target, the clutter covariance matrix, and the corresponding power mismatches, and propose three detectors based on the generalized likelihood ratio test (GLRT), Rao and the Wald tests. The results from simulated and real data both illustrate that the detectors based on GLRT and Rao test have higher probabilities of detection (PDs) than the existing competitors. Among them, the Rao test-based detector exhibits the best overall detection performance. We also analyze the impact of the target extended dimensions, the signal subspace dimensions, and the number of training samples on the detection performance. Furthermore, simulation experiments also demonstrate that the proposed detectors have a constant false alarm rate (CFAR) property for the structure of clutter covariance matrix.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.14049v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.OT</category>
      <pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daipeng Xiao, Weijian Liu, Jun Liu, Lingyan Dai, Xueli Fang, Jianjun Ge</dc:creator>
    </item>
    <item>
      <title>Advancing Employee Behavior Analysis through Synthetic Data: Leveraging ABMs, GANs, and Statistical Models for Enhanced Organizational Efficiency</title>
      <link>https://arxiv.org/abs/2409.14197</link>
      <description>arXiv:2409.14197v1 Announce Type: cross 
Abstract: Success in todays data-driven corporate climate requires a deep understanding of employee behavior. Companies aim to improve employee satisfaction, boost output, and optimize workflow. This research study delves into creating synthetic data, a powerful tool that allows us to comprehensively understand employee performance, flexibility, cooperation, and team dynamics. Synthetic data provides a detailed and accurate picture of employee activities while protecting individual privacy thanks to cutting-edge methods like agent-based models (ABMs), Generative Adversarial Networks (GANs), and statistical models. Through the creation of multiple situations, this method offers insightful viewpoints regarding increasing teamwork, improving adaptability, and accelerating overall productivity. We examine how synthetic data has evolved from a specialized field to an essential resource for researching employee behavior and enhancing management efficiency. Keywords: Agent-Based Model, Generative Adversarial Network, workflow optimization, organizational success</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.14197v1</guid>
      <category>cs.LG</category>
      <category>cs.FL</category>
      <category>stat.OT</category>
      <pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Rakshitha Jayashankar, Mahesh Balan</dc:creator>
    </item>
    <item>
      <title>Survey Data Integration for Distribution Function Estimation</title>
      <link>https://arxiv.org/abs/2409.14284</link>
      <description>arXiv:2409.14284v1 Announce Type: cross 
Abstract: Integration of probabilistic and non-probabilistic samples for the estimation of finite population totals (or means) has recently received considerable attention in the field of survey sampling; yet, to the best of our knowledge, this framework has not been extended to cumulative distribution function (CDF) estimation. To address this gap, we propose a novel CDF estimator that integrates data from probability samples with data from (potentially large) nonprobability samples. Assuming that a set of shared covariates are observed in both samples, while the response variable is observed only in the latter, the proposed estimator uses a survey-weighted empirical CDF of regression residuals trained on the convenience sample to estimate the CDF of the response variable. Under some regularity conditions, we show that our CDF estimator is both design-consistent for the finite population CDF and asymptotically normally distributed. Additionally, we define and study a quantile estimator based on the proposed CDF estimator. Furthermore, we use both the bootstrap and asymptotic formulae to estimate their respective sampling variances. Our empirical results show that the proposed CDF estimator is robust to model misspecification under ignorability, and robust to ignorability under model misspecification. When both assumptions are violated, our residual-based CDF estimator still outperforms its 'plug-in' mass imputation and naive siblings, albeit with noted decreases in efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.14284v1</guid>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <category>stat.OT</category>
      <category>stat.TH</category>
      <pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jeremy Flood (North Carolina A&amp;T State University), Sayed Mostafa (North Carolina A&amp;T State University)</dc:creator>
    </item>
    <item>
      <title>Generative AI for Data Science 101: Coding Without Learning To Code</title>
      <link>https://arxiv.org/abs/2401.17647</link>
      <description>arXiv:2401.17647v2 Announce Type: replace 
Abstract: Should one teach coding in a required introductory statistics and data science class for non-major students? Many professors advise against it, considering it a distraction from the important and challenging statistical topics that need to be covered. By contrast, other professors argue that the ability to interact flexibly with data will inspire students with a lasting love of the subject and a continued commitment to the material beyond the introductory course. With the release of large language models that write code, we saw an opportunity for a middle ground, which we tried in Fall 2023 in a required introductory data science course in our school's full-time MBA program. We taught students how to write English prompts to the artificial intelligence tool Github Copilot that could be turned into R code and executed. In this short article, we report on our experience using this new approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.17647v2</guid>
      <category>stat.OT</category>
      <category>stat.CO</category>
      <pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jacob Bien, Gourab Mukherjee</dc:creator>
    </item>
  </channel>
</rss>
