<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NA</link>
    <description>cs.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 25 Mar 2024 04:00:54 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 25 Mar 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A fourth-order exponential time differencing scheme with dimensional splitting for non-linear reaction-diffusion systems</title>
      <link>https://arxiv.org/abs/2403.14777</link>
      <description>arXiv:2403.14777v1 Announce Type: new 
Abstract: A fourth-order exponential time differencing (ETD) Runge-Kutta scheme with dimensional splitting is developed to solve multidimensional non-linear systems of reaction-diffusion equations (RDE). By approximating the matrix exponential in the scheme with the A-acceptable Pad\'e (2,2) rational function, the resulting scheme (ETDRK4P22-IF) is verified empirically to be fourth-order accurate for several RDE. The scheme is shown to be more efficient than competing fourth-order ETD and IMEX schemes, achieving up to 20 times speed in CPU time. Inclusion of up to three pre-smoothing steps of a lower order L-stable scheme facilitates efficient damping of spurious oscillations arising from problems with non-smooth initial/boundary conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.14777v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>E. O. Asante-Asamani, A. Kleefeld, B. A. Wade</dc:creator>
    </item>
    <item>
      <title>Learning WENO for entropy stable schemes to solve conservation laws</title>
      <link>https://arxiv.org/abs/2403.14848</link>
      <description>arXiv:2403.14848v1 Announce Type: new 
Abstract: Entropy conditions play a crucial role in the extraction of a physically relevant solution for a system of conservation laws, thus motivating the construction of entropy stable schemes that satisfy a discrete analogue of such conditions. TeCNO schemes (Fjordholm et al. 2012) form a class of arbitrary high-order entropy stable finite difference solvers, which require specialized reconstruction algorithms satisfying the sign property at each cell interface. Recently, third-order WENO schemes called SP-WENO (Fjordholm and Ray, 2016) and SP-WENOc (Ray, 2018) have been designed to satisfy the sign property. However, these WENO algorithms can perform poorly near shocks, with the numerical solutions exhibiting large spurious oscillations. In the present work, we propose a variant of the SP-WENO, termed as Deep Sign-Preserving WENO (DSP-WENO), where a neural network is trained to learn the WENO weighting strategy. The sign property and third-order accuracy are strongly imposed in the algorithm, which constrains the WENO weight selection region to a convex polygon. Thereafter, a neural network is trained to select the WENO weights from this convex region with the goal of improving the shock-capturing capabilities without sacrificing the rate of convergence in smooth regions. The proposed synergistic approach retains the mathematical framework of the TeCNO scheme while integrating deep learning to remedy the computational issues of the WENO-based reconstruction. We present several numerical experiments to demonstrate the significant improvement with DSP-WENO over the existing variants of WENO satisfying the sign property.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.14848v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Philip Charles, Deep Ray</dc:creator>
    </item>
    <item>
      <title>Two-scale Analysis for Multiscale Landau-Lifshitz-Gilbert Equation: Theory and Numerical Methods</title>
      <link>https://arxiv.org/abs/2403.14957</link>
      <description>arXiv:2403.14957v1 Announce Type: new 
Abstract: This paper discusses the theory and numerical method of two-scale analysis for the multiscale Landau-Lifshitz-Gilbert equation in composite ferromagnetic materials. The novelty of this work can be summarized in three aspects: Firstly, the more realistic and complex model is considered, including the effects of the exchange field, anisotropy field, stray field, and external magnetic field. The explicit convergence orders in the $H^1$ norm between the classical solution and the two-scale solution are obtained. Secondly, we propose a robust numerical framework, which is employed in several comprehensive experiments to validate the convergence results for the Periodic and Neumann problems. Thirdly, we design an improved implicit numerical scheme to reduce the required number of iterations and relaxes the constraints on the time step size, which can significantly improve computational efficiency. Specifically, the projection and the expansion methods are given to overcome the inherent non-consistency in the initial data between the multiscale problem and homogenized problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.14957v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaofei Guan, Hang Qi, Zhiwei Sun</dc:creator>
    </item>
    <item>
      <title>Anderson Acceleration with Truncated Gram-Schmidt</title>
      <link>https://arxiv.org/abs/2403.14961</link>
      <description>arXiv:2403.14961v1 Announce Type: new 
Abstract: Anderson Acceleration (AA) is a popular algorithm designed to enhance the convergence of fixed-point iterations. In this paper, we introduce a variant of AA based on a Truncated Gram-Schmidt process (AATGS) which has a few advantages over the classical AA. In particular, an attractive feature of AATGS is that its iterates obey a three-term recurrence in the situation when it is applied to solving symmetric linear problems and this can lead to a considerable reduction of memory and computational costs. We analyze the convergence of AATGS in both full-depth and limited-depth scenarios and establish its equivalence to the classical AA in the linear case. We also report on the effectiveness of AATGS through a set of numerical experiments, ranging from solving nonlinear partial differential equations to tackling nonlinear optimization problems. In particular, the performance of the method is compared with that of the classical AA algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.14961v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziyuan Tang, Tianshi Xu, Huan He, Yousef Saad, Yuanzhe Xi</dc:creator>
    </item>
    <item>
      <title>Stability of conforming space-time isogeometric methods for the wave equation</title>
      <link>https://arxiv.org/abs/2403.15043</link>
      <description>arXiv:2403.15043v1 Announce Type: new 
Abstract: We consider a family of conforming space-time finite element discretizations for the wave equation based on splines of maximal regularity in time. Traditional techniques may require a CFL condition to guarantee stability. Recent works by O. Steinbach and M. Zank (2018), and S. Fraschini, G. Loli, A. Moiola, and G. Sangalli (2023), have introduced unconditionally stable schemes by adding non-consistent penalty terms to the underlying bilinear form. Stability and error analysis have been carried out for lowest order discrete spaces. While higher order methods have shown promising properties through numerical testing, their rigorous analysis was still missing. In this paper, we address this stability analysis by studying the properties of the condition number of a family of matrices associated with the time discretization. For each spline order, we derive explicit estimates of both the CFL condition required in the unstabilized case and the penalty term that minimises the consistency error in the stabilized case. Numerical tests confirm the sharpness of our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15043v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Matteo Ferrari, Sara Fraschini</dc:creator>
    </item>
    <item>
      <title>Mixed finite element methods for linear Cosserat equations</title>
      <link>https://arxiv.org/abs/2403.15136</link>
      <description>arXiv:2403.15136v1 Announce Type: new 
Abstract: We consider the equilibrium equations for a linearized Cosserat material. We identify their structure in terms of a differential complex, which is isomorphic to six copies of the de Rham complex through an algebraic isomorphism. Moreover, we show how the Cosserat materials can be analyzed by inheriting results from linearized elasticity. Both perspectives give rise to mixed finite element methods, which we refer to as strongly and weaky coupled, respectively. We prove convergence of both classes of methods, with particular attention to improved convergence rate estimates, and stability in the limit of vanishing Cosserat material parameters. The theoretical results are fully reflected in the actual performance of the methods, as shown by the numerical verifications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15136v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wietse Marijn Boon, Omar Duran, Jan Martin Nordbotten</dc:creator>
    </item>
    <item>
      <title>Splitting methods for unbounded operators</title>
      <link>https://arxiv.org/abs/2403.15147</link>
      <description>arXiv:2403.15147v1 Announce Type: new 
Abstract: This paper considers computational methods that split a vector field into three components in the case when both the vector field and the split components might be unbounded. We first employ classical Taylor expansion which, after some algebra, results in an expression for a second-order splitting which, strictly speaking, makes sense only for bounded operators. Next, using an alternative approach, we derive an error expression and an error bound in the same setting which are however valid in the presence of unbounded operators.
  While the paper itself is concerned with second-order splittings using three components, the method of proof in the presence of unboundedness remains valid (although significantly more complicated) in a more general scenario, which will be the subject of a forthcoming paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15147v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arieh Iserles, Karolina Kropielnicka</dc:creator>
    </item>
    <item>
      <title>Accelerating Aeroelastic UVLM Simulations by Inexact Newton Algorithms</title>
      <link>https://arxiv.org/abs/2403.15286</link>
      <description>arXiv:2403.15286v1 Announce Type: new 
Abstract: We consider the aeroelastic simulation of flexible mechanical structures submerged in subsonic fluid flows at low Mach numbers. The nonlinear kinematics of flexible bodies are described in the total Lagrangian formulation and discretized by finite elements. The aerodynamic loads are computed using the unsteady vortex-lattice method wherein a free wake is tracked over time. Each implicit time step in the dynamic simulation then requires solving a nonlinear equation system in the structural variables with additional aerodynamic load terms. Our focus here is on the efficient numerical solution of this system by accelerating the Newton algorithm. The particular structure of the aeroelastic nonlinear system suggests the structural derivative as an approximation to the full derivative in the linear Newton system. We investigate and compare two promising algorithms based in this approximation, a quasi-Newton type algorithm and a novel inexact Newton algorithm. Numerical experiments are performed on a flexible plate and on a wind turbine. Our computational results show that the approximation can indeed accelerate the Newton algorithm substantially. Surprisingly, the theoretically preferable inexact Newton algorithm is much slower than the quasi-Newton algorithm, which motivates further research to speed up derivative evaluations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15286v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jenny Schubert, Marc C. Steinbach, Christian Hente, David M\"artins, Daniel Schuster</dc:creator>
    </item>
    <item>
      <title>Kernel Alignment for Unsupervised Feature Selection via Matrix Factorization</title>
      <link>https://arxiv.org/abs/2403.14688</link>
      <description>arXiv:2403.14688v1 Announce Type: cross 
Abstract: By removing irrelevant and redundant features, feature selection aims to find a good representation of the original features. With the prevalence of unlabeled data, unsupervised feature selection has been proven effective in alleviating the so-called curse of dimensionality. Most existing matrix factorization-based unsupervised feature selection methods are built upon subspace learning, but they have limitations in capturing nonlinear structural information among features. It is well-known that kernel techniques can capture nonlinear structural information. In this paper, we construct a model by integrating kernel functions and kernel alignment, which can be equivalently characterized as a matrix factorization problem. However, such an extension raises another issue: the algorithm performance heavily depends on the choice of kernel, which is often unknown a priori. Therefore, we further propose a multiple kernel-based learning method. By doing so, our model can learn both linear and nonlinear similarity information and automatically generate the most appropriate kernel. Experimental analysis on real-world data demonstrates that the two proposed methods outperform other classic and state-of-the-art unsupervised feature selection methods in terms of clustering results and redundancy reduction in almost all datasets tested.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.14688v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziyuan Lin, Deanna Needell</dc:creator>
    </item>
    <item>
      <title>Extrapolating Solution Paths of Polynomial Homotopies towards Singularities with PHCpack and phcpy</title>
      <link>https://arxiv.org/abs/2403.14844</link>
      <description>arXiv:2403.14844v1 Announce Type: cross 
Abstract: A robust path tracker [Telen, Van Barel, Verschelde, SISC 2020] computes the radius of convergence of Newton's method, estimates the distance to the nearest path, and then applies Pad\'e approximants to predict the next point on the path. Apriori step size control is less sensitive to finely tuned tolerances than aposteriori step size control, and is therefore robust. Extrapolation methods are effective to accurately locate the singular points at the end of solution paths, as illustrated with phcpy, the scripting interface to PHCpack.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.14844v1</guid>
      <category>cs.MS</category>
      <category>cs.NA</category>
      <category>cs.SC</category>
      <category>math.CV</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jan Verschelde, Kylash Viswanathan</dc:creator>
    </item>
    <item>
      <title>Riemannian Optimization and the Hartree-Fock Method</title>
      <link>https://arxiv.org/abs/2403.15024</link>
      <description>arXiv:2403.15024v1 Announce Type: cross 
Abstract: In the present work we studied a subfield of Applied Mathematics called Riemannian Optimization. The main goal of this subfield is to generalize algorithms, theorems and tools from Mathematical Optimization to the case in which the optimization problem is defined on a Riemannian manifold. As a case study, we implemented some of the main algorithms described in the literature (Gradient Descent, Newton-Raphson and Conjugate Gradient) to solve an optimization problem known as Hartree-Fock. This method is extremely important in the field of Computational Quantum Chemistry and it is a good case study because it is a problem somewhat hard to solve and, as a consequence of this, it requires many tools from Riemannian Optimization. Besides, it is also a good example to see how these algorithms perform in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15024v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Caio O. da Silva</dc:creator>
    </item>
    <item>
      <title>Optimal Contract Design for End-of-Life Care Payments</title>
      <link>https://arxiv.org/abs/2403.15099</link>
      <description>arXiv:2403.15099v1 Announce Type: cross 
Abstract: A large fraction of total healthcare expenditure occurs due to end-of-life (EOL) care, which means it is important to study the problem of more carefully incentivizing necessary versus unnecessary EOL care because this has the potential to reduce overall healthcare spending. This paper introduces a principal-agent model that integrates a mixed payment system of fee-for-service and pay-for-performance in order to analyze whether it is possible to better align healthcare provider incentives with patient outcomes and cost-efficiency in EOL care. The primary contributions are to derive optimal contracts for EOL care payments using a principal-agent framework under three separate models for the healthcare provider, where each model considers a different level of risk tolerance for the provider. We derive these optimal contracts by converting the underlying principal-agent models from a bilevel optimization problem into a single-level optimization problem that can be analytically solved. Our results are demonstrated using a simulation where an optimal contract is used to price intracranial pressure monitoring for traumatic brain injuries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15099v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.AP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Muyan Jiang, Ying Chen, Xin Chen, Javad Lavaei, Anil Aswani</dc:creator>
    </item>
    <item>
      <title>Stability and convergence of the Euler scheme for stochastic linear evolution equations in Banach spaces</title>
      <link>https://arxiv.org/abs/2211.08375</link>
      <description>arXiv:2211.08375v3 Announce Type: replace 
Abstract: For the Euler scheme of the stochastic linear evolution equations, discrete stochastic maximal $ L^p $-regularity estimate is established, and a sharp error estimate in the norm $ \|\cdot\|_{L^p((0,T)\times\Omega;L^q(\mathcal O))} $, $ p,q \in [2,\infty) $, is derived via a duality argument.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.08375v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Binjie Li, Xiaoping Xie</dc:creator>
    </item>
    <item>
      <title>A Stochastic ADMM Algorithm for Large-Scale Ptychography with Weighted Difference of Anisotropic and Isotropic Total Variation</title>
      <link>https://arxiv.org/abs/2301.02386</link>
      <description>arXiv:2301.02386v4 Announce Type: replace 
Abstract: Ptychography, a prevalent imaging technique in fields such as biology and optics, poses substantial challenges in its reconstruction process, characterized by nonconvexity and large-scale requirements. This paper presents a novel approach by introducing a class of variational models that incorporate the weighted difference of anisotropic--isotropic total variation. This formulation enables the handling of measurements corrupted by Gaussian or Poisson noise, effectively addressing the nonconvex challenge. To tackle the large-scale nature of the problem, we propose an efficient stochastic alternating direction method of multipliers, which guarantees convergence under mild conditions. Numerical experiments validate the superiority of our approach by demonstrating its capability to successfully reconstruct complex-valued images, especially in recovering the phase components even in the presence of highly corrupted measurements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.02386v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kevin Bui, Zichao Di</dc:creator>
    </item>
    <item>
      <title>Data-inspired modeling of accidents in traffic flow networks</title>
      <link>https://arxiv.org/abs/2305.03469</link>
      <description>arXiv:2305.03469v2 Announce Type: replace 
Abstract: We consider hyperbolic partial differential equations (PDEs) for a dynamic description of the traffic behavior in road networks. These equations are coupled to a Hawkes process that models traffic accidents taking into account their self-excitation property which means that accidents are more likely in areas in which another accident just occurred. We discuss how both model components interact and influence each other. A data analysis reveals the self-excitation property of accidents and determines further parameters. Numerical simulations using risk measures underline and conclude the discussion of traffic accident effects in our model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.03469v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Simone G\"ottlich, Thomas Schillinger</dc:creator>
    </item>
    <item>
      <title>Doubling the rate -- improved error bounds for orthogonal projection with application to numerical analysis</title>
      <link>https://arxiv.org/abs/2308.06052</link>
      <description>arXiv:2308.06052v2 Announce Type: replace 
Abstract: Convergence rates for $L_2$ approximation in a Hilbert space $H$ are a central theme in numerical analysis. The present work is inspired by Schaback (Math. Comp., 1999), who showed, in the context of best pointwise approximation for radial basis function interpolation, that the convergence rate for sufficiently smooth functions can be doubled, compared to the general rate for functions in the "native space" $H$. Motivated by this, we obtain a general result for $H$-orthogonal projection onto a finite dimensional subspace of $H$: namely, that any known $L_2$ convergence rate for all functions in $H$ translates into a doubled $L_2$ convergence rate for functions in a smoother normed space $B$, along with a similarly improved error bound in the $H$-norm, provided that $L_2$, $H$ and $B$ are suitably related. As a special case we improve the known $L_2$ and $H$-norm convergence rates for kernel interpolation in reproducing kernel Hilbert spaces, with particular attention to a recent study (Kaarnioja, Kazashi, Kuo, Nobile, Sloan, Numer. Math., 2022) of periodic kernel-based interpolation at lattice points applied to parametric partial differential equations. A second application is to radial basis function interpolation for general conditionally positive definite basis functions, where again the $L_2$ convergence rate is doubled, and the convergence rate in the native space norm is similarly improved, for all functions in a smoother normed space $B$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.06052v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ian H. Sloan, Vesa Kaarnioja</dc:creator>
    </item>
    <item>
      <title>Optimal finite element approximation of unique continuation</title>
      <link>https://arxiv.org/abs/2311.07440</link>
      <description>arXiv:2311.07440v2 Announce Type: replace 
Abstract: We consider finite element approximations of ill-posed elliptic problems with conditional stability. The notion of {\emph{optimal error estimates}} is defined including both convergence with respect to mesh parameter and perturbations in data. The rate of convergence is determined by the conditional stability of the underlying continuous problem and the polynomial order of the finite element approximation space. A proof is given that no finite element approximation can converge at a better rate than that given by the definition, justifying the concept. A recently introduced class of finite element methods with weakly consistent regularisation is recalled and the associated error estimates are shown to be quasi optimal in the sense of our definition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.07440v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Erik Burman, Mihai Nechita, Lauri Oksanen</dc:creator>
    </item>
    <item>
      <title>Eigenvector Continuation and Projection-Based Emulators</title>
      <link>https://arxiv.org/abs/2310.19419</link>
      <description>arXiv:2310.19419v2 Announce Type: replace-cross 
Abstract: Eigenvector continuation is a computational method for parametric eigenvalue problems that uses subspace projection with a basis derived from eigenvector snapshots from different parameter sets. It is part of a broader class of subspace-projection techniques called reduced-basis methods. In this colloquium article, we present the development, theory, and applications of eigenvector continuation and projection-based emulators. We introduce the basic concepts, discuss the underlying theory and convergence properties, and present recent applications for quantum systems and future prospects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.19419v2</guid>
      <category>nucl-th</category>
      <category>cond-mat.quant-gas</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>nucl-ex</category>
      <category>quant-ph</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thomas Duguet, Andreas Ekstr\"om, Richard J. Furnstahl, Sebastian K\"onig, Dean Lee</dc:creator>
    </item>
    <item>
      <title>Multiscale Hodge Scattering Networks for Data Analysis</title>
      <link>https://arxiv.org/abs/2311.10270</link>
      <description>arXiv:2311.10270v2 Announce Type: replace-cross 
Abstract: We propose new scattering networks for signals measured on simplicial complexes, which we call \emph{Multiscale Hodge Scattering Networks} (MHSNs). Our construction is based on multiscale basis dictionaries on simplicial complexes, i.e., the $\kappa$-GHWT and $\kappa$-HGLET, which we recently developed for simplices of dimension $\kappa \in \mathbb{N}$ in a given simplicial complex by generalizing the node-based Generalized Haar-Walsh Transform (GHWT) and Hierarchical Graph Laplacian Eigen Transform (HGLET). The $\kappa$-GHWT and the $\kappa$-HGLET both form redundant sets (i.e., dictionaries) of multiscale basis vectors and the corresponding expansion coefficients of a given signal. Our MHSNs use a layered structure analogous to a convolutional neural network (CNN) to cascade the moments of the modulus of the dictionary coefficients. The resulting features are invariant to reordering of the simplices (i.e., node permutation of the underlying graphs). Importantly, the use of multiscale basis dictionaries in our MHSNs admits a natural pooling operation that is akin to local pooling in CNNs, and which may be performed either locally or per-scale. These pooling operations are harder to define in both traditional scattering networks based on Morlet wavelets, and geometric scattering networks based on Diffusion Wavelets. As a result, we are able to extract a rich set of descriptive yet robust features that can be used along with very simple machine learning methods (i.e., logistic regression or support vector machines) to achieve high-accuracy classification systems with far fewer parameters to train than most modern graph neural networks. Finally, we demonstrate the usefulness of our MHSNs in three distinct types of problems: signal classification, domain (i.e., graph/simplex) classification, and molecular dynamics prediction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.10270v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>cs.SI</category>
      <category>eess.SP</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Naoki Saito, Stefan C. Schonsheck, Eugene Shvarts</dc:creator>
    </item>
    <item>
      <title>Elastic Analysis of Augmented Curves and Constrained Surfaces</title>
      <link>https://arxiv.org/abs/2402.04944</link>
      <description>arXiv:2402.04944v2 Announce Type: replace-cross 
Abstract: The square root velocity transformation is crucial for efficiently employing the elastic approach in functional and shape data analysis of curves. We study fundamental geometric properties of curves under this transformation. Moreover, utilizing natural geometric constructions, we employ the approach for intrinsic comparison within several classes of surfaces and augmented curves, which arise in the real world applications such as tubes, ruled surfaces spherical strips, protein molecules and hurricane tracks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.04944v2</guid>
      <category>math.DG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Esfandiar Nava-Yazdani</dc:creator>
    </item>
    <item>
      <title>Mathematical Opportunities in Digital Twins (MATH-DT)</title>
      <link>https://arxiv.org/abs/2402.10326</link>
      <description>arXiv:2402.10326v2 Announce Type: replace-cross 
Abstract: The report describes the discussions from the Workshop on Mathematical Opportunities in Digital Twins (MATH-DT) from December 11-13, 2023, George Mason University.
  It illustrates that foundational Mathematical advances are required for Digital Twins (DTs) that are different from traditional approaches. A traditional model, in biology, physics, engineering or medicine, starts with a generic physical law (e.g., equations) and is often a simplification of reality. A DT starts with a specific ecosystem, object or person (e.g., personalized care) representing reality, requiring multi -scale, -physics modeling and coupling. Thus, these processes begin at opposite ends of the simulation and modeling pipeline, requiring different reliability criteria and uncertainty assessments. Additionally, unlike existing approaches, a DT assists humans to make decisions for the physical system, which (via sensors) in turn feeds data into the DT, and operates for the life of the physical system.
  While some of the foundational mathematical research can be done without a specific application context, one must also keep specific applications in mind for DTs. E.g., modeling a bridge or a biological system (a patient), or a socio-technical system (a city) is very different. The models range from differential equations (deterministic/uncertain) in engineering, to stochastic in biology, including agent-based. These are multi-scale hybrid models or large scale (multi-objective) optimization problems under uncertainty. There are no universal models or approaches. For e.g., Kalman filters for forecasting might work in engineering, but can fail in biomedical domain. Ad hoc studies, with limited systematic work, have shown that AI/ML methods can fail for simple engineering systems and can work well for biomedical problems.
  A list of `Mathematical Opportunities and Challenges' concludes the report.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.10326v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Harbir Antil</dc:creator>
    </item>
    <item>
      <title>Inferring solar differential rotation and viscosity via passive imaging with inertial waves</title>
      <link>https://arxiv.org/abs/2403.00488</link>
      <description>arXiv:2403.00488v2 Announce Type: replace-cross 
Abstract: The recent discovery of inertial waves on the surface of the Sun offers new possibilities to learn about the solar interior. These waves are long-lived with a period on the order of the Sun rotation period ($\sim$27 days) and are sensitive to parameters deep inside the Sun. They are excited by turbulent convection, leading to a passive imaging problem. In this work, we present the forward and inverse problem of reconstructing viscosity and differential rotation on the Sun from cross-covariance observations of these inertial waves.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.00488v2</guid>
      <category>astro-ph.SR</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tram Thi Ngoc Nguyen, Thorsten Hohage, Damien Fournier, Laurent Gizon</dc:creator>
    </item>
  </channel>
</rss>
