<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.geo-ph updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.geo-ph</link>
    <description>physics.geo-ph updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.geo-ph" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 04 Sep 2025 01:30:33 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Revealing Hidden Precursors to Earthquakes via a Stress-Sensitive Transformation of Seismic Noise</title>
      <link>https://arxiv.org/abs/2509.00268</link>
      <description>arXiv:2509.00268v1 Announce Type: new 
Abstract: Earthquake prediction has long been one of the most elusive challenges in science. Laboratory experiments and simulations suggest that failure precursors should exist, yet reliable signals have remained unobserved in real-world seismic records, leaving open the question of whether they are absent in nature or simply hidden within noise. Here we introduce a stress-sensitive frequency-domain transformation that tracks energy differences between adjacent frequency bands, isolating subtle spectral changes linked to evolving shear and normal stress. Applied to both laboratory acoustic emission data and seismic records from seven major earthquakes (Mw 5.9-9.0), including the 2011 Tohoku and 2023 Turkey-Syria events, the transform consistently reveals precursory signatures, arc-like trajectories and accelerations toward extrema, emerging hours to days before rupture. These features are robust across diverse tectonic settings, from induced seismicity and volcanic collapse to continental strike-slip and subduction megathrust earthquakes. Our findings demonstrate that hidden precursors are indeed encoded in ambient seismic noise, offering a pathway toward real-time fault monitoring and actionable short-term earthquake forecasting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.00268v1</guid>
      <category>physics.geo-ph</category>
      <category>cs.AI</category>
      <category>eess.SP</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nader Shakibay Senobari</dc:creator>
    </item>
    <item>
      <title>A computer vision-based approach to enhance seismic catalogues</title>
      <link>https://arxiv.org/abs/2509.00791</link>
      <description>arXiv:2509.00791v1 Announce Type: new 
Abstract: In recent years, AI and deep learning earthquake detectors, combined with an increasing number of dense seismic networks deployed worldwide, have further contributed to the creation of massive seismic catalogs, significantly lowering their magnitude of completeness. However, these automated catalogs are typically released without systematic quality control, and may contain spurious detections, mislocations, or inconsistent magnitudes. In challenging scenarios, such as microseismic monitoring applications, where weak and closely spaced events often overlap in time, pick-based detection and location approaches often fail to reliably associate phases. This leads to missed detections or degraded location accuracy producing seismic catalogues polluted with false or mislocated events. To address this limitation, we present a computer vision-based workflow that integrates waveform-based seismic location methods with deep learning image classification to discriminate real seismic events from noise directly from coherence matrices. These matrices, computed via waveform stacking, exhibit distinct patterns for real events (single, focused maxima) versus noise (blurred, incoherent patterns) hence the problem of cleaning seismic catalogues can be solved as a binary image classification problem. In addition, the robustness of waveform-based location methods allows to obtain an increased resolution in the location of seismic events. Another advantage of this approach is that the training of neural networks can be based entirely on synthetic data. This synthetic-based training removes the need for large labeled datasets, enabling rapid deployment in newly instrumented areas. We validate our workflow using the publicly available COSEISMIQ dataset from the Hengill geothermal area, in Iceland.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.00791v1</guid>
      <category>physics.geo-ph</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michele De Solda, Francesco Grigoli, Sonja Gaviano, Giacomo Rapagnani, Bogdan Enescu</dc:creator>
    </item>
    <item>
      <title>Using explainable artificial intelligence (XAI) as a diagnostic tool: An application for deducing hydrologic connectivity at watershed scale</title>
      <link>https://arxiv.org/abs/2509.02127</link>
      <description>arXiv:2509.02127v1 Announce Type: new 
Abstract: Explainable artificial intelligence (XAI) methods have been applied to interpret deep learning model results. However, applications that integrate XAI with established hydrologic knowledge for process understanding remain limited. Here we present a framework that apply XAI method at point-scale to provide granular interpretation and enable cross-scale aggregation of hydrologic responses. Hydrologic connectivity is used as a demonstration of the value of this approach. Soil moisture and its movement generated by physically based hydrologic model were used to train a long short-term memory (LSTM) network, whose impacts of inputs were evaluated by XAI methods. Our results suggest that XAI-based classification can effectively identify the differences in the functional roles of various sub-regions at watershed scale. The aggregated XAI results provide an explicit and quantitative indicator of hydrologic connectivity development, offering insights to streamflow variation. This framework could be used to facilitate aggregation of other hydrologic responses to advance process understandings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02127v1</guid>
      <category>physics.geo-ph</category>
      <category>cs.LG</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sheng Ye, Jiyu Li, Yifan Chai, Lin Liu, Murugesu Sivapalan, Qihua Ran</dc:creator>
    </item>
    <item>
      <title>Earthquake Source Depth Determination using Single Station Waveforms and Deep Learning</title>
      <link>https://arxiv.org/abs/2509.02346</link>
      <description>arXiv:2509.02346v1 Announce Type: new 
Abstract: In areas with limited station coverage, earthquake depth constraints are much less accurate than their latitude and longitude. Traditional travel-time-based location methods struggle to constrain depths due to imperfect station distribution and the strong trade-off between source depth and origin time. Identifying depth phases at regional distances is usually hindered by strong wave scattering, which is particularly challenging for low-magnitude events. Deep learning algorithms, capable of extracting various features from seismic waveforms, including phase arrivals, phase amplitudes, as well as phase frequency, offer promising constraints to earthquake depths. In this work, we propose a novel depth feature extraction network (named VGGDepth), which directly maps seismic waveforms to earthquake depth using three-component waveforms. The network structure is adapted from VGG16 in computer vision. It is designed to take single-station three-component waveforms as inputs and produce depths as outputs, achieving a direct mapping from waveforms to depths. Two scenarios are considered in our model development: (1) training and testing solely on the same seismic station, and (2) generalizing by training and testing on different seismic stations within a particular region. We demonstrate the efficacy of our methodology using seismic data from the 2016-2017 Central Apennines, Italy earthquake sequence. Results demonstrate that earthquake depths can be estimated from single stations with uncertainties of hundreds of meters. These uncertainties are further reduced by averaging results from multiple stations. Our method shows strong potential for earthquake depth determination, particularly for events recorded by single or sparsely distributed stations, such as historically instrumented earthquakes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02346v1</guid>
      <category>physics.geo-ph</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Wenda Li, Miao Zhang</dc:creator>
    </item>
    <item>
      <title>Quantum Phase Space Tomography for Electromagnetic Biomaterial Imaging</title>
      <link>https://arxiv.org/abs/2509.00534</link>
      <description>arXiv:2509.00534v1 Announce Type: cross 
Abstract: I present a concise, first principles metrological framework for imaging dielectric biomaterials by probing the full phase space (Wigner) distribution of a quantum electromagnetic field. Building on a rigorous multilayer Maxwell and Cole Cole model for stratified tissue, my method (Quantum Phase space Tomography, QPST) couples analytical forward theory with quantum metrology and Bayesian inference. I prepare a structured quantum EM probe (e.g. a squeezed microwave pulse) that interacts with tissue and then perform full quantum state tomography of the outgoing field. The recovered Wigner quasi probability reveals subwavelength and non classical features lost in classical imaging. By projecting the measurement onto the analytically derived tissue response manifold, I recover key physiological parameters (e.g. layer thickness, dispersion). I further define a Dielectric Anaplasia Metric (DAM) that quantifies tissue microstructural heterogeneity (e.g. malignancy) via deviations in Cole Cole parameters. My design leverages state of the art quantum sensors (e.g. NV diamond magnetometers) and advanced inverse algorithms (physics informed neural networks, diffusion priors). Numerical examples demonstrate that QPST can non invasively map tissue permittivity with unprecedented sensitivity. This work bridges fundamental electromagnetic theory and emerging quantum technologies, promising a new paradigm for medical imaging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.00534v1</guid>
      <category>physics.optics</category>
      <category>physics.geo-ph</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alessandro Settimi</dc:creator>
    </item>
    <item>
      <title>Knowledge distillation as a pathway toward next-generation intelligent ecohydrological modeling systems</title>
      <link>https://arxiv.org/abs/2509.01972</link>
      <description>arXiv:2509.01972v1 Announce Type: cross 
Abstract: Simulating ecohydrological processes is essential for understanding complex environmental systems and guiding sustainable management amid accelerating climate change and human pressures. Process-based models provide physical realism but can suffer from structural rigidity, high computational costs, and complex calibration, while machine learning (ML) methods are efficient and flexible yet often lack interpretability and transferability. We propose a unified three-phase framework that integrates process-based models with ML and progressively embeds them into artificial intelligence (AI) through knowledge distillation. Phase I, behavioral distillation, enhances process models via surrogate learning and model simplification to capture key dynamics at lower computational cost. Phase II, structural distillation, reformulates process equations as modular components within a graph neural network (GNN), enabling multiscale representation and seamless integration with ML models. Phase III, cognitive distillation, embeds expert reasoning and adaptive decision-making into intelligent modeling agents using the Eyes-Brain-Hands-Mouth architecture. Demonstrations for the Samish watershed highlight the framework's applicability to ecohydrological modeling, showing that it can reproduce process-based model outputs, improve predictive accuracy, and support scenario-based decision-making. The framework offers a scalable and transferable pathway toward next-generation intelligent ecohydrological modeling systems, with the potential extension to other process-based domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.01972v1</guid>
      <category>cs.LG</category>
      <category>physics.geo-ph</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Long Jiang, Yang Yang, Ting Fong May Chui, Morgan Thornwell, Hoshin Vijai Gupta</dc:creator>
    </item>
    <item>
      <title>Controlled Latent Diffusion Models for 3D Porous Media Reconstruction</title>
      <link>https://arxiv.org/abs/2503.24083</link>
      <description>arXiv:2503.24083v3 Announce Type: replace 
Abstract: Note: The final version of this article was published in Computers and Geosciences, Volume 206, January 2026, 106038. DOI: 10.1016/j.cageo.2025.106038. Readers should refer to the published version for the most up-to-date content. Three-dimensional digital reconstruction of porous media presents a fundamental challenge in geoscience, requiring simultaneous resolution of fine-scale pore structures while capturing representative elementary volumes. We introduce a computational framework that addresses this challenge through latent diffusion models operating within the EDM framework. Our approach reduces dimensionality via a custom variational autoencoder trained in binary geological volumes, improving efficiency and also enabling the generation of larger volumes than previously possible with diffusion models. A key innovation is our controlled unconditional sampling methodology, which enhances distribution coverage by first sampling target statistics from their empirical distributions, then generating samples conditioned on these values. Extensive testing on four distinct rock types demonstrates that conditioning on porosity - a readily computable statistic - is sufficient to ensure a consistent representation of multiple complex properties, including permeability, two-point correlation functions, and pore size distributions. The framework achieves better generation quality than pixel-space diffusion while enabling significantly larger volume reconstruction (256-cube voxels) with substantially reduced computational requirements, establishing a new state-of-the-art for digital rock physics applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.24083v3</guid>
      <category>physics.geo-ph</category>
      <category>cs.LG</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.cageo.2025.106038</arxiv:DOI>
      <arxiv:journal_reference>Computers &amp; Geosciences Volume 206, January 2026, 106038</arxiv:journal_reference>
      <dc:creator>Danilo Naiff, Bernardo P. Schaeffer, Gustavo Pires, Dragan Stojkovic, Thomas Rapstine, Fabio Ramos</dc:creator>
    </item>
    <item>
      <title>Parallel Seismic Data Processing Performance with Cloud-based Storage</title>
      <link>https://arxiv.org/abs/2504.09075</link>
      <description>arXiv:2504.09075v2 Announce Type: replace 
Abstract: This article introduces a general processing framework to effectively utilize waveform data stored on modern cloud platforms. The focus is hybrid processing schemes where a local system drives processing. We show that downloading files and doing all processing locally is problematic even when the local system is a high-performance compute cluster. Benchmark tests with parallel processing show that approach always creates a bottleneck as the volume of data being handled increases with more processes pulling data. We find a hybrid model where processing to reduce the volume of data transferred from the cloud servers to the local system can dramatically improve processing time. Tests implemented with Massively Parallel Analysis System for Seismology (MsPASS) utilizing Amazon Web Service's Lamba service yield throughput comparable to processing day files on a local HPC file system. Given the ongoing migration of seismology data to cloud storage, our results show doing some or all processing on the cloud will be essential for any processing involving large volumes of data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.09075v2</guid>
      <category>physics.geo-ph</category>
      <category>cs.DC</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sasmita Mohapatra, Weiming Yang, Zhengtang Yang, Chenxiao Wang, Jinxin Ma, Gary L. Pavlis, Yinzhi Wang</dc:creator>
    </item>
  </channel>
</rss>
