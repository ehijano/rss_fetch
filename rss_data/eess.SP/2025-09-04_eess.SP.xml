<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>eess.SP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/eess.SP</link>
    <description>eess.SP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/eess.SP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 05 Sep 2025 01:25:26 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>EEG-MSAF: An Interpretable Microstate Framework uncovers Default-Mode Decoherence in Early Neurodegeneration</title>
      <link>https://arxiv.org/abs/2509.02568</link>
      <description>arXiv:2509.02568v1 Announce Type: new 
Abstract: Dementia (DEM) is a growing global health challenge, underscoring the need for early and accurate diagnosis. Electroencephalography (EEG) provides a non-invasive window into brain activity, but conventional methods struggle to capture its transient complexity. We present the \textbf{EEG Microstate Analysis Framework (EEG-MSAF)}, an end-to-end pipeline that leverages EEG microstates discrete, quasi-stable topographies to identify DEM-related biomarkers and distinguish DEM, mild cognitive impairment (MCI), and normal cognition (NC). EEG-MSAF comprises three stages: (1) automated microstate feature extraction, (2) classification with machine learning (ML), and (3) feature ranking using Shapley Additive Explanations (SHAP) to highlight key biomarkers. We evaluate on two EEG datasets: the public Chung-Ang University EEG (CAUEEG) dataset and a clinical cohort from Thessaloniki Hospital. Our framework demonstrates strong performance and generalizability. On CAUEEG, EEG-MSAF-SVM achieves \textbf{89\% $\pm$ 0.01 accuracy}, surpassing the deep learning baseline CEEDNET by \textbf{19.3\%}. On the Thessaloniki dataset, it reaches \textbf{95\% $\pm$ 0.01 accuracy}, comparable to EEGConvNeXt. SHAP analysis identifies mean correlation and occurrence as the most informative metrics: disruption of microstate C (salience/attention network) dominates DEM prediction, while microstate F, a novel default-mode pattern, emerges as a key early biomarker for both MCI and DEM. By combining accuracy, generalizability, and interpretability, EEG-MSAF advances EEG-based dementia diagnosis and sheds light on brain dynamics across the cognitive spectrum.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02568v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad Mehedi Hasan, Pedro G. Lind, Hernando Ombao, Anis Yazidi, Rabindra Khadka</dc:creator>
    </item>
    <item>
      <title>Recall Gabor Communication Theory and Joint Time-Frequency Analysis</title>
      <link>https://arxiv.org/abs/2509.02724</link>
      <description>arXiv:2509.02724v2 Announce Type: new 
Abstract: In this article, we first briefly recall Gabor's communication theory and then Gabor transform and expansion, and also its connection with joint time frequency analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02724v2</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiang-Gen Xia</dc:creator>
    </item>
    <item>
      <title>minPIC: Towards Optimal Power Allocation in Multi-User Interference Channels</title>
      <link>https://arxiv.org/abs/2509.02797</link>
      <description>arXiv:2509.02797v1 Announce Type: new 
Abstract: 6G envisions massive cell-free networks with spatially nested multiple access (MAC) and broadcast (BC) channels without centralized coordination. This makes optimal resource allocation across power, subcarriers, and decoding orders crucial for interference channels (ICs), where neither transmitters nor receivers can cooperate. Current orthogonal multiple access (OMA) methods, as well as non-orthogonal (NOMA) and rate-splitting (RSMA) schemes, rely on fixed heuristics for interference management, leading to suboptimal rates, power inefficiency, and scalability issues. This paper proposes a novel minPIC framework for optimal power, subcarrier, and decoding order allocation in general multi-user ICs. Unlike existing methods, minPIC eliminates heuristic SIC order assumptions. Despite the convexity of the IC capacity region, fixing an SIC order induces non-convexity in resource allocation, traditionally requiring heuristic approximations. We instead introduce a dual-variable-guided sorting criterion to identify globally optimal SIC orders, followed by convex optimization with auxiliary log-det constraints, efficiently solved via binary search. We also demonstrate that minPIC could potentially meet the stringent high-rate, low-power targets of immersive XR and other 6G applications. To the best of our knowledge, minPIC is the first algorithmic realisation of the Pareto boundary of the SIC-achievable rate region for Gaussian ICs, opening the door to scalable interference management in cell-free networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02797v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Sagnik Bhattacharya, Abhiram Rao Gorle, John M. Cioffi</dc:creator>
    </item>
    <item>
      <title>Protecting Legacy Wireless Systems Against Interference: Precoding and Codebook Approaches Using Massive MIMO and Region Constraints</title>
      <link>https://arxiv.org/abs/2509.02819</link>
      <description>arXiv:2509.02819v1 Announce Type: new 
Abstract: The ever-increasing demand for high-speed wireless communication has generated significant interest in utilizing frequency bands that are adjacent to those occupied by legacy wireless systems. Since the legacy wireless systems were designed based on often decades-old assumptions about wireless interference, utilizing these new bands will result in interference with the existing legacy users. Many of these legacy wireless devices are used by critical infrastructure networks upon which society depends. There is an urgent need to develop schemes that can protect legacy users from such interference. For many applications, legacy users are located within geographically-constrained regions. Several studies have proposed mitigating interference through the implementation of exclusion zones near these geographically-constrained regions. In contrast to solutions based on geographic exclusion zones, this paper presents a communication theory-based solution. By leveraging knowledge of these geographically-constrained regions, we aim to reduce the interference impact on legacy users. We achieve this by incorporating received power constraints, termed as region constraints, in our massive multiple-input multiple-output (MIMO) system design. We perform a capacity analysis of single-user massive MIMO and a sum-rate analysis of the multi-user massive MIMO system with transmit power and region constraints. We present a precoding design method that allows for the utilization of new frequency bands while protecting legacy users.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02819v1</guid>
      <category>eess.SP</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sameer Mathad, Taejoon Kim, David J. Love</dc:creator>
    </item>
    <item>
      <title>Spatially Adaptive SWIPT with Pinching Antenna under Probabilistic LoS Blockage</title>
      <link>https://arxiv.org/abs/2509.03038</link>
      <description>arXiv:2509.03038v1 Announce Type: new 
Abstract: This paper considers a power-splitting (PS)-based simultaneous wireless information and power transfer (SWIPT) system employing a reconfigurable pinching antenna (PA) under probabilistic line-of-sight (LoS) blockage. We formulate a joint optimization of the PA position and the PS ratio to maximize the average signal-to-noise ratio (SNR) at a user, subject to its average energy harvesting (EH) and PA placement limits. We derive a closed-form optimal solution. Results demonstrate that the EH requirement has a deterministic impact on the optimal PA position as well as its feasible region, requiring deployment of the PA as close to the user as possible to maximize average channel gain. This spatial adaptation, combined with dynamic PS, enables robust SWIPT performance in the presence of probabilistic LoS blockage, revealing that mechanical reconfigurability primarily enhances sustainability by ensuring energy feasibility in dynamic environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03038v1</guid>
      <category>eess.SP</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ruihong Jiang, Ruichen Zhang, Yanqing Xu, Huimin Hu, Yang Lu, Dusit Niyato</dc:creator>
    </item>
    <item>
      <title>S2M2ECG: Spatio-temporal bi-directional State Space Model Enabled Multi-branch Mamba for ECG</title>
      <link>https://arxiv.org/abs/2509.03066</link>
      <description>arXiv:2509.03066v1 Announce Type: new 
Abstract: As one of the most effective methods for cardiovascular disease (CVD) diagnosis, multi-lead Electrocardiogram (ECG) signals present a characteristic multi-sensor information fusion challenge that has been continuously researched in deep learning domains. Despite the numerous algorithms proposed with different DL architectures, maintaining a balance among performance, computational complexity, and multi-source ECG feature fusion remains challenging. Recently, state space models (SSMs), particularly Mamba, have demonstrated remarkable effectiveness across various fields. Their inherent design for high-efficiency computation and linear complexity makes them particularly suitable for low-dimensional data like ECGs. This work proposes S2M2ECG, an SSM architecture featuring three-level fusion mechanisms: (1) Spatio-temporal bi-directional SSMs with segment tokenization for low-level signal fusion, (2) Intra-lead temporal information fusion with bi-directional scanning to enhance recognition accuracy in both forward and backward directions, (3) Cross-lead feature interaction modules for spatial information fusion. To fully leverage the ECG-specific multi-lead mechanisms inherent in ECG signals, a multi-branch design and lead fusion modules are incorporated, enabling individual analysis of each lead while ensuring seamless integration with others. Experimental results reveal that S2M2ECG achieves superior performance in the rhythmic, morphological, and clinical scenarios. Moreover, its lightweight architecture ensures it has nearly the fewest parameters among existing models, making it highly suitable for efficient inference and convenient deployment. Collectively, S2M2ECG offers a promising alternative that strikes an excellent balance among performance, computational complexity, and ECG-specific characteristics, paving the way for high-performance, lightweight computations in CVD diagnosis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03066v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huaicheng Zhang, Ruoxin Wang, Chenlian Zhou, Jiguang Shi, Yue Ge, Zhoutong Li, Sheng Chang, Hao Wang, Jin He, Qijun Huang</dc:creator>
    </item>
    <item>
      <title>YOLO-based Bearing Fault Diagnosis With Continuous Wavelet Transform</title>
      <link>https://arxiv.org/abs/2509.03070</link>
      <description>arXiv:2509.03070v1 Announce Type: new 
Abstract: This letter proposes a YOLO-based framework for spatial bearing fault diagnosis using time-frequency spectrograms derived from continuous wavelet transform (CWT). One-dimensional vibration signals are first transformed into time-frequency spectrograms using Morlet wavelets to capture transient fault signatures. These spectrograms are then processed by YOLOv9, v10, and v11 models to classify fault types. Evaluated on three benchmark datasets, including Case Western Reserve University (CWRU), Paderborn University (PU), and Intelligent Maintenance System (IMS), the proposed CWT--YOLO pipeline achieves significantly higher accuracy and generalizability than the baseline MCNN--LSTM model. Notably, YOLOv11 reaches mAP scores of 99.4% (CWRU), 97.8% (PU), and 99.5% (IMS). In addition, its region-aware detection mechanism enables direct visualization of fault locations in spectrograms, offering a practical solution for condition monitoring in rotating machinery.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03070v1</guid>
      <category>eess.SP</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Po-Heng Chou, Wei-Lung Mao, Ru-Ping Lin</dc:creator>
    </item>
    <item>
      <title>Self-supervised Radio Representation Learning: Can we Learn Multiple Tasks?</title>
      <link>https://arxiv.org/abs/2509.03077</link>
      <description>arXiv:2509.03077v1 Announce Type: new 
Abstract: Artificial intelligence (AI) is anticipated to play a pivotal role in 6G. However, a key challenge in developing AI-powered solutions is the extensive data collection and labeling efforts required to train supervised deep learning models. To overcome this, self-supervised learning (SSL) approaches have recently demonstrated remarkable success across various domains by leveraging large volumes of unlabeled data to achieve near-supervised performance. In this paper, we propose an effective SSL scheme for radio signal representation learning using momentum contrast. By applying contrastive learning, our method extracts robust, transferable representations from a large real-world dataset. We assess the generalizability of these learned representations across two wireless communications tasks: angle of arrival (AoA) estimation and automatic modulation classification (AMC). Our results show that carefully designed augmentations and diverse data enable contrastive learning to produce high-quality, invariant latent representations. These representations are effective even with frozen encoder weights, and fine-tuning further enhances performance, surpassing supervised baselines. To the best of our knowledge, this is the first work to propose and demonstrate the effectiveness of self-supervised learning for radio signals across multiple tasks. Our findings highlight the potential of self-supervised learning to transform AI for wireless communications by reducing dependence on labeled data and improving model generalization - paving the way for scalable foundational 6G AI models and solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03077v1</guid>
      <category>eess.SP</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ogechukwu Kanu, Ashkan Eshaghbeigi, Hatem Abou-Zeid</dc:creator>
    </item>
    <item>
      <title>Handwriting Imagery EEG Classification based on Convolutional Neural Networks</title>
      <link>https://arxiv.org/abs/2509.03111</link>
      <description>arXiv:2509.03111v1 Announce Type: new 
Abstract: Handwriting imagery has emerged as a promising paradigm for brain-computer interfaces (BCIs) aimed at translating brain activity into text output. Compared with invasively recorded electroencephalography (EEG), non-invasive recording offers a more practical and feasible approach to capturing brain signals for BCI. This study explores the limit of decoding non-invasive EEG associated with handwriting imagery into English letters using deep neural networks. To this end, five participants were instructed to imagine writing the 26 English letters with their EEG being recorded from the scalp. A measurement of EEG similarity across letters was conducted to investigate letter-specific patterns in the dataset. Subsequently, four convolutional neural network (CNN) models were trained for EEG classification. Descriptively, the EEG data clearly exhibited letter-specific patterns serving as a proof-of-concept for EEG-to-text translation. Under the chance level of accuracy at 3.85%, the CNN classifiers trained on each participant reached the highest limit of around 20%. This study marks the first attempt to decode non-invasive EEG associated with handwriting imagery. Although the achieved accuracy is not sufficient for a usable brain-to-text BCI, the model's performance is noteworthy in revealing the potential for translating non-invasively recorded brain signals into text outputs and establishing a baseline for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03111v1</guid>
      <category>eess.SP</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hao Yang, Guang Ouyang</dc:creator>
    </item>
    <item>
      <title>Deep Learning for High Speed Optical Coherence Elastography with a Fiber Scanning Endoscope</title>
      <link>https://arxiv.org/abs/2509.03193</link>
      <description>arXiv:2509.03193v1 Announce Type: new 
Abstract: Tissue stiffness is related to soft tissue pathologies and can be assessed through palpation or via clinical imaging systems, e.g., ultrasound or magnetic resonance imaging. Typically, the image based approaches are not suitable during interventions, particularly for minimally invasive surgery. To this end, we present a miniaturized fiber scanning endoscope for fast and localized elastography. Moreover, we propose a deep learning based signal processing pipeline to account for the intricate data and the need for real-time estimates. Our elasticity estimation approach is based on imaging complex and diffuse wave fields that encompass multiple wave frequencies and propagate in various directions. We optimize the probe design to enable different scan patterns. To maximize temporal sampling while maintaining three-dimensional information we define a scan pattern in a conical shape with a temporal frequency of 5.05 kHz. To efficiently process the image sequences of complex wave fields we consider a spatio-temporal deep learning network. We train the network in an end-to-end fashion on measurements from phantoms representing multiple elasticities. The network is used to obtain localized and robust elasticity estimates, allowing to create elasticity maps in real-time. For 2D scanning, our approach results in a mean absolute error of 6.31+-5.76 kPa compared to 11.33+-12.78 kPa for conventional phase tracking. For scanning without estimating the wave direction, the novel 3D method reduces the error to 4.48+-3.63 kPa compared to 19.75+-21.82 kPa for the conventional 2D method. Finally, we demonstrate feasibility of elasticity estimates in ex-vivo porcine tissue.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03193v1</guid>
      <category>eess.SP</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TMI.2024.3505676</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Medical Imaging, vol. 44, no. 3, pp. 1445-1453, March 2025</arxiv:journal_reference>
      <dc:creator>Maximilian Neidhardt, Sarah Latus, Tim Eixmann, Gereon H\"uttmann, Alexander Schlaefer</dc:creator>
    </item>
    <item>
      <title>Crosstalk-Resilient Beamforming for Movable Antenna Enabled Integrated Sensing and Communication</title>
      <link>https://arxiv.org/abs/2509.03273</link>
      <description>arXiv:2509.03273v1 Announce Type: new 
Abstract: This paper investigates a movable antenna (MA) enabled integrated sensing and communication (ISAC) system under the influence of antenna crosstalk. First, it generalizes the antenna crosstalk model from the conventional fixed-position antenna (FPA) system to the MA scenario. Then, a Cramer-Rao bound (CRB) minimization problem driven by joint beamforming and antenna position design is presented. Specifically, to address this highly non-convex flexible beamforming problem, we deploy a deep reinforcement learning (DRL) approach to train a flexible beamforming agent. To ensure stability during training, a Twin Delayed Deep Deterministic Policy Gradient (TD3) algorithm is adopted to balance exploration with reward maximization for efficient and reliable learning. Numerical results demonstrate that the proposed crosstalk-resilient (CR) algorithm enhances the overall ISAC performance compared to other benchmark schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03273v1</guid>
      <category>eess.SP</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zeyuan Zhang, Yue Xiu, Zheng Dong, Jiacheng Yin, Maurice J. Khabbaz, Chadi Assi, Ning Wei</dc:creator>
    </item>
    <item>
      <title>Credible Uncertainty Quantification under Noise and System Model Mismatch</title>
      <link>https://arxiv.org/abs/2509.03311</link>
      <description>arXiv:2509.03311v1 Announce Type: new 
Abstract: State estimators often provide self-assessed uncertainty metrics, such as covariance matrices, whose reliability is critical for downstream tasks. However, these self-assessments can be misleading due to underlying modeling violations like noise or system model mismatch. This letter addresses the problem of estimator credibility by introducing a unified, multi-metric evaluation framework. We construct a compact credibility portfolio that synergistically combines traditional metrics like the Normalized Estimation Error Squared (NEES) and the Noncredibility Index (NCI) with proper scoring rules, namely the Negative Log-Likelihood (NLL) and the Energy Score (ES). Our key contributions are a novel energy distance-based location test to robustly detect system model misspecification and a method that leverages the asymmetric sensitivities of NLL and ES to distinguish optimism covariance scaling from system bias. Monte Carlo simulations across six distinct credibility scenarios demonstrate that our proposed method achieves high classification accuracy (80-100%), drastically outperforming single-metric baselines which consistently fail to provide a complete and correct diagnosis. This framework provides a practical tool for turning patterns of credibility indicators into actionable diagnoses of model deficiencies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03311v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Penggao Yan, Li-Ta Hsu</dc:creator>
    </item>
    <item>
      <title>Baseband Model, Cutoff Rate Bounds and Constellation Shaping for Mixed Gaussian-Impulsive Noise</title>
      <link>https://arxiv.org/abs/2509.03333</link>
      <description>arXiv:2509.03333v1 Announce Type: new 
Abstract: Mixed noise, composed of white Gaussian noise (WGN) and impulsive noise (IN), appears in numerous communication scenarios and can severely degrade system performance. In this paper, we address this issue by optimizing the transmitted constellation under mixed noise based on a theoretical analysis of the cutoff rate (CR). First, starting from the passband model of the mixed noise, we derive its corresponding baseband representation. Due to the complexity of the CR, an exact analytic expression is generally intractable. Therefore, the baseband noise model is employed to obtain closed-form lower and upper bounds of the CR. A piecewise linear approximation is applied to derive efficient bounds by exploiting the algebraic properties of the integral terms. These bounds are then used as criteria to optimize the transmitted constellation points in both geometric and probabilistic distributions. The projected gradient method is employed to solve the optimization problem, and the convergence and properties of the solutions are analyzed. Numerical results demonstrate that the proposed CR bounds are tight and exhibit the expected asymptotic behavior. Furthermore, the optimized constellation scheme achieves a significant rate improvement compared to baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03333v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianfu Qi, Jun Wang</dc:creator>
    </item>
    <item>
      <title>Efficient DoA Estimation with Hybrid Linear and Rectangular Arrays Using Compact DFT Codebook</title>
      <link>https://arxiv.org/abs/2509.03488</link>
      <description>arXiv:2509.03488v1 Announce Type: new 
Abstract: Hybrid Analog and Digital (HAD) architectures provide a cost-effective alternative for large-scale antenna arrays, but accurate Direction-of-Arrival (DoA) estimation remains challenging due to limited digital dimensionality and constrained beamforming design. In this work, we propose a HAD architecture that employs Butler matrices to synthesize DFT beams over a uniform linear array. By exploiting the Cauchy-like displacement structure of the beamformed signal, we introduce a second-order statistics estimation algorithm that achieves near-optimal accuracy, approaching the Cram\'er-Rao Lower Bound (CRLB) and outperforming state-of-the-art methods in simulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03488v1</guid>
      <category>eess.SP</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Miguel Rivas-Costa, Carlos Mosquera</dc:creator>
    </item>
    <item>
      <title>Gaussian Process Regression of Steering Vectors With Physics-Aware Deep Composite Kernels for Augmented Listening</title>
      <link>https://arxiv.org/abs/2509.02571</link>
      <description>arXiv:2509.02571v1 Announce Type: cross 
Abstract: This paper investigates continuous representations of steering vectors over frequency and position of microphone and source for augmented listening (e.g., spatial filtering and binaural rendering) with precise control of the sound field perceived by the user. Steering vectors have typically been used for representing the spatial characteristics of the sound field as a function of the listening position. The basic algebraic representation of steering vectors assuming an idealized environment cannot deal with the scattering effect of the sound field. One may thus collect a discrete set of real steering vectors measured in dedicated facilities and super-resolve (i.e., upsample) them. Recently, physics-aware deep learning methods have been effectively used for this purpose. Such deterministic super-resolution, however, suffers from the overfitting problem due to the non-uniform uncertainty over the measurement space. To solve this problem, we integrate an expressive representation based on the neural field (NF) into the principled probabilistic framework based on the Gaussian process (GP). Specifically, we propose a physics-aware composite kernel that model the directional incoming waves and the subsequent scattering effect. Our comprehensive comparative experiment showed the effectiveness of the proposed method under data insufficiency conditions. In downstream tasks such as speech enhancement and binaural rendering using the simulated data of the SPEAR challenge, the oracle performances were attained with less than ten times fewer measurements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02571v1</guid>
      <category>eess.AS</category>
      <category>cs.LG</category>
      <category>cs.SD</category>
      <category>eess.SP</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Diego Di Carlo (RIKEN AIP), Koyama Shoichi (UTokyo), Nugraha Aditya Arie (RIKEN AIP), Fontaine Mathieu (LTCI, S2A), Bando Yoshiaki (AIST), Yoshii Kazuyoshi (RIKEN AIP)</dc:creator>
    </item>
    <item>
      <title>IS${}^3$ : Generic Impulsive--Stationary Sound Separation in Acoustic Scenes using Deep Filtering</title>
      <link>https://arxiv.org/abs/2509.02622</link>
      <description>arXiv:2509.02622v1 Announce Type: cross 
Abstract: We are interested in audio systems capable of performing a differentiated processing of stationary backgrounds and isolated acoustic events within an acoustic scene, whether for applying specific processing methods to each part or for focusing solely on one while ignoring the other. Such systems have applications in real-world scenarios, including robust adaptive audio rendering systems (e.g., EQ or compression), plosive attenuation in voice mixing, noise suppression or reduction, robust acoustic event classification or even bioacoustics. To this end, we introduce IS${}^3$, a neural network designed for Impulsive--Stationary Sound Separation, that isolates impulsive acoustic events from the stationary background using a deep filtering approach, that can act as a pre-processing stage for the above-mentioned tasks. To ensure optimal training, we propose a sophisticated data generation pipeline that curates and adapts existing datasets for this task. We demonstrate that a learning-based approach, build on a relatively lightweight neural architecture and trained with well-designed and varied data, is successful in this previously unaddressed task, outperforming the Harmonic--Percussive Sound Separation masking method, adapted from music signal processing research, and wavelet filtering on objective separation metrics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02622v1</guid>
      <category>eess.AS</category>
      <category>cs.AI</category>
      <category>cs.SD</category>
      <category>eess.SP</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>IEEE Workshop on Applications of Signal Processing to Audio and Acoustics, IEEE, Oct 2025, Tahoe City, CA, United States</arxiv:journal_reference>
      <dc:creator>Berger Cl\'ementine (IDS, S2A), Stamadiatis Paraskevas (IDS, S2A), Badeau Roland (IDS, S2A), Essid Slim (IDS, S2A)</dc:creator>
    </item>
    <item>
      <title>AR-KAN: Autoregressive-Weight-Enhanced Kolmogorov-Arnold Network for Time Series Forecasting</title>
      <link>https://arxiv.org/abs/2509.02967</link>
      <description>arXiv:2509.02967v1 Announce Type: cross 
Abstract: Conventional neural networks frequently face challenges in spectral analysis of signals. To address this challenge, Fourier neural networks (FNNs) and similar approaches integrate components of Fourier series into the structure of neural networks. Nonetheless, a significant hurdle is often overlooked: the superposition of periodic signals does not necessarily result in a periodic signal. For example, when forecasting almost periodic functions composed of signals with incommensurate frequencies, traditional models such as Autoregressive Integrated Moving Average (ARIMA) frequently outperform most neural networks including large language models (LLMs). To tackle this goal, we propose Autoregressive-Weight-Enhanced AR-KAN, a hybrid model that combines the benefits of both methods. Using the Universal Myopic Mapping Theorem, we apply a Kolmogorov-Arnold Network (KAN) for the static nonlinear part and include memory through a pre-trained AR component, which can be explained to retain the most useful information while eliminating redundancy. Experimental data indicates that AR-KAN delivers superior results on $72\%$ of real-world datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02967v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>eess.SP</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chen Zeng, Tiehang Xu, Qiao Wang</dc:creator>
    </item>
    <item>
      <title>On the Terminal Location Uncertainty in Elliptical Footprints: Application in Air-to-Ground Links</title>
      <link>https://arxiv.org/abs/2309.07299</link>
      <description>arXiv:2309.07299v2 Announce Type: replace 
Abstract: Wireless transmitters (Txs) that radiate downward in a direction often generate circular footprints on the ground. The configurational flexibility of these footprints is inherently limited as coverage adjustments are restricted to variations in radius, the only parameter available for tuning. This simplification is inadequate for scenarios that require asymmetric coverage, extended service areas, or dynamic footprint adaptation due to antenna tilt or changes in altitude of unmanned aerial vehicles (UAVs). In specific scenarios, the use of elliptical cells can offer increased flexibility for providing user coverage due to unique network characteristics. For example, an elliptical footprint can be produced when a practical directional antenna with unequal azimuth and elevation half-power beamwidths is used in high-speed railway networks. Another common scenario involves the production of an elliptical footprint when an airborne Tx radiates at an angle by tilting its directional antenna by a few degrees. This paper aims to investigate for the first time the association between the random location of the user within an elliptical coverage area and the performance of a wireless communication link considering these scenarios. We assume a UAV as a Tx, although a tall cellular base station tower could also be employed without losing generality. To gain a deeper understanding of the impact of random location, we derive the relevant distance and signal-to-noise ratio metrics and examine the outage probability for a single-user link, as well as the throughput in a multiuser scenario. This analysis accounts for both random terminal locations and fading impairments in both cases. The findings provide valuable insights into the performance of comparable wireless systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.07299v2</guid>
      <category>eess.SP</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Vavoulas, Nicholas Vaiopoulos, Harilaos G. Sandalidis, Konstantinos K. Delibasis</dc:creator>
    </item>
    <item>
      <title>Model-based learning for joint channel estimationand hybrid MIMO precoding</title>
      <link>https://arxiv.org/abs/2505.04255</link>
      <description>arXiv:2505.04255v3 Announce Type: replace 
Abstract: Hybrid precoding is a key ingredient of cost-effective massive multiple-input multiple-output transceivers. However, setting jointly digital and analog precoders to optimally serve multiple users is a difficult optimization problem. Moreover, it relies heavily on precise knowledge of the channels, which is difficult to obtain, especially when considering realistic systems comprising hardware impairments. In this paper, a joint channel estimation and hybrid precoding method is proposed, which consists in an end-to-end architecture taking received pilots as inputs and outputting pre-coders. The resulting neural network is fully model-based, making it lightweight and interpretable with very few learnable parameters. The channel estimation step is performed using the unfolded matching pursuit algorithm, accounting for imperfect knowledge of the antenna system, while the precoding step is done via unfolded projected gradient ascent. The great potential of the proposed method is empirically demonstrated on realistic synthetic channels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.04255v3</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nay Klaimi (IETR, INSA Rennes), Amira Bedoui (IETR, INSA Rennes), Cl\'ement Elvira (IETR), Philippe Mary (INSA Rennes, IETR), Luc Le Magoarou (INSA Rennes, IETR)</dc:creator>
    </item>
    <item>
      <title>LLM4SG: Adapting Large Language Model for Scatterer Generation via Synesthesia of Machines</title>
      <link>https://arxiv.org/abs/2505.17879</link>
      <description>arXiv:2505.17879v3 Announce Type: replace 
Abstract: In this paper, a novel large language model (LLM)-based method for scatterer generation (LLM4SG) is proposed for sixth-generation (6G) artificial intelligence (AI)-native communications. To provide a solid data foundation, we construct a new synthetic intelligent sensing-communication dataset for Synesthesia of Machines (SoM) in vehicle-to-vehicle (V2V) communications, named SynthSoM-V2V, covering multiple V2V scenarios with multiple frequency bands and multiple vehicular traffic densities (VTDs). Leveraging the powerful cross-modal representation capabilities of LLMs, LLM4SG is designed to capture the general mapping relationship from light detection and ranging (LiDAR) point clouds to electromagnetic scatterers via SoM. To address the inherent and significant differences across multi-modal data, synergistically optimized four-module architecture, i.e., preprocessor, embedding, backbone, and output modules, are designed by considering sensing characteristics and electromagnetic propagation. The embedding module achieves effective cross-domain alignment of the sensing-communication domain and the natural language domain.The backbone network is adapted in a task-guided manner with low rank adaptation (LoRA), where a carefully selected subset of layers is fine tuned to preserve general knowledge and reduce training cost. The proposed LLM4SG is evaluated for scatterer generation by benchmarking against ray-tracing (RT) and conventional deep learning models. Simulation results demonstrate that the proposed LLM4SG achieves superior performance in both full-sample and cross-condition generalization testing. It significantly outperforms conventional deep learning models across different frequency bands, scenarios, and VTDs, and demonstrates the capability to provide the massive and high-quality channel small-scale fading data required by AI-native 6G systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.17879v3</guid>
      <category>eess.SP</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zengrui Han, Lu Bai, Ziwei Huang, Xiang Cheng</dc:creator>
    </item>
    <item>
      <title>Arbitrary Precision Printed Ternary Neural Networks with Holistic Evolutionary Approximation</title>
      <link>https://arxiv.org/abs/2508.19660</link>
      <description>arXiv:2508.19660v3 Announce Type: replace 
Abstract: Printed electronics offer a promising alternative for applications beyond silicon-based systems, requiring properties like flexibility, stretchability, conformality, and ultra-low fabrication costs. Despite the large feature sizes in printed electronics, printed neural networks have attracted attention for meeting target application requirements, though realizing complex circuits remains challenging. This work bridges the gap between classification accuracy and area efficiency in printed neural networks, covering the entire processing-near-sensor system design and co-optimization from the analog-to-digital interface-a major area and power bottleneck-to the digital classifier. We propose an automated framework for designing printed Ternary Neural Networks with arbitrary input precision, utilizing multi-objective optimization and holistic approximation. Our circuits outperform existing approximate printed neural networks by 17x in area and 59x in power on average, being the first to enable printed-battery-powered operation with under 5% accuracy loss while accounting for analog-to-digital interfacing costs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.19660v3</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TCASAI.2025.3604384</arxiv:DOI>
      <dc:creator>Vojtech Mrazek, Konstantinos Balaskas, Paula Carolina Lozano Duarte, Zdenek Vasicek, Mehdi B. Tahoori, Georgios Zervakis</dc:creator>
    </item>
    <item>
      <title>Symmetric Private Information Retrieval (SPIR) on Graph-Based Replicated Systems</title>
      <link>https://arxiv.org/abs/2507.17736</link>
      <description>arXiv:2507.17736v2 Announce Type: replace-cross 
Abstract: We introduce the problem of symmetric private information retrieval (SPIR) on replicated databases modeled by a simple graph. In this model, each vertex corresponds to a server, and a message is replicated on two servers if and only if there is an edge between them. We consider the setting where the server-side common randomness necessary to accomplish SPIR is also replicated at the servers according to the graph, and we call this as message-specific common randomness. In this setting, we establish a lower bound on the SPIR capacity, i.e., the maximum download rate, for general graphs, by proposing an achievable SPIR scheme. Next, we prove that, for any SPIR scheme to be feasible, the minimum size of message-specific randomness should be equal to the size of a message. Finally, by providing matching upper bounds, we derive the exact SPIR capacity for the class of path and regular graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.17736v2</guid>
      <category>cs.IT</category>
      <category>cs.CR</category>
      <category>cs.DB</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shreya Meel, Sennur Ulukus</dc:creator>
    </item>
  </channel>
</rss>
