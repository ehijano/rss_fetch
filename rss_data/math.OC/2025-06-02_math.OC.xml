<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 03 Jun 2025 03:03:56 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Boundary bilinear control of semilinear parabolic PDEs: quadratic convergence of the SQP method</title>
      <link>https://arxiv.org/abs/2505.24237</link>
      <description>arXiv:2505.24237v1 Announce Type: new 
Abstract: We analyze a bilinear control problem governed by a semilinear parabolic equation. The control variable is the Robin coefficient on the boundary. First-order necessary and second-order sufficient optimality conditions are derived. A sequential quadratic programming algorithm is then proposed to compute local solutions. Starting the iterations from an initial point in an $L^2$-neighborhood of the local solution we prove stability and quadratic convergence of the algorithm in $L^p$ ($p &lt; \infty$) and $L^\infty$ assuming that the local solution satisfies a no-gap second-order sufficient optimality condition and a strict complementarity condition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.24237v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eduardo Casas, Mariano Mateos</dc:creator>
    </item>
    <item>
      <title>Approximation of starshaped sets using polynomials</title>
      <link>https://arxiv.org/abs/2505.24352</link>
      <description>arXiv:2505.24352v1 Announce Type: new 
Abstract: We introduce polystar bodies: compact starshaped sets whose gauge or radial functions are expressible by polynomials, enabling tractable computations, such as that of intersection bodies. We prove that polystar bodies are uniformly dense in starshaped sets and obtain asymptotically optimal approximation guarantees. We develop tools for the construction of polystar approximations and illustrate them via several computational examples, including numerical estimations of largest volume slices and widths.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.24352v1</guid>
      <category>math.OC</category>
      <category>math.MG</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chiara Meroni, Jared Miller, Mauricio Velasco</dc:creator>
    </item>
    <item>
      <title>Provably convergent stochastic fixed-point algorithm for free-support Wasserstein barycenter of continuous non-parametric measures</title>
      <link>https://arxiv.org/abs/2505.24384</link>
      <description>arXiv:2505.24384v1 Announce Type: new 
Abstract: We propose a provably convergent algorithm for approximating the 2-Wasserstein barycenter of continuous non-parametric probability measures. Our algorithm is inspired by the fixed-point iterative scheme of \'Alvarez-Esteban et al. (2016) whose convergence to the 2-Wasserstein barycenter relies on obtaining exact optimal transport (OT) maps. However, typically in practice, OT maps are only approximately computed and exact computation of OT maps between continuous probability measures is only tractable for certain restrictive parametric families. To circumvent the need to compute exact OT maps between general non-parametric measures, we develop a tailored iterative scheme that utilizes consistent estimators of the OT maps instead of the exact OT maps. This gives rise to a computationally tractable stochastic fixed-point algorithm which is provably convergent to the 2-Wasserstein barycenter. Our algorithm remarkably does not restrict the support of the 2-Wasserstein barycenter to be any fixed finite set and can be implemented in a distributed computing environment, which makes it suitable for large-scale data aggregation problems. In our numerical experiments, we propose a method of generating non-trivial instances of 2-Wasserstein barycenter problems where the ground-truth barycenter measure is known. Our numerical results showcase the capability of our algorithm in developing high-quality approximations of the 2-Wasserstein barycenter, as well as its superiority over state-of-the-art methods based on generative neural networks in terms of accuracy, stability, and efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.24384v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zeyi Chen, Ariel Neufeld, Qikun Xiang</dc:creator>
    </item>
    <item>
      <title>Incremental Gain Computation and Regulation of Discrete-time Positive Lur\'e Systems using Linear Programming</title>
      <link>https://arxiv.org/abs/2505.24386</link>
      <description>arXiv:2505.24386v1 Announce Type: new 
Abstract: This work approaches the problem of computing incremental $\ell_1$ and $\ell_\infty$ gains for discrete-time positive systems in \lure feedback with static memoryless nonlinearities, and regulating the $\ell_\infty$ gain through the design of a state-feedback controller. Finite incremental gains provide a quantitative measure of robustness for trajectories, and will ensure that all pairs of trajectories will converge to a fixed point or will diverge together in the absence of an applied input. Upper-bounds on these incremental gains can be computed through linear programming. Computation and regulation of the $\ell_1$ and $\ell_\infty$ incremental gains are verified by numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.24386v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jared Miller</dc:creator>
    </item>
    <item>
      <title>Distributed gradient methods under heavy-tailed communication noise</title>
      <link>https://arxiv.org/abs/2505.24464</link>
      <description>arXiv:2505.24464v1 Announce Type: new 
Abstract: We consider a standard distributed optimization problem in which networked nodes collaboratively minimize the sum of their locally known convex costs. For this setting, we address for the first time the fundamental problem of design and analysis of distributed methods to solve the above problem when inter-node communication is subject to \emph{heavy-tailed} noise. Heavy-tailed noise is highly relevant and frequently arises in densely deployed wireless sensor and Internet of Things (IoT) networks. Specifically, we design a distributed gradient-type method that features a carefully balanced mixed time-scale time-varying consensus and gradient contribution step sizes and a bounded nonlinear operator on the consensus update to limit the effect of heavy-tailed noise. Assuming heterogeneous strongly convex local costs with mutually different minimizers that are arbitrarily far apart, we show that the proposed method converges to a neighborhood of the network-wide problem solution in the mean squared error (MSE) sense, and we also characterize the corresponding convergence rate. We further show that the asymptotic MSE can be made arbitrarily small through consensus step-size tuning, possibly at the cost of slowing down the transient error decay. Numerical experiments corroborate our findings and demonstrate the resilience of the proposed method to heavy-tailed (and infinite variance) communication noise. They also show that existing distributed methods, designed for finite-communication-noise-variance settings, fail in the presence of infinite variance noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.24464v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Manojlo Vukovic, Dusan Jakovetic, Dragana Bajovic, Soummya Kar</dc:creator>
    </item>
    <item>
      <title>Fine-tuning for Data-enabled Predictive Control of Noisy Systems by Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2505.24572</link>
      <description>arXiv:2505.24572v1 Announce Type: new 
Abstract: Data-enabled predictive control (DeePC) leverages system measurements in characterizing system dynamics for optimal control. The performance of DeePC relies on optimizing its hyperparameters, especially in noisy systems where the optimal hyperparameters adapt over time. Existing hyperparameter tuning approaches for DeePC are more than often computationally inefficient or overly conservative. This paper proposes an adaptive DeePC where we guide its hyperparameters adaption through reinforcement learning. We start with establishing the relationship between the system I/O behavior and DeePC hyperparameters. Then we formulate the hyperparameter tuning as a sequential decision-making problem, and we address the decision-making through reinforcement learning. We implement offline training to gain a reinforcement learning model, and we integrate the trained model with DeePC to adjust its hyperparameters adaptively in real time. We conduct numerical simulations with diverse noisy conditions, and the results demonstrate the identification of near-optimal hyperparameters and the robustness of the proposed approach against noises in the control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.24572v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jinbao Wang, Shiliang Zhang, Jun Liu, Xuehui Ma, Haolin Liu</dc:creator>
    </item>
    <item>
      <title>Neural Network-based Universal Formulas for Control</title>
      <link>https://arxiv.org/abs/2505.24744</link>
      <description>arXiv:2505.24744v1 Announce Type: new 
Abstract: We study the problem of designing a controller that satisfies an arbitrary number of affine inequalities at every point in the state space. This is motivated by the use of guardrails in autonomous systems. Indeed, a variety of key control objectives, such as stability, safety, and input saturation, are guaranteed by closed-loop systems whose controllers satisfy such inequalities. Many works in the literature design such controllers as the solution to a state-dependent quadratic program (QP) whose constraints are precisely the inequalities. When the input dimension and number of constraints are high, computing a solution of this QP in real time can become computationally burdensome. Additionally, the solution of such optimization problems is not smooth in general, which can degrade the performance of the system. This paper provides a novel method to design a smooth controller that satisfies an arbitrary number of affine constraints. This why we refer to it as a universal formula for control. The controller is given at every state as the minimizer of a strictly convex function. To avoid computing the minimizer of such function in real time, we introduce a method based on neural networks (NN) to approximate the controller. Remarkably, this NN can be used to solve the controller design problem for any task with less than a fixed input dimension and number of affine constraints, and is completely independent of the state dimension. Additionally, we show that the NN-based controller only needs to be trained with datapoints from a compact set in the state space, which significantly simplifies the training process. Various simulations showcase the performance of the proposed solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.24744v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pol Mestres, Jorge Cort\'es, Eduardo D. Sontag</dc:creator>
    </item>
    <item>
      <title>Convex Approximations of Random Constrained Markov Decision Processes</title>
      <link>https://arxiv.org/abs/2505.24815</link>
      <description>arXiv:2505.24815v1 Announce Type: new 
Abstract: Constrained Markov decision processes (CMDPs) are used as a decision-making framework to study the long-run performance of a stochastic system. It is well-known that a stationary optimal policy of a CMDP problem under discounted cost criterion can be obtained by solving a linear programming problem when running costs and transition probabilities are exactly known. In this paper, we consider a discounted cost CMDP problem where the running costs and transition probabilities are defined using random variables. Consequently, both the objective function and constraints become random. We use chance constraints to model these uncertainties and formulate the uncertain CMDP problem as a joint chance-constrained Markov decision process (JCCMDP). Under random running costs, we assume that the dependency among random constraint vectors is driven by a Gumbel-Hougaard copula. Using standard probability inequalities, we construct convex upper bound approximations of the JCCMDP problem under certain conditions on random running costs. In addition, we propose a linear programming problem whose optimal value gives a lower bound to the optimal value of the JCCMDP problem. When both running costs and transition probabilities are random, we define the latter variables as a sum of their means and random perturbations. Under mild conditions on the random perturbations and random running costs, we construct convex upper and lower bound approximations of the JCCMDP problem. We analyse the quality of the derived bounds through numerical experiments on a queueing control problem for random running costs. For the case when both running costs and transition probabilities are random, we choose randomly generated Markov decision problems called Garnets for numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.24815v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>V Varagapriya, Vikas Vikram Singh, Abdel Lisser</dc:creator>
    </item>
    <item>
      <title>The Rich and the Simple: On the Implicit Bias of Adam and SGD</title>
      <link>https://arxiv.org/abs/2505.24022</link>
      <description>arXiv:2505.24022v1 Announce Type: cross 
Abstract: Adam is the de facto optimization algorithm for several deep learning applications, but an understanding of its implicit bias and how it differs from other algorithms, particularly standard first-order methods such as (stochastic) gradient descent (GD), remains limited. In practice, neural networks trained with SGD are known to exhibit simplicity bias -- a tendency to find simple solutions. In contrast, we show that Adam is more resistant to such simplicity bias. To demystify this phenomenon, in this paper, we investigate the differences in the implicit biases of Adam and GD when training two-layer ReLU neural networks on a binary classification task involving synthetic data with Gaussian clusters. We find that GD exhibits a simplicity bias, resulting in a linear decision boundary with a suboptimal margin, whereas Adam leads to much richer and more diverse features, producing a nonlinear boundary that is closer to the Bayes' optimal predictor. This richer decision boundary also allows Adam to achieve higher test accuracy both in-distribution and under certain distribution shifts. We theoretically prove these results by analyzing the population gradients. To corroborate our theoretical findings, we present empirical results showing that this property of Adam leads to superior generalization across datasets with spurious correlations where neural networks trained with SGD are known to show simplicity bias and don't generalize well under certain distributional shifts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.24022v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bhavya Vasudeva, Jung Whan Lee, Vatsal Sharan, Mahdi Soltanolkotabi</dc:creator>
    </item>
    <item>
      <title>A Causation-Based Framework for Pricing and Cost Allocation of Energy, Reserves, and Transmission in Modern Power Systems</title>
      <link>https://arxiv.org/abs/2505.24159</link>
      <description>arXiv:2505.24159v1 Announce Type: cross 
Abstract: The increasing vulnerability of power systems has heightened the need for operating reserves to manage contingencies such as generator outages, line failures, and sudden load variations. Unlike energy costs, driven by consumer demand, operating reserve costs arise from addressing the most critical credible contingencies - prompting the question: how should these costs be allocated through efficient pricing mechanisms? As an alternative to previously reported schemes, this paper presents a new causation-based pricing framework for electricity markets based on contingency-constrained energy and reserve scheduling models. Major salient features include a novel security charge mechanism along with the explicit definition of prices for up-spinning reserves, down-spinning reserves, and transmission services. These features ensure more comprehensive and efficient cost-reflective market operations. Moreover, the proposed nodal pricing scheme yields revenue adequacy and neutrality while promoting reliability incentives for generators based on the cost-causation principle. An additional salient aspect of the proposed framework is the economic incentive for transmission assets, which are remunerated based on their use to deliver energy and reserves across all contingency states. Numerical results from two case studies illustrate the performance of the proposed pricing scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.24159v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>econ.TH</category>
      <category>math.OC</category>
      <category>q-fin.CP</category>
      <category>q-fin.PR</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luiza Ribeiro, Alexandre Street, Jose Manuel Arroyo, Rodrigo Moreno</dc:creator>
    </item>
    <item>
      <title>GradPower: Powering Gradients for Faster Language Model Pre-Training</title>
      <link>https://arxiv.org/abs/2505.24275</link>
      <description>arXiv:2505.24275v1 Announce Type: cross 
Abstract: We propose GradPower, a lightweight gradient-transformation technique for accelerating language model pre-training. Given a gradient vector $g=(g_i)_i$, GradPower first applies the elementwise sign-power transformation: $\varphi_p(g)=({\rm sign}(g_i)|g_i|^p)_{i}$ for a fixed $p&gt;0$, and then feeds the transformed gradient into a base optimizer. Notably, GradPower requires only a single-line code change and no modifications to the base optimizer's internal logic, including the hyperparameters. When applied to Adam (termed AdamPower), GradPower consistently achieves lower terminal loss across diverse architectures (LLaMA, Qwen2MoE), parameter scales (66M to 2B), datasets (C4, OpenWebText), and learning-rate schedules (cosine, warmup-stable-decay). The most pronounced gains are observed when training modern mixture-of-experts models with warmup-stable-decay schedules. GradPower also integrates seamlessly with other state-of-the-art optimizers, such as Muon, yielding further improvements. Finally, we provide theoretical analyses that reveal the underlying mechanism of GradPower and highlights the influence of gradient noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.24275v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mingze Wang, Jinbo Wang, Jiaqi Zhang, Wei Wang, Peng Pei, Xunliang Cai, Weinan E, Lei Wu</dc:creator>
    </item>
    <item>
      <title>Finsler and sub-Finsler geodesics with chattering</title>
      <link>https://arxiv.org/abs/2505.24474</link>
      <description>arXiv:2505.24474v1 Announce Type: cross 
Abstract: In this paper, we provide examples of Finsler and sub-Finsler manifolds whose geodesics exhibit chattering, that is, a countable number of switches over an arbitrarily small time interval. We also present an explicit left-invariant structure on a Carnot group whose geodesics exhibit chattering. This provides a negative answer to Le Donne's question. Furthermore, the paper presents a sufficient condition for normal Pontryagin maximum principle extremals in (sub-)Finsler problems to exhibit chattering.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.24474v1</guid>
      <category>math.DG</category>
      <category>math.MG</category>
      <category>math.OC</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>L. V. Lokutsievskiy, M. I. Zelikin</dc:creator>
    </item>
    <item>
      <title>Learning to Optimally Dispatch Power: Performance on a Nation-Wide Real-World Dataset</title>
      <link>https://arxiv.org/abs/2505.24505</link>
      <description>arXiv:2505.24505v1 Announce Type: cross 
Abstract: The Optimal Reactive Power Dispatch (ORPD) problem plays a crucial role in power system operations, ensuring voltage stability and minimizing power losses. Recent advances in machine learning, particularly within the ``learning to optimize'' framework, have enabled fast and efficient approximations of ORPD solutions, typically by training models on precomputed optimization results. While these approaches have demonstrated promising performance on synthetic datasets, their effectiveness under real-world grid conditions remains largely unexplored. This paper makes two key contributions. First, we introduce a publicly available power system dataset that includes both the structural characteristics of Uruguay's electrical grid and nearly two years of real-world operational data, encompassing actual demand and generation profiles. Given Uruguay's high penetration of renewable energy, the ORPD problem has become the primary optimization challenge in its power network. Second, we assess the impact of real-world data on learning-based ORPD solutions, revealing a significant increase in prediction errors when transitioning from synthetic to actual demand and generation inputs. Our results highlight the limitations of existing models in learning under the complex statistical properties of real grid conditions and emphasize the need for more expressive architectures. By providing this dataset, we aim to facilitate further research into robust learning-based optimization techniques for power system management.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.24505v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ignacio Boero, Santiago Diaz, Tom\'as V\'azquez, Enzo Coppes, Pablo Belzarena, Federico Larroca</dc:creator>
    </item>
    <item>
      <title>A Computational Search for Minimal Obstruction Graphs for the Lov\'{a}sz--Schrijver SDP Hierarchy</title>
      <link>https://arxiv.org/abs/2505.24735</link>
      <description>arXiv:2505.24735v1 Announce Type: cross 
Abstract: We study the lift-and-project relaxations of the stable set polytope of graphs generated by $\text{LS}_+$, the SDP lift-and-project operator devised by Lov\'{a}sz and Schrijver. In particular, we focus on searching for $\ell$-minimal graphs, which are graphs on $3\ell$ vertices whose stable set polytope has rank $\ell$ with respect to $\text{LS}_+$. These are the graphs which are the most challenging for the $\text{LS}_+$ operator according to one of the main complexity measures (smallest graphs with largest $\text{LS}_+$-rank). We introduce the notion of $\text{LS}_+$ certificate packages, which is a framework that allows for efficient and reliable verification of membership of points in $\text{LS}_+$-relaxations. Using this framework, we present numerical certificates which (combined with other results) show that there are at least $49$ $3$-minimal graphs, as well as over $4000$ $4$-minimal graphs. This marks a significant leap from the $14$ $3$-minimal and $588$ $4$-minimal graphs known before this work, with many of the newly-discovered graphs containing novel structures which helps enrich and recalibrate our understanding of $\ell$-minimal graphs. Some of this computational work leads to interesting conjectures. We also find all of the smallest vertex-transitive graphs with $\text{LS}_+$-rank $\ell$ for every $\ell \leq 4$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.24735v1</guid>
      <category>math.CO</category>
      <category>cs.DM</category>
      <category>math.OC</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu Hin Au, Levent Tun\c{c}el</dc:creator>
    </item>
    <item>
      <title>SUMO: Subspace-Aware Moment-Orthogonalization for Accelerating Memory-Efficient LLM Training</title>
      <link>https://arxiv.org/abs/2505.24749</link>
      <description>arXiv:2505.24749v1 Announce Type: cross 
Abstract: Low-rank gradient-based optimization methods have significantly improved memory efficiency during the training of large language models (LLMs), enabling operations within constrained hardware without sacrificing performance. However, these methods primarily emphasize memory savings, often overlooking potential acceleration in convergence due to their reliance on standard isotropic steepest descent techniques, which can perform suboptimally in the highly anisotropic landscapes typical of deep networks, particularly LLMs. In this paper, we propose SUMO (Subspace-Aware Moment-Orthogonalization), an optimizer that employs exact singular value decomposition (SVD) for moment orthogonalization within a dynamically adapted low-dimensional subspace, enabling norm-inducing steepest descent optimization steps. By explicitly aligning optimization steps with the spectral characteristics of the loss landscape, SUMO effectively mitigates approximation errors associated with commonly used methods like Newton-Schulz orthogonalization approximation. We theoretically establish an upper bound on these approximation errors, proving their dependence on the condition numbers of moments, conditions we analytically demonstrate are encountered during LLM training. Furthermore, we both theoretically and empirically illustrate that exact orthogonalization via SVD substantially improves convergence rates while reducing overall complexity. Empirical evaluations confirm that SUMO accelerates convergence, enhances stability, improves performance, and reduces memory requirements by up to 20% compared to state-of-the-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.24749v1</guid>
      <category>cs.LG</category>
      <category>cs.CL</category>
      <category>math.OC</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yehonathan Refael, Guy Smorodinsky, Tom Tirer, Ofir Lindenbaum</dc:creator>
    </item>
    <item>
      <title>Input-Power-to-State Stability of Time-Varying Systems</title>
      <link>https://arxiv.org/abs/2505.24805</link>
      <description>arXiv:2505.24805v1 Announce Type: cross 
Abstract: When the state of a system may remain bounded even if both the input amplitude and energy are unbounded, then the state bounds given by the standard input-to-state stability (ISS) and integral-ISS (iISS) properties may provide no useful information. This paper considers an ISS-related concept suitable in such a case: input-power-to-state stability (IPSS). Necessary and sufficient conditions for IPSS are developed for time-varying systems under very mild assumptions on the dynamics. More precisely, it is shown that (a) the existence of a dissipation-form ISS-Lyapunov function implies IPSS, but not necessarily that of an implication-form one, (b) iISS with exponential class-$\KL$ function implies IPSS, and (c) ISS and stronger assumptions on the dynamics imply the existence of a dissipation-form ISS-Lyapunov function and hence IPSS. The latter result is based on a converse Lyapunov theorem for time-varying systems whose dynamics (i.e. state derivative) is not necessarily continuous with respect to time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.24805v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hernan Haimovich, Shenyu Liu, Antonio Russo, Jose L. Mancilla-Aguilar</dc:creator>
    </item>
    <item>
      <title>A localized consensus-based sampling algorithm</title>
      <link>https://arxiv.org/abs/2505.24861</link>
      <description>arXiv:2505.24861v1 Announce Type: cross 
Abstract: We develop a novel interacting-particle method for sampling from non-Gaussian distributions. As a first step, we propose a new way to derive the consensus-based sampling (CBS) algorithm, starting from ensemble-preconditioned Langevin diffusions. We approximate the target potential by its Moreau envelope, such that the gradient in the Langevin equation can be replaced by a proximal operator. We then approximate the proximal operator by a weighted mean, and finally assume that the initial and target distributions are Gaussian, resulting in the CBS dynamics. If we keep only those approximations that can be justified in the non-Gaussian setting, the result is a new interacting-particle method for sampling, which we call localized consensus-based sampling. We prove that our algorithm is affine-invariant and exact for Gaussian distributions in the mean-field setting. Numerical tests illustrate that localized CBS compares favorably to alternative methods in terms of affine-invariance and performance on non-Gaussian distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.24861v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arne Bouillon, Alexander Bodard, Panagiotis Patrinos, Dirk Nuyens, Giovanni Samaey</dc:creator>
    </item>
    <item>
      <title>An Output-Polynomial Time Algorithm to Determine all Supported Efficient Solutions for Multi-Objective Integer Network Flow Problems</title>
      <link>https://arxiv.org/abs/2305.12867</link>
      <description>arXiv:2305.12867v5 Announce Type: replace 
Abstract: This paper addresses the problem of enumerating all supported efficient solutions for a linear multi-objective integer minimum cost flow problem (MOIMCF). It derives an output-polynomial time algorithm to determine all supported efficient solutions for MOIMCF problems. This is the first approach to solve this general problem in output-polynomial time. Moreover, we prove that the existence of an output-polynomial time algorithm to determine all weakly supported nondominated vectors (or all weakly supported efficient solutions) for a MOIMCF problem with a fixed number of d &gt;= 3 objectives can be excluded unless P = NP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.12867v5</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>David K\"onen, Michael Stiglmayr</dc:creator>
    </item>
    <item>
      <title>Near-Optimal Nonconvex-Strongly-Convex Bilevel Optimization with Fully First-Order Oracles</title>
      <link>https://arxiv.org/abs/2306.14853</link>
      <description>arXiv:2306.14853v3 Announce Type: replace 
Abstract: In this work, we consider bilevel optimization when the lower-level problem is strongly convex. Recent works show that with a Hessian-vector product (HVP) oracle, one can provably find an $\epsilon$-stationary point within ${\mathcal{O}}(\epsilon^{-2})$ oracle calls. However, the HVP oracle may be inaccessible or expensive in practice. Kwon et al. (ICML 2023) addressed this issue by proposing a first-order method that can achieve the same goal at a slower rate of $\tilde{\mathcal{O}}(\epsilon^{-3})$. In this paper, we incorporate a two-time-scale update to improve their method to achieve the near-optimal $\tilde {\mathcal{O}}(\epsilon^{-2})$ first-order oracle complexity. Our analysis is highly extensible. In the stochastic setting, our algorithm can achieve the stochastic first-order oracle complexity of $\tilde {\mathcal{O}}(\epsilon^{-4})$ and $\tilde {\mathcal{O}}(\epsilon^{-6})$ when the stochastic noises are only in the upper-level objective and in both level objectives, respectively. When the objectives have higher-order smoothness conditions, our deterministic method can escape saddle points by injecting noise, and can be accelerated to achieve a faster rate of $\tilde {\mathcal{O}}(\epsilon^{-1.75})$ using Nesterov's momentum.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.14853v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Lesi Chen, Yaohua Ma, Jingzhao Zhang</dc:creator>
    </item>
    <item>
      <title>Episodic Bayesian Optimal Control with Unknown Randomness Distributions</title>
      <link>https://arxiv.org/abs/2308.08478</link>
      <description>arXiv:2308.08478v2 Announce Type: replace 
Abstract: Stochastic optimal control with unknown randomness distributions has been studied for a long time, encompassing robust control, distributionally robust control, and adaptive control. We propose a new episodic Bayesian approach that incorporates Bayesian learning with optimal control. In each episode, the approach learns the randomness distribution with a Bayesian posterior and subsequently solves the corresponding Bayesian average estimate of the true problem. The resulting policy is exercised during the episode, while additional data/observations of the randomness are collected to update the Bayesian posterior for the next episode. We show that the resulting episodic value functions and policies converge almost surely to their optimal counterparts of the true problem if the parametrized model of the randomness distribution is correctly specified. We further show that the asymptotic convergence rate of the episodic value functions is of the order $O(N^{-1/2})$, where $N$ is the number of episodes given that only one data point is collected in each episode. We develop an efficient computational method based on stochastic dual dynamic programming (SDDP) for a class of problems that have convex cost functions and linear state dynamics. Our numerical results on a classical inventory control problem verify the theoretical convergence results, and numerical comparison with two other methods demonstrate the effectiveness of the proposed Bayesian approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.08478v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Shapiro, Enlu Zhou, Yifan Lin, Yuhao Wang</dc:creator>
    </item>
    <item>
      <title>Robust Binary and Multinomial Logit Models for Classification with Data Uncertainties</title>
      <link>https://arxiv.org/abs/2401.03276</link>
      <description>arXiv:2401.03276v2 Announce Type: replace 
Abstract: Binary logit (BNL) and multinomial logit (MNL) models are the two most widely used discrete choice models for travel behavior modeling and prediction. However, in many scenarios, the collected data for those models are subject to measurement errors. Previous studies on measurement errors mostly focus on "better estimating model parameters" with training data. In this study, we focus on using BNL and MNL for classification problems, that is, to ``better predict the behavior of new samples'' when measurement errors occur in testing data. To this end, we propose a robust BNL and MNL framework that is able to account for data uncertainties in both features and labels. The models are based on robust optimization theory that minimizes the worst-case loss over a set of uncertainty data scenarios. Specifically, for feature uncertainties, we assume that the l_p-norm of the measurement errors in features is smaller than a pre-established threshold. We model label uncertainties by limiting the number of mislabeled choices to at most Gamma. Based on these assumptions, we derive a tractable robust counterpart. The derived robust-feature BNL and the robust-label MNL models are exact. However, the formulation for the robust-feature MNL model is an approximation of the exact robust optimization problem. An upper bound of the approximation gap is provided. We prove that the robust estimators are inconsistent but with a higher trace of the Fisher information matrix. They are preferred when out-of-sample data has errors due to the shrunk scale of the estimated parameters. The proposed models are validated in a binary choice data set and a multinomial choice data set, respectively. Results show that the robust models (both features and labels) can outperform the conventional BNL and MNL models in prediction accuracy and log-likelihood.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.03276v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Baichuan Mo, Yunhan Zheng, Xiaotong Guo, Ruoyun Ma, Jinhua Zhao</dc:creator>
    </item>
    <item>
      <title>(Accelerated) Noise-adaptive Stochastic Heavy-Ball Momentum</title>
      <link>https://arxiv.org/abs/2401.06738</link>
      <description>arXiv:2401.06738v3 Announce Type: replace 
Abstract: Stochastic heavy ball momentum (SHB) is commonly used to train machine learning models, and often provides empirical improvements over stochastic gradient descent. By primarily focusing on strongly-convex quadratics, we aim to better understand the theoretical advantage of SHB and subsequently improve the method. For strongly-convex quadratics, Kidambi et al. (2018) show that SHB (with a mini-batch of size $1$) cannot attain accelerated convergence, and hence has no theoretical benefit over SGD. They conjecture that the practical gain of SHB is a by-product of using larger mini-batches. We first substantiate this claim by showing that SHB can attain an accelerated rate when the mini-batch size is larger than a threshold $b^*$ that depends on the condition number $\kappa$. Specifically, we prove that with the same step-size and momentum parameters as in the deterministic setting, SHB with a sufficiently large mini-batch size results in an $O\left(\exp(-\frac{T}{\sqrt{\kappa}}) + \sigma \right)$ convergence when measuring the distance to the optimal solution in the $\ell_2$ norm, where $T$ is the number of iterations and $\sigma^2$ is the variance in the stochastic gradients. We prove a lower-bound which demonstrates that a $\kappa$ dependence in $b^*$ is necessary. To ensure convergence to the minimizer, we design a noise-adaptive multi-stage algorithm that results in an $O\left(\exp\left(-\frac{T}{\sqrt{\kappa}}\right) + \frac{\sigma}{\sqrt{T}}\right)$ rate when measuring the distance to the optimal solution in the $\ell_2$ norm. We also consider the general smooth, strongly-convex setting and propose the first noise-adaptive SHB variant that converges to the minimizer at an $O(\exp(-\frac{T}{\kappa}) + \frac{\sigma^2}{T})$ rate when measuring the distance to the optimal solution in the squared $\ell_2$ norm. We empirically demonstrate the effectiveness of the proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.06738v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anh Dang, Reza Babanezhad, Sharan Vaswani</dc:creator>
    </item>
    <item>
      <title>Stochastic Bregman Subgradient Methods for Nonsmooth Nonconvex Optimization Problems</title>
      <link>https://arxiv.org/abs/2404.17386</link>
      <description>arXiv:2404.17386v3 Announce Type: replace 
Abstract: This paper focuses on the problem of minimizing a locally Lipschitz continuous function. Motivated by the effectiveness of Bregman gradient methods in training nonsmooth deep neural networks and the recent progress in stochastic subgradient methods for nonsmooth nonconvex optimization problems \cite{bolte2021conservative,bolte2022subgradient,xiao2023adam}, we investigate the long-term behavior of stochastic Bregman subgradient methods in such context, especially when the objective function lacks Clarke regularity. We begin by exploring a general framework for Bregman-type methods, establishing their convergence by a differential inclusion approach. For practical applications, we develop a stochastic Bregman subgradient method that allows the subproblems to be solved inexactly. Furthermore, we demonstrate how a single timescale momentum can be integrated into the Bregman subgradient method with slight modifications to the momentum update. Additionally, we introduce a Bregman proximal subgradient method for solving composite optimization problems possibly with constraints, whose convergence can be guaranteed based on the general framework. Numerical experiments on training nonsmooth neural networks are conducted to validate the effectiveness of our proposed methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17386v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kuangyu Ding, Kim-Chuan Toh</dc:creator>
    </item>
    <item>
      <title>Birth control and turnpike property of Lotka-McKendrick models with diffusion</title>
      <link>https://arxiv.org/abs/2409.11247</link>
      <description>arXiv:2409.11247v2 Announce Type: replace 
Abstract: In this paper, we study the turnpike property in age structured population dynamics with birth control. These models describe the temporal evolution of one or more populations, incorporating age dependence and spatial structure. To this end, we first establish the null controllability of the system: we prove that for any T &gt; A and any initial datum in L2(Omega x (0,A)), the population can be driven to zero using control functions that are spatially localized in time but act only at age a = 0. We then show that although this control is initially applied only at birth, it can be reformulated as a distributed control, and we demonstrate that the resulting control operator is admissible in the state space. Thus, to prove the turnpike property we combine our null controllability results with Phillips' theorem on exponential stability to design a suitable dichotomy transformation based on solutions of the algebraic Riccati and Lyapunov equations. Finally, we present numerical examples that substantiate our analytical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.11247v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marius Bargo, Yacouba Simpore</dc:creator>
    </item>
    <item>
      <title>Best Subset Selection: Optimal Pursuit for Feature Selection and Elimination</title>
      <link>https://arxiv.org/abs/2501.16815</link>
      <description>arXiv:2501.16815v2 Announce Type: replace 
Abstract: This paper introduces two novel criteria: one for feature selection and another for feature elimination in the context of best subset selection, which is a benchmark problem in statistics and machine learning. From the perspective of optimization, we revisit the classical selection and elimination criteria in traditional best subset selection algorithms, revealing that these classical criteria capture only partial variations of the objective function after the entry or exit of features. By formulating and solving optimization subproblems for feature entry and exit exactly, new selection and elimination criteria are proposed, proved as the optimal decisions for the current entry-and-exit process compared to classical criteria. Replacing the classical selection and elimination criteria with the proposed ones generates a series of enhanced best subset selection algorithms. These generated algorithms not only preserve the theoretical properties of the original algorithms but also achieve significant meta-gains without increasing computational cost across various scenarios and evaluation metrics on multiple tasks such as compressed sensing and sparse regression.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16815v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhihan Zhu, Yanhao Zhang, Yong Xia</dc:creator>
    </item>
    <item>
      <title>Linear programming for finite-horizon vector-valued Markov decision processes</title>
      <link>https://arxiv.org/abs/2502.13697</link>
      <description>arXiv:2502.13697v3 Announce Type: replace 
Abstract: We propose a vector linear programming formulation for a non-stationary, finite-horizon Markov decision process with vector-valued rewards. Pareto efficient policies are shown to correspond to efficient solutions of the linear program, and vector linear programming theory allows us to fully characterize deterministic efficient policies. An algorithm for enumerating all efficient deterministic policies is presented then tested numerically in an engineering application.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13697v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.61208/pjo-2025-028</arxiv:DOI>
      <dc:creator>Anas Mifrani, Dominikus Noll</dc:creator>
    </item>
    <item>
      <title>Kinetic variable-sample methods for stochastic optimization problems</title>
      <link>https://arxiv.org/abs/2502.17982</link>
      <description>arXiv:2502.17982v2 Announce Type: replace 
Abstract: We discuss kinetic-based particle optimization methods and variable-sample strategies for problems where the cost function represents the expected value of a random mapping. Kinetic-based optimization methods rely on a consensus mechanism targeting the global minimizer, and they exploit tools of kinetic theory to establish a rigorous framework for proving convergence to that minimizer. Variable-sample strategies replace the expected value by an approximation at each iteration of the optimization algorithm. We combine these approaches and introduce a novel algorithm based on instantaneous collisions governed by a linear Boltzmann-type equation. After proving the convergence of the resulting kinetic method under appropriate parameter constraints, we establish a connection to a recently introduced consensus-based method for solving the random problem in a suitable scaling. Finally, we showcase its enhanced computational efficiency compared to the aforementioned algorithm and validate the consistency of the proposed modeling approaches through several numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.17982v2</guid>
      <category>math.OC</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sabrina Bonandin, Michael Herty</dc:creator>
    </item>
    <item>
      <title>Risk-Sensitive Model Predictive Control for Interaction-Aware Planning -- A Sequential Convexification Algorithm</title>
      <link>https://arxiv.org/abs/2503.14328</link>
      <description>arXiv:2503.14328v2 Announce Type: replace 
Abstract: This paper considers risk-sensitive model predictive control for stochastic systems with a decision-dependent distribution. This class of systems is commonly found in human-robot interaction scenarios. We derive computationally tractable convex upper bounds to both the objective function, and to frequently used penalty terms for collision avoidance, allowing us to efficiently solve the generally nonconvex optimal control problem as a sequence of convex problems. Simulations of a robot navigating a corridor demonstrate the effectiveness and the computational advantage of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14328v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Renzi Wang, Mathijs Schuurmans, Panagiotis Patrinos</dc:creator>
    </item>
    <item>
      <title>A Nurse Staffing and Scheduling Problem with Bounded Flexibility and Demand Uncertainty</title>
      <link>https://arxiv.org/abs/2505.22124</link>
      <description>arXiv:2505.22124v2 Announce Type: replace 
Abstract: Nurse staffing and scheduling are persistent challenges in healthcare due to demand fluctuations and individual nurse preferences. This study introduces the concept of bounded flexibility, balancing nurse satisfaction with strict rostering rules, particularly a real-world time regularity policy from a major hospital in Singapore. We model the problem as a multi-stage stochastic program to address evolving demand, optimizing both aggregate staffing and detailed scheduling decisions. A reformulation into a two-stage structure using block-separable recourse reduces computational burden without loss of accuracy. To solve the problem efficiently, we develop a Generative AI-guided algorithm. Numerical experiments with real hospital data show substantial cost savings and improved nurse flexibility with minimal compromise to schedule regularity. Numerical experiments based on real-world nurse profiles, nurse preferences, and patient demand data are conducted to evaluate the performance of the proposed methods. Our results demonstrate that the stochastic model achieves significant cost savings compared to the deterministic model. Notably, a slight reduction in the regularity level can remarkably enhance nurse flexibility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22124v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Si Zhang, Paul Mingzheng Tang, Hoong Chuin Lau</dc:creator>
    </item>
    <item>
      <title>Algorithms for mean-field variational inference via polyhedral optimization in the Wasserstein space</title>
      <link>https://arxiv.org/abs/2312.02849</link>
      <description>arXiv:2312.02849v4 Announce Type: replace-cross 
Abstract: We develop a theory of finite-dimensional polyhedral subsets over the Wasserstein space and optimization of functionals over them via first-order methods. Our main application is to the problem of mean-field variational inference, which seeks to approximate a distribution $\pi$ over $\mathbb{R}^d$ by a product measure $\pi^\star$. When $\pi$ is strongly log-concave and log-smooth, we provide (1) approximation rates certifying that $\pi^\star$ is close to the minimizer $\pi^\star_\diamond$ of the KL divergence over a \emph{polyhedral} set $\mathcal{P}_\diamond$, and (2) an algorithm for minimizing $\text{KL}(\cdot\|\pi)$ over $\mathcal{P}_\diamond$ based on accelerated gradient descent over $\R^d$. As a byproduct of our analysis, we obtain the first end-to-end analysis for gradient-based algorithms for MFVI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.02849v4</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.TH</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yiheng Jiang, Sinho Chewi, Aram-Alexandre Pooladian</dc:creator>
    </item>
    <item>
      <title>A Branch-Price-Cut-And-Switch Approach for Optimizing Team Formation and Routing for Airport Baggage Handling Tasks with Stochastic Travel Times</title>
      <link>https://arxiv.org/abs/2405.20912</link>
      <description>arXiv:2405.20912v2 Announce Type: replace-cross 
Abstract: In airport operations, optimally using dedicated personnel for baggage handling tasks plays a crucial role in the design of resource-efficient processes. Teams of workers with different qualifications must be formed, and loading or unloading tasks must be assigned to them. Each task has a time window within which it can be started and should be finished. Violating these temporal restrictions incurs severe financial penalties for the operator. In practice, various components of this process are subject to uncertainties. We consider the aforementioned problem under the assumption of stochastic travel times across the apron. We present two binary program formulations to model the problem at hand and propose a novel solution approach that we call Branch-Price-Cut-and-Switch, in which we dynamically switch between two master problem formulations. Furthermore, we use an exact separation method to identify violated rank-1 Chv\'atal-Gomory cuts and utilize an efficient branching rule relying on task finish times. We test the algorithm on instances generated based on real-world data from a major European hub airport with a planning horizon of up to two hours, 30 flights per hour, and three available task execution modes to choose from. Our results indicate that our algorithm is able to significantly outperform existing solution approaches. Moreover, an explicit consideration of stochastic travel times allows for solutions that utilize the available workforce more efficiently, while simultaneously guaranteeing a stable service level for the baggage handling operator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20912v2</guid>
      <category>econ.GN</category>
      <category>math.OC</category>
      <category>q-fin.EC</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andreas Hagn, Rainer Kolisch, Giacomo Dall'Olio, Stefan Weltge</dc:creator>
    </item>
    <item>
      <title>A Generalization Result for Convergence in Learning-to-Optimize</title>
      <link>https://arxiv.org/abs/2410.07704</link>
      <description>arXiv:2410.07704v2 Announce Type: replace-cross 
Abstract: Learning-to-optimize leverages machine learning to accelerate optimization algorithms. While empirical results show tremendous improvements compared to classical optimization algorithms, theoretical guarantees are mostly lacking, such that the outcome cannot be reliably assured. Especially, convergence is hardly studied in learning-to-optimize, because conventional convergence guarantees in optimization are based on geometric arguments, which cannot be applied easily to learned algorithms. Thus, we develop a probabilistic framework that resembles classical optimization and allows for transferring geometric arguments into learning-to-optimize. Based on our new proof-strategy, our main theorem is a generalization result for parametric classes of potentially non-smooth, non-convex loss functions and establishes the convergence of learned optimization algorithms to critical points with high probability. This effectively generalizes the results of a worst-case analysis into a probabilistic framework, and frees the design of the learned algorithm from using safeguards.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07704v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Sucker, Peter Ochs</dc:creator>
    </item>
    <item>
      <title>Optimal response for stochastic differential equations by local kernel perturbations</title>
      <link>https://arxiv.org/abs/2502.09300</link>
      <description>arXiv:2502.09300v2 Announce Type: replace-cross 
Abstract: We consider a random dynamical system on $\mathbb{R}^d$, whose dynamics is defined by a stochastic differential equation. The annealed transfer operator associated with such systems is a kernel operator. Given a set of feasible infinitesimal perturbations $P$ to this kernel, with support in a certain compact set, and a specified observable function $\phi: \mathbb{R}^d \to \mathbb{R}$, we study which infinitesimal perturbation in $P$ produces the greatest change in expectation of $\phi$. We establish conditions under which the optimal perturbation uniquely exists and present a numerical method to approximate the optimal infinitesimal kernel perturbation. Finally, we numerically illustrate our findings with concrete examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09300v2</guid>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gianmarco del Sarto, Stefano Galatolo, Sakshi Jain</dc:creator>
    </item>
    <item>
      <title>Bayesian Inferential Motion Planning Using Heavy-Tailed Distributions</title>
      <link>https://arxiv.org/abs/2503.22030</link>
      <description>arXiv:2503.22030v2 Announce Type: replace-cross 
Abstract: Robots rely on motion planning to navigate safely and efficiently while performing various tasks. In this paper, we investigate motion planning through Bayesian inference, where motion plans are inferred based on planning objectives and constraints. However, existing Bayesian motion planning methods often struggle to explore low-probability regions of the planning space, where high-quality plans may reside. To address this limitation, we propose the use of heavy-tailed distributions -- specifically, Student's-$t$ distributions -- to enhance probabilistic inferential search for motion plans. We develop a novel sequential single-pass smoothing approach that integrates Student's-$t$ distribution with Monte Carlo sampling. A special case of this approach is ensemble Kalman smoothing, which depends on short-tailed Gaussian distributions. We validate the proposed approach through simulations in autonomous vehicle motion planning, demonstrating its superior performance in planning, sampling efficiency, and constraint satisfaction compared to ensemble Kalman smoothing. While focused on motion planning, this work points to the broader potential of heavy-tailed distributions in enhancing probabilistic decision-making in robotics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.22030v2</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ali Vaziri, Iman Askari, Huazhen Fang</dc:creator>
    </item>
    <item>
      <title>Collision Probability Estimation for Optimization-based Vehicular Motion Planning</title>
      <link>https://arxiv.org/abs/2505.21161</link>
      <description>arXiv:2505.21161v2 Announce Type: replace-cross 
Abstract: Many motion planning algorithms for automated driving require estimating the probability of collision (POC) to account for uncertainties in the measurement and estimation of the motion of road users. Common POC estimation techniques often utilize sampling-based methods that suffer from computational inefficiency and a non-deterministic estimation, i.e., each estimation result for the same inputs is slightly different. In contrast, optimization-based motion planning algorithms require computationally efficient POC estimation, ideally using deterministic estimation, such that typical optimization algorithms for motion planning retain feasibility. Estimating the POC analytically, however, is challenging because it depends on understanding the collision conditions (e.g., vehicle's shape) and characterizing the uncertainty in motion prediction. In this paper, we propose an approach in which we estimate the POC between two vehicles by over-approximating their shapes by a multi-circular shape approximation. The position and heading of the predicted vehicle are modelled as random variables, contrasting with the literature, where the heading angle is often neglected. We guarantee that the provided POC is an over-approximation, which is essential in providing safety guarantees, and present a computationally efficient algorithm for computing the POC estimate for Gaussian uncertainty in the position and heading. This algorithm is then used in a path-following stochastic model predictive controller (SMPC) for motion planning. With the proposed algorithm, the SMPC generates reproducible trajectories while the controller retains its feasibility in the presented test cases and demonstrates the ability to handle varying levels of uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21161v2</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Leon Tolksdorf, Arturo Tejada, Christian Birkner, Nathan van de Wouw</dc:creator>
    </item>
  </channel>
</rss>
