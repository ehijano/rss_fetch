<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.ST updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.ST</link>
    <description>math.ST updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.ST" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 14 Mar 2025 04:00:34 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Batch List-Decodable Linear Regression via Higher Moments</title>
      <link>https://arxiv.org/abs/2503.09802</link>
      <description>arXiv:2503.09802v1 Announce Type: cross 
Abstract: We study the task of list-decodable linear regression using batches. A batch is called clean if it consists of i.i.d. samples from an unknown linear regression distribution. For a parameter $\alpha \in (0, 1/2)$, an unknown $\alpha$-fraction of the batches are clean and no assumptions are made on the remaining ones. The goal is to output a small list of vectors at least one of which is close to the true regressor vector in $\ell_2$-norm. [DJKS23] gave an efficient algorithm, under natural distributional assumptions, with the following guarantee. Assuming that the batch size $n$ satisfies $n \geq \tilde{\Omega}(\alpha^{-1})$ and the number of batches is $m = \mathrm{poly}(d, n, 1/\alpha)$, their algorithm runs in polynomial time and outputs a list of $O(1/\alpha^2)$ vectors at least one of which is $\tilde{O}(\alpha^{-1/2}/\sqrt{n})$ close to the target regressor. Here we design a new polynomial time algorithm with significantly stronger guarantees under the assumption that the low-degree moments of the covariates distribution are Sum-of-Squares (SoS) certifiably bounded. Specifically, for any constant $\delta&gt;0$, as long as the batch size is $n \geq \Omega_{\delta}(\alpha^{-\delta})$ and the degree-$\Theta(1/\delta)$ moments of the covariates are SoS certifiably bounded, our algorithm uses $m = \mathrm{poly}((dn)^{1/\delta}, 1/\alpha)$ batches, runs in polynomial-time, and outputs an $O(1/\alpha)$-sized list of vectors one of which is $O(\alpha^{-\delta/2}/\sqrt{n})$ close to the target. That is, our algorithm achieves substantially smaller minimum batch size and final error, while achieving the optimal list size. Our approach uses higher-order moment information by carefully combining the SoS paradigm interleaved with an iterative method and a novel list pruning procedure. In the process, we give an SoS proof of the Marcinkiewicz-Zygmund inequality that may be of broader applicability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09802v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ilias Diakonikolas, Daniel M. Kane, Sushrut Karmalkar, Sihan Liu, Thanasis Pittas</dc:creator>
    </item>
    <item>
      <title>Generalized network autoregressive modelling of longitudinal networks with application to presidential elections in the USA</title>
      <link>https://arxiv.org/abs/2503.10433</link>
      <description>arXiv:2503.10433v1 Announce Type: cross 
Abstract: Longitudinal networks are becoming increasingly relevant in the study of dynamic processes characterised by known or inferred community structure. Generalised Network Autoregressive (GNAR) models provide a parsimonious framework for exploiting the underlying network and multivariate time series. We introduce the community-$\alpha$ GNAR model with interactions that exploits prior knowledge or exogenous variables for analysing interactions within and between communities, and can describe serial correlation in longitudinal networks. We derive new explicit finite-sample error bounds that validate analysing high-dimensional longitudinal network data with GNAR models, and provide insights into their attractive properties. We further illustrate our approach by analysing the dynamics of $\textit{Red, Blue}$ and $\textit{Swing}$ states throughout presidential elections in the USA from 1976 to 2020, that is, a time series of length twelve on 51 time series (US states and Washington DC). Our analysis connects network autocorrelation to eight-year long terms, highlights a possible change in the system after the 2016 election, and a difference in behaviour between $\textit{Red}$ and $\textit{Blue}$ states.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10433v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Guy Nason, Daniel Salnikov, Mario Cortina-Borja</dc:creator>
    </item>
    <item>
      <title>On the Injective Norm of Sums of Random Tensors and the Moments of Gaussian Chaoses</title>
      <link>https://arxiv.org/abs/2503.10580</link>
      <description>arXiv:2503.10580v1 Announce Type: cross 
Abstract: We prove an upper bound on the expected $\ell_p$ injective norm of sums of subgaussian random tensors. Our proof is simple and does not rely on any explicit geometric or chaining arguments. Instead, it follows from a simple application of the PAC-Bayesian lemma, a tool that has proven effective at controlling the suprema of certain ``smooth'' empirical processes in recent years. Our bound strictly improves a very recent result of Bandeira, Gopi, Jiang, Lucca, and Rothvoss. In the Euclidean case ($p=2$), our bound sharpens a result of Lata{\l}a that was central to proving his estimates on the moments of Gaussian chaoses. As a consequence, we obtain an elementary proof of this fundamental result.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10580v1</guid>
      <category>math.PR</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ishaq Aden-Ali</dc:creator>
    </item>
    <item>
      <title>Change-Point Detection in Dynamic Networks with Missing Links</title>
      <link>https://arxiv.org/abs/2106.14470</link>
      <description>arXiv:2106.14470v2 Announce Type: replace 
Abstract: Structural changes occur in dynamic networks quite frequently and its detection is an important question in many situations such as fraud detection or cybersecurity. Real-life networks are often incompletely observed due to individual non-response or network size. In the present paper we consider the problem of change-point detection at a temporal sequence of partially observed networks. The goal is to test whether there is a change in the network parameters. Our approach is based on the Matrix CUSUM test statistic and allows growing size of networks. We show that the proposed test is minimax optimal and robust to missing links. We also demonstrate the good behavior of our approach in practice through simulation study and a real-data application.</description>
      <guid isPermaLink="false">oai:arXiv.org:2106.14470v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Farida Enikeeva (LMA), Olga Klopp (CREST)</dc:creator>
    </item>
    <item>
      <title>Benign Overfitting in Time Series Linear Models with Over-Parameterization</title>
      <link>https://arxiv.org/abs/2204.08369</link>
      <description>arXiv:2204.08369v3 Announce Type: replace 
Abstract: The success of large-scale models in recent years has increased the importance of statistical models with numerous parameters. Several studies have analyzed over-parameterized linear models with high-dimensional data, which may not be sparse; however, existing results rely on the assumption of sample independence. In this study, we analyze a linear regression model with dependent time-series data in an over-parameterized setting. We consider an estimator using interpolation and develop a theory for the excess risk of the estimator. Then, we derive non-asymptotic risk bounds for the estimator for cases with dependent data. This analysis reveals that the coherence of the temporal covariance plays a key role; the risk bound is influenced by the product of temporal covariance matrices at different time steps. Moreover, we show the convergence rate of the risk bound and demonstrate that it is also influenced by the coherence of the temporal covariance. Finally, we provide several examples of specific dependent processes applicable to our setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2204.08369v3</guid>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shogo Nakakita, Masaaki Imaizumi</dc:creator>
    </item>
    <item>
      <title>Semi-parametric Bernstein-von Mises in Linear Inverse Problems</title>
      <link>https://arxiv.org/abs/2310.02883</link>
      <description>arXiv:2310.02883v3 Announce Type: replace 
Abstract: We consider a Bayesian approach for the recovery of scalar parameters arising in inverse problems. We consider a general signal-in white noise model where we have access to two independent noisy observations of a function, and of a linear transformation of the function. The linear operator is unknown up to a scalar parameter. We present a Bernstein-von Mises theorem for the marginal posterior of the scalar under regularity assumptions of the operator. We further derive Bernstein-von Mises results for different priors and apply them to two concrete examples: the recovery of the thermal diffusivity in a heat equation problem, and the recovery of a location parameter in a semi-blind deconvolution problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.02883v3</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adel Magra, Aad van der Vaart, Harry van Zanten</dc:creator>
    </item>
    <item>
      <title>Directional testing for one-way MANOVA in divergent dimensions</title>
      <link>https://arxiv.org/abs/2403.07679</link>
      <description>arXiv:2403.07679v2 Announce Type: replace 
Abstract: Testing the equality of mean vectors across $g$ different groups plays an important role in many scientific fields. In regular frameworks, likelihood-based statistics under the normality assumption offer a general solution to this task. However, the accuracy of standard asymptotic results is not reliable when the dimension $p$ of the data is large relative to the sample size $n_i$ of each group. We propose here an exact directional test for the equality of $g$ normal mean vectors with identical unknown covariance matrix in a high dimensional setting, provided that $\sum_{i=1}^g n_i \ge p+g+1$. In the case of two groups ($g=2$), the directional test coincides with the Hotelling's $T^2$ test. In the more general situation where the $g$ independent groups may have different unknown covariance matrices, although exactness does not hold, simulation studies show that the directional test is more accurate than most commonly used likelihood{-}based solutions, at least in a moderate dimensional setting in which $p=O(n_i^\tau)$, $\tau \in (0,1)$. Robustness of the directional approach and its competitors under deviation from the assumption of multivariate normality is also numerically investigated. Our proposal is here applied to data on blood characteristics of male athletes and to microarray data storing gene expressions in patients with breast tumors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07679v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Caizhu Huang, Claudia Di Caterina, Nicola Sartori</dc:creator>
    </item>
    <item>
      <title>Asymptotic spectrum of weighted sample covariance: another proof of spectrum convergence</title>
      <link>https://arxiv.org/abs/2410.14408</link>
      <description>arXiv:2410.14408v2 Announce Type: replace 
Abstract: We propose another proof of the high dimensional spectrum convergence of the weighted sample covariance, more concise and self-sufficient but with stronger, but reasonable assumptions. We explain and illustrates this theorem for different weight distributions and show how the spectrum behaves in finite samples with heavy tails. The general purpose is to provide a detailed introduction to the high dimensional spectrum of weighted sample covariance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14408v2</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Benoit Oriol</dc:creator>
    </item>
    <item>
      <title>Entropy of Exchangeable Random Graphs</title>
      <link>https://arxiv.org/abs/2302.01856</link>
      <description>arXiv:2302.01856v3 Announce Type: replace-cross 
Abstract: Quantifying the complexity of large graphs requires measures that extend beyond predefined structural features and scale efficiently with graph size. This work adopts a generative perspective, modeling large networks as exchangeable graphs to quantify the information content of their generating mechanisms via graphon entropy. As a graph property, graphon entropy is invariant under isomorphisms, making it an effective measure of complexity; however, it is not directly computable. To address this, we introduce a suite of graphon entropy estimators, including a nonparametric estimator for broad applicability and specialized versions for structured graphons arising from well-studied random graph models such as Erd\H{o}s-R\'enyi, Chung-Lu, and stochastic block models. We establish their large-sample properties, deriving convergence rates and Central Limit Theorems. Simulations illustrate how the nonparametric graphon entropy estimator captures structural variations in graphs, while real-world applications demonstrate its role in characterizing evolving network dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.01856v3</guid>
      <category>cs.IT</category>
      <category>math.CO</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anda Skeja, Sofia C. Olhede</dc:creator>
    </item>
    <item>
      <title>The Breakdown of Gaussian Universality in Classification of High-dimensional Linear Factor Mixtures</title>
      <link>https://arxiv.org/abs/2410.05609</link>
      <description>arXiv:2410.05609v3 Announce Type: replace-cross 
Abstract: The assumption of Gaussian or Gaussian mixture data has been extensively exploited in a long series of precise performance analyses of machine learning (ML) methods, on large datasets having comparably numerous samples and features. To relax this restrictive assumption, subsequent efforts have been devoted to establish "Gaussian equivalent principles" by studying scenarios of Gaussian universality where the asymptotic performance of ML methods on non-Gaussian data remains unchanged when replaced with Gaussian data having the same mean and covariance. Beyond the realm of Gaussian universality, there are few exact results on how the data distribution affects the learning performance.
  In this article, we provide a precise high-dimensional characterization of empirical risk minimization, for classification under a general mixture data setting of linear factor models that extends Gaussian mixtures. The Gaussian universality is shown to break down under this setting, in the sense that the asymptotic learning performance depends on the data distribution beyond the class means and covariances. To clarify the limitations of Gaussian universality in the classification of mixture data and to understand the impact of its breakdown, we specify conditions for Gaussian universality and discuss their implications for the choice of loss function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05609v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaoyi Mai, Zhenyu Liao</dc:creator>
    </item>
  </channel>
</rss>
