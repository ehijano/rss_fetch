<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DB updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DB</link>
    <description>cs.DB updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DB" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 29 Jan 2025 02:33:41 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Towards Interoperable Data Spaces: Comparative Analysis of Data Space Implementations between Japan and Europe</title>
      <link>https://arxiv.org/abs/2501.15738</link>
      <description>arXiv:2501.15738v1 Announce Type: new 
Abstract: The rapid evolution of data spaces is transforming the landscape of secure and interoperable data sharing across industries and geographies. In Europe, the concept of data spaces, supported by initiatives such as the European Data Strategy, emphasises the importance of trust, sovereignty, and interoperability. Meanwhile, Japan has been developing its approach to data sharing, in line with global trends but also to address unique domestic challenges. Despite these parallel advances, achieving interoperability between European and Japanese data spaces remains a critical challenge due to differences in governance, technology standards, and authentication frameworks. This paper undertakes a comparative analysis of DATA-EX and Catena-X to explore the challenges and opportunities for achieving interoperability between Japanese and European data spaces. By examining common data exchange processes, key objects such as participants, datasets, and data catalogs, and specific evaluation criteria, the study identifies gaps and proposes actionable solutions. Through this analysis, the paper aims to contribute to the ongoing discourse on global data interoperability. It proposes an interoperable architecture that bridges regional differences while addressing common challenges. It also identifies challenges that should be addressed to achieve interoperability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.15738v1</guid>
      <category>cs.DB</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shun Ishihara, Taka Matsutsuka</dc:creator>
    </item>
    <item>
      <title>Improving DBMS Scheduling Decisions with Fine-grained Performance Prediction on Concurrent Queries -- Extended</title>
      <link>https://arxiv.org/abs/2501.16256</link>
      <description>arXiv:2501.16256v1 Announce Type: new 
Abstract: Query scheduling is a critical task that directly impacts query performance in database management systems (DBMS). Deeply integrated schedulers, which require changes to DBMS internals, are usually customized for a specific engine and can take months to implement. In contrast, non-intrusive schedulers make coarse-grained decisions, such as controlling query admission and re-ordering query execution, without requiring modifications to DBMS internals. They require much less engineering effort and can be applied across a wide range of DBMS engines, offering immediate benefits to end users. However, most existing non-intrusive scheduling systems rely on simplified cost models and heuristics that cannot accurately model query interactions under concurrency and different system states, possibly leading to suboptimal scheduling decisions.
  This work introduces IconqSched, a new, principled non-intrusive scheduler that optimizes the execution order and timing of queries to enhance total end-to-end runtime as experienced by the user query queuing time plus system runtime. Unlike previous approaches, IconqSched features a novel fine-grained predictor, Iconq, which treats the DBMS as a black box and accurately estimates the system runtime of concurrently executed queries under different system states. Using these predictions, IconqSched is able to capture system runtime variations across different query mixes and system loads. It then employs a greedy scheduling algorithm to effectively determine which queries to submit and when to submit them. We compare IconqSched to other schedulers in terms of end-to-end runtime using real workload traces. On Postgres, IconqSched reduces end-to-end runtime by 16.2%-28.2% on average and 33.6%-38.9% in the tail. Similarly, on Redshift, it reduces end-to-end runtime by 10.3%-14.1% on average and 14.9%-22.2% in the tail.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16256v1</guid>
      <category>cs.DB</category>
      <category>cs.LG</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziniu Wu, Markos Markakis, Chunwei Liu, Peter Baile Chen, Balakrishnan Narayanaswamy, Tim Kraska, Samuel Madden</dc:creator>
    </item>
    <item>
      <title>NetChain: Authenticated Blockchain Top-k Graph Data Queries and its Application in Asset Management</title>
      <link>https://arxiv.org/abs/2501.15077</link>
      <description>arXiv:2501.15077v1 Announce Type: cross 
Abstract: As a valuable digital resource, graph data is an important data asset, which has been widely utilized across various fields to optimize decision-making and enable smarter solutions. To manage data assets, blockchain is widely used to enable data sharing and trading, but it cannot supply complex analytical queries. vChain was proposed to achieve verifiable boolean queries over blockchain by designing an embedded authenticated data structure (ADS). However, for generating (non-)existence proofs, vChain suffers from expensive storage and computation costs in ADS construction, along with high communication and verification costs. In this paper, we propose a novel NetChain framework that enables efficient top-k queries over on-chain graph data with verifiability. Specifically, we design a novel authenticated two-layer index that supports (non-)existence proof generation in block-level and built-in verifiability for matched objects. To further alleviate the computation and verification overhead, an optimized variant NetChain+ is derived. The authenticity of our frameworks is validated through security analysis. Evaluations show that NetChain and NetChain+ outperform vChain, respectively achieving up to 85X and 31X improvements on ADS construction. Moreover, compared with vChain, NetChain+ reduces the communication and verification costs by 87% and 96% respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.15077v1</guid>
      <category>cs.CR</category>
      <category>cs.DB</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongguang Zhao, Xu Yang, Saiyu Qi, Qiuhao Wang, Ke Li</dc:creator>
    </item>
    <item>
      <title>Technology Mapping with Large Language Models</title>
      <link>https://arxiv.org/abs/2501.15120</link>
      <description>arXiv:2501.15120v1 Announce Type: cross 
Abstract: In today's fast-evolving business landscape, having insight into the technology stacks that organizations use is crucial for forging partnerships, uncovering market openings, and informing strategic choices. However, conventional technology mapping, which typically hinges on keyword searches, struggles with the sheer scale and variety of data available, often failing to capture nascent technologies. To overcome these hurdles, we present STARS (Semantic Technology and Retrieval System), a novel framework that harnesses Large Language Models (LLMs) and Sentence-BERT to pinpoint relevant technologies within unstructured content, build comprehensive company profiles, and rank each firm's technologies according to their operational importance. By integrating entity extraction with Chain-of-Thought prompting and employing semantic ranking, STARS provides a precise method for mapping corporate technology portfolios. Experimental results show that STARS markedly boosts retrieval accuracy, offering a versatile and high-performance solution for cross-industry technology mapping.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.15120v1</guid>
      <category>cs.IR</category>
      <category>cs.DB</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Minh Hieu Nguyen, Hien Thu Pham, Hiep Minh Ha, Ngoc Quang Hung Le, Jun Jo</dc:creator>
    </item>
    <item>
      <title>Diversity of Answers to Conjunctive Queries</title>
      <link>https://arxiv.org/abs/2301.08848</link>
      <description>arXiv:2301.08848v5 Announce Type: replace 
Abstract: Enumeration problems aim at outputting, without repetition, the set of solutions to a given problem instance. However, outputting the entire solution set may be prohibitively expensive if it is too big. In this case, outputting a small, sufficiently diverse subset of the solutions would be preferable. This leads to the Diverse-version of the original enumeration problem, where the goal is to achieve a certain level d of diversity by selecting k solutions. In this paper, we look at the Diverse-version of the query answering problem for Conjunctive Queries and extensions thereof. That is, we study the problem if it is possible to achieve a certain level d of diversity by selecting k answers to the given query and, in the positive case, to actually compute such k answers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.08848v5</guid>
      <category>cs.DB</category>
      <category>cs.CC</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Timo Camillo Merkl, Reinhard Pichler, Sebastian Skritek</dc:creator>
    </item>
    <item>
      <title>Enumeration of Minimal Hitting Sets Parameterized by Treewidth</title>
      <link>https://arxiv.org/abs/2408.15776</link>
      <description>arXiv:2408.15776v2 Announce Type: replace 
Abstract: Enumerating the minimal hitting sets of a hypergraph is a problem which arises in many data management applications that include constraint mining, discovering unique column combinations, and enumerating database repairs. Previously, Eiter et al. showed that the minimal hitting sets of an $n$-vertex hypergraph, with treewidth $w$, can be enumerated with delay $O^*(n^{w})$ (ignoring polynomial factors), with space requirements that scale with the output size. We improve this to fixed-parameter-linear delay, following an FPT preprocessing phase. The memory consumption of our algorithm is exponential with respect to the treewidth of the hypergraph.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.15776v2</guid>
      <category>cs.DB</category>
      <category>cs.DS</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Batya Kenig, Dan Shlomo Mizrahi</dc:creator>
    </item>
    <item>
      <title>The Selection Problem in Multi-Query Optimization: a Comprehensive Survey</title>
      <link>https://arxiv.org/abs/2412.11828</link>
      <description>arXiv:2412.11828v2 Announce Type: replace 
Abstract: View materialization, index selection, and plan caching are well-known techniques for optimization of query processing in database systems. The essence of these tasks is to select and save a subset of the most useful candidates (views/indexes/plans) for reuse within given space/time budget constraints. In this paper, we propose a unified view on these selection problems. We make a detailed analysis of the root causes of their complexity and summarize techniques to address them. Our survey provides a modern classification of selection algorithms known in the literature, including the latest ones based on Machine Learning. We provide a ground for reuse of the selection techniques between different optimization scenarios and highlight challenges and promising directions in the field. Based on our analysis we derive a method to exponentially accelerate some of the state-of-the-art selection algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.11828v2</guid>
      <category>cs.DB</category>
      <category>cs.DM</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sergey Zinchenko, Denis Ponomaryov</dc:creator>
    </item>
    <item>
      <title>Retrieval with Learned Similarities</title>
      <link>https://arxiv.org/abs/2407.15462</link>
      <description>arXiv:2407.15462v4 Announce Type: replace-cross 
Abstract: Retrieval plays a fundamental role in recommendation systems, search, and natural language processing (NLP) by efficiently finding relevant items from a large corpus given a query. Dot products have been widely used as the similarity function in such tasks, enabled by Maximum Inner Product Search (MIPS) algorithms for efficient retrieval. However, state-of-the-art retrieval algorithms have migrated to learned similarities. These advanced approaches encompass multiple query embeddings, complex neural networks, direct item ID decoding via beam search, and hybrid solutions. Unfortunately, we lack efficient solutions for retrieval in these state-of-the-art setups. Our work addresses this gap by investigating efficient retrieval techniques with expressive learned similarity functions. We establish Mixture-of-Logits (MoL) as a universal approximator of similarity functions, demonstrate that MoL's expressiveness can be realized empirically to achieve superior performance on diverse retrieval scenarios, and propose techniques to retrieve the approximate top-k results using MoL with tight error bounds. Through extensive experimentation, we show that MoL, enhanced by our proposed mutual information-based load balancing loss, sets new state-of-the-art results across heterogeneous scenarios, including sequential retrieval models in recommendation systems and finetuning language models for question answering; and our approximate top-$k$ algorithms outperform baselines by up to 66x in latency while achieving &gt;.99 recall rate compared to exact algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15462v4</guid>
      <category>cs.IR</category>
      <category>cs.DB</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3696410.3714822</arxiv:DOI>
      <dc:creator>Bailu Ding, Jiaqi Zhai</dc:creator>
    </item>
  </channel>
</rss>
