<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 07 Aug 2025 01:30:20 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Understanding Demand for Shared Autonomous Micro-Mobility</title>
      <link>https://arxiv.org/abs/2508.03521</link>
      <description>arXiv:2508.03521v1 Announce Type: new 
Abstract: This study examines the behavioral and environmental implications of shared autonomous micro-mobility systems, focusing on autonomous bicycles and their integration with transit in the U.S. While prior research has addressed operational and lifecycle aspects, a critical gap remains in understanding which modes these services are likely to substitute, who is most inclined to adopt them, and how service attributes influence user decisions. We design a context-aware stated preference survey grounded in real-world trips and estimate discrete choice models, including a hybrid model incorporating latent attitudes. Findings indicate that adoption, mode shift, and environmental impacts are highly sensitive to service design. Scenarios with minimal wait and cost yield high adoption but increase emissions, while moderate waits are more likely to reduce impacts. Adoption likelihood varies with demographic characteristics, and outcomes depend on city type, context, and infrastructure assumptions. These insights can inform the development of more sustainable and equitable mobility systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03521v1</guid>
      <category>cs.ET</category>
      <category>cs.CY</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Naroa Coretti Sanchez, Kent Larson</dc:creator>
    </item>
    <item>
      <title>Embedding-Enhanced Probabilistic Modeling of Ferroelectric Field Effect Transistors (FeFETs)</title>
      <link>https://arxiv.org/abs/2508.02737</link>
      <description>arXiv:2508.02737v1 Announce Type: cross 
Abstract: FeFETs hold strong potential for advancing memory and logic technologies, but their inherent randomness arising from both operational cycling and fabrication variability poses significant challenges for accurate and reliable modeling. Capturing this variability is critical, as it enables designers to predict behavior, optimize performance, and ensure reliability and robustness against variations in manufacturing and operating conditions. Existing deterministic and machine learning-based compact models often fail to capture the full extent of this variability or lack the mathematical smoothness required for stable circuit-level integration. In this work, we present an enhanced probabilistic modeling framework for FeFETs that addresses these limitations. Building upon a Mixture Density Network (MDN) foundation, our approach integrates C-infinity continuous activation functions for smooth, stable learning and a device-specific embedding layer to capture intrinsic physical variability across devices. Sampling from the learned embedding distribution enables the generation of synthetic device instances for variability-aware simulation. With an R2 of 0.92, the model demonstrates high accuracy in capturing the variability of FeFET current behavior. Altogether, this framework provides a scalable, data-driven solution for modeling the full stochastic behavior of FeFETs and offers a strong foundation for future compact model development and circuit simulation integration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02737v1</guid>
      <category>cs.LG</category>
      <category>cs.ET</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tasnia Nobi Afee, Jack Hutchins, Md Mazharul Islam, Thomas Kampfe, Ahmedullah Aziz</dc:creator>
    </item>
    <item>
      <title>Thermal-Aware 3D Design for Side-Channel Information Leakage</title>
      <link>https://arxiv.org/abs/2508.02816</link>
      <description>arXiv:2508.02816v1 Announce Type: cross 
Abstract: Side-channel attacks are important security challenges as they reveal sensitive information about on-chip activities. Among such attacks, the thermal side-channel has been shown to disclose the activities of key functional blocks and even encryption keys. This paper proposes a novel approach to proactively conceal critical activities in the functional layers while minimizing the power dissipation by (i) leveraging inherent characteristics of 3D integration to protect from side-channel attacks and (ii) dynamically generating custom activity patterns to match the activity to be concealed in the functional layers. Experimental analysis shows that 3D technology combined with the proposed run-time algorithm effectively reduces the Side channel vulnerability Factor (SVF) below 0.05 and the Spatial Thermal Side-channel Factor (STSF) below 0.59.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02816v1</guid>
      <category>cs.CR</category>
      <category>cs.ET</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>IEEE 34th International Conference on Computer Design (ICCD), 520-527, 2016</arxiv:journal_reference>
      <dc:creator>Dylan Stow, Russell Barnes, Eren Kurshan, Yuan Xie</dc:creator>
    </item>
    <item>
      <title>Towards Memory Specialization: A Case for Long-Term and Short-Term RAM</title>
      <link>https://arxiv.org/abs/2508.02992</link>
      <description>arXiv:2508.02992v1 Announce Type: cross 
Abstract: Both SRAM and DRAM have stopped scaling: there is no technical roadmap to reduce their cost (per byte/GB). As a result, memory now dominates system cost. This paper argues for a paradigm shift from today's simple memory hierarchy toward specialized memory architectures that exploit application-specific access patterns. Rather than relying solely on traditional off-chip DRAM and on-chip SRAM, we envisage memory systems equipped with additional types of memory whose performance trade-offs benefit workloads through non-hierarchical optimization. We propose two new memory classes deserving explicit OS support: long-term RAM (LtRAM) optimized for read-intensive data with long lifetimes, and short-term RAM (StRAM) designed for transient, frequently-accessed data with short lifetimes. We explore underlying device technologies that could implement these classes, including their evolution and their potential integration into current system designs given emerging workload requirements. We identify critical research challenges to realize what we believe is a necessary evolution toward more efficient and scalable computing systems capable of meeting future demands.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02992v1</guid>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peijing Li, Muhammad Shahir Abdurraman, Rachel Cleaveland, Sergey Legtchenko, Philip Levis, Ioan Stefanovici, Thierry Tambe, David Tennenhouse, Caroline Trippel</dc:creator>
    </item>
    <item>
      <title>Can Large Language Models Identify Materials from Radar Signals?</title>
      <link>https://arxiv.org/abs/2508.03120</link>
      <description>arXiv:2508.03120v1 Announce Type: cross 
Abstract: Accurately identifying the material composition of objects is a critical capability for AI robots powered by large language models (LLMs) to perform context-aware manipulation. Radar technologies offer a promising sensing modality for material recognition task. When combined with deep learning, radar technologies have demonstrated strong potential in identifying the material of various objects. However, existing radar-based solutions are often constrained to closed-set object categories and typically require task-specific data collection to train deep learning models, largely limiting their practical applicability. This raises an important question: Can we leverage the powerful reasoning capabilities of pre-trained LLMs to directly infer material composition from raw radar signals? Answering this question is non-trivial due to the inherent redundancy of radar signals and the fact that pre-trained LLMs have no prior exposure to raw radar data during training. To address this, we introduce LLMaterial, the first study to investigate the feasibility of using LLM to identify materials directly from radar signals. First, we introduce a physics-informed signal processing pipeline that distills high-redundancy radar raw data into a set of compact intermediate parameters that encapsulate the material's intrinsic characteristics. Second, we adopt a retrieval-augmented generation (RAG) strategy to provide the LLM with domain-specific knowledge, enabling it to interpret and reason over the extracted intermediate parameters. Leveraging this integration, the LLM is empowered to perform step-by-step reasoning on the condensed radar features, achieving open-set material recognition directly from raw radar signals. Preliminary results show that LLMaterial can effectively distinguish among a variety of common materials, highlighting its strong potential for real-world material identification applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03120v1</guid>
      <category>eess.SP</category>
      <category>cs.ET</category>
      <category>cs.RO</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3714394.3756289</arxiv:DOI>
      <dc:creator>Jiangyou Zhu, Hongyu Deng, He Chen</dc:creator>
    </item>
    <item>
      <title>Investigating the Cognitive Response of Brake Lights in Initiating Braking Action Using EEG</title>
      <link>https://arxiv.org/abs/2508.03274</link>
      <description>arXiv:2508.03274v1 Announce Type: cross 
Abstract: Half of all road accidents result from either lack of driver attention or from maintaining insufficient separation between vehicles. Collision from the rear, in particular, has been identified as the most common class of accident in the UK, and its influencing factors have been widely studied for many years. Rear-mounted stop lamps, illuminated when braking, are the primary mechanism to alert following drivers to the need to reduce speed or brake. This paper develops a novel brain response approach to measuring subject reaction to different brake light designs. A variety of off-the-shelf brake light assemblies are tested in a physical simulated driving environment to assess the cognitive reaction times of 22 subjects. Eight pairs of LED-based and two pairs of incandescent bulb-based brake light assemblies are used and electroencephalogram (EEG) data recorded. Channel Pz is utilised to extract the P3 component evoked during the decision making process that occurs in the brain when a participant decides to lift their foot from the accelerator and depress the brake. EEG analysis shows that both incandescent bulb-based lights are statistically slower to evoke cognitive responses than all tested LED-based lights. Between the LED designs, differences are evident, but not statistically significant, attributed to the significant amount of movement artifact in the EEG signal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03274v1</guid>
      <category>eess.SP</category>
      <category>cs.ET</category>
      <category>cs.HC</category>
      <category>cs.IR</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TITS.2021.3091291</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Intelligent Transportation Systems Aug 2022</arxiv:journal_reference>
      <dc:creator>Ramaswamy Palaniappan, Surej Mouli, Howard Bowman, Ian McLoughlin</dc:creator>
    </item>
    <item>
      <title>Live Demonstration: Neuromorphic Radar for Gesture Recognition</title>
      <link>https://arxiv.org/abs/2508.03324</link>
      <description>arXiv:2508.03324v2 Announce Type: cross 
Abstract: We present a neuromorphic radar framework for real-time, low-power hand gesture recognition (HGR) using an event-driven architecture inspired by biological sensing. Our system comprises a 24 GHz Doppler radar front-end and a custom neuromorphic sampler that converts intermediate-frequency (IF) signals into sparse spike-based representations via asynchronous sigma-delta encoding. These events are directly processed by a lightweight neural network deployed on a Cortex-M0 microcontroller, enabling low-latency inference without requiring spectrogram reconstruction. Unlike conventional radar HGR pipelines that continuously sample and process data, our architecture activates only when meaningful motion is detected, significantly reducing memory, power, and computation overhead. Evaluated on a dataset of five gestures collected from seven users, our system achieves &gt; 85% real-time accuracy. To the best of our knowledge, this is the first work that employs bio-inspired asynchronous sigma-delta encoding and an event-driven processing framework for radar-based HGR.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03324v2</guid>
      <category>cs.CV</category>
      <category>cs.ET</category>
      <category>cs.NE</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Satyapreet Singh Yadav, Akash K S, Chandra Sekhar Seelamantula, Chetan Singh Thakur</dc:creator>
    </item>
    <item>
      <title>Efficient Variational Quantum Algorithms via Circuit Knitting and Architecture Search</title>
      <link>https://arxiv.org/abs/2508.03376</link>
      <description>arXiv:2508.03376v1 Announce Type: cross 
Abstract: Current quantum hardware presents a significant limitation in the number of available qubits compared to the requirements of practical quantum algorithms. Circuit knitting has been proposed as a solution to this issue by partitioning larger quantum circuits into smaller parts that can be executed by current devices. However, this approach often leads to a high sampling overhead, which increases exponentially with the number of cut points. In this paper, we introduce CKVQA, a framework that applies circuit knitting to variational quantum algorithms (VQAs). By employing a quantum circuit architecture search adapted to this scenario, CKVQA aims to minimize the sampling overhead by identifying parameterized quantum circuits that achieve a favorable balance between algorithmic performance and sampling overhead. Additionally, since circuit knitting generates multiple subcircuits, we have developed a subcircuit-level optimization method to accelerate the training of VQAs and reduce overall execution time. We apply this framework to two widely-used VQAs: the Quantum Approximate Optimization Algorithm and the Variational Quantum Eigensolver. Our numerical results demonstrate that the CKVQA framework significantly reduces the sampling overheads while maintaining comparable accuracy to conventional parameterized quantum circuit designs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03376v1</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jun Wu, Jiaqi Yang, Jicun Li, Wei Xie, Xiang-Yang Li</dc:creator>
    </item>
    <item>
      <title>Decoding and Engineering the Phytobiome Communication for Smart Agriculture</title>
      <link>https://arxiv.org/abs/2508.03584</link>
      <description>arXiv:2508.03584v1 Announce Type: cross 
Abstract: Smart agriculture applications, integrating technologies like the Internet of Things and machine learning/artificial intelligence (ML/AI) into agriculture, hold promise to address modern challenges of rising food demand, environmental pollution, and water scarcity. Alongside the concept of the phytobiome, which defines the area including the plant, its environment, and associated organisms, and the recent emergence of molecular communication (MC), there exists an important opportunity to advance agricultural science and practice using communication theory. In this article, we motivate to use the communication engineering perspective for developing a holistic understanding of the phytobiome communication and bridge the gap between the phytobiome communication and smart agriculture. Firstly, an overview of phytobiome communication via molecular and electrophysiological signals is presented and a multi-scale framework modeling the phytobiome as a communication network is conceptualized. Then, how this framework is used to model electrophysiological signals is demonstrated with plant experiments. Furthermore, possible smart agriculture applications, such as smart irrigation and targeted delivery of agrochemicals, through engineering the phytobiome communication are proposed. These applications merge ML/AI methods with the Internet of Bio-Nano-Things enabled by MC and pave the way towards more efficient, sustainable, and eco-friendly agricultural production. Finally, the implementation challenges, open research issues, and industrial outlook for these applications are discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03584v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.NI</category>
      <category>q-bio.MN</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fatih Gulec, Hamdan Awan, Nigel Wallbridge, Andrew W. Eckford</dc:creator>
    </item>
    <item>
      <title>Beyond risk: A proto-framework for assessing the societal impact of AI systems</title>
      <link>https://arxiv.org/abs/2508.03666</link>
      <description>arXiv:2508.03666v2 Announce Type: cross 
Abstract: In the discourse on AI regulation, 'responsible AI' is the dominant paradigm, with the focus on mitigating the risks related to AI systems. While this focus is important and necessary, it has limited use for a systematic consideration of AI's societal impact. This paper proposes a proto-framework for assessing the societal impact of AI systems by operationalising the concept of freedom. This proto-framework is intended as a step towards a fully operationalised framework to be used in policymaking contexts. By drawing on Kantian philosophy and related contemporary interpretations, freedom is developed as the counterpart to the concept of responsibility. Two dimensions of freedom are developed in further detail: freedom as capability and freedom as opportunity. These two dimensions of freedom are then applied in a proto-framework that systematically considers AI's impact on society using the Sustainable Development Goals. This proto-framework aims to complement current risk-based approaches and thereby offers a first step towards operationalising the concept of freedom in AI regulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03666v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Willem Fourie</dc:creator>
    </item>
    <item>
      <title>Managing Escalation in Off-the-Shelf Large Language Models</title>
      <link>https://arxiv.org/abs/2508.01056</link>
      <description>arXiv:2508.01056v2 Announce Type: replace 
Abstract: U.S. national security customers have begun to utilize large language models, including enterprise versions of ``off-the-shelf'' models (e.g., ChatGPT) familiar to the public. This uptake will likely accelerate. However, recent studies suggest that off-the-shelf large language models frequently suggest escalatory actions when prompted with geopolitical or strategic scenarios. We demonstrate two simple, non-technical interventions to control these tendencies. Introducing these interventions into the experimental wargame design of a recent study, we substantially reduce escalation throughout the game. Calls to restrict the use of large language models in national security applications are thus premature. The U.S. government is already, and will continue, employing large language models for scenario planning and suggesting courses of action. Rather than warning against such applications, this study acknowledges the imminent adoption of large language models, and provides actionable measures to align them with national security goals, including escalation management.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.01056v2</guid>
      <category>cs.ET</category>
      <category>cs.AI</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sebastian Elbaum, Jonathan Panter</dc:creator>
    </item>
    <item>
      <title>Task Scheduling Optimization with Direct Constraints from a Tensor Network Perspective</title>
      <link>https://arxiv.org/abs/2311.10433</link>
      <description>arXiv:2311.10433v3 Announce Type: replace-cross 
Abstract: This work presents a novel method for task optimization in industrial plants using quantum-inspired tensor network technology. This method obtains the best possible combination of tasks on a set of machines with directed constraints. With this method, an exact and explicit solution of the problem is provided. This algorithm constructs a tensor network representation of the tensor which provides the solution of the problem. This method is improved in order to reduce the computational complexity of the solution computation, using problem preprocessing, new techniques of condensation of logical constraints, optimization of the value determination technique with previously calculated results, reuse of intermediate computations, and iterative relations for constraints. Three algorithms for computation are presented: the main algorithm, the iterative algorithm which adds only the minimal amount of necessary constraints, and the genetic algorithm which combines the iterative algorithm with basic genetic algorithms. Finally, a simple version of both algorithms was implemented, and their performance was tested, all publicly available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.10433v3</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alejandro Mata Ali, I\~nigo Perez Delgado, Beatriz Garc\'ia Markaida, Aitor Moreno Fdez. de Leceta</dc:creator>
    </item>
    <item>
      <title>End-to-End Protocol for High-Quality QAOA Parameters with Few Shots</title>
      <link>https://arxiv.org/abs/2408.00557</link>
      <description>arXiv:2408.00557v4 Announce Type: replace-cross 
Abstract: The quantum approximate optimization algorithm (QAOA) is a quantum heuristic for combinatorial optimization that has been demonstrated to scale better than state-of-the-art classical solvers for some problems. For a given problem instance, QAOA performance depends crucially on the choice of the parameters. While average-case optimal parameters are available in many cases, meaningful performance gains can be obtained by fine-tuning these parameters for a given instance. This task is especially challenging, however, when the number of circuit executions (shots) is limited. In this work, we develop an end-to-end protocol that combines multiple parameter settings and fine-tuning techniques. We use large-scale numerical experiments to optimize the protocol for the shot-limited setting and observe that optimizers with the simplest internal model (linear) perform best. We implement the optimized pipeline on a trapped-ion processor using up to 32 qubits and 5 QAOA layers, and we demonstrate that the pipeline is robust to small amounts of hardware noise. To the best of our knowledge, these are the largest demonstrations of QAOA parameter fine-tuning on a trapped-ion processor in terms of 2-qubit gate count.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.00557v4</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1103/24gg-7p8z</arxiv:DOI>
      <dc:creator>Tianyi Hao, Zichang He, Ruslan Shaydulin, Jeffrey Larson, Marco Pistoia</dc:creator>
    </item>
    <item>
      <title>GainSight: A Unified Framework for Data Lifetime Profiling and Heterogeneous Memory Composition</title>
      <link>https://arxiv.org/abs/2504.14866</link>
      <description>arXiv:2504.14866v5 Announce Type: replace-cross 
Abstract: As AI workloads drive increasing memory requirements, domain-specific accelerators need higher-density on-chip memory beyond what current SRAM scaling trends can provide. Simultaneously, the vast amounts of short-lived data in these workloads make SRAM overprovisioned in retention capability. To address this mismatch, we propose a wholesale shift from uniform SRAM arrays to heterogeneous on-chip memory, incorporating denser short-term RAM (StRAM) devices whose limited retention times align with transient data lifetimes. To facilitate this shift, we introduce GainSight, the first comprehensive, open-source framework that aligns dynamic, fine-grained workload lifetime profiles with memory device characteristics to enable generation of optimal StRAM memory compositions. GainSight combines retargetable profiling backends with an architecture-agnostic analytical frontend. The various backends capture cycle-accurate data lifetimes, while the frontend correlates workload patterns with StRAM retention properties to generate optimal memory compositions and project performance. GainSight elevates data lifetime to a first-class design consideration for next-generation AI accelerators, enabling systematic exploitation of data transience for improved on-chip memory density and efficiency. Applying GainSight to MLPerf Inference and PolyBench workloads reveals that 64.3% of first-level GPU cache accesses and 79.01% of systolic array scratchpad accesses exhibit sub-microsecond lifetimes suitable for high-density StRAM, with optimal heterogeneous on-chip memory compositions achieving up to 3x active energy and 4x area reductions compared to uniform SRAM hierarchies. To facilitate adoption and further research, GainSight is open-sourced at https://gainsight.stanford.edu/.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14866v5</guid>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peijing Li, Matthew Hung, Yiming Tan, Konstantin Ho{\ss}feld, Jake Cheng Jiajun, Shuhan Liu, Lixian Yan, Xinxin Wang, Philip Levis, H. -S. Philip Wong, Thierry Tambe</dc:creator>
    </item>
  </channel>
</rss>
