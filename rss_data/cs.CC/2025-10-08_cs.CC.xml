<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 08 Oct 2025 04:00:41 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Computational Complexity in Property Testing</title>
      <link>https://arxiv.org/abs/2510.05927</link>
      <description>arXiv:2510.05927v1 Announce Type: new 
Abstract: We initiate a systematic study of the computational complexity of property testing, focusing on the relationship between query and time complexity. While traditional work in property testing has emphasized query complexity, relatively little is known about the computational hardness of property testers. Our goal is to chart the landscape of time-query interplay and develop tools for proving time complexity lower bounds. Our first contribution is a pair of time-query hierarchy theorems for property testing. For all suitable nondecreasing functions $q(n)$ and $t(n)$ with $t(n)\geq q(n)$, we construct properties with query complexity $\tilde{\Theta}(q(n))$ and time complexity $\tilde\Omega(t(n))$. Our weak hierarchy holds unconditionally, whereas the strong version-assuming the Strong Exponential Time Hypothesis-provides better control over the time complexity of the constructed properties.
  We then turn to halfspaces in $\mathbb{R}^d$, a fundamental class in property testing and learning theory. We study the problem of approximating the distance from the input function to the nearest halfspace within additive error $\epsilon$. For the distribution-free distance approximation problem, known algorithms achieve query complexity $O(d/\epsilon^2)$, but take time $\tilde{\Theta}(1/\epsilon^d)$. We provide a fine-grained justification for this gap: assuming the $k$-SUM conjecture, any algorithm must have running time ${\Omega}(1/\epsilon^{d/2})$. This fine-grained lower bound yields a provable separation between query and time complexity for a natural and well-studied (tolerant) testing problem. We also prove that any Statistical Query (SQ) algorithm under the standard Gaussian distribution requires $(1/\epsilon)^{\Omega(d)}$ queries if the queries are answered with additive error up to $\epsilon^{\Omega(d)}$, revealing a fundamental barrier even in the distribution-specific setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05927v1</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Renato Ferreira Pinto Jr., Diptaksho Palit, Sofya Raskhodnikova</dc:creator>
    </item>
    <item>
      <title>Peaked quantum advantage using error correction</title>
      <link>https://arxiv.org/abs/2510.05262</link>
      <description>arXiv:2510.05262v1 Announce Type: cross 
Abstract: A key issue of current quantum advantage experiments is that their verification requires a full classical simulation of the ideal computation. This limits the regime in which the experiments can be verified to precisely the regime in which they are also simulatable. An important outstanding question is therefore to find quantum advantage schemes that are also classically verifiable. We make progress on this question by designing a new quantum advantage proposal--Hidden Code Sampling--whose output distribution is conditionally peaked. These peaks enable verification in far less time than it takes for full simulation. At the same time, we show that exactly sampling from the output distribution is classically hard unless the polynomial hierarchy collapses, and we propose a plausible conjecture regarding average-case hardness. Our scheme is based on ideas from quantum error correction. The required quantum computations are closely related to quantum fault-tolerant circuits and can potentially be implemented transversally. Our proposal may thus give rise to a next generation of quantum advantage experiments en route to full quantum fault tolerance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05262v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Abhinav Deshpande, Bill Fefferman, Soumik Ghosh, Michael Gullans, Dominik Hangleiter</dc:creator>
    </item>
    <item>
      <title>Fundamental Limits of Crystalline Equivariant Graph Neural Networks: A Circuit Complexity Perspective</title>
      <link>https://arxiv.org/abs/2510.05494</link>
      <description>arXiv:2510.05494v1 Announce Type: cross 
Abstract: Graph neural networks (GNNs) have become a core paradigm for learning on relational data. In materials science, equivariant GNNs (EGNNs) have emerged as a compelling backbone for crystalline-structure prediction, owing to their ability to respect Euclidean symmetries and periodic boundary conditions. Despite strong empirical performance, their expressive power in periodic, symmetry-constrained settings remains poorly understood. This work characterizes the intrinsic computational and expressive limits of EGNNs for crystalline-structure prediction through a circuit-complexity lens. We analyze the computations carried out by EGNN layers acting on node features, atomic coordinates, and lattice matrices, and prove that, under polynomial precision, embedding width $d=O(n)$ for $n$ nodes, $O(1)$ layers, and $O(1)$-depth, $O(n)$-width MLP instantiations of the message/update/readout maps, these models admit a simulation by a uniform $\mathsf{TC}^0$ threshold-circuit family of polynomial size (with an explicit constant-depth bound). Situating EGNNs within $\mathsf{TC}^0$ provides a concrete ceiling on the decision and prediction problems solvable by such architectures under realistic resource constraints and clarifies which architectural modifications (e.g., increased depth, richer geometric primitives, or wider layers) are required to transcend this regime. The analysis complements Weisfeiler-Lehman style results that do not directly transfer to periodic crystals, and offers a complexity-theoretic foundation for symmetry-aware graph learning on crystalline systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05494v1</guid>
      <category>cs.LG</category>
      <category>cs.CC</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yang Cao, Zhao Song, Jiahao Zhang, Jiale Zhao</dc:creator>
    </item>
    <item>
      <title>On the Interplay of Cube Learning and Dependency Schemes in QCDCL Proof Systems</title>
      <link>https://arxiv.org/abs/2510.05876</link>
      <description>arXiv:2510.05876v1 Announce Type: cross 
Abstract: Quantified Conflict Driven Clause Leaning (QCDCL) is one of the main approaches to solving Quantified Boolean Formulas (QBF). Cube-learning is employed in this approach to ensure that true formulas can be verified. Dependency Schemes help to detect spurious dependencies that are implied by the variable ordering in the quantifier prefix of QBFs but are not essential for constructing (counter)models. This detection can provably shorten refutations in specific proof systems, and is expected to speed up runs of QBF solvers.
  The simplest underlying proof system [BeyersdorffB\"ohm-LMCS2023], formalises the reasoning in the QCDCL approach on false formulas, when neither cube learning nor dependency schemes is used. The work of [B\"ohmPeitlBeyersdorff-AI2024] further incorporates cube-learning. The work of [ChoudhuryMahajan-JAR2024] incorporates a limited use of dependency schemes, but without cube-learning.
  In this work, proof systems underlying the reasoning of QCDCL solvers which use cube learning, and which use dependency schemes at all stages, are formalised. Sufficient conditions for soundness and completeness are presented, and it is shown that using the standard and reflexive resolution path dependency schemes ($D^{std}$ and $D^{rrs}$) to relax the decision order provably shortens refutations.
  When the decisions are restricted to follow quantification order, but dependency schemes are used in propagation and learning, in conjunction with cube-learning, the resulting proof systems using the dependency schemes $D^{std}$ and $D^{rrs}$ are investigated in detail and their relative strengths are analysed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05876v1</guid>
      <category>cs.LO</category>
      <category>cs.CC</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abhimanyu Choudhury, Meena Mahajan</dc:creator>
    </item>
    <item>
      <title>Learning stabilizer structure of quantum states</title>
      <link>https://arxiv.org/abs/2510.05890</link>
      <description>arXiv:2510.05890v1 Announce Type: cross 
Abstract: We consider the task of learning a structured stabilizer decomposition of an arbitrary $n$-qubit quantum state $|\psi\rangle$: for $\varepsilon &gt; 0$, output a state $|\phi\rangle$ with stabilizer-rank $\textsf{poly}(1/\varepsilon)$ such that $|\psi\rangle=|\phi\rangle+|\phi'\rangle$ where $|\phi'\rangle$ has stabilizer fidelity $&lt; \varepsilon$. We firstly show the existence of such decompositions using the recently established inverse theorem for the Gowers-$3$ norm of states [AD,STOC'25].
  To learn this structure, we initiate the task of self-correction of a state $|\psi\rangle$ with respect to a class of states $\textsf{C}$: given copies of $|\psi\rangle$ which has fidelity $\geq \tau$ with a state in $\textsf{C}$, output $|\phi\rangle \in \textsf{C}$ with fidelity $|\langle \phi | \psi \rangle|^2 \geq \tau^C$ for a constant $C&gt;1$. Assuming the algorithmic polynomial Frieman-Rusza (APFR) conjecture (whose combinatorial version was recently resolved [GGMT,Annals of Math.'25], we give a polynomial-time algorithm for self-correction of stabilizer states. Given access to the state preparation unitary $U_\psi$ for $|\psi\rangle$ and its controlled version $cU_\psi$, we give a polynomial-time protocol that learns a structured decomposition of $|\psi\rangle$. Without assuming APFR, we give a quasipolynomial-time protocol for the same task.
  As our main application, we give learning algorithms for states $|\psi\rangle$ promised to have stabilizer extent $\xi$, given access to $U_\psi$ and $cU_\psi$. We give a protocol that outputs $|\phi\rangle$ which is constant-close to $|\psi\rangle$ in time $\textsf{poly}(n,\xi^{\log \xi})$, which can be improved to polynomial-time assuming APFR. This gives an unconditional learning algorithm for stabilizer-rank $k$ states in time $\textsf{poly}(n,k^{k^2})$. As far as we know, learning arbitrary states with even stabilizer-rank $k \geq 2$ was unknown.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05890v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>math.CO</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Srinivasan Arunachalam, Arkopal Dutt</dc:creator>
    </item>
    <item>
      <title>Efficient Heuristics and Exact Methods for Pairwise Interaction Sampling</title>
      <link>https://arxiv.org/abs/2510.05955</link>
      <description>arXiv:2510.05955v1 Announce Type: cross 
Abstract: We consider a class of optimization problems that are fundamental to testing in modern configurable software systems, e.g., in automotive industries. In pairwise interaction sampling, we are given a (potentially very large) configuration space, in which each dimension corresponds to a possible Boolean feature of a software system; valid configurations are the satisfying assignments of a given propositional formula $\varphi$. The objective is to find a minimum-sized family of configurations, such that each pair of features is jointly tested at least once. Due to its relevance in Software Engineering, this problem has been studied extensively for over 20 years. In addition to new theoretical insights (we prove BH-hardness), we provide a broad spectrum of key contributions on the practical side that allow substantial progress for the practical performance. Remarkably, we are able to solve the largest instances we found in published benchmark sets (with about 500000000 feasible interactions) to provable optimality. Previous approaches were not even able to compute feasible solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05955v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.SE</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>S\'andor P. Fekete, Phillip Keldenich, Dominik Krupke, Michael Perk</dc:creator>
    </item>
    <item>
      <title>Symmetric Algebraic Circuits and Homomorphism Polynomials</title>
      <link>https://arxiv.org/abs/2502.06740</link>
      <description>arXiv:2502.06740v2 Announce Type: replace 
Abstract: The central open question of algebraic complexity is whether VP is unequal to VNP, which is saying that the permanent cannot be represented by families of polynomial-size algebraic circuits. For symmetric algebraic circuits, this has been confirmed by Dawar and Wilsenach (2020) who showed exponential lower bounds on the size of symmetric circuits for the permanent. In this work, we set out to develop a more general symmetric algebraic complexity theory. Our main result is that a family of symmetric polynomials admits small symmetric circuits if and only if they can be written as a linear combination of homomorphism counting polynomials of graphs of bounded treewidth. We also establish a relationship between the symmetric complexity of subgraph counting polynomials and the vertex cover number of the pattern graph. As a concrete example, we examine the symmetric complexity of immanant families (a generalisation of the determinant and permanent) and show that a known conditional dichotomy due to Curticapean (2021) holds unconditionally in the symmetric setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06740v2</guid>
      <category>cs.CC</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anuj Dawar, Benedikt Pago, Tim Seppelt</dc:creator>
    </item>
    <item>
      <title>Oracle Separations for RPH</title>
      <link>https://arxiv.org/abs/2502.09279</link>
      <description>arXiv:2502.09279v3 Announce Type: replace 
Abstract: While theoretical computer science primarily works with discrete models of computation, like the Turing machine and the wordRAM, there are many scenarios in which introducing real computation models is more adequate. We want to compare real models of computation with discrete models of computation. We do this by means of oracle separation results.
  We define the notion of a real Turing machine as an extension of the (binary) Turing machine by adding a real tape. Using those machines, we define and study the real polynomial hierarchy RPH. We are interested in RPH as the first level of the hierarchy corresponds to the well-known complexity class ER. It is known that $NP \subseteq ER \subseteq PSPACE$ and furthermore $PH \subseteq RPH \subseteq PSPACE$. We are interested to know if any of those inclusions are tight. In the absence of unconditional separations of complexity classes, we turn to oracle separation. We develop a technique that allows us to transform oracle separation results from the binary world to the real world. As applications, we show there are oracles such that:
  - $RPH^O$ proper subset of $PSPACE^O$,
  - $\Sigma_{k+1}^O$ not contained in $\Sigma_kR^O$, for all $k\geq 0$,
  - $\Sigma_kR^O$ proper subset of $\Sigma_{k+1}R^O$, for all $k\geq 0$,
  - $BQP^O$ not contained in $RPH^O$.
  Our results hint that ER is strictly contained in PSPACE and that there is a separation between the different levels of the real polynomial hierarchy. We also bound the power of real computations by showing that NP-hard problems are unlikely to be solvable using polynomial time on a realRAM. Furthermore, our oracle separations hint that polynomial-time quantum computing cannot be simulated on an efficient real Turing machine.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09279v3</guid>
      <category>cs.CC</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thekla Hamm, Lucas Meijer, Tillmann Miltzow, Subhasree Patro</dc:creator>
    </item>
    <item>
      <title>Studying homing and synchronizing sequences for Timed Finite State Machines with output delays</title>
      <link>https://arxiv.org/abs/2507.14526</link>
      <description>arXiv:2507.14526v3 Announce Type: replace-cross 
Abstract: The paper introduces final state identification (synchronizing and homing) sequences for Timed Finite State Machines (TFSMs) with output delays and investigates their properties. We formally define the notions of homing sequences (HSs) and synchronizing sequences (SSs) for these TFSMs and demonstrate that several properties that hold for untimed machines do not necessarily apply to timed ones. Furthermore, we explore the applicability of various approaches for deriving SSs and HSs for Timed FSMs with output delays, such as truncated successor tree-based and FSM abstraction-based methods. Correspondingly, we identify the subclasses of TFSMs for which these approaches can be directly applied and those for which other methods are required. Additionally, we evaluate the complexity of existence check and derivation of (shortest) HSs / SSs for TFSMs with output delays.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.14526v3</guid>
      <category>cs.FL</category>
      <category>cs.CC</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Evgenii Vinarskii, Jakub Ruszil, Adam Roman, Natalia Kushik</dc:creator>
    </item>
  </channel>
</rss>
