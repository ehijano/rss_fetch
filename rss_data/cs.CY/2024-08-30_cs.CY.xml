<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CY updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CY</link>
    <description>cs.CY updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CY" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 30 Aug 2024 04:00:43 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 30 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Verification methods for international AI agreements</title>
      <link>https://arxiv.org/abs/2408.16074</link>
      <description>arXiv:2408.16074v1 Announce Type: new 
Abstract: What techniques can be used to verify compliance with international agreements about advanced AI development? In this paper, we examine 10 verification methods that could detect two types of potential violations: unauthorized AI training (e.g., training runs above a certain FLOP threshold) and unauthorized data centers. We divide the verification methods into three categories: (a) national technical means (methods requiring minimal or no access from suspected non-compliant nations), (b) access-dependent methods (methods that require approval from the nation suspected of unauthorized activities), and (c) hardware-dependent methods (methods that require rules around advanced hardware). For each verification method, we provide a description, historical precedents, and possible evasion techniques. We conclude by offering recommendations for future work related to the verification and enforcement of international AI governance agreements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16074v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Fri, 30 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Akash R. Wasil, Tom Reed, Jack William Miller, Peter Barnett</dc:creator>
    </item>
    <item>
      <title>Life Histories of Taboo Knowledge Artifacts</title>
      <link>https://arxiv.org/abs/2408.16099</link>
      <description>arXiv:2408.16099v1 Announce Type: new 
Abstract: Communicating about some vital topics -- such as sexuality and health -- is treated as taboo and subjected to censorship. How can we construct knowledge about these topics? Wikipedia is home to numerous high-quality knowledge artifacts about taboo topics like sexual organs and human reproduction. How did these artifacts come into being? How is their existence sustained? This mixed-methods comparative project builds on previous work on taboo topics in Wikipedia and draws from qualitative and quantitative approaches. We follow a sequential complementary design, developing a narrative articulation of the life of taboo articles, comparing them to nontaboo articles, and examining some of their quantifiable traits. We find that taboo knowledge artifacts develop through multiple successful collaboration styles and, unsurprisingly, that taboo subjects are the sites of conflict. We identify and describe six themes in the development of taboo knowledge artifacts. These artifacts need &lt;i&gt;resilient leadership&lt;/i&gt; and &lt;i&gt;engaged organizations&lt;/i&gt; to thrive under conditions of &lt;i&gt;limited identifiability&lt;/i&gt; and &lt;i&gt;disjointed sensemaking&lt;/i&gt;, while contributors simultaneously engage in &lt;i&gt;emergent governance&lt;/i&gt; and &lt;i&gt;imagining public audiences&lt;/i&gt;. Our observations have important implications for supporting public knowledge work on controversial subjects such as taboos and more generally.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16099v1</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Fri, 30 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kaylea Champion, Benjamin Mako Hill</dc:creator>
    </item>
    <item>
      <title>JINet: easy and secure private data analysis for everyone</title>
      <link>https://arxiv.org/abs/2408.16402</link>
      <description>arXiv:2408.16402v1 Announce Type: new 
Abstract: JINet is a web browser-based platform intended to democratise access to advanced clinical and genomic data analysis software. It hosts numerous data analysis applications that are run in the safety of each User's web browser, without the data ever leaving their machine. JINet promotes collaboration, standardisation and reproducibility by sharing scripts rather than data and creating a self-sustaining community around it in which Users and data analysis tools developers interact thanks to JINets interoperability primitives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16402v1</guid>
      <category>cs.CY</category>
      <pubDate>Fri, 30 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Giada Lalli, James Collier, Yves Moreau, Daniele Raimondi</dc:creator>
    </item>
    <item>
      <title>Defining Interoperability: a universal standard</title>
      <link>https://arxiv.org/abs/2408.16411</link>
      <description>arXiv:2408.16411v1 Announce Type: new 
Abstract: Interoperability is crucial for modern scientific advancement, yet its fragmented definitions across domains hinder researchers' ability to effectively reap the rewards. This paper proposes a new, universal definition by tracing the evolution of interoperability and identifying challenges posed by varying definitions. This definition addresses these inconsistencies, offering a robust solution applicable across diverse fields. Adopting this unified approach will enhance global collaboration and drive innovation by removing obstacles to interoperability posed by conflicting or incomplete definitions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16411v1</guid>
      <category>cs.CY</category>
      <pubDate>Fri, 30 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Giada Lalli</dc:creator>
    </item>
    <item>
      <title>LLMs generate structurally realistic social networks but overestimate political homophily</title>
      <link>https://arxiv.org/abs/2408.16629</link>
      <description>arXiv:2408.16629v1 Announce Type: new 
Abstract: Generating social networks is essential for many applications, such as epidemic modeling and social simulations. Prior approaches either involve deep learning models, which require many observed networks for training, or stylized models, which are limited in their realism and flexibility. In contrast, LLMs offer the potential for zero-shot and flexible network generation. However, two key questions are: (1) are LLM's generated networks realistic, and (2) what are risks of bias, given the importance of demographics in forming social ties? To answer these questions, we develop three prompting methods for network generation and compare the generated networks to real social networks. We find that more realistic networks are generated with "local" methods, where the LLM constructs relations for one persona at a time, compared to "global" methods that construct the entire network at once. We also find that the generated networks match real networks on many characteristics, including density, clustering, community structure, and degree. However, we find that LLMs emphasize political homophily over all other types of homophily and overestimate political homophily relative to real-world measures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16629v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.SI</category>
      <pubDate>Fri, 30 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Serina Chang, Alicja Chaszczewicz, Emma Wang, Maya Josifovska, Emma Pierson, Jure Leskovec</dc:creator>
    </item>
    <item>
      <title>RLCP: A Reinforcement Learning-based Copyright Protection Method for Text-to-Image Diffusion Model</title>
      <link>https://arxiv.org/abs/2408.16634</link>
      <description>arXiv:2408.16634v1 Announce Type: new 
Abstract: The increasing sophistication of text-to-image generative models has led to complex challenges in defining and enforcing copyright infringement criteria and protection. Existing methods, such as watermarking and dataset deduplication, fail to provide comprehensive solutions due to the lack of standardized metrics and the inherent complexity of addressing copyright infringement in diffusion models. To deal with these challenges, we propose a Reinforcement Learning-based Copyright Protection(RLCP) method for Text-to-Image Diffusion Model, which minimizes the generation of copyright-infringing content while maintaining the quality of the model-generated dataset. Our approach begins with the introduction of a novel copyright metric grounded in copyright law and court precedents on infringement. We then utilize the Denoising Diffusion Policy Optimization (DDPO) framework to guide the model through a multi-step decision-making process, optimizing it using a reward function that incorporates our proposed copyright metric. Additionally, we employ KL divergence as a regularization term to mitigate some failure modes and stabilize RL fine-tuning. Experiments conducted on 3 mixed datasets of copyright and non-copyright images demonstrate that our approach significantly reduces copyright infringement risk while maintaining image quality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16634v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.CR</category>
      <pubDate>Fri, 30 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhuan Shi, Jing Yan, Xiaoli Tang, Lingjuan Lyu, Boi Faltings</dc:creator>
    </item>
    <item>
      <title>Fostering Creative Visualisation Skills Through Data-Art Exhibitions</title>
      <link>https://arxiv.org/abs/2408.16479</link>
      <description>arXiv:2408.16479v1 Announce Type: cross 
Abstract: Data-art exhibitions offer a unique and real-world setting to foster creative visualisation skills among students. They serve as real-world platform for students to display their work, bridging the gap between classroom learning and professional practice. Students must develop a technical solution, grasp the context, and produce work that is appropriate for public presentation. This scenario helps to encourage innovative thinking, engagement with the topic, and helps to enhance technical proficiency. We present our implementation of a data-art exhibition within a computing curriculum, for third-year degree-level students. Students create art-based visualisations from selected datasets and present their work in a public exhibition. We have used this initiative over the course of two academic years with different cohorts, and reflect on its impact on student learning and creativity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16479v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <pubDate>Fri, 30 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jonathan C. Roberts</dc:creator>
    </item>
    <item>
      <title>Uncertainty-based Fairness Measures</title>
      <link>https://arxiv.org/abs/2312.11299</link>
      <description>arXiv:2312.11299v2 Announce Type: replace-cross 
Abstract: Unfair predictions of machine learning (ML) models impede their broad acceptance in real-world settings. Tackling this arduous challenge first necessitates defining what it means for an ML model to be fair. This has been addressed by the ML community with various measures of fairness that depend on the prediction outcomes of the ML models, either at the group level or the individual level. These fairness measures are limited in that they utilize point predictions, neglecting their variances, or uncertainties, making them susceptible to noise, missingness and shifts in data. In this paper, we first show that an ML model may appear to be fair with existing point-based fairness measures but biased against a demographic group in terms of prediction uncertainties. Then, we introduce new fairness measures based on different types of uncertainties, namely, aleatoric uncertainty and epistemic uncertainty. We demonstrate on many datasets that (i) our uncertainty-based measures are complementary to existing measures of fairness, and (ii) they provide more insights about the underlying issues leading to bias.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.11299v2</guid>
      <category>cs.LG</category>
      <category>cs.CY</category>
      <category>stat.ML</category>
      <pubDate>Fri, 30 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Selim Kuzucu, Jiaee Cheong, Hatice Gunes, Sinan Kalkan</dc:creator>
    </item>
    <item>
      <title>From Data Creator to Data Reuser: Distance Matters</title>
      <link>https://arxiv.org/abs/2402.07926</link>
      <description>arXiv:2402.07926v2 Announce Type: replace-cross 
Abstract: Sharing research data is necessary, but not sufficient, for data reuse. Open science policies focus more heavily on data sharing than on reuse, yet both are complex, labor-intensive, expensive, and require infrastructure investments by multiple stakeholders. The value of data reuse lies in relationships between creators and reusers. By addressing knowledge exchange, rather than mere transactions between stakeholders, investments in data management and knowledge infrastructures can be made more wisely. Drawing upon empirical studies of data sharing and reuse, we develop the theoretical construct of distance between data creator and data reuser, identifying six distance dimensions that influence the ability to transfer knowledge effectively: domain, methods, collaboration, curation, purposes, and time and temporality. We address the social and socio-technical aspects of these dimensions, exploring ways in which they may decrease -- or increase -- distances between creators and reusers. Our theoretical framing of the distance between data creators and prospective reusers leads to recommendations to four categories of stakeholders on how to make data sharing and reuse more effective: data creators, data reusers, data archivists, and funding agencies. 'It takes a village' to share research data -- and a village to reuse data. Our aim is to provoke new research questions, new research, and new investments in effective and efficient circulation of research data; and to identify criteria for investments at each stage of data and research life cycles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.07926v2</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <category>cs.DL</category>
      <category>cs.IR</category>
      <pubDate>Fri, 30 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Christine L. Borgman, Paul T. Groth</dc:creator>
    </item>
    <item>
      <title>PsychoGAT: A Novel Psychological Measurement Paradigm through Interactive Fiction Games with LLM Agents</title>
      <link>https://arxiv.org/abs/2402.12326</link>
      <description>arXiv:2402.12326v2 Announce Type: replace-cross 
Abstract: Psychological measurement is essential for mental health, self-understanding, and personal development. Traditional methods, such as self-report scales and psychologist interviews, often face challenges with engagement and accessibility. While game-based and LLM-based tools have been explored to improve user interest and automate assessment, they struggle to balance engagement with generalizability. In this work, we propose PsychoGAT (Psychological Game AgenTs) to achieve a generic gamification of psychological assessment. The main insight is that powerful LLMs can function both as adept psychologists and innovative game designers. By incorporating LLM agents into designated roles and carefully managing their interactions, PsychoGAT can transform any standardized scales into personalized and engaging interactive fiction games. To validate the proposed method, we conduct psychometric evaluations to assess its effectiveness and employ human evaluators to examine the generated content across various psychological constructs, including depression, cognitive distortions, and personality traits. Results demonstrate that PsychoGAT serves as an effective assessment tool, achieving statistically significant excellence in psychometric metrics such as reliability, convergent validity, and discriminant validity. Moreover, human evaluations confirm PsychoGAT's enhancements in content coherence, interactivity, interest, immersion, and satisfaction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.12326v2</guid>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Fri, 30 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qisen Yang, Zekun Wang, Honghui Chen, Shenzhi Wang, Yifan Pu, Xin Gao, Wenhao Huang, Shiji Song, Gao Huang</dc:creator>
    </item>
  </channel>
</rss>
