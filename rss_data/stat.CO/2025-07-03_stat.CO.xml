<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 04 Jul 2025 04:03:05 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 04 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>DUST: A Duality-Based Pruning Method For Exact Multiple Change-Point Detection</title>
      <link>https://arxiv.org/abs/2507.02467</link>
      <description>arXiv:2507.02467v1 Announce Type: cross 
Abstract: We tackle the challenge of detecting multiple change points in large time series by optimising a penalised likelihood derived from exponential family models. While dynamic programming algorithms can solve this task exactly with at most quadratic time complexity, recent years have seen the development of pruning strategies to improve their time efficiency. However, the two existing approaches have notable limitations: PELT struggles with pruning efficiency in sparse-change scenarios, while FPOP's structure is ill-suited for multi-parametric settings. To address these issues, we introduce the DUal Simple Test (DUST) framework, which prunes candidates by evaluating a dual function against a threshold. This approach is highly flexible and broadly applicable to parametric models of any dimension. Under mild assumptions, we establish strong duality for the underlying non-convex pruning problem. We demonstrate DUST's effectiveness across various change point regimes and models. In particular, for one-parametric models, DUST matches the simplicity of PELT with the efficiency of FPOP. Its use is especially advantageous for non-Gaussian models. Its use is especially advantageous for non-Gaussian models. Finally, we apply DUST to mouse monitoring time series under a change-in-variance model, illustrating its ability to recover the optimal change point structure efficiently.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.02467v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Fri, 04 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vincent Runge, Charles Truong, Simon Quern\'e</dc:creator>
    </item>
    <item>
      <title>Non-negative matrix factorization algorithms generally improve topic model fits</title>
      <link>https://arxiv.org/abs/2105.13440</link>
      <description>arXiv:2105.13440v3 Announce Type: replace-cross 
Abstract: We report on the potential for using algorithms for non-negative matrix factorization (NMF) to improve parameter estimation in topic models. While several papers have studied connections between NMF and topic models, none have suggested leveraging these connections to develop new algorithms for fitting topic models. NMF avoids the "sum-to-one" constraints on the topic model parameters, resulting in an optimization problem with simpler structure and more efficient computations. Building on recent advances in optimization algorithms for NMF, we show that first solving the NMF problem then recovering the topic model fit can produce remarkably better fits, and in less time, than standard algorithms for topic models. While we focus primarily on maximum likelihood estimation, we show that this approach also has the potential to improve variational inference for topic models. Our methods are implemented in the R package fastTopics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2105.13440v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <pubDate>Fri, 04 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Peter Carbonetto, Abhishek Sarkar, Zihao Wang, Matthew Stephens</dc:creator>
    </item>
    <item>
      <title>Rational function approximation with normalized positive denominators</title>
      <link>https://arxiv.org/abs/2310.12053</link>
      <description>arXiv:2310.12053v4 Announce Type: replace-cross 
Abstract: Recent years have witnessed the introduction and development of extremely fast rational function algorithms. Many ideas in this realm arose from polynomial-based linear-algebraic algorithms. However, polynomial approximation is occasionally ill-suited to specific challenging tasks arising in several situations. Some occasions require maximal efficiency in the number of encoding parameters whilst retaining the renowned accuracy of polynomial-based approximation. One application comes from promoting empirical pointwise functions to sparse matrix operators. Rational function approximations provide a simple but flexible alternative (actually a superset), allowing one to capture complex non-linearities. However, these come with extra challenges: i) coping with singularities and near singularities arising from a vanishing denominator, and ii) a non-uniqueness owing to a simultaneous renormalization of both numerator and denominator.
  We, therefore, introduce a new rational function framework using manifestly positive and normalized Bernstein polynomials for the denominator and any traditional polynomial basis (e.g., Chebyshev) for the numerator. While an expressly non-singular approximation slightly reduces the maximum degree of compression, it keeps all the benefits of rational functions while maintaining the flexibility and robustness of polynomials. We illustrate the relevant aspects of this approach with a series of derivations and computational examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.12053v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>stat.CO</category>
      <pubDate>Fri, 04 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>James Chok, Geoffrey M. Vasil</dc:creator>
    </item>
    <item>
      <title>Filtrated Grouping in Multiple Functional Regression</title>
      <link>https://arxiv.org/abs/2506.11369</link>
      <description>arXiv:2506.11369v2 Announce Type: replace-cross 
Abstract: To understand and communicate the risk of chronic joint disease associated with aging, it is essential to investigate how age is associated with gait patterns, particularly through gait angular kinematics. Motivated by this need, and by the critical role of joint coordination in gait, we propose a novel covariate grouping framework within the context of multiple functional regression, where a scalar response is linked to multiple functional covariates. We apply this approach to investigate the relationship between chronological age and gait angular kinematics, aiming to uncover biomechanical patterns that signal age-related gait pattern evolution. Specifically, we develop a forest-structured covariate grouping framework in which different functional covariates are aggregated hierarchically based on the level of coefficient homogeneity. This approach allows for the analysis of both common and idiosyncratic effects of covariates in a nuanced, multi-resolution manner. The identification of the forest structure is entirely data-driven and requires no prior knowledge, providing valuable insights into the interdependence among covariates. Compared to existing methods, the proposed regression framework demonstrates superior predictive power and offers more insightful interpretability on joint coordination. In addition, the proposed framework is broadly applicable and can be readily extended to analyze multivariate functional data in other scientific domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11369v2</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Fri, 04 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuhao Jiao, Hernando Ombao, Ian W. McKeague</dc:creator>
    </item>
  </channel>
</rss>
