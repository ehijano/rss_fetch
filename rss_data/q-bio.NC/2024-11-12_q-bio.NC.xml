<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 13 Nov 2024 02:44:30 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Events in Noise-Driven Oscillators: Markov Renewal Processes and the "Unruly" Breakdown of Phase-Reduction Theory</title>
      <link>https://arxiv.org/abs/2411.05792</link>
      <description>arXiv:2411.05792v1 Announce Type: new 
Abstract: We introduce an extension to the standard reduction of oscillatory systems to a single phase variable. The standard reduction is often insufficient, particularly when the oscillations have variable amplitude and the magnitude of each oscillatory excursion plays a defining role in the impact of that oscillator on other systems, i.e. on its output. For instance, large excursions in bursting or mixed-mode neural oscillators may constitute events like action potentials, which trigger output to other neurons, while smaller, sub-threshold oscillations generate no output and therefore induce no coupling between neurons. Noise induces diffusion-like dynamics of the oscillator phase on top of its otherwise constant rate-of-change, resulting in the irregular occurrence of these output events. We model the events as corresponding to distinguished crossings of a Poincare section. Using a linearization of the noisy Poincare map and its description under phase-isostable coordinates, we determine the diffusion coefficient for the occurrence and timing of the events using Markov renewal theory. We show that for many oscillator models the corresponding point process can exhibit "unruly" diffusion: with increasing input noise strength the diffusion coefficient vastly increases compared to the standard phase reduction analysis, and, strikingly, it also decreases when the input noise strength is increased further. We provide a thorough analysis in the case of planar oscillators, which exhibit unruliness in a finite region of the natural parameter space. Our results in part explain the surprising synchronization behavior obtained in pulse-coupled, mixed-mode oscillators as they arise, e.g., in neural systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05792v1</guid>
      <category>q-bio.NC</category>
      <category>math.DS</category>
      <category>nlin.CD</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Avinash J. Karamchandani</dc:creator>
    </item>
    <item>
      <title>Review of a Heaviside step sequence function and the recursive Heaviside step sequence function for modeling human mental state</title>
      <link>https://arxiv.org/abs/2411.05800</link>
      <description>arXiv:2411.05800v1 Announce Type: new 
Abstract: In this paper, we define a novel recursive Heaviside step sequence function and demonstrate its applicability to modeling human mental states such as thought processes, memory recall, and forgetfulness. By extending the traditional Heaviside step function, which typically represents binary transitions, into a recursive sequence framework, we introduce a dynamic model that better captures the complexities of cognitive states. Furthermore, the recursive Heaviside step sequence function approximates solutions to a multidimensional inviscid advection equation, offering a unique mathematical perspective on the evolution of mental states over time. This continuous model, combined with the recursive delta sequence function, provides a comprehensive approach to exploring how memories and thoughts emerge, evolve, and fade. Through this approach, we propose that mental states can be expressed as time series functions, and the selection of the parameter N reflects individual variability in mental processing, influenced by external environments and internal experiences. We also discuss the implications of this framework for understanding human cognition and potential limitations due to modern technological constraints in replicating such processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05800v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Changsoo Shin</dc:creator>
    </item>
    <item>
      <title>Is it me, or is A larger than B: Uncovering the determinants of relational cognitive dissonance resolution</title>
      <link>https://arxiv.org/abs/2411.05809</link>
      <description>arXiv:2411.05809v1 Announce Type: new 
Abstract: This study explores the computational mechanisms underlying the resolution of cognitive dissonances. We focus on scenarios in which an observation violates the expected relationship between objects. For instance, an agent expects object A to be smaller than B in some feature space but observes the opposite. One solution is to adjust the expected relationship according to the new observation and change the expectation to A being larger than B. An alternative solution would be to adapt the representation of A and B in the feature space such that in the new representation, the relationship that A is smaller than B is maintained. While both pathways resolve the dissonance, they generalize differently to different tasks. Using Artificial Neural Networks (ANNs) capable of relational learning, we demonstrate the existence of these two pathways and show that the chosen pathway depends on the dissonance magnitude. Large dissonances alter the representation of the objects, while small dissonances lead to adjustments in the expected relationships. We show that this effect arises from the inherently different learning dynamics of relationships and representations and study the implications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05809v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tomer Barak, Yonatan Loewenstein</dc:creator>
    </item>
    <item>
      <title>Neurophysiological Analysis in Motor and Sensory Cortices for Improving Motor Imagination</title>
      <link>https://arxiv.org/abs/2411.05811</link>
      <description>arXiv:2411.05811v1 Announce Type: new 
Abstract: Brain-computer interface (BCI) enables direct communication between the brain and external devices by decoding neural signals, offering potential solutions for individuals with motor impairments. This study explores the neural signatures of motor execution (ME) and motor imagery (MI) tasks using EEG signals, focusing on four conditions categorized as sense-related (hot and cold) and motor-related (pull and push) conditions. We conducted scalp topography analysis to examine activation patterns in the sensorimotor cortex, revealing distinct regional differences: sense--related conditions primarily activated the posterior region of the sensorimotor cortex, while motor--related conditions activated the anterior region of the sensorimotor cortex. These spatial distinctions align with neurophysiological principles, suggesting condition-specific functional subdivisions within the sensorimotor cortex. We further evaluated the performances of three neural network models-EEGNet, ShallowConvNet, and DeepConvNet-demonstrating that ME tasks achieved higher classification accuracies compared to MI tasks. Specifically, in sense-related conditions, the highest accuracy was observed in the cold condition. In motor-related conditions, the pull condition showed the highest performance, with DeepConvNet yielding the highest results. These findings provide insights into optimizing BCI applications by leveraging specific condition-induced neural activations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05811v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Si-Hyun Kim, Sung-Jin Kim, Dae-Hyeok Lee</dc:creator>
    </item>
    <item>
      <title>Low-Rank + Sparse Decomposition (LR+SD) for EEG Artifact Removal</title>
      <link>https://arxiv.org/abs/2411.05812</link>
      <description>arXiv:2411.05812v1 Announce Type: new 
Abstract: Concurrent EEG-fMRI recordings are advantageous over serial recordings, as they offer the ability to explore the relationship between both signals without the compounded effects of nonstationarity in the brain. Nonetheless, analysis of simultaneous recordings is challenging given that a number of noise sources are introduced into the EEG signal even after MR gradient artifact removal with balistocardiogram artifact being highly prominent. Here, we present an algorithm for automatically removing residual noise sources from the EEG signal in a single process using low rank + sparse decomposition (LR+SD). We apply this method to both experimental and simulated EEG data, where in the latter case the true EEG signature is known. The experimental data consisted of EEG data collected concurrently with fMRI (EEG-fMRI) as well as alone outside the scanning environment while subjects viewed Gabor flashes, a perceptual task known to produce event related power diminutions in the alpha spectral band. On the simulated data, the LR+SD method was able to recover the pure EEG signal and separate it from artifact with up to three EEG sources. On the experimental data, LR+SD was able to recover the diminution in alpha spectral power that follows light flashes in concurrent EEG-fMRI data, which was not detectable prior to artifact removal. At the group level, we found that the signal-to-noise ratio was increased ~34\% following LR+SD cleaning, as compared independent component analysis (ICA) in concurrently collected EEG-fMRI data. We anticipate that this method will be highly useful for analyzing simultaneously collected EEG-fMRI data, and downstream for exploring the coupling between these two modalities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05812v1</guid>
      <category>q-bio.NC</category>
      <category>eess.SP</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:journal_reference>Proceedings of the Second International Workshop on Sparsity Techniques in Medical Imaging (STMI 2014), Boston, USA, September 2014</arxiv:journal_reference>
      <dc:creator>Jerome Gilles, Travis Meyer, Pamela K. Douglas</dc:creator>
    </item>
    <item>
      <title>SurfGNN: A robust surface-based prediction model with interpretability for coactivation maps of spatial and cortical features</title>
      <link>https://arxiv.org/abs/2411.05825</link>
      <description>arXiv:2411.05825v1 Announce Type: new 
Abstract: Current brain surface-based prediction models often overlook the variability of regional attributes at the cortical feature level. While graph neural networks (GNNs) excel at capturing regional differences, they encounter challenges when dealing with complex, high-density graph structures. In this work, we consider the cortical surface mesh as a sparse graph and propose an interpretable prediction model-Surface Graph Neural Network (SurfGNN). SurfGNN employs topology-sampling learning (TSL) and region-specific learning (RSL) structures to manage individual cortical features at both lower and higher scales of the surface mesh, effectively tackling the challenges posed by the overly abundant mesh nodes and addressing the issue of heterogeneity in cortical regions. Building on this, a novel score-weighted fusion (SWF) method is implemented to merge nodal representations associated with each cortical feature for prediction. We apply our model to a neonatal brain age prediction task using a dataset of harmonized MR images from 481 subjects (503 scans). SurfGNN outperforms all existing state-of-the-art methods, demonstrating an improvement of at least 9.0% and achieving a mean absolute error (MAE) of 0.827+0.056 in postmenstrual weeks. Furthermore, it generates feature-level activation maps, indicating its capability to identify robust regional variations in different morphometric contributions for prediction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05825v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhuoshuo Li (Department of Biomedical Engineering, Sun Yat-sen University, Shenzhen, China), Jiong Zhang (Institute of Biomedical Engineering, Ningbo Institute of Materials Technology and Engineering, Chinese Academy of Sciences, Ningbo, China), Youbing Zeng (Department of Biomedical Engineering, Sun Yat-sen University, Shenzhen, China), Jiaying Lin (Department of Biomedical Engineering, Sun Yat-sen University, Shenzhen, China), Dan Zhang (School of Cyber Science and Engineering, Ningbo University of Technology, Ningbo, China), Jianjia Zhang (Department of Biomedical Engineering, Sun Yat-sen University, Shenzhen, China), Duan Xu (Department of Radiology, School of Medicine, University of California San Francisco, San Francisco, CA, USA), Hosung Kim (USC Mark and Mary Stevens Neuroimaging and Informatics Institute, Keck School of Medicine of USC, University of Southern California, Los Angeles, CA, USA), Bingguang Liu (Department of Radiology, Shenzhen Maternity and Child Healthcare Hospital, Shenzhen, China), Mengting Liu (Department of Biomedical Engineering, Sun Yat-sen University, Shenzhen, China)</dc:creator>
    </item>
    <item>
      <title>Input-Driven Dynamics for Robust Memory Retrieval in Hopfield Networks</title>
      <link>https://arxiv.org/abs/2411.05849</link>
      <description>arXiv:2411.05849v1 Announce Type: new 
Abstract: The Hopfield model provides a mathematically idealized yet insightful framework for understanding the mechanisms of memory storage and retrieval in the human brain. This model has inspired four decades of extensive research on learning and retrieval dynamics, capacity estimates, and sequential transitions among memories. Notably, the role and impact of external inputs has been largely underexplored, from their effects on neural dynamics to how they facilitate effective memory retrieval. To bridge this gap, we propose a novel dynamical system framework in which the external input directly influences the neural synapses and shapes the energy landscape of the Hopfield model. This plasticity-based mechanism provides a clear energetic interpretation of the memory retrieval process and proves effective at correctly classifying highly mixed inputs. Furthermore, we integrate this model within the framework of modern Hopfield architectures, using this connection to elucidate how current and past information are combined during the retrieval process. Finally, we embed both the classic and the new model in an environment disrupted by noise and compare their robustness during memory retrieval.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05849v1</guid>
      <category>q-bio.NC</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.DS</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Simone Betteti, Giacomo Baggio, Francesco Bullo, Sandro Zampieri</dc:creator>
    </item>
    <item>
      <title>From Electrode to Global Brain: Integrating Multi- and Cross-Scale Brain Connections and Interactions Under Cross-Subject and Within-Subject Scenarios</title>
      <link>https://arxiv.org/abs/2411.05862</link>
      <description>arXiv:2411.05862v1 Announce Type: new 
Abstract: The individual variabilities of electroencephalogram signals pose great challenges to cross-subject motor imagery (MI) classification, especially for the data-scarce single-source to single-target (STS) scenario. The multi-scale spatial data distribution differences can not be fully eliminated in MI experiments for the topological structure and connection are the inherent properties of the human brain. Overall, no literature investigates the multi-scale spatial data distribution problem in STS cross-subject MI classification task, neither intra-subject nor inter-subject scenarios. In this paper, a novel multi-scale spatial domain adaptation network (MSSDAN) consists of both multi-scale spatial feature extractor (MSSFE) and deep domain adaptation method called multi-scale spatial domain adaptation (MSSDA) is proposed and verified, our goal is to integrate the principles of multi-scale brain topological structures in order to solve the multi-scale spatial data distribution difference problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05862v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chen Zhige, Qin Chengxuan</dc:creator>
    </item>
    <item>
      <title>Expansion microscopy reveals neural circuit organization in genetic animal models</title>
      <link>https://arxiv.org/abs/2411.06676</link>
      <description>arXiv:2411.06676v1 Announce Type: new 
Abstract: Expansion Microscopy is a super-resolution technique in which physically enlarging samples in an isotropic manner increases inter-molecular distances such that nano-scale structures can be resolved using light microscopy. This is particularly useful in neuroscience as many important structures are smaller than the diffraction limit. Since its invention in 2015, a variety of Expansion Microscopy protocols have been generated and applied to advance knowledge in many prominent organisms in neuroscience, including zebrafish, mice, Drosophila, and C. elegans. Here we review the last decade of Expansion Microscopy-enabled advances with a focus on neuroscience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.06676v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Shakila Behzadi (New Jersey Institute of Technology), Jacquelin Ho (Albert Einstein College of Medicine), Zainab Tanvir (Rutgers University), Gal Haspel (New Jersey Institute of Technology), Limor Freifeld (Technion), Kristen E. Severi (New Jersey Institute of Technology)</dc:creator>
    </item>
    <item>
      <title>Identifying the impact of local connectivity patterns on dynamics in excitatory-inhibitory networks</title>
      <link>https://arxiv.org/abs/2411.06802</link>
      <description>arXiv:2411.06802v1 Announce Type: new 
Abstract: Networks of excitatory and inhibitory (EI) neurons form a canonical circuit in the brain. Seminal theoretical results on dynamics of such networks are based on the assumption that synaptic strengths depend on the type of neurons they connect, but are otherwise statistically independent. Recent synaptic physiology datasets however highlight the prominence of specific connectivity patterns that go well beyond what is expected from independent connections. While decades of influential research have demonstrated the strong role of the basic EI cell type structure, to which extent additional connectivity features influence dynamics remains to be fully determined. Here we examine the effects of pairwise connectivity motifs on the linear dynamics in EI networks using an analytical framework that approximates the connectivity in terms of low-rank structures. This low-rank approximation is based on a mathematical derivation of the dominant eigenvalues of the connectivity matrix and predicts the impact on responses to external inputs of connectivity motifs and their interactions with cell-type structure. Our results reveal that a particular pattern of connectivity, chain motifs, have a much stronger impact on dominant eigenmodes than other pairwise motifs. An overrepresentation of chain motifs induces a strong positive eigenvalue in inhibition-dominated networks and generates a potential instability that requires revisiting the classical excitation-inhibition balance criteria. Examining effects of external inputs, we show that chain motifs can on their own induce paradoxical responses where an increased input to inhibitory neurons leads to a decrease in their activity due to the recurrent feedback. These findings have direct implications for the interpretation of experiments in which responses to optogenetic perturbations are measured and used to infer the dynamical regime of cortical circuits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.06802v1</guid>
      <category>q-bio.NC</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.NE</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yuxiu Shao (School of Systems Science, Beijing Normal University, Beijing, China, Laboratoire de Neurosciences Cognitives et Computationnelles, INSERM U960, Ecole Normale Superieure - PSL Research University, Paris, France), David Dahmen (Institute for Advanced Simulation), Stefano Recanatesi (Technion, Israel Institute of Technology, Haifa, Israel), Eric Shea-Brown (Department of Applied Mathematics and Computational Neuroscience Center, University of Washington, Seattle, WA, USA, Allen Institute for Brain Science, Seattle, WA, USA), Srdjan Ostojic (Laboratoire de Neurosciences Cognitives et Computationnelles, INSERM U960, Ecole Normale Superieure - PSL Research University, Paris, France)</dc:creator>
    </item>
    <item>
      <title>Evaluating tDCS Intervention Effectiveness via Functional Connectivity Network on Resting-State EEG Data in Major Depressive Disorder</title>
      <link>https://arxiv.org/abs/2411.06359</link>
      <description>arXiv:2411.06359v1 Announce Type: cross 
Abstract: Transcranial direct current stimulation (tDCS) has emerged as a promising non-invasive therapeutic intervention for major depressive disorder (MDD), yet its effects on neural mechanisms remain incompletely understood. This study investigates the impact of tDCS in individuals with MDD using resting-state EEG data and network neuroscience to analyze functional connectivity. We examined power spectral density (PSD) changes and functional connectivity (FC) patterns across theta, alpha, and beta bands before and after tDCS intervention. A notable aspect of this research involves the modification of the binarizing threshold algorithm to assess functional connectivity networks, facilitating a meaningful comparison at the group level. Our analysis using optimal threshold binarization techniques revealed significant modifications in network topology, particularly evident in the beta band, indicative of reduced randomization or enhanced small-worldness after tDCS. Furthermore, the hubness analysis identified specific brain regions, notably the dorsolateral prefrontal cortex (DLPFC) regions across all frequency bands, exhibiting increased functional connectivity, suggesting their involvement in the antidepressant effects of tDCS. Notably, tDCS intervention transformed the dispersed high connectivity into localized connectivity and increased left-sided asymmetry across all frequency bands. Overall, this study provides valuable insights into the effects of tDCS on neural mechanisms in MDD, offering a potential direction for further research and therapeutic development in the field of neuromodulation for mental health disorders.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.06359v1</guid>
      <category>q-bio.QM</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vishwani Singh, Rohit Verma, Shaurya Shriyam, Tapan K. Gandhi</dc:creator>
    </item>
    <item>
      <title>Psycho Gundam: Electroencephalography based real-time robotic control system with deep learning</title>
      <link>https://arxiv.org/abs/2411.06414</link>
      <description>arXiv:2411.06414v1 Announce Type: cross 
Abstract: The Psycho Frame, a sophisticated system primarily used in Universal Century (U.C.) series mobile suits for NEWTYPE pilots, has evolved as an integral component in harnessing the latent potential of mental energy. Its ability to amplify and resonate with the pilot's psyche enables real-time mental control, creating unique applications such as psychomagnetic fields and sensory-based weaponry. This paper presents the development of a novel robotic control system inspired by the Psycho Frame, combining electroencephalography (EEG) and deep learning for real-time control of robotic systems. By capturing and interpreting brainwave data through EEG, the system extends human cognitive commands to robotic actions, reflecting the seamless synchronization of thought and machine, much like the Psyco Frame's integration with a Newtype pilot's mental faculties. This research demonstrates how modern AI techniques can expand the limits of human-machine interaction, potentially transcending traditional input methods and enabling a deeper, more intuitive control of complex robotic systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.06414v1</guid>
      <category>cs.RO</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chi-Sheng Chen, Wei-Sheng Wang</dc:creator>
    </item>
    <item>
      <title>SequentialSamplingModels.jl: Simulating and Evaluating Cognitive Models of Response Times in Julia</title>
      <link>https://arxiv.org/abs/2411.06631</link>
      <description>arXiv:2411.06631v1 Announce Type: cross 
Abstract: Sequential sampling models (SSMs) are a widely used framework describing decision-making as a stochastic, dynamic process of evidence accumulation. SSMs popularity across cognitive science has driven the development of various software packages that lower the barrier for simulating, estimating, and comparing existing SSMs. Here, we present a software tool, SequentialSamplingModels.jl (SSM.jl), designed to make SSM simulations more accessible to Julia users, and to integrate with the Julia ecosystem. We demonstrate the basic use of SSM.jl for simulation, plotting, and Bayesian inference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.06631v1</guid>
      <category>cs.MS</category>
      <category>q-bio.NC</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Kiant\'e Fernandez, Dominique Makowski, Christopher Fisher</dc:creator>
    </item>
    <item>
      <title>Estimating the contribution of early and late noise in vision from psychophysical data</title>
      <link>https://arxiv.org/abs/2012.06608</link>
      <description>arXiv:2012.06608v3 Announce Type: replace 
Abstract: In many psychophysical detection and discrimination tasks human performance is thought to be limited by internal or inner noise when neuronal activity is converted into an overt behavioural response. It is unclear, however, to what extent the behaviourally limiting inner noise arises from early noise in the photoreceptors and the retina, or from late noise in cortex at or immediately prior to the decision stage. Presumably, the behaviourally limiting inner noise is a non-trivial combination of both early and late noises. Here we propose a method to quantify the contributions of early and late noise purely from psychophysical data. Our analysis generalizes classical results for linear systems (Burgess and Colborne, 1988) by combining the theory of noise propagation through a nonlinear network (Ahumada, 1987) with the expressions to obtain the perceptual metric along the nonlinear network (Malo and Simoncelli, 2006; Laparra et al., 2010). We show that from threshold-only data the relative contribution of early and late noise can only be determined if the experiments include substantial external noise in some of the stimuli used during experiments. If experimenters collected full psychometric functions, however, then early and late noise sources can be quantified even in the absence of external noise. Our psychophysical estimate of the magnitude of the early noise assuming a standard cascade of linear and nonlinear model stages is substantially lower than the noise in cone photocurrents computed via an accurate model of retinal physiology (Brainard and Wandell, 2020, ISETBIO). This is consistent with the idea that one of the fundamental tasks of early vision is to reduce the comparatively large retinal noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2012.06608v3</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jesus Malo, Jose Juan Esteve-Taboada, Guillermo Aguilar, Marianne Maertens, Felix A. Wichmann</dc:creator>
    </item>
    <item>
      <title>Brain memory working. Optimal control behavior for improved Hopfield-like models</title>
      <link>https://arxiv.org/abs/2305.14360</link>
      <description>arXiv:2305.14360v4 Announce Type: replace 
Abstract: Recent works have highlighted the need for a new dynamical paradigm in the modeling of brain function and evolution. Specifically, these models should incorporate non-constant and asymmetric synaptic weights \(T_{ij}\) in the neuron-neuron interaction matrix, moving beyond the classical Hopfield framework. Krotov and Hopfield proposed a non-constant yet symmetric model, resulting in a vector field that describes gradient-type dynamics, which includes a Lyapunov-like energy function. Firstly, we will outline the general conditions for generating a Hopfield-like vector field of gradient type, recovering the Krotov-Hopfield condition as a particular case. Secondly, we address the issue of symmetry, which we abandon for two key physiological reasons: (1) actual neural connections have a distinctly directional character (axons and dendrites), and (2) the gradient structure derived from symmetry forces the dynamics towards stationary points, leading to the recognition of every pattern. We propose a novel model that incorporates a set of limited but variable controls \(|\xi_{ij}|\leq K\), which are used to adjust an initially constant interaction matrix, \(T_{ij}=A_{ij}+\xi_{ij}\). Additionally, we introduce a reasonable controlled variational functional for optimization. This allows us to simulate three potential outcomes when a pattern is submitted to the learning system: (1) if the dynamics converges to an existing stationary point without activating controls, the system has \emph{recognized} an existing pattern; (2) if a new stationary point is reached through control activation, the system has \emph{learned} a new pattern; and (3) if the dynamics \emph{wanders} without reaching any stationary point, the system is unable to recognize or learn the submitted pattern. An additional feature (4) models the processes of \emph{forgetting and restoring} memory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.14360v4</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Franco Cardin, Alberto Lovison, Amos Maritan, Aram Megighian</dc:creator>
    </item>
    <item>
      <title>Enhancing learning in spiking neural networks through neuronal heterogeneity and neuromodulatory signaling</title>
      <link>https://arxiv.org/abs/2407.04525</link>
      <description>arXiv:2407.04525v4 Announce Type: replace 
Abstract: Recent progress in artificial intelligence (AI) has been driven by insights from neuroscience, particularly with the development of artificial neural networks (ANNs). This has significantly enhanced the replication of complex cognitive tasks such as vision and natural language processing. Despite these advances, ANNs struggle with continual learning, adaptable knowledge transfer, robustness, and resource efficiency - capabilities that biological systems handle seamlessly. Specifically, ANNs often overlook the functional and morphological diversity of the brain, hindering their computational capabilities. Furthermore, incorporating cell-type specific neuromodulatory effects into ANNs with neuronal heterogeneity could enable learning at two spatial scales: spiking behavior at the neuronal level, and synaptic plasticity at the circuit level, thereby potentially enhancing their learning abilities. In this article, we summarize recent bio-inspired models, learning rules and architectures and propose a biologically-informed framework for enhancing ANNs. Our proposed dual-framework approach highlights the potential of spiking neural networks (SNNs) for emulating diverse spiking behaviors and dendritic compartments to simulate morphological and functional diversity of neuronal computations. Finally, we outline how the proposed approach integrates brain-inspired compartmental models and task-driven SNNs, balances bioinspiration and complexity, and provides scalable solutions for pressing AI challenges, such as continual learning, adaptability, robustness, and resource-efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04525v4</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alejandro Rodriguez-Garcia, Jie Mei, Srikanth Ramaswamy</dc:creator>
    </item>
    <item>
      <title>Relationships between the degrees of freedom in the affine Gaussian derivative model for visual receptive fields and 2-D affine image transformations, with application to covariance properties of simple cells in the primary visual cortex</title>
      <link>https://arxiv.org/abs/2411.05673</link>
      <description>arXiv:2411.05673v2 Announce Type: replace 
Abstract: When observing the surface patterns of objects delimited by smooth surfaces, the projections of the surface patterns to the image domain will be subject to substantial variabilities, as induced by variabilities in the geometric viewing conditions, and as generated by either monocular or binocular imaging conditions, or by relative motions between the object and the observer over time. To first order of approximation, the image deformations of such projected surface patterns can be modelled as local linearizations in terms of local 2-D spatial affine transformations.
  This paper presents a theoretical analysis of relationships between the degrees of freedom in 2-D spatial affine image transformations and the degrees of freedom in the affine Gaussian derivative model for visual receptive fields. For this purpose, we first describe a canonical decomposition of 2-D affine transformations on a product form, closely related to a singular value decomposition, while in closed form, and which reveals the degrees of freedom in terms of (i) uniform scaling transformations, (ii) an overall amount of global rotation, (iii) a complementary non-uniform scaling transformation and (iv) a relative normalization to a preferred symmetry orientation in the image domain. Then, we show how these degrees of freedom relate to the degrees of freedom in the affine Gaussian derivative model.
  Finally, we use these theoretical results to consider whether we could regard the biological receptive fields in the primary visual cortex of higher mammals as being able to span the degrees of freedom of 2-D spatial affine transformations, based on interpretations of existing neurophysiological experimental results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05673v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tony Lindeberg</dc:creator>
    </item>
    <item>
      <title>Disentangling Hippocampal Shape Variations: A Study of Neurological Disorders Using Mesh Variational Autoencoder with Contrastive Learning</title>
      <link>https://arxiv.org/abs/2404.00785</link>
      <description>arXiv:2404.00785v3 Announce Type: replace-cross 
Abstract: This paper presents a comprehensive study focused on disentangling hippocampal shape variations from diffusion tensor imaging (DTI) datasets within the context of neurological disorders. Leveraging a Mesh Variational Autoencoder (VAE) enhanced with Supervised Contrastive Learning, our approach aims to improve interpretability by disentangling two distinct latent variables corresponding to age and the presence of diseases. In our ablation study, we investigate a range of VAE architectures and contrastive loss functions, showcasing the enhanced disentanglement capabilities of our approach. This evaluation uses synthetic 3D torus mesh data and real 3D hippocampal mesh datasets derived from the DTI hippocampal dataset. Our supervised disentanglement model outperforms several state-of-the-art (SOTA) methods like attribute and guided VAEs in terms of disentanglement scores. Our model distinguishes between age groups and disease status in patients with Multiple Sclerosis (MS) using the hippocampus data. Our Mesh VAE with Supervised Contrastive Learning shows the volume changes of the hippocampus of MS populations at different ages, and the result is consistent with the current neuroimaging literature. This research provides valuable insights into the relationship between neurological disorder and hippocampal shape changes in different age groups of MS populations using a Mesh VAE with Supervised Contrastive loss. Our code is available at https://github.com/Jakaria08/Explaining_Shape_Variability</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00785v3</guid>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.59275/j.melba.2024-267f</arxiv:DOI>
      <arxiv:journal_reference>Machine.Learning.for.Biomedical.Imaging. 2 (2024)</arxiv:journal_reference>
      <dc:creator>Jakaria Rabbi, Johannes Kiechle, Christian Beaulieu, Nilanjan Ray, Dana Cobzas</dc:creator>
    </item>
  </channel>
</rss>
