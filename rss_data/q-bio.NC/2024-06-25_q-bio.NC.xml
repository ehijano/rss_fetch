<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 26 Jun 2024 01:48:23 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 25 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Orangutan: A Multiscale Brain Emulation-Based Artificial Intelligence Framework for Dynamic Environments</title>
      <link>https://arxiv.org/abs/2406.15488</link>
      <description>arXiv:2406.15488v1 Announce Type: new 
Abstract: Achieving General Artificial Intelligence (AGI) has long been a grand challenge in the field of AI, and brain-inspired computing is widely acknowledged as one of the most promising approaches to realize this goal. This paper introduces a novel brain-inspired AI framework, Orangutan. It simulates the structure and computational mechanisms of biological brains on multiple scales, encompassing multi-compartment neuron architectures, diverse synaptic connection modalities, neural microcircuits, cortical columns, and brain regions, as well as biochemical processes including facilitation, feedforward inhibition, short-term potentiation, and short-term depression, all grounded in solid neuroscience. Building upon these highly integrated brain-like mechanisms, I have developed a sensorimotor model that simulates human saccadic eye movements during object observation. The model's algorithmic efficacy was validated through testing with the observation of handwritten digit images.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15488v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yong Xie</dc:creator>
    </item>
    <item>
      <title>R&amp;B -- Rhythm and Brain: Cross-subject Decoding of Music from Human Brain Activity</title>
      <link>https://arxiv.org/abs/2406.15537</link>
      <description>arXiv:2406.15537v1 Announce Type: new 
Abstract: Music is a universal phenomenon that profoundly influences human experiences across cultures. This study investigates whether music can be decoded from human brain activity measured with functional MRI (fMRI) during its perception. Leveraging recent advancements in extensive datasets and pre-trained computational models, we construct mappings between neural data and latent representations of musical stimuli. Our approach integrates functional and anatomical alignment techniques to facilitate cross-subject decoding, addressing the challenges posed by the low temporal resolution and signal-to-noise ratio (SNR) in fMRI data. Starting from the GTZan fMRI dataset, where five participants listened to 540 musical stimuli from 10 different genres while their brain activity was recorded, we used the CLAP (Contrastive Language-Audio Pretraining) model to extract latent representations of the musical stimuli and developed voxel-wise encoding models to identify brain regions responsive to these stimuli. By applying a threshold to the association between predicted and actual brain activity, we identified specific regions of interest (ROIs) which can be interpreted as key players in music processing. Our decoding pipeline, primarily retrieval-based, employs a linear map to project brain activity to the corresponding CLAP features. This enables us to predict and retrieve the musical stimuli most similar to those that originated the fMRI data. Our results demonstrate state-of-the-art identification accuracy, with our methods significantly outperforming existing approaches. Our findings suggest that neural-based music retrieval systems could enable personalized recommendations and therapeutic applications. Future work could use higher temporal resolution neuroimaging and generative models to improve decoding accuracy and explore the neural underpinnings of music perception and emotion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15537v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.SD</category>
      <category>eess.AS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matteo Ferrante, Matteo Ciferri, Nicola Toschi</dc:creator>
    </item>
    <item>
      <title>Brain states analysis of EEG data distinguishes Multiple Sclerosis</title>
      <link>https://arxiv.org/abs/2406.15665</link>
      <description>arXiv:2406.15665v1 Announce Type: new 
Abstract: Background: The treatment of multiple sclerosis implies, beside protecting the body, the preserving of mental functions, considering how adverse cognitive decay affects quality of life. However a cognitive assessment is nowadays still realized with neuro-psychological tests without monitoring cognition on objective neurobiological grounds whereas the ongoing neural activity is in fact readily observable and readable.
  Objective: The proposed method deciphers electrical brain states which as multi-dimensional cognetoms discriminate quantitatively normal from pathological patterns in the EEG signal.
  Methods: Baseline recordings from a prior EEG study of 93 subjects, 37 with MS, were analyzed. Spectral bands served to compute cognetoms and categorize subsequent feature combination sets.
  Results: Using cognetoms and spectral bands, a cross-sectional comparison separated patients from controls with a precision of 82\% while using bands alone arrived at 64\%. A few feature combinations were identified to drive this distinction.
  Conclusions: Brain states analysis distinguishes successfully controls from patients with MS. Our results imply that this data-driven cross-sectional comparison of EEG data may complement customary diagnostic methods in neurology and psychiatry. However, thinking ahead in terms of quantitative monitoring of disease time course and treatment efficacy, we hope having established the analytic principles applicable to longitudinal clinical studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15665v1</guid>
      <category>q-bio.NC</category>
      <category>q-bio.QM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Istv\'an M\'orocz (McGill University Montreal QC Canada, Noisis Inc. Montreal QC Canada), Mojtaba Jouzizadeh (University of Ottawa Canada), Amir H. Ghaderi (University of Calgary Canada), Hamed Cheraghmakani (Mazandaran University of Medical Sciences Sari Iran), Seyed M. Baghbanian (Mazandaran University of Medical Sciences Sari Iran), Reza Khanbabaie (University of British Columbia Kelowna BC Canada), Andrei Mogoutov (Noisis Inc. Montreal QC Canada)</dc:creator>
    </item>
    <item>
      <title>Learning in Wilson-Cowan model for metapopulation</title>
      <link>https://arxiv.org/abs/2406.16453</link>
      <description>arXiv:2406.16453v1 Announce Type: new 
Abstract: The Wilson-Cowan model for metapopulation, a Neural Mass Network Model, treats different subcortical regions of the brain as connected nodes, with connections representing various types of structural, functional, or effective neuronal connectivity between these regions. Each region comprises interacting populations of excitatory and inhibitory cells, consistent with the standard Wilson-Cowan model. By incorporating stable attractors into such a metapopulation model's dynamics, we transform it into a learning algorithm capable of achieving high image and text classification accuracy. We test it on MNIST and Fashion MNIST, in combination with convolutional neural networks, on CIFAR-10 and TF-FLOWERS, and, in combination with a transformer architecture (BERT), on IMDB, always showing high classification accuracy. These numerical evaluations illustrate that minimal modifications to the Wilson-Cowan model for metapopulation can reveal unique and previously unobserved dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16453v1</guid>
      <category>q-bio.NC</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Raffaele Marino, Lorenzo Buffoni, Lorenzo Chicchi, Francesca Di Patti, Diego Febbe, Lorenzo Giambagli, Duccio Fanelli</dc:creator>
    </item>
    <item>
      <title>Explicit Retinal Networks Produce Center-Surround Opponent Color Cells</title>
      <link>https://arxiv.org/abs/2406.16788</link>
      <description>arXiv:2406.16788v1 Announce Type: new 
Abstract: Previous articles proposed an explicit retinal logic circuit that can generate neural correlates of phenomena central to color vision. Here it is shown that this network can be divided into its component parts and slightly modified to produce center-surround phenomena.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16788v1</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Lane Yoder</dc:creator>
    </item>
    <item>
      <title>How Does Culture Evolve?</title>
      <link>https://arxiv.org/abs/2406.15464</link>
      <description>arXiv:2406.15464v1 Announce Type: cross 
Abstract: This chapter synthesizes evidence from cognitive science, evolutionary theory, anthropology, psychological studies, and computational models for a complex systems inspired theory of creativity, and its role in cultural evolution. Creativity is guided by the global shape of one's integrated network of memories, concepts, and beliefs: one's worldview. This integrated structure and its dynamical change over time are described using autocatalytic networks. Autocatalytic networks can interact with each other, and they can grow and evolve; through interactions between their components, they generate novel components. Thus, they are used to describe cultural change both within and between individuals, as well as across cultural lineages. The chapter outlines autocatalytic network models of the origin of culture, the cognitive developmental process by which each child becomes a participant in cultural evolution, and the role of imitation, leadership, and social media on cultural evolution, as well as the trade-off between creativity and continuity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15464v1</guid>
      <category>physics.soc-ph</category>
      <category>q-bio.NC</category>
      <category>q-bio.PE</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>2024. Chapter in: M. Gelfand, C. Chiu &amp; Y. Hong (Eds.) 10th Volume of the Annual Series on Advances in Culture and Psychology. New York: Oxford University Press</arxiv:journal_reference>
      <dc:creator>Liane Gabora</dc:creator>
    </item>
    <item>
      <title>Integral Betti signature confirms the hyperbolic geometry of brain, climate, and financial networks</title>
      <link>https://arxiv.org/abs/2406.15505</link>
      <description>arXiv:2406.15505v1 Announce Type: cross 
Abstract: This paper extends the possibility to examine the underlying curvature of data through the lens of topology by using the Betti curves, tools of Persistent Homology, as key topological descriptors, building on the clique topology approach. It was previously shown that Betti curves distinguish random from Euclidean geometric matrices - i.e. distance matrices of points randomly distributed in a cube with Euclidean distance. In line with previous experiments, we consider their low-dimensional approximations named integral Betti values, or signatures that effectively distinguish not only Euclidean, but also spherical and hyperbolic geometric matrices, both from purely random matrices as well as among themselves. To prove this, we analyse the behaviour of Betti curves for various geometric matrices -- i.e. distance matrices of points randomly distributed on manifolds of constant sectional curvature, considering the classical models of curvature 0, 1, -1, given by the Euclidean space, the sphere, and the hyperbolic space. We further investigate the dependence of integral Betti signatures on factors including the sample size and dimension. This is important for assessment of real-world connectivity matrices, as we show that the standard approach to network construction gives rise to (spurious) spherical geometry, with topology dependent on sample dimensions. Finally, we use the manifolds of constant curvature as comparison models to infer curvature underlying real-world datasets coming from neuroscience, finance and climate. Their associated topological features exhibit a hyperbolic character: the integral Betti signatures associated to these datasets sit in between Euclidean and hyperbolic (of small curvature). The potential confounding ``hyperbologenic effect'' of intrinsic low-rank modular structures is also evaluated through simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15505v1</guid>
      <category>math.AT</category>
      <category>physics.data-an</category>
      <category>q-bio.NC</category>
      <category>q-fin.CP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luigi Caputi, Anna Pidnebesna, Jaroslav Hlinka</dc:creator>
    </item>
    <item>
      <title>A Digital Human Model for Symptom Progression of Vestibular Motion Sickness based on Subjective Vertical Conflict Theory</title>
      <link>https://arxiv.org/abs/2406.16737</link>
      <description>arXiv:2406.16737v1 Announce Type: cross 
Abstract: Digital human models of motion sickness have been actively developed, among which models based on subjective vertical conflict (SVC) theory are the most actively studied. These models facilitate the prediction of motion sickness in various scenarios such as riding in a car. Most SVC theory models predict the motion sickness incidence (MSI), which is defined as the percentage of people who would vomit with the given specific motion stimulus. However, no model has been developed to describe milder forms of discomfort or specific symptoms of motion sickness, even though predicting milder symptoms is important for applications in automobiles and daily use vehicles. Therefore, the purpose of this study was to build a computational model of symptom progression of vestibular motion sickness based on SVC theory. We focused on a model of vestibular motion sickness with six degrees-of-freedom (6DoF) head motions. The model was developed by updating the output part of the state-of-the-art SVC model, termed the 6DoF-SVC (IN1) model, from MSI to the MIsery SCale (MISC), which is a subjective rating scale for symptom progression. We conducted an experiment to measure the progression of motion sickness during a straight fore-aft motion. It was demonstrated that our proposed method, with the parameters of the output parts optimized by the experimental results, fits well with the observed MISC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16737v1</guid>
      <category>cs.HC</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shota Inoue, Hailong Liu, Takahiro Wada</dc:creator>
    </item>
    <item>
      <title>Inferring stochastic low-rank recurrent neural networks from neural data</title>
      <link>https://arxiv.org/abs/2406.16749</link>
      <description>arXiv:2406.16749v1 Announce Type: cross 
Abstract: A central aim in computational neuroscience is to relate the activity of large populations of neurons to an underlying dynamical system. Models of these neural dynamics should ideally be both interpretable and fit the observed data well. Low-rank recurrent neural networks (RNNs) exhibit such interpretability by having tractable dynamics. However, it is unclear how to best fit low-rank RNNs to data consisting of noisy observations of an underlying stochastic system. Here, we propose to fit stochastic low-rank RNNs with variational sequential Monte Carlo methods. We validate our method on several datasets consisting of both continuous and spiking neural data, where we obtain lower dimensional latent dynamics than current state of the art methods. Additionally, for low-rank models with piecewise linear nonlinearities, we show how to efficiently identify all fixed points in polynomial rather than exponential cost in the number of units, making analysis of the inferred dynamics tractable for large RNNs. Our method both elucidates the dynamical systems underlying experimental recordings and provides a generative model whose trajectories match observed trial-to-trial variability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16749v1</guid>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthijs Pals, A Erdem Sa\u{g}tekin, Felix Pei, Manuel Gloeckler, Jakob H Macke</dc:creator>
    </item>
    <item>
      <title>Walks with jumps: a neurobiologically motivated class of paths in the hyperbolic plane</title>
      <link>https://arxiv.org/abs/2406.16765</link>
      <description>arXiv:2406.16765v1 Announce Type: cross 
Abstract: We introduce the notion of a "walk with jumps", which we conceive as an evolving process in which a point moves in a space (for us, typically $\mathbb{H}^2$) over time, in a consistent direction and at a consistent speed except that it is interrupted by a finite set of "jumps" in a fixed direction and distance from the walk direction. Our motivation is biological; specifically, to use walks with jumps to encode the activity of a neuron over time (a ``spike train``). Because (in $\mathbb{H}^2$) the walk is built out of a sequence of transformations that do not commute, the walk's endpoint encodes aspects of the sequence of jump times beyond their total number, but does so incompletely. The main results of the paper use the tools of hyperbolic geometry to give positive and negative answers to the following question: to what extent does the endpoint of a walk with jumps faithfully encode the walk's sequence of jump times?</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16765v1</guid>
      <category>math.GT</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jason DeBlois, Eduard Einstein, Jonathan D. Victor</dc:creator>
    </item>
    <item>
      <title>Progress Towards Decoding Visual Imagery via fNIRS</title>
      <link>https://arxiv.org/abs/2406.07662</link>
      <description>arXiv:2406.07662v3 Announce Type: replace-cross 
Abstract: We demonstrate the possibility of reconstructing images from fNIRS brain activity and start building a prototype to match the required specs. By training an image reconstruction model on downsampled fMRI data, we discovered that cm-scale spatial resolution is sufficient for image generation. We obtained 71% retrieval accuracy with 1-cm resolution, compared to 93% on the full-resolution fMRI, and 20% with 2-cm resolution. With simulations and high-density tomography, we found that time-domain fNIRS can achieve 1-cm resolution, compared to 2-cm resolution for continuous-wave fNIRS. Lastly, we share designs for a prototype time-domain fNIRS device, consisting of a laser driver, a single photon detector, and a time-to-digital converter system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.07662v3</guid>
      <category>eess.IV</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michel Adamic, Wellington Avelino, Anna Brandenberger, Bryan Chiang, Hunter Davis, Stephen Fay, Andrew Gregory, Aayush Gupta, Raphael Hotter, Grace Jiang, Fiona Leng, Stephen Polcyn, Thomas Ribeiro, Paul Scotti, Michelle Wang, Marley Xiong, Jonathan Xu</dc:creator>
    </item>
  </channel>
</rss>
