<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NA</link>
    <description>cs.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 15 Apr 2025 03:10:16 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 14 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Deep learning-based moment closure for multi-phase computation of semiclassical limit of the Schr\"odinger equation</title>
      <link>https://arxiv.org/abs/2504.08341</link>
      <description>arXiv:2504.08341v1 Announce Type: new 
Abstract: We present a deep learning approach for computing multi-phase solutions to the semiclassical limit of the Schr\"odinger equation. Traditional methods require deriving a multi-phase ansatz to close the moment system of the Liouville equation, a process that is often computationally intensive and impractical. Our method offers an efficient alternative by introducing a novel two-stage neural network framework to close the $2N\times 2N$ moment system, where $N$ represents the number of phases in the solution ansatz. In the first stage, we train neural networks to learn the mapping between higher-order moments and lower-order moments (along with their derivatives). The second stage incorporates physics-informed neural networks (PINNs), where we substitute the learned higher-order moments to systematically close the system. We provide theoretical guarantees for the convergence of both the loss functions and the neural network approximations. Numerical experiments demonstrate the effectiveness of our method for one- and two-dimensional problems with various phase numbers $N$ in the multi-phase solutions. The results confirm the accuracy and computational efficiency of the proposed approach compared to conventional techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.08341v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 14 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jin Woo Jang, Jae Yong Lee, Liu Liu, Zhenyi Zhu</dc:creator>
    </item>
    <item>
      <title>An posteriori error estimator for discontinuous Galerkin discretisations of convection-diffusion problems with application to Earth's mantle convection simulations</title>
      <link>https://arxiv.org/abs/2504.08382</link>
      <description>arXiv:2504.08382v1 Announce Type: new 
Abstract: We present new aposteriori error estimates for the interior penalty discontinuous Galerkin method applied to non-stationary convection-diffusion equations. The focus is on strongly convection-dominated problems without zeroth-order reaction terms, which leads to the absence of positive L^2-like components. An important specific example is the energy/temperature equation of the Boussinesq system arising from the modelling of mantle convection of the Earth. The key mathematical challenge of mitigating the effects of exponential factors with respect to the final time, arising from the use of Gronwall-type arguments, is addressed by an exponential fitting technique. The latter results to a new class of aposteriori error estimates for the stationary problem, which are valid in cases of convection and reaction coefficient combinations not covered by the existing literature. This new class of estimators is combined with an elliptic reconstruction technique to derive new respective estimates for the non-stationary problem, exhibiting reduced dependence on Gronwall-type exponents and, thus, offer more accurate estimation for longer time intervals. We showcase the superior performance of the new class of aposteriori error estimators in driving mesh adaptivity in Earth's mantle convection simulations, in a setting where the energy/temperature equation is discretised by the discontinuous Galerkin method, coupled with the Taylor-Hood finite element for the momentum and mass conservation equations. We exploit the community code ASPECT, to present numerical examples showing the effectivity of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.08382v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 14 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tiffany Barry, Andrea Cangiani, Samuel P. Cox, Emmanuil H. Georgoulis</dc:creator>
    </item>
    <item>
      <title>Well-Posedness of Discretizations for Fractional Elasto-Plasticity</title>
      <link>https://arxiv.org/abs/2504.08450</link>
      <description>arXiv:2504.08450v1 Announce Type: new 
Abstract: We consider a fractional plasticity model based on linear isotropic and kinematic hardening as well as a standard von-Mises yield function, where the flow rule is replaced by a Riesz--Caputo fractional derivative. The resulting mathematical model is typically non-local and non-smooth. Our numerical algorithm is based on the well-known radial return mapping and exploits that the kernel is finitely supported. We propose explicit and implicit discretizations of the model and show the well-posedness of the explicit in time discretization in combination with a standard finite element approach in space. Our numerical results in 2D and 3D illustrate the performance of the algorithm and the influence of the fractional parameter.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.08450v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 14 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Feischl, David Niederkofler, Barbara Wohlmuth</dc:creator>
    </item>
    <item>
      <title>Discretization Error Analysis of a High Order Unfitted Space-Time Method for moving domain problems</title>
      <link>https://arxiv.org/abs/2504.08608</link>
      <description>arXiv:2504.08608v1 Announce Type: new 
Abstract: We present a numerical analysis of a higher order unfitted space-time Finite Element method applied to a convection-diffusion model problem posed on a moving bulk domain. The method uses isoparametric space-time mappings for the geometry approximation of level set domains and has been presented and investigated computationally in [Heimann, Lehrenfeld, Preu{\ss}, SIAM J. Sci. Comp. 45(2), 2023, B139 - B165]. Recently, in [Heimann, Lehrenfeld, IMA J. Numer. Anal., 2025] error bounds for the geometry approximation have been proven. In this paper we prove stability and accuracy including the influence of the geometry approximation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.08608v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 14 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fabian Heimann, Christoph Lehrenfeld, Janosch Preu{\ss}</dc:creator>
    </item>
    <item>
      <title>Dimension reduction for derivative-informed operator learning: An analysis of approximation errors</title>
      <link>https://arxiv.org/abs/2504.08730</link>
      <description>arXiv:2504.08730v1 Announce Type: new 
Abstract: We study the derivative-informed learning of nonlinear operators between infinite-dimensional separable Hilbert spaces by neural networks. Such operators can arise from the solution of partial differential equations (PDEs), and are used in many simulation-based outer-loop tasks in science and engineering, such as PDE-constrained optimization, Bayesian inverse problems, and optimal experimental design. In these settings, the neural network approximations can be used as surrogate models to accelerate the solution of the outer-loop tasks. However, since outer-loop tasks in infinite dimensions often require knowledge of the underlying geometry, the approximation accuracy of the operator's derivatives can also significantly impact the performance of the surrogate model. Motivated by this, we analyze the approximation errors of neural operators in Sobolev norms over infinite-dimensional Gaussian input measures. We focus on the reduced basis neural operator (RBNO), which uses linear encoders and decoders defined on dominant input/output subspaces spanned by reduced sets of orthonormal bases. To this end, we study two methods for generating the bases; principal component analysis (PCA) and derivative-informed subspaces (DIS), which use the dominant eigenvectors of the covariance of the data or the derivatives as the reduced bases, respectively. We then derive bounds for errors arising from both the dimension reduction and the latent neural network approximation, including the sampling errors associated with the empirical estimation of the PCA/DIS. Our analysis is validated on numerical experiments with elliptic PDEs, where our results show that bases informed by the map (i.e., DIS or output PCA) yield accurate reconstructions and generalization errors for both the operator and its derivatives, while input PCA may underperform unless ranks and training sample sizes are sufficiently large.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.08730v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Mon, 14 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dingcheng Luo, Thomas O'Leary-Roseberry, Peng Chen, Omar Ghattas</dc:creator>
    </item>
    <item>
      <title>A physics informed neural network approach to simulating ice dynamics governed by the shallow ice approximation</title>
      <link>https://arxiv.org/abs/2504.08136</link>
      <description>arXiv:2504.08136v1 Announce Type: cross 
Abstract: In this article we develop a Physics Informed Neural Network (PINN) approach to simulate ice sheet dynamics governed by the Shallow Ice Approximation. This problem takes the form of a time-dependent parabolic obstacle problem. Prior work has used this approach to address the stationary obstacle problem and here we extend it to the time dependent problem. Through comprehensive 1D and 2D simulations, we validate the model's effectiveness in capturing complex free-boundary conditions. By merging traditional mathematical modeling with cutting-edge deep learning methods, this approach provides a scalable and robust solution for predicting temporal variations in ice thickness. To illustrate this approach in a real world setting, we simulate the dynamics of the Devon Ice Cap, incorporating aerogeophysical data from 2000 and 2018.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.08136v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.ao-ph</category>
      <pubDate>Mon, 14 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kapil Chawla, William Holmes</dc:creator>
    </item>
    <item>
      <title>A GPU-accelerated simulation of rapid intensification of a tropical cyclone with observed heating</title>
      <link>https://arxiv.org/abs/2504.08157</link>
      <description>arXiv:2504.08157v1 Announce Type: cross 
Abstract: This paper presents a limited-area atmospheric simulation of a tropical cyclone accelerated using GPUs. The OpenACC directive-based programming model is used to port the atmospheric model to the GPU. The GPU implementation of the main functions and kernels is discussed. The GPU-accelerated code produces high-fidelity simulations of a realistic tropical cyclone forced by observational latent heating. Performance tests show that the GPU-accelerated code yields energy-efficient simulations and scales well in both the strong and weak limit.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.08157v1</guid>
      <category>physics.comp-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 14 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Soonpil Kang, Francis X. Giraldo, Seth Camp</dc:creator>
    </item>
    <item>
      <title>Stochastic Momentum ADMM for nonconvex and nonsmooth optimization with application to PnP algorithm</title>
      <link>https://arxiv.org/abs/2504.08223</link>
      <description>arXiv:2504.08223v1 Announce Type: cross 
Abstract: This paper introduces a single-loop Stochastic Momentum Alternating Direction Method of Multipliers (SMADMM) for tackling a class of nonconvex and nonsmooth optimization problems. We establish that SMADMM achieves an optimal oracle complexity of $\mathcal{O}(\epsilon^{-\frac{3}{2}})$ in the online setting, where only stochastic first-order oracle, is available. In particular, SMADMM requires only $\mathcal{O}(1)$ stochastic gradient evaluations per iteration and avoids the need for restarting with large batch gradient estimates. This is the first stochastic ADMM method achieving optimal oracle complexity for nonconvex and nonsmooth problems, requiring $\mathcal{O}(1)$ batch size. Furthermore, we extend our method by integrating it with plug-and-play (PnP) priors, resulting in the PnP-SMADMM algorithm. Numerical experiments on classification, CT image reconstruction and phase retrieve demonstrate the practical effectiveness of our approach and validate the theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.08223v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 14 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kangkang Deng, Shuchang Zhang, Boyu Wang, Jiachen Jin, Juan Zhou, Hongxia Wang</dc:creator>
    </item>
    <item>
      <title>Slicing the Gaussian Mixture Wasserstein Distance</title>
      <link>https://arxiv.org/abs/2504.08544</link>
      <description>arXiv:2504.08544v1 Announce Type: cross 
Abstract: Gaussian mixture models (GMMs) are widely used in machine learning for tasks such as clustering, classification, image reconstruction, and generative modeling. A key challenge in working with GMMs is defining a computationally efficient and geometrically meaningful metric. The mixture Wasserstein (MW) distance adapts the Wasserstein metric to GMMs and has been applied in various domains, including domain adaptation, dataset comparison, and reinforcement learning. However, its high computational cost -- arising from repeated Wasserstein distance computations involving matrix square root estimations and an expensive linear program -- limits its scalability to high-dimensional and large-scale problems. To address this, we propose multiple novel slicing-based approximations to the MW distance that significantly reduce computational complexity while preserving key optimal transport properties. From a theoretical viewpoint, we establish several weak and strong equivalences between the introduced metrics, and show the relations to the original MW distance and the well-established sliced Wasserstein distance. Furthermore, we validate the effectiveness of our approach through numerical experiments, demonstrating computational efficiency and applications in clustering, perceptual image comparison, and GMM minimization</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.08544v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Mon, 14 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Moritz Piening, Robert Beinert</dc:creator>
    </item>
    <item>
      <title>A Second-Order TGV Discretization with $90^{\circ}$ Rotational Invariance Property</title>
      <link>https://arxiv.org/abs/2209.11450</link>
      <description>arXiv:2209.11450v3 Announce Type: replace 
Abstract: In this work, we propose a new discretization for second-order total generalized variation (TGV) with some distinct properties compared to existing discrete formulations. The introduced model is based on same design principles as Condat's discrete total variation model (\textit{SIAM J. Imaging Sci}., 10(3), 1258--1290, 2017) and shares its benefits, in particular, improved quality for the solution of imaging problems. An algorithm for image denoising with second-order TGV using the new discretization is proposed. Numerical results obtained with this algorithm demonstrate the discretization's advantages. Moreover, in order to compare invariance properties of the new model, an algorithm for calculating the TGV value with respect to the new discretization model is given.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.11450v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 14 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alireza Hosseini, Kristian Bredies</dc:creator>
    </item>
    <item>
      <title>Frequency-Explicit Shape Holomorphy in Uncertainty Quantification for Acoustic Scattering</title>
      <link>https://arxiv.org/abs/2408.01194</link>
      <description>arXiv:2408.01194v2 Announce Type: replace 
Abstract: We consider frequency-domain acoustic scattering at a homogeneous star-shaped penetrable obstacle, whose shape is uncertain and modelled via a radial spectral parameterization with random coefficients. Using recent results on the stability of Helmholtz transmission problems with piecewise constant coefficients from [A. Moiola and E. A. Spence, Acoustic transmission problems: wavenumber-explicit bounds and resonance-free regions, Mathematical Models and Methods in Applied Sciences, 29 (2019), pp. 317-354] we obtain frequency-explicit statements on the holomorphic dependence of the scattered field and the far-field pattern on the stochastic shape parameters. This paves the way for applying general results on the efficient construction of high-dimensional surrogate models. We also take into account the effect of domain truncation by means of perfectly matched layers (PML). In addition, spatial regularity estimates which are explicit in terms of the wavenumber $k$ permit us to quantify the impact of finite-element Galerkin discretization using high-order Lagrangian finite-element spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01194v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 14 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ralf Hiptmair, Christoph Schwab, Euan A. Spence</dc:creator>
    </item>
    <item>
      <title>A $\ell_2-\ell_p$ regulariser based model for Poisson noise removal using augmented Lagrangian method</title>
      <link>https://arxiv.org/abs/2411.12457</link>
      <description>arXiv:2411.12457v2 Announce Type: replace 
Abstract: In this article, we propose a variational PDE model using $\ell_2-\ell_p$ regulariser for removing Poisson noise in presence of blur. The proposed minimization problem is solved using augmented Lagrangian method. The convergence of the sequence of minimizers have been carried out. Numerical simulations on some standard test images have been shown. The numerical results are compared with that of a few models existed in literature in terms of image quality metric such as SSIM, PSNR and SNR.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12457v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 14 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abdul Halim, Abdur Rohim</dc:creator>
    </item>
    <item>
      <title>Fast convolution algorithm for state space models</title>
      <link>https://arxiv.org/abs/2411.17729</link>
      <description>arXiv:2411.17729v3 Announce Type: replace 
Abstract: We present an unconditionally stable algorithm for applying matrix transfer function of a linear time invariant system (LTI) in time domain. The state matrix of an LTI system used for modeling long range dependencies in state space models (SSMs) has eigenvalues close to $1$. The standard recursion defining LTI system becomes unstable if the $m\times m$ state matrix has just one eigenvalue with absolute value even slightly greater than 1. This may occur when approximating a state matrix by a structured matrix to reduce the cost of matrix-vector multiplication from $\mathcal{O}\left(m^{2}\right)$ to $\mathcal{O}\left(m\right)$ or $\mathcal{O}\left(m\log m\right).$ We introduce an unconditionally stable algorithm that uses an approximation of the rational transfer function in the z-domain by a matrix polynomial of degree $2^{N+1}-1$, where $N$ is chosen to achieve any user-selected accuracy. Using a cascade implementation in time domain, applying such transfer function to compute $L$ states requires no more than $2L$ matrix-vector multiplications (whereas the standard recursion requires $L$ matrix-vector multiplications). However, using unconditionally stable algorithm, it is not necessary to assure that an approximate state matrix has all eigenvalues with absolute values strictly less than 1 i.e., within the desired accuracy, the absolute value of some eigenvalues may possibly exceed $1$. Consequently, this algorithm allows one to use a wider variety of structured approximations to reduce the cost of matrix-vector multiplication and we briefly describe several of them to be used for this purpose.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.17729v3</guid>
      <category>math.NA</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <pubDate>Mon, 14 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gregory Beylkin</dc:creator>
    </item>
    <item>
      <title>Weighted approximate sampling recovery and integration based on B-spline interpolation and quasi-interpolation</title>
      <link>https://arxiv.org/abs/2501.01167</link>
      <description>arXiv:2501.01167v3 Announce Type: replace 
Abstract: We propose novel methods for approximate sampling recovery and integration of functions in the Freud-weighted Sobolev space $W^r_{p,w}(\mathbb{R})$. The approximation error of sampling recovery is measured in the norm of the Freud-weighted Lebesgue space $L_{q,w}(\mathbb{R})$. Namely, we construct equidistant compact-supported B-spline quasi-interpolation and interpolation sampling algorithms $Q_{\rho,m}$ and $P_{\rho,m}$ which are asymptotically optimal in terms of the sampling $n$-widths $\varrho_n(\boldsymbol{W}^r_{p,w}(\mathbb{R}), L_{q,w}(\mathbb{R}))$ for every pair $p,q \in [1,\infty]$, and prove the right convergence rate of these sampling $n$-widths, where $\boldsymbol{W}^r_{p,w}(\mathbb{R})$ denotes the unit ball in $W^r_{p,w}(\mathbb{R})$. The algorithms $Q_{\rho,m}$ and $P_{\rho,m}$ are based on truncated scaled B-spline quasi-interpolation and interpolation, respectively. We also prove the asymptotical optimality and right convergence rate of the equidistant quadratures generated from $Q_{\rho,m}$ and $P_{\rho,m}$, for Freud-weighted numerical integration of functions in $W^r_{p,w}(\mathbb{R})$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01167v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 14 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dinh D\~ung</dc:creator>
    </item>
    <item>
      <title>Diffusion-based Models for Unpaired Super-resolution in Fluid Dynamics</title>
      <link>https://arxiv.org/abs/2504.05443</link>
      <description>arXiv:2504.05443v2 Announce Type: replace 
Abstract: High-fidelity, high-resolution numerical simulations are crucial for studying complex multiscale phenomena in fluid dynamics, such as turbulent flows and ocean waves. However, direct numerical simulations with high-resolution solvers are computationally prohibitive. As an alternative, super-resolution techniques enable the enhancement of low-fidelity, low-resolution simulations. However, traditional super-resolution approaches rely on paired low-fidelity, low-resolution and high-fidelity, high-resolution datasets for training, which are often impossible to acquire in complex flow systems. To address this challenge, we propose a novel two-step approach that eliminates the need for paired datasets. First, we perform unpaired domain translation at the low-resolution level using an Enhanced Denoising Diffusion Implicit Bridge. This process transforms low-fidelity, low-resolution inputs into high-fidelity, low-resolution outputs, and we provide a theoretical analysis to highlight the advantages of this enhanced diffusion-based approach. Second, we employ the cascaded Super-Resolution via Repeated Refinement model to upscale the high-fidelity, low-resolution prediction to the high-resolution result. We demonstrate the effectiveness of our approach across three fluid dynamics problems. Moreover, by incorporating a neural operator to learn system dynamics, our method can be extended to improve evolutionary simulations of low-fidelity, low-resolution data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05443v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.flu-dyn</category>
      <pubDate>Mon, 14 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wuzhe Xu, Yulong Lu, Lian Shen, Anqing Xuan, Ali Barzegari</dc:creator>
    </item>
    <item>
      <title>Faster Linear Systems and Matrix Norm Approximation via Multi-level Sketched Preconditioning</title>
      <link>https://arxiv.org/abs/2405.05865</link>
      <description>arXiv:2405.05865v2 Announce Type: replace-cross 
Abstract: We present a new class of preconditioned iterative methods for solving linear systems of the form $Ax = b$. Our methods are based on constructing a low-rank Nystr\"om approximation to $A$ using sparse random matrix sketching. This approximation is used to construct a preconditioner, which itself is inverted quickly using additional levels of random sketching and preconditioning. We prove that the convergence of our methods depends on a natural average condition number of $A$, which improves as the rank of the Nystr\"om approximation increases. Concretely, this allows us to obtain faster runtimes for a number of fundamental linear algebraic problems:
  1. We show how to solve any $n\times n$ linear system that is well-conditioned except for $k$ outlying large singular values in $\tilde{O}(n^{2.065} + k^\omega)$ time, improving on a recent result of [Derezi\'nski, Yang, STOC 2024] for all $k \gtrsim n^{0.78}$.
  2. We give the first $\tilde{O}(n^2 + {d_\lambda}^{\omega}$) time algorithm for solving a regularized linear system $(A + \lambda I)x = b$, where $A$ is positive semidefinite with effective dimension $d_\lambda=\mathrm{tr}(A(A+\lambda I)^{-1})$. This problem arises in applications like Gaussian process regression.
  3. We give faster algorithms for approximating Schatten $p$-norms and other matrix norms. For example, for the Schatten 1-norm (nuclear norm), we give an algorithm that runs in $\tilde{O}(n^{2.11})$ time, improving on an $\tilde{O}(n^{2.18})$ method of [Musco et al., ITCS 2018]. All results are proven in the real RAM model of computation. Interestingly, previous state-of-the-art algorithms for most of the problems above relied on stochastic iterative methods, like stochastic coordinate and gradient descent. Our work takes a completely different approach, instead leveraging tools from matrix sketching.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.05865v2</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Mon, 14 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Micha{\l} Derezi\'nski, Christopher Musco, Jiaming Yang</dc:creator>
    </item>
    <item>
      <title>Quantum Error Detection For Early Term Fault-Tolerant Quantum Algorithms</title>
      <link>https://arxiv.org/abs/2503.10790</link>
      <description>arXiv:2503.10790v2 Announce Type: replace-cross 
Abstract: Quantum error detection (QED) offers a promising pathway to fault tolerance in near-term quantum devices by balancing error suppression with minimal resource overhead. However, its practical utility hinges on optimizing design parameters-such as syndrome measurement frequency-to avoid diminishing returns from detection overhead. In this work, we present a comprehensive framework for fault-tolerant compilation and simulation of quantum algorithms using [[n, n-2, 2]] codes, which enable low-qubit-overhead error detection and a simple nearly fault-tolerant universal set of operations. We demonstrate and analyze our pipeline with a purely statistical interpretation and through the implementation of Grover's search algorithm. Our results are used to answer the question is quantum error detection a worthwhile avenue for early-term fault tolerance, and if so how can we get the most out of it? Simulations under the circuit-level noise model reveal that finding optimal syndrome schedules improves algorithm success probabilities by an average of 6.7x but eventual statistical limits from post-selection in noisy/resource-limited regimes constrain scalability. Furthermore, we propose a simple data-driven approach to predict fault tolerant compilation parameters, such as optimal syndrome schedules, and expected fault tolerant performance gains based on circuit and noise features. These results provide actionable guidelines for implementing QED in early-term quantum experiments and underscore its role as a pragmatic, constant-overhead error mitigation layer for shallow algorithms. To aid in further research, we release all simulation data computed for this work and provide an experimental QED compiler at https://codeqraft.xyz/qed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10790v2</guid>
      <category>quant-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 14 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tom Ginsberg, Vyom Patel</dc:creator>
    </item>
    <item>
      <title>VPAL: A novel method to reduce reconstruction time for 5D free-running imaging</title>
      <link>https://arxiv.org/abs/2503.15711</link>
      <description>arXiv:2503.15711v2 Announce Type: replace-cross 
Abstract: Purpose: Ferumoxytal-enhanced 5D free-running whole heart CMR provides image quality comparable to CTA, but requires hours-long reconstruction time, preventing clinical usage. This study developed a variable projection augmented Lagrangian (VPAL) method for 5D motion-resolved image reconstruction and compared it with alternating direction method of multipliers (ADMM) in five numerical simulations and 15 in-vivo pediatric data set.
  Approach: Relative error of the reconstructed images against the ground-truth images was assessed in numerical simulations. In-vivo analysis compared reconstruction time, mid-short axis (SA) blood-myocardium sharpness, left ventricular ejection fraction (LVEF), and a radiologist's image quality ratings between VPAL and ADMM. A paired t-test (p&lt;0.05) was used to determine statistical significance, while linear regression and Bland-Altman analysis for agreement assessments.
  Results: VPAL and ADMM had similar relative errors compared to the ground truth, p = 0.07. In in-vivo datasets, VPAL reduced the reconstruction time from 16.3 +/- 3.6 hours (ADMM) to 4.7 +/- 1.1 hours (VPAL), p=1e-10. Blood-myocardium border sharpness in VPAL closely correlates to ADMM , R^2 = 0.97. The LVEFs values measured by VPAL and ADMM reconstructions are largely similar, 56 +/- 6 % in ADMM and 56 +/- 6 % in VPAL, p=0.55. Both VPAL and ADMM reconstructions have good to excellent diagnostic ratings (VPAL vs. ADMM: 3.9 +/- 0.3 vs. 3.8 +/- 0.4 in 2-chamber; 3.9 +/- 0.4 vs. 3.9 +/- in 4-chamber; 3.7 +/- 0.5 vs. 3.7 +/- 0.5 in mid-SA reformatted views. Conclusion: VPAL enables faster reconstruction than ADMM while maintaining equivalent image quality for functional assessments, supporting its potential for clinical use.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15711v2</guid>
      <category>physics.med-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 14 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yitong Yang, Muhammad Naeem, Marly Van Assen, Jerome Yerly, Davide Piccini, Matthias Stuber, John Oshinski, Matthias Chung</dc:creator>
    </item>
  </channel>
</rss>
