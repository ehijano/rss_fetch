<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 10 Sep 2025 01:34:07 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Newton to Einstein: Axiom-Based Discovery via Game Design</title>
      <link>https://arxiv.org/abs/2509.05448</link>
      <description>arXiv:2509.05448v1 Announce Type: new 
Abstract: This position paper argues that machine learning for scientific discovery should shift from inductive pattern recognition to axiom-based reasoning. We propose a game design framework in which scientific inquiry is recast as a rule-evolving system: agents operate within environments governed by axioms and modify them to explain outlier observations. Unlike conventional ML approaches that operate within fixed assumptions, our method enables the discovery of new theoretical structures through systematic rule adaptation. We demonstrate the feasibility of this approach through preliminary experiments in logic-based games, showing that agents can evolve axioms that solve previously unsolvable problems. This framework offers a foundation for building machine learning systems capable of creative, interpretable, and theory-driven discovery.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.05448v1</guid>
      <category>cs.CE</category>
      <category>cs.AI</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pingchuan Ma, Benjamin Tod Jones, Tsun-Hsuan Wang, Minghao Guo, Michal Piotr Lipiec, Chuang Gan, Wojciech Matusik</dc:creator>
    </item>
    <item>
      <title>GUIDe: Generative and Uncertainty-Informed Inverse Design for On-Demand Nonlinear Functional Responses</title>
      <link>https://arxiv.org/abs/2509.05641</link>
      <description>arXiv:2509.05641v1 Announce Type: new 
Abstract: Inverse design problems are pervasive in engineering, particularly when dealing with nonlinear system responses, such as in mechanical behavior or spectral analysis. The inherent intractability, non-existence, or non-uniqueness of their solutions, and the need for swift exploration of the solution space necessitate the adoption of machine learning and data-driven approaches, such as deep generative models. Here, we show that both deep generative model-based and optimization-based methods can yield unreliable solutions or incomplete coverage of the solution space. To address this, we propose the Generative and Uncertainty-informed Inverse Design (GUIDe) framework, leveraging probabilistic machine learning, statistical inference, and Markov chain Monte Carlo sampling to generate designs with targeted nonlinear behaviors. Unlike inverse models that directly map response to design, i.e., response $\mapsto$ design, we employ a design $\mapsto$ response strategy: a forward model that predicts each design's nonlinear functional response allows GUIDe to evaluate the confidence that a design will meet the target, conditioned on a target response with a user-specified tolerance level. Then, solutions are generated by sampling the solution space based on the confidence. We validate the method by designing the interface properties for nacre-inspired composites to achieve target stress-strain responses. Results show that GUIDe enables the discovery of diverse feasible solutions, including those outside the training data range, even for out-of-distribution targets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.05641v1</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haoxuan Dylan Mu, Mingjian Tang, Wei Gao, Wei "Wayne" Chen</dc:creator>
    </item>
    <item>
      <title>Transformer-based Topology Optimization</title>
      <link>https://arxiv.org/abs/2509.05800</link>
      <description>arXiv:2509.05800v1 Announce Type: new 
Abstract: Topology optimization enables the design of highly efficient and complex structures, but conventional iterative methods, such as SIMP-based approaches, often suffer from high computational costs and sensitivity to initial conditions. Although machine learning methods have recently shown promise for accelerating topology generation, existing models either remain iterative or struggle to match ground-truth performance. In this work, we propose a transformer-based machine learning model for topology optimization that embeds critical boundary and loading conditions directly into the tokenized domain representation via a class token mechanism. We implement this model on static and dynamic datasets, using transfer learning and FFT encoding of dynamic loads to improve our performance on the dynamic dataset. Auxiliary loss functions are introduced to promote the realism and manufacturability of the generated designs. We conduct a comprehensive evaluation of the model's performance, including compliance error, volume fraction error, floating material percentage, and load discrepancy error, and benchmark it against state-of-the-art non-iterative and iterative generative models. Our results demonstrate that the proposed model approaches the fidelity of diffusion-based models while remaining iteration-free, offering a significant step toward real-time, high-fidelity topology generation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.05800v1</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aaron Lutheran, Srijan Das, Alireza Tabarraei</dc:creator>
    </item>
    <item>
      <title>Distortion Minimization in Reverse Engineering for Additive Manufacturing: An Integrated 3D Scanning and Simulation Framework</title>
      <link>https://arxiv.org/abs/2509.05857</link>
      <description>arXiv:2509.05857v1 Announce Type: new 
Abstract: Reverse engineering can be used to derive a 3D model of an existing physical part when such a model is not readily available. For parts that will be fabricated with subtractive and formative manufacturing processes, existing reverse engineering techniques can be readily applied, but parts produced with additive manufacturing can present new challenges due to the high level of process-induced distortions and unique part attributes. This paper introduces an integrated 3D scanning and process simulation data-driven framework to minimize distortions of reverse-engineered additively manufactured components. This framework employs iterative finite element simulations to predict geometric distortions to minimize errors between the predicted and measured geometrical deviations of the key dimensional characteristics of the part. The effectiveness of this approach is then demonstrated by reverse engineering two Inconel-718 components manufactured using laser powder bed fusion additive manufacturing. This paper presents a remanufacturing process that combines reverse engineering and additive manufacturing, leveraging geometric feature-based part compensation through process simulation. Our approach can generate both compensated STL and parametric CAD models, eliminating laborious experimentation during reverse engineering. We evaluate the merits of STL-based and CAD-based approaches by quantifying the errors induced at the different steps of the proposed approach and analyzing the influence of varying part geometries. Using the proposed CAD-based method, the average absolute percent error between simulation-predicted distorted dimensions and actual measured dimensions of the manufactured parts was 0.087%, with better accuracy than the STL-based method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.05857v1</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jannatul Bushra (The University of Arizona), Md Habibor Rahman (University of Massachusetts Dartmouth), Mohammed Shafae (The University of Arizona), Hannah D. Budinoff (The University of Arizona)</dc:creator>
    </item>
    <item>
      <title>Anticipating AMOC transitions via deep learning</title>
      <link>https://arxiv.org/abs/2509.06450</link>
      <description>arXiv:2509.06450v1 Announce Type: new 
Abstract: Key components of the Earth system can undergo abrupt and potentially irreversible transitions when the magnitude or rate of external forcing exceeds critical thresholds. In this study, we use the example of the Atlantic Meridional Overturning Circulation (AMOC) to demonstrate the challenges associated with anticipating such transitions when the system is susceptible to bifurcation-induced, rate-induced, and noise-induced tipping. Using a calibrated AMOC box model, we conduct large ensemble simulations and show that transition behavior is inherently probabilistic: under identical freshwater forcing scenarios, some ensemble members exhibit transitions while others do not. In this stochastic regime, traditional early warning indicators based on critical slowing down are unreliable in predicting impending transitions. To address this limitation, we develop a convolutional neural network (CNN)-based approach that identifies higher-order statistical differences between transitioning and non-transitioning trajectories within the ensemble realizations. This method enables the real-time prediction of transition probabilities for individual trajectories prior to the onset of tipping. Our results show that the CNN-based indicator provides effective early warnings in a system where transitions can be induced by bifurcations, critical forcing rates, and noise. These findings underscore the potential in identifying safe operating spaces and early warning indicators for abrupt transitions of Earth system components under uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.06450v1</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenjie Zhang, Yu Huang, Sebastian Bathiany, Yechul Shin, Maya Ben-Yami, Suiping Zhou, Niklas Boers</dc:creator>
    </item>
    <item>
      <title>Reusable Surrogate Models for Distillation Columns</title>
      <link>https://arxiv.org/abs/2509.06638</link>
      <description>arXiv:2509.06638v2 Announce Type: new 
Abstract: Surrogate modeling is a powerful methodology in chemical process engineering, frequently employed to accelerate optimization tasks where traditional flowsheet simulators are computationally prohibitive. However, the state-of-the-art is dominated by surrogate models trained for a narrow range of fixed chemical systems and operating conditions, limiting their reusability. This work introduces a paradigm shift towards reusable surrogates by developing a single model for distillation columns that generalizes across a vast design space. The key enabler is a novel ML-fueled modelfluid representation which allows for the generation of datasets of more than $1,000,000$ samples. This allows the surrogate to generalize not only over column specifications but also over the entire chemical space of homogeneous ternary vapor-liquid mixtures. We validate the model's accuracy and demonstrate its practical utility in a case study on entrainer distillation, where it successfully screens and ranks candidate entrainers, significantly reducing the computational effort compared to rigorous optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.06638v2</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martin Bubel, Tobias Seidel, Michael Bortz</dc:creator>
    </item>
    <item>
      <title>Optimizing Stateful Microservice Migration in Kubernetes with MS2M and Forensic Checkpointing</title>
      <link>https://arxiv.org/abs/2509.05794</link>
      <description>arXiv:2509.05794v1 Announce Type: cross 
Abstract: The widespread adoption of microservices architecture in modern software systems has emphasized the need for efficient management of distributed services. While stateless microservices enable straightforward migration, stateful microservices introduce added complexity due to the need to preserve in-memory state during migration. However, most container orchestrators, including Kubernetes, lack native support for live stateful service migration. This paper proposes an optimized migration scheme for stateful services in Kubernetes by integrating the Message-based Stateful Microservice Migration (MS2M) framework with Kubernetes' Forensic Container Checkpointing (FCC) feature. Key enhancements include support for migrating StatefulSet-managed Pods and the introduction of a Threshold-Based Cutoff Mechanism to handle high incoming message rates. Evaluation results demonstrate that MS2M for individual Pods reduces downtime by 96.986% compared to cold migration methods, while the StatefulSet approach provides greater flexibility in managing stateful services. These insights provide practical strategies for optimizing stateful microservice migration in cloud-native environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.05794v1</guid>
      <category>cs.PF</category>
      <category>cs.CE</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/ICIN64016.2025.10942720</arxiv:DOI>
      <dc:creator>Hai Dinh-Tuan, Jialun Jiang</dc:creator>
    </item>
    <item>
      <title>TinyDef-DETR:An Enhanced DETR Detector for UAV Power Line Defect Detection</title>
      <link>https://arxiv.org/abs/2509.06035</link>
      <description>arXiv:2509.06035v1 Announce Type: cross 
Abstract: Automated inspection of transmission lines using UAVs is hindered by the difficulty of detecting small and ambiguous defects against complex backgrounds. Conventional detectors often suffer from detail loss due to strided downsampling, weak boundary sensitivity in lightweight backbones, and insufficient integration of global context with local cues. To address these challenges, we propose TinyDef-DETR, a DETR-based framework designed for small-defect detection. The method introduces a stride-free space-to-depth module for lossless downsampling, an edge-enhanced convolution for boundary-aware feature extraction, a cross-stage dual-domain multi-scale attention module to jointly capture global and local information, and a Focaler-Wise-SIoU regression loss to improve localization of small objects. Experiments conducted on the CSG-ADCD dataset demonstrate that TinyDef-DETR achieves substantial improvements in both precision and recall compared to competitive baselines, with particularly notable gains on small-object subsets, while incurring only modest computational overhead. Further validation on the VisDrone benchmark confirms the generalization capability of the proposed approach. Overall, the results indicate that integrating detail-preserving downsampling, edge-sensitive representations, dual-domain attention, and difficulty-adaptive regression provides a practical and efficient solution for UAV-based small-defect inspection in power grids.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.06035v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiaming Cui</dc:creator>
    </item>
    <item>
      <title>Distillation of CNN Ensemble Results for Enhanced Long-Term Prediction of the ENSO Phenomenon</title>
      <link>https://arxiv.org/abs/2509.06227</link>
      <description>arXiv:2509.06227v1 Announce Type: cross 
Abstract: The accurate long-term forecasting of the El Nino Southern Oscillation (ENSO) is still one of the biggest challenges in climate science. While it is true that short-to medium-range performance has been improved significantly using the advances in deep learning, statistical dynamical hybrids, most operational systems still use the simple mean of all ensemble members, implicitly assuming equal skill across members. In this study, we demonstrate, through a strictly a-posteriori evaluation , for any large enough ensemble of ENSO forecasts, there is a subset of members whose skill is substantially higher than that of the ensemble mean. Using a state-of-the-art ENSO forecast system cross-validated against the 1986-2017 observed Nino3.4 index, we identify two Top-5 subsets one ranked on lowest Root Mean Square Error (RMSE) and another on highest Pearson correlation. Generally across all leads, these outstanding members show higher correlation and lower RMSE, with the advantage rising enormously with lead time. Whereas at short leads (1 month) raises the mean correlation by about +0.02 (+1.7%) and lowers the RMSE by around 0.14 {\deg}C or by 23.3% compared to the All-40 mean, at extreme leads (23 months) the correlation is raised by +0.43 (+172%) and RMSE by 0.18 {\deg}C or by 22.5% decrease. The enhancements are largest during crucial ENSO transition periods such as SON and DJF, when accurate amplitude and phase forecasting is of greatest socio-economic benefit, and furthermore season-dependent e.g., mid-year months such as JJA and MJJ have incredibly large RMSE reductions. This study provides a solid foundation for further investigations to identify reliable clues for detecting high-quality ensemble members, thereby enhancing forecasting skill.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.06227v1</guid>
      <category>physics.ao-ph</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>physics.app-ph</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Saghar Ganji, Mohammad Naisipour, Alireza Hassani, Arash Adib</dc:creator>
    </item>
    <item>
      <title>CAME-AB: Cross-Modality Attention with Mixture-of-Experts for Antibody Binding Site Prediction</title>
      <link>https://arxiv.org/abs/2509.06465</link>
      <description>arXiv:2509.06465v2 Announce Type: cross 
Abstract: Antibody binding site prediction plays a pivotal role in computational immunology and therapeutic antibody design. Existing sequence or structure methods rely on single-view features and fail to identify antibody-specific binding sites on the antigens. In this paper, we propose \textbf{CAME-AB}, a novel Cross-modality Attention framework with a Mixture-of-Experts (MoE) backbone for robust antibody binding site prediction. CAME-AB integrates five biologically grounded modalities, including raw amino acid encodings, BLOSUM substitution profiles, pretrained language model embeddings, structure-aware features, and GCN-refined biochemical graphs, into a unified multimodal representation. To enhance adaptive cross-modal reasoning, we propose an \emph{adaptive modality fusion} module that learns to dynamically weight each modality based on its global relevance and input-specific contribution. A Transformer encoder combined with an MoE module further promotes feature specialization and capacity expansion. We additionally incorporate a supervised contrastive learning objective to explicitly shape the latent space geometry, encouraging intra-class compactness and inter-class separability. To improve optimization stability and generalization, we apply stochastic weight averaging during training. Extensive experiments on benchmark antibody-antigen datasets demonstrate that CAME-AB consistently outperforms strong baselines on multiple metrics, including Precision, Recall, F1-score, AUC-ROC, and MCC. Ablation studies further validate the effectiveness of each architectural component and the benefit of multimodal feature integration. The model implementation details and the codes are available on https://anonymous.4open.science/r/CAME-AB-C525</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.06465v2</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <category>q-bio.BM</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hongzong Li, Jiahao Ma, Zhanpeng Shi, Rui Xiao, Fanming Jin, Ye-Fan Hu, Jian-Dong Huang</dc:creator>
    </item>
    <item>
      <title>A machine-learned expression for the excess Gibbs energy</title>
      <link>https://arxiv.org/abs/2509.06484</link>
      <description>arXiv:2509.06484v1 Announce Type: cross 
Abstract: The excess Gibbs energy plays a central role in chemical engineering and chemistry, providing a basis for modeling the thermodynamic properties of liquid mixtures. Predicting the excess Gibbs energy of multi-component mixtures solely from the molecular structures of their components is a long-standing challenge. In this work, we address this challenge by integrating physical laws as hard constraints within a flexible neural network. The resulting model, HANNA, was trained end-to-end on an extensive experimental dataset for binary mixtures from the Dortmund Data Bank, guaranteeing thermodynamically consistent predictions. A novel surrogate solver developed in this work enabled the inclusion of liquid-liquid equilibrium data in the training process. Furthermore, a geometric projection method was applied to enable robust extrapolations to multi-component mixtures, without requiring additional parameters. We demonstrate that HANNA delivers excellent predictions, clearly outperforming state-of-the-art benchmark methods in accuracy and scope. The trained model and corresponding code are openly available, and an interactive interface is provided on our website, MLPROP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.06484v1</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marco Hoffmann, Thomas Specht, Quirin G\"ottl, Jakob Burger, Stephan Mandt, Hans Hasse, Fabian Jirasek</dc:creator>
    </item>
    <item>
      <title>A Parallel Solver with Multiphysics Finite Element Method for Poroelasticity Coupled with Elasticity Model</title>
      <link>https://arxiv.org/abs/2509.06673</link>
      <description>arXiv:2509.06673v1 Announce Type: cross 
Abstract: In this paper, we propose a parallel solver for solving the quasi-static linear poroelasticity coupled with linear elasticity model in the Lagrange multiplier framework. Firstly, we reformulate the model into a coupling of the nearly incompressible elasticity and an unsteady affection-diffusion equations by setting new variable ``elastic pressure" and ``volumetric fluid content". And we introduce a Lagrange multiplier to guarantee the normal stress continuity on the interface. Then, we give the variational formulations in each subdomain and choose the $\boldsymbol{P}_k$-$P_1$-$P_1$ mixed finite element tuple for poroelasticity subdomain, and $\boldsymbol{P}_k$-$P_1$ finite element pair ($k=1,2$) for elasticity subdomain and the backward Euler scheme for time. Also, we propose a parallel solver for solving the fully discrete scheme at each time step -- the FETI method with a classical FETI preconditioner for solving the Lagrange multiplier and calculating the subproblems in each subdomain in parallel. And we show several numerical tests to validate the computational efficiency and the convergence error order, and we consider Barry-Mercer's model as the benchmark test to show that there no oscillation in the computed pressure. Finally, we draw conclusions to summarize the main results of this paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.06673v1</guid>
      <category>math.NA</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhihao Ge, Chengxin Wang</dc:creator>
    </item>
    <item>
      <title>A simple and efficient hybrid discretization approach to alleviate membrane locking in isogeometric thin shells</title>
      <link>https://arxiv.org/abs/2312.16944</link>
      <description>arXiv:2312.16944v2 Announce Type: replace 
Abstract: This work presents a new hybrid discretization approach to alleviate membrane locking in isogeometric finite element formulations for Kirchhoff-Love shells. The approach is simple, and requires no additional dofs and no static condensation. It does not increase the bandwidth of the tangent matrix and is effective for both linear and nonlinear problems. It combines isogeometric surface discretizations with classical Lagrange-based surface discretizations, and can thus be run with existing isogeometric finite element codes. Also, the stresses can be recovered straightforwardly. The effectiveness of the proposed approach in alleviating, if not eliminating, membrane locking is demonstrated through the rigorous study of the convergence behavior of several classical benchmark problems. Accuracy gains are particularly large in the membrane stresses. The approach is formulated here for quadratic NURBS, but an extension to other discretization types can be anticipated. The same applies to other constraints and associated locking phenomena.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.16944v2</guid>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.cma.2024.116869</arxiv:DOI>
      <arxiv:journal_reference>Comput. Methods Appl. Mech. Eng., 424:116869, 2024</arxiv:journal_reference>
      <dc:creator>Roger A. Sauer, Zhihui Zou, Thomas J. R. Hughes</dc:creator>
    </item>
    <item>
      <title>Projection-based model-order reduction via graph autoencoders suited for unstructured meshes</title>
      <link>https://arxiv.org/abs/2407.13669</link>
      <description>arXiv:2407.13669v4 Announce Type: replace 
Abstract: This paper presents the development of a graph autoencoder architecture capable of performing projection-based model-order reduction (PMOR) using a nonlinear manifold least-squares Petrov-Galerkin (LSPG) projection scheme. The architecture is particularly useful for advection-dominated flows modeled by unstructured meshes, as it provides a robust nonlinear mapping that can be leveraged in a PMOR setting. The presented graph autoencoder is constructed with a two-part process that consists of (1) generating a hierarchy of reduced graphs to emulate the compressive abilities of convolutional neural networks (CNNs) and (2) training a message passing operation at each step in the hierarchy of reduced graphs to emulate the filtering process of a CNN. The resulting framework provides improved flexibility over traditional CNN-based autoencoders because it is readily extendable to unstructured meshes. We provide an analysis of the interpretability of the graph autoencoder's latent state variables, where we find that the Jacobian of the decoder for the proposed graph autoencoder provides interpretable mode shapes akin to traditional proper orthogonal decomposition modes. To highlight the capabilities of the proposed framework, which is named geometric deep least-squares Petrov-Galerkin (GD-LSPG), we benchmark the method on a one-dimensional Burgers' model with a structured mesh and demonstrate the flexibility of GD-LSPG by deploying it on two test cases for two-dimensional Euler equations that use an unstructured mesh. The proposed framework is more flexible than using a traditional CNN-based autoencoder and provides considerable improvement in accuracy for very low-dimensional latent spaces in comparison with traditional affine projections.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13669v4</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liam K. Magargal, Parisa Khodabakhshi, Steven N. Rodriguez, Justin W. Jaworski, John G. Michopoulos</dc:creator>
    </item>
    <item>
      <title>Mixed-precision numerics in scientific applications: survey and perspectives</title>
      <link>https://arxiv.org/abs/2412.19322</link>
      <description>arXiv:2412.19322v3 Announce Type: replace 
Abstract: The explosive demand for artificial intelligence (AI) workloads has led to a significant increase in silicon area dedicated to lower-precision computations on recent high-performance computing hardware designs. However, mixed-precision capabilities, which can achieve performance improvements of 8x compared to double-precision in extreme compute-intensive workloads, remain largely untapped in most scientific applications. A growing number of efforts have shown that mixed-precision algorithmic innovations can deliver superior performance without sacrificing accuracy. These developments should prompt computational scientists to seriously consider whether their scientific modeling and simulation applications could benefit from the acceleration offered by new hardware and mixed-precision algorithms. In this survey, we (1) review progress across diverse scientific domains -- including fluid dynamics, weather and climate, quantum chemistry, and computational genomics -- that have begun adopting mixed-precision strategies; (2) examine state-of-the-art algorithmic techniques such as iterative refinement, splitting and emulation schemes, and adaptive precision solvers; (3) assess their implications for accuracy, performance, and resource utilization; and (4) survey the emerging software ecosystem that enables mixed-precision methods at scale. We conclude with perspectives and recommendations on cross-cutting opportunities, domain-specific challenges, and the role of co-design between application scientists, numerical analysts and computer scientists. Collectively, this survey underscores that mixed-precision numerics can reshape computational science by aligning algorithms with the evolving landscape of hardware capabilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.19322v3</guid>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aditya Kashi, Hao Lu, Wesley Brewer, David Rogers, Michael Matheson, Mallikarjun Shankar, Feiyi Wang</dc:creator>
    </item>
    <item>
      <title>Numerical optimization of aviation decarbonization scenarios: balancing traffic and emissions with maturing energy carriers and aircraft technology</title>
      <link>https://arxiv.org/abs/2503.22435</link>
      <description>arXiv:2503.22435v2 Announce Type: replace 
Abstract: Despite being considered a hard-to-abate sector, aviation's emissions will play an important role in long-term climate mitigation of transportation. The introduction of low-carbon energy carriers and the deployment of new aircraft in the current fleet are modeled as technology-centered decarbonization policies, while supply constraints in targeted market segments are modeled as demand-side policies. Shared Socioeconomic Pathways (SSPs) are used to estimate trend traffic demand and to limit the sectoral consumption of electricity and biomass. Mitigation scenarios are formulated as optimization problems, and three applications are demonstrated: no-policy baselines, single-policy optimization, and scenario-robust policies. Results show that the choice of energy carrier is highly dependent on assumptions regarding aircraft technology and the background energy system. Across all SSP-based scenarios, emissions peak by around 2040, but achieving alignment with the Paris Agreement requires either targeted demand management or additional low-carbon energy supply. The use of gradient-based optimization within a multidisciplinary framework enables the efficient resolution of these nonlinear, high-dimensional problems while reducing implementation effort.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.22435v2</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ian Costa-Alves (ISAE-SUPAERO), Nicolas Gourdain (ISAE-SUPAERO), Fran\c{c}ois Gallard (ISAE-SUPAERO, ENAC), Anne Gazaix (ISAE-SUPAERO, ENAC), Yri Amandine Kambiri (ISAE-SUPAERO, ENAC), Thierry Druot (ENAC)</dc:creator>
    </item>
    <item>
      <title>Estimating Deprivation Cost Functions for Power Outages During Disasters: A Discrete Choice Modeling Approach</title>
      <link>https://arxiv.org/abs/2506.16993</link>
      <description>arXiv:2506.16993v2 Announce Type: replace 
Abstract: Systems for the generation and distribution of electrical power represents critical infrastructure and, when extreme weather events disrupt such systems, this imposes substantial costs on consumers. These costs can be conceptualized as deprivation costs, an increasing function of time without service, quantifiable through individuals' willingness to pay for power restoration. Despite widespread recognition of outage impacts, a gap in the research literature exists regarding the systematic measurement of deprivation costs. This study addresses this deficiency by developing and implementing a methodology to estimate deprivation cost functions for electricity outages, using stated preference survey data collected from Harris County, Texas. This study compares multiple discrete choice model architectures, including multinomial logit and mixed logit specifications, as well as models incorporating BoxCox and exponential utility transformations for the deprivation time attribute. The analysis examines heterogeneity in deprivation valuation through sociodemographic interactions, particularly across income groups. Results confirm that power outage deprivation cost functions are convex and strictly increasing with time. Additionally, the study reveals both systematic and random taste variation in how individuals value power loss, highlighting the need for flexible modeling approaches. By providing both methodological and empirical foundations for incorporating deprivation costs into infrastructure risk assessments and humanitarian logistics, this research enables policymakers to better quantify service disruption costs and develop more equitable resilience strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16993v2</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Xiangpeng Li, Mona Ahmadiani, Richard Woodward, Bo Li, Arnold Vedlitz, Ali Mostafavi</dc:creator>
    </item>
    <item>
      <title>Conservative data-driven finite element framework</title>
      <link>https://arxiv.org/abs/2506.18206</link>
      <description>arXiv:2506.18206v2 Announce Type: replace 
Abstract: This paper presents a new data-driven finite element framework that is applicable to a broad range of engineering simulation problems. In the data-driven approach, the conservation laws and boundary conditions are satisfied by means of the finite element method, while the experimental data is used directly in numerical simulations, avoiding material models. Critically, we introduce a "weaker'" mixed finite element formulation, which relaxes the regularity requirements on the approximation space for the primary field. At the same time, the continuity of the normal flux component is enforced across inner boundaries, allowing the conservation law to be satisfied in the strong sense. The relaxed regularity of the approximation spaces makes it easier to observe how imperfections in the datasets, such as missing or noisy data, result in non-uniqueness of the solution. This can be quantified to predict the uncertainty of the results using methods such as Markov chain Monte Carlo. Furthermore, this formulation provides a posteriori error indicators tailored for the data-driven approach, providing confidence in the results and enabling efficient solution schemes via adaptive hp-refinement. The capabilities of the formulation are demonstrated on an example of the nonlinear heat transfer in nuclear graphite using synthetically generated material datasets. This work provides an essential component for numerical frameworks for complex engineering systems such as digital twins.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.18206v2</guid>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adriana Kulikov\'a (Glasgow Computational Engineering Centre), Andrei G. Shvarts (Glasgow Computational Engineering Centre), {\L}ukasz Kaczmarczyk (Glasgow Computational Engineering Centre), Chris J. Pearce (Glasgow Computational Engineering Centre)</dc:creator>
    </item>
    <item>
      <title>Robust blue-green urban flood risk management optimised with a genetic algorithm for multiple rainstorm return periods</title>
      <link>https://arxiv.org/abs/2502.12174</link>
      <description>arXiv:2502.12174v2 Announce Type: replace-cross 
Abstract: Flood risk managers seek to optimise Blue-Green Infrastructure (BGI) designs to maximise return on investment. Current systems often use optimisation algorithms and detailed flood models to maximise benefit-cost ratios for single rainstorm return periods. However, these schemes may lack robustness in mitigating flood risks across different storm magnitudes. For example, a BGI scheme optimised for a 100-year return period may differ from one optimised for a 10-year return period. This study introduces a novel methodology incorporating five return periods (T = 10, 20, 30, 50, and 100 years) into a multi-objective BGI optimisation framework. The framework combines a Non-dominated Sorting Genetic Algorithm II (NSGA-II) with a fully distributed hydrodynamic model to optimise the spatial placement and combined size of BGI features. For the first time, direct damage cost (DDC) and expected annual damage (EAD), calculated for various building types, are used as risk objective functions, transforming a many-objective problem into a multi-objective one. Performance metrics such as Median Risk Difference (MedRD), Maximum Risk Difference (MaxRD), and Area Under Pareto Front (AUPF) reveal that a 100-year optimised BGI design performs poorly when evaluated for other return periods, particularly shorter ones. In contrast, a BGI design optimised using composite return periods enhances performance metrics across all return periods, with the greatest improvements observed in MedRD (22%) and AUPF (73%) for the 20-year return period, and MaxRD (23%) for the 50-year return period. Furthermore, climate uplift stress testing confirms the robustness of the proposed design to future rainfall extremes. This study advocates a paradigm shift in flood risk management, moving from single maximum to multiple rainstorm return period-based designs to enhance resilience and adaptability to future climate extremes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12174v2</guid>
      <category>cs.NE</category>
      <category>cs.CE</category>
      <category>cs.CY</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1111/jfr3.70118</arxiv:DOI>
      <arxiv:journal_reference>Journal of Flood Risk Management, Volume18, Issue3, September 2025, e70118</arxiv:journal_reference>
      <dc:creator>Asid Ur Rehman, Vassilis Glenis, Elizabeth Lewis, Chris Kilsby, Claire Walsh</dc:creator>
    </item>
    <item>
      <title>An Efficient Continuous-Time MILP for Integrated Aircraft Hangar Scheduling and Layout</title>
      <link>https://arxiv.org/abs/2508.02640</link>
      <description>arXiv:2508.02640v2 Announce Type: replace-cross 
Abstract: Efficient management of aircraft MRO hangars requires the integration of spatial layout with time-continuous scheduling to minimize operational costs. We propose a continuous-time mixed-integer linear program that jointly optimizes aircraft placement and timing, overcoming the scalability limits of prior formulations. A comprehensive study benchmarks the model against a constructive heuristic, probes large-scale performance, and quantifies its sensitivity to temporal congestion. The model achieves orders-of-magnitude speedups on benchmarks from the literature, solving a long-standing congested instance in 0.11 seconds, and finds proven optimal solutions for instances with up to 40 aircraft. Within a one-hour limit for large-scale problems, the model finds solutions with small optimality gaps for instances up to 80 aircraft and provides strong bounds for problems with up to 160 aircraft. Optimized plans consistently increase hangar throughput (e.g., +33% serviced aircraft vs. a heuristic on instance RND-N030-I03), leading to lower delay penalties and higher asset utilization. These findings establish that exact optimization has become computationally viable for large-scale hangar planning, providing a validated tool that balances solution quality and computation time for strategic and operational decisions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02640v2</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shayan Farhang Pazhooh, Hossein Shams Shemirani</dc:creator>
    </item>
  </channel>
</rss>
