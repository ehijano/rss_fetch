<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DB updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DB</link>
    <description>cs.DB updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DB" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 16 Jan 2025 02:28:44 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 15 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Real-Time Outlier Connections Detection in Databases Network Traffic</title>
      <link>https://arxiv.org/abs/2501.07689</link>
      <description>arXiv:2501.07689v1 Announce Type: new 
Abstract: The article describes a practical method for detecting outlier database connections in real-time. Outlier connections are detected with a specified level of confidence. The method is based on generalized security rules and a simple but effective real-time machine learning mechanism. The described method is non-intrusive to the database and does not depend on the type of database. The method is used to proactively control access even before database connection is established, minimize false positives, and maintain the required response speed to detected database connection outliers. The capabilities of the system are demonstrated with several examples of outliers in real-world scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.07689v1</guid>
      <category>cs.DB</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 15 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Leonid Rodniansky, Tania Butovsky, Mikhail Shpak</dc:creator>
    </item>
    <item>
      <title>An Empirical Evaluation of Serverless Cloud Infrastructure for Large-Scale Data Processing</title>
      <link>https://arxiv.org/abs/2501.07771</link>
      <description>arXiv:2501.07771v1 Announce Type: new 
Abstract: Data processing systems are increasingly deployed in the cloud. While monolithic systems run fully on virtual servers, recent systems embrace cloud infrastructure and utilize the disaggregation of compute and storage to scale them independently. The introduction of serverless compute services, such as AWS Lambda, enables finer-grained and elastic scalability within these systems. Prior work shows the viability of serverless infrastructure for scalable data processing yet also sees limitations due to variable performance and cost overhead, in particular for networking and storage.
  In this paper, we perform a detailed analysis of the performance and cost characteristics of serverless infrastructure in the data processing context. We base our analysis on a large series of micro-benchmarks across different compute and storage services, as well as end-to-end workloads. To enable our analysis, we propose the Skyrise serverless evaluation platform. For the widely used serverless infrastructure of AWS, our analysis reveals distinct boundaries for performance variability in serverless networks and storage. We further present cost break-even points for serverless compute and storage. These insights provide guidance on when and how serverless infrastructure can be efficiently used for data processing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.07771v1</guid>
      <category>cs.DB</category>
      <pubDate>Wed, 15 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Bodner, Theo Radig, David Justen, Daniel Ritter, Tilmann Rabl</dc:creator>
    </item>
    <item>
      <title>Efficient Dataframe Systems: Lazy Fat Pandas on a Diet</title>
      <link>https://arxiv.org/abs/2501.08207</link>
      <description>arXiv:2501.08207v1 Announce Type: new 
Abstract: Pandas is widely used for data science applications, but users often run into problems when datasets are larger than memory. There are several frameworks based on lazy evaluation that handle large datasets, but the programs have to be rewritten to suit the framework, and the presence of multiple frameworks complicates the life of a programmer. In this paper we present a framework that allows programmers to code in plain Pandas; with just two lines of code changed by the user, our system optimizes the program using a combination of just-in-time static analysis, and runtime optimization based on a lazy dataframe wrapper framework. Moreover, our system allows the programmer to choose the backend. It works seamlessly with Pandas, Dask, and Modin, allowing the choice of the best-suited backend for an application based on factors such as data size. Performance results on a variety of programs show the benefits of our framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08207v1</guid>
      <category>cs.DB</category>
      <pubDate>Wed, 15 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Bhushan Pal Singh, Priyesh Kumar, Chiranmoy Bhattacharya, S. Sudarshan</dc:creator>
    </item>
    <item>
      <title>Multi-variable Quantification of BDDs in External Memory using Nested Sweeping (Extended Paper)</title>
      <link>https://arxiv.org/abs/2408.14216</link>
      <description>arXiv:2408.14216v2 Announce Type: replace-cross 
Abstract: Previous research on the Adiar BDD package has been successful at designing algorithms capable of handling large Binary Decision Diagrams (BDDs) stored in external memory. To do so, it uses consecutive sweeps through the BDDs to resolve computations. Yet, this approach has kept algorithms for multi-variable quantification, the relational product, and variable reordering out of its scope.
  In this work, we address this by introducing the nested sweeping framework. Here, multiple concurrent sweeps pass information between eachother to compute the result. We have implemented the framework in Adiar and used it to create a new external memory multi-variable quantification algorithm. Compared to conventional depth-first implementations, Adiar with nested sweeping is able to solve more instances of our benchmarks and/or solve them faster.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.14216v2</guid>
      <category>cs.DS</category>
      <category>cs.DB</category>
      <pubDate>Wed, 15 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Steffan Christ S{\o}lvsten, Jaco van de Pol</dc:creator>
    </item>
    <item>
      <title>QMDB: Quick Merkle Database</title>
      <link>https://arxiv.org/abs/2501.05262</link>
      <description>arXiv:2501.05262v2 Announce Type: replace-cross 
Abstract: Quick Merkle Database (QMDB) addresses longstanding bottlenecks in blockchain state management by integrating key-value (KV) and Merkle tree storage into a single unified architecture. QMDB delivers a significant throughput improvement over existing architectures, achieving up to 6X over the widely used RocksDB and 8X over NOMT, a leading verifiable database. Its novel append-only twig-based design enables one SSD read per state access, O(1) IOs for updates, and in-memory Merkleization on a memory footprint as small as 2.3 bytes per entry, enabling it to run on even modest consumer-grade PCs. QMDB scales seamlessly across both commodity and enterprise hardware, achieving up to 2.28 million state updates per second. This performance enables support for 1 million token transfers per second (TPS), marking QMDB as the first solution achieving such a milestone. QMDB has been benchmarked with workloads exceeding 15 billion entries (10X Ethereum's 2024 state) and has proven the capacity to scale to 280 billion entries on a single server. Furthermore, QMDB introduces historical proofs, unlocking the ability to query its blockchain's historical state at the latest block. QMDB not only meets the demands of current blockchains but also provides a robust foundation for building scalable, efficient, and verifiable decentralized applications across diverse use cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.05262v2</guid>
      <category>cs.NI</category>
      <category>cs.DB</category>
      <pubDate>Wed, 15 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Isaac Zhang, Ryan Zarick, Daniel Wong, Thomas Kim, Bryan Pellegrino, Mignon Li, Kelvin Wong</dc:creator>
    </item>
  </channel>
</rss>
