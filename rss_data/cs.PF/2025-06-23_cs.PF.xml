<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.PF updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.PF</link>
    <description>cs.PF updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.PF" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 24 Jun 2025 02:20:19 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>How to Increase Energy Efficiency with a Single Linux Command</title>
      <link>https://arxiv.org/abs/2506.16046</link>
      <description>arXiv:2506.16046v1 Announce Type: new 
Abstract: Processors with dynamic power management provide a variety of settings to control energy efficiency. However, tuning these settings does not achieve optimal energy savings. We highlight how existing power capping mechanisms can address these limitations without requiring any changes to current power governors. We validate this approach using system measurements across a month-long data acquisition campaign from SPEC CPU 2017 benchmarks on a server-class system equipped with dual Intel Xeon Scalable processors. Our results indicate that setting a simple power cap can improve energy efficiency by up to 25% over traditional energy-saving system configurations with little performance loss, as most default settings focus on thermal regulation and performance rather than compute efficiency. Power capping is very accessible compared to other approaches, as it can be implemented with a single Linux command. Our results point to programmers and administrators using power caps as a primary mechanism to maintain significant energy efficiency while retaining acceptable performance, as opposed to deploying complex DVFS algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16046v1</guid>
      <category>cs.PF</category>
      <category>cs.AR</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alborz Jelvani, Richard P Martin, Santosh Nagarakatte</dc:creator>
    </item>
    <item>
      <title>Dependability of UAV-Based Networks and Computing Systems: A Survey</title>
      <link>https://arxiv.org/abs/2506.16786</link>
      <description>arXiv:2506.16786v1 Announce Type: new 
Abstract: Uncrewed Aerial Vehicle (UAV) computing and networking are becoming a fundamental computation infrastructure for diverse cyber-physical application systems. UAVs can be empowered by AI on edge devices and can communicate with other UAVs and ground stations via wireless communication networks. Dynamic computation demands and heterogeneous computing resources are distributed in the system and need to be controlled to maintain the quality of services and to accomplish critical missions. With the evolution of UAV-based systems, dependability assurance of such systems emerges as a crucial challenge. UAV-based systems confront diverse sources of uncertainty that may threaten their dependability, such as software bugs, component failures, network disconnections, battery shortages, and disturbances from the real world. In this paper, we conduct systematic literature reviews on the dependability of UAV-based networks and computing systems. The survey report reveals emerging research trends in this field and summarizes the literature into comprehensive categories by threat types and adopted technologies. Based on our literature reviews, we identify eight research fields that require further exploration in the future to achieve dependable UAV-based systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16786v1</guid>
      <category>cs.PF</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qingyang Zhang, Mohammad Dwipa Furqan, Tasfia Nutzhat, Fumio Machida, Ermeson Andrade</dc:creator>
    </item>
    <item>
      <title>Implementing Keyword Spotting on the MCUX947 Microcontroller with Integrated NPU</title>
      <link>https://arxiv.org/abs/2506.08911</link>
      <description>arXiv:2506.08911v1 Announce Type: cross 
Abstract: This paper presents a keyword spotting (KWS) system implemented on the NXP MCXN947 microcontroller with an integrated Neural Processing Unit (NPU), enabling real-time voice interaction on resource-constrained devices. The system combines MFCC feature extraction with a CNN classifier, optimized using Quantization Aware Training to reduce model size with minimal accuracy drop. Experimental results demonstrate a 59x speedup in inference time when leveraging the NPU compared to CPU-only execution, achieving 97.06% accuracy with a model size of 30.58 KB, demonstrating the feasibility of efficient, low-power voice interfaces on embedded platforms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.08911v1</guid>
      <category>cs.HC</category>
      <category>cs.AR</category>
      <category>cs.LG</category>
      <category>cs.PF</category>
      <category>cs.SD</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Petar Jaku\v{s}, Hrvoje D\v{z}apo</dc:creator>
    </item>
    <item>
      <title>Spatially-Aware Evaluation of Segmentation Uncertainty</title>
      <link>https://arxiv.org/abs/2506.16589</link>
      <description>arXiv:2506.16589v1 Announce Type: cross 
Abstract: Uncertainty maps highlight unreliable regions in segmentation predictions. However, most uncertainty evaluation metrics treat voxels independently, ignoring spatial context and anatomical structure. As a result, they may assign identical scores to qualitatively distinct patterns (e.g., scattered vs. boundary-aligned uncertainty). We propose three spatially aware metrics that incorporate structural and boundary information and conduct a thorough validation on medical imaging data from the prostate zonal segmentation challenge within the Medical Segmentation Decathlon. Our results demonstrate improved alignment with clinically important factors and better discrimination between meaningful and spurious uncertainty patterns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16589v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.PF</category>
      <category>stat.ML</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tal Zeevi, El\'eonore V. Lieffrig, Lawrence H. Staib, John A. Onofrey</dc:creator>
    </item>
    <item>
      <title>Fast solvers for Tokamak fluid models with PETSC -- Part I</title>
      <link>https://arxiv.org/abs/2506.16676</link>
      <description>arXiv:2506.16676v1 Announce Type: cross 
Abstract: This report develops the first step in adding multigrid solvers to scientific and engineering-relevant magnetohydrodynamics (MHD) models of Tokamaks. These models are characterized by a distinguished direction in the toroidal coordinate that is partially aligned with the magnetic guide field, which dominates the plasma dynamics. All Tokamak models exploit this structure, for example, NIMROD (https://nimrodteam.org/) uses $2D$, unstructured, high-order finite elements in the poloidal plane with Fourier modes in the toroidal coordinate, and the $3D$, extended MHD code M3D-C1 (https://w3.pppl.gov/~nferraro/m3dc1.html) uses $2D$, unstructured $C^1$ elements in the poloidal plane with cubic Hermite functions in the toroidal direction. This structure suggests adding toroidal semi-coarsening multigrid to the existing solver and thereby reducing reliance on direct solvers, which do not scale optimally and are not well suited to modern hardware that demands extreme levels of parallelism. This report focuses on the velocity solve in M3D-C1, using the PETSC -- the Portable, Extensible Toolkit for Scientific Computation -- numerical library (https://petsc.org), and shows that with little new application code, one-dimensional multigrid is about $5x$ faster than the existing one-level method on an MHD disruption, with runaway electrons, test problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16676v1</guid>
      <category>physics.plasm-ph</category>
      <category>cs.PF</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Mark F. Adams, Jin Chen, Benjamin Sturdevant</dc:creator>
    </item>
    <item>
      <title>JANUS: Resilient and Adaptive Data Transmission for Enabling Timely and Efficient Cross-Facility Scientific Workflows</title>
      <link>https://arxiv.org/abs/2506.17084</link>
      <description>arXiv:2506.17084v1 Announce Type: cross 
Abstract: In modern science, the growing complexity of large-scale projects has increased reliance on cross-facility workflows, where institutions share resources and expertise to accelerate discovery. These workflows often involve transferring massive data over wide-area networks. While high-speed networks like ESnet and data transfer services like Globus have improved data mobility, challenges remain. Large data volumes can strain bandwidth, TCP suffers from retransmissions due to packet loss, and traditional fault-tolerance methods like erasure coding introduce significant overhead.
  This paper presents JANUS, a resilient and adaptive data transmission approach for cross-facility scientific workflows. JANUS uses UDP, integrates erasure coding for fault tolerance, and applies error-bounded lossy compression to reduce overhead. This design enables users to balance transmission time and accuracy based on specific needs. JANUS also adapts coding parameters to real-time network conditions and uses optimization models to determine ideal configurations. Experiments show that JANUS significantly improves data transfer efficiency while preserving fidelity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.17084v1</guid>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <category>cs.PF</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Vladislav Esaulov, Jieyang Chen, Norbert Podhorszki, Fred Suter, Scott Klasky, Anu G Bourgeois, Lipeng Wan</dc:creator>
    </item>
    <item>
      <title>Assessing Tenstorrent's RISC-V MatMul Acceleration Capabilities</title>
      <link>https://arxiv.org/abs/2505.06085</link>
      <description>arXiv:2505.06085v3 Announce Type: replace 
Abstract: The increasing demand for generative AI as Large Language Models (LLMs) services has driven the need for specialized hardware architectures that optimize computational efficiency and energy consumption. This paper evaluates the performance of the Tenstorrent Grayskull e75 RISC-V accelerator for basic linear algebra kernels at reduced numerical precision, a fundamental operation in LLM computations. We present a detailed characterization of Grayskull's execution model, gridsize, matrix dimensions, data formats, and numerical precision impact computational efficiency. Furthermore, we compare Grayskull's performance against state-of-the-art architectures with tensor acceleration, including Intel Sapphire Rapids processors and two NVIDIA GPUs (V100 and A100). Whilst NVIDIA GPUs dominate raw performance, Grayskull demonstrates a competitive trade-off between power consumption and computational throughput, reaching a peak of 1.55 TFLOPs/Watt with BF16.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06085v3</guid>
      <category>cs.PF</category>
      <category>cs.AI</category>
      <category>cs.AR</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hiari Pizzini Cavagna, Daniele Cesarini, Andrea Bartolini</dc:creator>
    </item>
    <item>
      <title>FALCON: Feedback-driven Adaptive Long/short-term memory reinforced Coding Optimization system</title>
      <link>https://arxiv.org/abs/2410.21349</link>
      <description>arXiv:2410.21349v5 Announce Type: replace-cross 
Abstract: Recently, large language models (LLMs) have achieved significant progress in automated code generation. Despite their strong instruction-following capabilities, these models frequently struggled to align with user intent in coding scenarios. In particular, they were hampered by datasets that lacked diversity and failed to address specialized tasks or edge cases. Furthermore, challenges in supervised fine-tuning (SFT) and reinforcement learning from human feedback (RLHF) led to failures in generating precise, human-intent-aligned code. To tackle these challenges and improve the code generation performance for automated programming systems, we propose Feedback-driven Adaptive Long/short-term memory reinforced Coding Optimization (i.e., FALCON). FALCON is structured into two hierarchical levels. From the global level, long-term memory improves code quality by retaining and applying learned knowledge. At the local level, short-term memory allows for the incorporation of immediate feedback from compilers and AI systems. Additionally, we introduce meta-reinforcement learning with feedback rewards to solve the global-local bi-level optimization problem and enhance the model's adaptability across diverse code generation tasks. Extensive experiments demonstrate that our technique achieves state-of-the-art performance, leading other reinforcement learning methods by more than 4.5 percentage points on the MBPP benchmark and 6.1 percentage points on the Humaneval benchmark. The open-sourced code is publicly available at https://github.com/titurte/FALCON.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21349v5</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.PF</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zeyuan Li, Yangfan He, Lewei He, Jianhui Wang, Tianyu Shi, Bin Lei, Yuchen Li, Qiuwu Chen</dc:creator>
    </item>
  </channel>
</rss>
