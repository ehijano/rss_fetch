<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CG updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CG</link>
    <description>cs.CG updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CG" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 14 Jun 2024 04:01:37 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 14 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>DeepJEB: 3D Deep Learning-based Synthetic Jet Engine Bracket Dataset</title>
      <link>https://arxiv.org/abs/2406.09047</link>
      <description>arXiv:2406.09047v1 Announce Type: new 
Abstract: Recent advancements in artificial intelligence (AI) have significantly influenced various fields, including mechanical engineering. Nonetheless, the development of high-quality, diverse datasets for structural analysis still needs to be improved. Although traditional datasets, such as simulated jet engine bracket dataset, are useful, they are constrained by a small number of samples, which must be improved for developing robust data-driven surrogate models. This study presents the DeepJEB dataset, which has been created using deep generative models and automated engineering simulation pipelines, to overcome these challenges. Moreover, this study provides comprehensive 3D geometries and their corresponding structural analysis data.
  Key experiments validated the effectiveness of the DeepJEB dataset, demonstrating significant improvements in the prediction accuracy and reliability of surrogate models trained on this data. The enhanced dataset showed a broader design space and better generalization capabilities than traditional datasets. These findings highlight the potential of DeepJEB as a benchmark dataset for developing reliable surrogate models in structural engineering. The DeepJEB dataset supports advanced modeling techniques, such as graph neural networks (GNNs) and high-dimensional convolutional networks (CNNs), leveraging node-level field data for precise predictions. This dataset is set to drive innovation in engineering design applications, enabling more accurate and efficient structural performance predictions. The DeepJEB dataset is publicly accessible at: https://www.narnia.ai/dataset</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.09047v1</guid>
      <category>cs.CG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Seongjun Hong, Yongmin Kwon, Dongju Shin, Jangseop Park, Namwoo Kang</dc:creator>
    </item>
    <item>
      <title>Maximizing the Maximum Degree in Ordered Yao Graphs</title>
      <link>https://arxiv.org/abs/2406.08913</link>
      <description>arXiv:2406.08913v1 Announce Type: cross 
Abstract: For an ordered point set in a Euclidean space or, more generally, in an abstract metric space, the ordered Yao graph is obtained by connecting each of the points to its closest predecessor by a directed edge. We show that for every set of $n$ points in $\mathbb{R}^d$, there exists an order such that the corresponding ordered Yao graph has maximum degree at least $\log{n}/(4d)$. Apart from the $1/(4d)$ factor, this bound is the best possible. As for the abstract setting, we show that for every $n$-element metric space, there exists an order such that the corresponding ordered Yao graph has maximum degree $\Omega(\sqrt{\log{n}/\log\log{n}})$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.08913v1</guid>
      <category>math.CO</category>
      <category>cs.CG</category>
      <category>math.MG</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>P\'eter \'Agoston, Adrian Dumitrescu, Arsenii Sagdeev, Karamjeet Singh, Ji Zeng</dc:creator>
    </item>
    <item>
      <title>ALPHAGMUT: A Rationale-Guided Alpha Shape Graph Neural Network to Evaluate Mutation Effects</title>
      <link>https://arxiv.org/abs/2406.09159</link>
      <description>arXiv:2406.09159v1 Announce Type: cross 
Abstract: In silico methods evaluating the mutation effects of missense mutations are providing an important approach for understanding mutations in personal genomes and identifying disease-relevant biomarkers. However, existing methods, including deep learning methods, heavily rely on sequence-aware information, and do not fully leverage the potential of available 3D structural information. In addition, these methods may exhibit an inability to predict mutations in domains difficult to formulate sequence-based embeddings. In this study, we introduce a novel rationale-guided graph neural network AlphaGMut to evaluate mutation effects and to distinguish pathogenic mutations from neutral mutations. We compute the alpha shapes of protein structures to obtain atomic-resolution edge connectivities and map them to an accurate residue-level graph representation. We then compute structural-, topological-, biophysical-, and sequence properties of the mutation sites, which are assigned as node attributes in the graph. These node attributes could effectively guide the graph neural network to learn the difference between pathogenic and neutral mutations using k-hop message passing with a short training period. We demonstrate that AlphaGMut outperforms state-of-the-art methods, including DeepMind's AlphaMissense, in many performance metrics. In addition, AlphaGMut has the advantage of performing well in alignment-free settings, which provides broader prediction coverage and better generalization compared to current methods requiring deep sequence-aware information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.09159v1</guid>
      <category>q-bio.QM</category>
      <category>cs.AI</category>
      <category>cs.CG</category>
      <category>q-bio.GN</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Boshen Wang, Bowei Ye, Lin Xu, Jie Liang</dc:creator>
    </item>
    <item>
      <title>Keeping it sparse: Computing Persistent Homology revisited</title>
      <link>https://arxiv.org/abs/2211.09075</link>
      <description>arXiv:2211.09075v3 Announce Type: replace 
Abstract: In this work, we study several variants of matrix reduction via Gaussian elimination that try to keep the reduced matrix sparse. The motivation comes from the growing field of topological data analysis where matrix reduction is the major subroutine to compute barcodes, the main invariant therein. We propose two novel variants of the standard algorithm, called swap and retrospective reductions. We test them on a large collection of data against other known variants to compare their efficiency, and we find that sometimes they provide a considerable speed-up. We also present novel output-sensitive bounds for the retrospective variant which better explain the discrepancy between the cubic worst-case complexity bound and the almost linear practical behavior of matrix reduction. Finally, we provide several constructions on which one of the variants performs strictly better than the others.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.09075v3</guid>
      <category>cs.CG</category>
      <category>math.AT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ulrich Bauer, Talha Bin Masood, Barbara Giunti, Guillaume Houry, Michael Kerber, Abhishek Rathod</dc:creator>
    </item>
    <item>
      <title>Reconstructing Curves from Sparse Samples on Riemannian Manifolds</title>
      <link>https://arxiv.org/abs/2404.09661</link>
      <description>arXiv:2404.09661v2 Announce Type: replace 
Abstract: Reconstructing 2D curves from sample points has long been a critical challenge in computer graphics, finding essential applications in vector graphics. The design and editing of curves on surfaces has only recently begun to receive attention, primarily relying on human assistance, and where not, limited by very strict sampling conditions. In this work, we formally improve on the state-of-the-art requirements and introduce an innovative algorithm capable of reconstructing closed curves directly on surfaces from a given sparse set of sample points. We extend and adapt a state-of-the-art planar curve reconstruction method to the realm of surfaces while dealing with the challenges arising from working on non-Euclidean domains. We demonstrate the robustness of our method by reconstructing multiple curves on various surface meshes. We explore novel potential applications of our approach, allowing for automated reconstruction of curves on Riemannian manifolds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.09661v2</guid>
      <category>cs.CG</category>
      <category>cs.GR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Diana Marin, Filippo Maggioli, Simone Melzi, Stefan Ohrhallinger, Michael Wimmer</dc:creator>
    </item>
    <item>
      <title>Connecting 3-manifold triangulations with monotonic sequences of elementary moves</title>
      <link>https://arxiv.org/abs/2012.02398</link>
      <description>arXiv:2012.02398v2 Announce Type: replace-cross 
Abstract: A key result in computational 3-manifold topology is that any two triangulations of the same 3-manifold are connected by a finite sequence of bistellar flips, also known as Pachner moves. One limitation of this result is that little is known about the structure of this sequence; knowing more about the structure could help both proofs and algorithms. Motivated by this, we consider sequences of moves that are "monotonic" in the sense that they break up into two parts: first, a sequence that monotonically increases the size of the triangulation; and second, a sequence that monotonically decreases the size. We prove that any two one-vertex triangulations of the same 3-manifold, each with at least two tetrahedra, are connected by a monotonic sequence of 2-3 and 2-0 moves. We also study the practical utility of monotonic sequences; specifically, we implement an algorithm to find such sequences, and use this algorithm to perform some detailed computational experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2012.02398v2</guid>
      <category>math.GT</category>
      <category>cs.CG</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Benjamin A. Burton, Alexander He</dc:creator>
    </item>
  </channel>
</rss>
