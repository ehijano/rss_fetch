<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NE</link>
    <description>cs.NE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 24 May 2024 04:00:16 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 24 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>An Efficient Approach for Solving Expensive Constrained Multiobjective Optimization Problems</title>
      <link>https://arxiv.org/abs/2405.13298</link>
      <description>arXiv:2405.13298v1 Announce Type: new 
Abstract: To solve real-world expensive constrained multi-objective optimization problems (ECMOPs), surrogate/approximation models are commonly incorporated in evolutionary algorithms to pre-select promising candidate solutions for evaluation. However, the performance of existing approaches are highly dependent on the relative position of unconstrained and constrained Pareto fronts (UPF and CPF, respectively). In addition, the uncertainty information of surrogate models is often ignored, which can misguide the search. To mitigate these key issues (among others), an efficient probabilistic selection based constrained multi-objective EA is proposed, referred to as PSCMOEA. It comprises novel elements such as (a) an adaptive search bound identification scheme based on the feasibility and convergence status of evaluated solutions (b) a probabilistic selection method backed by theoretical formulations of model mean and uncertainties to conduct search in the predicted space to identify promising solutions (c) an efficient single infill sampling approach to balance feasibility, convergence and diversity across different stages of the search and (d) an adaptive switch to unconstrained search based on certain search conditions. Numerical experiments are conducted on an extensive range of challenging constrained problems using low evaluation budgets to simulate ECMOPs. The performance of PSCMOEA is benchmarked against five competitive state-of-the-art algorithms, to demonstrate its competitive and consistent performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13298v1</guid>
      <category>cs.NE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Kamrul Hasan Rahi</dc:creator>
    </item>
    <item>
      <title>Towards Exploratory Quality Diversity Landscape Analysis</title>
      <link>https://arxiv.org/abs/2405.13433</link>
      <description>arXiv:2405.13433v1 Announce Type: new 
Abstract: This work is a preliminary study on using Exploratory Landscape Analysis (ELA) for Quality Diversity (QD) problems. We seek to understand whether ELA features can potentially be used to characterise QD problems paving the way for automating QD algorithm selection. Our results demonstrate that ELA features are affected by QD optimisation differently than random sampling, and more specifically, by the choice of variation operator, behaviour function, archive size and problem dimensionality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13433v1</guid>
      <category>cs.NE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kyriacos Mosphilis, Vassilis Vassiliades</dc:creator>
    </item>
    <item>
      <title>Illustrating the Efficiency of Popular Evolutionary Multi-Objective Algorithms Using Runtime Analysis</title>
      <link>https://arxiv.org/abs/2405.13572</link>
      <description>arXiv:2405.13572v1 Announce Type: new 
Abstract: Runtime analysis has recently been applied to popular evolutionary multi-objective (EMO) algorithms like NSGA-II in order to establish a rigorous theoretical foundation. However, most analyses showed that these algorithms have the same performance guarantee as the simple (G)SEMO algorithm. To our knowledge, there are no runtime analyses showing an advantage of a popular EMO algorithm over the simple algorithm for deterministic problems.
  We propose such a problem and use it to showcase the superiority of popular EMO algorithms over (G)SEMO: OneTrapZeroTrap is a straightforward generalization of the well-known Trap function to two objectives. We prove that, while GSEMO requires at least $n^n$ expected fitness evaluations to optimise OneTrapZeroTrap, popular EMO algorithms NSGA-II, NSGA-III and SMS-EMOA, all enhanced with a mild diversity mechanism of avoiding genotype duplication, only require $O(n \log n)$ expected fitness evaluations. Our analysis reveals the importance of the key components in each of these sophisticated algorithms and contributes to a better understanding of their capabilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13572v1</guid>
      <category>cs.NE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3638529.3654177</arxiv:DOI>
      <dc:creator>Duc-Cuong Dang, Andre Opris, Dirk Sudholt</dc:creator>
    </item>
    <item>
      <title>EchoSpike Predictive Plasticity: An Online Local Learning Rule for Spiking Neural Networks</title>
      <link>https://arxiv.org/abs/2405.13976</link>
      <description>arXiv:2405.13976v1 Announce Type: new 
Abstract: The drive to develop artificial neural networks that efficiently utilize resources has generated significant interest in bio-inspired Spiking Neural Networks (SNNs). These networks are particularly attractive due to their potential in applications requiring low power and memory. This potential is further enhanced by the ability to perform online local learning, enabling them to adapt to dynamic environments. This requires the model to be adaptive in a self-supervised manner. While self-supervised learning has seen great success in many deep learning domains, its application for online local learning in multi-layer SNNs remains underexplored. In this paper, we introduce the "EchoSpike Predictive Plasticity" (ESPP) learning rule, a pioneering online local learning rule designed to leverage hierarchical temporal dynamics in SNNs through predictive and contrastive coding. We validate the effectiveness of this approach using benchmark datasets, demonstrating that it performs on par with current state-of-the-art supervised learning rules. The temporal and spatial locality of ESPP makes it particularly well-suited for low-cost neuromorphic processors, representing a significant advancement in developing biologically plausible self-supervised learning models for neuromorphic computing at the edge.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13976v1</guid>
      <category>cs.NE</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lars Graf, Zhe Su, Giacomo Indiveri</dc:creator>
    </item>
    <item>
      <title>Automated Optimal Layout Generator for Animal Shelters: A framework based on Genetic Algorithm, TOPSIS and Graph Theory</title>
      <link>https://arxiv.org/abs/2405.14172</link>
      <description>arXiv:2405.14172v1 Announce Type: new 
Abstract: Overpopulation in animal shelters contributes to increased disease spread and higher expenses on animal healthcare, leading to fewer adoptions and more shelter deaths. Additionally, one of the greatest challenges that shelters face is the noise level in the dog kennel area, which is physically and physiologically hazardous for both animals and staff. This paper proposes a multi-criteria optimization framework to automatically design cage layouts that maximize shelter capacity, minimize tension in the dog kennel area by reducing the number of cages facing each other, and ensure accessibility for staff and visitors. The proposed framework uses a Genetic Algorithm (GA) to systematically generate and improve layouts. A novel graph theory-based algorithm is introduced to process solutions and calculate fitness values. Additionally, the Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS) is used to rank and sort the layouts in each iteration. The graph-based algorithm calculates variables such as cage accessibility and shortest paths to access points. Furthermore, a heuristic algorithm is developed to calculate layout scores based on the number of cages facing each other. This framework provides animal shelter management with a flexible decision-support system that allows for different strategies by assigning various weights to the TOPSIS criteria. Results from cats' and dogs' kennel areas show that the proposed framework can suggest optimal layouts that respect different priorities within acceptable runtimes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14172v1</guid>
      <category>cs.NE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arghavan Jalayer, Masoud Jalayer, Mehdi Khahzand, Mohsen Faizi</dc:creator>
    </item>
    <item>
      <title>Multi-Representation Genetic Programming: A Case Study on Tree-based and Linear Representations</title>
      <link>https://arxiv.org/abs/2405.14268</link>
      <description>arXiv:2405.14268v1 Announce Type: new 
Abstract: Existing genetic programming (GP) methods are typically designed based on a certain representation, such as tree-based or linear representations. These representations show various pros and cons in different domains. However, due to the complicated relationships among representation and fitness landscapes of GP, it is hard to intuitively determine which GP representation is the most suitable for solving a certain problem. Evolving programs (or models) with multiple representations simultaneously can alternatively search on different fitness landscapes since representations are highly related to the search space that essentially defines the fitness landscape. Fully using the latent synergies among different GP individual representations might be helpful for GP to search for better solutions. However, existing GP literature rarely investigates the simultaneous effective use of evolving multiple representations. To fill this gap, this paper proposes a multi-representation GP algorithm based on tree-based and linear representations, which are two commonly used GP representations. In addition, we develop a new cross-representation crossover operator to harness the interplay between tree-based and linear representations. Empirical results show that navigating the learned knowledge between basic tree-based and linear representations successfully improves the effectiveness of GP with solely tree-based or linear representation in solving symbolic regression and dynamic job shop scheduling problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14268v1</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhixing Huang, Yi Mei, Fangfang Zhang, Mengjie Zhang, Wolfgang Banzhaf</dc:creator>
    </item>
    <item>
      <title>Green Multi-Objective Scheduling -- A memetic NSGA-III for flexible production with real-time energy cost and emissions</title>
      <link>https://arxiv.org/abs/2405.14339</link>
      <description>arXiv:2405.14339v1 Announce Type: new 
Abstract: The use of renewable energies strengthens decarbonization strategies. To integrate volatile renewable sources, energy systems require grid expansion, storage capabilities, or flexible consumption. This study focuses on industries adjusting production to real-time energy markets, offering flexible consumption to the grid. Flexible production considers not only traditional goals like minimizing production time but also minimizing energy costs and emissions, thereby enhancing the sustainability of businesses. However, existing research focuses on single goals, neglects the combination of makespan, energy costs and emissions, or assumes constant or periodic tariffs instead of a dynamic energy market. We present a novel memetic NSGA-III to minimize makespan, energy cost, and emissions, integrating real energy market data, and allowing manufacturers to adapt consumption to current grid conditions. Evaluating it with benchmark instances from literature and real energy market data, we explore the trade-offs between objectives, showcasing potential savings in energy costs and emissions on estimated Pareto fronts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14339v1</guid>
      <category>cs.NE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sascha C Burmeister</dc:creator>
    </item>
    <item>
      <title>Advancing Spiking Neural Networks for Sequential Modeling with Central Pattern Generators</title>
      <link>https://arxiv.org/abs/2405.14362</link>
      <description>arXiv:2405.14362v1 Announce Type: new 
Abstract: Spiking neural networks (SNNs) represent a promising approach to developing artificial neural networks that are both energy-efficient and biologically plausible. However, applying SNNs to sequential tasks, such as text classification and time-series forecasting, has been hindered by the challenge of creating an effective and hardware-friendly spike-form positional encoding (PE) strategy. Drawing inspiration from the central pattern generators (CPGs) in the human brain, which produce rhythmic patterned outputs without requiring rhythmic inputs, we propose a novel PE technique for SNNs, termed CPG-PE. We demonstrate that the commonly used sinusoidal PE is mathematically a specific solution to the membrane potential dynamics of a particular CPG. Moreover, extensive experiments across various domains, including time-series forecasting, natural language processing, and image classification, show that SNNs with CPG-PE outperform their conventional counterparts. Additionally, we perform analysis experiments to elucidate the mechanism through which SNNs encode positional information and to explore the function of CPGs in the human brain. This investigation may offer valuable insights into the fundamental principles of neural computation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14362v1</guid>
      <category>cs.NE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Changze Lv, Dongqi Han, Yansen Wang, Xiaoqing Zheng, Xuanjing Huang, Dongsheng Li</dc:creator>
    </item>
    <item>
      <title>Time Cell Inspired Temporal Codebook in Spiking Neural Networks for Enhanced Image Generation</title>
      <link>https://arxiv.org/abs/2405.14474</link>
      <description>arXiv:2405.14474v1 Announce Type: new 
Abstract: This paper presents a novel approach leveraging Spiking Neural Networks (SNNs) to construct a Variational Quantized Autoencoder (VQ-VAE) with a temporal codebook inspired by hippocampal time cells. This design captures and utilizes temporal dependencies, significantly enhancing the generative capabilities of SNNs. Neuroscientific research has identified hippocampal "time cells" that fire sequentially during temporally structured experiences. Our temporal codebook emulates this behavior by triggering the activation of time cell populations based on similarity measures as input stimuli pass through it. We conducted extensive experiments on standard benchmark datasets, including MNIST, FashionMNIST, CIFAR10, CelebA, and downsampled LSUN Bedroom, to validate our model's performance. Furthermore, we evaluated the effectiveness of the temporal codebook on neuromorphic datasets NMNIST and DVS-CIFAR10, and demonstrated the model's capability with high-resolution datasets such as CelebA-HQ, LSUN Bedroom, and LSUN Church. The experimental results indicate that our method consistently outperforms existing SNN-based generative models across multiple datasets, achieving state-of-the-art performance. Notably, our approach excels in generating high-resolution and temporally consistent data, underscoring the crucial role of temporal information in SNN-based generative modeling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14474v1</guid>
      <category>cs.NE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Linghao Feng, Dongcheng Zhao, Sicheng Shen, Yiting Dong, Guobin Shen, Yi Zeng</dc:creator>
    </item>
    <item>
      <title>Domain Wall Magnetic Tunnel Junction Reliable Integrate and Fire Neuron</title>
      <link>https://arxiv.org/abs/2405.14851</link>
      <description>arXiv:2405.14851v1 Announce Type: new 
Abstract: In spiking neural networks, neuron dynamics are described by the biologically realistic integrate-and-fire model that captures membrane potential accumulation and above-threshold firing behaviors. Among the hardware implementations of integrate-and-fire neuron devices, one important feature, reset, has been largely ignored. Here, we present the design and fabrication of a magnetic domain wall and magnetic tunnel junction based artificial integrate-and-fire neuron device that achieves reliable reset at the end of the integrate-fire cycle. We demonstrate the domain propagation in the domain wall racetrack (integration), reading using a magnetic tunnel junction (fire), and reset as the domain is ejected from the racetrack, showing the artificial neuron can be operated continuously over 100 integrate-fire-reset cycles. Both pulse amplitude and pulse number encoding is demonstrated. The device data is applied on an image classification task using a spiking neural network and shown to have comparable performance to an ideal leaky, integrate-and-fire neural network. These results achieve the first demonstration of reliable integrate-fire-reset in domain wall-magnetic tunnel junction-based neuron devices and shows the promise of spintronics for neuromorphic computing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14851v1</guid>
      <category>cs.NE</category>
      <category>cond-mat.mes-hall</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Can Cui1, Sam Liu, Jaesuk Kwon, Jean Anne C. Incorvia</dc:creator>
    </item>
    <item>
      <title>Combining Relevance and Magnitude for Resource-Aware DNN Pruning</title>
      <link>https://arxiv.org/abs/2405.13088</link>
      <description>arXiv:2405.13088v1 Announce Type: cross 
Abstract: Pruning neural networks, i.e., removing some of their parameters whilst retaining their accuracy, is one of the main ways to reduce the latency of a machine learning pipeline, especially in resource- and/or bandwidth-constrained scenarios. In this context, the pruning technique, i.e., how to choose the parameters to remove, is critical to the system performance. In this paper, we propose a novel pruning approach, called FlexRel and predicated upon combining training-time and inference-time information, namely, parameter magnitude and relevance, in order to improve the resulting accuracy whilst saving both computational resources and bandwidth. Our performance evaluation shows that FlexRel is able to achieve higher pruning factors, saving over 35% bandwidth for typical accuracy targets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13088v1</guid>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Carla Fabiana Chiasserini, Francesco Malandrino, Nuria Molner, Zhiqiang Zhao</dc:creator>
    </item>
    <item>
      <title>Contribute to balance, wire in accordance: Emergence of backpropagation from a simple, bio-plausible neuroplasticity rule</title>
      <link>https://arxiv.org/abs/2405.14139</link>
      <description>arXiv:2405.14139v1 Announce Type: cross 
Abstract: Backpropagation (BP) has been pivotal in advancing machine learning and remains essential in computational applications and comparative studies of biological and artificial neural networks. Despite its widespread use, the implementation of BP in the brain remains elusive, and its biological plausibility is often questioned due to inherent issues such as the need for symmetry of weights between forward and backward connections, and the requirement of distinct forward and backward phases of computation. Here, we introduce a novel neuroplasticity rule that offers a potential mechanism for implementing BP in the brain. Similar in general form to the classical Hebbian rule, this rule is based on the core principles of maintaining the balance of excitatory and inhibitory inputs as well as on retrograde signaling, and operates over three progressively slower timescales: neural firing, retrograde signaling, and neural plasticity. We hypothesize that each neuron possesses an internal state, termed credit, in addition to its firing rate. After achieving equilibrium in firing rates, neurons receive credits based on their contribution to the E-I balance of postsynaptic neurons through retrograde signaling. As the network's credit distribution stabilizes, connections from those presynaptic neurons are strengthened that significantly contribute to the balance of postsynaptic neurons. We demonstrate mathematically that our learning rule precisely replicates BP in layered neural networks without any approximations. Simulations on artificial neural networks reveal that this rule induces varying community structures in networks, depending on the learning rate. This simple theoretical framework presents a biologically plausible implementation of BP, with testable assumptions and predictions that may be evaluated through biological experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14139v1</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Xinhao Fan, Shreesh P Mysore</dc:creator>
    </item>
    <item>
      <title>Neuro-Vision to Language: Enhancing Visual Reconstruction and Language Interaction through Brain Recordings</title>
      <link>https://arxiv.org/abs/2404.19438</link>
      <description>arXiv:2404.19438v3 Announce Type: replace 
Abstract: Decoding non-invasive brain recordings is pivotal for advancing our understanding of human cognition but faces challenges due to individual differences and complex neural signal representations. Traditional methods often require customized models and extensive trials, lacking interpretability in visual reconstruction tasks. Our framework integrates 3D brain structures with visual semantics using a Vision Transformer 3D. This unified feature extractor efficiently aligns fMRI features with multiple levels of visual embeddings, eliminating the need for subject-specific models and allowing extraction from single-trial data. The extractor consolidates multi-level visual features into one network, simplifying integration with Large Language Models (LLMs). Additionally, we have enhanced the fMRI dataset with diverse fMRI-image-related textual data to support multimodal large model development. Integrating with LLMs enhances decoding capabilities, enabling tasks such as brain captioning, complex reasoning, concept localization, and visual reconstruction. Our approach demonstrates superior performance across these tasks, precisely identifying language-based concepts within brain signals, enhancing interpretability, and providing deeper insights into neural processes. These advances significantly broaden the applicability of non-invasive brain decoding in neuroscience and human-computer interaction, setting the stage for advanced brain-computer interfaces and cognitive models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.19438v3</guid>
      <category>cs.NE</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guobin Shen, Dongcheng Zhao, Xiang He, Linghao Feng, Yiting Dong, Jihang Wang, Qian Zhang, Yi Zeng</dc:creator>
    </item>
    <item>
      <title>Early years of Biased Random-Key Genetic Algorithms: A systematic review</title>
      <link>https://arxiv.org/abs/2405.01765</link>
      <description>arXiv:2405.01765v3 Announce Type: replace 
Abstract: This paper presents a systematic literature review and bibliometric analysis focusing on Biased Random-Key Genetic Algorithms (BRKGA). BRKGA is a metaheuristic framework that uses random-key-based chromosomes with biased, uniform, and elitist mating strategies alongside a genetic algorithm. This review encompasses around~250 papers, covering a diverse array of applications ranging from classical combinatorial optimization problems to real-world industrial scenarios, and even non-traditional applications like hyperparameter tuning in machine learning and scenario generation for two-stage problems. In summary, this study offers a comprehensive examination of the BRKGA metaheuristic and its various applications, shedding light on key areas for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01765v3</guid>
      <category>cs.NE</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mariana A. Londe, Luciana S. Pessoa, Cartlos E. Andrade, Mauricio G. C. Resende</dc:creator>
    </item>
    <item>
      <title>Exploring the Improvement of Evolutionary Computation via Large Language Models</title>
      <link>https://arxiv.org/abs/2405.02876</link>
      <description>arXiv:2405.02876v2 Announce Type: replace 
Abstract: Evolutionary computation (EC), as a powerful optimization algorithm, has been applied across various domains. However, as the complexity of problems increases, the limitations of EC have become more apparent. The advent of large language models (LLMs) has not only transformed natural language processing but also extended their capabilities to diverse fields. By harnessing LLMs' vast knowledge and adaptive capabilities, we provide a forward-looking overview of potential improvements LLMs can bring to EC, focusing on the algorithms themselves, population design, and additional enhancements. This presents a promising direction for future research at the intersection of LLMs and EC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02876v2</guid>
      <category>cs.NE</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jinyu Cai, Jinglue Xu, Jialong Li, Takuto Ymauchi, Hitoshi Iba, Kenji Tei</dc:creator>
    </item>
    <item>
      <title>All-to-all reconfigurability with sparse and higher-order Ising machines</title>
      <link>https://arxiv.org/abs/2312.08748</link>
      <description>arXiv:2312.08748v2 Announce Type: replace-cross 
Abstract: Domain-specific hardware to solve computationally hard optimization problems has generated tremendous excitement recently. Here, we evaluate probabilistic bit (p-bit) based on Ising Machines (IM) or p-computers with a benchmark combinatorial optimization problem, namely the 3-regular 3-XOR Satisfiability (3R3X). The 3R3X problem has a glassy energy landscape, and it has recently been used to benchmark various IMs and other solvers. We introduce a multiplexed architecture where p-computers emulate all-to-all (complete) graph functionality despite being interconnected in sparse networks, enabling a highly parallelized chromatic Gibbs sampling. We implement this architecture in FPGAs and show that p-bit networks running an adaptive version of the powerful parallel tempering algorithm demonstrate competitive algorithmic and prefactor advantages over alternative IMs by D-Wave, Toshiba, and Fujitsu, except a greedy algorithm accelerated on a GPU. We further extend our APT results using higher-order interactions in FPGAs and show that while higher-order interactions lead to prefactor advantages, they do not show any algorithmic scaling advantages for the XORSAT problem, settling an open conjecture. Even though FPGA implementations of p-bits are still not quite as fast as the best possible greedy algorithms implemented in GPUs, scaled magnetic versions of p-computers could lead to orders of magnitude over such algorithms according to experimentally established projections.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.08748v2</guid>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <category>cs.NE</category>
      <category>quant-ph</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Srijan Nikhar, Sidharth Kannan, Navid Anjum Aadit, Shuvro Chowdhury, Kerem Y. Camsari</dc:creator>
    </item>
    <item>
      <title>MorphGrower: A Synchronized Layer-by-layer Growing Approach for Plausible Neuronal Morphology Generation</title>
      <link>https://arxiv.org/abs/2401.09500</link>
      <description>arXiv:2401.09500v2 Announce Type: replace-cross 
Abstract: Neuronal morphology is essential for studying brain functioning and understanding neurodegenerative disorders. As acquiring real-world morphology data is expensive, computational approaches for morphology generation have been studied. Traditional methods heavily rely on expert-set rules and parameter tuning, making it difficult to generalize across different types of morphologies. Recently, MorphVAE was introduced as the sole learning-based method, but its generated morphologies lack plausibility, i.e., they do not appear realistic enough and most of the generated samples are topologically invalid. To fill this gap, this paper proposes MorphGrower, which mimicks the neuron natural growth mechanism for generation. Specifically, MorphGrower generates morphologies layer by layer, with each subsequent layer conditioned on the previously generated structure. During each layer generation, MorphGrower utilizes a pair of sibling branches as the basic generation block and generates branch pairs synchronously. This approach ensures topological validity and allows for fine-grained generation, thereby enhancing the realism of the final generated morphologies. Results on four real-world datasets demonstrate that MorphGrower outperforms MorphVAE by a notable margin. Importantly, the electrophysiological response simulation demonstrates the plausibility of our generated samples from a neuroscience perspective. Our code is available at https://github.com/Thinklab-SJTU/MorphGrower.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.09500v2</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nianzu Yang, Kaipeng Zeng, Haotian Lu, Yexin Wu, Zexin Yuan, Danni Chen, Shengdian Jiang, Jiaxiang Wu, Yimin Wang, Junchi Yan</dc:creator>
    </item>
    <item>
      <title>Universal Post-Training Reverse-Engineering Defense Against Backdoors in Deep Neural Networks</title>
      <link>https://arxiv.org/abs/2402.02034</link>
      <description>arXiv:2402.02034v2 Announce Type: replace-cross 
Abstract: A variety of defenses have been proposed against backdoors attacks on deep neural network (DNN) classifiers. Universal methods seek to reliably detect and/or mitigate backdoors irrespective of the incorporation mechanism used by the attacker, while reverse-engineering methods often explicitly assume one. In this paper, we describe a new detector that: relies on internal feature map of the defended DNN to detect and reverse-engineer the backdoor and identify its target class; can operate post-training (without access to the training dataset); is highly effective for various incorporation mechanisms (i.e., is universal); and which has low computational overhead and so is scalable. Our detection approach is evaluated for different attacks on benchmark CIFAR-10 and CIFAR-100 image classifiers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.02034v2</guid>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xi Li, Hang Wang, David J. Miller, George Kesidis</dc:creator>
    </item>
    <item>
      <title>Breaking Free: How to Hack Safety Guardrails in Black-Box Diffusion Models!</title>
      <link>https://arxiv.org/abs/2402.04699</link>
      <description>arXiv:2402.04699v2 Announce Type: replace-cross 
Abstract: Deep neural networks can be exploited using natural adversarial samples, which do not impact human perception. Current approaches often rely on deep neural networks' white-box nature to generate these adversarial samples or synthetically alter the distribution of adversarial samples compared to the training distribution. In contrast, we propose EvoSeed, a novel evolutionary strategy-based algorithmic framework for generating photo-realistic natural adversarial samples. Our EvoSeed framework uses auxiliary Conditional Diffusion and Classifier models to operate in a black-box setting. We employ CMA-ES to optimize the search for an initial seed vector, which, when processed by the Conditional Diffusion Model, results in the natural adversarial sample misclassified by the Classifier Model. Experiments show that generated adversarial images are of high image quality, raising concerns about generating harmful content bypassing safety classifiers. Our research opens new avenues to understanding the limitations of current safety mechanisms and the risk of plausible attacks against classifier systems using image generation. Project Website can be accessed at: https://shashankkotyan.github.io/EvoSeed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.04699v2</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shashank Kotyan, Po-Yuan Mao, Pin-Yu Chen, Danilo Vasconcellos Vargas</dc:creator>
    </item>
    <item>
      <title>Ant Colony Sampling with GFlowNets for Combinatorial Optimization</title>
      <link>https://arxiv.org/abs/2403.07041</link>
      <description>arXiv:2403.07041v2 Announce Type: replace-cross 
Abstract: This paper introduces the Generative Flow Ant Colony Sampler (GFACS), a neural-guided probabilistic search algorithm for solving combinatorial optimization (CO). GFACS integrates generative flow networks (GFlowNets), an emerging amortized inference method, with ant colony optimization (ACO), a promising probabilistic search algorithm. Specifically, we use GFlowNets to learn a constructive policy in combinatorial spaces for enhancing ACO by providing an informed prior distribution over decision variables conditioned on input graph instances. Furthermore, we introduce a novel off-policy training algorithm for scaling conditional GFlowNets into large-scale combinatorial spaces by leveraging local search and shared energy normalization. Our experimental results demonstrate that GFACS outperforms baseline ACO algorithms in seven CO tasks and is competitive with problem-specific heuristics for vehicle routing problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07041v2</guid>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Minsu Kim, Sanghyeok Choi, Hyeonah Kim, Jiwoo Son, Jinkyoo Park, Yoshua Bengio</dc:creator>
    </item>
  </channel>
</rss>
