<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.ao-ph updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.ao-ph</link>
    <description>physics.ao-ph updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.ao-ph" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 14 Oct 2025 04:01:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Top-of-atmosphere radiation fields over the last millennium reconstructed from proxies</title>
      <link>https://arxiv.org/abs/2510.09896</link>
      <description>arXiv:2510.09896v1 Announce Type: new 
Abstract: Earth's energy imbalance at the top of the atmosphere is a key climate system metric, but its variability is poorly constrained by the short observational record and large uncertainty in coupled climate models. While existing ocean heat content reconstructions offer a longer perspective, they cannot separate the contributions of shortwave and longwave radiation, obscuring the underlying processes. We extend the energy budget record by reconstructing the top-of-atmosphere radiation and related surface variables over the last millennium (850--2000 CE). Our method combines proxy data and model dynamics using seasonal, gridded data assimilation, exploiting the covariance of radiation with proxies sensitive to surface temperatures. The method validates well in a pseudoproxy experiment and against instrumental observations. We find that a last-millennium cooling trend coincides with heat loss that gradually slowed, although there are intermittent multidecadal periods of energy gain. The cooling trend is associated with a southwestward shift of Indo--Pacific convection and growth of sea ice, with seasonal sea ice trends following orbital-scale changes in polar insolation. We also find that the upper-ocean heat content following large volcanic eruptions does not begin to recover until 5--10 years later, suggesting the initiation of the Little Ice Age by decadally-paced eruptions in the early 1100s and late 1200s. Indeed, the latter period marks the decade of largest energy loss over the last millennium. Our reconstruction reveals that the energy imbalance for all 20-yr periods after 1980 is unprecedented in the pre-industrial period.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.09896v1</guid>
      <category>physics.ao-ph</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dominik Stiller, Gregory J. Hakim</dc:creator>
    </item>
    <item>
      <title>Generative Modeling of Aerosol State Representations</title>
      <link>https://arxiv.org/abs/2510.10361</link>
      <description>arXiv:2510.10361v1 Announce Type: new 
Abstract: Aerosol-cloud--radiation interactions remain among the most uncertain components of the Earth's climate system, in partdue to the high dimensionality of aerosol state representations and the difficulty of obtaining complete \textit{in situ} measurements. Addressing these challenges requires methods that distill complex aerosol properties into compact yet physically meaningful forms. Generative autoencoder models provide such a pathway. We present a framework for learning deep variational autoencoder (VAE) models of speciated mass and number concentration distributions, which capture detailed aerosol size-composition characteristics. By compressing hundreds of original dimensions into ten latent variables, the approach enables efficient storage and processing while preserving the fidelity of key diagnostics, including cloud condensation nuclei (CCN) spectra, optical scattering and absorption coefficients, and ice nucleation properties. Results show that CCN spectra are easiest to reconstruct accurately, optical properties are moderately difficult, and ice nucleation properties are the most challenging. To improve performance, we introduce a preprocessing optimization strategy that avoids repeated retraining and yields latent representations resilient to high-magnitude Gaussian noise, boosting accuracy for CCN spectra, optical coefficients, and frozen fraction spectra. Finally, we propose a novel realism metric -- based on the sliced Wasserstein distance between generated samples and a held-out test set -- for optimizing the KL divergence weight in VAEs. Together, these contributions enable compact, robust, and physically meaningful representations of aerosol states for large-scale climate applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.10361v1</guid>
      <category>physics.ao-ph</category>
      <category>cs.LG</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ehsan Saleh, Saba Ghaffari, Jeffrey H. Curtis, Lekha Patel, Peter A. Bosler, Nicole Riemer, Matthew West</dc:creator>
    </item>
    <item>
      <title>Interactive Atmospheric Composition Emulation for Next-Generation Earth System Models</title>
      <link>https://arxiv.org/abs/2510.10654</link>
      <description>arXiv:2510.10654v1 Announce Type: new 
Abstract: Interactive composition simulations in Earth System Models (ESMs) are computationally expensive as they transport numerous gaseous and aerosol tracers at each timestep. This limits higher-resolution transient climate simulations with current computational resources. ESMs like NASA GISS-ModelE3 (ModelE) often use pre-computed monthly-averaged atmospheric composition concentrations (Non-Interactive Tracers or NINT) to reduce computational costs. While NINT significantly cuts computations, it fails to capture real-time feedback between aerosols and other climate processes by relying on pre-calculated fields. We extended the ModelE NINT version using machine learning (ML) to create Smart NINT, which emulates interactive emissions. Smart NINT interactively calculates concentrations using ML with surface emissions and meteorological data as inputs, avoiding full physics parameterizations. Our approach utilizes a spatiotemporal architecture that possesses a well-matched inductive bias to effectively capture the spatial and temporal dependencies in tracer evolution. Input data processed through the first 20 vertical levels (from the surface up to 656 hPa) using the ModelE OMA scheme. This vertical range covers nearly the entire BCB concentration distribution in the troposphere, where significant variation on short time horizons due to surface-level emissions is observed. Our evaluation shows excellent model performance with R-squared values of 0.92 and Pearson-r of 0.96 at the first pressure level. This high performance continues through level 15 (808.5 hPa), then gradually decreases as BCB concentrations drop significantly. The model maintains acceptable performance even when tested on data from entirely different periods outside the training domain, which is a crucial capability for climate modeling applications requiring reliable long-term projections.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.10654v1</guid>
      <category>physics.ao-ph</category>
      <category>cs.LG</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Seyed Mohammad Hassan Erfani, Kara Lamb, Susanne Bauer, Kostas Tsigaridis, Marcus van Lier-Walqui, Gavin Schmidt</dc:creator>
    </item>
    <item>
      <title>From deep to shallow water 2D wave turbulence: Emergence of soliton gas</title>
      <link>https://arxiv.org/abs/2510.09637</link>
      <description>arXiv:2510.09637v1 Announce Type: cross 
Abstract: Experiments on 2D random water wave propagation in a large wave tank are analyzed when the effect of dispersion changes. A stereoscopic profilometry technique is used to measure the water surface displacement resolved in both time and space over a significant fraction of the wave tank. The wave regimes are characterized by analyzing the space-time spectral statistical properties of the wave field. At a given, finite, water depth, the effect of dispersion can be varied by tuning the peak frequency of the wave generation. In shallow water conditions, the waves are only weakly dispersive and this enables the propagation of solitons. {In these conditions random wave forcing produces soliton gases}. In deep water conditions, the waves are dispersive and for wideband spectra, one observes the development of weak turbulence. A transition between these regimes is observed when changing the peak forcing frequency (dispersion) and the wave amplitude (nonlinearity), with a clear threshold between states with solitons and soliton-less states. The development of a soliton gas is associated with a strong change of the wave spectrum as well as a significant evolution of the distribution of the water elevation. We also observed a strong effect of the finite size of the tank due to the peculiar reflection laws of line solitons.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.09637v1</guid>
      <category>physics.flu-dyn</category>
      <category>nlin.PS</category>
      <category>nlin.SI</category>
      <category>physics.ao-ph</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thibault Leduque, Maxime Kaczmarek, Herv\'e Michallet, Eric Barth\'elemy, Nicolas Mordant</dc:creator>
    </item>
    <item>
      <title>Chlorophyll-a Mapping and Prediction in the Mar Menor Lagoon Using C2RCC-Processed Sentinel 2 Imagery</title>
      <link>https://arxiv.org/abs/2510.09736</link>
      <description>arXiv:2510.09736v1 Announce Type: cross 
Abstract: The Mar Menor, Europe's largest coastal lagoon, located in Spain, has undergone severe eutrophication crises. Monitoring chlorophyll-a (Chl-a) is essential to anticipate harmful algal blooms and guide mitigation. Traditional in situ measurements are spatially and temporally limited. Satellite-based approaches provide a more comprehensive view, enabling scalable, long-term, and transferable monitoring. This study aims to overcome limitations of chlorophyll monitoring, often restricted to surface estimates or limited temporal coverage, by developing a reliable methodology to predict and map Chl-a across the water column of the Mar Menor. The work integrates Sentinel 2 imagery with buoy-based ground truth to create models capable of high-resolution, depth-specific monitoring, enhancing early-warning capabilities for eutrophication. Nearly a decade of Sentinel 2 images was atmospherically corrected using C2RCC processors. Buoy data were aggregated by depth (0-1 m, 1-2 m, 2-3 m, 3-4 m). Multiple ML and DL algorithms-including RF, XGBoost, CatBoost, Multilater Perceptron Networks, and ensembles-were trained and validated using cross-validation. Systematic band-combination experiments and spatial aggregation strategies were tested to optimize prediction. Results show depth-dependent performance. At the surface, C2X-Complex with XGBoost and ensemble models achieved R2 = 0.89; at 1-2 m, CatBoost and ensemble models reached R2 = 0.87; at 2-3 m, TOA reflectances with KNN performed best (R2 = 0.81); while at 3-4 m, RF achieved R2 = 0.66. Generated maps successfully reproduced known eutrophication events (e.g., 2016 crisis, 2025 surge), confirming robustness. The study delivers an end-to-end, validated methodology for depth-specific Chl-amapping. Its integration of multispectral band combinations, buoy calibration, and ML/DL modeling offers a transferable framework for other turbid coastal systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.09736v1</guid>
      <category>eess.IV</category>
      <category>cs.AI</category>
      <category>physics.ao-ph</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Antonio Mart\'inez-Ibarra, Aurora Gonz\'alez-Vidal, Adri\'an C\'anovas-Rodr\'iguez, Antonio F. Skarmeta</dc:creator>
    </item>
    <item>
      <title>Principled Operator Learning in Ocean Dynamics: The Role of Temporal Structure</title>
      <link>https://arxiv.org/abs/2510.09792</link>
      <description>arXiv:2510.09792v1 Announce Type: cross 
Abstract: Neural operators are becoming the default tools to learn solutions to governing partial differential equations (PDEs) in weather and ocean forecasting applications. Despite early promising achievements, significant challenges remain, including long-term prediction stability and adherence to physical laws, particularly for high-frequency processes. In this paper, we take a step toward addressing these challenges in high-resolution ocean prediction by incorporating temporal Fourier modes, demonstrating how this modification enhances physical fidelity. This study compares the standard Fourier Neural Operator (FNO) with its variant, FNOtD, which has been modified to internalize the dispersion relation while learning the solution operator for ocean PDEs. The results demonstrate that entangling space and time in the training of integral kernels enables the model to capture multiscale wave propagation and effectively learn ocean dynamics. FNOtD substantially improves long-term prediction stability and consistency with underlying physical dynamics in challenging high-frequency settings compared to the standard FNO. It also provides competitive predictive skill relative to a state-of-the-art numerical ocean model, while requiring significantly lower computational cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.09792v1</guid>
      <category>cs.LG</category>
      <category>physics.ao-ph</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vahidreza Jahanmard, Ali Ramezani-Kebrya, Robinson Hordoir</dc:creator>
    </item>
    <item>
      <title>Probabilistic bias adjustment of seasonal predictions of Arctic Sea Ice Concentration</title>
      <link>https://arxiv.org/abs/2510.09891</link>
      <description>arXiv:2510.09891v1 Announce Type: cross 
Abstract: Seasonal forecast of Arctic sea ice concentration is key to mitigate the negative impact and assess potential opportunities posed by the rapid decline of sea ice coverage. Seasonal prediction systems based on climate models often show systematic biases and complex spatio-temporal errors that grow with the forecasts. Consequently, operational predictions are routinely bias corrected and calibrated using retrospective forecasts. For predictions of Arctic sea ice concentration, error corrections are mainly based on one-to-one post-processing methods including climatological mean or linear regression correction and, more recently, machine learning. Such deterministic adjustments are confined at best to the limited number of costly-to-run ensemble members of the raw forecast. However, decision-making requires proper quantification of uncertainty and likelihood of events, particularly of extremes. We introduce a probabilistic error correction framework based on a conditional Variational Autoencoder model to map the conditional distribution of observations given the biased model prediction. This method naturally allows for generating large ensembles of adjusted forecasts. We evaluate our model using deterministic and probabilistic metrics and show that the adjusted forecasts are better calibrated, closer to the observational distribution, and have smaller errors than climatological mean adjusted forecasts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.09891v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>physics.ao-ph</category>
      <category>stat.ML</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Parsa Gooya, Reinel Sospedra-Alfonso</dc:creator>
    </item>
    <item>
      <title>Rethinking deep learning: linear regression remains a key benchmark in predicting terrestrial water storage</title>
      <link>https://arxiv.org/abs/2510.10799</link>
      <description>arXiv:2510.10799v1 Announce Type: cross 
Abstract: Recent advances in machine learning such as Long Short-Term Memory (LSTM) models and Transformers have been widely adopted in hydrological applications, demonstrating impressive performance amongst deep learning models and outperforming physical models in various tasks. However, their superiority in predicting land surface states such as terrestrial water storage (TWS) that are dominated by many factors such as natural variability and human driven modifications remains unclear. Here, using the open-access, globally representative HydroGlobe dataset - comprising a baseline version derived solely from a land surface model simulation and an advanced version incorporating multi-source remote sensing data assimilation - we show that linear regression is a robust benchmark, outperforming the more complex LSTM and Temporal Fusion Transformer for TWS prediction. Our findings highlight the importance of including traditional statistical models as benchmarks when developing and evaluating deep learning models. Additionally, we emphasize the critical need to establish globally representative benchmark datasets that capture the combined impact of natural variability and human interventions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.10799v1</guid>
      <category>cs.LG</category>
      <category>physics.ao-ph</category>
      <category>physics.geo-ph</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wanshu Nie, Sujay V. Kumar, Junyu Chen, Long Zhao, Olya Skulovich, Jinwoong Yoo, Justin Pflug, Shahryar Khalique Ahmad, Goutam Konapala</dc:creator>
    </item>
    <item>
      <title>A novel spatial distribution method for wind farm parameterizations based on the Gaussian function</title>
      <link>https://arxiv.org/abs/2510.11392</link>
      <description>arXiv:2510.11392v1 Announce Type: cross 
Abstract: Wind farm parameterizations are crucial for quantifying the wind-farm atmosphere interaction, where wind turbines are typically modeled as elevated momentum sinks and sources of turbulence kinetic energy (TKE). These quantities must be properly distributed to the mesoscale grid. Existing parameterizations use the single-column method. However, this method can easily lead to the errors of the spatial distribution of the sink and source, thereby impacting the accuracy of mesoscale flow simulations. To this end, we propose a multi-column spatial distribution method based on the Gaussian function. This method distributes the sink and source to multiple vertical grid columns based on the grid weights, which are analytically determined by integrating the two-dimensional Gaussian function over the mesoscale grid. We have applied this method to the classic Fitch model, proposed the improved Fitch-Gaussian model, and integrated it into the mesoscale Weather Research and Forecasting model. Using high-fidelity large eddy simulation as a benchmark, we compared the performance of the proposed method with the single-column method. The results show that the proposed method captures the spatial distribution of the sink and source more accurately, with a higher correlation coefficient and lower normalized root mean square error. Furthermore, the Fitch-Gaussian model better captures the overall spatial distribution patterns of velocity deficit and added TKE. Therefore, the proposed method is recommended for future mesoscale wind farm simulations, especially when the influence of the wind turbine rotor spans multiple mesoscale grid columns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.11392v1</guid>
      <category>physics.flu-dyn</category>
      <category>physics.ao-ph</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bowen Du, Qi Li, Mingwei Ge, Xintao Li, Yongqian Liu</dc:creator>
    </item>
    <item>
      <title>Is methane the 'climate culprit'? The dangers of using imprecise, long-term GWP for methane to address the climate emergency</title>
      <link>https://arxiv.org/abs/2409.06212</link>
      <description>arXiv:2409.06212v3 Announce Type: replace 
Abstract: The United Nations Environmental Program's (UNEP) Emissions Gap Report, 2023, Temperatures hit new highs, yet world fails to cut emissions (again)'', and in 2024, No more hot air, emissions' massive gap between rhetoric and reality''. A climate emergency has been declared yet policies and emission reductions continue to fail. Global temperature anomalies in recent years have not been modelled well. Methane (CH4) is a potent greenhouse gas (GHG) with a short atmospheric half-life (~8.4 years), and a perturbation lifetime of 11.8 $\pm$ 1.8 yrs (IPCC AR6). It has a high, short-term impact on global warming: substantially greater than CO2. Traditional metrics such as the 100-year Global Warming Potential (GWP100) obscure the short-term, negative climatic effects of CH4, potentially leading to inadequate policy responses. This study examines the limitations of GWP100 in capturing the true, immediate climate impact of CH4 and its inability to incorporate varying emissions, explores alternative metrics, and discusses the multi-faceted implications of this under-reporting of CH4 emissions. Recalculation of 2024 Emissions Gap Report using a ten-year GWP of 105 increased CH4's warming effect to almost 90% of CO2, rather than 25% using a GWP100 of 28. We highlight the necessity of adopting a more immediate time horizon for CH4's warming effects, accelerating climate emergency action, while recognizing the adverse effects of the rapid growth rate of CH4 emissions on reduction efforts. To overcome the limitations of GWP100, a static constant, we propose GWPEFF(t) which dynamically represents warming across various time periods. It is a novel, physically realistic measure that is simple to understand, and effective for policies in reducing short-term emissions such as CH4.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06212v3</guid>
      <category>physics.ao-ph</category>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Roger W. Bryenton, Farrukh A. Chishtie, T. Andrew Black, Mujtaba Hassan, Tom Mommsen, Devyani Singh</dc:creator>
    </item>
    <item>
      <title>Assessing submesoscale sea surface height signals from the SWOT mission</title>
      <link>https://arxiv.org/abs/2505.09856</link>
      <description>arXiv:2505.09856v2 Announce Type: replace 
Abstract: The sea surface height (SSH) field measured by Surface Water and Ocean Topography (SWOT) mission's wide-swath altimeter is analyzed with a focus on submesoscale features. Along-track wavenumber spectra of SSH variance are estimated for the global ocean using the 1-day repeat period from March 26 to July 10, 2023. In regions with an energetic mesoscale eddy field, the spectra have a mesoscale plateau, a steep drop-off due to balanced submesoscale turbulence, and a much flatter power-law tail at small scales. These spectra are characterized by fitting a spectral model. For the balanced signal, this fit yields a power law exponent between -4 and -6 for most regions, broadly consistent with expectations and previous observations. The amplitude of the distinct small-scale signal, which typically dominates at wavelengths less than 30 to 50 km, is strongly correlated in time and space with the height of surface gravity waves, suggesting aliased wave signals as the most likely source. A simple method is proposed to isolate the balanced signal in regions with negligible internal tides. Maps of the balanced signal in the Antarctic Circumpolar Current show compact cyclones with geostrophic relative vorticities frequently in excess of the local planetary vorticity, challenging the quasi-geostrophic framework commonly used to interpret altimetric data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09856v2</guid>
      <category>physics.ao-ph</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xihan Zhang, J\"orn Callies</dc:creator>
    </item>
    <item>
      <title>Generative artificial intelligence improves projections of climate extremes</title>
      <link>https://arxiv.org/abs/2508.16396</link>
      <description>arXiv:2508.16396v2 Announce Type: replace 
Abstract: Climate change is amplifying extreme events, posing escalating risks to biodiversity, human health, and food security. GCMs are essential for projecting future climate, yet their coarse resolution and high computational costs constrain their ability to represent extremes. Here, we introduce FuXi-CMIPAlign, a generative deep learning framework for downscaling CMIP outputs. The model integrates Flow Matching for generative modeling with domain adaptation via MMD loss to align feature distributions between training data and inference data, thereby mitigating input discrepancies and improving accuracy, stability, and generalization across emission scenarios. FuXi-CMIPAlign performs spatial, temporal, and multivariate downscaling, enabling more realistic simulation of compound extremes such as TCs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16396v2</guid>
      <category>physics.ao-ph</category>
      <category>cs.AI</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ruian Tie, Xiaohui Zhong, Zhengyu Shi, Hao Li, Bin Chen, Jun Liu, Wu Libo</dc:creator>
    </item>
    <item>
      <title>Project Severe Weather Archive of the Philippines (SWAP) Part 2: Baseline Climatology of Close Proximity Soundings in Hailstorm Environments across Luzon, Philippines</title>
      <link>https://arxiv.org/abs/2510.09530</link>
      <description>arXiv:2510.09530v2 Announce Type: replace 
Abstract: The environments of severe thunderstorms that produced hail were examined using 171 proximity soundings (2005-2024) archived in the 3rd Data Release of Project SWAP. These soundings were categorized based on their geographical occurrence into three hail-prone environments across Luzon, Philippines. For each case, key parameters describing instability, vertical wind shear, and moisture were calculated to assess the conditions for hail production. The probability of hail occurrence, expressed as a function of W$_{\text{MAX}}$ ($\sqrt{2 \times \text{CAPE}}$) and 0-6 km bulk shear (DLS), revealed patterns distinct from those reported in other regions. Hail events in Luzon were most likely under high CAPE conditions, where boundary-layer moisture was sufficient, mid- and low-level lapse rates were steep, and lifting condensation levels were high. Surprisingly, weak DLS was common across Luzon hail environments, diverging from existing severe weather climatologies, yet large DCAPE indicated environments conducive to damaging wind events. When DLS was replaced with the shear magnitude between the cloud base and equilibrium level, the probability of hail occurrence increased, better aligning with global severe weather climatologies. This finding is supported by hodograph analyses, which show largely unidirectional wind profiles: strong speed shear aloft but weak directional shear in the low-levels. Parameters such as W$_{\text{MAX}}$SHEAR, W$_{\text{MAX}}$SHEAR$_{\text{LCL-EL}}$, and BWD$_{\text{LCL-EL}}$ emerge as potential discriminators between non-severe and severe thunderstorms capable of producing hail, and as useful metrics for assessing convective storm severity in Luzon and possibly countrywide. Finally, two recurring severe setups conducive to hail were identified: (1) an easterly regime associated with trade winds, and (2) a westerly regime linked to the Asian summer monsoon.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.09530v2</guid>
      <category>physics.ao-ph</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Generich H. Capuli</dc:creator>
    </item>
    <item>
      <title>Growth rate and energy dissipation in wind-forced breaking waves</title>
      <link>https://arxiv.org/abs/2506.17802</link>
      <description>arXiv:2506.17802v2 Announce Type: replace-cross 
Abstract: We investigate the energy growth and dissipation of wind-forced breaking waves at high wind speed using direct numerical simulations of the coupled air-water Navier-Stokes equations. A turbulent wind boundary layer drives the growth of a pre-existing narrowband wave field until it breaks, transferring energy into the water column. Under sustained wind forcing, the wave field resumes growth. We separately analyze energy transfers during wave growth and breaking-induced dissipation. Energy transfers are dominated by pressure input during growth and turbulent dissipation during breaking. Wind input during growth is balanced with dissipation during breaking over an entire growing-breaking cycle. The wave growth rate scales with $(u_\ast/c)^2$, modulated by the wave steepness due to sheltering, and the energy dissipation follows the inertial scaling with wave slope at breaking, confirming the universality of the process. Following breaking, near-surface vertical turbulence dissipation profiles scale as $z^{-1}$, with their magnitude controlled by the breaking-induced dissipation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.17802v2</guid>
      <category>physics.flu-dyn</category>
      <category>physics.ao-ph</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicol\`o Scapin, Jiarong Wu, J. Thomas Farrar, Bertrand Chapron, St\'ephane Popinet, Luc Deike</dc:creator>
    </item>
    <item>
      <title>How Effective Are Time-Series Models for Rainfall Nowcasting? A Comprehensive Benchmark for Rainfall Nowcasting Incorporating PWV Data</title>
      <link>https://arxiv.org/abs/2509.25263</link>
      <description>arXiv:2509.25263v2 Announce Type: replace-cross 
Abstract: Rainfall nowcasting, which aims to predict precipitation within the next 0 to 3 hours, is critical for disaster mitigation and real-time response planning. However, most time series forecasting benchmarks in meteorology are evaluated on variables with strong periodicity, such as temperature and humidity, which fail to reflect model capabilities in more complex and practically meteorology scenarios like rainfall nowcasting. To address this gap, we propose RainfallBench, a benchmark designed for rainfall nowcasting, a highly challenging and practically relevant task characterized by zero inflation, temporal decay, and non-stationarity, focused on predicting precipitation within the next 0 to 3 hours. The dataset is derived from five years of meteorological observations, recorded at 15-minute intervals across six essential variables, and collected from more than 12,000 GNSS stations globally. In particular, it incorporates precipitable water vapor (PWV), a crucial indicator of rainfall that is absent in other datasets. We further design specialized evaluation strategies to assess model performance on key meteorological challenges, such as multi-scale prediction and extreme rainfall events, and evaluate over 20 state-of-the-art models across six major architectures on RainfallBench. Additionally, to address the zero-inflation and temporal decay issues overlooked by existing models, we introduce Bi-Focus Precipitation Forecaster (BFPF), a plug-and-play module that incorporates domain-specific priors to enhance rainfall time series forecasting. Statistical analysis and ablation studies validate the comprehensiveness of our dataset as well as the superiority of our methodology. Code and datasets are available at https://anonymous.4open.science/r/RainfallBench-A710.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.25263v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>physics.ao-ph</category>
      <category>stat.ML</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yifang Zhang, Pengfei Duan, Henan Wang, Wenjie Yin, Chen Zhou, Shengwu Xiong</dc:creator>
    </item>
  </channel>
</rss>
