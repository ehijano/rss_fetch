<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CY updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CY</link>
    <description>cs.CY updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CY" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 07 Nov 2025 05:01:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Levers of Power in the Field of AI</title>
      <link>https://arxiv.org/abs/2511.03859</link>
      <description>arXiv:2511.03859v1 Announce Type: new 
Abstract: This paper examines how decision makers in academia, government, business, and civil society navigate questions of power in implementations of artificial intelligence. The study explores how individuals experience and exercise levers of power, which are presented as social mechanisms that shape institutional responses to technological change. The study reports on the responses of personalized questionnaires designed to gather insight on a decision maker's institutional purview, based on an institutional governance framework developed from the work of Neo-institutionalists. Findings present the anonymized, real responses and circumstances of respondents in the form of twelve fictional personas of high-level decision makers from North America and Europe. These personas illustrate how personal agency, organizational logics, and institutional infrastructures may intersect in the governance of AI. The decision makers' responses to the questionnaires then inform a discussion of the field-level personal power of decision makers, methods of fostering institutional stability in times of change, and methods of influencing institutional change in the field of AI. The final section of the discussion presents a table of the dynamics of the levers of power in the field of AI for change makers and five testable hypotheses for institutional and social movement researchers. In summary, this study provides insight on the means for policymakers within institutions and their counterparts in civil society to personally engage with AI governance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03859v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tammy Mackenzie, Sukriti Punj, Natalie Perez, Sreyoshi Bhaduri, Branislav Radeljic</dc:creator>
    </item>
    <item>
      <title>The Benefits of Data Storytelling in Accessible Teaching</title>
      <link>https://arxiv.org/abs/2511.04024</link>
      <description>arXiv:2511.04024v1 Announce Type: new 
Abstract: Accessible teaching has been extensively investigated in computer science, yet its integration into other disciplines, such as data literacy, remains limited. This paper examines the potential of data storytelling, defined as the integration of data, visualizations, and narrative, as a possible strategy for making complex information accessible to diverse learners in compliance with Title II of the Americans with Disabilities Act (ADA). We propose six design principles, derived from Title II's core obligations, to guide educators in applying data storytelling within inclusive learning environments. A simulated scenario shows the operationalization of these principles, illustrating how narrative-driven data presentation can enhance comprehension, engagement, and equitable access across different educational contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.04024v1</guid>
      <category>cs.CY</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>2nd Workshop on Teaching Accessibility Across Disciplines (TA2D), 2025</arxiv:journal_reference>
      <dc:creator>Marina Buzzi, Barbara Leporini, Angelica Lo Duca</dc:creator>
    </item>
    <item>
      <title>The Psychogeography of Imaginary Places</title>
      <link>https://arxiv.org/abs/2511.04105</link>
      <description>arXiv:2511.04105v1 Announce Type: new 
Abstract: Psychogeography -- the study of how environments shape emotion and behaviour -- has long concerned itself with the emotional resonance of the physical, often through the idea of the derive through the city. Its philosophical core, however, is primarily concerned with identifying affective relationships between the personal and the environmental, and this does not require the constraint of concrete.
  This paper extends psychogeographical practice into the realm of the imaginary, proposing a psychogeography of virtual and fictive spaces. Drawing on literary, Situationist, and contemporary psychogeographical traditions, we examine how the derive might operate within the elastic spatiality and temporalities of video game worlds. We argue that digital environments, being wholly constructed, invite new forms of meaning-making and self-reflection. Through this reframing, games become both laboratory and landscape for a revitalised psychogeography: one attuned not only to the spirits of streets and cities, but also to the ghosts that haunt code, pixels, and play.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.04105v1</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Michael Heron, Pauline Belford, Klara Aune</dc:creator>
    </item>
    <item>
      <title>Measuring Teaching with LLMs</title>
      <link>https://arxiv.org/abs/2510.22968</link>
      <description>arXiv:2510.22968v1 Announce Type: cross 
Abstract: Objective and scalable measurement of teaching quality is a persistent challenge in education. While Large Language Models (LLMs) offer potential, general-purpose models have struggled to reliably apply complex, authentic classroom observation instruments. This paper uses custom LLMs built on sentence-level embeddings, an architecture better suited for the long-form, interpretive nature of classroom transcripts than conventional subword tokenization. We systematically evaluate five different sentence embeddings under a data-efficient training regime designed to prevent overfitting. Our results demonstrate that these specialized models can achieve human-level and even super-human performance with expert human ratings above 0.65 and surpassing the average human-human rater correlation. Further, through analysis of annotation context windows, we find that more advanced models-those better aligned with human judgments-attribute a larger share of score variation to lesson-level features rather than isolated utterances, challenging the sufficiency of single-turn annotation paradigms. Finally, to assess external validity, we find that aggregate model scores align with teacher value-added measures, indicating they are capturing features relevant to student learning. However, this trend does not hold at the individual item level, suggesting that while the models learn useful signals, they have not yet achieved full generalization. This work establishes a viable and powerful new methodology for AI-driven instructional measurement, offering a path toward providing scalable, reliable, and valid feedback for educator development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22968v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Michael Hardy</dc:creator>
    </item>
    <item>
      <title>Leveraging LLM-based agents for social science research: insights from citation network simulations</title>
      <link>https://arxiv.org/abs/2511.03758</link>
      <description>arXiv:2511.03758v1 Announce Type: cross 
Abstract: The emergence of Large Language Models (LLMs) demonstrates their potential to encapsulate the logic and patterns inherent in human behavior simulation by leveraging extensive web data pre-training. However, the boundaries of LLM capabilities in social simulation remain unclear. To further explore the social attributes of LLMs, we introduce the CiteAgent framework, designed to generate citation networks based on human-behavior simulation with LLM-based agents. CiteAgent successfully captures predominant phenomena in real-world citation networks, including power-law distribution, citational distortion, and shrinking diameter. Building on this realistic simulation, we establish two LLM-based research paradigms in social science: LLM-SE (LLM-based Survey Experiment) and LLM-LE (LLM-based Laboratory Experiment). These paradigms facilitate rigorous analyses of citation network phenomena, allowing us to validate and challenge existing theories. Additionally, we extend the research scope of traditional science of science studies through idealized social experiments, with the simulation experiment results providing valuable insights for real-world academic environments. Our work demonstrates the potential of LLMs for advancing science of science research in social science.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03758v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.MA</category>
      <category>cs.SI</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiarui Ji, Runlin Lei, Xuchen Pan, Zhewei Wei, Hao Sun, Yankai Lin, Xu Chen, Yongzheng Yang, Yaliang Li, Bolin Ding, Ji-Rong Wen</dc:creator>
    </item>
    <item>
      <title>Just in Plain Sight: Unveiling CSAM Distribution Campaigns on the Clear Web</title>
      <link>https://arxiv.org/abs/2511.03816</link>
      <description>arXiv:2511.03816v1 Announce Type: cross 
Abstract: Child sexual abuse is among the most hideous crimes, yet, after the COVID-19 pandemic, there is a huge surge in the distribution of child sexual abuse material (CSAM). Traditionally, the exchange of such material is performed on the dark web, as it provides many privacy guarantees that facilitate illicit trades. However, the introduction of end-to-end encryption platforms has brought it to the deep web. In this work, we report our findings for a campaign of spreading child sexual abuse material on the clear web. The campaign utilized at least 1,026 web pages for at least 738,286 registered users. Our analysis details the operation of such a campaign, showcasing how social networks are abused and the role of bots, but also the bypasses that are used. Going a step further and exploiting operational faults in the campaign, we gain insight into the demand for such content, as well as the dynamics of the user network that supports it.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03816v1</guid>
      <category>cs.CR</category>
      <category>cs.CY</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nikolaos Lykousas, Constantinos Patsakis</dc:creator>
    </item>
    <item>
      <title>Evaluating Machine Translation Datasets for Low-Web Data Languages: A Gendered Lens</title>
      <link>https://arxiv.org/abs/2511.03880</link>
      <description>arXiv:2511.03880v1 Announce Type: cross 
Abstract: As low-resourced languages are increasingly incorporated into NLP research, there is an emphasis on collecting large-scale datasets. But in prioritizing quantity over quality, we risk 1) building language technologies that perform poorly for these languages and 2) producing harmful content that perpetuates societal biases. In this paper, we investigate the quality of Machine Translation (MT) datasets for three low-resourced languages--Afan Oromo, Amharic, and Tigrinya, with a focus on the gender representation in the datasets. Our findings demonstrate that while training data has a large representation of political and religious domain text, benchmark datasets are focused on news, health, and sports. We also found a large skew towards the male gender--in names of persons, the grammatical gender of verbs, and in stereotypical depictions in the datasets. Further, we found harmful and toxic depictions against women, which were more prominent for the language with the largest amount of data, underscoring that quantity does not guarantee quality. We hope that our work inspires further inquiry into the datasets collected for low-resourced languages and prompts early mitigation of harmful content. WARNING: This paper contains discussion of NSFW content that some may find disturbing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03880v1</guid>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Hellina Hailu Nigatu, Bethelhem Yemane Mamo, Bontu Fufa Balcha, Debora Taye Tesfaye, Elbethel Daniel Zewdie, Ikram Behiru Nesiru, Jitu Ewnetu Hailu, Senait Mengesha Yayo</dc:creator>
    </item>
    <item>
      <title>The Human Flourishing Geographic Index: A County-Level Dataset for the United States, 2013--2023</title>
      <link>https://arxiv.org/abs/2511.03915</link>
      <description>arXiv:2511.03915v1 Announce Type: cross 
Abstract: Quantifying human flourishing, a multidimensional construct including happiness, health, purpose, virtue, relationships, and financial stability, is critical for understanding societal well-being beyond economic indicators. Existing measures often lack fine spatial and temporal resolution. Here we introduce the Human Flourishing Geographic Index (HFGI), derived from analyzing approximately 2.6 billion geolocated U.S. tweets (2013-2023) using fine-tuned large language models to classify expressions across 48 indicators aligned with Harvard's Global Flourishing Study framework plus attitudes towards migration and perception of corruption. The dataset offers monthly and yearly county- and state-level indicators of flourishing-related discourse, validated to confirm that the measures accurately represent the underlying constructs and show expected correlations with established indicators. This resource enables multidisciplinary analyses of well-being, inequality, and social change at unprecedented resolution, offering insights into the dynamics of human flourishing as reflected in social media discourse across the United States over the past decade.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03915v1</guid>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>stat.AP</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefano M. Iacus, Devika Jain, Andrea Nasuto, Giuseppe Porro, Marcello Carammia, Andrea Vezzulli</dc:creator>
    </item>
    <item>
      <title>Sub-exponential Growth in Online Word Usage: A Piecewise Power-Law Model</title>
      <link>https://arxiv.org/abs/2511.04106</link>
      <description>arXiv:2511.04106v1 Announce Type: cross 
Abstract: The diffusion of ideas and language in society has conventionally been described by S-shaped models, such as the logistic curve. However, the role of sub-exponential growth -a slower than exponential pattern known in epidemiology- has been largely overlooked in broader social phenomena. Here, we present a piecewise power-law model to characterize complex growth curves with a few parameters. We systematically analyzed a large-scale dataset of approximately one billion Japanese blog articles linked to Wikipedia vocabulary, and observed consistent patterns in web search trend data (English, Spanish, and Japanese). Our analysis of the 2,965 selected items reveals that about 55% (1,625 items) were found to have no abrupt jumps and were well captured by one or two segments. For single-segment curves, we found that (i) the mode of the shape parameter alpha was near 0.5, indicating prevalent sub-exponential growth; (ii) the ultimate diffusion scale is primarily determined by the growth rate R, with minor contributions from alpha or the duration T; and (iii) alpha showed a tendency to vary with the nature of the topic, being smaller for niche/local topics and larger for widely shared ones. Furthermore, a micro-behavioral model distinguishing outward contact with strangers from inward interaction within their community suggests that alpha can be interpreted as an index of the preference for outward-oriented communication. These findings suggest that sub-exponential growth is a common pattern of social diffusion, and our model provides a practical framework for consistently describing, comparing, and interpreting complex and diverse growth curves.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.04106v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>stat.AP</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hayafumi Watanabe</dc:creator>
    </item>
    <item>
      <title>Alternative Fairness and Accuracy Optimization in Criminal Justice</title>
      <link>https://arxiv.org/abs/2511.04505</link>
      <description>arXiv:2511.04505v1 Announce Type: cross 
Abstract: Algorithmic fairness has grown rapidly as a research area, yet key concepts remain unsettled, especially in criminal justice. We review group, individual, and process fairness and map the conditions under which they conflict. We then develop a simple modification to standard group fairness. Rather than exact parity across protected groups, we minimize a weighted error loss while keeping differences in false negative rates within a small tolerance. This makes solutions easier to find, can raise predictive accuracy, and surfaces the ethical choice of error costs. We situate this proposal within three classes of critique: biased and incomplete data, latent affirmative action, and the explosion of subgroup constraints. Finally, we offer a practical framework for deployment in public decision systems built on three pillars: need-based decisions, Transparency and accountability, and narrowly tailored definitions and solutions. Together, these elements link technical design to legitimacy and provide actionable guidance for agencies that use risk assessment and related tools.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.04505v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Proceedings of the AAAI 2026 AI Governance Workshop (AIGOV), Singapore, 2026</arxiv:journal_reference>
      <dc:creator>Shaolong Wu, James Blume, Geshi Yeung</dc:creator>
    </item>
    <item>
      <title>Question the Questions: Auditing Representation in Online Deliberative Processes</title>
      <link>https://arxiv.org/abs/2511.04588</link>
      <description>arXiv:2511.04588v1 Announce Type: cross 
Abstract: A central feature of many deliberative processes, such as citizens' assemblies and deliberative polls, is the opportunity for participants to engage directly with experts. While participants are typically invited to propose questions for expert panels, only a limited number can be selected due to time constraints. This raises the challenge of how to choose a small set of questions that best represent the interests of all participants. We introduce an auditing framework for measuring the level of representation provided by a slate of questions, based on the social choice concept known as justified representation (JR). We present the first algorithms for auditing JR in the general utility setting, with our most efficient algorithm achieving a runtime of $O(mn\log n)$, where $n$ is the number of participants and $m$ is the number of proposed questions. We apply our auditing methods to historical deliberations, comparing the representativeness of (a) the actual questions posed to the expert panel (chosen by a moderator), (b) participants' questions chosen via integer linear programming, (c) summary questions generated by large language models (LLMs). Our results highlight both the promise and current limitations of LLMs in supporting deliberative processes. By integrating our methods into an online deliberation platform that has been used for over hundreds of deliberations across more than 50 countries, we make it easy for practitioners to audit and improve representation in future deliberations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.04588v1</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Soham De, Lodewijk Gelauff, Ashish Goel, Smitha Milli, Ariel Procaccia, Alice Siu</dc:creator>
    </item>
    <item>
      <title>Students' Acceptance of Arduino Technology Integration in Student-Led Science Inquiry: Insights from the Technology Acceptance Model</title>
      <link>https://arxiv.org/abs/2511.04614</link>
      <description>arXiv:2511.04614v1 Announce Type: cross 
Abstract: This study examines high school students' acceptance of Arduino technology in a student-led, inquiry-based science class, using the extended Technology Acceptance Model (TAM2) as a guiding framework. Through qualitative analysis of interviews and classroom observations, we explored how students perceived Arduino's usefulness and ease of use. Going beyond traditional quantitative TAM studies, this qualitative TAM research provides a nuanced, in-depth understanding of the contextual factors shaping technology acceptance. Key findings reveal that acceptance was driven not only by instrumental factors like job relevance and output quality but also by the unique sociocultural context of the Korean education system, where technology use was perceived as valuable for university admissions (subjective norm and image). Critically, unlike earlier research that emphasized programming challenges, participants in this study found Arduino accessible and intuitive, thanks to integrated visual block-coding tools. These findings highlight the importance of both technological design and pedagogical support in shaping students' experiences. Implications for science curriculum design, teacher preparation, and equitable technology integration in secondary education are discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.04614v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Seok-Hyun Ga, Chun-Yen Chang, Sonya Martin</dc:creator>
    </item>
    <item>
      <title>Will Large Language Models Transform Clinical Prediction?</title>
      <link>https://arxiv.org/abs/2505.18246</link>
      <description>arXiv:2505.18246v2 Announce Type: replace 
Abstract: Objective: Large language models (LLMs) are attracting increasing interest in healthcare. This commentary evaluates the potential of LLMs to improve clinical prediction models (CPMs) for diagnostic and prognostic tasks, with a focus on their ability to process longitudinal electronic health record (EHR) data.
  Findings: LLMs show promise in handling multimodal and longitudinal EHR data and can support multi-outcome predictions for diverse health conditions. However, methodological, validation, infrastructural, and regulatory chal- lenges remain. These include inadequate methods for time-to-event modelling, poor calibration of predictions, limited external validation, and bias affecting underrepresented groups. High infrastructure costs and the absence of clear regulatory frameworks further prevent adoption.
  Implications: Further work and interdisciplinary collaboration are needed to support equitable and effective integra- tion into the clinical prediction. Developing temporally aware, fair, and explainable models should be a priority focus for transforming clinical prediction workflow.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18246v2</guid>
      <category>cs.CY</category>
      <category>cs.CL</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1186/s41512-025-00211-w</arxiv:DOI>
      <dc:creator>Yusuf Yildiz, Goran Nenadic, Meghna Jani, David A. Jenkins</dc:creator>
    </item>
    <item>
      <title>Artificial Intelligence in Elementary STEM Education: A Systematic Review of Current Applications and Future Challenges</title>
      <link>https://arxiv.org/abs/2511.00105</link>
      <description>arXiv:2511.00105v2 Announce Type: replace 
Abstract: Artificial intelligence (AI) is transforming elementary STEM education, yet evidence remains fragmented. This systematic review synthesizes 258 studies (2020-2025) examining AI applications across eight categories: intelligent tutoring systems (45% of studies), learning analytics (18%), automated assessment (12%), computer vision (8%), educational robotics (7%), multimodal sensing (6%), AI-enhanced extended reality (XR) (4%), and adaptive content generation. The analysis shows that most studies focus on upper elementary grades (65%) and mathematics (38%), with limited cross-disciplinary STEM integration (15%). While conversational AI demonstrates moderate effectiveness (d = 0.45-0.70 where reported), only 34% of studies include standardized effect sizes. Eight major gaps limit real-world impact: fragmented ecosystems, developmental inappropriateness, infrastructure barriers, lack of privacy frameworks, weak STEM integration, equity disparities, teacher marginalization, and narrow assessment scopes. Geographic distribution is also uneven, with 90% of studies originating from North America, East Asia, and Europe. Future directions call for interoperable architectures that support authentic STEM integration, grade-appropriate design, privacy-preserving analytics, and teacher-centered implementations that enhance rather than replace human expertise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00105v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Majid Memari, Krista Ruggles</dc:creator>
    </item>
    <item>
      <title>A Criminology of Machines</title>
      <link>https://arxiv.org/abs/2511.02895</link>
      <description>arXiv:2511.02895v2 Announce Type: replace 
Abstract: While the possibility of reaching human-like Artificial Intelligence (AI) remains controversial, the likelihood that the future will be characterized by a society with a growing presence of autonomous machines is high. Autonomous AI agents are already deployed and active across several industries and digital environments and alongside human-human and human-machine interactions, machine-machine interactions are poised to become increasingly prevalent. Given these developments, I argue that criminology must begin to address the implications of this transition for crime and social control. Drawing on Actor-Network Theory and Woolgar's decades-old call for a sociology of machines -- frameworks that acquire renewed relevance with the rise of generative AI agents -- I contend that criminologists should move beyond conceiving AI solely as a tool. Instead, AI agents should be recognized as entities with agency encompassing computational, social, and legal dimensions. Building on the literature on AI safety, I thus examine the risks associated with the rise of multi-agent AI systems, proposing a dual taxonomy to characterize the channels through which interactions among AI agents may generate deviant, unlawful, or criminal outcomes. I then advance and discuss four key questions that warrant theoretical and empirical attention: (1) Can we assume that machines will simply mimic humans? (2) Will crime theories developed for humans suffice to explain deviant or criminal behaviors emerging from interactions between autonomous AI agents? (3) What types of criminal behaviors will be affected first? (4) How might this unprecedented societal shift impact policing? These questions underscore the urgent need for criminologists to theoretically and empirically engage with the implications of multi-agent AI systems for the study of crime and play a more active role in debates on AI safety and governance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.02895v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>physics.soc-ph</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gian Maria Campedelli</dc:creator>
    </item>
    <item>
      <title>Biomedical Open Source Software: Crucial Packages and Hidden Heroes</title>
      <link>https://arxiv.org/abs/2404.06672</link>
      <description>arXiv:2404.06672v5 Announce Type: replace-cross 
Abstract: Despite the importance of scientific software for research, it is often not formally recognized and rewarded. This is especially true for foundational libraries, which are hidden below packages visible to the users (and thus doubly hidden, since even the packages directly used in research are frequently not visible in the paper). Research stakeholders like funders, infrastructure providers, and other organizations need to understand the complex network of computer programs that contemporary research relies upon.
  In this work, we use the CZ Software Mentions Dataset to map the upstream dependencies of software used in biomedical papers and find the packages critical to scientific software ecosystems. We propose centrality metrics for the network of software dependencies, analyze three ecosystems (PyPi, CRAN, Bioconductor), and determine the packages with the highest centrality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06672v5</guid>
      <category>cs.SE</category>
      <category>cs.CY</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eva Maxfield Brown, Stephan Druskat, Laurent H\'ebert-Dufresne, James Howison, Daniel Mietchen, Andrew Nesbitt, Jo\~ao Felipe Pimentel, Boris Veytsman</dc:creator>
    </item>
    <item>
      <title>Legal Fact Prediction: The Missing Piece in Legal Judgment Prediction</title>
      <link>https://arxiv.org/abs/2409.07055</link>
      <description>arXiv:2409.07055v3 Announce Type: replace-cross 
Abstract: Legal judgment prediction (LJP), which enables litigants and their lawyers to forecast judgment outcomes and refine litigation strategies, has emerged as a crucial legal NLP task. Existing studies typically utilize legal facts, i.e., facts that have been established by evidence and determined by the judge, to predict the judgment. However, legal facts are often difficult to obtain in the early stages of litigation, significantly limiting the practical applicability of fact-based LJP. To address this limitation, we propose a novel legal NLP task: legal fact prediction (LFP), which takes the evidence submitted by litigants for trial as input to predict legal facts, thereby empowering fact-based LJP technologies to make predictions in the absence of ground-truth legal facts. We also propose the first benchmark dataset, LFPBench, for evaluating the LFP task. Our extensive experiments on LFPBench demonstrate the effectiveness of LFP-empowered LJP and highlight promising research directions for LFP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07055v3</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junkai Liu, Yujie Tong, Hui Huang, Bowen Zheng, Yiran Hu, Peicheng Wu, Chuan Xiao, Makoto Onizuka, Muyun Yang, Shuyuan Zheng</dc:creator>
    </item>
    <item>
      <title>Finetuning LLMs for Human Behavior Prediction in Social Science Experiments</title>
      <link>https://arxiv.org/abs/2509.05830</link>
      <description>arXiv:2509.05830v2 Announce Type: replace-cross 
Abstract: Large language models (LLMs) offer a powerful opportunity to simulate the results of social science experiments. In this work, we demonstrate that finetuning LLMs directly on individual-level responses from past experiments meaningfully improves the accuracy of such simulations across diverse social science domains. We construct SocSci210 via an automatic pipeline, a dataset comprising 2.9 million responses from 400,491 participants in 210 open-source social science experiments. Through finetuning, we achieve multiple levels of generalization. In completely unseen studies, our strongest model, Socrates-Qwen-14B, produces predictions that are 26% more aligned with distributions of human responses to diverse outcome questions under varying conditions relative to its base model (Qwen2.5-14B), outperforming GPT-4o by 13%. By finetuning on a subset of conditions in a study, generalization to new unseen conditions is particularly robust, improving by 71%. Since SocSci210 contains rich demographic information, we reduce demographic parity difference, a measure of bias, by 10.6% through finetuning. Because social sciences routinely generate rich, topic-specific datasets, our findings indicate that finetuning on such data could enable more accurate simulations for experimental hypothesis screening. We release our data, models and finetuning code at stanfordhci.github.io/socrates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.05830v2</guid>
      <category>cs.LG</category>
      <category>cs.CY</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing, pages 30084-30099</arxiv:journal_reference>
      <dc:creator>Akaash Kolluri, Shengguang Wu, Joon Sung Park, Michael S. Bernstein</dc:creator>
    </item>
  </channel>
</rss>
