<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.TH</link>
    <description>stat.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 03 Dec 2024 05:03:38 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Nonparametric estimation of linear multiplier for stochastic differential equations driven by multiplicative stochastic volatility</title>
      <link>https://arxiv.org/abs/2412.00005</link>
      <description>arXiv:2412.00005v1 Announce Type: new 
Abstract: We study the problem of nonparametric estimation of the linear multiplier function $\theta(t)$ for processes satisfying stochastic differential equations of the type $$dX_t= \theta(t)X_t dt+ \epsilon\; \sigma_1(t,X_t)\sigma_2(t,Y_t)dW_t, X_0=x_0, 0 \leq t \leq T$$ where $\{W_t, t\geq 0\}$ is a standard Brownian motion, $\{Y_t, t\geq 0\}$ is a process adapted to the filtration generated by the Brownian motion. We study the problem of estimation of the unknown function $\theta(.)$ as $\epsilon \rightarrow 0$ based on the observation of the process $\{X_t,0\leq t \leq T\}.$</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00005v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>B. L. S Prakasa Rao</dc:creator>
    </item>
    <item>
      <title>The Bernstein-von Mises theorem for Semiparametric Mixtures</title>
      <link>https://arxiv.org/abs/2412.00219</link>
      <description>arXiv:2412.00219v1 Announce Type: new 
Abstract: Semiparametric mixture models are parametric models with latent variables. They are defined kernel, $p_\theta(x | z)$, where z is the unknown latent variable, and $\theta$ is the parameter of interest. We assume that the latent variables are an i.i.d. sample from some mixing distribution $F$. A Bayesian would put a prior on the pair $(\theta, F)$. We prove consistency for these models in fair generality and then study efficiency. We first prove an abstract Semiparametric Bernstein-von Mises theorem, and then provide tools to verify the assumptions. We use these tools to study the efficiency for estimating $\theta$ in the frailty model and the errors in variables model in the case were we put a generic prior on $\theta$ and a species sampling process prior on $F$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00219v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stefan Franssen, Jeanne Nguyen, Aad van der Vaart</dc:creator>
    </item>
    <item>
      <title>Functional worst risk minimization</title>
      <link>https://arxiv.org/abs/2412.00412</link>
      <description>arXiv:2412.00412v1 Announce Type: new 
Abstract: The aim of this paper is to extend worst risk minimization, also called worst average loss minimization, to the functional realm. This means finding a functional regression representation that will be robust to future distribution shifts on the basis of data from two environments. In the classical non-functional realm, structural equations are based on a transfer matrix $B$. In section~\ref{sec:sfr}, we generalize this to consider a linear operator $\mathcal{T}$ on square integrable processes that plays the the part of $B$. By requiring that $(I-\mathcal{T})^{-1}$ is bounded -- as opposed to $\mathcal{T}$ -- this will allow for a large class of unbounded operators to be considered. Section~\ref{sec:worstrisk} considers two separate cases that both lead to the same worst-risk decomposition. Remarkably, this decomposition has the same structure as in the non-functional case. We consider any operator $\mathcal{T}$ that makes $(I-\mathcal{T})^{-1}$ bounded and define the future shift set in terms of the covariance functions of the shifts. In section~\ref{sec:minimizer}, we prove a necessary and sufficient condition for existence of a minimizer to this worst risk in the space of square integrable kernels. Previously, such minimizers were expressed in terms of the unknown eigenfunctions of the target and covariate integral operators (see for instance \cite{HeMullerWang} and \cite{YaoAOS}). This means that in order to estimate the minimizer, one must first estimate these unknown eigenfunctions. In contrast, the solution provided here will be expressed in any arbitrary ON-basis. This completely removes any necessity of estimating eigenfunctions. This pays dividends in section~\ref{sec:estimation}, where we provide a family of estimators, that are consistent with a large sample bound. Proofs of all the results are provided in the appendix.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00412v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Philip Kennerberg, Ernst C. Wit</dc:creator>
    </item>
    <item>
      <title>Gaussian quasi-likelihood analysis for non-Gaussian linear mixed-effects model with system noise</title>
      <link>https://arxiv.org/abs/2412.00796</link>
      <description>arXiv:2412.00796v1 Announce Type: new 
Abstract: We consider statistical inference for a class of mixed-effects models with system noise described by a non-Gaussian integrated Ornstein-Uhlenbeck process. Under the asymptotics where the number of individuals goes to infinity with possibly unbalanced sampling frequency across individuals, we prove some theoretical properties of the Gaussian quasi-likelihood function, followed by the asymptotic normality and the tail-probability estimate of the associated estimator. In addition to the joint inference, we propose and investigate the three-stage inference strategy, revealing that they are first-order equivalent while quantitatively different in the second-order terms. Numerical experiments are given to illustrate the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00796v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Takumi Imamura, Hiroki Masuda</dc:creator>
    </item>
    <item>
      <title>Least-Squares Estimator for cumulative INAR($\infty$) processes</title>
      <link>https://arxiv.org/abs/2412.01569</link>
      <description>arXiv:2412.01569v1 Announce Type: new 
Abstract: We consider the estimation of the parameters $s = (\nu, \alpha_1, \alpha_2, \cdots, \alpha_T)$ of a cumulative INAR($\infty$) process based on finite observations under the assumption $\sum_{k=1}^T \alpha_k &lt; 1$ and $\sum_{k=1}^T\alpha_k^2&lt;\frac12$. The parameter space is modeled as a Euclidean space $\mathfrak{l}^2$, with an inner product defined for pairs of parameter vectors. The primary goal is to estimate the intensity function $\Phi_s(t)$, which represents the expected value of the process at time $t$. We introduce a Least-Squares Contrast $\gamma_T(f)$, which measures the distance between the intensity function $\Phi_f(t)$ and the true intensity $\Phi_s(t)$. We further show that the contrast function $\gamma_T(f)$ can be used to estimate the parameters effectively, with an associated metric derived from a quadratic form. The analysis involves deriving upper and lower bounds for the expected values of the process and its square, leading to conditions under which the estimators are consistent. We also provide a bound on the variance of the estimators to ensure their asymptotic reliability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01569v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaohong Duan, Yingli Wang</dc:creator>
    </item>
    <item>
      <title>Unifying AMP Algorithms for Rotationally-Invariant Models</title>
      <link>https://arxiv.org/abs/2412.01574</link>
      <description>arXiv:2412.01574v1 Announce Type: new 
Abstract: This paper presents a unified framework for constructing Approximate Message Passing (AMP) algorithms for rotationally-invariant models. By employing a general iterative algorithm template and reducing it to long-memory Orthogonal AMP (OAMP), we systematically derive the correct Onsager terms of AMP algorithms. This approach allows us to rederive an AMP algorithm introduced by Fan and Opper et al., while shedding new light on the role of free cumulants of the spectral law. The free cumulants arise naturally from a recursive centering operation, potentially of independent interest beyond the scope of AMP. To illustrate the flexibility of our framework, we introduce two novel AMP variants and apply them to estimation in spiked models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01574v1</guid>
      <category>math.ST</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Songbin Liu, Junjie Ma</dc:creator>
    </item>
    <item>
      <title>Quantifying perturbation impacts for large language models</title>
      <link>https://arxiv.org/abs/2412.00868</link>
      <description>arXiv:2412.00868v1 Announce Type: cross 
Abstract: We consider the problem of quantifying how an input perturbation impacts the outputs of large language models (LLMs), a fundamental task for model reliability and post-hoc interpretability. A key obstacle in this domain is disentangling the meaningful changes in model responses from the intrinsic stochasticity of LLM outputs. To overcome this, we introduce Distribution-Based Perturbation Analysis (DBPA), a framework that reformulates LLM perturbation analysis as a frequentist hypothesis testing problem. DBPA constructs empirical null and alternative output distributions within a low-dimensional semantic similarity space via Monte Carlo sampling. Comparisons of Monte Carlo estimates in the reduced dimensionality space enables tractable frequentist inference without relying on restrictive distributional assumptions. The framework is model-agnostic, supports the evaluation of arbitrary input perturbations on any black-box LLM, yields interpretable p-values, supports multiple perturbation testing via controlled error rates, and provides scalar effect sizes for any chosen similarity or distance metric. We demonstrate the effectiveness of DBPA in evaluating perturbation impacts, showing its versatility for perturbation analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00868v1</guid>
      <category>cs.LG</category>
      <category>cs.CL</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paulius Rauba, Qiyao Wei, Mihaela van der Schaar</dc:creator>
    </item>
    <item>
      <title>Toric Multivariate Gaussian Models from Symmetries in a Tree</title>
      <link>https://arxiv.org/abs/2412.00895</link>
      <description>arXiv:2412.00895v1 Announce Type: cross 
Abstract: Given a rooted tree $T$ on $n$ non-root leaves with colored and zeroed nodes, we construct a linear space $L_T$ of $n\times n$ symmetric matrices with constraints determined by the combinatorics of the tree. When $L_T$ represents the covariance matrices of a Gaussian model, it provides natural generalizations of Brownian motion tree (BMT) models in phylogenetics. When $L_T$ represents a space of concentration matrices of a Gaussian model, it gives certain colored Gaussian graphical models, which we refer to as BMT derived models. We investigate conditions under which the reciprocal variety $L_T^{-1}$ is toric. Relying on the birational isomorphism of the inverse matrix map, we show that if the BMT derived graph of $T$ is vertex-regular and a block graph, under the derived Laplacian transformation, $L_T^{-1}$ is the vanishing locus of a toric ideal. This ideal is given by the sum of the toric ideal of the Gaussian graphical model on the block graph, the toric ideal of the original BMT model, and binomial linear conditions coming from vertex-regularity. To this end, we provide monomial parametrizations for these toric models realized through paths among leaves in $T$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00895v1</guid>
      <category>math.AG</category>
      <category>math.CO</category>
      <category>math.ST</category>
      <category>q-bio.PE</category>
      <category>stat.TH</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Emma Cardwell, Aida Maraj, Alvaro Ribot</dc:creator>
    </item>
    <item>
      <title>On the Weak Convergence of the Function-Indexed Sequential Empirical Process and its Smoothed Analogue under Nonstationarity</title>
      <link>https://arxiv.org/abs/2412.01635</link>
      <description>arXiv:2412.01635v1 Announce Type: cross 
Abstract: We study the sequential empirical process indexed by general function classes and its smoothed set-indexed analogue. Sufficient conditions for asymptotic equicontinuity and weak convergence are provided for nonstationary arrays of time series, in terms of uniform moment bounds for partial sums and, for the set-indexed smoothed process, $L_p$-Lipschitz regularity. This yields comprehensive general results on the weak convergence of sequential empirical processes, which are applicable to various notions of dependence. Especially, we show that our moment conditions imply the weak convergence of the sequential process under essentially the same mild assumptions (on the degree of dependence and the complexity of the indexing function class) as known for the classical empirical process. This is exemplified in detail for nonstationary $\alpha$-mixing time series. Core ingredients of the proofs are a novel maximal inequality for nonmeasurable stochastic processes, uniform chaining arguments and suitable pathwise uniform Lipschitz properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01635v1</guid>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Florian Alexander Scholze, Ansgar Steland</dc:creator>
    </item>
    <item>
      <title>Environment Invariant Linear Least Squares</title>
      <link>https://arxiv.org/abs/2303.03092</link>
      <description>arXiv:2303.03092v3 Announce Type: replace 
Abstract: This paper considers a multi-environment linear regression model in which data from multiple experimental settings are collected. The joint distribution of the response variable and covariates may vary across different environments, yet the conditional expectations of $y$ given the unknown set of important variables are invariant. Such a statistical model is related to the problem of endogeneity, causal inference, and transfer learning. The motivation behind it is illustrated by how the goals of prediction and attribution are inherent in estimating the true parameter and the important variable set. We construct a novel environment invariant linear least squares (EILLS) objective function, a multi-environment version of linear least-squares regression that leverages the above conditional expectation invariance structure and heterogeneity among different environments to determine the true parameter. Our proposed method is applicable without any additional structural knowledge and can identify the true parameter under a near-minimal identification condition. We establish non-asymptotic $\ell_2$ error bounds on the estimation error for the EILLS estimator in the presence of spurious variables. Moreover, we further show that the $\ell_0$ penalized EILLS estimator can achieve variable selection consistency in high-dimensional regimes. These non-asymptotic results demonstrate the sample efficiency of the EILLS estimator and its capability to circumvent the curse of endogeneity in an algorithmic manner without any prior structural knowledge. To the best of our knowledge, this paper is the first to realize statistically efficient invariance learning in the general linear model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.03092v3</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1214/24-AOS2435</arxiv:DOI>
      <arxiv:journal_reference>The Annals of Statistics 52(5) (2024) 2268-2292</arxiv:journal_reference>
      <dc:creator>Jianqing Fan, Cong Fang, Yihong Gu, Tong Zhang</dc:creator>
    </item>
    <item>
      <title>On the existence of powerful p-values and e-values for composite hypotheses</title>
      <link>https://arxiv.org/abs/2305.16539</link>
      <description>arXiv:2305.16539v4 Announce Type: replace 
Abstract: Given a composite null $ \mathcal P$ and composite alternative $ \mathcal Q$, when and how can we construct a p-value whose distribution is exactly uniform under the null, and stochastically smaller than uniform under the alternative? Similarly, when and how can we construct an e-value whose expectation exactly equals one under the null, but its expected logarithm under the alternative is positive? We answer these basic questions, and other related ones, when $ \mathcal P$ and $ \mathcal Q$ are convex polytopes (in the space of probability measures). We prove that such constructions are possible if and only if $ \mathcal Q$ does not intersect the span of $ \mathcal P$. If the p-value is allowed to be stochastically larger than uniform under $P\in \mathcal P$, and the e-value can have expectation at most one under $P\in \mathcal P$, then it is achievable whenever $ \mathcal P$ and $ \mathcal Q$ are disjoint. More generally, even when $ \mathcal P$ and $ \mathcal Q$ are not polytopes, we characterize the existence of a bounded nontrivial e-variable whose expectation exactly equals one under any $P \in \mathcal P$. The proofs utilize recently developed techniques in simultaneous optimal transport. A key role is played by coarsening the filtration: sometimes, no such p-value or e-value exists in the richest data filtration, but it does exist in some reduced filtration, and our work provides the first general characterization of this phenomenon. We also provide an iterative construction that explicitly constructs such processes, and under certain conditions it finds the one that grows fastest under a specific alternative $Q$. We discuss implications for the construction of composite nonnegative (super)martingales, and end with some conjectures and open problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.16539v4</guid>
      <category>math.ST</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhenyuan Zhang, Aaditya Ramdas, Ruodu Wang</dc:creator>
    </item>
    <item>
      <title>Towards a robust frequency-domain analysis: Spectral R\'{e}nyi divergence revisited</title>
      <link>https://arxiv.org/abs/2310.06902</link>
      <description>arXiv:2310.06902v2 Announce Type: replace 
Abstract: This paper studies a specific category of statistical divergences for spectral densities of time series: the spectral $\alpha$-R\'{e}nyi divergences, which includes the Itakura--Saito divergence as a subset. While the spectral $\alpha$-R\'{e}nyi divergence has been acknowledged in past works, its statistical attributes have not been thoroughly investigated. The aim of this paper is to highlight these properties. We reveal the connection between the spectral $\alpha$-R\'{e}nyi divergence and the $\gamma$-divergence in robust statistics, and a variational representation of spectral $\alpha$-R\'{e}nyi divergence. Inspired by these results suggesting ``robustness'' of spectral $\alpha$-R\'{e}nyi divergence, we show that the minimum spectral R\'{e}nyi divergence estimate has a stable optimization path with respect to outliers in the frequency domain, unlike the minimum Itakura-Saito divergence estimator, and thus it delivers more stable estimate, reducing the need for intricate pre-processing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.06902v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tetsuya Takabatake, Keisuke Yano</dc:creator>
    </item>
    <item>
      <title>Log-rank test with coarsened exact matching</title>
      <link>https://arxiv.org/abs/2403.16121</link>
      <description>arXiv:2403.16121v3 Announce Type: replace 
Abstract: It is of special importance in the clinical trial to compare survival times between the treatment group and the control group. Propensity score methods with a logistic regression model are often used to reduce the effects of confounders. However, the modeling of complex structures between the covariates, the treatment assignment and the survival time is difficult. In this paper, we consider coarsened exact matching (CEM), which does not need any parametric models, and we propose the weighted log-rank statistic based on CEM. We derive asymptotic properties of the weighted log-rank statistic, such as the weak convergence to a Gaussian process in Skorokhod space, in particular the asymptotic normality, under the null hypothesis and the consistency of the log-rank test. Simulation experiments are also conducted to compare the performance of the log-rank statistic with a propensity score method and CEM. Simulation studies show that the log-rank statistic based on CEM is more robust than the log-rank statistic based on the propensity score.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16121v3</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tomoya Baba, Nakahiro Yoshida</dc:creator>
    </item>
    <item>
      <title>A Statistical Framework of Watermarks for Large Language Models: Pivot, Detection Efficiency and Optimal Rules</title>
      <link>https://arxiv.org/abs/2404.01245</link>
      <description>arXiv:2404.01245v3 Announce Type: replace 
Abstract: Since ChatGPT was introduced in November 2022, embedding (nearly) unnoticeable statistical signals into text generated by large language models (LLMs), also known as watermarking, has been used as a principled approach to provable detection of LLM-generated text from its human-written counterpart. In this paper, we introduce a general and flexible framework for reasoning about the statistical efficiency of watermarks and designing powerful detection rules. Inspired by the hypothesis testing formulation of watermark detection, our framework starts by selecting a pivotal statistic of the text and a secret key -- provided by the LLM to the verifier -- to enable controlling the false positive rate (the error of mistakenly detecting human-written text as LLM-generated). Next, this framework allows one to evaluate the power of watermark detection rules by obtaining a closed-form expression of the asymptotic false negative rate (the error of incorrectly classifying LLM-generated text as human-written). Our framework further reduces the problem of determining the optimal detection rule to solving a minimax optimization program. We apply this framework to two representative watermarks -- one of which has been internally implemented at OpenAI -- and obtain several findings that can be instrumental in guiding the practice of implementing watermarks. In particular, we derive optimal detection rules for these watermarks under our framework. These theoretically derived detection rules are demonstrated to be competitive and sometimes enjoy a higher power than existing detection approaches through numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01245v3</guid>
      <category>math.ST</category>
      <category>cs.CL</category>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiang Li, Feng Ruan, Huiyuan Wang, Qi Long, Weijie J. Su</dc:creator>
    </item>
    <item>
      <title>Dynamic Treatment Effects under Functional Longitudinal Studies</title>
      <link>https://arxiv.org/abs/2406.06868</link>
      <description>arXiv:2406.06868v2 Announce Type: replace 
Abstract: Establishing causality is a fundamental goal in fields like medicine and social sciences. While randomized controlled trials are the gold standard for causal inference, they are not always feasible or ethical. Observational studies can serve as alternatives but introduce confounding biases, particularly in complex longitudinal data, where treatment-confounder feedback complicates analysis. The challenge increases with Dynamic Treatment Regimes (DTRs), where treatment allocation depends on rich historical patient data. The advent of real-time healthcare monitoring technologies, such as MIMIC-IV and Continuous Glucose Monitoring (CGM), has popularized Functional Longitudinal Data (FLD). However, there is yet no investigate of causal inference for FLD with DTRs. In this paper, we address it by developing a population-level framework for functional longitudinal data, accommodating DTRs. To that end, we define the potential outcomes and causal effects of interest. We then develop identification assumptions, and derive g-computation, inverse probability weighting, and doubly robust formulas through novel applications of stochastic process and measure theory. We further show that our framework is nonparametric and compute the efficient influence curve using semiparametric theory. Last, we illustrate our framework's potential through Monte Carlo simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06868v2</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrew Ying</dc:creator>
    </item>
    <item>
      <title>Generalized Principal Component Analysis for Large-dimensional Matrix Factor Model</title>
      <link>https://arxiv.org/abs/2411.06423</link>
      <description>arXiv:2411.06423v2 Announce Type: replace 
Abstract: Matrix factor models have been growing popular dimension reduction tools for large-dimensional matrix time series. However, the heteroscedasticity of the idiosyncratic components has barely received any attention. Starting from the pseudo likelihood function, this paper introduces a Generalized Principal Component Analysis (GPCA) method for matrix factor model which takes the heteroscedasticity into account. Theoretically, we first derive the asymptotic distributions of the GPCA estimators by assuming the separable covariance matrices are known in advance. We then propose adaptive thresholding estimators for the separable covariance matrices and derive their convergence rates, which is of independent interest. We also show that this would not alter the asymptotic distributions of the GPCA estimators under certain regular sparsity conditions in the high-dimensional covariance matrix estimation literature. The GPCA estimators are shown to be more efficient than the state-of-the-art methods under certain heteroscedasticity conditions. Thorough numerical studies are conducted to demonstrate the superiority of our method over the existing approaches. Analysis of a financial portfolio dataset illustrates the empirical usefulness of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.06423v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yong He, Yujie Hou, Haixia Liu, Yalin Wang</dc:creator>
    </item>
    <item>
      <title>Towards a theory for testing statistical hypothesis: Multivariate mean with nuisance covariance matrix</title>
      <link>https://arxiv.org/abs/2411.12532</link>
      <description>arXiv:2411.12532v2 Announce Type: replace 
Abstract: Under a multinormal distribution with an arbitrary unknown covariance matrix, the main purpose of this paper is to propose a framework to achieve the goal of reconciliation of Bayesian, frequentist, and Fisher's reporting $p$-values, Neyman-Pearson's optimal theory and Wald's decision theory for the problems of testing mean against restricted alternatives (closed convex cones). To proceed, the tests constructed via the likelihood ratio (LR) and the union-intersection (UI) principles are studied. For the problems of testing against restricted alternatives, first, we show that the LRT and the UIT are not the proper Bayes tests, however, they are shown to be the integrated LRT and the integrated UIT, respectively. For the problem of testing against the positive orthant space alternative, both the null distributions of the LRT and the UIT depend on the unknown nuisance covariance matrix. Hence we have difficulty adopting Fisher's approach to reporting $p$-values. On the other hand, according to the definition of the level of significance, both the LRT and the UIT are shown to be power-dominated by the corresponding LRT and UIT for testing against the half-space alternative, respectively. Hence, both the LRT and the UIT are $\alpha$-inadmissible, these results are against the common statistical sense. Neither Fisher's approach of reporting $p$-values alone nor Neyman-Pearson's optimal theory for power function alone is a satisfactory criterion for evaluating the performance of tests. Wald's decision theory via $d$-admissibility may shed light on resolving these challenging issues of imposing the balance between type 1 error and power.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12532v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ming-Tien Tsai</dc:creator>
    </item>
    <item>
      <title>New possibilities in identification of binary choice models with fixed effects</title>
      <link>https://arxiv.org/abs/2206.10475</link>
      <description>arXiv:2206.10475v5 Announce Type: replace-cross 
Abstract: We study the identification of binary choice models with fixed effects. We provide a condition called sign saturation and show that this condition is sufficient for the identification of the model. In particular, we can guarantee identification even with bounded regressors. We also show that without this condition, the model is not identified unless the error distribution belongs to a small class. The same sign saturation condition is also essential for identifying the sign of treatment effects. A test is provided to check the sign saturation condition and can be implemented using existing algorithms for the maximum score estimator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.10475v5</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yinchu Zhu</dc:creator>
    </item>
    <item>
      <title>Is Behavior Cloning All You Need? Understanding Horizon in Imitation Learning</title>
      <link>https://arxiv.org/abs/2407.15007</link>
      <description>arXiv:2407.15007v2 Announce Type: replace-cross 
Abstract: Imitation learning (IL) aims to mimic the behavior of an expert in a sequential decision making task by learning from demonstrations, and has been widely applied to robotics, autonomous driving, and autoregressive text generation. The simplest approach to IL, behavior cloning (BC), is thought to incur sample complexity with unfavorable quadratic dependence on the problem horizon, motivating a variety of different online algorithms that attain improved linear horizon dependence under stronger assumptions on the data and the learner's access to the expert.
  We revisit the apparent gap between offline and online IL from a learning-theoretic perspective, with a focus on the realizable/well-specified setting with general policy classes up to and including deep neural networks. Through a new analysis of behavior cloning with the logarithmic loss, we show that it is possible to achieve horizon-independent sample complexity in offline IL whenever (i) the range of the cumulative payoffs is controlled, and (ii) an appropriate notion of supervised learning complexity for the policy class is controlled. Specializing our results to deterministic, stationary policies, we show that the gap between offline and online IL is smaller than previously thought: (i) it is possible to achieve linear dependence on horizon in offline IL under dense rewards (matching what was previously only known to be achievable in online IL); and (ii) without further assumptions on the policy class, online IL cannot improve over offline IL with the logarithmic loss, even in benign MDPs. We complement our theoretical results with experiments on standard RL tasks and autoregressive language generation to validate the practical relevance of our findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15007v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dylan J. Foster, Adam Block, Dipendra Misra</dc:creator>
    </item>
    <item>
      <title>A Note on Doubly Robust Estimator in Regression Continuity Designs</title>
      <link>https://arxiv.org/abs/2411.07978</link>
      <description>arXiv:2411.07978v3 Announce Type: replace-cross 
Abstract: This note introduces a doubly robust (DR) estimator for regression discontinuity (RD) designs. RD designs provide a quasi-experimental framework for estimating treatment effects, where treatment assignment depends on whether a running variable surpasses a predefined cutoff. A common approach in RD estimation is the use of nonparametric regression methods, such as local linear regression. However, the validity of these methods still relies on the consistency of the nonparametric estimators. In this study, we propose the DR-RD estimator, which combines two distinct estimators for the conditional expected outcomes. The primary advantage of the DR-RD estimator lies in its ability to ensure the consistency of the treatment effect estimation as long as at least one of the two estimators is consistent. Consequently, our DR-RD estimator enhances robustness of treatment effect estimators in RD designs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07978v3</guid>
      <category>econ.EM</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Masahiro Kato</dc:creator>
    </item>
    <item>
      <title>Inference on Dynamic Spatial Autoregressive Models with Change Point Detection</title>
      <link>https://arxiv.org/abs/2411.18773</link>
      <description>arXiv:2411.18773v2 Announce Type: replace-cross 
Abstract: We analyze a varying-coefficient dynamic spatial autoregressive model with spatial fixed effects. One salient feature of the model is the incorporation of multiple spatial weight matrices through their linear combinations with varying coefficients, which help solve the problem of choosing the most "correct" one for applied econometricians who often face the availability of multiple expert spatial weight matrices. We estimate and make inferences on the model coefficients and coefficients in basis expansions of the varying coefficients through penalized estimations, establishing the oracle properties of the estimators and the consistency of the overall estimated spatial weight matrix, which can be time-dependent. We further consider two applications of our model in change point detections in dynamic spatial autoregressive models, providing theoretical justifications in consistent change point locations estimation and practical implementations. Simulation experiments demonstrate the performance of our proposed methodology, and a real data analysis is also carried out.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18773v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zetai Cen, Yudong Chen, Clifford Lam</dc:creator>
    </item>
  </channel>
</rss>
