<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 17 Sep 2025 01:37:18 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Bilevel subsidy-enabled mobility hub network design with perturbed utility coalitional choice-based assignment</title>
      <link>https://arxiv.org/abs/2509.10465</link>
      <description>arXiv:2509.10465v1 Announce Type: new 
Abstract: Urban mobility is undergoing rapid transformation with the emergence of new services. Mobility hubs (MHs) have been proposed as physical-digital convergence points, offering a range of public and private mobility options in close proximity. By supporting Mobility-as-a-Service, these hubs can serve as focal points where travel decisions intersect with operator strategies. We develop a bilevel MH platform design model that treats MHs as control levers. The upper level (platform) maximizes revenue or flow by setting subsidies to incentivize last-mile operators; the lower level captures joint traveler-operator decisions with a link-based Perturbed Utility Route Choice (PURC) assignment, yielding a strictly convex quadratic program. We reformulate the bilevel problem to a single-level program via the KKT conditions of the lower level and solve it with a gap-penalty method and an iterative warm-start scheme that exploits the computationally cheap lower-level problem. Numerical experiments on a toy network and a Long Island Rail Road (LIRR) case (244 nodes, 469 links, 78 ODs) show that the method attains sub-1% optimality gaps in minutes. In the base LIRR case, the model allows policymakers to quantify the social surplus value of a MH, or the value of enabling subsidy or regulating the microtransit operator's pricing. Comparing link-based subsidies to hub-based subsidies, the latter is computationally more expensive but offers an easier mechanism for comparison and control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10465v1</guid>
      <category>math.OC</category>
      <category>cs.CY</category>
      <category>cs.GT</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hai Yang, Joseph Y. J. Chow</dc:creator>
    </item>
    <item>
      <title>Asymptotic stability properties and a priori bounds for Adam and other gradient descent optimization methods</title>
      <link>https://arxiv.org/abs/2509.10476</link>
      <description>arXiv:2509.10476v1 Announce Type: new 
Abstract: Gradient descent (GD) based optimization methods are these days the standard tools to train deep neural networks in artificial intelligence systems. In optimization procedures in deep learning the employed optimizer is often not the standard GD method but instead suitable adaptive and accelerated variants of standard GD (including the momentum and the root mean square propagation (RMSprop) optimizers) are considered. The adaptive moment estimation (Adam) optimizer proposed in 2014 by Kingma \&amp; Ba is presumably the most popular variant of such adaptive and accelerated GD based optimization methods. Despite the popularity of such sophisticated optimization methods, it remains a fundamental open problem of research to provide a rigorous mathematical analysis for such accelerated and adaptive optimization methods. In particular, it remains an open problem of research to establish boundedness of the Adam optimizer. In this work we solve this problem in the case of a simple class of quadratic strongly convex stochastic optimization problems. Specifically, for the considered class of stochastic optimization problems we reveal a priori bounds for momentum, RMSprop, and Adam. In particular, we prove for the considered class of strongly convex stochastic optimization problems, for the first time, that Adam does not explode but stays bounded for any choices of the learning rates. In this work we also introduce certain stability concepts - such as the notion of the stability region - for deep learning optimizers and we discover that among standard GD, momentum, RMSprop, and Adam we have that Adam is the only optimizer that achieves the optimal higher order convergence speed and also has the maximal stability region.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10476v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Steffen Dereich, Robin Graeber, Arnulf Jentzen, Adrian Riekert</dc:creator>
    </item>
    <item>
      <title>Demand Charge Management: Prototype Design and Testing</title>
      <link>https://arxiv.org/abs/2509.10713</link>
      <description>arXiv:2509.10713v1 Announce Type: new 
Abstract: This paper presents the design, implementation, and validation of a smart, low-cost Energy Management System (EMS) and Demand Charge Management (DCM) prototype, developed as part of an undergraduate senior design project. The system serves as both a practical solution for reducing electricity costs and a pedagogical tool for teaching real-time energy control concepts in power and embedded systems courses. Unlike conventional EMS/DCM solutions that rely on high-cost commercial hardware or purely theoretical models, the proposed system integrates grid power, lithium-iron phosphate (LiFePO4) battery storage, and real-time control into a unified, scalable platform constructed at a fraction of the cost, approximately $1,800 compared to over $16,000 for leading commercial options. The controller dynamically optimizes energy usage by switching between grid and battery sources based on real-time measurements of electricity prices, load power, and battery state of charge (SoC). This enables peak shaving, energy arbitrage, and backup power functionality, thereby enhancing cost efficiency and grid resilience for both residential and small commercial users. The architecture features a modular three-layer design comprising a sensing layer for electrical data acquisition, a control layer executing Python-based logic on a Raspberry Pi, and an actuator layer for seamless energy switching. Data is communicated via MQTT and visualized through the Blynk IoT platform, providing an intuitive and remotely accessible user interface. The prototype's effectiveness was validated through real-world testing, confirming its capability to reduce demand charges and ensure reliable energy delivery under varying operational conditions. Its affordability, open-source control logic, and educational versatility make it an ideal candidate for both deployment and instructional use.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10713v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christian Escarrega, Wyatt Lopez Coggins, Sammy Hamed, Mohammadreza Iranpour, Mohammad Rasoul Narimani</dc:creator>
    </item>
    <item>
      <title>Large-Scale Network Utility Maximization via GPU-Accelerated Proximal Message Passing</title>
      <link>https://arxiv.org/abs/2509.10722</link>
      <description>arXiv:2509.10722v1 Announce Type: new 
Abstract: We present a GPU-accelerated proximal message passing algorithm for large-scale network utility maximization (NUM). NUM is a fundamental problem in resource allocation, where resources are allocated across various streams in a network to maximize total utility while respecting link capacity constraints. Our method, a variant of ADMM, requires only sparse matrix-vector multiplies with the link-route matrix and element-wise proximal operator evaluations, enabling fully parallel updates across streams and links. It also supports heterogeneous utility types, including logarithmic utilities common in NUM, and does not assume strict concavity. We implement our method in PyTorch and demonstrate its performance on problems with tens of millions of variables and constraints, achieving 4x to 20x speedups over existing CPU and GPU solvers and solving problem sizes that exhaust the memory of baseline methods. Additionally, we show that our algorithm is robust to congestion and link-capacity degradation. Finally, using a time-expanded transit seat allocation case study, we illustrate how our approach yields interpretable allocations in realistic networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10722v1</guid>
      <category>math.OC</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Akshay Sreekumar, Anthony Degleris, Ram Rajagopal</dc:creator>
    </item>
    <item>
      <title>Highly Efficient Optimal Control for Lyophilization via Simulation of Discrete/Continuous Mixed-index Differential-algebraic Equations</title>
      <link>https://arxiv.org/abs/2509.10826</link>
      <description>arXiv:2509.10826v1 Announce Type: new 
Abstract: This article presents a highly efficient optimal control algorithm and policies for lyophilization (also known as freeze drying). The optimal solutions and control policies are derived using an extended version of the simulation-based algorithm, which reformulates the optimal control problem as a hybrid discrete/continuous system of mixed-index differential-algebraic equations and subsequently calculates the optimal control vector via simulation of the resulting DAEs. Our algorithm and control policies are demonstrated via a number of case studies that encompass various lyophilization and optimal control strategies. All the case studies can be solved within less than a second on a normal laptop, regardless of their complexity. The method is several orders of magnitude faster than the traditional optimization-based techniques while giving similar/better accuracy. The proposed algorithm offers an efficient and reliable framework for optimal control of lyophilization, which can also be extended to other similar systems with phase transitions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10826v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Prakitr Srisuma, Richard D. Braatz</dc:creator>
    </item>
    <item>
      <title>Metric Subregularity of Multifunctions and Applications to Characterizations of Asplund Spaces</title>
      <link>https://arxiv.org/abs/2509.11004</link>
      <description>arXiv:2509.11004v1 Announce Type: new 
Abstract: In this paper, we investigate metric subregularity of multifunctions between Asplund spaces. Using Mordukhovich normal cones and coderivatives, we introduce the limiting Basic Constraint Qualification (BCQ) associated with a given multifunction. This BCQ provides necessary dual conditions for the metric subregularity of multifunctions in the Asplund space setting.
  Furthermore, we establish characterizations of Asplund spaces in terms of the limiting BCQ condition implied by metric subregularity. By employing Frechet normal cones and coderivatives, we derive necessary dual conditions for metric subregularity expressed as fuzzy inclusions, and we also obtain characterizations of Asplund spaces via these fuzzy inclusions.
  As an application, we examine metric subregularity of the conic inequality defined by a vector-valued function and a closed (not necessarily convex) cone with a nontrivial recession cone. By using Mordukhovich and Frechet subdifferentials relative to the given cone, we establish necessary dual conditions for the metric subregularity of such inequalities in Asplund spaces. The results based on Mordukhovich subdifferentials characterize Asplund spaces, while those based on Frechet subdifferentials yield necessary or sufficient conditions for Asplund spaces. These conditions recover, as special cases, the known error-bound results for inequalities defined by extended-real-valued functions on Asplund spaces.
  Overall, this work highlights that the validity of necessary conditions formulated via normal cones and subdifferentials for error bounds of convex or nonconvex inequalities depends crucially on the Asplund property of the underlying space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11004v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Zhou Wei, Michel Thera, Jen-Chih Yao</dc:creator>
    </item>
    <item>
      <title>Gradient Methods with Online Scaling Part II. Practical Aspects</title>
      <link>https://arxiv.org/abs/2509.11007</link>
      <description>arXiv:2509.11007v1 Announce Type: new 
Abstract: Part I of this work [Gao25] establishes online scaled gradient methods (OSGM), a framework that utilizes online convex optimization to adapt stepsizes in gradient methods. This paper focuses on the practical aspects of OSGM. We leverage the OSGM framework to design new adaptive first-order methods and provide insights into their empirical behavior. The resulting method, OSGM-Best, matches the performance of quasi-Newton variants while requiring less memory and cheaper iterations. We also extend OSGM to nonconvex optimization and outline directions that connect OSGM to existing branches of optimization theory and practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11007v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ya-Chi Chu, Wenzhi Gao, Yinyu Ye, Madeleine Udell</dc:creator>
    </item>
    <item>
      <title>Adaptive Stochastic Gradient Descent Ascent Algorithm for Nonconvex Minimax Problems with Decision-Dependent Distributions</title>
      <link>https://arxiv.org/abs/2509.11018</link>
      <description>arXiv:2509.11018v1 Announce Type: new 
Abstract: In this paper, we study stochastic minimax problems with decision-dependent distributions (SMDD), where the probability distribution of stochastic variable depends on decision variable. For SMDD with nonconvex-(strongly) concave objective function, we propose an adaptive stochastic gradient descent ascent algorithm (ASGDA) to find the stationary points of SMDD, which learns the unknown distribution map dynamically and optimizes the minimax problem simultaneously. When the distribution map follows a location-scale model, we show that ASGDA finds an $\epsilon$-stationary point within $\mathcal{O}\left(\epsilon^{-\left(4+\delta\right)} \right)$ for $\forall\delta&gt;0$, and $\mathcal{O}(\epsilon^{-8})$ stochastic gradient evaluations in nonconvex-strongly concave and nonconvex-concave settings respectively. When the objective function of SMDD is nonconvex in $x$ and satisfies Polyak-{\L}ojasiewicz (P{\L}) inequality in $y$, we propose an alternating adaptive stochastic gradient descent ascent algorithm (AASGDA) and show that AASGDA finds an $\epsilon$-stationary point within $\mathcal{O}(\kappa_y^4\epsilon^{-4})$ stochastic gradient evaluations, where $\kappa_y$ denotes the condition number. We verify the effectiveness of the proposed algorithms through numerical experiments on both synthetic and real-world data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11018v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yan Gao, Yongchao Liu</dc:creator>
    </item>
    <item>
      <title>Final Exam Scheduling at Bucknell University: A Case Study and Open-Source Tool</title>
      <link>https://arxiv.org/abs/2509.11031</link>
      <description>arXiv:2509.11031v1 Announce Type: new 
Abstract: Problem Definition: Final exam scheduling is a common but challenging optimization problem. At Bucknell University, a small liberal arts institution, the problem is particularly complex and has historically required the Registrar's Office to spend months manually designing an exam schedule each semester.
  Methodology: We worked in close collaboration with the Registrar's Office. First, we created visualization tools to help their manual scheduling process. Then we designed integer programming models and heuristics to produce a portfolio of possible exam schedules. Finally, we developed open-source, user-friendly software, enabling their office to directly produce and adjust these schedules.
  Results and Managerial Implications: Our tools - both software and algorithms - are now in use at Bucknell University. This collaboration has led to both substantial time savings and improved schedules. Since the implementation of this project, for example, the proportion of students who have a back-to-back exam in a given semester has decreased from roughly a third to about 10%. Our tools are fully open-source and rely on an open-source optimization solver, and our approach garnered national media attention with an article in Inside Higher Ed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11031v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Clara Chaplin, Stanley Gai, Samuel C. Gutekunst, Tsugunobu Miyake, Thiago Serra, Luke Snyder, Vy Tran, Lucas Waddell</dc:creator>
    </item>
    <item>
      <title>Convergence Rate in Nonlinear Two-Time-Scale Stochastic Approximation with State (Time)-Dependence</title>
      <link>https://arxiv.org/abs/2509.11039</link>
      <description>arXiv:2509.11039v1 Announce Type: new 
Abstract: The nonlinear two-time-scale stochastic approximation is widely studied under conditions of bounded variances in noise. Motivated by recent advances that allow for variability linked to the current state or time, we consider state- and time-dependent noises. We show that the Lyapunov function exhibits polynomial convergence rates in both cases, with the rate of polynomial delay depending on the parameters of state- or time-dependent noises. Notably, if the state noise parameters fully approach their limiting value, the Lyapunov function achieves an exponential convergence rate. We provide two numerical examples to illustrate our theoretical findings in the context of stochastic gradient descent with Polyak-Ruppert averaging and stochastic bilevel optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11039v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1609/aaai.v39i15.33756</arxiv:DOI>
      <arxiv:journal_reference>Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 39, No. 15, pp. 15993-16000, 2025</arxiv:journal_reference>
      <dc:creator>Zixi Chen, Yumin Xu, Ruixun Zhang</dc:creator>
    </item>
    <item>
      <title>Hybrid Quantum Branch-and-Bound Method for Quadratic Unconstrained Binary Optimization</title>
      <link>https://arxiv.org/abs/2509.11040</link>
      <description>arXiv:2509.11040v1 Announce Type: new 
Abstract: Quantum algorithms have shown promise in solving Quadratic Unconstrained Binary Optimization (QUBO) problems, benefiting from their connection to the transverse field Ising model. Various Ising solvers, both classical and quantum, have emerged to tackle such problems efficiently but lack global optimality guarantees and often suffer from hardware limitations such as limited qubit availability. In this work, we propose a hybrid branch-and-bound (B&amp;B) framework that integrates Ising solvers as heuristics within a classical B&amp;B algorithm. Unlike prior theoretical studies, our work presents a practical implementation, available as open-source on GitHub. We explore when and where to apply Ising solvers in the search tree and introduce a custom branching rule optimized QUBO embedding. Our method is evaluated on hundreds of QUBO instances from QUBOLib.jl using Gurobi and the D-Wave quantum annealer. Our results show up to 11% less solution time and 17% fewer nodes compared to default Gurobi, an off-the-shelf commercial optimization solver. These findings demonstrate the value of hybrid quantum-classical strategies for enhancing exact optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11040v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zedong Peng, Daniel de Roux, David E. Bernal Neira</dc:creator>
    </item>
    <item>
      <title>A Proximal Stochastic Gradient Method with Adaptive Step Size and Variance Reduction for Convex Composite Optimization</title>
      <link>https://arxiv.org/abs/2509.11043</link>
      <description>arXiv:2509.11043v1 Announce Type: new 
Abstract: In this paper, we propose a proximal stochasitc gradient algorithm (PSGA) for solving composite optimization problems by incorporating variance reduction techniques and an adaptive step-size strategy. In the PSGA method, the objective function consists of two components: one is a smooth convex function, and the other is a non-smooth convex function. We establish the strong convergence of the proposed method, provided that the smooth convex function is Lipschitz continuous. We also prove that the expected value of the error between the estimated gradient and the actual gradient converges to zero. Furthermore, we get an \( O(\sqrt{1/k}) \) convergence rate for our method. Finally, the effectiveness of the proposed method is validated through numerical experiments on Logistic regression and Lasso regression.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11043v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Changjie Fang, Hao Yang, Shenglan Chen</dc:creator>
    </item>
    <item>
      <title>Landmark MDS Revisited for Sensor Network Localization with Anchors</title>
      <link>https://arxiv.org/abs/2509.11126</link>
      <description>arXiv:2509.11126v1 Announce Type: new 
Abstract: The landmark multi-dimensional scaling (LMDS) is a leading method that embeds new points to an existing coordinate system based on observed distance information. It has long been known as a variant of Nystr\"{o}m algorithm. It was recently revealed that LMDS is Gower's method proposed in 1960s. However, the relationship with other range-based embedding methods including the least-squares (LS) has been unexplored, proposing the question of which method to use in practice. This paper provides a fresh look at those methods and explicitly differentiates them in terms of the objectives they try to minimize. For the first time for the case of single source localization, we show that both LMDS and LS are generated from a same family of objectives, which balance between length and angle preservation among the embedding points. Despite being nonconvex, the new objectives can be globally optimized through a trust-region method. An important result is that the LS solution can be thought as a regularized solution of LMDS. Extension to the case of multiple source localization is also explored. Comprehensive numerical results demonstrate the quality of the proposed objectives and the efficiency of the trust-region method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11126v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ting Ouyang, Lingchen Kong, Houduo Qi</dc:creator>
    </item>
    <item>
      <title>A note on finding optimal cut-offs</title>
      <link>https://arxiv.org/abs/2509.11229</link>
      <description>arXiv:2509.11229v1 Announce Type: new 
Abstract: This paper addresses the challenge of determining optimal cut-offs for a set of n items with m scores to maximize distinguishability. The term distinguishability is defined as the fraction of item pairs assigned to different buckets, where buckets are determined by the number of cut-offs an items scores exceed. A brute-force approach to this problem is computationally intractable, with complexity growing exponentially with the number of scores. On the other hand, attempts to solve the problem in the continuous domain lead to local minima, making it unreliable. To overcome these challenges, the problem is formulated as a Integer Quadratic Program (IQP). Since IQPs become computationally difficult with even moderate size problems, a surrogate Integer Linear Program (ILP) is introduced, which can be solved more efficiently for larger instances. In addition to these exact methods, a simple heuristic is proposed that offers a balance between solution quality and computational efficiency. This heuristic iteratively adjusts cutoffs for each score, considering a finite-set of meaningful cut-off points. Computational results provide an empirically evidence for the effectiveness of our proposed methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11229v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Shravan Mohan</dc:creator>
    </item>
    <item>
      <title>Comparing Model-based Control Strategies for a Quadruple Tank System: Decentralized PID, LMPC, and NMPC</title>
      <link>https://arxiv.org/abs/2509.11235</link>
      <description>arXiv:2509.11235v1 Announce Type: new 
Abstract: This paper compares the performance of a decentralized proportional-integral-derivative (PID) controller, a linear model predictive controller (LMPC), and a nonlinear model predictive controller (NMPC) applied to a quadruple tank system (QTS). We present experimental data from a physical setup of the QTS as well as simulation results. The QTS is modeled as a stochastic nonlinear continuous-discrete-time system, with parameters estimated using a maximum-likelihood prediction-error-method (ML-PEM). The NMPC applies the stochastic nonlinear continuous-discrete-time model, while the LMPC uses a linearized version of the same model. We tune the decentralized PID controller using the simple internal model control (SIMC) rules. The SIMC rules require transfer functions of the process, and we obtain these from the linearized model. We compare the controller performances based on systematic tests using both the physical setup and the simulated QTS. We measure the performance in terms of tracking errors and rate of movement in the manipulated variables. The LMPC and the NMPC perform better than the decentralized PID control system for tracking pre-announced time-varying setpoints. For disturbance rejection, the MPCs perform only slightly better than the decentralized PID controller. The primary advantage of the MPCs is their ability to use the information of future setpoints. We demonstrate this by providing simulation results of the MPCs with and without such information. Finally, the NMPC achieves slightly improved tracking errors compared to the LMPC but at the expense of having a higher input rate of movement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11235v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anders H. D. Christensen, Tobias K. S. Ritschel, Jan Lorenz Svensen, Steen H{\o}rsholt, Jakob Kj{\o}bsted Huusom, John Bagterp J{\o}rgensen</dc:creator>
    </item>
    <item>
      <title>From PowerSGD to PowerSGD+: Low-Rank Gradient Compression for Distributed Optimization with Convergence Guarantees</title>
      <link>https://arxiv.org/abs/2509.11254</link>
      <description>arXiv:2509.11254v1 Announce Type: new 
Abstract: Low-rank gradient compression methods, such as PowerSGD, have gained attention in communication-efficient distributed optimization. However, the convergence guarantees of PowerSGD remain unclear, particularly in stochastic settings. In this paper, we show that PowerSGD does not always converge to the optimal solution and provide a clear counterexample to support this finding. To address this, we introduce PowerSGD+, which periodically updates the projection subspace via singular value decomposition, ensuring that it remains aligned with the optimal subspace. We prove that PowerSGD+ converges under standard assumptions and validate its effectiveness through empirical evaluation on large language model tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11254v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shengping Xie, Chuyan Chen, Kun Yuan</dc:creator>
    </item>
    <item>
      <title>A conjecture related to the Newman phase</title>
      <link>https://arxiv.org/abs/2509.11278</link>
      <description>arXiv:2509.11278v1 Announce Type: new 
Abstract: A conjecture is proposed concerning the recovery of a discrete magnitude spectrum through a nonlinear transformation involving the Newman's phase sequence. Given a discrete magnitude spectrum sampled from a continuous function, consider the process of applying a complex exponential with the Newman's phase sequence, computing the inverse discrete Fourier transform (IFFT), taking the absolute value of the result, and reversing the time-domain signal. The conjecture states that Newman's phase sequence, defined by a formula $\phi^{(N)}[k] = \frac{\pi (k-1)^2}{N}$, asymptotically recovers the original magnitude spectrum as the number of samples $N \to \infty$. Notably, the phase sequence is also independent of the input signal and is unique up to an overall constant phase shift. The broader implications of this conjecture remain to be fully understood, but the phenomenon raises fundamental questions about the role of phase in nonlinear spectral recovery.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11278v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shravan Mohan</dc:creator>
    </item>
    <item>
      <title>Prioritizing Recurrent Services</title>
      <link>https://arxiv.org/abs/2509.11383</link>
      <description>arXiv:2509.11383v1 Announce Type: new 
Abstract: We study optimal scheduling in multi-class queueing systems with reentrance, where jobs may return for additional service after completion. Such reentrance creates feedback loops that fundamentally alter congestion dynamics and challenge classical scheduling results. We model two distinct dimensions of the reentrance behavior, the probability of return and the speed of return, and show that their product, the effective return rate, is the key statistic that governs optimal priorities. Our main result establishes a dichotomy: when the effective return rate of the smaller job class (the class with lower expected total workload) is lower, a fixed priority rule is optimal; when it is higher, fixed rules are suboptimal and the optimal policy must be state dependent. This characterization clarifies how reentrance changes the externalities that jobs impose on one another and provides structural guidance for designing scheduling policies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11383v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lin Franklin Feng, Yue Hu, Xu Kuang</dc:creator>
    </item>
    <item>
      <title>On the geometry of flat minima</title>
      <link>https://arxiv.org/abs/2509.11386</link>
      <description>arXiv:2509.11386v1 Announce Type: new 
Abstract: What does it mean to be flat?
  We propose to define it by measuring the maximal variation around a point, or from a dual perspective, the distance to neighboring level sets.
  After developing some calculus rules, we show how flat minima, conservation laws, and symmetries are intertwined. Gradient flows of conserved quantities are of particular interest, due to their flattening properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11386v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>C\'edric Josz</dc:creator>
    </item>
    <item>
      <title>Lyapunov stability of the Euler method</title>
      <link>https://arxiv.org/abs/2509.11415</link>
      <description>arXiv:2509.11415v1 Announce Type: new 
Abstract: We extend the Lyapunov stability criterion to Euler discretizations of set-valued dynamical systems. It relies on a pair of Lyapunov functions, one in continuous time and one in discrete time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11415v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>C\'edric Josz</dc:creator>
    </item>
    <item>
      <title>Subdifferentiation with symmetry</title>
      <link>https://arxiv.org/abs/2509.11422</link>
      <description>arXiv:2509.11422v1 Announce Type: new 
Abstract: Given an objective function that is invariant under an action of a Lie group, we study how its subgradients relate to the orbits of the action. Our main finding is that they satisfy projection formulae analogous to those stemming from the Whitney and Verdier stratifications. If the function is definable in an o-minimal structure on the real field, then we also obtain an invariant variational stratification. On the application side, we derive a conservation law for subgradient dynamics under minimal assumptions. It can be used to detect instability in discrete subgradient dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11422v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>C\'edric Josz</dc:creator>
    </item>
    <item>
      <title>Finite dominating sets for the refueling station location problem in fleet operations</title>
      <link>https://arxiv.org/abs/2509.11441</link>
      <description>arXiv:2509.11441v1 Announce Type: new 
Abstract: This study considers a set of routes used by public transportation vehicles and dedicated distribution fleets in a general network. We aim to optimally locate alternative fuel refueling stations in the network to serve these dedicated routes. Deviations from prescribed routes for refueling purposes are allowed. Unlike most related literature, our approach considers all points in the network as candidate refueling station locations. We derive coverage constraints for any candidate location to serve a given route. Then we develop an exact algorithm to establish a finite dominating set (FDS) of candidate locations guaranteed to include an optimal solution to the problem. This set can be used in a mathematical model to minimize the number of stations required to cover all flows in the network. Numerical experiments on realistic networks are presented to illustrate the proposed methodology and to demonstrate its scalability and sensitivity to changes in parameter values.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11441v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Moddassir Khan Nayeem, Fuhad Ahmed Opu, Omar Abbaas, Sara Abu-Aridah</dc:creator>
    </item>
    <item>
      <title>Optimal Micro-Transit Zoning via Clique Generation and Integer Programming</title>
      <link>https://arxiv.org/abs/2509.11445</link>
      <description>arXiv:2509.11445v1 Announce Type: new 
Abstract: Micro-transit services offer a promising solution to enhance urban mobility and access, particularly by complementing existing public transit. However, effectively designing these services requires determining optimal service zones for these on-demand shuttles, a complex challenge often constrained by operating budgets and transit agency priorities. This paper presents a novel two-phase algorithmic framework for designing optimal micro-transit service zones based on the objective of maximizing served demand. A key innovation is our adaptation of the shareability graph concept from its traditional use in dynamic trip assignment to the distinct challenge of static spatial zoning. We redefine shareability by considering geographical proximity within a specified diameter constraint, rather than trip characteristics. In Phase 1, the framework employs a highly scalable algorithm to generate a comprehensive set of candidate zones. In Phase 2, it formulates the selection of a specified number of zones as a Weighted Maximum Coverage Problem, which can be efficiently solved by an integer programming solver. Evaluations on real-world data from Chattanooga, TN, and synthetic datasets show that our framework outperforms a baseline algorithm, serving 27.03% more demand in practice and up to 49.5% more demand in synthetic settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11445v1</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hins Hu, Rhea Goswami, Hongyi Jiang, Samitha Samaranayake</dc:creator>
    </item>
    <item>
      <title>Preconditioned subgradient method for composite optimization: overparameterization and fast convergence</title>
      <link>https://arxiv.org/abs/2509.11486</link>
      <description>arXiv:2509.11486v1 Announce Type: new 
Abstract: Composite optimization problems involve minimizing the composition of a smooth map with a convex function. Such objectives arise in numerous data science and signal processing applications, including phase retrieval, blind deconvolution, and collaborative filtering. The subgradient method achieves local linear convergence when the composite loss is well-conditioned. However, if the smooth map is, in a certain sense, ill-conditioned or overparameterized, the subgradient method exhibits much slower sublinear convergence even when the convex function is well-conditioned. To overcome this limitation, we introduce a Levenberg-Morrison-Marquardt subgradient method that converges linearly under mild regularity conditions at a rate determined solely by the convex function. Further, we demonstrate that these regularity conditions hold for several problems of practical interest, including square-variable formulations, matrix sensing, and tensor factorization. Numerical experiments illustrate the benefits of our method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11486v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mateo D\'iaz, Liwei Jiang, Abdel Ghani Labassi</dc:creator>
    </item>
    <item>
      <title>Dynamic Factor Models with Forward-Looking Views</title>
      <link>https://arxiv.org/abs/2509.11528</link>
      <description>arXiv:2509.11528v1 Announce Type: new 
Abstract: Prediction models calibrated using historical data may forecast poorly if the dynamics of the present and future differ from observations in the past. For this reason, predictions can be improved if information like forward looking views about the state of the system are used to refine the forecast. We develop an approach for combining a dynamic factor model for risky asset prices calibrated on historical data, and noisy expert views of future values of the factors/covariates in the model, and study the implications for dynamic portfolio choice. By exploiting the graphical structure linking factors, asset prices, and views, we derive closed-form expressions for the dynamics of the factor and price processes after conditioning on the views. For linear factor models, the price process becomes a time-inhomogeneous affine process with a new covariate formed from the views. We establish a novel theoretical connection between the conditional factor process and a process we call a Mean-Reverting Bridge (MrB), an extension of the classical Brownian bridge. We derive the investor's optimal portfolio strategy and show that views influence both the myopic mean-variance term and the intertemporal hedge. The optimal dynamic portfolio when the long-run mean of the expected return is uncertain and learned online from data is also derived. More generally, our framework offers a generalizable approach for embedding forward-looking information about covariates in a dynamic factor model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11528v1</guid>
      <category>math.OC</category>
      <category>q-fin.PM</category>
      <category>q-fin.RM</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anas Abdelhakmi, Andrew E. B. Lim</dc:creator>
    </item>
    <item>
      <title>Q-Linear Convergence of the Proximal Augmented Lagrangian Method for Non-Convex Conic Programming</title>
      <link>https://arxiv.org/abs/2509.11531</link>
      <description>arXiv:2509.11531v1 Announce Type: new 
Abstract: This paper provides a local convergence analysis of the proximal augmented Lagrangian method (PALM) applied to a class of non-convex conic programming problems. Previous convergence results for PALM typically imposed assumptions such as constraint non-degeneracy, strict complementarity, second-order sufficiency conditions, or a combination of constraint nondegeneracy with strong second-order sufficiency conditions. In contrast, our work demonstrates a Q-linear convergence rate for an inexact version of PALM in the context of non-convex conic programming, without requiring the uniqueness of the Lagrange multipliers. The analysis relies solely on the second-order sufficiency condition and the calmness property of the multiplier mapping, presenting a more relaxed set of conditions for ensuring convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11531v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ning Zhang, Yi Zhang</dc:creator>
    </item>
    <item>
      <title>Positive Definiteness and Stability of Interval Tensors</title>
      <link>https://arxiv.org/abs/2509.11540</link>
      <description>arXiv:2509.11540v1 Announce Type: new 
Abstract: In this paper, we focus on the positive definiteness and Hurwitz stability of interval tensors. First, we introduce auxiliary tensors $\mathcal{A}^z$ and establish equivalent conditions for the positive (semi-)definiteness of interval tensors. That is, an interval tensor is positive definite if and only if all $\mathcal{A}^z$ are positive (semi-)definite. For Hurwitz stability, it is revealed that the stability of the symmetric interval tensor $\mathcal{A}_s^I$ can deduce the stability of the interval tensor $\mathcal{A}^I$, and the stability of symmetric interval tensors is equivalent to that of auxiliary tensors $\tilde{\mathcal{A}}^z$. Finally, taking $4$th order $3$-dimensional interval tensors as examples, the specific sufficient conditions are built for their positive (semi-)definiteness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11540v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Li Ye, Yisheng Song</dc:creator>
    </item>
    <item>
      <title>Improved Rates for Stochastic Variance-Reduced Difference-of-Convex Algorithms</title>
      <link>https://arxiv.org/abs/2509.11657</link>
      <description>arXiv:2509.11657v1 Announce Type: new 
Abstract: In this work, we propose and analyze DCA-PAGE, a novel algorithm that integrates the difference-of-convex algorithm (DCA) with the ProbAbilistic Gradient Estimator (PAGE) to solve structured nonsmooth difference-of-convex programs. In the finite-sum setting, our method achieves a gradient computation complexity of $O(N + N^{1/2}\varepsilon^{-2})$ with sample size $N$, surpassing the previous best-known complexity of $O(N + N^{2/3}\varepsilon^{-2})$ for stochastic variance-reduced (SVR) DCA methods. Furthermore, DCA-PAGE readily extends to online settings with a similar optimal gradient computation complexity $O(b + b^{1/2}\varepsilon^{-2})$ with batch size $b$, a significant advantage over existing SVR DCA approaches that only work for the finite-sum setting. We further refine our analysis with a gap function, which enables us to obtain comparable convergence guarantees under milder assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11657v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anh Duc Nguyen, Alp Yurtsever, Suvrit Sra, Kim-Chuan Toh</dc:creator>
    </item>
    <item>
      <title>Two-point Random Gradient-free Methods for Model-free Feedback Optimization</title>
      <link>https://arxiv.org/abs/2509.11666</link>
      <description>arXiv:2509.11666v1 Announce Type: new 
Abstract: Feedback optimization has emerged as a promising approach for optimizing the steady-state operation of dynamical systems while requiring minimal modeling efforts. Unfortunately, most existing feedback optimization methods rely on knowledge of the plant dynamics, which may be difficult to obtain or estimate in practice. In this paper, we introduce a novel randomized two-point gradient-free feedback optimization method, inspired by zeroth-order optimization techniques. Our method relies on function evaluations at two points to estimate the gradient and update the control input in real-time. We provide convergence guarantees and show that our method is capable of computing an $\epsilon$-stationary point for smooth, nonconvex functions at a rate $\mathcal{O} (\epsilon^{-1})$, in line with existing results for two-point gradient-free methods for static optimization. Simulation results validate the findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11666v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Amir Mehrnoosh, Gianluca Bianchin</dc:creator>
    </item>
    <item>
      <title>Implicit Third-Order Peer Triplets with Variable Stepsizes for Gradient-Based Solutions in Large-Scale ODE-Constrained Optimal Control</title>
      <link>https://arxiv.org/abs/2509.11684</link>
      <description>arXiv:2509.11684v1 Announce Type: new 
Abstract: This paper is concerned with the theory, construction and application of variable-stepsize implicit Peer two-step methods that are super-convergent for variable stepsizes, i.e., preserve their classical order achieved for uniform stepsizes when applied in a gradient-based solution algorithm to solve ODE-constrained optimal control problems in a first-discretize-then-optimize setting. Gradients of the objective function can be computed most efficiently using approximate adjoint variables. High accuracy with moderate computational effort can be achieved through time integration methods that satisfy a sufficiently large number of adjoint order conditions for variable stepsizes and provide gradients with higher-order consistency. In this paper, we enhance our previously developed variable implicit two-step Peer triplets constructed in [J. Comput. Appl. Math. 460, 2025] to get ready for large-scale dynamical systems with varying time scales without loosing efficiency. A key advantage of Peer methods is their use of multiple stages with the same high stage order, which prevents order reduction - an issue commonly encountered in semi discretized PDE problems with boundary control. Two third-order methods with four stages, good stability properties, small error constants, and a grid adaptation by equi-distributing global errors are constructed and tested for a 1D boundary heat control problem and an optimal control of cytotoxic therapies in the treatment of prostate cancer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11684v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jens Lang, Bernhard A. Schmitt</dc:creator>
    </item>
    <item>
      <title>Computing all Nash equilibria of low-rank bi-matrix games</title>
      <link>https://arxiv.org/abs/2509.11718</link>
      <description>arXiv:2509.11718v1 Announce Type: new 
Abstract: We study constrained bi-matrix games, with a particular focus on low-rank games. Our main contribution is a framework that reduces low-rank games to smaller, equivalent constrained games, along with a necessary and sufficient condition for when such reductions exist. Building on this framework, we present three approaches for computing the set of extremal Nash equilibria, based on vertex enumeration, polyhedral calculus, and vector linear programming. Numerical case studies demonstrate the effectiveness of the proposed reduction and solution methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11718v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zachary Feinstein, Andreas L\"ohne, Birgit Rudloff</dc:creator>
    </item>
    <item>
      <title>Convergence Filters for Efficient Economic MPC of Non-dissipative Systems</title>
      <link>https://arxiv.org/abs/2509.11869</link>
      <description>arXiv:2509.11869v1 Announce Type: new 
Abstract: This note presents a novel, efficient economic model predictive control (EMPC) scheme for non-dissipative systems subject to state and input constraints. A new conception of convergence filters is defined to address the stability issue of EMPC for constrained non-dissipative systems. Three convergence filters are designed accordingly to be imposed into the receding horizon optimization problem of EMPC. To improve online computational efficiency, the variable horizon idea without terminal constraints is adopted to compromise the convergence speed, economic performance, and computational burden of EMPC. Moreover, sufficient conditions are derived to guarantee the recursive feasibility and stability of the EMPC. The advantages of the proposed EMPC are validated by a classical non-dissipative continuous stirred-tank reactor.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11869v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Defeng He, Weiliang Xiong, Shiqiang He, Haiping Du</dc:creator>
    </item>
    <item>
      <title>An Inexact Tensor-Train Primal-Dual Interior-Point Method for Semidefinite Programs</title>
      <link>https://arxiv.org/abs/2509.11890</link>
      <description>arXiv:2509.11890v1 Announce Type: new 
Abstract: In this work, we introduce an interior-point method that employs tensor decompositions to efficiently represent and manipulate the variables and constraints of semidefinite programs, targeting problems where the solutions may not be low-rank but admit low-tensor-train rank approximations. Our method maintains approximate superlinear convergence despite inexact computations in the tensor format and leverages a primal-dual infeasible interior-point framework. In experiments on Maximum Cut, Maximum Stable Set, and Correlation Clustering, the tensor-train interior point method handles problems up to size $2^{12}$ with duality gaps around $10^{-6}$ in approximately 1.5~h and using less than 2~GB of memory, outperforming state-of-the-art solvers on larger instances. Moreover, numerical evidence indicates that tensor-train ranks of the iterates remain moderate along the interior-point trajectory, explaining the scalability of the approach. Tensor-train interior point methods offer a promising avenue for problems that lack traditional sparsity or low-rank structure, exploiting tensor-train structures instead.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11890v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Frederik Kelbel, Sergey Dolgov, Dante Kalise, Alessandra Russo</dc:creator>
    </item>
    <item>
      <title>Fractional-Order Nesterov Dynamics for Convex Optimization</title>
      <link>https://arxiv.org/abs/2509.11987</link>
      <description>arXiv:2509.11987v1 Announce Type: new 
Abstract: We propose and analyze a class of second-order dynamical systems for continuous-time optimization that incorporate fractional-order gradient terms. The system is given by \begin{equation} \ddot{x}(t) + \frac{\alpha}{t}\dot{x}(t) + \nabla^{\theta} f(x(t)) = 0, \end{equation} where $\theta \in (1,2)$, and the fractional operators are interpreted in the sense of Caputo, Riemann--Liouville, and Gr\"unwald--Letnikov derivatives. This formulation interpolates between memory effects of fractional dynamics and higher-order damping mechanisms, thereby extending the classical Nesterov accelerated flow into the fractional domain. A particular focus of our analysis is the regime $\alpha \leq 3$, and especially the critical case $\alpha = 3$, where the ordinary Nesterov flow fails to guarantee convergence. We show that in the fractional setting, convergence can still be established, with fractional gradient terms providing a stabilizing effect that compensates for the borderline damping. This highlights the ability of fractional dynamics to overcome fundamental limitations of classical second-order flows. We develop a convergence analysis framework for such systems by introducing fractional Opial-type lemmas and Lyapunov memory functionals. In the convex case, we establish weak convergence of trajectories toward the minimizer, as well as asymptotic decay of functional values. For strongly convex functions, we obtain explicit convergence rates that improve upon those of standard second-order flows</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11987v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tumelo Ranoto</dc:creator>
    </item>
    <item>
      <title>SSNCVX: A primal-dual semismooth Newton method for convex composite optimization problem</title>
      <link>https://arxiv.org/abs/2509.11995</link>
      <description>arXiv:2509.11995v1 Announce Type: new 
Abstract: In this paper, we propose a uniform semismooth Newton-based algorithmic framework called SSNCVX for solving a broad class of convex composite optimization problems.
  By exploiting the augmented Lagrangian duality, we reformulate the original problem into a saddle point problem and characterize the optimality conditions via a semismooth system of nonlinear equations. The nonsmooth structure is handled internally without requiring problem specific transformation or introducing auxiliary variables. This design allows easy modifications to the model structure, such as adding linear, quadratic, or shift terms through simple interface-level updates. The proposed method features a single loop structure that simultaneously updates the primal and dual variables via a semismooth Newton step. Extensive numerical experiments on benchmark datasets show that SSNCVX outperforms state-of-the-art solvers in both robustness and efficiency across a wide range of problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11995v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Zhanwang Deng, Tao Wei, Jirui Ma, Zaiwen Wen</dc:creator>
    </item>
    <item>
      <title>A Two-fold Randomization Framework for Impulse Control Problems</title>
      <link>https://arxiv.org/abs/2509.12018</link>
      <description>arXiv:2509.12018v2 Announce Type: new 
Abstract: We propose and analyze a randomization scheme for a general class of impulse control problems. The solution to this randomized problem is characterized as the fixed point of a compound operator which consists of a regularized nonlocal operator and a regularized stopping operator. This approach allows us to derive a semi-linear Hamilton-Jacobi-Bellman (HJB) equation. Through an equivalent randomization scheme with a Poisson compound measure, we establish a verification theorem that implies the uniqueness of the solution. Via an iterative approach, we prove the existence of the solution. The existence-and-uniqueness result ensures the randomized problem is well-defined. We then demonstrate that our randomized impulse control problem converges to its classical counterpart as the randomization parameter $\pmb \lambda$ vanishes. This convergence, combined with the value function's $C^{2,\alpha}_{loc}$ regularity, confirms our framework provides a robust approximation and a foundation for developing learning algorithms. Under this framework, we propose an offline reinforcement learning (RL) algorithm. Its policy improvement step is naturally derived from the iterative approach from the existence proof, which enjoys a geometric convergence rate. We implement a model-free version of the algorithm and numerically demonstrate its effectiveness using a widely-studied example. The results show that our RL algorithm can learn the randomized solution, which accurately approximates its classical counterpart. A sensitivity analysis with respect to the volatility parameter $\sigma$ in the state process effectively demonstrates the exploration-exploitation tradeoff.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.12018v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haoyang Cao, Yuchao Dong, Zhouhao Yang</dc:creator>
    </item>
    <item>
      <title>Optimal Solutions to Deflect Earth Crossing Objects Using Laser</title>
      <link>https://arxiv.org/abs/2509.12033</link>
      <description>arXiv:2509.12033v1 Announce Type: new 
Abstract: This paper solves and analyzes a trajectory optimization problem to deflect Earth-crossing objects (ECOs) employing continuous thrust obtained using a laser ablative system. The optimal control is determined for various initial ECO-Earth configurations to achieve the desired miss distance. The formulation incorporates the gravitational effect on the object due to the Earth using the patched-conic method. The constrained trajectory optimization problem is solved using Non-Linear Programming (NLP). First, the continuous control problem is solved, assuming both constant and variable power consumption, followed by a detailed comparison between the continuous control schemes. Subsequently, the work extends to studying sub-optimal solutions that can accommodate power fluctuations in the controller. The optimal control offers a range of alternative operational methods for asteroid deflection missions with trade-offs in power consumption and the total mission time. For impulsive deflection, the existing work reports two optimal solutions. One of the solutions is found to be better as it leads to a final ECO orbit that has its next Earth passage later than the other solution. Finally, the Moon's gravitational effect on the orbit of an ECO is studied. The reported results provide a comprehensive understanding of various scenarios in the process of ECO deflection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.12033v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Vivek Verma, Shribharath B., Mangal Kothari</dc:creator>
    </item>
    <item>
      <title>Reachability of gradient dynamics</title>
      <link>https://arxiv.org/abs/2509.12165</link>
      <description>arXiv:2509.12165v1 Announce Type: new 
Abstract: We show that gradient dynamics can converge to any local minimum of a semi-algebraic function. Our results cover both discrete and continuous dynamics. For discrete gradient dynamics, we show that it can converge to any local minimum once the stepsize is nonsummable and sufficiently small, and the initial value is properly chosen.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.12165v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cedric Josz, Wenqing Ouyang</dc:creator>
    </item>
    <item>
      <title>Using Integer Programming to Solve Games, Puzzles, and Ciphers</title>
      <link>https://arxiv.org/abs/2509.12174</link>
      <description>arXiv:2509.12174v1 Announce Type: new 
Abstract: In this paper, we introduce three different classes of undergraduate research projects that implement model building and integer programming. These research projects focus on determining and analyzing solutions to the game The Genius Square, optimizing allocation of trains to maximize points in the game Ticket to Ride, and (code)breaking monoalphabetic substitution ciphers. Initial models and analyses for these scenarios that came from previous undergraduate research projects are shared along with a variety of open research questions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.12174v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elizabeth Bouzarth, John Harris, Kevin Hutson, Christian Millichap</dc:creator>
    </item>
    <item>
      <title>A Converse Control Lyapunov Theorem for Joint Safety and Stability</title>
      <link>https://arxiv.org/abs/2509.12182</link>
      <description>arXiv:2509.12182v1 Announce Type: new 
Abstract: We show that the existence of a strictly compatible pair of control Lyapunov and control barrier functions is equivalent to the existence of a single smooth Lyapunov function that certifies both asymptotic stability and safety. This characterization complements existing literature on converse Lyapunov functions by establishing a partial differential equation (PDE) characterization with prescribed boundary conditions on the safe set, ensuring that the safe set is exactly certified by this Lyapunov function. The result also implies that if a safety and stability specification cannot be certified by a single Lyapunov function, then any pair of control Lyapunov and control barrier functions necessarily leads to a conflict and cannot be satisfied simultaneously in a robust sense.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.12182v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thanin Quartz, Maxwell Fitzsimmons, Jun Liu</dc:creator>
    </item>
    <item>
      <title>JD.com Improves Fulfillment Efficiency with Data-driven Integrated Assortment Planning and Inventory Allocation</title>
      <link>https://arxiv.org/abs/2509.12183</link>
      <description>arXiv:2509.12183v1 Announce Type: new 
Abstract: This paper presents data-driven approaches for integrated assortment planning and inventory allocation that significantly improve fulfillment efficiency at JD.com, a leading E-commerce company. JD.com uses a two-level distribution network that includes regional distribution centers (RDCs) and front distribution centers (FDCs). Selecting products to stock at FDCs and then optimizing daily inventory allocation from RDCs to FDCs is critical to improving fulfillment efficiency, which is crucial for enhancing customer experiences. For assortment planning, we propose efficient algorithms to maximize the number of orders that can be fulfilled by FDCs (local fulfillment). For inventory allocation, we develop a novel end-to-end algorithm that integrates forecasting, optimization, and simulation to minimize lost sales and inventory transfer costs. Numerical experiments demonstrate that our methods outperform existing approaches, increasing local order fulfillment rates by 0.54% and our inventory allocation algorithm increases FDC demand satisfaction rates by 1.05%. Considering the high-volume operations of JD.com, with millions of weekly orders per region, these improvements yield substantial benefits beyond the company's established supply chain system. Implementation across JD.com's network has reduced costs, improved stock availability, and increased local order fulfillment rates for millions of orders annually.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.12183v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zuo-Jun Max Shen, Shuo Sun, Yongzhi Qi, Hao Hu, Ningxuan Kang, Jianshen Zhang, Xin Wang, Xiaoming Lin</dc:creator>
    </item>
    <item>
      <title>Dynamic Decision Modeling for Viable Short and Long Term Production Policies: An HJB Approach</title>
      <link>https://arxiv.org/abs/2509.12205</link>
      <description>arXiv:2509.12205v1 Announce Type: new 
Abstract: This study introduces a mathematical framework to investigate the viability and reachability of production systems under constraints. We develop a model that incorporates key decision variables, such as pricing policy, quality investment, and advertising, to analyze short-term tactical decisions and long-term strategic outcomes. In the short term, we constructed a capture basin that defined the initial conditions under which production viability constraints were satisfied within the target zone. In the long term, we explore the dynamics of product quality and market demand to achieve and sustain the desired target. The Hamilton-Jacobi-Bellman (HJB) theory characterizes the capture basin and viability kernel using viscosity solutions of the HJB equation. This approach, which avoids controllability assumptions, is well suited to viability problems with specified targets. It provides managers with insights into maintaining production and inventory levels within viable ranges while considering product quality and evolving market demand. We numerically studied the HJB equation to design and test computational methods that validate the theoretical insights. Simulations offer practical tools for decision-makers to address operational challenges while aligning with the long-term sustainability goals. This study enhances the production system performance and resilience by linking rigorous mathematics with actionable solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.12205v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Achraf Bouhmady, Mustapha Serhani, Nadia Raissi</dc:creator>
    </item>
    <item>
      <title>Designing MacPherson Suspension Architectures using Bayesian Optimization</title>
      <link>https://arxiv.org/abs/2206.09022</link>
      <description>arXiv:2206.09022v1 Announce Type: cross 
Abstract: Engineering design is traditionally performed by hand: an expert makes design proposals based on past experience, and these proposals are then tested for compliance with certain target specifications. Testing for compliance is performed first by computer simulation using what is called a discipline model. Such a model can be implemented by a finite element analysis, multibody systems approach, etc. Designs passing this simulation are then considered for physical prototyping. The overall process may take months, and is a significant cost in practice. We have developed a Bayesian optimization system for partially automating this process by directly optimizing compliance with the target specification with respect to the design parameters. The proposed method is a general framework for computing a generalized inverse of a high-dimensional non-linear function that does not require e.g. gradient information, which is often unavailable from discipline models. We furthermore develop a two-tier convergence criterion based on (i) convergence to a solution optimally satisfying all specified design criteria, or (ii) convergence to a minimum-norm solution. We demonstrate the proposed approach on a vehicle chassis design problem motivated by an industry setting using a state-of-the-art commercial discipline model. We show that the proposed approach is general, scalable, and efficient, and that the novel convergence criteria can be implemented straightforwardly based on existing concepts and subroutines in popular Bayesian optimization software packages.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.09022v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sinnu Susan Thomas, Jacopo Palandri, Mohsen Lakehal-ayat, Punarjay Chakravarty, Friedrich Wolf-Monheim, Matthew B. Blaschko</dc:creator>
    </item>
    <item>
      <title>Optimal Multimarginal Schr\"odinger Bridge: Minimum Spanning Tree over Measure-valued Vertices</title>
      <link>https://arxiv.org/abs/2509.10626</link>
      <description>arXiv:2509.10626v1 Announce Type: cross 
Abstract: The Multimarginal Schr\"odinger Bridge (MSB) finds the optimal coupling among a collection of random vectors with known statistics and a known correlation structure. In the MSB formulation, this correlation structure is specified \emph{a priori} as an undirected connected graph with measure-valued vertices. In this work, we formulate and solve the problem of finding the optimal MSB in the sense we seek the optimal coupling over all possible graph structures. We find that computing the optimal MSB amounts to solving the minimum spanning tree problem over measure-valued vertices. We show that the resulting problem can be solved in two steps. The first step constructs a complete graph with edge weight equal to a sum of the optimal value of the corresponding bimarginal SB and the entropies of the endpoints. The second step solves a standard minimum spanning tree problem over that complete weighted graph. Numerical experiments illustrate the proposed solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10626v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Georgiy A. Bondar, Abhishek Halder</dc:creator>
    </item>
    <item>
      <title>Learning Concave Bid Shading Strategies in Online Auctions via Measure-valued Proximal Optimization</title>
      <link>https://arxiv.org/abs/2509.10693</link>
      <description>arXiv:2509.10693v1 Announce Type: cross 
Abstract: This work proposes a bid shading strategy for first-price auctions as a measure-valued optimization problem. We consider a standard parametric form for bid shading and formulate the problem as convex optimization over the joint distribution of shading parameters. After each auction, the shading parameter distribution is adapted via a regularized Wasserstein-proximal update with a data-driven energy functional. This energy functional is conditional on the context, i.e., on publisher/user attributes such as domain, ad slot type, device, or location. The proposed algorithm encourages the bid distribution to place more weight on values with higher expected surplus, i.e., where the win probability and the value gap are both large. We show that the resulting measure-valued convex optimization problem admits a closed form solution. A numerical example illustrates the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10693v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Iman Nodozi, Djordje Gligorijevic, Abhishek Halder</dc:creator>
    </item>
    <item>
      <title>Combinatorial Control Barrier Functions: Nested Boolean and p-choose-r Compositions of Safety Constraints</title>
      <link>https://arxiv.org/abs/2509.10716</link>
      <description>arXiv:2509.10716v1 Announce Type: cross 
Abstract: This paper investigates the problem of composing multiple control barrier functions (CBFs) -- and matrix control barrier functions (MCBFs) -- through logical and combinatorial operations. Standard CBF formulations naturally enable conjunctive (AND) combinations, but disjunctive (OR) and more general logical structures introduce nonsmoothness and possibly a combinatorial blow-up in the number of logical combinations. We introduce the framework of combinatorial CBFs that addresses p-choose-r safety specifications and their nested composition. The proposed framework ensures safety for the exact safe set in a scalable way, using the original number of primitive constraints. We establish theoretical guarantees on safety under these compositions, and we demonstrate their use on a patrolling problem in a multi-agent system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10716v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pio Ong, Haejoon Lee, Tamas G. Molnar, Dimitra Panagou, Aaron D. Ames</dc:creator>
    </item>
    <item>
      <title>ViSTR-GP: Online Cyberattack Detection via Vision-to-State Tensor Regression and Gaussian Processes in Automated Robotic Operations</title>
      <link>https://arxiv.org/abs/2509.10948</link>
      <description>arXiv:2509.10948v1 Announce Type: cross 
Abstract: Industrial robotic systems are central to automating smart manufacturing operations. Connected and automated factories face growing cybersecurity risks that can potentially cause interruptions and damages to physical operations. Among these attacks, data-integrity attacks often involve sophisticated exploitation of vulnerabilities that enable an attacker to access and manipulate the operational data and are hence difficult to detect with only existing intrusion detection or model-based detection. This paper addresses the challenges in utilizing existing side-channels to detect data-integrity attacks in robotic manufacturing processes by developing an online detection framework, ViSTR-GP, that cross-checks encoder-reported measurements against a vision-based estimate from an overhead camera outside the controller's authority. In this framework, a one-time interactive segmentation initializes SAM-Track to generate per-frame masks. A low-rank tensor-regression surrogate maps each mask to measurements, while a matrix-variate Gaussian process models nominal residuals, capturing temporal structure and cross-joint correlations. A frame-wise test statistic derived from the predictive distribution provides an online detector with interpretable thresholds. We validate the framework on a real-world robotic testbed with synchronized video frame and encoder data, collecting multiple nominal cycles and constructing replay attack scenarios with graded end-effector deviations. Results on the testbed indicate that the proposed framework recovers joint angles accurately and detects data-integrity attacks earlier with more frequent alarms than all baselines. These improvements are most evident in the most subtle attacks. These results show that plants can detect data-integrity attacks by adding an independent physical channel, bypassing the controller's authority, without needing complex instrumentation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10948v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.CR</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Navid Aftabi, Philip Samaha, Jin Ma, Long Cheng, Ramy Harik, Dan Li</dc:creator>
    </item>
    <item>
      <title>Approximation in an optimal design problem governed by the heat equation</title>
      <link>https://arxiv.org/abs/2509.11011</link>
      <description>arXiv:2509.11011v1 Announce Type: cross 
Abstract: This paper studies a two-material optimal design problem for the time-averaged duality pairing between a (possibly time-dependent) heat source and the weak solution of an initial-boundary value problem for the heat equation with a two-material diffusion coefficient, under a volume constraint. In general, such optimal designs are not guaranteed to exist, and geometric constraints such as the perimeter are required. As an approximation of the problem with an additional perimeter constraint, a material representation based on a level set function, together with a perturbation of the Dirichlet energy, is employed. It is then shown that optimal level set functions exist for the perturbation problem, and the corresponding minimum value converges to that of the elliptic case, thereby elucidating the long-time behavior. Furthermore, two-material domains satisfying this property are also constructed via the nonlinear diffusion-based level set method. In particular, the asymptotic behavior with respect to the perturbation parameter is clarified, and the validity of the approximation is established.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11011v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kei Matsushima, Tomoyuki Oka</dc:creator>
    </item>
    <item>
      <title>Privacy-Preserving Uncertainty Disclosure for Facilitating Enhanced Energy Storage Dispatch</title>
      <link>https://arxiv.org/abs/2509.11022</link>
      <description>arXiv:2509.11022v1 Announce Type: cross 
Abstract: This paper proposes a novel privacy-preserving uncertainty disclosure framework, enabling system operators to release marginal value function bounds to reduce the conservativeness of interval forecast and mitigate excessive withholding, thereby enhancing storage dispatch and social welfare. We propose a risk-averse analytical storage arbitrage model based on stochastic dynamic programming and explicitly account for uncertainty intervals in value function training. We derive real-time marginal value function bounds using a rolling-horizon chance-constrained economic dispatch formulation. We rigorously prove that the bounds reliably cap the true opportunity cost and dynamically converge to the hindsight value. We verify that both the marginal value function and its bounds monotonically decrease with the state of charge and increase with uncertainty, providing a theoretical basis for risk-averse strategic behaviors and SoC-dependent designs. We validate the effectiveness of the proposed framework via an agent-based simulation on the ISO-NE test system. Under 50% renewable capacity and 35% storage capacity, the proposed bounds enhance storage response by 38.91% and reduce the optimality gap to 3.91% through improved interval predictions. Additionally, by mitigating excessive withholding, the bounds yield an average system cost reduction of 0.23% and an average storage profit increase of 13.22%. These benefits further scale with higher prediction conservativeness, storage capacity, and system uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11022v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ning Qi, Xiaolong Jin, Kai Hou, Zeyu Liu, Hongjie Jia, Wei Wei</dc:creator>
    </item>
    <item>
      <title>Online Optimization on Hadamard Manifolds: Curvature Independent Regret Bounds on Horospherically Convex Objectives</title>
      <link>https://arxiv.org/abs/2509.11236</link>
      <description>arXiv:2509.11236v1 Announce Type: cross 
Abstract: We study online Riemannian optimization on Hadamard manifolds under the framework of horospherical convexity (h-convexity). Prior work mostly relies on the geodesic convexity (g-convexity), leading to regret bounds scaling poorly with the manifold curvature. To address this limitation, we analyze Riemannian online gradient descent for h-convex and strongly h-convex functions and establish $O(\sqrt{T})$ and $O(\log(T))$ regret guarantees, respectively. These bounds are curvature-independent and match the results in the Euclidean setting. We validate our approach with experiments on the manifold of symmetric positive definite (SPD) matrices equipped with the affine-invariant metric. In particular, we investigate online Tyler's $M$-estimation and online Fr\'echet mean computation, showing the application of h-convexity in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11236v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Emre Sahinoglu, Shahin Shahrampour</dc:creator>
    </item>
    <item>
      <title>Chow and Rashevskii meet Sobolev</title>
      <link>https://arxiv.org/abs/2509.11400</link>
      <description>arXiv:2509.11400v1 Announce Type: cross 
Abstract: We prove a weak version of the Chow-Rashevskii theorem for vector fields having only Sobolev regularity and generating suitable flows as selections of solutions to the respective ODEs, for a.e.\ initial datum.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11400v1</guid>
      <category>math.DS</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sergey Kryzhevich, Eugene Stepanov, Dario Trevisan</dc:creator>
    </item>
    <item>
      <title>Long-time dynamics and universality of nonconvex gradient descent</title>
      <link>https://arxiv.org/abs/2509.11426</link>
      <description>arXiv:2509.11426v1 Announce Type: cross 
Abstract: This paper develops a general approach to characterize the long-time trajectory behavior of nonconvex gradient descent in generalized single-index models in the large aspect ratio regime. In this regime, we show that for each iteration the gradient descent iterate concentrates around a deterministic vector called the `Gaussian theoretical gradient descent', whose dynamics can be tracked by a state evolution system of two recursive equations for two scalars. Our concentration guarantees hold universally for a broad class of design matrices and remain valid over long time horizons until algorithmic convergence or divergence occurs. Moreover, our approach reveals that gradient descent iterates are in general approximately independent of the data and strongly incoherent with the feature vectors, a phenomenon previously known as the `implicit regularization' effect of gradient descent in specific models under Gaussian data.
  As an illustration of the utility of our general theory, we present two applications of different natures in the regression setting. In the first, we prove global convergence of nonconvex gradient descent with general independent initialization for a broad class of structured link functions, and establish universality of randomly initialized gradient descent in phase retrieval for large aspect ratios. In the second, we develop a data-free iterative algorithm for estimating state evolution parameters along the entire gradient descent trajectory, thereby providing a low-cost yet statistically valid tool for practical tasks such as hyperparameter tuning and runtime determination.
  As a by-product of our analysis, we show that in the large aspect ratio regime, the Gaussian theoretical gradient descent coincides with a recent line of dynamical mean-field theory for gradient descent over the constant-time horizon.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11426v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiyang Han</dc:creator>
    </item>
    <item>
      <title>Lie symmetry analysis and similarity reductions for the tempered-fractional Keller Segel system</title>
      <link>https://arxiv.org/abs/2509.11690</link>
      <description>arXiv:2509.11690v1 Announce Type: cross 
Abstract: We perform a Lie symmetry analysis on the tempered-fractional Keller Segel (TFKS) system, a chemo-taxis model incorporating anomalous diffusion. A novel approach is used to handle the nonlocal nature of tempered fractional operators. By deriving the full set of Lie point symmetries and identifying the optimal one-dimensional subalgebras, we reduce the TFKS PDEs to ordinary differential equations (ODEs), yielding new exact solutions. These results offer insights into the long-term behavior and aggregation dynamics of the TFKS model and present a methodology applicable to other tempered fractional differential equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11690v1</guid>
      <category>math-ph</category>
      <category>math.AP</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ghorbanali Haghighatdoost, Mustafa Bazghandi</dc:creator>
    </item>
    <item>
      <title>Data Fusion and Machine Learning for Ship Fuel Consumption Modelling -- A Case of Bulk Carrier Vessel</title>
      <link>https://arxiv.org/abs/2509.11750</link>
      <description>arXiv:2509.11750v1 Announce Type: cross 
Abstract: There is an increasing push for operational measures to reduce ships' bunker fuel consumption and carbon emissions, driven by the International Maritime Organization (IMO) mandates. Key performance indicators such as the Energy Efficiency Operational Indicator (EEOI) focus on fuel efficiency. Strategies like trim optimization, virtual arrival, and green routing have emerged. The theoretical basis for these approaches lies in accurate prediction of fuel consumption as a function of sailing speed, displacement, trim, climate, and sea state. This study utilized 296 voyage reports from a bulk carrier vessel over one year (November 16, 2021 to November 21, 2022) and 28 parameters, integrating hydrometeorological big data from the Copernicus Marine Environment Monitoring Service (CMEMS) with 19 parameters and the European Centre for Medium-Range Weather Forecasts (ECMWF) with 61 parameters. The objective was to evaluate whether fusing external public data sources enhances modeling accuracy and to highlight the most influential parameters affecting fuel consumption. The results reveal a strong potential for machine learning techniques to predict ship fuel consumption accurately by combining voyage reports with climate and sea data. However, validation on similar classes of vessels remains necessary to confirm generalizability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11750v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abdella Mohamed, Xiangyu Hu, Christian Hendricks</dc:creator>
    </item>
    <item>
      <title>Fundamental limits on taming infectious disease epidemics</title>
      <link>https://arxiv.org/abs/2509.11764</link>
      <description>arXiv:2509.11764v1 Announce Type: cross 
Abstract: Epidemic control frequently relies on adjusting interventions based on prevalence. But designing such policies is a highly non-trivial problem due to uncertain intervention effects, costs and the difficulty of quantifying key transmission mechanisms and parameters. Here, using exact mathematical and computational methods, we reveal a fundamental limit in epidemic control in that prevalence feedback policies are outperformed by a single optimally chosen constant control level. Specifically, we find no incentive to use prevalence based control under a wide class of cost functions that depend arbitrarily on interventions and scale with infections. We also identify regimes where prevalence feedback is beneficial. Our results challenge the current understanding that prevalence based interventions are required for epidemic control and suggest that, for many classes of epidemics, interventions should not be varied unless the epidemic is near the herd immunity threshold.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11764v1</guid>
      <category>q-bio.PE</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giovanni Pugliese Carratelli, Xiaodong Cheng, Kris V. Parag, Ioannis Lestas</dc:creator>
    </item>
    <item>
      <title>Low-rank Orthogonalization for Large-scale Matrix Optimization with Applications to Foundation Model Training</title>
      <link>https://arxiv.org/abs/2509.11983</link>
      <description>arXiv:2509.11983v1 Announce Type: cross 
Abstract: Neural network (NN) training is inherently a large-scale matrix optimization problem, yet the matrix structure of NN parameters has long been overlooked. Recently, the optimizer Muon \cite{jordanmuon}, which explicitly exploits this structure, has gained significant attention for its strong performance in foundation model training. A key component contributing to Muon's success is matrix orthogonalization. In this paper, we propose {\it low-rank orthogonalization}, which explicitly leverages the low-rank nature of gradients during NN training. Building on this, we propose low-rank matrix-signed gradient descent and a low-rank variant of Muon. Our numerical experiments demonstrate the superior performance of low-rank orthogonalization, with the low-rank Muon achieving promising results in GPT-2 and LLaMA pretraining -- surpassing the performance of the carefully tuned vanilla Muon. Theoretically, we establish the iteration complexity of the low-rank matrix-signed gradient descent for finding an approximate stationary solution, as well as that of low-rank Muon for finding an approximate stochastic stationary solution under heavy-tailed noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11983v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Chuan He, Zhanwang Deng, Zhaosong Lu</dc:creator>
    </item>
    <item>
      <title>Learning Neural Networks by Neuron Pursuit</title>
      <link>https://arxiv.org/abs/2509.12154</link>
      <description>arXiv:2509.12154v1 Announce Type: cross 
Abstract: The first part of this paper studies the evolution of gradient flow for homogeneous neural networks near a class of saddle points exhibiting a sparsity structure. The choice of these saddle points is motivated from previous works on homogeneous networks, which identified the first saddle point encountered by gradient flow after escaping the origin. It is shown here that, when initialized sufficiently close to such saddle points, gradient flow remains near the saddle point for a sufficiently long time, during which the set of weights with small norm remain small but converge in direction. Furthermore, important empirical observations are made on the behavior of gradient descent after escaping these saddle points. The second part of the paper, motivated by these results, introduces a greedy algorithm to train deep neural networks called Neuron Pursuit (NP). It is an iterative procedure which alternates between expanding the network by adding neuron(s) with carefully chosen weights, and minimizing the training loss using this augmented network. The efficacy of the proposed algorithm is validated using numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.12154v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Akshay Kumar, Jarvis Haupt</dc:creator>
    </item>
    <item>
      <title>Optimal Savings with Preference for Wealth</title>
      <link>https://arxiv.org/abs/2509.12195</link>
      <description>arXiv:2509.12195v1 Announce Type: cross 
Abstract: The consumption function maps current wealth and the exogenous state to current consumption. We prove the existence and uniqueness of a consumption function when the agent has a preference for wealth. When the period utility functions are restricted to power functions, we prove that the consumption function is asymptotically linear as wealth tends to infinity and provide a complete characterization of the asymptotic slopes. When the risk aversion with respect to wealth is less than that for consumption, the asymptotic slope is zero regardless of other model parameters, implying wealthy households save a large fraction of their income, consistent with empirical evidence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.12195v1</guid>
      <category>econ.TH</category>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qingyin Ma, Alexis Akira Toda</dc:creator>
    </item>
    <item>
      <title>Optimal investment with insider information using Skorokhod &amp; Russo-Vallois integration</title>
      <link>https://arxiv.org/abs/2211.07471</link>
      <description>arXiv:2211.07471v4 Announce Type: replace 
Abstract: We study the maximization of the logarithmic utility for an insider with different anticipating techniques. Our aim is to compare the utilization of Russo-Vallois forward and Skorokhod integrals in this context. Theoretical analysis and illustrative numerical examples showcase that the Skorokhod insider outperforms the forward insider. This remarkable observation stands in contrast to the scenario involving risk-neutral traders. Furthermore, an ordinary trader could surpass both insiders if a significant negative fluctuation in the driving stochastic process leads to a sufficiently negative final value. These findings underline the intricate interplay between anticipating stochastic calculus and nonlinear utilities, which may yield non-intuitive results from the financial viewpoint.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.07471v4</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>q-fin.MF</category>
      <category>q-fin.PM</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s10957-025-02789-z</arxiv:DOI>
      <arxiv:journal_reference>J Optim Theory Appl 207, 48 (2025)</arxiv:journal_reference>
      <dc:creator>Mauricio Elizalde, Carlos Escudero, Tomoyuki Ichiba</dc:creator>
    </item>
    <item>
      <title>When Deep Learning Meets Polyhedral Theory: A Survey</title>
      <link>https://arxiv.org/abs/2305.00241</link>
      <description>arXiv:2305.00241v4 Announce Type: replace 
Abstract: In the past decade, deep learning became the prevalent methodology for predictive modeling thanks to the remarkable accuracy of deep neural networks in tasks such as computer vision and natural language processing. Meanwhile, the structure of neural networks converged back to simpler representations based on piecewise constant and piecewise linear functions such as the Rectified Linear Unit (ReLU), which became the most commonly used type of activation function in neural networks. That made certain types of network structure $\unicode{x2014}$such as the typical fully-connected feedforward neural network$\unicode{x2014}$ amenable to analysis through polyhedral theory and to the application of methodologies such as Linear Programming (LP) and Mixed-Integer Linear Programming (MILP) for a variety of purposes. In this paper, we survey the main topics emerging from this fast-paced area of work, which bring a fresh perspective to understanding neural networks in more detail as well as to applying linear optimization techniques to train, verify, and reduce the size of such networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.00241v4</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joey Huchette, Gonzalo Mu\~noz, Thiago Serra, Calvin Tsay</dc:creator>
    </item>
    <item>
      <title>Set-Valued Koopman Theory for Control Systems</title>
      <link>https://arxiv.org/abs/2401.11569</link>
      <description>arXiv:2401.11569v3 Announce Type: replace 
Abstract: In this paper, we introduce a new notion of Koopman operator which faithfully encodes the dynamics of controlled systems by leveraging the tools of set-valued analysis. In this context, we propose generalisations of the Liouville and Perron-Frobenius operators, and show that they respectively coincide with proper set-valued analogues of the infinitesimal generator and dual operator of the Koopman semigroup. We also give meaning to the spectra of these set-valued maps and prove an adapted version of the classical spectral mapping theorem relating the eigenvalues of a semigroup with those of its generator. Our approach provides theoretical justifications for existing practical methods in the Koopman community that study control systems by bundling together the Koopman and Liouville operators associated with different control inputs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.11569v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Beno\^it Bonnet-Weill, Milan Korda</dc:creator>
    </item>
    <item>
      <title>Newsvendor under Ambiguity and Misspecification</title>
      <link>https://arxiv.org/abs/2405.07008</link>
      <description>arXiv:2405.07008v2 Announce Type: replace 
Abstract: Problem definition: We consider a newsvendor problem with unknown demand distribution, where we distinguish ambiguity under which the newsvendor does not differentiate demand distributions of common characteristics and misspecification under which such characteristics might be misspecified.
  Methodology/results: The newsvendor hedges against ambiguity and misspecification by maximizing the worst-case expected profit regularized by a distribution's distance to an ambiguity set. Focusing on the popular mean-variance ambiguity set and optimal-transport cost for the misspecification, we show that the decision criterion of misspecification aversion possesses insightful interpretations as distributional transforms. We derive the closed-form optimal order quantity that generalizes the solution of the Scarf model under only ambiguity aversion. We establish the finite-sample performance guarantee, which consists of two parts: in-sample optimal value and out-of-sample effect of misspecification that can be further decoupled into estimation error and distribution shift. We also extend the framework to multiple products, distributional characteristics specified via optimal transport, and misspecification measured by total variation distance.
  Managerial implications: The closed-form solution highlights the impact of misspecification aversion: the optimal order quantity under misspecification aversion can decrease as the price or variance increases, reversing the monotonicity of that under only ambiguity aversion. Hence, ambiguity and misspecification, as different layers of distributional uncertainty, can result in distinct operational consequences. The finite-sample performance guarantee theoretically justifies the necessity of incorporating misspecification aversion in a non-stationary environment, which is also well demonstrated in our experiments with real-world data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07008v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Feng Liu, Zhi Chen, Ruodu Wang, Shuming Wang</dc:creator>
    </item>
    <item>
      <title>A constraint-based approach to function interpolation, with application to performance estimation for weakly convex optimisation</title>
      <link>https://arxiv.org/abs/2405.08405</link>
      <description>arXiv:2405.08405v3 Announce Type: replace 
Abstract: We consider the problem of obtaining interpolation constraints for function classes, i.e., necessary and sufficient constraints that a set of points, function values and (sub)gradients must satisfy to ensure the existence of a global function of the class considered, consistent with this set. The derivation of such constraints is crucial, e.g., in the performance analysis of optimization methods, since obtaining a priori tight performance guarantees requires using a tight description of function classes of interest. We propose an approach that allows setting aside all analytic properties of the function class to work only at an algebraic level, and to obtain counterexamples when a condition characterizing a function class cannot serve as an interpolation constraint. As an illustration, we provide interpolation constraints for the class of weakly convex functions with bounded subgradients, and rely on these constraints to outperform state-of-the-art bounds on the performance of the subgradient method on this class.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.08405v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anne Rubbens, Julien M. Hendrickx</dc:creator>
    </item>
    <item>
      <title>A tactical time slot management problem under mixed logit demand</title>
      <link>https://arxiv.org/abs/2407.02308</link>
      <description>arXiv:2407.02308v3 Announce Type: replace 
Abstract: We study the tactical time slot management problem under mixed logit demand for attended home delivery in subscription settings. We propose a static mixed-integer linear programming model that integrates delivery slot assortment, price discount decisions, and routing optimization while capturing customer heterogeneity through the mixed logit model. To overcome the computational challenges posed by simulation-based choice probabilities, we develop a simulation-based Adaptive Large Neighborhood Search method aligned with a Sample Average Approximation reformulation. Computational experiments on large-scale instances demonstrate the effectiveness of our approach in capturing stochastic customer behavior and preference heterogeneity, providing a scalable and flexible method for optimizing time slot management under complex demand structures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02308v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Dorsa Abdolhamidi, Virginie Lurkin</dc:creator>
    </item>
    <item>
      <title>Global Optimization Algorithm through High-Resolution Sampling</title>
      <link>https://arxiv.org/abs/2410.13737</link>
      <description>arXiv:2410.13737v4 Announce Type: replace 
Abstract: We present an optimization algorithm that can identify a global minimum of a potentially nonconvex smooth function with high probability, assuming the Gibbs measure of the potential satisfies a logarithmic Sobolev inequality. Our contribution is twofold: on the one hand we propose a global optimization method, which is built on an oracle sampling algorithm producing arbitrarily accurate samples from a given Gibbs measure. On the other hand, we propose a new sampling algorithm, drawing inspiration from both overdamped and underdamped Langevin dynamics, as well as from the high-resolution differential equation known for its acceleration in deterministic settings. While the focus of the paper is primarily theoretical, we demonstrate the effectiveness of our algorithms on the Rastrigin function, where it outperforms recent approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13737v4</guid>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Transactions on Machine Learning Research (09/2025)</arxiv:journal_reference>
      <dc:creator>Daniel Cortild, Claire Delplancke, Nadia Oudjane, Juan Peypouquet</dc:creator>
    </item>
    <item>
      <title>Composing Optimized Stepsize Schedules for Gradient Descent</title>
      <link>https://arxiv.org/abs/2410.16249</link>
      <description>arXiv:2410.16249v2 Announce Type: replace 
Abstract: Recent works by Altschuler and Parrilo and the authors have shown that it is possible to accelerate the convergence of gradient descent on smooth convex functions, even without momentum, just by picking special stepsizes. In this paper, we provide a general theory for composing stepsize schedules capturing all recent advances in this area and more. We propose three notions of ``composable'' stepsize schedules with elementary associated composition operations for combining them. From these operations, in addition to recovering recent works, we construct three highly optimized sequences of stepsize schedules. We first construct optimized stepsize schedules of every length generalizing the exponentially spaced silver stepsizes. We then construct highly optimized stepsizes schedules for minimizing final objective gap or gradient norm, improving on prior rates by constants and, more importantly, matching or beating the numerically computed minimax optimal schedules. We conjecture these schedules are in fact minimax (information theoretic) optimal. Several novel tertiary results follow from our theory including recovery of the recent dynamic gradient norm minimizing short stepsizes and extending them to objective gap minimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16249v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Benjamin Grimmer, Kevin Shu, Alex L. Wang</dc:creator>
    </item>
    <item>
      <title>Lipschitz-free Projected Subgradient Method with Time-varying Step-size</title>
      <link>https://arxiv.org/abs/2410.22336</link>
      <description>arXiv:2410.22336v3 Announce Type: replace 
Abstract: We introduce a novel family of time-varying step-sizes for the classical projected subgradient method, offering optimal ergodic convergence. Importantly, this approach does not depend on the Lipschitz assumption of the objective function, thereby broadening the convergence result of projected subgradient method to non-Lipschitz case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.22336v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s40305-025-00629-5</arxiv:DOI>
      <dc:creator>Yong Xia, Yanhao Zhang, Zhihan Zhu</dc:creator>
    </item>
    <item>
      <title>Suboptimal MPC with a Computation Governor: Stability, Recursive Feasibility, and Applications to ADMM</title>
      <link>https://arxiv.org/abs/2411.07919</link>
      <description>arXiv:2411.07919v2 Announce Type: replace 
Abstract: The paper considers a computational governor strategy to facilitate the implementation of Model Predictive Control (MPC) based on inexact optimization when the time available to compute the solution may be insufficient. In the setting of linear-quadratic MPC and a class of optimizers that includes Alternating Direction Method of Multipliers (ADMM), we derive conditions on the reference command adjustment by the computational governor and on a constraint tightening strategy which ensure recursive feasibility, convergence of the modified reference command, and closed-loop stability. An online procedure to select the modified reference command and construct an implicit terminal set is also proposed. A simulation example is reported which illustrates the developed procedures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07919v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Steven van Leeuwen, Ilya Kolmanovsky</dc:creator>
    </item>
    <item>
      <title>Differential Game with Geometric Formulation for Differential Systems Under Bilateral Perception Constraints</title>
      <link>https://arxiv.org/abs/2503.00434</link>
      <description>arXiv:2503.00434v2 Announce Type: replace 
Abstract: This letter employs differential game theory to address the defense problem of a circular target area with perception constraints, involving a single defender and a single attacker. The defender is restricted to moving along the perimeter, while the mobile attacker aims to make itself to the edge of the circular target to win. We examine a scenario where both the attacker and defender face perception constraints, dividing the interaction into four distinct stages based on detection capabilities and deriving the corresponding optimal control strategies. Simulations are conducted to validate the proposed strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00434v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinyi Zhu, Jiali Wang, Yang Tang, Fangfei Li, Yan Zhu</dc:creator>
    </item>
    <item>
      <title>A globalized inexact semismooth Newton method for strongly convex optimal control problems</title>
      <link>https://arxiv.org/abs/2503.21612</link>
      <description>arXiv:2503.21612v3 Announce Type: replace 
Abstract: We investigate a globalized inexact semismooth Newton method applied to strongly convex optimization problems in Hilbert spaces. Here, the semismooth Newton method is appplied to the dual problem, which has a continuously differentiable objective. We prove global strong convergence of iterates as well as transition to local superlinear convergence. The latter needs a second-order Taylor expansion involving semismooth derivative concepts. The convergence of the globalized method is demonstrated in numerical examples, for which the local unglobalized method diverges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21612v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Daniel Wachsmuth</dc:creator>
    </item>
    <item>
      <title>Hands-Off Covariance Steering: Inducing Feedback Sparsity via Iteratively Reweighted $\ell_{1,p}$ Regularization</title>
      <link>https://arxiv.org/abs/2504.00690</link>
      <description>arXiv:2504.00690v2 Announce Type: replace 
Abstract: We consider the problem of optimally steering the state covariance matrix of a discrete-time linear stochastic system to a desired terminal covariance matrix, while inducing the control input to be zero over many time intervals. We propose to induce sparsity in the feedback gain matrices by using a sum-of-norms version of the iteratively reweighted $\ell_1$-norm minimization. We show that the lossless convexification property holds even with the regularization term. Numerical simulations show that the proposed method produces a Pareto front of transient cost and sparsity that is not achievable by a simple $\ell_1$-norm minimization and closely approximates the $\ell_0$-norm minimization obtained from brute-force search.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.00690v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Naoya Kumagai, Kenshiro Oguri</dc:creator>
    </item>
    <item>
      <title>Parametric Reachable Sets Via Controlled Dynamical Embeddings</title>
      <link>https://arxiv.org/abs/2504.06955</link>
      <description>arXiv:2504.06955v2 Announce Type: replace 
Abstract: In this work, we propose a new framework for reachable set computation through continuous evolution of a set of parameters and offsets which define a parametope, through the intersection of constraints. This results in a dynamical approach towards nonlinear reachability analysis: a single trajectory of an embedding system provides a parametope reachable set for the original system, and uncertainties are accounted for through continuous parameter evolution. This is dual to most existing computational strategies, which define sets through some combination of generator vectors, and usually discretize the system dynamics. We show how, under some regularity assumptions of the dynamics and the set considered, any desired parameter evolution can be accommodated as long as the offset dynamics are set accordingly, providing a virtual "control input" for reachable set computation. In a special case of the theory, we demonstrate how closing the loop for the parameter dynamics using the adjoint of the linearization results in a desirable first-order cancellation of the original system dynamics. Using interval arithmetic in JAX, we demonstrate the efficiency and utility of reachable parametope computation through two numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06955v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Akash Harapanahalli, Samuel Coogan</dc:creator>
    </item>
    <item>
      <title>Adaptive Gradient Descent on Riemannian Manifolds with Nonnegative Curvature</title>
      <link>https://arxiv.org/abs/2504.16724</link>
      <description>arXiv:2504.16724v2 Announce Type: replace 
Abstract: In this paper, we present an adaptive gradient descent method for geodesically convex optimization on a Riemannian manifold with nonnegative sectional curvature. The method automatically adapts to the local geometry of the function and does not use additional expensive computations other than calculation of the derivative of the Riemannian exponential. We prove the convergence of the method under the assumption of geodesic completeness. The performance of the method is illustrated by experiments on the sphere, the manifold of symmetric positive definite matrices equipped with the Bures-Wasserstein metric.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16724v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aban Ansari-\"Onnestam, Yura Malitsky</dc:creator>
    </item>
    <item>
      <title>Nonlinear Derivative-free Constrained Optimization with a Penalty-Interior Point Method and Direct Search</title>
      <link>https://arxiv.org/abs/2504.17682</link>
      <description>arXiv:2504.17682v2 Announce Type: replace 
Abstract: In this work, we propose the joint use of a mixed penalty-interior point method and direct search, for addressing nonlinearly constrained derivative-free optimization problems. A merit function is considered, wherein the set of nonlinear inequality constraints is divided into two groups: one treated with a logarithmic barrier approach, and another, along with the equality constraints, addressed using a penalization term. This strategy, is adapted and incorporated into a direct search method, enabling the effective handling of general nonlinear constraints. Convergence to KKT-stationary points is established under continuous differentiability assumptions, without requiring any kind of convexity. Using CUTEst test problems, numerical experiments demonstrate the robustness, efficiency, and overall effectiveness of the proposed method, when compared with state-of-the-art solvers</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17682v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrea Brilli, Ana L. Cust\'odio, Giampaolo Liuzzi, Everton J. Silva</dc:creator>
    </item>
    <item>
      <title>A dynamic view of some anomalous phenomena in SGD</title>
      <link>https://arxiv.org/abs/2505.01751</link>
      <description>arXiv:2505.01751v3 Announce Type: replace 
Abstract: It has been observed by Belkin et al.\ that over-parametrized neural networks exhibit a `double descent' phenomenon. That is, as the model complexity (as reflected in the number of features) increases, the test error initially decreases, then increases, and then decreases again. A counterpart of this phenomenon in the time domain has been noted in the context of epoch-wise training, viz., the test error decreases with the number of iterates, then increases, then decreases again. Another anomalous phenomenon is that of \textit{grokking} wherein two regimes of descent are interrupted by a third regime wherein the mean loss remains almost constant. This note presents a plausible explanation for these and related phenomena by using the theory of two time scale stochastic approximation, applied to the continuous time limit of the gradient dynamics. This gives a novel perspective for an already well studied theme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01751v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vivek Shripad Borkar</dc:creator>
    </item>
    <item>
      <title>Improving Travel Time Reliability with Variable Speed Limits</title>
      <link>https://arxiv.org/abs/2505.08059</link>
      <description>arXiv:2505.08059v2 Announce Type: replace 
Abstract: This paper analyzes the use of variable speed limits to optimize travel time reliability for commuters. The investigation focuses on a traffic corridor with a bottleneck subject to the capacity drop phenomenon. The optimization criterion is a linear combination of the expected value and standard deviation of average travel time, with traffic flow dynamics following the kinematic wave model (Lighthill, 1955; Richards, 1956). We develop two complementary models to optimally set variable speed limits: In the first model, daily peak traffic demand is conceptualized as a stochastic variable, and the resulting model is solved through a three-stage optimization algorithm. The second model is based on deterministic demand, instead modeling bottleneck capacity as a stochastic process using a stochastic differential equation (SDE). The practical applicability of both approaches is demonstrated through numerical examples with empirically calibrated data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.08059v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Hammerl, Ravi Seshadri, Thomas Kj{\ae}r Rasmussen, Otto Anker Nielsen</dc:creator>
    </item>
    <item>
      <title>cuPDLPx: A Further Enhanced GPU-Based First-Order Solver for Linear Programming</title>
      <link>https://arxiv.org/abs/2507.14051</link>
      <description>arXiv:2507.14051v3 Announce Type: replace 
Abstract: We introduce cuPDLPx, a further enhanced GPU-based first-order solver for linear programming. Building on the recently developed restarted Halpern PDHG for LP, cuPDLPx incorporates a number of new techniques, including a new restart criterion and a PID-controlled primal weight update. These improvements are carefully tailored for GPU architectures and deliver substantial computational gains. Across benchmark datasets, cuPDLPx achieves 2.5x-5x speedups on MIPLIB LP relaxations and 3x-6.8x on Mittelmann's benchmark set, with particularly strong improvements in high-accuracy and presolve-enabled settings. The solver is publicly available at https://github.com/MIT-Lu-Lab/cuPDLPx.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.14051v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haihao Lu, Zedong Peng, Jinwen Yang</dc:creator>
    </item>
    <item>
      <title>The Implicit Barrier from Utility Maximization: Lightweight Interior-Point Methods for Market Equilibrium</title>
      <link>https://arxiv.org/abs/2508.04822</link>
      <description>arXiv:2508.04822v2 Announce Type: replace 
Abstract: We study the computation of the market equilibrium in Fisher exchange markets with divisible goods and players endowed with heterogeneous utilities. In particular, we consider the decentralized polynomial-time interior-point strategies that update \emph{only} the prices, mirroring the t\^atonnement process. The key ingredient is the \emph{implicit barrier} inherent from utility maximization, which induces unbounded demand when the goods are almost free of charge. Focusing on a ubiquitous class of utilities, we formalize this observation. A companion result suggests that no additional effort is required for computing high-order derivatives; all the necessary information is readily available when collecting the best responses. To tackle the Newton systems in the interior-point methods, we present an explicitly invertible approximation of the Hessian operator with high probability guarantees, and a scaling matrix that minimizes the condition number of the linear system. Building on these tools, we design two inexact lightweight interior-point methods. One such method has $\cO(\log(\tfrac{1}{\epsilon}))$ complexity rate. Under mild conditions, the other method achieves a non-asymptotic superlinear convergence rate. Preliminary experiments are presented to justify the capability of the proposed methods for large-scale problems. Extensions of our approach are also discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04822v2</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Chuwen Zhang, Chang He, Bo Jiang, Yinyu Ye</dc:creator>
    </item>
    <item>
      <title>Differential Stochastic Variational Inequalities with Parametric Optimization</title>
      <link>https://arxiv.org/abs/2508.15241</link>
      <description>arXiv:2508.15241v2 Announce Type: replace 
Abstract: The differential stochastic variational inequality with parametric convex optimization (DSVI-O) is an ordinary differential equation whose right-hand side involves a stochastic variational inequality and solutions of several dynamic and random parametric convex optimization problems. We consider that the distribution of the random variable is time-dependent and assume that the involved functions are continuous and the expectation is well-defined. We show that the DSVI-O has a weak solution with integrable and measurable solutions of the parametric optimization problems. Moreover, we propose a discrete scheme of DSVI-O by using a time-stepping approximation and the sample average approximation and prove the convergence of the discrete scheme. We illustrate our theoretical results of DSVI-O with applications in an embodied intelligence system for the elderly health by synthetic health care data generated by Multimodal Large Language Models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.15241v2</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaojun Chen, Jian Guo, Guan Wang</dc:creator>
    </item>
    <item>
      <title>Distributed Combined Space Partitioning and Network Flow Optimization: an Optimal Transport Approach (Extended Version)</title>
      <link>https://arxiv.org/abs/2509.00279</link>
      <description>arXiv:2509.00279v2 Announce Type: replace 
Abstract: This paper studies a combined space partitioning and network flow optimization problem, with applications to large-scale power, transportation, or communication systems. In dense wireless networks, one may want to simultaneously optimize the assignment of many spatially distributed users to base stations and route the resulting communication traffic through the backbone network. We formulate the overall problem by coupling a semi-discrete optimal transport (SDOT) problem, capturing the space partitioning component, with a minimum-cost flow problem on a discrete network. This formulation jointly optimizes the assignment of a continuous demand distribution to certain endpoint network nodes and the routing of flows over the network to serve the demand, under capacity constraints. As for SDOT problems, we show that the formulation of our problem admits a tight relaxation taking the form of an infinite-dimensional linear program, derive a finite-dimensional dual problem, and show that strong duality holds. We leverage these results to design a distributed dual gradient ascent algorithm to solve the problem, where nodes in the graph perform computations based solely on locally available information. Simulation results illustrate the algorithm performance and its applicability to an electric power distribution network reconfiguration problem. This version extends the CDC 2025 conference paper with additional proof sketches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.00279v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Th\'eo Laurentin, Patrick Coirault, Emmanuel Moulay, Antoine Lesage-Landry, Jerome Le Ny</dc:creator>
    </item>
    <item>
      <title>Distance Between Stochastic Linear Systems</title>
      <link>https://arxiv.org/abs/2509.04014</link>
      <description>arXiv:2509.04014v2 Announce Type: replace 
Abstract: While the existing stochastic control theory is well equipped to handle dynamical systems with stochastic uncertainties, a paradigm shift using distance measure based decision making is required for the effective further exploration of the field. As a first step, a distance measure between two stochastic linear time invariant systems is proposed here, extending the existing distance metrics between deterministic linear dynamical systems. In the frequency domain, the proposed distance measure corresponds to the worst-case point-wise in frequency Wasserstein distance between distributions characterising the uncertainties using inverse stereographic projection on the Riemann sphere. For the time domain setting, the proposed distance corresponds to the gap metric induced type-q Wasserstein distance between the distributions characterising the uncertainty of plant models. Apart from providing lower and upper bounds for the proposed distance measures in both frequency and time domain settings, it is proved that the former never exceeds the latter. The proposed distance measures will facilitate the provision of probabilistic guarantees on system robustness and controller performances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.04014v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Venkatraman Renganathan, Sei Zhen Khong</dc:creator>
    </item>
    <item>
      <title>On the convergence rate of the Douglas-Rachford splitting algorithm</title>
      <link>https://arxiv.org/abs/2509.06676</link>
      <description>arXiv:2509.06676v2 Announce Type: replace 
Abstract: This work is concerned with the convergence rate analysis of the Douglas-Rachford splitting (DRS) method for finding a zero of the sum of two maximally monotone operators. We obtain an exact rate of convergence for the DRS algorithm and demonstrate its sharpness in the setting of convex feasibility problems. Furthermore, we investigate the linear convergence of the DRS algorithm, providing both necessary and sufficient conditions that characterize this behavior. We further examine the performance of the DRS method when applied to convex composite optimization problems. The paper concludes with several conjectures on the convergence behavior of the DRS algorithm for this class of problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.06676v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hadi Abbaszadehpeivasti, Moslem Zamani</dc:creator>
    </item>
    <item>
      <title>Data-Induced Interactions of Sparse Sensors Using Statistical Physics</title>
      <link>https://arxiv.org/abs/2307.11838</link>
      <description>arXiv:2307.11838v2 Announce Type: replace-cross 
Abstract: Large-dimensional empirical data in science and engineering frequently have a low-rank structure and can be represented as a combination of just a few eigenmodes. Because of this structure, we can use just a few spatially localized sensor measurements to reconstruct the full state of a complex system. The quality of this reconstruction, especially in the presence of sensor noise, depends significantly on the spatial configuration of the sensors. Multiple algorithms based on gappy interpolation and QR factorization have been proposed to optimize sensor placement. Here, instead of an algorithm that outputs a single "optimal" sensor configuration, we take a statistical mechanics view to compute the full landscape of sensor interactions induced by the training data. The two key advances of this paper are the recasting of the sensor placement landscape in an Ising model form and a regularized reconstruction that significantly decreases reconstruction error for few sensors. In addition, we provide first uncertainty quantification of the sparse sensing reconstruction and open questions about the shape of reconstruction risk curve. Mapping out these data-induced sensor interactions allows combining them with external selection criteria and anticipating sensor replacement impacts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.11838v2</guid>
      <category>cond-mat.stat-mech</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrei A. Klishin, J. Nathan Kutz, Krithika Manohar</dc:creator>
    </item>
    <item>
      <title>Cooperative Nonlinear Guidance Strategies for Guaranteed Pursuit-Evasion</title>
      <link>https://arxiv.org/abs/2402.06176</link>
      <description>arXiv:2402.06176v3 Announce Type: replace-cross 
Abstract: This paper investigates a pursuit-evasion problem involving three agents: a pursuer, an evader, and a defender. Cooperative guidance laws are developed for the evader-defender team that guarantee interception of the pursuer by the defender before it reaches the vicinity of the evader. Unlike heuristic methods, optimal control, differential game formulation, and recently proposed time-constrained guidance techniques, a geometry-based solution is proposed to safeguard the evader from the pursuer's incoming threat. The proposed strategy is computationally efficient and expected to be scalable as the number of agents increases. Another notable feature of the proposed strategy is that the evader-defender team does not require knowledge of the pursuer's strategy, yet the pursuer's interception is guaranteed for arbitrary initial engagement geometries. It is further shown that the relevant error variables for the evader-defender team (or individual) converge to zero at a prespecified finite time that can be exactly prescribed prior to the three-body engagement. Finally, the effectiveness of the proposed cooperative pursuit-evasion strategy is demonstrated through simulations across diverse engagement scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.06176v3</guid>
      <category>eess.SY</category>
      <category>cs.MA</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Saurabh Kumar, Shashi Ranjan Kumar, Abhinav Sinha</dc:creator>
    </item>
    <item>
      <title>Analysis of the SQP Method for Hyperbolic PDE-Constrained Optimization in Acoustic Full Waveform Inversion</title>
      <link>https://arxiv.org/abs/2405.05158</link>
      <description>arXiv:2405.05158v3 Announce Type: replace-cross 
Abstract: In this paper, the SQP method applied to a hyperbolic PDE-constrained optimization problem is considered. The model arises from the acoustic full waveform inversion in the time domain. The analysis is mainly challenging due to the involved hyperbolicity and second-order bilinear structure. This notorious character leads to an undesired effect of loss of regularity in the SQP method, calling for a substantial extension of developed parabolic techniques. We propose and analyze a novel strategy for the well-posedness and convergence analysis based on the use of a smooth-in-time initial condition, a tailored self-mapping operator, and a two-step estimation process along with Stampacchia's method for second-order wave equations. Our final theoretical result is the R-superlinear convergence of the SQP method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.05158v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luis Ammann, Irwin Yousept</dc:creator>
    </item>
    <item>
      <title>Reinforcement Learning for Infinite-Dimensional Systems</title>
      <link>https://arxiv.org/abs/2409.15737</link>
      <description>arXiv:2409.15737v3 Announce Type: replace-cross 
Abstract: Interest in reinforcement learning (RL) for large-scale systems, comprising extensive populations of intelligent agents interacting with heterogeneous environments, has surged significantly across diverse scientific domains in recent years. However, the large-scale nature of these systems often leads to high computational costs or reduced performance for most state-of-the-art RL techniques. To address these challenges, we propose a novel RL architecture and derive effective algorithms to learn optimal policies for arbitrarily large systems of agents. In our formulation, we model such systems as parameterized control systems defined on an infinite-dimensional function space. We then develop a moment kernel transform that maps the parameterized system and the value function into a reproducing kernel Hilbert space. This transformation generates a sequence of finite-dimensional moment representations for the RL problem, organized into a filtrated structure. Leveraging this RL filtration, we develop a hierarchical algorithm for learning optimal policies for the infinite-dimensional parameterized system. To enhance the algorithm's efficiency, we exploit early stopping at each hierarchy, demonstrating the fast convergence property of the algorithm through the construction of a convergent spectral sequence. The performance and efficiency of the proposed algorithm are validated using practical examples in engineering and quantum systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.15737v3</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Wei Zhang, Jr-Shin Li</dc:creator>
    </item>
    <item>
      <title>Control Barrier Functions via Minkowski Operations for Safe Navigation among Polytopic Sets</title>
      <link>https://arxiv.org/abs/2504.00364</link>
      <description>arXiv:2504.00364v3 Announce Type: replace-cross 
Abstract: Safely navigating around obstacles while respecting the dynamics, control, and geometry of the underlying system is a key challenge in robotics. Control Barrier Functions (CBFs) generate safe control policies by considering system dynamics and geometry when calculating safe forward-invariant sets. Existing CBF-based methods often rely on conservative shape approximations, like spheres or ellipsoids, which have explicit and differentiable distance functions. In this paper, we propose an optimization-defined CBF that directly considers the exact Signed Distance Function (SDF) between a polytopic robot and polytopic obstacles. Inspired by the Gilbert-Johnson-Keerthi (GJK) algorithm, we formulate both (i) minimum distance and (ii) penetration depth between polytopic sets as convex optimization problems in the space of Minkowski difference operations (the MD-space). Convenient geometric properties of the MD-space enable the derivatives of implicit SDF between two polytopes to be computed via differentiable optimization. We demonstrate the proposed framework in three scenarios including pure translation, initialization inside an unsafe set, and multi-obstacle avoidance. These three scenarios highlight the generation of a non-conservative maneuver, a recovery after starting in collision, and the consideration of multiple obstacles via pairwise CBF constraint, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.00364v3</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yi-Hsuan Chen, Shuo Liu, Wei Xiao, Calin Belta, Michael Otte</dc:creator>
    </item>
    <item>
      <title>Dion: Distributed Orthonormalized Updates</title>
      <link>https://arxiv.org/abs/2504.05295</link>
      <description>arXiv:2504.05295v3 Announce Type: replace-cross 
Abstract: Orthonormalized updates accelerate training, improve stability, and enable robust hyperparameter transfer, but existing methods like Muon rely on dense matrix operations that clash with sharded weights in large-scale LLM training, causing high compute and communication cost. We introduce Dion (Distributed Orthonormalization), a scalable and efficient update rule that replaces Newton-Schulz iteration with amortized power iteration on a momentum buffer, avoiding full-matrix reconstruction and integrating cleanly with weight sharding. The rank-fraction parameter with error feedback enables low-rank updates that balance quality with significant cost savings. On language models from 160M to 3B parameters, Dion retains the benefits of orthonormalized updates, while markedly reducing wall-clock time at scale, making it a practical optimizer for next-generation foundation models. Code is available at: https://github.com/microsoft/dion/</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05295v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kwangjun Ahn, Byron Xu, Natalie Abreu, Ying Fan, Gagik Magakyan, Pratyusha Sharma, Zheng Zhan, John Langford</dc:creator>
    </item>
    <item>
      <title>Greedy Low-Rank Gradient Compression for Distributed Learning with Convergence Guarantees</title>
      <link>https://arxiv.org/abs/2507.08784</link>
      <description>arXiv:2507.08784v3 Announce Type: replace-cross 
Abstract: Distributed optimization is pivotal for large-scale signal processing and machine learning, yet communication overhead remains a major bottleneck. Low-rank gradient compression, in which the transmitted gradients are approximated by low-rank matrices to reduce communication, offers a promising remedy. Existing methods typically adopt either randomized or greedy compression strategies: randomized approaches project gradients onto randomly chosen subspaces, introducing high variance and degrading empirical performance; greedy methods select the most informative subspaces, achieving strong empirical results but lacking convergence guarantees. To address this gap, we propose GreedyLore--the first Greedy Low-Rank gradient compression algorithm for distributed learning with rigorous convergence guarantees. GreedyLore incorporates error feedback to correct the bias introduced by greedy compression and introduces a semi-lazy subspace update that ensures the compression operator remains contractive throughout all iterations. With these techniques, we prove that GreedyLore achieves a convergence rate of $\mathcal{O}(\sigma/\sqrt{NT} + 1/T)$ under standard optimizers such as MSGD and Adam--marking the first linear speedup convergence rate for low-rank gradient compression. Extensive experiments are conducted to validate our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.08784v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chuyan Chen, Yutong He, Pengrui Li, Weichen Jia, Kun Yuan</dc:creator>
    </item>
    <item>
      <title>Efficient Defection: Overage-Proportional Rationing Attains the Cooperative Frontier</title>
      <link>https://arxiv.org/abs/2509.07145</link>
      <description>arXiv:2509.07145v3 Announce Type: replace-cross 
Abstract: We study a noncooperative $n$-player game of slack allocation in which each player $j$ has entitlement $L_j&gt;0$ and chooses a claim $C_j\ge0$. Let $v_j=(C_j-L_j)_+$ (overage) and $s_j=(L_j-C_j)_+$ (slack); set $X=\sum_j v_j$ and $I=\sum_j s_j$. At the end of the period an overage-proportional clearing rule allocates cooperative surplus $I$ to defectors in proportion to $v_j$; cooperators receive $C_j$. We show: (i) the selfish outcome reproduces the cooperative payoff vector $(L_1,\dots,L_n)$; (ii) with bounded actions, defection is a weakly dominant strategy; (iii) within the $\alpha$-power family, the linear rule ($\alpha=1$) is the unique boundary-continuous member; and (iv) the dominant-strategy outcome is Strong Nash under transferable utility and hence coalition-proof (Bernheim et al., 1987). We give a policy interpretation for carbon rationing with a penalty collar.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.07145v3</guid>
      <category>econ.TH</category>
      <category>math.OC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Florian Lengyel</dc:creator>
    </item>
  </channel>
</rss>
