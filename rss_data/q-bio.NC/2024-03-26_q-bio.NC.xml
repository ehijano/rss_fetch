<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 27 Mar 2024 04:00:20 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 27 Mar 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Assessing the similarity of real matrices with arbitrary shape</title>
      <link>https://arxiv.org/abs/2403.17687</link>
      <description>arXiv:2403.17687v1 Announce Type: new 
Abstract: Assessing the similarity of matrices is valuable for analyzing the extent to which data sets exhibit common features in tasks such as data clustering, dimensionality reduction, pattern recognition, group comparison, and graph analysis. Methods proposed for comparing vectors, such as cosine similarity, can be readily generalized to matrices. However, this approach usually neglects the inherent two-dimensional structure of matrices. Here, we propose singular angle similarity (SAS), a measure for evaluating the structural similarity between two arbitrary, real matrices of the same shape based on singular value decomposition. After introducing the measure, we compare SAS with standard measures for matrix comparison and show that only SAS captures the two-dimensional structure of matrices. Further, we characterize the behavior of SAS in the presence of noise and as a function of matrix dimensionality. Finally, we apply SAS to two use cases: square non-symmetric matrices of probabilistic network connectivity, and non-square matrices representing neural brain activity. For synthetic data of network connectivity, SAS matches intuitive expectations and allows for a robust assessment of similarities and differences. For experimental data of brain activity, SAS captures differences in the structure of high-dimensional responses to different stimuli. We conclude that SAS is a suitable measure for quantifying the shared structure of matrices with arbitrary shape.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17687v1</guid>
      <category>q-bio.NC</category>
      <category>physics.data-an</category>
      <category>q-bio.QM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jasper Albers, Anno C. Kurth, Robin Gutzen, Aitor Morales-Gregorio, Michael Denker, Sonja Gr\"un, Sacha J. van Albada, Markus Diesmann</dc:creator>
    </item>
    <item>
      <title>Decoding Probing: Revealing Internal Linguistic Structures in Neural Language Models using Minimal Pairs</title>
      <link>https://arxiv.org/abs/2403.17299</link>
      <description>arXiv:2403.17299v1 Announce Type: cross 
Abstract: Inspired by cognitive neuroscience studies, we introduce a novel `decoding probing' method that uses minimal pairs benchmark (BLiMP) to probe internal linguistic characteristics in neural language models layer by layer. By treating the language model as the `brain' and its representations as `neural activations', we decode grammaticality labels of minimal pairs from the intermediate layers' representations. This approach reveals: 1) Self-supervised language models capture abstract linguistic structures in intermediate layers that GloVe and RNN language models cannot learn. 2) Information about syntactic grammaticality is robustly captured through the first third layers of GPT-2 and also distributed in later layers. As sentence complexity increases, more layers are required for learning grammatical capabilities. 3) Morphological and semantics/syntax interface-related features are harder to capture than syntax. 4) For Transformer-based models, both embeddings and attentions capture grammatical features but show distinct patterns. Different attention heads exhibit similar tendencies toward various linguistic phenomena, but with varied contributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17299v1</guid>
      <category>cs.CL</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Linyang He, Peili Chen, Ercong Nie, Yuanning Li, Jonathan R. Brennan</dc:creator>
    </item>
    <item>
      <title>Labeling subtypes in a Parkinson's Cohort using Multifeatures in MRI - Integrating Grey and White Matter Information</title>
      <link>https://arxiv.org/abs/2403.17332</link>
      <description>arXiv:2403.17332v1 Announce Type: cross 
Abstract: Thresholding of networks has long posed a challenge in brain connectivity analysis. Weighted networks are typically binarized using threshold measures to facilitate network analysis. Previous studies on MRI-based brain networks have predominantly utilized density or sparsity-based thresholding techniques, optimized within specific ranges derived from network metrics such as path length, clustering coefficient, and small-world index. Thus, determination of a single threshold value for facilitating comparative analysis of networks remains elusive. To address this, our study introduces Mutual K-Nearest Neighbor (MKNN)-based thresholding for brain network analysis. Here, nearest neighbor selection is based on the highest correlation between features of brain regions. Construction of brain networks was accomplished by computing Pearson correlations between grey matter volume and white matter volume for each pair of brain regions. Structural MRI data from 180 Parkinsons patients and 70 controls from the NIMHANS, India were analyzed. Subtypes within Parkinsons disease were identified based on grey and white matter volume atrophy using source-based morphometric decomposition. The loading coefficients were correlated with clinical features to discern clinical relationship with the deciphered subtypes. Our data-mining approach revealed: Subtype A (N = 51, intermediate type), Subtype B (N = 57, mild-severe type with mild motor symptoms), and Subtype AB (N = 36, most-severe type with predominance in motor impairment). Subtype-specific weighted matrices were binarized using MKNN-based thresholding for brain network analysis. Permutation tests on network metrics of resulting bipartite graphs demonstrated significant group differences in betweenness centrality and participation coefficient. The identified hubs were specific to each subtype, with some hubs conserved across different subtypes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17332v1</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tanmayee Samantaray, Jitender Saini, Pramod Kumar Pal, Bithiah Grace Jaganathan, Vijaya V Saradhi, Gupta CN</dc:creator>
    </item>
    <item>
      <title>Gray matter volume correlates of Comorbid Depression in Autism Spectrum Disorder</title>
      <link>https://arxiv.org/abs/2311.00997</link>
      <description>arXiv:2311.00997v2 Announce Type: replace 
Abstract: Autism Spectrum Disorder (ASD) involves diverse neurodevelopmental syndromes with significant deficits in communication, motor behaviours, emotional and social comprehension. Often, individuals with ASD exhibit comorbid conditions, one of the most prevalent being depression characterized by a persistent change in mood and diminished interest in previously enjoyable activities. Due to communicative challenges and lack of appropriate assessments in individuals with ASD, comorbid depression can often go undiagnosed during routine clinical examinations, which may aggravate their problems. The current literature on comorbid depression in adults with ASD is limited. Therefore, understanding the neural basis of the comorbid psychopathology of depression in ASD is crucial for identifying objective brain-based markers for its timely and effective management. Towards this end, using structural MRI and phenotypic data from the Autism Brain Imaging Data Exchange II (ABIDE II) repository, we specifically examined the pattern of relationship regional grey matter volume (rGMV) has with comorbid depression and autism severity within regions of a priori interest in adults with ASD (n = 44). The severity of comorbid depression correlated negatively with the rGMV of the right thalamus. Additionally, a significant interaction was evident between the severity of comorbid depression and core ASD symptoms towards explaining the rGMV in the left cerebellum crus II. The whole-brain regional rGMV differences between ASD and typically developed (TD, n = 39) adults remained inconclusive. The results further the understanding of the neurobiological underpinnings of comorbid depression in adults with ASD and are relevant in exploring structural neuroimaging-based biomarkers in the same cohort.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.00997v2</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dolcy Dhar, Manasi Chaturvedi, Saanvi Sehwag, Chehak Malhotra,  Udit, Chetan Saraf, Mrinmoy Chakrabarty</dc:creator>
    </item>
    <item>
      <title>Two-compartment neuronal spiking model expressing brain-state specific apical-amplification, -isolation and -drive regimes</title>
      <link>https://arxiv.org/abs/2311.06074</link>
      <description>arXiv:2311.06074v2 Announce Type: replace 
Abstract: Mounting experimental evidence suggests that brain-state-specific neural mechanisms, supported by connectomic architectures, play a crucial role in integrating past and contextual knowledge with the current, incoming flow of evidence (e.g., from sensory systems). These mechanisms operate across multiple spatial and temporal scales, necessitating dedicated support at the levels of individual neurons and synapses. A notable feature within the neocortex is the structure of large, deep pyramidal neurons, which exhibit a distinctive separation between an apical dendritic compartment and a basal dendritic/perisomatic compartment. This separation is characterized by distinct patterns of incoming connections and brain-state-specific activation mechanisms, namely, apical amplification, isolation, and drive, which are associated with wakefulness, deeper NREM sleep stages, and REM sleep, respectively. The cognitive roles of apical mechanisms have been demonstrated in behaving animals. In contrast, classical models of learning in spiking networks are based on single-compartment neurons, lacking the ability to describe the integration of apical and basal/somatic information. This work aims to provide the computational community with a two-compartment spiking neuron model that incorporates features essential for supporting brain-state-specific learning. This model includes a piece-wise linear transfer function (ThetaPlanes) at the highest abstraction level, making it suitable for use in large-scale bio-inspired artificial intelligence systems. A machine learning evolutionary algorithm, guided by a set of fitness functions, selected the parameters that define neurons expressing the desired apical mechanisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.06074v2</guid>
      <category>q-bio.NC</category>
      <category>cs.NE</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Elena Pastorelli, Alper Yegenoglu, Nicole Kolodziej, Willem Wybo, Francesco Simula, Sandra Diaz, Johan Frederik Storm, Pier Stanislao Paolucci</dc:creator>
    </item>
    <item>
      <title>Joint Learning Neuronal Skeleton and Brain Circuit Topology with Permutation Invariant Encoders for Neuron Classification</title>
      <link>https://arxiv.org/abs/2312.14518</link>
      <description>arXiv:2312.14518v2 Announce Type: replace 
Abstract: Determining the types of neurons within a nervous system plays a significant role in the analysis of brain connectomics and the investigation of neurological diseases. However, the efficiency of utilizing anatomical, physiological, or molecular characteristics of neurons is relatively low and costly. With the advancements in electron microscopy imaging and analysis techniques for brain tissue, we are able to obtain whole-brain connectome consisting neuronal high-resolution morphology and connectivity information. However, few models are built based on such data for automated neuron classification. In this paper, we propose NeuNet, a framework that combines morphological information of neurons obtained from skeleton and topological information between neurons obtained from neural circuit. Specifically, NeuNet consists of three components, namely Skeleton Encoder, Connectome Encoder, and Readout Layer. Skeleton Encoder integrates the local information of neurons in a bottom-up manner, with a one-dimensional convolution in neural skeleton's point data; Connectome Encoder uses a graph neural network to capture the topological information of neural circuit; finally, Readout Layer fuses the above two information and outputs classification results. We reprocess and release two new datasets for neuron classification task from volume electron microscopy(VEM) images of human brain cortex and Drosophila brain. Experiments on these two datasets demonstrated the effectiveness of our model with accuracy of 0.9169 and 0.9363, respectively. Code and data are available at: https://github.com/WHUminghui/NeuNet.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.14518v2</guid>
      <category>q-bio.NC</category>
      <category>cs.CV</category>
      <category>eess.IV</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Minghui Liao, Guojia Wan, Bo Du</dc:creator>
    </item>
    <item>
      <title>Identification of Craving Maps among Marijuana Users via the Analysis of Functional Brain Networks with High-Order Attention Graph Neural Networks</title>
      <link>https://arxiv.org/abs/2403.00033</link>
      <description>arXiv:2403.00033v4 Announce Type: replace 
Abstract: The excessive consumption of marijuana can induce substantial psychological and social consequences. In this investigation, we propose an elucidative framework termed high-order graph attention neural networks (HOGANN) for the classification of Marijuana addiction, coupled with an analysis of localized brain network communities exhibiting abnormal activities among chronic marijuana users. HOGANN integrates dynamic intrinsic functional brain networks, estimated from resting-state functional magnetic resonance imaging (rs-fMRI), using long short-term memory (LSTM) to capture temporal network dynamics. We employ a high-order attention module for information fusion and message passing among neighboring nodes, enhancing the network community analysis. Our model is validated across two distinct data cohorts, yielding substantially higher classification accuracy than benchmark algorithms. Furthermore, we discern the most pertinent subnetworks and cognitive regions affected by persistent marijuana consumption, indicating adverse effects on functional brain networks, particularly within the dorsal attention and frontoparietal networks. Intriguingly, our model demonstrates superior performance in cohorts exhibiting prolonged dependence, implying that prolonged marijuana usage induces more pronounced alterations in brain networks. The model proficiently identifies craving brain maps, thereby delineating critical brain regions for analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.00033v4</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jun-En Ding, Shihao Yang, Anna Zilverstand, Feng Liu</dc:creator>
    </item>
    <item>
      <title>Brain Networks and Intelligence: A Graph Neural Network Based Approach to Resting State fMRI Data</title>
      <link>https://arxiv.org/abs/2311.03520</link>
      <description>arXiv:2311.03520v2 Announce Type: replace-cross 
Abstract: Resting-state functional magnetic resonance imaging (rsfMRI) is a powerful tool for investigating the relationship between brain function and cognitive processes as it allows for the functional organization of the brain to be captured without relying on a specific task or stimuli. In this paper, we present a novel modeling architecture called BrainRGIN for predicting intelligence (fluid, crystallized, and total intelligence) using graph neural networks on rsfMRI derived static functional network connectivity matrices. Extending from the existing graph convolution networks, our approach incorporates a clustering-based embedding and graph isomorphism network in the graph convolutional layer to reflect the nature of the brain sub-network organization and efficient network expression, in combination with TopK pooling and attention-based readout functions. We evaluated our proposed architecture on a large dataset, specifically the Adolescent Brain Cognitive Development Dataset, and demonstrated its effectiveness in predicting individual differences in intelligence. Our model achieved lower mean squared errors and higher correlation scores than existing relevant graph architectures and other traditional machine learning models for all of the intelligence prediction tasks. The middle frontal gyrus exhibited a significant contribution to both fluid and crystallized intelligence, suggesting their pivotal role in these cognitive processes. Total composite scores identified a diverse set of brain regions to be relevant which underscores the complex nature of total intelligence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.03520v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bishal Thapaliya, Esra Akbas, Jiayu Chen, Raam Sapkota, Bhaskar Ray, Pranav Suresh, Vince Calhoun, Jingyu Liu</dc:creator>
    </item>
    <item>
      <title>The Nature of the Action Potential</title>
      <link>https://arxiv.org/abs/2401.18051</link>
      <description>arXiv:2401.18051v3 Announce Type: replace-cross 
Abstract: We demonstrate that our recently developed theory of electric field wave propagation in anisotropic and inhomogeneous brain tissues, which has been shown to explain a broad range of observed coherent synchronous brain electrical processes, also explains the spiking behavior of single neurons, thus bridging the gap between the fundamental element of brain electrical activity (the neuron) and large-scale coherent synchronous electrical activity.
  Our analysis indicates that the membrane interface of the axonal cellular system can be mathematically described by a nonlinear system with several small parameters. This allows for the rigorous derivation of an accurate yet simpler nonlinear model following the formal small parameter expansion. The resulting action potential model exhibits a smooth, continuous transition from the linear wave oscillatory regime to the nonlinear spiking regime, as well as a critical transition to a non-oscillatory regime. These transitions occur with changes in the criticality parameter and include several different bifurcation types, representative of the various experimentally detected neuron types.
  This new theory overcomes the limitations of the Hodgkin-Huxley model, such as the inability to explain extracellular spiking, efficient brain synchronization, saltatory conduction along myelinated axons, and a variety of other observed coherent macroscopic brain electrical phenomena. We also show that the standard cable axon theory can be recovered by our approach, using the very crude assumptions of piece-wise homogeneity and isotropy. However, the diffusion process described by the cable equation is not capable of supporting action potential propagation across a wide range of experimentally reported axon parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.18051v3</guid>
      <category>physics.bio-ph</category>
      <category>nlin.AO</category>
      <category>physics.class-ph</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vitaly L. Galinsky, Lawrence R. Frank</dc:creator>
    </item>
  </channel>
</rss>
