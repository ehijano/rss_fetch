<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 09 May 2025 04:00:12 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 09 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Network Digital Twin for Route Optimization in 5G/B5G Transport Slicing with What-If Analysis</title>
      <link>https://arxiv.org/abs/2505.04879</link>
      <description>arXiv:2505.04879v1 Announce Type: new 
Abstract: The advent of fifth-generation (5G) and Beyond 5G (B5G) networks introduces diverse service requirements, from ultra-low latency to high bandwidth, demanding dynamic monitoring and advanced solutions to ensure Quality of Service (QoS). The transport network - responsible for interconnecting the radio access network and core networks - will increasingly face challenges in efficiently managing complex traffic patterns. The Network Digital Twin (NDT) concept emerges as a promising solution for testing configurations and algorithms in a virtual network before real-world deployment. In this context, this work designs an experimental platform with NDT in a transport network domain, synchronizing with the virtual counterpart and a recommendation system for what-if analysis, enabling intelligent decision-making for dynamic route optimization problems in 5G/B5G scenarios. Our NDT, composed of a Graph Neural Network (GNN), was evaluated across three different network topologies consisting of 8, 16, and 30 nodes. It achieved lower MAPE values for URLLC and eMBB slices, comparing latency predictions with actual latency after the solution implementation. These values indicate high accuracy, demonstrating the solution's effectiveness in generating precise insights into network performance if a particular solution were implemented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.04879v1</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 09 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rebecca Aben-Athar, Heitor Anglada, Lucas Costa, Jo\~ao Albuquerque, Abrah\~ao Ferreira, Cristiano Bonato Both, Kleber Cardoso, Silvia Lins, Andrey Silva, Glauco Gon\c{c}alves, Ilan Correa, Aldebaro Klautau</dc:creator>
    </item>
    <item>
      <title>Cross-Problem Solving for Network Optimization: Is Problem-Aware Learning the Key?</title>
      <link>https://arxiv.org/abs/2505.05067</link>
      <description>arXiv:2505.05067v1 Announce Type: new 
Abstract: As intelligent network services continue to diversify, ensuring efficient and adaptive resource allocation in edge networks has become increasingly critical. Yet the wide functional variations across services often give rise to new and unforeseen optimization problems, rendering traditional manual modeling and solver design both time-consuming and inflexible. This limitation reveals a key gap between current methods and human solving - the inability to recognize and understand problem characteristics. It raises the question of whether problem-aware learning can bridge this gap and support effective cross-problem generalization. To answer this question, we propose a problem-aware diffusion (PAD) model, which leverages a problem-aware learning framework to enable cross-problem generalization. By explicitly encoding the mathematical formulations of optimization problems into token-level embeddings, PAD empowers the model to understand and adapt to problem structures. Extensive experiments across six diverse network optimization problems show that PAD generalizes well to unseen problems while significantly improving solution quality and feasibility. Meanwhile, an auxiliary constraint-aware module is designed to enforce solution validity further. The experiments reveal that problem-aware learning is promising for building general-purpose solvers for intelligent network operation and resource management. Our code is open source at https://github.com/qiyu3816/PAD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.05067v1</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 09 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruihuai Liang, Bo Yang, Pengyu Chen, Xuelin Cao, Zhiwen Yu, H. Vincent Poor, Chau Yuen</dc:creator>
    </item>
    <item>
      <title>Temporal Spectrum Analysis for Multi-Constellation Space Domain Awareness</title>
      <link>https://arxiv.org/abs/2505.05149</link>
      <description>arXiv:2505.05149v1 Announce Type: new 
Abstract: Space Domain Awareness (SDA) system has different major aspects including continues and robust awareness from the network that is crucial for an efficient control over all actors in space. The observability of the space assets on the other hand requires efficient analysis on when and how observed space objects can be controlled. This becomes crucial when real-world spatial dynamics are taken into account as it introduces complexities into the system. The real-world dynamics can reveal the structure of the network including isolated and dominant stations. We propose a Temporal Spectrum Analysis (TSA) scheme that takes into account a set of real-world parameters including actual dynamics of the objects in space to analyze the structure of a ground-space network that inherits temporal spectrum as the key element of design. We study the potential interactions between multiple constellations using TSA and conduct a comprehensive real-world simulations to quantify the structure of the network. Numerical results show how the temporal spectrum of each satellite affects the intra- and inter-constellation network structure including interactions between ground stations and constellations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.05149v1</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 09 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mansour Naslcheraghi, Gunes Karabulut-Kurt</dc:creator>
    </item>
    <item>
      <title>In-Situ Model Validation for Continuous Processes Using In-Network Computing</title>
      <link>https://arxiv.org/abs/2505.05184</link>
      <description>arXiv:2505.05184v1 Announce Type: new 
Abstract: The advancing industrial digitalization enables evolved process control schemes that rely on accurate models learned through data-driven approaches. While they provide high control performance and are robust to smaller deviations, a larger change in process behavior can pose significant challenges, in the worst case even leading to a damaged process plant. Hence, it is important to frequently assess the fit between the model and the actual process behavior. As the number of controlled processes and associated data volumes increase, the need for lightweight and fast reacting assessment solutions also increases. In this paper, we propose CIVIC, an in-network computing-based solution for Continuous In-situ Validation of Industrial Control models. In short, CIVIC monitors relevant process variables and detects different process states through comparison with a priori knowledge about the desired process behavior. This detection can then be leveraged to, e.g., shut down the process or trigger a reconfiguration. We prototype CIVIC on an Intel Tofino-based switch and apply it to a lab-scale water treatment plant. Our results show that we can achieve a high detection accuracy, proving that such monitoring systems are feasible and sensible.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.05184v1</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 09 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/ICPS59941.2024.10639999</arxiv:DOI>
      <dc:creator>Ike Kunze, Dominik Scheurenberg, Liam Tirpitz, Sandra Geisler, Klaus Wehrle</dc:creator>
    </item>
    <item>
      <title>SDR-RDMA: Software-Defined Reliability Architecture for Planetary Scale RDMA Communication</title>
      <link>https://arxiv.org/abs/2505.05366</link>
      <description>arXiv:2505.05366v1 Announce Type: new 
Abstract: RDMA is vital for efficient distributed training across datacenters, but millisecond-scale latencies complicate the design of its reliability layer. We show that depending on long-haul link characteristics, such as drop rate, distance and bandwidth, the widely used Selective Repeat algorithm can be inefficient, warranting alternatives like Erasure Coding. To enable such alternatives on existing hardware, we propose SDR-RDMA, a software-defined reliability stack for RDMA. Its core is a lightweight SDR SDK that extends standard point-to-point RDMA semantics -- fundamental to AI networking stacks -- with a receive buffer bitmap. SDR bitmap enables partial message completion to let applications implement custom reliability schemes tailored to specific deployments, while preserving zero-copy RDMA benefits. By offloading the SDR backend to NVIDIA's Data Path Accelerator (DPA), we achieve line-rate performance, enabling efficient inter-datacenter communication and advancing reliability innovation for intra-datacenter training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.05366v1</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 09 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mikhail Khalilov, Siyuan Shen, Marcin Chrapek, Tiancheng Chen, Kenji Nakano, Peter-Jan Gootzen, Salvatore Di Girolamo, Rami Nudelman, Gil Bloch, Sreevatsa Anantharamu, Mahmoud Elhaddad, Jithin Jose, Abdul Kabbani, Scott Moe, Konstantin Taranov, Zhuolong Yu, Jie Zhang, Nicola Mazzoletti, Torsten Hoefler</dc:creator>
    </item>
    <item>
      <title>Impact of Weather on Satellite Communication: Evaluating Starlink Resilience</title>
      <link>https://arxiv.org/abs/2505.04772</link>
      <description>arXiv:2505.04772v1 Announce Type: cross 
Abstract: Satellite communications have emerged as one of the most feasible solutions to provide global wireless coverage and connect the unconnected. Starlink dominates the market with over 7,000 operational satellites in low Earth orbit (LEO) and offers global high-speed and low-latency Internet service for stationary and mobile use cases, including in-motion connectivity for vehicles, vessels, and aircraft. Starlink terminals are designed to handle extreme weather conditions. Starlink recommends a flat high performance (FHP) terminal for users living in areas with extreme weather conditions. The earlier studies evaluated Starlink's FHP throughput for stationary and in-motion users without providing a detailed analysis of how weather affects its performance. There remains a need to investigate the impact of weather on FHP's throughput. In this paper, we address this shortcoming by analyzing the impact of weather on Starlink's performance in Oulu, Finland, a city located in Northern Europe near the Arctic Circle. Our measurements reveal that rain degrades median uplink and downlink throughput by 52.27% and 37.84%, respectively. On the contrary, there was no noticeable impact on the round-trip time. Additionally, we also examine the impact of cloud cover on the Starlink throughput. The linear regression analysis reveals the negative relationship between throughput and cloud cover. The cloud cover of up to 12.5% has around 20% greater throughput than the cloud cover of 87.5%</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.04772v1</guid>
      <category>cs.ET</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Fri, 09 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Muhammad Asad Ullah, Antti Heikkinen, Mikko Uitto, Antti Anttonen, Konstantin Mikhaylov</dc:creator>
    </item>
    <item>
      <title>AI and Vision based Autonomous Navigation of Nano-Drones in Partially-Known Environments</title>
      <link>https://arxiv.org/abs/2505.04972</link>
      <description>arXiv:2505.04972v1 Announce Type: cross 
Abstract: The miniaturisation of sensors and processors, the advancements in connected edge intelligence, and the exponential interest in Artificial Intelligence are boosting the affirmation of autonomous nano-size drones in the Internet of Robotic Things ecosystem. However, achieving safe autonomous navigation and high-level tasks such as exploration and surveillance with these tiny platforms is extremely challenging due to their limited resources. This work focuses on enabling the safe and autonomous flight of a pocket-size, 30-gram platform called Crazyflie 2.1 in a partially known environment. We propose a novel AI-aided, vision-based reactive planning method for obstacle avoidance under the ambit of Integrated Sensing, Computing and Communication paradigm. We deal with the constraints of the nano-drone by splitting the navigation task into two parts: a deep learning-based object detector runs on the edge (external hardware) while the planning algorithm is executed onboard. The results show the ability to command the drone at $\sim8$ frames-per-second and a model performance reaching a COCO mean-average-precision of $60.8$. Field experiments demonstrate the feasibility of the solution with the drone flying at a top speed of $1$ m/s while steering away from an obstacle placed in an unknown position and reaching the target destination. The outcome highlights the compatibility of the communication delay and the model performance with the requirements of the real-time navigation task. We provide a feasible alternative to a fully onboard implementation that can be extended to autonomous exploration with nano-drones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.04972v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Fri, 09 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mattia Sartori, Chetna Singhal, Neelabhro Roy, Davide Brunelli, James Gross</dc:creator>
    </item>
    <item>
      <title>A Weighted Byzantine Fault Tolerance Consensus Driven Trusted Multiple Large Language Models Network</title>
      <link>https://arxiv.org/abs/2505.05103</link>
      <description>arXiv:2505.05103v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) have achieved remarkable success across a wide range of applications. However, individual LLMs often produce inconsistent, biased, or hallucinated outputs due to limitations in their training corpora and model architectures. Recently, collaborative frameworks such as the Multi-LLM Network (MultiLLMN) have been introduced, enabling multiple LLMs to interact and jointly respond to user queries. Nevertheless, MultiLLMN architectures raise critical concerns regarding the reliability and security of the generated content, particularly in open environments where malicious or compromised LLMs may be present. Moreover, reliance on centralized coordination undermines system efficiency and introduces single points of failure. In this paper, we propose a novel Trusted MultiLLMN framework, driven by a Weighted Byzantine Fault Tolerance (WBFT) blockchain consensus mechanism, to ensure the reliability, security, and efficiency of multi-LLM collaboration. In WBFT, voting weights are adaptively assigned to each LLM based on its response quality and trustworthiness, incentivizing reliable behavior, and reducing the impact of malicious nodes. Extensive simulations demonstrate that WBFT significantly improves both consensus security and efficiency compared to classical and modern consensus mechanisms, particularly under wireless network conditions. Furthermore, our evaluations reveal that Trusted MultiLLMN supported by WBFT can deliver higher-quality and more credible responses than both single LLMs and conventional MultiLLMNs, thereby providing a promising path toward building robust, decentralized AI collaboration networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.05103v1</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Fri, 09 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Haoxiang Luo, Gang Sun, Yinqiu Liu, Dongcheng Zhao, Dusit Niyato, Hongfang Yu, Schahram Dustdar</dc:creator>
    </item>
    <item>
      <title>Lazy Eye Inspection: Capturing the State of Happy Eyeballs Implementations</title>
      <link>https://arxiv.org/abs/2412.00263</link>
      <description>arXiv:2412.00263v3 Announce Type: replace 
Abstract: Happy Eyeballs (HE) started out by describing a mechanism that prefers IPv6 connections while ensuring a fast fallback to IPv4 when IPv6 fails. The IETF is currently working on the third version of HE. While the standards include recommendations for HE parameters choices, it is up to the client and OS to implement HE. In this paper we investigate the state of HE in various clients, particularly web browsers and recursive resolvers. We introduce a framework to analyze and measure client's HE implementations and parameter choices. According to our evaluation, only Safari supports all HE features. Safari is also the only client implementation in our study that uses a dynamic IPv4 connection attempt delay, a resolution delay, and interlaces addresses. We further show that problems with the DNS A record lookup can even delay and interrupt the network connectivity despite a fully functional IPv6 setup with Chrome and Firefox. We publish our testbed measurement framework and a web-based tool to test HE properties on arbitrary browsers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00263v3</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 09 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3730567.3732925</arxiv:DOI>
      <dc:creator>Patrick Sattler, Matthias Kirstein, Lars W\"ustrich, Johannes Zirngibl, Georg Carle</dc:creator>
    </item>
    <item>
      <title>ECSeptional DNS Data: Evaluating Nameserver ECS Deployments with Response-Aware Scanning</title>
      <link>https://arxiv.org/abs/2412.08478</link>
      <description>arXiv:2412.08478v2 Announce Type: replace 
Abstract: DNS is one of the cornerstones of the Internet. Nowadays, a substantial fraction of DNS queries are handled by public resolvers (e.g., Google Public DNS and Cisco's OpenDNS) rather than ISP nameservers. This behavior makes it difficult for authoritative nameservers to provide answers based on the requesting resolver. The impact is especially important for entities that make client origin inferences to perform DNS-based load balancing (e.g., CDNS). The EDNS0 Client Subnet (ECS) option adds the client's IP prefix to DNS queries, which allows authoritative nameservers to provide prefix-based responses. In this study, we introduce a new method for conducting ECS scans, which provides insights into ECS behavior and significantly reduces the required number of queries by up to 97% compared to state-of-the-art techniques. Our approach is also the first to facilitate ECS scans for IPv6. We conduct a comprehensive evaluation of the ECS landscape, examining the usage and implementation of ECS across various services. Overall, 53% of all nameservers support prefix-based responses. Furthermore, we find that Google nameservers do not comply with the Google Public DNS guidelines. Lastly, we plan to make our tool, and data publicly available to foster further research in the area.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.08478v2</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 09 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3730977</arxiv:DOI>
      <dc:creator>Patrick Sattler, Johannes Zirngibl, Fahad Hilal, Oliver Gasser, Kevin Vermeulen, Georg Carle, Mattijs Jonker</dc:creator>
    </item>
    <item>
      <title>Vision Transformers for Efficient Indoor Pathloss Radio Map Prediction</title>
      <link>https://arxiv.org/abs/2412.09507</link>
      <description>arXiv:2412.09507v2 Announce Type: replace-cross 
Abstract: Indoor pathloss prediction is a fundamental task in wireless network planning, yet it remains challenging due to environmental complexity and data scarcity. In this work, we propose a deep learning-based approach utilizing a vision transformer (ViT) architecture with DINO-v2 pretrained weights to model indoor radio propagation. Our method processes a floor map with additional features of the walls to generate indoor pathloss maps. We systematically evaluate the effects of architectural choices, data augmentation strategies, and feature engineering techniques. Our findings indicate that extensive augmentation significantly improves generalization, while feature engineering is crucial in low-data regimes. Through comprehensive experiments, we demonstrate the robustness of our model across different generalization scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09507v2</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <pubDate>Fri, 09 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.3390/electronics14101905</arxiv:DOI>
      <arxiv:journal_reference>Published in Electronics 2025, 14(10), 1905</arxiv:journal_reference>
      <dc:creator>Rafayel Mkrtchyan, Edvard Ghukasyan, Khoren Petrosyan, Hrant Khachatrian, Theofanis P. Raptis</dc:creator>
    </item>
  </channel>
</rss>
