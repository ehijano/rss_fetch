<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 20 Feb 2025 05:00:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Detectability, Riccati Equations, and the Game-Based Control of Discrete-Time MJLSs with the Markov Chain on a Borel Space</title>
      <link>https://arxiv.org/abs/2502.13404</link>
      <description>arXiv:2502.13404v1 Announce Type: new 
Abstract: In this paper, detectability is first put forward for discrete-time Markov jump linear systems with the Markov chain on a Borel space ($\Theta$, $\mathcal{B}(\Theta)$). Under the assumption that the unforced system is detectable, a stability criterion is established relying on the existence of the positive semi-definite solution to the generalized Lyapunov equation. It plays a key role in seeking the conditions that guarantee the existence and uniqueness of the maximal solution and the stabilizing solution for a class of general coupled algebraic Riccati equations (coupled-AREs). Then the nonzero-sum game-based control problem is tackled, and Nash equilibrium strategies are achieved by solving four integral coupled-AREs. As an application of the Nash game approach, the infinite horizon mixed $H_{2}/H_{\infty}$ control problem is studied, along with its solvability conditions. These works unify and generalize those set up in the case where the state space of the Markov chain is restricted to a finite or countably infinite set. Finally, some examples are included to validate the developed results, involving a practical example of the solar thermal receiver.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13404v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chunjie Xiao, Ting Hou, Weihai Zhang, Feiqi Deng</dc:creator>
    </item>
    <item>
      <title>Integrating Sequential Hypothesis Testing into Adversarial Games: A Sun Zi-Inspired Framework</title>
      <link>https://arxiv.org/abs/2502.13462</link>
      <description>arXiv:2502.13462v1 Announce Type: new 
Abstract: This paper investigates the interplay between sequential hypothesis testing (SHT) and adversarial decision-making in partially observable games, focusing on the deceptive strategies of red and blue teams. Inspired by Sun Zi's The Art of War and its emphasis on deception, we develop a novel framework to both deceive adversaries and counter their deceptive tactics. We model this interaction as a Stackelberg game where the blue team, as the follower, optimizes its controls to achieve its goals while misleading the red team into forming incorrect beliefs on its intentions. The red team, as the leader, strategically constructs and instills false beliefs through the blue team's envisioned SHT to manipulate the blue team's behavior and reveal its true objectives. The blue team's optimization problem balances the fulfillment of its primary objectives and the level of misdirection, while the red team coaxes the blue team into behaving consistently with its actual intentions. We derive a semi-explicit solution for the blue team's control problem within a linear-quadratic framework, and illustrate how the red team leverages leaked information from the blue team to counteract deception. Numerical experiments validate the model, showcasing the effectiveness of deception-driven strategies in adversarial systems. These findings integrate ancient strategic insights with modern control and game theory, providing a foundation for further exploration in adversarial decision-making, such as cybersecurity, autonomous systems, and financial markets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13462v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haosheng Zhou, Daniel Ralston, Xu Yang, Ruimeng Hu</dc:creator>
    </item>
    <item>
      <title>PyJobShop: Solving scheduling problems with constraint programming in Python</title>
      <link>https://arxiv.org/abs/2502.13483</link>
      <description>arXiv:2502.13483v1 Announce Type: new 
Abstract: This paper presents PyJobShop, an open-source Python library for solving scheduling problems with constraint programming. PyJobShop provides an easy-to-use modeling interface that supports a wide variety of scheduling problems, including well-known variants such as the flexible job shop problem and the resource-constrained project scheduling problem. PyJobShop integrates two state-of-the-art constraint programming solvers: Google's OR-Tools CP-SAT and IBM ILOG's CP Optimizer. We leverage PyJobShop to conduct large-scale numerical experiments on more than 9,000 benchmark instances from the machine scheduling and project scheduling literature, comparing the performance of OR-Tools and CP Optimizer. While CP Optimizer performs better on permutation scheduling and large-scale problems, OR-Tools is highly competitive on job shop scheduling and project scheduling problems--while also being fully open-source. By providing an accessible and tested implementation of constraint programming for scheduling, we hope that PyJobShop will enable researchers and practitioners to use constraint programming for real-world scheduling problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13483v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Leon Lan, Joost Berkhout</dc:creator>
    </item>
    <item>
      <title>An application of the mean motion problem to time-optimal control</title>
      <link>https://arxiv.org/abs/2502.13523</link>
      <description>arXiv:2502.13523v1 Announce Type: new 
Abstract: We consider time-optimal controls of a controllable linear system with a scalar control on a long time interval. It is well-known that if all the eigenvalues of the matrix describing the linear system dynamics are real then any time-optimal control has a bounded number of switching points, where the bound does not depend on the length of the time interval. We consider the case where the governing matrix has purely imaginary eigenvalues, and show that then, in the generic case, the number of switching points is bounded from below by a linear function of the length of the time interval. The proof is based on relating the switching function in the optimal control problem to the mean motion problem that dates back to Lagrange and was solved by Hermann Weyl.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13523v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Omri Dalin, Alexander Ovseevich, Michael Margaliot</dc:creator>
    </item>
    <item>
      <title>Evaluability of paired comparison data in stochastic paired comparison models: Necessary and sufficient condition</title>
      <link>https://arxiv.org/abs/2502.13617</link>
      <description>arXiv:2502.13617v1 Announce Type: new 
Abstract: In this paper, paired comparison models with stochastic background are investigated. We focus on the models that allow three options for choice. We estimate all parameters, the strength of the objects and the boundaries of equal decision, by maximum likelihood method. The existence and uniqueness of the estimator are key issues of the evaluation. Although a necessary and sufficient condition for the general case of three options has not been known until now, there are some different sufficient conditions that are formulated in the literature. In this paper, we provide a necessary and sufficient condition for the existence of a maximum and the uniqueness of the argument that maximizes the value, i.e. for the evaluability of the data in models of these types. By computer simulation, we present the efficiency of the condition, comparing it to the previously known sufficient conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13617v1</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>L\'aszl\'o Gyarmati, Csaba Mih\'alyk\'o, Eva Orb\'an-Mih\'alyk\'o, Andr\'as Mih\'alyk\'o</dc:creator>
    </item>
    <item>
      <title>Scalable Multi-Level optimization for Sequentially Cleared Energy Markets with a Case Study on Gas and Carbon Aware Unit Commitment</title>
      <link>https://arxiv.org/abs/2502.13643</link>
      <description>arXiv:2502.13643v1 Announce Type: new 
Abstract: This paper examines Mixed-Integer Multi-Level problems with Sequential Followers (MIMLSF), a specialized optimization model aimed at enhancing upper-level decision-making by incorporating anticipated outcomes from lower-level sequential market-clearing processes. We introduce a novel approach that combines lexicographic optimization with a weighted-sum method to asymptotically approximate the MIMLSF as a single-level problem, capable of managing multi-level problems exceeding three levels. To enhance computational efficiency and scalability, we propose a dedicated Benders decomposition method with multi-level subproblem separability. To demonstrate the practical application of our MIMLSF solution technique, we tackle a unit commitment problem (UC) within an integrated electricity, gas, and carbon market clearing framework in the Northeastern United States, enabling the incorporation of anticipated costs and revenues from gas and carbon markets into UC decisions. This ensures that only profitable gas-fired power plants (GFPPs) are committed, allowing system operators to make informed decisions that prevent GFPP economic losses and reduce total operational costs under stressed electricity and gas systems. The case study not only demonstrates the applicability of the MIMLSF model but also highlights the computational benefits of the dedicated Benders decomposition technique, achieving average reductions of 32.23% in computing time and 94.23% in optimality gaps compared to state-of-the-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13643v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuxin Xia, Iacopo Savelli, Thomas Morstyn</dc:creator>
    </item>
    <item>
      <title>Logistics Analysis for Lunar Post-Mission Disposal</title>
      <link>https://arxiv.org/abs/2502.13679</link>
      <description>arXiv:2502.13679v1 Announce Type: new 
Abstract: As human activities on the Moon expand through initiatives like NASA's Artemis program, the need for sustainable post-mission disposal strategies becomes critical to maintaining the lunar environment. This paper analyzes the logistics and environmental implications of waste products generated by In-Situ Resource Utilization technologies employed in oxygen production on the Moon. The study examines the inputs, generation of products, and the resulting byproducts from Molten Regolith Electrolysis, Soil/Water Extraction, and Direct Water Electrolysis systems. These technologies yield varied byproducts, including slag, metals and volatiles, each presenting unique challenges for disposal and recycling. The analysis assesses the economic and ecological impacts of In-Situ Resource Utilization activities on lunar operations using a multi-commodity flow model adapted from cislunar logistics frameworks. The results inform that ISRU-enabled missions achieve a significant threefold cost reduction. However, the management of byproducts remains a critical challenge, demanding innovative solutions to address their impact and support scalable and sustainable lunar exploration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13679v1</guid>
      <category>math.OC</category>
      <category>physics.geo-ph</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.2514/6.2025-1480</arxiv:DOI>
      <dc:creator>Evangelia Gkaravela, Hao Chen</dc:creator>
    </item>
    <item>
      <title>Linear programming for finite-horizon vector-valued Markov decision processes</title>
      <link>https://arxiv.org/abs/2502.13697</link>
      <description>arXiv:2502.13697v1 Announce Type: new 
Abstract: We propose a vector linear programming formulation for a non-stationary, finite-horizon Markov decision process with vector-valued rewards. Pareto efficient policies are shown to correspond to efficient solutions of the linear program, and vector linear programming theory allows us to fully characterize deterministic efficient policies. An algorithm for enumerating all efficient deterministic policies is presented then tested numerically in an engineering application.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13697v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anas Mifrani, Dominikus Noll</dc:creator>
    </item>
    <item>
      <title>A low-rank augmented Lagrangian method for doubly nonnegative relaxations of mixed-binary quadratic programs</title>
      <link>https://arxiv.org/abs/2502.13849</link>
      <description>arXiv:2502.13849v1 Announce Type: new 
Abstract: Doubly nonnegative (DNN) programming problems are known to be challenging to solve because of their huge number of $\Omega(n^2)$ constraints and $\Omega(n^2)$ variables. In this work, we introduce RNNAL, a method for solving DNN relaxations of large-scale mixed-binary quadratic programs by leveraging their solutions' possible low-rank property. RNNAL is a globally convergent Riemannian augmented Lagrangian method (ALM) that penalizes the nonnegativity and complementarity constraints while preserving all other constraints as an algebraic variety. After applying the low-rank decomposition to the ALM subproblem, its feasible region becomes an algebraic variety with favorable geometric properties. Our low-rank decomposition model is different from the standard Burer-Monteiro (BM) decomposition model in that we make the key improvement to equivalently reformulate most of the quadratic constraints after the BM decomposition into fewer and more manageable affine constraints. This modification is also important in helping us to alleviate the violation of Slater's condition for the primal DNN problem. Moreover, we make the crucial step to show that the metric projection onto the algebraic variety, although non-convex, can be transformed into a solvable convex optimization problem under certain regularity conditions, which can be ensured by a constraint-relaxation strategy. RNNAL is able to handle general semidefinite programming (SDP) with additional polyhedral cone constraints, thus serving as a prototype algorithm for solving general DNN problems. Numerous numerical experiments are conducted to validate the efficiency of the proposed RNNAL method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13849v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Di Hou, Tianyun Tang, Kim-Chuan Toh</dc:creator>
    </item>
    <item>
      <title>Variable aggregation for nonlinear optimization problems</title>
      <link>https://arxiv.org/abs/2502.13869</link>
      <description>arXiv:2502.13869v1 Announce Type: new 
Abstract: Variable aggregation has been largely studied as an important pre-solve algorithm for optimization of linear and mixed-integer programs. Although some nonlinear solvers and algebraic modeling languages implement variable aggregation as a pre-solve, the impact it can have on constrained nonlinear programs is unexplored. In this work, we formalize variable aggregation as a pre-solve algorithm to develop reduced-space formulations of nonlinear programs. A novel approximate maximum variable aggregation strategy is developed to aggregate as many variables as possible. Furthermore, aggregation strategies that preserve the problem structure are compared against approximate maximum aggregation. Our results show that variable aggregation can generally help to improve the convergence reliability of nonlinear programs. It can also help in reducing total solve time. However, Hessian evaluation can become a bottleneck if aggregation significantly increases the number of variables appearing nonlinearly in many constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13869v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sakshi Naik, Lorenz Biegler, Russell Bent, Robert Parker</dc:creator>
    </item>
    <item>
      <title>Sum-Of-Squares To Approximate Knapsack</title>
      <link>https://arxiv.org/abs/2502.13292</link>
      <description>arXiv:2502.13292v1 Announce Type: cross 
Abstract: These notes give a self-contained exposition of Karlin, Mathieu and Nguyen's tight estimate of the integrality gap of the sum-of-squares semidefinite program for solving the knapsack problem. They are based on a sequence of three lectures in CMU course on Advanced Approximation Algorithms in Fall'21 that used the KMN result to introduce the Sum-of-Squares method for algorithm design. The treatment in these notes uses the pseudo-distribution view of solutions to the sum-of-squares SDPs and only rely on a few basic, reusable results about pseudo-distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13292v1</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pravesh K. Kothari, Sherry Sarkar</dc:creator>
    </item>
    <item>
      <title>An Uncertainty-Aware Data-Driven Predictive Controller for Hybrid Power Plants</title>
      <link>https://arxiv.org/abs/2502.13333</link>
      <description>arXiv:2502.13333v1 Announce Type: cross 
Abstract: Given the advancements in data-driven modeling for complex engineering and scientific applications, this work utilizes a data-driven predictive control method, namely subspace predictive control, to coordinate hybrid power plant components and meet a desired power demand despite the presence of weather uncertainties. An uncertainty-aware data-driven predictive controller is proposed, and its potential is analyzed using real-world electricity demand profiles. For the analysis, a hybrid power plant with wind, solar, and co-located energy storage capacity of 4 MW each is considered. The analysis shows that the predictive controller can track a real-world-inspired electricity demand profile despite the presence of weather-induced uncertainties and be an intelligent forecaster for HPP performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13333v1</guid>
      <category>eess.SY</category>
      <category>cs.CE</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Manavendra Desai, Himanshu Sharma, Sayak Mukherjee, Sonja Glavaski</dc:creator>
    </item>
    <item>
      <title>Probabilistically Robust Uncertainty Analysis and Optimal Control of Continuous Lyophilization via Polynomial Chaos Theory</title>
      <link>https://arxiv.org/abs/2502.13420</link>
      <description>arXiv:2502.13420v1 Announce Type: cross 
Abstract: Lyophilization, aka freeze drying, is a process commonly used to increase the stability of various drug products in biotherapeutics manufacturing, e.g., mRNA vaccines, allowing for higher storage temperature. While the current trends in the industry are moving towards continuous manufacturing, the majority of industrial lyophilization processes are still being operated in a batch mode. This article presents a framework that accounts for the probabilistic uncertainty during the primary and secondary drying steps in continuous lyophilization. The probabilistic uncertainty is incorporated into the mechanistic model via polynomial chaos theory (PCT). The resulting PCT-based model is able to accurately and efficiently quantify the effects of uncertainty on several critical process variables, including the temperature, sublimation front, and concentration of bound water. The integration of the PCT-based model into stochastic optimization and control is demonstrated. The proposed framework and case studies can be used to guide the design and control of continuous lyophilization while accounting for probabilistic uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13420v1</guid>
      <category>cs.CE</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Prakitr Srisuma, George Barbastathis, Richard D. Braatz</dc:creator>
    </item>
    <item>
      <title>Smoothed Normalization for Efficient Distributed Private Optimization</title>
      <link>https://arxiv.org/abs/2502.13482</link>
      <description>arXiv:2502.13482v1 Announce Type: cross 
Abstract: Federated learning enables training machine learning models while preserving the privacy of participants. Surprisingly, there is no differentially private distributed method for smooth, non-convex optimization problems. The reason is that standard privacy techniques require bounding the participants' contributions, usually enforced via $\textit{clipping}$ of the updates. Existing literature typically ignores the effect of clipping by assuming the boundedness of gradient norms or analyzes distributed algorithms with clipping but ignores DP constraints. In this work, we study an alternative approach via $\textit{smoothed normalization}$ of the updates motivated by its favorable performance in the single-node setting. By integrating smoothed normalization with an error-feedback mechanism, we design a new distributed algorithm $\alpha$-$\sf NormEC$. We prove that our method achieves a superior convergence rate over prior works. By extending $\alpha$-$\sf NormEC$ to the DP setting, we obtain the first differentially private distributed optimization algorithm with provable convergence guarantees. Finally, our empirical results from neural network training indicate robust convergence of $\alpha$-$\sf NormEC$ across different parameter settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13482v1</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Egor Shulgin, Sarit Khirirat, Peter Richt\'arik</dc:creator>
    </item>
    <item>
      <title>Kernel Mean Embedding Topology: Weak and Strong Forms for Stochastic Kernels and Implications for Model Learning</title>
      <link>https://arxiv.org/abs/2502.13486</link>
      <description>arXiv:2502.13486v1 Announce Type: cross 
Abstract: We introduce a novel topology, called Kernel Mean Embedding Topology, for stochastic kernels, in a weak and strong form. This topology, defined on the spaces of Bochner integrable functions from a signal space to a space of probability measures endowed with a Hilbert space structure, allows for a versatile formulation. This construction allows one to obtain both a strong and weak formulation. (i) For its weak formulation, we highlight the utility on relaxed policy spaces, and investigate connections with the Young narrow topology and Borkar (or \( w^* \))-topology, and establish equivalence properties. We report that, while both the \( w^* \)-topology and kernel mean embedding topology are relatively compact, they are not closed. Conversely, while the Young narrow topology is closed, it lacks relative compactness. (ii) We show that the strong form provides an appropriate formulation for placing topologies on spaces of models characterized by stochastic kernels with explicit robustness and learning theoretic implications on optimal stochastic control under discounted or average cost criteria. (iii) We show that this topology possesses several properties making it ideal to study optimality, approximations, robustness and continuity properties. In particular, the kernel mean embedding topology has a Hilbert space structure, which is particularly useful for approximating stochastic kernels through simulation data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13486v1</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Naci Saldi, Serdar Yuksel</dc:creator>
    </item>
    <item>
      <title>Fundamental Bias in Inverting Random Sampling Matrices with Application to Sub-sampled Newton</title>
      <link>https://arxiv.org/abs/2502.13583</link>
      <description>arXiv:2502.13583v1 Announce Type: cross 
Abstract: A substantial body of work in machine learning (ML) and randomized numerical linear algebra (RandNLA) has exploited various sorts of random sketching methodologies, including random sampling and random projection, with much of the analysis using Johnson--Lindenstrauss and subspace embedding techniques. Recent studies have identified the issue of inversion bias -- the phenomenon that inverses of random sketches are not unbiased, despite the unbiasedness of the sketches themselves. This bias presents challenges for the use of random sketches in various ML pipelines, such as fast stochastic optimization, scalable statistical estimators, and distributed optimization.
  In the context of random projection, the inversion bias can be easily corrected for dense Gaussian projections (which are, however, too expensive for many applications). Recent work has shown how the inversion bias can be corrected for sparse sub-gaussian projections. In this paper, we show how the inversion bias can be corrected for random sampling methods, both uniform and non-uniform leverage-based, as well as for structured random projections, including those based on the Hadamard transform. Using these results, we establish problem-independent local convergence rates for sub-sampled Newton methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13583v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chengmei Niu, Zhenyu Liao, Zenan Ling, Michael W. Mahoney</dc:creator>
    </item>
    <item>
      <title>An Adaptive Data-Enabled Policy Optimization Approach for Autonomous Bicycle Control</title>
      <link>https://arxiv.org/abs/2502.13676</link>
      <description>arXiv:2502.13676v1 Announce Type: cross 
Abstract: This paper presents a unified control framework that integrates a Feedback Linearization (FL) controller in the inner loop with an adaptive Data-Enabled Policy Optimization (DeePO) controller in the outer loop to balance an autonomous bicycle. While the FL controller stabilizes and partially linearizes the inherently unstable and nonlinear system, its performance is compromised by unmodeled dynamics and time-varying characteristics. To overcome these limitations, the DeePO controller is introduced to enhance adaptability and robustness. The initial control policy of DeePO is obtained from a finite set of offline, persistently exciting input and state data. To improve stability and compensate for system nonlinearities and disturbances, a robustness-promoting regularizer refines the initial policy, while the adaptive section of the DeePO framework is enhanced with a forgetting factor to improve adaptation to time-varying dynamics. The proposed DeePO+FL approach is evaluated through simulations and real-world experiments on an instrumented autonomous bicycle. Results demonstrate its superiority over the FL-only approach, achieving more precise tracking of the reference lean angle and lean rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13676v1</guid>
      <category>eess.SY</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Niklas Persson, Feiran Zhao, Mojtaba Kaheni, Florian D\"orfler, Alessandro V. Papadopoulos</dc:creator>
    </item>
    <item>
      <title>Interior point methods are not worse than Simplex</title>
      <link>https://arxiv.org/abs/2206.08810</link>
      <description>arXiv:2206.08810v4 Announce Type: replace 
Abstract: We develop a new `subspace layered least squares' interior point method (IPM) for solving linear programs. Applied to an $n$-variable linear program in standard form, the iteration complexity of our IPM is up to an $O(n^{1.5} \log n)$ factor upper bounded by the \emph{straight line complexity} (SLC) of the linear program. This term refers to the minimum number of segments of any piecewise linear curve that traverses the \emph{wide neighborhood} of the central path, a lower bound on the iteration complexity of any IPM that follows a piecewise linear trajectory along a path induced by a self-concordant barrier. In particular, our algorithm matches the number of iterations of any such IPM up to the same factor $O(n^{1.5}\log n)$. As our second contribution, we show that the SLC of any linear program is upper bounded by $2^{n + o(1)}$, which implies that our IPM's iteration complexity is at most exponential. This in contrast to existing iteration complexity bounds that depend on either bit-complexity or condition measures; these can be unbounded in the problem dimension. We achieve our upper bound by showing that the central path is well-approximated by a combinatorial proxy we call the \emph{max central path}, which consists of $2n$ shadow vertex simplex paths. Our upper bound complements the lower bounds of Allamigeon, Benchimol, Gaubert, and Joswig (SIAGA 2018), and Allamigeon, Gaubert, and Vandame (STOC 2022), who constructed linear programs with exponential SLC. Finally, we show that each iteration of our IPM can be implemented in strongly polynomial time. Along the way, we develop a deterministic algorithm that approximates the singular value decomposition of a matrix in strongly polynomial time to high accuracy, which may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.08810v4</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xavier Allamigeon, Daniel Dadush, Georg Loho, Bento Natura, L\'aszl\'o A. V\'egh</dc:creator>
    </item>
    <item>
      <title>A novel dual-decomposition method for non-convex two-stage stochastic mixed-integer quadratically constrained quadratic problems</title>
      <link>https://arxiv.org/abs/2302.09872</link>
      <description>arXiv:2302.09872v5 Announce Type: replace 
Abstract: We propose the novel p-branch-and-bound method for solving two-stage stochastic programming problems whose deterministic equivalents are represented by non-convex mixed-integer quadratically constrained quadratic programming (MIQCQP) models. The precision of the solution generated by the p-branch-and-bound method can be arbitrarily adjusted by altering the value of the precision factor p. The proposed method combines two key techniques. The first one, named p-Lagrangian decomposition, generates a mixed-integer relaxation of a dual problem with a separable structure for a primal non-convex MIQCQP problem. The second one is a version of the classical dual decomposition approach that is applied to solve the Lagrangian dual problem and ensures that integrality and non-anticipativity conditions are met once the optimal solution is obtained. This paper also presents a comparative analysis of the p-branch-and-bound method efficiency considering two alternative solution methods for the dual problems as a subroutine. These are the proximal bundle method and Frank-Wolfe progressive hedging. The latter algorithm relies on the interpolation of linearisation steps similar to those taken in the Frank-Wolfe method as an inner loop in the classic progressive hedging. The p-branch-and-bound method's efficiency was tested on randomly generated instances and demonstrated superior performance over commercial solver Gurobi.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.09872v5</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1111/itor.70001</arxiv:DOI>
      <dc:creator>Nikita Belyak, Fabricio Oliveira</dc:creator>
    </item>
    <item>
      <title>Improved residual mode separation for finite-dimensional control of PDEs: application to the Euler-Bernoulli beam</title>
      <link>https://arxiv.org/abs/2308.05551</link>
      <description>arXiv:2308.05551v4 Announce Type: replace 
Abstract: We consider a simply-supported Euler-Bernoulli beam with viscous and Kelvin--Voigt damping. Our objective is to attenuate the effect of an unknown distributed disturbance using one piezoelectric actuator. We show how to design a suitable $H_\infty$ state-feedback controller based on a finite number of dominating modes. If the remaining (infinitely many) modes are ignored, the calculated $L^2$ gain is wrong. This happens because of the spillover phenomenon that occurs when the effect of the control on truncated modes is not accounted for in the feedback design. We propose a simple modification of the $H_\infty$ cost that prevents spillover. The key idea is to treat the control as a disturbance in the truncated modes and find the corresponding $L^2$ gains using the bounded real lemma. These $L^2$ gains are added to the control weight in the $H_\infty$ cost for the dominating modes, which prevents spillover. A numerical simulation of an aluminum beam with realistic parameters demonstrates the effectiveness of the proposed method. The presented approach is applicable to other types of PDEs, such as the heat, wave, and Kuramoto-Sivashinsky equations, as well as their semilinear versions. While this work focuses on $H_\infty$ control, the same methodology can be applied to guaranteed cost control, regional stability analysis, input-to-state stability, and systems with time-varying delays, including sampled-data systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.05551v4</guid>
      <category>math.OC</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.sysconle.2025.106048</arxiv:DOI>
      <dc:creator>Anton Selivanov, Emilia Fridman</dc:creator>
    </item>
    <item>
      <title>Risk-averse decision strategies for influence diagrams using rooted junction trees</title>
      <link>https://arxiv.org/abs/2401.03734</link>
      <description>arXiv:2401.03734v2 Announce Type: replace 
Abstract: This paper focuses on a mixed-integer programming formulation for influence diagrams, based on a gradual rooted junction tree representation of the diagram. We show that different risk considerations, including chance constraints and conditional value-at-risk, can be incorporated into the formulation with targeted, appropriate modifications to the diagram structure. The computational performance of the formulation is assessed on two example problems and is found to be highly dependent on the structure of the junction tree.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.03734v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Olli Herrala, Topias Terho, Fabricio Oliveira</dc:creator>
    </item>
    <item>
      <title>Truss topology design under harmonic loads: Peak power minimization with semidefinite programming</title>
      <link>https://arxiv.org/abs/2401.16175</link>
      <description>arXiv:2401.16175v2 Announce Type: replace 
Abstract: Designing lightweight yet stiff structures that can withstand vibrations is a crucial task in structural optimization. Here, we present a novel framework for truss topology optimization under undamped harmonic oscillations. Our approach minimizes the peak power of the structure under harmonic loads, overcoming the limitations of single-frequency and in-phase assumptions found in previous methods. For this, we leverage the concept of semidefinite representable (SDr) functions, demonstrating that while compliance readily conforms to an SDr representation, peak power requires a derivation based on the non-negativity of trigonometric functions. Finally, we introduce convex relaxations for the minimization problem and provide promising computational results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.16175v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shenyuan Ma, Jakub Marecek, Vyacheslav Kungurtsev, Marek Tyburec</dc:creator>
    </item>
    <item>
      <title>On finite termination of quasi-Newton methods on quadratic problems</title>
      <link>https://arxiv.org/abs/2407.03072</link>
      <description>arXiv:2407.03072v3 Announce Type: replace 
Abstract: Quasi-Newton methods form an important class of methods for solving nonlinear optimization problems. In such methods, first order information is used to approximate the second derivative. The aim is to mimic the fast convergence that can be guaranteed by Newton-based methods. In the best case, quasi-Newton methods will far outperform steepest descent and other first order methods, without the computational cost of calculating the exact second derivative. These convergence guarantees hold locally, which follows closely from the fact that, if the objective function is strongly convex, it can be approximated well by a quadratic function close to the solution. Understanding the performance of quasi-Newton methods on quadratic problems with a symmetric positive definite Hessian is therefore of vital importance. In the classic case, an approximation of the Hessian is updated at every iteration and exact line search is used. It is well known that the algorithm terminates finitely, even when the Hessian approximation is memoryless, i.e. requires only the most recent information. In this paper, we explore the possibilities in which reliance on exact line search and dependence on conjugate search directions can be relaxed, while preserving finite termination properties of quasi-Newton methods on quadratic problems. We show that it suffices to create a memoryless quasi-Newton matrix based on two vectors to give ability to compute a Newton direction within a finite number of iterations, independent of step lengths. It is unnecessary for the quasi-Newton approximation to act as the Hessian on the full space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03072v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aban Ansari-\"Onnestam, Anders Forsgren</dc:creator>
    </item>
    <item>
      <title>Linear Convergence Rate in Convex Setup is Possible! Gradient Descent Method Variants under $(L_0,L_1)$-Smoothness</title>
      <link>https://arxiv.org/abs/2412.17050</link>
      <description>arXiv:2412.17050v2 Announce Type: replace 
Abstract: The gradient descent (GD) method -- is a fundamental and likely the most popular optimization algorithm in machine learning (ML), with a history traced back to a paper in 1847 (Cauchy, 1847). It was studied under various assumptions, including so-called $(L_0,L_1)$-smoothness, which received noticeable attention in the ML community recently. In this paper, we provide a refined convergence analysis of gradient descent and its variants, assuming generalized smoothness. In particular, we show that $(L_0,L_1)$-GD has the following behavior in the convex setup: as long as $\|\nabla f(x^k)\| \geq \frac{L_0}{L_1}$ the algorithm has linear convergence in function suboptimality, and when $\|\nabla f(x^k)\| &lt; \frac{L_0}{L_1}$ is satisfied, $(L_0,L_1)$-GD has standard sublinear rate. Moreover, we also show that this behavior is common for its variants with different types of oracle: Normalized Gradient Descent as well as Clipped Gradient Descent (the case when the full gradient $\nabla f(x)$ is available); Random Coordinate Descent (when the gradient component $\nabla_{i} f(x)$ is available); Random Coordinate Descent with Order Oracle (when only $\text{sign} [f(y) - f(x)]$ is available). In addition, we also extend our analysis of $(L_0,L_1)$-GD to the strongly convex case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17050v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aleksandr Lobanov, Alexander Gasnikov, Eduard Gorbunov, Martin Tak\'a\v{c}</dc:creator>
    </item>
    <item>
      <title>Public Access Defibrillator Deployment for Cardiac Arrests: A Learn-Then-Optimize Approach with SHAP-based Interpretable Analytics</title>
      <link>https://arxiv.org/abs/2501.00819</link>
      <description>arXiv:2501.00819v2 Announce Type: replace 
Abstract: Out-of-hospital cardiac arrest (OHCA) survival rates remain extremely low due to challenges in the timely accessibility of medical devices. Therefore, effective deployment of automated external defibrillators (AED) can significantly increase survival rates. Precise and interpretable predictions of OHCA occurrences provide a solid foundation for efficient and robust AED deployment optimization. This study develops a novel learn-then-optimize approach, integrating three key components: a machine learning prediction model, SHAP-based interpretable analytics, and a SHAP-guided integer programming (SIP) model. The machine learning model is trained utilizing only geographic data as inputs to overcome data availability obstacles, and its strong predictive performance validates the feasibility of interpretation. Furthermore, the SHAP model elaborates on the contribution of each geographic feature to the OHCA occurrences. Finally, an integer programming model is formulated for optimizing AED deployment, incorporating SHAP-weighted OHCA densities. Various numerical experiments are conducted across different settings. Based on comparative and sensitive analysis, the optimization effect of our approach is verified and valuable insights are derived to provide substantial support for theoretical extension and practical implementation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.00819v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Chih-Yuan Yang, Keng-Hou Leong, Kexin Cao, Mingchuan Yang, Wai Kin Victor Chan</dc:creator>
    </item>
    <item>
      <title>Differentiation of inertial methods for optimizing smooth parametric function</title>
      <link>https://arxiv.org/abs/2502.00522</link>
      <description>arXiv:2502.00522v2 Announce Type: replace 
Abstract: In this paper, we consider the minimization of a $C^2-$smooth and strongly convex objective depending on a given parameter, which is usually found in many practical applications. We suppose that we desire to solve the problem with some inertial methods which cover a broader existing well-known inertial methods. Our main goal is to analyze the derivative of this algorithm as an infinite iterative process in the sense of ``automatic'' differentiation. This procedure is very common and has gain more attention recently. From a pure optimization perspective and under some mild premises, we show that any sequence generated by these inertial methods converge to the unique minimizer of the problem, which depends on the parameter. Moreover, we show a local linear convergence rate of the generated sequence. Concerning the differentiation of the scheme, we prove that the derivative of the sequence with respect to the parameter converges to the derivative of the limit of the sequence showing that any sequence is &lt;&lt;derivative stable&gt;&gt;. Finally, we investigate the rate at which the convergence occurs. We show that, this is locally linear with an error term tending to zero.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00522v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jean-Jacques Godeme</dc:creator>
    </item>
    <item>
      <title>Robust Optimization of Rank-Dependent Models with Uncertain Probabilities</title>
      <link>https://arxiv.org/abs/2502.11780</link>
      <description>arXiv:2502.11780v2 Announce Type: replace 
Abstract: This paper studies distributionally robust optimization for a large class of risk measures with ambiguity sets defined by $\phi$-divergences. The risk measures are allowed to be non-linear in probabilities, are represented by a Choquet integral possibly induced by a probability weighting function, and include many well-known examples (for example, CVaR, Mean-Median Deviation, Gini-type). Optimization for this class of robust risk measures is challenging due to their rank-dependent nature. We show that for many types of probability weighting functions including concave, convex and inverse $S$-shaped, the robust optimization problem can be reformulated into a rank-independent problem. In the case of a concave probability weighting function, the problem can be further reformulated into a convex optimization problem with finitely many constraints that admits explicit conic representability for a collection of canonical examples. While the number of constraints in general scales exponentially with the dimension of the state space, we circumvent this dimensionality curse and provide two types of upper and lower bounds algorithms. They yield tight upper and lower bounds on the exact optimal value and are formally shown to converge asymptotically. This is illustrated numerically in two examples given by a robust newsvendor problem and a robust portfolio choice problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11780v2</guid>
      <category>math.OC</category>
      <category>econ.TH</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Guanyu Jin, Roger J. A. Laeven, Dick den Hertog</dc:creator>
    </item>
    <item>
      <title>On the Steiner tree connecting a fractal set</title>
      <link>https://arxiv.org/abs/2304.01932</link>
      <description>arXiv:2304.01932v2 Announce Type: replace-cross 
Abstract: We construct an example of an infinite planar embedded self-similar binary tree $\Sigma$ which is the essentially unique solution to the Steiner problem of finding the shortest connection of a given planar self-similar fractal set $C$ of positive Hausdorff dimension. The set $C$ can be considered the set of leaves, or the ``boundary``, of the tree $\Sigma$, so that $\Sigma$ is an irreducible solution to the Steiner problem with datum $C$ (i.e. $\Sigma\setminus C$ is connected).</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.01932v2</guid>
      <category>math.MG</category>
      <category>math.DG</category>
      <category>math.OC</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Emanuele Paolini, Eugene Stepanov</dc:creator>
    </item>
    <item>
      <title>Stochastic Security as a Performance Metric for Quantum-enhanced Generative AI</title>
      <link>https://arxiv.org/abs/2305.07973</link>
      <description>arXiv:2305.07973v2 Announce Type: replace-cross 
Abstract: Motivated by applications of quantum computers in Gibbs sampling from continuous real-valued functions, we ask whether such algorithms can provide practical advantages for machine learning models trained on classical data and seek measures for quantifying such impacts. In this study, we focus on deep energy-based models (EBM), as they require continuous-domain Gibbs sampling both during training and inference. In lieu of fault-tolerant quantum computers that can execute quantum Gibbs sampling algorithms, we use the Monte Carlo simulation of diffusion processes as a classical alternative. More specifically, we investigate whether long-run persistent chain Monte Carlo simulation of Langevin dynamics improves the quality of the representations achieved by EBMs. We consider a scheme in which the Monte Carlo simulation of a diffusion, whose drift is given by the gradient of the energy function, is used to improve the adversarial robustness and calibration score of an independent classifier network. Our results show that increasing the computational budget of Gibbs sampling in persistent contrastive divergence improves both the calibration and adversarial robustness of the model, suggesting a prospective avenue of quantum advantage for generative AI using future large-scale quantum computers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.07973v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>quant-ph</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Noah A. Crum, Leanto Sunny, Pooya Ronagh, Raymond Laflamme, Radhakrishnan Balu, George Siopsis</dc:creator>
    </item>
    <item>
      <title>Learning stochastic dynamics from snapshots through regularized unbalanced optimal transport</title>
      <link>https://arxiv.org/abs/2410.00844</link>
      <description>arXiv:2410.00844v3 Announce Type: replace-cross 
Abstract: Reconstructing dynamics using samples from sparsely time-resolved snapshots is an important problem in both natural sciences and machine learning. Here, we introduce a new deep learning approach for solving regularized unbalanced optimal transport (RUOT) and inferring continuous unbalanced stochastic dynamics from observed snapshots. Based on the RUOT form, our method models these dynamics without requiring prior knowledge of growth and death processes or additional information, allowing them to be learned directly from data. Theoretically, we explore the connections between the RUOT and Schr\"odinger bridge problem and discuss the key challenges and potential solutions. The effectiveness of our method is demonstrated with a synthetic gene regulatory network, high-dimensional Gaussian Mixture Model, and single-cell RNA-seq data from blood development. Compared with other methods, our approach accurately identifies growth and transition patterns, eliminates false transitions, and constructs the Waddington developmental landscape. Our code is available at: https://github.com/zhenyiizhang/DeepRUOT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00844v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>physics.comp-ph</category>
      <category>q-bio.QM</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Zhenyi Zhang, Tiejun Li, Peijie Zhou</dc:creator>
    </item>
    <item>
      <title>Learning Variational Inequalities from Data: Fast Generalization Rates under Strong Monotonicity</title>
      <link>https://arxiv.org/abs/2410.20649</link>
      <description>arXiv:2410.20649v3 Announce Type: replace-cross 
Abstract: Variational inequalities (VIs) are a broad class of optimization problems encompassing machine learning problems ranging from standard convex minimization to more complex scenarios like min-max optimization and computing the equilibria of multi-player games. In convex optimization, strong convexity allows for fast statistical learning rates requiring only $\Theta(1/\epsilon)$ stochastic first-order oracle calls to find an $\epsilon$-optimal solution, rather than the standard $\Theta(1/\epsilon^2)$ calls. This note provides a simple overview of how one can similarly obtain fast $\Theta(1/\epsilon)$ rates for learning VIs that satisfy strong monotonicity, a generalization of strong convexity. Specifically, we demonstrate that standard stability-based generalization arguments for convex minimization extend directly to VIs when the domain admits a small covering, or when the operator is integrable and suboptimality is measured by potential functions; such as when finding equilibria in multi-player games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20649v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eric Zhao, Tatjana Chavdarova, Michael Jordan</dc:creator>
    </item>
    <item>
      <title>Identifiability of Autonomous and Controlled Open Quantum Systems</title>
      <link>https://arxiv.org/abs/2501.05270</link>
      <description>arXiv:2501.05270v2 Announce Type: replace-cross 
Abstract: Open quantum systems are a rich area of research in the intersection of quantum mechanics and stochastic analysis. By considering a variety of master equations, we unify multiple views of autonomous and controlled open quantum systems and, through considering their measurement dynamics, connect them to classical linear and bilinear system identification theory. This allows us to formulate corresponding notions of quantum state identifiability for these systems which, in particular, applies to quantum state tomography, providing conditions under which the probed quantum system is reconstructible. Interestingly, the dynamical representation of the system lends itself to considering two types of identifiability: the full master equation recovery and the recovery of the corresponding system matrices of the linear and bilinear systems. Both of these concepts are discussed in detail, and conditions under which reconstruction is possible are given. We set the groundwork for a number of constructive approaches to the identification of open quantum systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.05270v2</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Waqas Parvaiz, Johannes Aspman, Ales Wodecki, Georgios Korpas, Jakub Marecek</dc:creator>
    </item>
    <item>
      <title>Navigating Demand Uncertainty in Container Shipping: Deep Reinforcement Learning for Enabling Adaptive and Feasible Master Stowage Planning</title>
      <link>https://arxiv.org/abs/2502.12756</link>
      <description>arXiv:2502.12756v2 Announce Type: replace-cross 
Abstract: Reinforcement learning (RL) has shown promise in solving various combinatorial optimization problems. However, conventional RL faces challenges when dealing with real-world constraints, especially when action space feasibility is explicit and dependent on the corresponding state or trajectory. In this work, we focus on using RL in container shipping, often considered the cornerstone of global trade, by dealing with the critical challenge of master stowage planning. The main objective is to maximize cargo revenue and minimize operational costs while navigating demand uncertainty and various complex operational constraints, namely vessel capacity and stability, which must be dynamically updated along the vessel's voyage. To address this problem, we implement a deep reinforcement learning framework with feasibility projection to solve the master stowage planning problem (MPP) under demand uncertainty. The experimental results show that our architecture efficiently finds adaptive, feasible solutions for this multi-stage stochastic optimization problem, outperforming traditional mixed-integer programming and RL with feasibility regularization. Our AI-driven decision-support policy enables adaptive and feasible planning under uncertainty, optimizing operational efficiency and capacity utilization while contributing to sustainable and resilient global supply chains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12756v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jaike van Twiller, Yossiri Adulyasak, Erick Delage, Djordje Grbic, Rune M{\o}ller Jensen</dc:creator>
    </item>
  </channel>
</rss>
