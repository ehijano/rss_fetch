<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.PF updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.PF</link>
    <description>cs.PF updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.PF" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 30 Jan 2025 02:32:54 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Pulse-engineered Controlled-V gate and its applications on superconducting quantum device</title>
      <link>https://arxiv.org/abs/2102.06117</link>
      <description>arXiv:2102.06117v3 Announce Type: cross 
Abstract: In this paper, we demonstrate that, by employing OpenPulse design kit for IBM superconducting quantum devices, the controlled-V gate (CV gate) can be implemented in about half the gate time to the controlled-X (CX or CNOT gate) and consequently 65.5\% reduced gate time compared to the CX-based implementation of CV. Then, based on the theory of Cartan decomposition, we characterize the set of all two-qubit gates implemented with only two or three CV gates; using pulse-engineered CV gates enables us to implement these gates with shorter gate time and possibly better gate fidelity than the CX-based one, as actually demonstrated in two examples. Moreover, we showcase the improvement of linearly-coupled three-qubit Toffoli gate, by implementing it with the pulse-engineered CV gate, both in gate time and the averaged output-state fidelity. These results imply the importance of our CV gate implementation technique, which, as an additional option for the basis gate set design, may shorten the overall computation time and consequently improve the precision of several quantum algorithms executed on a real device.</description>
      <guid isPermaLink="false">oai:arXiv.org:2102.06117v3</guid>
      <category>quant-ph</category>
      <category>cs.PF</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TQE.2022.3170008</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Quantum Engineering, Volume: 3 (2022)</arxiv:journal_reference>
      <dc:creator>Takahiko Satoh, Shun Oomura, Michihiko Sugawara, Naoki Yamamoto</dc:creator>
    </item>
    <item>
      <title>Enhancements to P4TG: Performance, Protocols, and Automation</title>
      <link>https://arxiv.org/abs/2501.17127</link>
      <description>arXiv:2501.17127v1 Announce Type: cross 
Abstract: The P4-based traffic generator (P4TG) is a hardware-based traffic generator (TG) running on the Intel Tofino 1 ASIC. The TG can generate up to 1 Tb/s of traffic and directly measures rates, packet loss, and other metrics in the data plane. Many researchers and industrial partners have used it since its publication in 2023 and new features have been requested to be incorporated into P4TG. In this work, we provide an overview of the recently added features of P4TG. These enhancements include new traffic generation capabilities including IPv6 and segment routing v6 (SRv6) support and various encapsulation protocols such as VLAN, QinQ, VxLAN, and MPLS. Further, P4TG is ported to the Intel Tofino 2 platform enabling a generation capability of up to 4 Tb/s. The enhancements to P4TG also provide an improved user experience facilitating automated testing based on RFC 2544, report generation, and visualization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.17127v1</guid>
      <category>cs.NI</category>
      <category>cs.PF</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fabian Ihle, Etienne Zink, Steffen Lindner, Michael Menth</dc:creator>
    </item>
    <item>
      <title>Profiling Apple Silicon Performance for ML Training</title>
      <link>https://arxiv.org/abs/2501.14925</link>
      <description>arXiv:2501.14925v2 Announce Type: replace 
Abstract: Apple Silicon has attracted much attention for its performance and role in machine learning (ML) training. Unlike NVIDIA GPUs, which have traditionally dominated ML training, Apple Silicon has a significant difference in memory architecture. It uses Unified Memory, which integrates CPU and GPU memory instead of separate CPU memory and GPU VRAM. However, it is difficult to tell whether Unified Memory means more performance benefits.
  This paper investigates the performance differences by training several large language model (LLM) workloads end-to-end under different memory scenarios. The results show a significant performance gap between Apple Silicon and NVIDIA GPUs. This paper attributes this gap to system-level factors such as page faults, power consumption, and kernel launch time. In addition, the performance difference of basic linear algebra subprograms (BLAS) on the NVIDIA GPUs and Apple Silicon chips is analyzed to further explain the observed gap.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14925v2</guid>
      <category>cs.PF</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dahua Feng, Zhiming Xu, Rongxiang Wang, Felix Xiaozhu Lin</dc:creator>
    </item>
  </channel>
</rss>
