<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.NA</link>
    <description>math.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 11 Sep 2025 01:19:28 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>PeTTO: Leveraging GPUs to Accelerate Topology Optimization with the Pseudo-Transient Methods</title>
      <link>https://arxiv.org/abs/2509.06971</link>
      <description>arXiv:2509.06971v1 Announce Type: new 
Abstract: We present a Pseudo-Transient Topology Optimization (PeTTO) approach that can leverage graphics processing units (GPUs) to efficiently solve single-material and multi-material topology optimization problems. By integrating PeTTO with phase field methods, the partial differential equations (PDEs) constrained optimization problem in topology optimization is transformed into a set of time dependent PDEs, which can be analyzed using the knowledge of transient physics. The sensitivities with respect to the design variable are calculated with the automatic differentiation which help avoid tedious and error-prone manual derivations. The overall system of equations is efficiently solved using a hybrid of the pseudo-transient method and the accelerated pseudo-transient method, balancing the convergence rate and numerical stability. A variety of numerical examples are presented to demonstrate the effectiveness and efficiency of the proposed PeTTO approach. These examples cover different physics scenarios including mechanical and thermal problems, as well as single-material and multi-materials cases in both 2D and 3D. The numerical results show a 40- to 50-fold speedup when running the same PeTTO code on a single GPU compared to desktop CPUs. This work helps bridge the gap between high-performance computing and topology optimization, potentially enabling faster and better designs for real-world problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.06971v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mingyuan Yang, Qian Yu, Chao Yang</dc:creator>
    </item>
    <item>
      <title>Safe cross-entropy-based importance sampling for rare event simulations</title>
      <link>https://arxiv.org/abs/2509.07160</link>
      <description>arXiv:2509.07160v1 Announce Type: new 
Abstract: The Improved Cross-Entropy (ICE) method is a powerful tool for estimating failure probabilities in reliability analysis. Its core idea is to approximate the optimal importance-sampling density by minimizing the forward Kullback-Leibler divergence within a chosen parametric family-typically a mixture model. However, conventional mixtures are often light-tailed, which leads to slow convergence and instability when targeting very small failure probabilities. Moreover, selecting the number of mixture components in advance can be difficult and may undermine stability. To overcome these challenges, we adopt a weighted cross-entropy-penalized expectation-maximization (EM) algorithm that automatically prunes redundant components during the iterative process, making the approach more stable. Furthermore, we introduce a novel two-component mixture that pairs a light-tailed distribution with a heavy-tailed one, enabling more effective exploration of the tail region and thus accelerating convergence for extremely small failure probabilities. We call the resulting method Safe-ICE and assess it on a variety of test problems. Numerical results show that Safe-ICE not only converges more rapidly and yields more accurate failure-probability estimates than standard ICE, but also identifies the appropriate number of mixture components without manual tuning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.07160v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>stat.CO</category>
      <pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhiwei Gao, George Karniadakis</dc:creator>
    </item>
    <item>
      <title>Auxiliary space theory for the analysis of iterative methods for semidefinite linear systems</title>
      <link>https://arxiv.org/abs/2509.07179</link>
      <description>arXiv:2509.07179v1 Announce Type: new 
Abstract: We present an auxiliary space theory that provides a unified framework for analyzing various iterative methods for solving linear systems that may be semidefinite. By interpreting a given iterative method for the original system as an equivalent, yet more elementary, iterative method for an auxiliary system defined on a larger space, we derive sharp convergence estimates using elementary linear algebra. In particular, we establish identities for the error propagation operator and the condition number associated with iterative methods, which generalize and refine existing results. The proposed auxiliary space theory is applicable to the analysis of numerous advanced numerical methods in scientific computing. To illustrate its utility, we present three examples -- subspace correction methods, Hiptmair--Xu preconditioners, and auxiliary grid methods -- and demonstrate how the proposed theory yields refined analyses for these cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.07179v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jongho Park, Jinchao Xu</dc:creator>
    </item>
    <item>
      <title>The spectrum of the Steklov-Helmholtz operator</title>
      <link>https://arxiv.org/abs/2509.07249</link>
      <description>arXiv:2509.07249v1 Announce Type: new 
Abstract: We present a wavenumber-robust strategy for computing Steklov eigenpairs of the Helmholtz operator $-\Delta -\mu^2$. As the wavenumber $\mu \rightarrow \mu_D$ from below (where $\mu_D^2 $ is a Dirichlet- Laplace eigenvalue of multiplicity $\ell$), the lowest $\ell$ Steklov-Helmholtz eigenvalues diverge to $-\infty$. Computationally, the Steklov-Helmholtz eigenvalue problem becomes severely ill-conditioned when $\mu \approx \mu_D$.
  We first reformulate the problem in terms of a suitably-defined Dirichlet-to-Neumann map. We then use an indirect approach based on a single layer ansatz. The discrete single layer matrix is nearly singular close to exceptional wavenumbers, and we use a reduced singular value decomposition to avoid the consequent ill-conditioning. For smooth domains, convergence of our eigenvalue solver is spectral. We use this method (called the BIO-MOD approach) for shape optimization of scale-invariant Steklov-Helmholtz problems and prove that the disk maximizes the second eigenvalue under appropriate scaling. For curvilinear polygons, we use polynomially-graded meshes rather than uniform meshes. As a proof of concept, we also implemented BIO-MOD using RCIP quadratures (using the ChunkIE implementation). The BIO-MOD approach successfully removes ill-conditioning near exceptional wavenumbers, and very high eigenvalue accuracy (up to 10 digits for polygons, arbitrary precision accuracy for smooth domains) is observed.
  We deploy our approach to computationally study the spectral geometry of the Steklov-Helmholtz operator, including some questions about spectral asymptotics and spectral optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.07249v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nilima Nigam, Kshitij Patil, Weiran Sun</dc:creator>
    </item>
    <item>
      <title>The Stability of Block Eliminations and Additive Modifications</title>
      <link>https://arxiv.org/abs/2509.07305</link>
      <description>arXiv:2509.07305v1 Announce Type: new 
Abstract: The block elimination with additive modifications (BEAM) method was recently proposed as a alternative to LU with partial pivoting requiring less communication. Because of the novelty of BEAM, the existing theoretical analysis is lacking. To that end, we analyze both the numerical stability of the underlying block LU factorization and the effects of additive modifications. For the block LU factorization, we are able to improve the previous results of Demmel et al. from being cubic in the element growth to merely quadratic. Furthermore, we propose an alternative measure of element growth that is better aligned with block LU; this new measure of growth allows our analysis to apply to matrices that cannot be factored with pointwise LU. In the second part, we analyzed the modifications produced by BEAM and the effect they have on the condition number and growth factor. Finally, we show that BEAM will not apply any modifications in some cases that regular block LU can safely factor.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.07305v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Neil Lindquist, Piotr Luszczek, Jack Dongarra</dc:creator>
    </item>
    <item>
      <title>Quasi-Monte Carlo integration over $\mathbb{R}^s$ with boundary-damping importance sampling</title>
      <link>https://arxiv.org/abs/2509.07509</link>
      <description>arXiv:2509.07509v1 Announce Type: new 
Abstract: This paper proposes a new importance sampling (IS) that is tailored to quasi-Monte Carlo (QMC) integration over $\mathbb{R}^s$. IS introduces a multiplicative adjustment to the integrand by compensating the sampling from the proposal instead of the target distribution. Improper proposals result in severe adjustment factor for QMC. Our strategy is to first design a adjustment factor to meet desired regularities and then determine a tractable transport map from the standard uniforms to the proposal for using QMC quadrature points as inputs. The transport map has the effect of damping the boundary growth of the resulting integrand so that the effectiveness of QMC can be reclaimed. Under certain conditions on the original integrand, our proposed IS enjoys a fast convergence rate independently of the dimension $s$, making it amenable to high-dimensional problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.07509v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zexin Pan, Du Ouyang, Zhijian He</dc:creator>
    </item>
    <item>
      <title>High-order staggered Lagrangian hydrodynamics (II) : the artificial viscosity and hourglass control algorithm</title>
      <link>https://arxiv.org/abs/2509.07636</link>
      <description>arXiv:2509.07636v1 Announce Type: new 
Abstract: In this article, we investigate the artificial viscosity and hourglass control algorithms for high-order staggered Lagrangian hydrodynamics(SGH), as proposed in~\cite[Sun et al., 2025]{Sun2025High}. Inspired by the subzonal pressure method in classical staggered Lagrangian hydrodynamics, we extend the stiffness-based hourglass control algorithm to the high-order setting, enriching the pressure field from the $Q^{m-1}$ to the $Q^{m}$ polynomial space. A unified framework for this hourglass control approach is established, from which the classical subzonal pressure method naturally emerges as the special case of the $Q^1-P^0$ space. The artificial viscosity follows the formulation in~\cite[Dobrev et al., 2012]{Dobrev2012High}. We show that the viscosity admits a concise form, with intermediate variables explicitly computable, leading to improved computational efficiency and easier implementation. Moreover, the tensor viscosity in classical staggered Lagrangian hydrodynamics can be derived in a similarly compact and explicit form. Numerical experiments on two-dimensional problems are presented to demonstrate the accuracy and efficiency of the proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.07636v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zhiyuan Sun, Jun Liu, Pei Wang</dc:creator>
    </item>
    <item>
      <title>Physics-informed low-rank neural operators with application to parametric elliptic PDEs</title>
      <link>https://arxiv.org/abs/2509.07687</link>
      <description>arXiv:2509.07687v1 Announce Type: new 
Abstract: We present the Physics-Informed Low-Rank Neural Operator (PILNO), a neural operator framework for efficiently approximating solution operators of partial differential equations (PDEs) on point cloud data. PILNO combines low-rank kernel approximations with an encoder--decoder architecture, enabling fast, continuous one-shot predictions while remaining independent of specific discretizations. The model is trained using a physics-informed penalty framework, ensuring that PDE constraints and boundary conditions are satisfied in both supervised and unsupervised settings. We demonstrate its effectiveness on diverse problems, including function fitting, the Poisson equation, the screened Poisson equation with variable coefficients, and parameterized Darcy flow. The low-rank structure provides computational efficiency in high-dimensional parameter spaces, establishing PILNO as a scalable and flexible surrogate modeling tool for PDEs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.07687v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <category>stat.ML</category>
      <pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sebastian Schaffer, Lukas Exl</dc:creator>
    </item>
    <item>
      <title>Realizability-preserving monolithic convex limiting in continuous Galerkin discretizations of the M1 model of radiative transfer</title>
      <link>https://arxiv.org/abs/2509.07689</link>
      <description>arXiv:2509.07689v1 Announce Type: new 
Abstract: We discretize the $M_1$ model of radiative transfer using continuous finite elements and propose a tailor-made monolithic convex limiting (MCL) procedure for enforcing physical realizability. The $M_1$ system of nonlinear balance laws for the zeroth and first moments of a probability distribution function is derived from the linear Boltzmann equation and equipped with an entropy-based closure for the second moment. To ensure hyperbolicity and physical admissibility, evolving moments must stay in an invariant domain representing a convex set of realizable states. We first construct a low-order method that is provably invariant domain preserving (IDP). Introducing intermediate states that represent spatially averaged exact solutions of homogeneous Riemann problems, we prove that these so-called bar states are realizable in any number of space dimensions. This key auxiliary result enables us to show the IDP property of a fully discrete scheme with a diagonally implicit treatment of reactive terms. To achieve high resolution, we add nonlinear correction terms that are constrained using a two-step MCL algorithm. In the first limiting step, local bounds are imposed on each conserved variable to avoid spurious oscillations and maintain positivity of the scalar-valued zeroth moment (particle density). The second limiting step constrains the magnitude of the vector-valued first moment to be realizable. The flux-corrected finite element scheme is provably IDP. Its ability to prevent nonphysical behavior while attaining high-order accuracy in smooth regions is verified in a series of numerical tests. The developed methodology provides a robust simulation tool for dose calculation in radiotherapy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.07689v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paul Moujaes, Dmitri Kuzmin, Christian B\"aumer</dc:creator>
    </item>
    <item>
      <title>Embedding structures in continua: linear models and finite element discretizations</title>
      <link>https://arxiv.org/abs/2509.07735</link>
      <description>arXiv:2509.07735v1 Announce Type: new 
Abstract: This work describes models and numerical approximations that describe the mechanical behavior of deformable continua with embedded structural members, such as rigid bodies, beams, shells, etc. The continuum formulation extends an idea first presented in the context of the Arlequin method and constrains the kinematics of the two types of bodies to be compatible in the energy sense. In the article, we exploit the shared similarities of all structural theories to introduce a general framework for energetically coupling the latter with continua. In addition, we show that the problems, as well as their finite element approximations, are well-posed. Numerical examples of bodies with inclusions, fibers, and embedded surfaces are provided to illustrate the generality and robustness of the approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.07735v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>David Portillo, Ignacio Romero</dc:creator>
    </item>
    <item>
      <title>Feature Understanding and Sparsity Enhancement via 2-Layered kernel machines (2L-FUSE)</title>
      <link>https://arxiv.org/abs/2509.07806</link>
      <description>arXiv:2509.07806v1 Announce Type: new 
Abstract: We propose a novel sparsity enhancement strategy for regression tasks, based on learning a data-adaptive kernel metric, i.e., a shape matrix, through 2-Layered kernel machines. The resulting shape matrix, which defines a Mahalanobis-type deformation of the input space, is then factorized via an eigen-decomposition, allowing us to identify the most informative directions in the space of features. This data-driven approach provides a flexible, interpretable and accurate feature reduction scheme. Numerical experiments on synthetic and applications to real datasets of geomagnetic storms demonstrate that our approach achieves minimal yet highly informative feature sets without losing predictive performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.07806v1</guid>
      <category>math.NA</category>
      <category>astro-ph.SR</category>
      <category>cs.NA</category>
      <category>stat.ML</category>
      <pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fabiana Camattari, Sabrina Guastavino, Francesco Marchetti, Emma Perracchione</dc:creator>
    </item>
    <item>
      <title>Convergence analysis for the Barrett-Garcke-Nurnberg method of transport type</title>
      <link>https://arxiv.org/abs/2509.07834</link>
      <description>arXiv:2509.07834v1 Announce Type: new 
Abstract: In this paper, we propose a Barrett-Garcke-Nurnberg (BGN) method for evolving geometries under general flows and present the corresponding convergence analysis. Specifically, we examine the scenario where a closed curve evolves according to a prescribed background velocity field. Unlike mean curvature flow and surface diffusion, where the evolution velocities inherently exhibit parabolicity, this case is dominated by transport which poses a significant difficulty in establishing convergence proofs. To address the challenges imposed by this transport-dominant nature, we derive several discrete energy estimates of the transport type on discretized polynomial surfaces within the framework of the projection error. The use of the projection error is indispensable as it provides crucial additional stability through its orthogonality structure. We prove that the proposed method converges sub-optimally in the L2 norm, and this is the first convergence proof for a fully discrete numerical method solving the evolution of curves driven by general flows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.07834v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Genming Bai, Harald Garcke, Shravan Veerapaneni</dc:creator>
    </item>
    <item>
      <title>Quantum algorithms for general nonlinear dynamics based on the Carleman embedding</title>
      <link>https://arxiv.org/abs/2509.07155</link>
      <description>arXiv:2509.07155v1 Announce Type: cross 
Abstract: Important nonlinear dynamics, such as those found in plasma and fluid systems, are typically hard to simulate on classical computers. Thus, if fault-tolerant quantum computers could efficiently solve such nonlinear problems, it would be a transformative change for many industries. In a recent breakthrough [Liu et al., PNAS 2021], the first efficient quantum algorithm for solving nonlinear differential equations was constructed, based on a single condition $R&lt;1$, where $R$ characterizes the ratio of nonlinearity to dissipation. This result, however, is limited to the class of purely dissipative systems with negative log-norm, which excludes application to many important problems. In this work, we correct technical issues with this and other prior analysis, and substantially extend the scope of nonlinear dynamical systems that can be efficiently simulated on a quantum computer in a number of ways. Firstly, we extend the existing results from purely dissipative systems to a much broader class of stable systems, and show that every quadratic Lyapunov function for the linearized system corresponds to an independent $R$-number criterion for the convergence of the Carlemen scheme. Secondly, we extend our stable system results to physically relevant settings where conserved polynomial quantities exist. Finally, we provide extensive results for the class of non-resonant systems. With this, we are able to show that efficient quantum algorithms exist for a much wider class of nonlinear systems than previously known, and prove the BQP-completeness of nonlinear oscillator problems of exponential size. In our analysis, we also obtain several results related to the Poincar\'{e}-Dulac theorem and diagonalization of the Carleman matrix, which could be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.07155v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Jennings, Kamil Korzekwa, Matteo Lostaglio, Andrew T Sornborger, Yigit Subasi, Guoming Wang</dc:creator>
    </item>
    <item>
      <title>CLEAN and multi-scale CLEAN for STIX in Solar Orbiter</title>
      <link>https://arxiv.org/abs/2509.07167</link>
      <description>arXiv:2509.07167v1 Announce Type: cross 
Abstract: CLEAN is a well-established deconvolution approach to Fourier imaging at both radio wavelwengths and hard X-ray energies. However, specifically for hard X-ray imaging, CLEAN suffers two significant drawbacks: a rather limited degree of automation, and a tendency to under-resolution. This paper introduces a multi-scale version of CLEAN specifically tailored to the reconstruction of images from measurements observed by the Spectrometer/Telescope for Imaging X-rays (STIX) on-board Solar Orbiter. Using synthetic STIX data, this study shows that multi-scale CLEAN may represent a reliable solution to the two previously mentioned CLEAN limitations. Further, this paper shows the performances of CLEAN and its multi-scale release in reconstructing experimental real scenarios characterized by complex emission morphologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.07167v1</guid>
      <category>astro-ph.SR</category>
      <category>astro-ph.IM</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Miriana Catalano, Anna Volpara, Paolo Massa, Michele Piana, Anna Maria Massone</dc:creator>
    </item>
    <item>
      <title>A novel statistical workflow for nonstationary modelling of successive Fr\'{e}chet extremes</title>
      <link>https://arxiv.org/abs/2509.07296</link>
      <description>arXiv:2509.07296v1 Announce Type: cross 
Abstract: Accurate estimation of the frequency and magnitude of successive extreme events in energy demand is critical for strategic resource planning. Traditional approaches based on extreme value theory (EVT) are typically limited to modelling isolated extreme events and struggle to capture the dynamics of temporally clustered extremes, such as those driven by prolonged extreme weather events. These limitations are exacerbated by the scarcity of historical data and computational costs of longrun simulations leading to high uncertainty in return level estimates for successive extremes. Here, we introduce a novel statistical framework leveraging recent theoretical advances in successive extreme value modelling in dynamical systems. Under reasonable assumptions of the time series data (e.g. the data follow a fat-tailed Fr\'{e}chet distribution), our tool allows for significantly more robust estimates of returns and magnitudes of successive extreme events compared to standard likelihood methods. We illustrate our statistical workflow on scenarios of forecasted gas supply levels from 2025 to 2050. Common measures of statistical accuracy are provided as benchmarks for comparison.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.07296v1</guid>
      <category>math.ST</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.TH</category>
      <pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Grace Burtenshaw, Joe Lane, Meagan Carney</dc:creator>
    </item>
    <item>
      <title>Model Order Reduction for Quantum Molecular Dynamics</title>
      <link>https://arxiv.org/abs/2509.07340</link>
      <description>arXiv:2509.07340v1 Announce Type: cross 
Abstract: Molecular dynamics simulations are indispensable for exploring the behavior of atoms and molecules. Grounded in quantum mechanical principles, quantum molecular dynamics provides high predictive power but its computational cost is dominated by iterative high-fidelity electronic structure calculations. We propose a novel model order reduction approach as an alternative to high-fidelity electronic structure calculation. By learning a low-dimensional representation of the electronic solution manifold within the Kohn-Sham density functional theory framework, our model order reduction approach determines the ground state electronic density by projecting the problem onto a low-dimensional subspace, thereby avoiding the computationally expensive iterative optimization of electronic wavefunctions in the full space. We demonstrate the capability of our method on a water molecule, showing excellent agreement with high-fidelity simulations for both molecular geometry and dynamic properties, highlighting the generalizability through carefully designed parametrization and systematic sampling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.07340v1</guid>
      <category>physics.chem-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Siu Wun Cheung, Youngsoo Choi, Jean-Luc Fattebert, Daniel Osei-Kuffuor</dc:creator>
    </item>
    <item>
      <title>On Global Rates for Regularization Methods based on Secant Derivative Approximations</title>
      <link>https://arxiv.org/abs/2509.07580</link>
      <description>arXiv:2509.07580v1 Announce Type: cross 
Abstract: An inexact framework for high-order adaptive regularization methods is presented, in which approximations may be used for the $p$th-order tensor, based on lower-order derivatives. Between each recalculation of the $p$th-order derivative approximation, a high-order secant equation can be used to update the $p$th-order tensor as proposed in (Welzel 2024) or the approximation can be kept constant in a lazy manner. When refreshing the $p$th-order tensor approximation after $m$ steps, an exact evaluation of the tensor or a finite difference approximation can be used with an explicit discretization stepsize. For all the newly adaptive regularization variants, we prove an $\mathcal{O}\left( \max[ \epsilon_1^{-(p+1)/p}, \, \epsilon_2^{(-p+1)/(p-1)} ] \right)$ bound on the number of iterations needed to reach an $(\epsilon_1, \, \epsilon_2)$ second-order stationary points. Discussions on the number of oracle calls for each introduced variant are also provided.
  When $p=2$, we obtain a second-order method that uses quasi-Newton approximations with an $\mathcal{O}\left(\max[\epsilon_1^{-3/2}, \, \, \epsilon_2^{-3}]\right)$ iteration bound to achieve approximate second-order stationarity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.07580v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Coralia Cartis, Sadok Jerad</dc:creator>
    </item>
    <item>
      <title>Asymmetric Modulation Design for Fluid-Antenna SWIPT Systems</title>
      <link>https://arxiv.org/abs/2509.07610</link>
      <description>arXiv:2509.07610v1 Announce Type: cross 
Abstract: In this work, we propose the design of modulation schemes that improve the rate-energy region of fluid antenna-assisted simultaneous wireless information and power transfer (SWIPT) systems. By considering the nonlinear characteristics of practical energy harvesting circuits, we formulate a dual-objective rate-energy (RE) region optimization problem to jointly maximize the discrete-input mutual information (DIMI) and harvested current. The problem is solved using the epsilon-constraint method and optimized constellations are designed for various energy harvesting thresholds. We then evaluate the performance of the optimized constellations under three different fluid antenna (FA) port selection strategies: (i) Best Port, (ii) Fixed Port, and (iii) Random Port. Our simulation results demonstrate significant performance gains of optimized constellations over conventional constellations in both information rate and energy harvesting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.07610v1</guid>
      <category>eess.SP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ahsan Mehmood, Ioannis Krikidis, Ghassan M. Kraidy</dc:creator>
    </item>
    <item>
      <title>Generalized eigenvalue stabilization for immersed explicit dynamics</title>
      <link>https://arxiv.org/abs/2509.07632</link>
      <description>arXiv:2509.07632v1 Announce Type: cross 
Abstract: Explicit time integration for immersed finite element discretizations severely suffers from the influence of poorly cut elements. In this contribution, we propose a generalized eigenvalue stabilization (GEVS) strategy for the element mass matrices of cut elements to cure their adverse impact on the critical time step size of the global system. We use spectral basis functions, specifically $C^0$ continuous Lagrangian interpolation polynomials defined on Gauss-Lobatto-Legendre (GLL) points, which, in combination with its associated GLL quadrature rule, yield high-order convergent diagonal mass matrices for uncut elements. Moreover, considering cut elements, we combine the proposed GEVS approach with the finite cell method (FCM) to guarantee definiteness of the system matrices. However, the proposed GEVS stabilization can directly be applied to other immersed boundary finite element methods. Numerical experiments demonstrate that the stabilization strategy achieves optimal convergence rates and recovers critical time step sizes of equivalent boundary-conforming discretizations. This also holds in the presence of weakly enforced Dirichlet boundary conditions using either Nitsche's method or penalty formulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.07632v1</guid>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tim B\"urchner, Lars Radtke, Sascha Eisentr\"ager, Alexander D\"uster, Ernst Rank, Stefan Kollmannsberger, Philipp Kopp</dc:creator>
    </item>
    <item>
      <title>HYLU: Hybrid Parallel Sparse LU Factorization</title>
      <link>https://arxiv.org/abs/2509.07690</link>
      <description>arXiv:2509.07690v1 Announce Type: cross 
Abstract: This article introduces HYLU, a hybrid parallel LU factorization-based general-purpose solver designed for efficiently solving sparse linear systems (Ax=b) on multi-core shared-memory architectures. The key technical feature of HYLU is the integration of hybrid numerical kernels so that it can adapt to various sparsity patterns of coefficient matrices. Tests on 34 sparse matrices from SuiteSparse Matrix Collection reveal that HYLU outperforms Intel MKL PARDISO in the numerical factorization phase by geometric means of 1.74X (for one-time solving) and 2.26X (for repeated solving). HYLU can be downloaded from https://github.com/chenxm1986/hylu.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.07690v1</guid>
      <category>cs.AR</category>
      <category>cs.DC</category>
      <category>cs.MS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaoming Chen</dc:creator>
    </item>
    <item>
      <title>Estimation of Cointegration Vectors in Time Series via Global Optimisation</title>
      <link>https://arxiv.org/abs/2409.02552</link>
      <description>arXiv:2409.02552v3 Announce Type: replace 
Abstract: Time Series Analysis has been given a great amount of study in which many useful tests were developed. The phenomenal work of Engle and Granger in 1987 and Johansen in 1988 has paved the way for the most commonly used cointegration tests so far. Even though cointegrating relationships focus on long-term behaviour and correlation of multiple nonstationary time series, oftentimes we encounter statistical data with limited sample sizes and other information. Thus other tests with empirical advantages may also be of considerable importance. In this paper, we provide an optimisation approach motivated by the Blind Source Separation, or also known as Independent Component Analysis, for cointegration between financial time series. Two methods for cointegration tests are introduced, namely decorrelation for the bivariate case and maximisation of nongaussianity for higher-dimensions. We highlight the empirical preponderances of independent components and also the computational simplicity, compared to common practices of cointegration such as the Johansen's Cointegration Test. The advantages of our methods, especially the better performances in limited sample size, enable a wider range of application and accessibility for researchers and practitioners to identify cointegrating relationships.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02552v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alvey Qianli Lin, Zhiwen Zhang</dc:creator>
    </item>
    <item>
      <title>Global convergence of adaptive least-squares finite element methods for nonlinear PDEs</title>
      <link>https://arxiv.org/abs/2509.01531</link>
      <description>arXiv:2509.01531v2 Announce Type: replace 
Abstract: The Zarantonello fixed-point iteration is an established linearization scheme for quasilinear PDEs with strongly monotone and Lipschitz continuous nonlinearity. This paper presents a weighted least-squares minimization for the computation of the update of this scheme. The resulting formulation allows for a conforming finite element discretization of the primal and dual variable of the PDE with arbitrary polynomial degree. The least-squares functional provides a built-in a posteriori discretization error estimator in each linearization step motivating an adaptive Uzawa-type algorithm with an outer linearization loop and an inner adaptive mesh-refinement loop. We prove R-linear convergence of the linearization iterates for arbitrary initial guesses. Particular focus is on the role of the weights in the least-squares functional of the linearized problem and their influence on the robustness of the Zarantonello damping parameter. Numerical experiments illustrate the performance of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.01531v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Philipp Bringmann, Dirk Praetorius</dc:creator>
    </item>
    <item>
      <title>CLINN: Conservation Law Informed Neural Network for Approximating Discontinuous Solutions</title>
      <link>https://arxiv.org/abs/2509.02091</link>
      <description>arXiv:2509.02091v2 Announce Type: replace 
Abstract: Physics-informed Neural Network (PINN) faces significant challenges when approximating solutions to conservation laws, particularly in ensuring conservation and accurately resolving discontinuities. To address these limitations, we propose Conservation Law-informed Neural Network (CLINN), a novel framework that incorporates the boundedness constraint, implicit solution form, and Rankine-Hugoniot condition of scalar conservation laws into the loss function, thereby enforcing exact conservation properties. Furthermore, we integrate a residual-based adaptive refinement (RAR) strategy to dynamically prioritize training near discontinuities, substantially improving the network's ability to capture sharp gradients. Numerical experiments are conducted on benchmark problems, including the inviscid Burgers equation, the Lighthill-Whitham-Richards (LWR) traffic flow model, and the Buckley-Leverett problem. Results demonstrate that CLINN achieves superior accuracy in resolving solution profiles and discontinuity locations while reducing numeral oscillations. Compared to conventional PINN, CLINN yields a maximum reduction of 99.2% in mean squared error (MSE).</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02091v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weiheng Zeng, Kun Wang, Ruoxi Lu, Tiegang Liu</dc:creator>
    </item>
    <item>
      <title>High-order staggered Lagrangian hydrodynamics (I): framework of the discretization scheme</title>
      <link>https://arxiv.org/abs/2509.05944</link>
      <description>arXiv:2509.05944v2 Announce Type: replace 
Abstract: This paper presents a discretization framework for high-order staggered Lagrangian hydrodynamics, bridging two well-established algorithms algorithms: high-order curvilinear finite element Lagrangian hydrodynamics [Dobrev et al. 2012] and compatible hydrodynamics methods[Caramana et al.1998]. We emphasizes the critical relationship between the degrees of freedom (DOFs) associated with the density variable and the choice of numerical quadrature rules which is employed in the mass conservation law. The precise quadrature rule will lead the consistency issues arising from the density and internal energy variables being defined at different physical points. Our approach resolves this by unifying the quadrature rule for the specific discretization space, though this inevitably introduces hourglass distortion. Another key feature of the proposed framework is the strategic arrangement of DOFs for kinematic and thermodynamic variables, which enhances computational efficiency and leads to diagonal mass matrices in the momentum and energy equations. Finally, we present a smooth numerical example that validate the accuracy of the proposed high-order Lagrangian hydrodynamics framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.05944v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zhiyuan Sun, Jun Liu, Pei Wang</dc:creator>
    </item>
    <item>
      <title>Expanding Hardware-Efficiently Manipulable Hilbert Space via Hamiltonian Embedding</title>
      <link>https://arxiv.org/abs/2401.08550</link>
      <description>arXiv:2401.08550v2 Announce Type: replace-cross 
Abstract: Many promising quantum applications depend on the efficient quantum simulation of an exponentially large sparse Hamiltonian, a task known as sparse Hamiltonian simulation, which is fundamentally important in quantum computation. Although several theoretically appealing quantum algorithms have been proposed for this task, they typically require a black-box query model of the sparse Hamiltonian, rendering them impractical for near-term implementation on quantum devices.
  In this paper, we propose a technique named Hamiltonian embedding. This technique simulates a desired sparse Hamiltonian by embedding it into the evolution of a larger and more structured quantum system, allowing for more efficient simulation through hardware-efficient operations. We conduct a systematic study of this new technique and demonstrate significant savings in computational resources for implementing prominent quantum applications. As a result, we can now experimentally realize quantum walks on complicated graphs (e.g., binary trees, glued-tree graphs), quantum spatial search, and the simulation of real-space Schr\"odinger equations on current trapped-ion and neutral-atom platforms. Given the fundamental role of Hamiltonian evolution in the design of quantum algorithms, our technique markedly expands the horizon of implementable quantum advantages in the NISQ era.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.08550v2</guid>
      <category>quant-ph</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiaqi Leng, Joseph Li, Yuxiang Peng, Xiaodi Wu</dc:creator>
    </item>
    <item>
      <title>Self-Supervised Temporal Super-Resolution of Energy Data using Generative Adversarial Transformer</title>
      <link>https://arxiv.org/abs/2508.10587</link>
      <description>arXiv:2508.10587v2 Announce Type: replace-cross 
Abstract: To bridge the temporal granularity gap in energy network design and operation based on Energy System Models, resampling of time series is required. While conventional upsampling methods are computationally efficient, they often result in significant information loss or increased noise. Advanced models such as time series generation models, Super-Resolution models and imputation models show potential, but also face fundamental challenges. The goal of time series generative models is to learn the distribution of the original data to generate high-resolution series with similar statistical characteristics. This is not entirely consistent with the definition of upsampling. Time series Super-Resolution models or imputation models can degrade the accuracy of upsampling because the input low-resolution time series are sparse and may have insufficient context. Moreover, such models usually rely on supervised learning paradigms. This presents a fundamental application paradox: their training requires the high-resolution time series that is intrinsically absent in upsampling application scenarios. To address the mentioned upsampling issue, this paper introduces a new method utilizing Generative Adversarial Transformers (GATs), which can be trained without access to any ground-truth high-resolution data. Compared with conventional interpolation methods, the introduced method can reduce the root mean square error (RMSE) of upsampling tasks by 9%, and the accuracy of a model predictive control (MPC) application scenario is improved by 13%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10587v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>eess.SP</category>
      <category>math.NA</category>
      <pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xuanhao Mu, G\"okhan Demirel, Yuzhe Zhang, Jianlei Liu, Thorsten Schlachter, Veit Hagenmeyer</dc:creator>
    </item>
  </channel>
</rss>
