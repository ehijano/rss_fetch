<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.PF updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.PF</link>
    <description>cs.PF updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.PF" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 12 Mar 2025 04:01:34 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Disaggregated Design for GPU-Based Volumetric Data Structures</title>
      <link>https://arxiv.org/abs/2503.07898</link>
      <description>arXiv:2503.07898v1 Announce Type: cross 
Abstract: Volumetric data structures are traditionally optimized for data locality, with a primary focus on efficient memory access patterns in computational tasks. However, prioritizing data locality alone can overlook other critical factors necessary for optimal performance, e.g., occupancy, communication, and kernel fusion. We propose a novel disaggregated design approach that rebalances the trade-offs between data locality and these essential objectives. This includes reducing communication overhead in distributed memory architectures, mitigating the impact of register pressure in complex boundary conditions for fluid simulation, and increasing opportunities for kernel fusion.
  We present a comprehensive analysis of the benefits of our disaggregated design, applied to a fluid solver based on the Lattice Boltzmann Method (LBM) and deployed on a single-node multi-GPU system. Our evaluation spans various discretizations, ranging from dense to block-sparse and multi-resolution representations, highlighting the flexibility and efficiency of the disaggregated design across diverse use cases. Leveraging the disaggregated design, we showcase how we target different optimization objectives that result in up to a $3\times$ speedup compared to state-of-the-art solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.07898v1</guid>
      <category>cs.DC</category>
      <category>cs.PF</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Massimiliano Meneghin, Ahmed H. Mahmoud</dc:creator>
    </item>
    <item>
      <title>Investigating Execution-Aware Language Models for Code Optimization</title>
      <link>https://arxiv.org/abs/2503.08228</link>
      <description>arXiv:2503.08228v1 Announce Type: cross 
Abstract: Code optimization is the process of enhancing code efficiency, while preserving its intended functionality. This process often requires a deep understanding of the code execution behavior at run-time to identify and address inefficiencies effectively. Recent studies have shown that language models can play a significant role in automating code optimization. However, these models may have insufficient knowledge of how code execute at run-time. To address this limitation, researchers have developed strategies that integrate code execution information into language models. These strategies have shown promise, enhancing the effectiveness of language models in various software engineering tasks. However, despite the close relationship between code execution behavior and efficiency, the specific impact of these strategies on code optimization remains largely unexplored. This study investigates how incorporating code execution information into language models affects their ability to optimize code. Specifically, we apply three different training strategies to incorporate four code execution aspects -- line executions, line coverage, branch coverage, and variable states -- into CodeT5+, a well-known language model for code. Our results indicate that execution-aware models provide limited benefits compared to the standard CodeT5+ model in optimizing code.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08228v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.PF</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Federico Di Menna, Luca Traini, Gabriele Bavota, Vittorio Cortellessa</dc:creator>
    </item>
  </channel>
</rss>
