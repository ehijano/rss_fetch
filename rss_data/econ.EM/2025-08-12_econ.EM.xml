<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 12 Aug 2025 04:16:00 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Conceptual winsorizing: An application to the social cost of carbon</title>
      <link>https://arxiv.org/abs/2508.07384</link>
      <description>arXiv:2508.07384v1 Announce Type: new 
Abstract: There are many published estimates of the social cost of carbon. Some are clear outliers, the result of poorly constrained models. Percentile winsorizing is an option, but I here propose conceptual winsorizing: The social cost of carbon is either a willingness to pay, which cannot exceed the ability to pay, or a proposed carbon tax, which cannot raise more revenue than all other taxes combined. Conceptual winsorizing successfully removes high outliers. It slackens as economies decarbonize, slowly without climate policy, faster with.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07384v1</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Richard S. J. Tol</dc:creator>
    </item>
    <item>
      <title>Treatment-Effect Estimation in Complex Designs under a Parallel-trends Assumption</title>
      <link>https://arxiv.org/abs/2508.07808</link>
      <description>arXiv:2508.07808v1 Announce Type: new 
Abstract: This paper considers the identification of dynamic treatment effects with panel data, in complex designs where the treatment may not be binary and may not be absorbing. We first show that under no-anticipation and parallel-trends assumptions, we can identify event-study effects comparing outcomes under the actual treatment path and under the status-quo path where all units would have kept their period-one treatment throughout the panel. Those effects can be helpful to evaluate ex-post the policies that effectively took place, and once properly normalized they estimate weighted averages of marginal effects of the current and lagged treatments on the outcome. Yet, they may still be hard to interpret, and they cannot be used to evaluate the effects of other policies than the ones that were conducted. To make progress, we impose another restriction, namely a random coefficients distributed-lag linear model, where effects remain constant over time. Under this model, the usual distributed-lag two-way-fixed-effects regression may be misleading. Instead, we show that this random coefficients model can be estimated simply. We illustrate our findings by revisiting Gentzkow et al. (2011).</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07808v1</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Cl\'ement de Chaisemartin, Xavier D'Haultf{\oe}uille</dc:creator>
    </item>
    <item>
      <title>Amazon Ads Multi-Touch Attribution</title>
      <link>https://arxiv.org/abs/2508.08209</link>
      <description>arXiv:2508.08209v1 Announce Type: new 
Abstract: Amazon's new Multi-Touch Attribution (MTA) solution allows advertisers to measure how each touchpoint across the marketing funnel contributes to a conversion. This gives advertisers a more comprehensive view of their Amazon Ads performance across objectives when multiple ads influence shopping decisions. Amazon MTA uses a combination of randomized controlled trials (RCTs) and machine learning (ML) models to allocate credit for Amazon conversions across Amazon Ads touchpoints in proportion to their value, i.e., their likely contribution to shopping decisions. ML models trained purely on observational data are easy to scale and can yield precise predictions, but the models might produce biased estimates of ad effects. RCTs yield unbiased ad effects but can be noisy. Our MTA methodology combines experiments, ML models, and Amazon's shopping signals in a thoughtful manner to inform attribution credit allocation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08209v1</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Randall Lewis, Florian Zettelmeyer, Brett R. Gordon, Cristobal Garib, Johannes Hermle, Mike Perry, Henrique Romero, German Schnaidt</dc:creator>
    </item>
    <item>
      <title>Interaction between Returns and Order Flow Imbalances: Endogeneity, Intraday Variations, and Macroeconomic News Announcements</title>
      <link>https://arxiv.org/abs/2508.06788</link>
      <description>arXiv:2508.06788v1 Announce Type: cross 
Abstract: The study examines the interaction between returns and order flow imbalances (differences between buy and sell orders), constructed from the best bid and offer files of S&amp;P 500 E-mini futures contract, using a structural vector autoregressive model. The intraday variation in market activity is considered by applying the model for each short interval each day, whereas the endogeneity due to time aggregation is handled by estimating the structural parameters via the identification through heteroskedasticity. The estimation results show that significant endogeneity exists and that the estimated parameters and impulse responses exhibit significant intraday variations, reflecting intense or mild order submission activities. Further, the estimated parameters change around macroeconomic news announcements, suggesting inactive order submission periods exist when they occur. Overall, such announcement effects are mostly explained by the order submission activities reflecting the public information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.06788v1</guid>
      <category>q-fin.TR</category>
      <category>econ.EM</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Makoto Takahashi</dc:creator>
    </item>
    <item>
      <title>The Power of Tests for Detecting $p$-Hacking</title>
      <link>https://arxiv.org/abs/2205.07950</link>
      <description>arXiv:2205.07950v4 Announce Type: replace 
Abstract: A flourishing empirical literature investigates the prevalence of $p$-hacking based on the distribution of $p$-values across studies. Interpreting results in this literature requires a careful understanding of the power of methods for detecting $p$-hacking. We theoretically study the implications of likely forms of $p$-hacking on the distribution of $p$-values to understand the power of tests for detecting it. Power can be low and depends crucially on the $p$-hacking strategy and the distribution of true effects. Combined tests for upper bounds and monotonicity and tests for continuity of the $p$-curve tend to have the highest power for detecting $p$-hacking.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.07950v4</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Graham Elliott, Nikolay Kudrin, Kaspar W\"uthrich</dc:creator>
    </item>
    <item>
      <title>Quasi-Bayes in Latent Variable Models</title>
      <link>https://arxiv.org/abs/2311.06831</link>
      <description>arXiv:2311.06831v3 Announce Type: replace 
Abstract: Latent variable models are widely used to account for unobserved determinants of economic behavior. This paper introduces a quasi-Bayes approach to nonparametrically estimate a large class of latent variable models. As an application, we model U.S. individual log earnings from the Panel Study of Income Dynamics (PSID) as the sum of latent permanent and transitory components. Simulations illustrate the favorable performance of quasi-Bayes estimators relative to common alternatives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.06831v3</guid>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sid Kankanala</dc:creator>
    </item>
    <item>
      <title>Structural Periodic Vector Autoregressions</title>
      <link>https://arxiv.org/abs/2401.14545</link>
      <description>arXiv:2401.14545v2 Announce Type: replace 
Abstract: While seasonality inherent to raw macroeconomic data is commonly removed by seasonal adjustment techniques before it is used for structural inference, this may distort valuable information in the data. As an alternative method to commonly used structural vector autoregressions (SVARs) for seasonally adjusted data, we propose to model potential periodicity in seasonally unadjusted (raw) data directly by structural periodic vector autoregressions (SPVARs). This approach does not only allow for periodically time-varying intercepts, but also for periodic autoregressive parameters and innovations variances. As this larger flexibility leads to an increased number of parameters, we propose linearly constrained estimation techniques. Moreover, based on SPVARs, we provide two novel identification schemes and propose a general framework for impulse response analyses that allows for direct consideration of seasonal patterns. We provide asymptotic theory for SPVAR estimators and impulse responses under flexible linear restrictions and introduce a test for seasonality in impulse responses. For the construction of confidence intervals, we discuss several residual-based (seasonal) bootstrap methods and prove their bootstrap consistency under different assumptions. A real data application shows that useful information about the periodic structure in the data may be lost when relying on common seasonal adjustment methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.14545v2</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Dzikowski, Carsten Jentsch</dc:creator>
    </item>
    <item>
      <title>Continuous difference-in-differences with double/debiased machine learning</title>
      <link>https://arxiv.org/abs/2408.10509</link>
      <description>arXiv:2408.10509v4 Announce Type: replace 
Abstract: This paper extends difference-in-differences to settings with continuous treatments. Specifically, the average treatment effect on the treated (ATT) at any level of treatment intensity is identified under a conditional parallel trends assumption. Estimating the ATT in this framework requires first estimating infinite-dimensional nuisance parameters, particularly the conditional density of the continuous treatment, which can introduce substantial bias. To address this challenge, we propose estimators for the causal parameters under the double/debiased machine learning framework and establish their asymptotic normality. Additionally, we provide consistent variance estimators and construct uniform confidence bands based on a multiplier bootstrap procedure. To demonstrate the effectiveness of our approach, we apply our estimators to the 1983 Medicare Prospective Payment System (PPS) reform studied by Acemoglu and Finkelstein (2008), reframing it as a DiD with continuous treatment and nonparametrically estimating its effects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10509v4</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lucas Z. Zhang</dc:creator>
    </item>
    <item>
      <title>Bayesian Smoothed Quantile Regression</title>
      <link>https://arxiv.org/abs/2508.01738</link>
      <description>arXiv:2508.01738v2 Announce Type: replace-cross 
Abstract: Bayesian quantile regression based on the asymmetric Laplace distribution (ALD) likelihood suffers from two fundamental limitations: the non-differentiability of the check loss precludes gradient-based Markov chain Monte Carlo (MCMC) methods, and the posterior mean provides biased quantile estimates. We propose Bayesian smoothed quantile regression (BSQR), which replaces the check loss with a kernel-smoothed version, creating a continuously differentiable likelihood. This smoothing has two crucial consequences: it enables efficient Hamiltonian Monte Carlo sampling, and it yields a consistent posterior distribution, thereby resolving the inferential bias of the standard approach. We further establish conditions for posterior propriety under various priors (including improper and hierarchical) and characterize how kernel choice affects posterior concentration and computational efficiency. Extensive simulations validate our theoretical findings, demonstrating that BSQR achieves up to a 50% reduction in predictive check loss at extreme quantiles compared to ALD-based methods, while improving MCMC efficiency by 20-40% in effective sample size. An empirical application to financial risk measurement during the COVID-19 era illustrates BSQR's practical advantages in capturing dynamic systemic risk. The BSQR framework provides a theoretically-grounded and computationally-efficient solution to longstanding challenges in Bayesian quantile regression, with compact-support kernels like the uniform and triangular emerging as particularly effective choices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.01738v2</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bingqi Liu, Kangqiang Li, Tianxiao Pang</dc:creator>
    </item>
  </channel>
</rss>
