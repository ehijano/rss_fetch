<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 21 Nov 2024 02:40:31 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>ChemSICal: Evaluating a Stochastic Chemical Reaction Network for Molecular Multiple Access</title>
      <link>https://arxiv.org/abs/2411.12637</link>
      <description>arXiv:2411.12637v1 Announce Type: new 
Abstract: Proposals for molecular communication networks as part of a future internet of bio-nano-things have become more intricate and the question of practical implementation is gaining more importance. One option is to apply detailed chemical modeling to capture more realistic effects of computing processes in biological systems. In this paper, we present ChemSICal, a detailed model for implementing the successive interference cancellation (SIC) algorithm for molecular multiple access in diffusion-based molecular communication networks as a chemical reaction network (CRN). We describe the structure of the model as a number of smaller reaction blocks, their speed controlled by reaction rate constants (RRCs). Deterministic and stochastic methods are utilized to first iteratively improve the choice of RRCs and subsequently investigate the performance of the model in terms of an error probability. We analyze the model's sensitivity to parameter changes and find that the analytically optimal values for the non-chemical model do not necessarily translate to the chemical domain. This necessitates careful optimization, especially of the RRCs, which are crucial for the successful operation of the ChemSICal system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12637v1</guid>
      <category>cs.ET</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Wietfeld, Marina Wendrich, Sebastian Schmidt, Wolfgang Kellerer</dc:creator>
    </item>
    <item>
      <title>LLM4DS: Evaluating Large Language Models for Data Science Code Generation</title>
      <link>https://arxiv.org/abs/2411.11908</link>
      <description>arXiv:2411.11908v1 Announce Type: cross 
Abstract: The adoption of Large Language Models (LLMs) for code generation in data science offers substantial potential for enhancing tasks such as data manipulation, statistical analysis, and visualization. However, the effectiveness of these models in the data science domain remains underexplored. This paper presents a controlled experiment that empirically assesses the performance of four leading LLM-based AI assistants-Microsoft Copilot (GPT-4 Turbo), ChatGPT (o1-preview), Claude (3.5 Sonnet), and Perplexity Labs (Llama-3.1-70b-instruct)-on a diverse set of data science coding challenges sourced from the Stratacratch platform. Using the Goal-Question-Metric (GQM) approach, we evaluated each model's effectiveness across task types (Analytical, Algorithm, Visualization) and varying difficulty levels. Our findings reveal that all models exceeded a 50% baseline success rate, confirming their capability beyond random chance. Notably, only ChatGPT and Claude achieved success rates significantly above a 60% baseline, though none of the models reached a 70% threshold, indicating limitations in higher standards. ChatGPT demonstrated consistent performance across varying difficulty levels, while Claude's success rate fluctuated with task complexity. Hypothesis testing indicates that task type does not significantly impact success rate overall. For analytical tasks, efficiency analysis shows no significant differences in execution times, though ChatGPT tended to be slower and less predictable despite high success rates. This study provides a structured, empirical evaluation of LLMs in data science, delivering insights that support informed model selection tailored to specific task demands. Our findings establish a framework for future AI assessments, emphasizing the value of rigorous evaluation beyond basic accuracy measures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11908v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nathalia Nascimento, Everton Guimaraes, Sai Sanjna Chintakunta, Santhosh Anitha Boominathan</dc:creator>
    </item>
    <item>
      <title>Distributed quantum logic algorithm</title>
      <link>https://arxiv.org/abs/2411.11979</link>
      <description>arXiv:2411.11979v1 Announce Type: cross 
Abstract: Parallel computation enables multiple processors to execute different parts of a task simultaneously, improving processing speed and efficiency. In quantum computing, parallel gate implementation involves executing gates independently in different registers, directly impacting the circuit depth, the number of sequential quantum gate operations, and thus the algorithm execution time. This work examines a method for reducing circuit depth by introducing auxiliary qubits to enable parallel gate execution, potentially enhancing the performance of quantum simulations on near-term quantum devices. We show that any circuit on $n$ qubits with depth $O\left(M n^2\right)$, where $M = M(n)$ is some function of $n$, can be transformed into a circuit with depth $O\left(\log_2(M) n^2\right)$ operating on $O\left(M n\right)$ qubits. This technique may be particularly useful in noisy environments, where recent findings indicate that only the final $O\left(\log n\right)$ layers influence the expectation value of observables. It may also optimize Trotterization by exponentially reducing the number of Trotter steps. Additionally, the method may offer advantages for distributed quantum computing, and the intuition of treating quantum states as gates and operators as vectors used in this work may have broader applications in quantum computation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11979v1</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Boris Arseniev</dc:creator>
    </item>
    <item>
      <title>Empowering Large Scale Quantum Circuit Development: Effective Simulation of Sycamore Circuits</title>
      <link>https://arxiv.org/abs/2411.12131</link>
      <description>arXiv:2411.12131v1 Announce Type: cross 
Abstract: Simulating quantum systems using classical computing equipment has been a significant research focus. This work demonstrates that circuits as large and complex as the random circuit sampling (RCS) circuits published as a part of Google's pioneering work [4-7] claiming quantum supremacy can be effectively simulated with high fidelity on classical systems commonly available to developers, using the universal quantum simulator included in the Quantum Rings SDK, making this advancement accessible to everyone. This study achieved an average linear cross-entropy benchmarking (XEB) score of 0.678, indicating a strong correlation with ideal quantum simulation and exceeding the XEB values currently reported for the same circuits today while completing circuit execution in a reasonable timeframe. This capability empowers researchers and developers to build, debug, and execute large-scale quantum circuits ahead of the general availability of low-error rate quantum computers and invent new quantum algorithms or deploy commercial-grade applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12131v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.ET</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Venkateswaran Kasirajan, Torey Battelle, Bob Wold</dc:creator>
    </item>
    <item>
      <title>From Centralized RAN to Open RAN: A Survey on the Evolution of Distributed Antenna Systems</title>
      <link>https://arxiv.org/abs/2411.12166</link>
      <description>arXiv:2411.12166v1 Announce Type: cross 
Abstract: Next-generation mobile networks require evolved radio access network (RAN) architectures to meet the demands of high capacity, massive connectivity, reduced costs, and energy efficiency, and to realize communication with ultra-low latency and ultra-high reliability. {Meeting such} requirements for both mobile users and vertical industries in the next decade {requires novel solutions. One of the potential solutions that attracted significant research attention in the past 15 years} is to redesign the radio access network (RAN). In this survey, we present a comprehensive survey on distributed antenna system (DAS) architectures that address these challenges and improve network performance. We cover the transition from traditional decentralized RAN to DAS, including cloud radio-access networks (C-RAN), fog radio-access networks (F-RAN), virtualized radio-access networks (V-RAN), cell-free massive multiple-input multiple-output (CF-mMIMO), and {the most recent advances manifested in} open radio-access network (O-RAN). In the process, we discuss the benefits and limitations of these architectures, including the impact of limited-capacity fronthaul links, various cooperative uplink and downlink coding strategies, cross-layer optimization, and techniques to optimize the performance of DAS. Moreover, we review key enabling technologies for next-generation RAN systems, such as multi-access edge computing, network function virtualization, software-defined networking, and network slicing; in addition to some crucial radio access technologies, such as millimeter wave, massive multi-input multi-output, device-to-device communication, and massive machine-type communication. Last but not least, we discuss the major research challenges in DAS and identify several possible directions for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12166v1</guid>
      <category>eess.SP</category>
      <category>cs.ET</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mahmoud A. Hasabelnaby, Mohanad Obeed, Mohammed Saif, Anas Chaaban, M. J. Hossain</dc:creator>
    </item>
    <item>
      <title>Perfecting Imperfect Physical Neural Networks with Transferable Robustness using Sharpness-Aware Training</title>
      <link>https://arxiv.org/abs/2411.12352</link>
      <description>arXiv:2411.12352v1 Announce Type: cross 
Abstract: AI models are essential in science and engineering, but recent advances are pushing the limits of traditional digital hardware. To address these limitations, physical neural networks (PNNs), which use physical substrates for computation, have gained increasing attention. However, developing effective training methods for PNNs remains a significant challenge. Current approaches, regardless of offline and online training, suffer from significant accuracy loss. Offline training is hindered by imprecise modeling, while online training yields device-specific models that can't be transferred to other devices due to manufacturing variances. Both methods face challenges from perturbations after deployment, such as thermal drift or alignment errors, which make trained models invalid and require retraining. Here, we address the challenges with both offline and online training through a novel technique called Sharpness-Aware Training (SAT), where we innovatively leverage the geometry of the loss landscape to tackle the problems in training physical systems. SAT enables accurate training using efficient backpropagation algorithms, even with imprecise models. PNNs trained by SAT offline even outperform those trained online, despite modeling and fabrication errors. SAT also overcomes online training limitations by enabling reliable transfer of models between devices. Finally, SAT is highly resilient to perturbations after deployment, allowing PNNs to continuously operate accurately under perturbations without retraining. We demonstrate SAT across three types of PNNs, showing it is universally applicable, regardless of whether the models are explicitly known. This work offers a transformative, efficient approach to training PNNs, addressing critical challenges in analog computing and enabling real-world deployment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12352v1</guid>
      <category>physics.optics</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tengji Xu, Zeyu Luo, Shaojie Liu, Li Fan, Qiarong Xiao, Benshan Wang, Dongliang Wang, Chaoran Huang</dc:creator>
    </item>
    <item>
      <title>MAViS: Modular Autonomous Virtualization System for Two-Dimensional Semiconductor Quantum Dot Arrays</title>
      <link>https://arxiv.org/abs/2411.12516</link>
      <description>arXiv:2411.12516v1 Announce Type: cross 
Abstract: Arrays of gate-defined semiconductor quantum dots are among the leading candidates for building scalable quantum processors. High-fidelity initialization, control, and readout of spin qubit registers require exquisite and targeted control over key Hamiltonian parameters that define the electrostatic environment. However, due to the tight gate pitch, capacitive crosstalk between gates hinders independent tuning of chemical potentials and interdot couplings. While virtual gates offer a practical solution, determining all the required cross-capacitance matrices accurately and efficiently in large quantum dot registers is an open challenge. Here, we establish a Modular Automated Virtualization System (MAViS) -- a general and modular framework for autonomously constructing a complete stack of multi-layer virtual gates in real time. Our method employs machine learning techniques to rapidly extract features from two-dimensional charge stability diagrams. We then utilize computer vision and regression models to self-consistently determine all relative capacitive couplings necessary for virtualizing plunger and barrier gates in both low- and high-tunnel-coupling regimes. Using MAViS, we successfully demonstrate accurate virtualization of a dense two-dimensional array comprising ten quantum dots defined in a high-quality Ge/SiGe heterostructure. Our work offers an elegant and practical solution for the efficient control of large-scale semiconductor quantum dot systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12516v1</guid>
      <category>cond-mat.mes-hall</category>
      <category>cs.CV</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <category>quant-ph</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anantha S. Rao, Donovan Buterakos, Barnaby van Straaten, Valentin John, C\'ecile X. Yu, Stefan D. Oosterhout, Lucas Stehouwer, Giordano Scappucci, Menno Veldhorst, Francesco Borsoi, Justyna P. Zwolak</dc:creator>
    </item>
    <item>
      <title>Neurosymbolic Graph Enrichment for Grounded World Models</title>
      <link>https://arxiv.org/abs/2411.12671</link>
      <description>arXiv:2411.12671v1 Announce Type: cross 
Abstract: The development of artificial intelligence systems capable of understanding and reasoning about complex real-world scenarios is a significant challenge. In this work we present a novel approach to enhance and exploit LLM reactive capability to address complex problems and interpret deeply contextual real-world meaning. We introduce a method and a tool for creating a multimodal, knowledge-augmented formal representation of meaning that combines the strengths of large language models with structured semantic representations. Our method begins with an image input, utilizing state-of-the-art large language models to generate a natural language description. This description is then transformed into an Abstract Meaning Representation (AMR) graph, which is formalized and enriched with logical design patterns, and layered semantics derived from linguistic and factual knowledge bases. The resulting graph is then fed back into the LLM to be extended with implicit knowledge activated by complex heuristic learning, including semantic implicatures, moral values, embodied cognition, and metaphorical representations. By bridging the gap between unstructured language models and formal semantic structures, our method opens new avenues for tackling intricate problems in natural language understanding and reasoning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12671v1</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.ET</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Stefano De Giorgis, Aldo Gangemi, Alessandro Russo</dc:creator>
    </item>
    <item>
      <title>Regulating Chatbot Output via Inter-Informational Competition</title>
      <link>https://arxiv.org/abs/2403.11046</link>
      <description>arXiv:2403.11046v2 Announce Type: replace-cross 
Abstract: The advent of ChatGPT has sparked over a year of regulatory frenzy. However, few existing studies have rigorously questioned the assumption that, if left unregulated, AI chatbot's output would inflict tangible, severe real harm on human affairs. Most researchers have overlooked the critical possibility that the information market itself can effectively mitigate these risks and, as a result, they tend to use regulatory tools to address the issue directly. This Article develops a yardstick for reevaluating both AI-related content risks and corresponding regulatory proposals by focusing on inter-informational competition among various outlets. The decades-long history of regulating information and communications technologies indicates that regulators tend to err too much on the side of caution and to put forward excessive regulatory measures when encountering the uncertainties brought about by new technologies. In fact, a trove of empirical evidence has demonstrated that market competition among information outlets can effectively mitigate most risks and that overreliance on regulation is not only unnecessary but detrimental, as well. This Article argues that sufficient competition among chatbots and other information outlets in the information marketplace can sufficiently mitigate and even resolve most content risks posed by generative AI technologies. This renders certain loudly advocated regulatory strategies, like mandatory prohibitions, licensure, curation of datasets, and notice-and-response regimes, truly unnecessary and even toxic to desirable competition and innovation throughout the AI industry. Ultimately, the ideas that I advance in this Article should pour some much-needed cold water on the regulatory frenzy over generative AI and steer the issue back to a rational track.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11046v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>22 Northwestern Journal of Technology and Intellectual Property 109 (2024)</arxiv:journal_reference>
      <dc:creator>Jiawei Zhang</dc:creator>
    </item>
    <item>
      <title>Unveiling and Mitigating Bias in Large Language Model Recommendations: A Path to Fairness</title>
      <link>https://arxiv.org/abs/2409.10825</link>
      <description>arXiv:2409.10825v2 Announce Type: replace-cross 
Abstract: Large Language Model (LLM)-based recommendation systems provide more comprehensive recommendations than traditional systems by deeply analyzing content and user behavior. However, these systems often exhibit biases, favoring mainstream content while marginalizing non-traditional options due to skewed training data. This study investigates the intricate relationship between bias and LLM-based recommendation systems, with a focus on music, song, and book recommendations across diverse demographic and cultural groups. Through a comprehensive analysis conducted over different LLM-models, this paper evaluates the impact of bias on recommendation outcomes. Our findings highlight that biases are not only deeply embedded but also widely pervasive across these systems, emphasizing the substantial and widespread nature of the issue. Moreover, contextual information, such as socioeconomic status, further amplify these biases, demonstrating the complexity and depth of the challenges faced in creating fair recommendations across different groups.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.10825v2</guid>
      <category>cs.IR</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shahnewaz Karim Sakib, Anindya Bijoy Das</dc:creator>
    </item>
  </channel>
</rss>
