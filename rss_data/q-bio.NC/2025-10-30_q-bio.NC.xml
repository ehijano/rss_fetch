<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 31 Oct 2025 04:00:30 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>InputDSA: Demixing then Comparing Recurrent and Externally Driven Dynamics</title>
      <link>https://arxiv.org/abs/2510.25943</link>
      <description>arXiv:2510.25943v1 Announce Type: new 
Abstract: In control problems and basic scientific modeling, it is important to compare observations with dynamical simulations. For example, comparing two neural systems can shed light on the nature of emergent computations in the brain and deep neural networks. Recently, Ostrow et al. (2023) introduced Dynamical Similarity Analysis (DSA), a method to measure the similarity of two systems based on their recurrent dynamics rather than geometry or topology. However, DSA does not consider how inputs affect the dynamics, meaning that two similar systems, if driven differently, may be classified as different. Because real-world dynamical systems are rarely autonomous, it is important to account for the effects of input drive. To this end, we introduce a novel metric for comparing both intrinsic (recurrent) and input-driven dynamics, called InputDSA (iDSA). InputDSA extends the DSA framework by estimating and comparing both input and intrinsic dynamic operators using a variant of Dynamic Mode Decomposition with control (DMDc) based on subspace identification. We demonstrate that InputDSA can successfully compare partially observed, input-driven systems from noisy data. We show that when the true inputs are unknown, surrogate inputs can be substituted without a major deterioration in similarity estimates. We apply InputDSA on Recurrent Neural Networks (RNNs) trained with Deep Reinforcement Learning, identifying that high-performing networks are dynamically similar to one another, while low-performing networks are more diverse. Lastly, we apply InputDSA to neural data recorded from rats performing a cognitive task, demonstrating that it identifies a transition from input-driven evidence accumulation to intrinsically-driven decision-making. Our work demonstrates that InputDSA is a robust and efficient method for comparing intrinsic dynamics and the effect of external input on dynamical systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25943v1</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <category>q-bio.QM</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ann Huang, Mitchell Ostrow, Satpreet H. Singh, Leo Kozachkov, Ila Fiete, Kanaka Rajan</dc:creator>
    </item>
    <item>
      <title>Integrated Information Theory: A Consciousness-First Approach to What Exists</title>
      <link>https://arxiv.org/abs/2510.25998</link>
      <description>arXiv:2510.25998v1 Announce Type: new 
Abstract: This overview of integrated information theory (IIT) emphasizes IIT's "consciousness-first" approach to what exists. Consciousness demonstrates to each of us that something exists--experience--and reveals its essential properties--the axioms of phenomenal existence. IIT formulates these properties operationally, yielding the postulates of physical existence. To exist intrinsically or absolutely, an entity must have cause-effect power upon itself, in a specific, unitary, definite and structured manner. IIT's explanatory identity claims that an entity's cause-effect structure accounts for all properties of an experience--essential and accidental--with no additional ingredients. These include the feeling of spatial extendedness, temporal flow, of objects binding general concepts with particular configurations of features, and of qualia such as colors and sounds. IIT's intrinsic ontology has implications for understanding meaning, perception, and free will, for assessing consciousness in patients, infants, other species, and artifacts, and for reassessing our place in nature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25998v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Giulio Tononi, Melanie Boly</dc:creator>
    </item>
    <item>
      <title>Brain-IT: Image Reconstruction from fMRI via Brain-Interaction Transformer</title>
      <link>https://arxiv.org/abs/2510.25976</link>
      <description>arXiv:2510.25976v1 Announce Type: cross 
Abstract: Reconstructing images seen by people from their fMRI brain recordings provides a non-invasive window into the human brain. Despite recent progress enabled by diffusion models, current methods often lack faithfulness to the actual seen images. We present "Brain-IT", a brain-inspired approach that addresses this challenge through a Brain Interaction Transformer (BIT), allowing effective interactions between clusters of functionally-similar brain-voxels. These functional-clusters are shared by all subjects, serving as building blocks for integrating information both within and across brains. All model components are shared by all clusters &amp; subjects, allowing efficient training with a limited amount of data. To guide the image reconstruction, BIT predicts two complementary localized patch-level image features: (i)high-level semantic features which steer the diffusion model toward the correct semantic content of the image; and (ii)low-level structural features which help to initialize the diffusion process with the correct coarse layout of the image. BIT's design enables direct flow of information from brain-voxel clusters to localized image features. Through these principles, our method achieves image reconstructions from fMRI that faithfully reconstruct the seen images, and surpass current SotA approaches both visually and by standard objective metrics. Moreover, with only 1-hour of fMRI data from a new subject, we achieve results comparable to current methods trained on full 40-hour recordings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25976v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Roman Beliy, Amit Zalcher, Jonathan Kogman, Navve Wasserman, Michal Irani</dc:creator>
    </item>
    <item>
      <title>Modeling Neural Activity with Conditionally Linear Dynamical Systems</title>
      <link>https://arxiv.org/abs/2502.18347</link>
      <description>arXiv:2502.18347v2 Announce Type: replace 
Abstract: Neural population activity exhibits complex, nonlinear dynamics, varying in time, over trials, and across experimental conditions. Here, we develop Conditionally Linear Dynamical System (CLDS) models as a general-purpose method to characterize these dynamics. These models use Gaussian Process (GP) priors to capture the nonlinear dependence of circuit dynamics on task and behavioral variables. Conditioned on these covariates, the data is modeled with linear dynamics. This allows for transparent interpretation and tractable Bayesian inference. We find that CLDS models can perform well even in severely data-limited regimes (e.g. one trial per condition) due to their Bayesian formulation and ability to share statistical power across nearby task conditions. In example applications, we apply CLDS to model thalamic neurons that nonlinearly encode heading direction and to model motor cortical neurons during a cued reaching task.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.18347v2</guid>
      <category>q-bio.NC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Victor Geadah, Amin Nejatbakhsh, David Lipshutz, Jonathan W. Pillow, Alex H. Williams</dc:creator>
    </item>
    <item>
      <title>Low dimensional dynamics of a sparse balanced synaptic network of quadratic integrate-and-fire neurons</title>
      <link>https://arxiv.org/abs/2508.06253</link>
      <description>arXiv:2508.06253v2 Announce Type: replace 
Abstract: Kinetics of a balanced network of neurons with a sparse grid of synaptic links is well representable by the stochastic dynamics of a generic neuron subject to an effective shot noise. The rate of delta-pulses of the noise is determined self-consistently from the probability density of the neuron states. Importantly, the most sophisticated (but robust) collective regimes of the network do not allow for the diffusion approximation, which is routinely adopted for a shot noise in mathematical neuroscience. These regimes can be expected to be biologically relevant. For the kinetics equations of the complete mean field theory of a homogeneous inhibitory network of quadratic integrate-and-fire neurons, we introduce circular cumulants of the genuine phase variable and derive a rigorous two cumulant reduction for both time-independent conditions and modulation of the excitatory current. The low dimensional model is examined with numerical simulations and found to be accurate for time-independent states and dynamic response to a periodic modulation deep into the parameter domain where the diffusion approximation is not applicable. The accuracy of a low dimensional model indicates and explains a low embedding dimensionality of the macroscopic collective dynamics of the network. The reduced model can be instrumental for theoretical studies of inhibitory-excitatory balanced neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.06253v2</guid>
      <category>q-bio.NC</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maria V. Ageeva, Denis S. Goldobin</dc:creator>
    </item>
    <item>
      <title>Effect of an auditory static distractor on the perception of an auditory moving target</title>
      <link>https://arxiv.org/abs/2510.25119</link>
      <description>arXiv:2510.25119v2 Announce Type: replace 
Abstract: It is known that listeners lose the ability to discriminate the direction of motion of a revolving sound (clockwise vs. counterclockwise) beyond a critical velocity ("the upper limit"), primarily due to degraded front-back discrimination. Little is known about how this ability is affected by simultaneously present distractor sounds, despite the real-life importance of tracking moving sounds in the presence of distractors. We hypothesized that the presence of a static distractor sound would impair the perception of moving target sounds and reduce the upper limit, and show that this is indeed the case. A distractor on the right was as effective as a distractor at the front in reducing the upper limit despite the importance of resolving front-back confusions. By manipulating the spectral content of both the target and distractor, we found that the upper limit was reduced if and only if the distractor spectrally overlaps with the target in the frequency range relevant for front/back discrimination; energetic masking thus explains the upper limit reduction by the distractor. We did not find any evidence for informational masking by the distractor. Our findings form the first steps towards a better understanding of the tracking of multiple sounds in the presence of distractors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25119v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Noa Kemp, Cynthia Tarlao, Catherine Guastavino, B. Suresh Krishna</dc:creator>
    </item>
  </channel>
</rss>
