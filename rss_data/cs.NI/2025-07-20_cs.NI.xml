<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 21 Jul 2025 04:00:09 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Addressing the ML Domain Adaptation Problem for Networking: Realistic and Controllable Training Data Generation with NetReplica</title>
      <link>https://arxiv.org/abs/2507.13476</link>
      <description>arXiv:2507.13476v1 Announce Type: new 
Abstract: Machine learning models in networking suffer from the domain adaptation problem; models trained in one domain often fail when deployed in different production environments. This paper presents the design and implementation of NetReplica, a system that addresses this challenge by generating training datasets with two critical properties: realism in protocol dynamics and controllability of network conditions. NetReplica models networks as collections of bottleneck links with specific attributes, achieves realism by leveraging production network traces, and enables controllability through fine grained control knobs for each link attribute. Our evaluation using Puffer demonstrates that NetReplica not only matches existing data characteristics but generates realistic samples that are underrepresented in or absent from Puffer data. Models trained on NetReplica augmented datasets show substantially improved generalizability, reducing transmission time prediction error by up to 47% for challenging network conditions compared to models trained solely on Puffer data. This work represents a significant step toward solving the domain adaptation problem that has limited the effectiveness of ML based networking systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13476v1</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jaber Daneshamooz, Jessica Nguyen, William Chen, Sanjay Chandrasekaran, Satyandra Guthula, Ankit Gupta, Arpit Gupta, Walter Willinger</dc:creator>
    </item>
    <item>
      <title>CARTS: Cooperative and Adaptive Resource Triggering and Stitching for 5G ISAC</title>
      <link>https://arxiv.org/abs/2507.13676</link>
      <description>arXiv:2507.13676v1 Announce Type: new 
Abstract: This paper presents CARTS, an adaptive 5G uplink sensing scheme designed to provide Integrated Sensing and Communication (ISAC) services. The performance of both communication and sensing fundamentally depends on the availability of accurate and up-to-date channel state information (CSI). In modern 5G networks, uplink CSI is derived from two reference signals: the demodulation reference signal (DMRS) and the sounding reference signal (SRS). However, current base station implementations treat these CSI measurements as separate information streams. The key innovation of CARTS is to fuse these two CSI streams, thereby increasing the frequency of CSI updates and extending sensing opportunities to more users. CARTS addresses two key challenges: (i) a novel channel stitching and compensation method that integrates asynchronous CSI estimates from DMRS and SRS, despite their different time and frequency allocations, and (ii) a real-time SRS triggering algorithm that complements the inherently uncontrollable DMRS schedule, ensuring sufficient and non-redundant sensing opportunities for all users. Our trace-driven evaluation shows that CARTS significantly improves scalability, achieving a channel estimation error (NMSE) of 0.167 and UE tracking accuracy of 85 cm while supporting twice the number of users as a periodic SRS-only baseline with similar performance. By opportunistically combining DMRS and SRS, CARTS therefore provides a practical, standard-compliant solution to improve CSI availability for ISAC without requiring additional radio resources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13676v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cheng Jiang, Yihe Yan, Yanxiang Wang, Jiawei Hu, Chun Tung Chou, Wen Hu</dc:creator>
    </item>
    <item>
      <title>ATRO: A Fast Solver-Free Algorithm for Topology and Routing Optimization of Reconfigurable Datacenter Networks</title>
      <link>https://arxiv.org/abs/2507.13717</link>
      <description>arXiv:2507.13717v1 Announce Type: new 
Abstract: The growing scale and complexity of reconfigurable data center networks (DCNs) demand more scalable and efficient algorithms for computing logical topologies and routing. Reconfigurable DCNs typically operate in two modes: one-hop configurations that require frequent topology optimization (TO), and multi-hop scenarios that involve joint topology and routing optimization (TRO). In both cases, the combinatorial nature of topology decisions makes it difficult for existing methods to balance solution quality and runtime efficiency. To address this, we introduce Alternating Topology and Routing Optimization (ATRO), a solver-free framework that alternates between TO and routing optimization (RO). This decomposition exploits two key insights: first, each alternating update step monotonically reduces maximum link utilization (MLU), ensuring consistent performance improvement across iterations; second, the TO subproblem, equivalent to one-hop optimization, exhibits a monotonic structure that enables optimal solutions via an efficient Accelerated Binary Search Method (ABSM). To preserve the solver-free design, RO is solved using existing Traffic Engineering accelerators. ATRO attains the global optimum in one-hop scenarios and significantly outperforms baselines in multi-hop settings in terms of both runtime and solution quality. Evaluations confirm its scalability and robustness across diverse DCNs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13717v1</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yingming Mao, Qiaozhu Zhai, Zhen Yao, Xia Zhu, Ximeng Liu, Xinchi Han</dc:creator>
    </item>
    <item>
      <title>On the Trade-Off Between Sum-Rate and Energy Efficiency through the Convergence of HAPS and Active RIS Technologies</title>
      <link>https://arxiv.org/abs/2507.13889</link>
      <description>arXiv:2507.13889v1 Announce Type: new 
Abstract: This paper investigates the integration of active reconfigurable intelligent surfaces (RIS) relay with high-altitude platform stations (HAPS) to enhance non-terrestrial network (NTN) performance in next-generation wireless systems. While prior studies focused on passive RIS architectures, the severe path loss and double fading in long-distance HAPS links make active RIS a more suitable alternative due to its inherent signal amplification capabilities. We formulate a sum-rate maximization problem to jointly optimize power allocation and RIS element assignment for ground user equipments (UEs) supported by a HAPS-based active RIS-assisted communication system. To reduce power consumption and hardware complexity, several sub-connected active RIS architectures are also explored. Simulation results reveal that active RIS configurations significantly outperform passive RIS in terms of quality of service (QoS). Moreover, although fully-connected architectures achieve the highest throughput, sub-connected schemes demonstrate superior energy efficiency under practical power constraints. These findings highlight the potential of active RIS-enabled HAPS systems to meet the growing demands of beyond-cellular coverage and green networking.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13889v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Bilal Karaman, Ilhan Basturk, Ferdi Kara, Metin Ozturk, Sezai Taskin, Halil Yanikomeroglu</dc:creator>
    </item>
    <item>
      <title>Preprint: Did I Just Browse A Website Written by LLMs?</title>
      <link>https://arxiv.org/abs/2507.13933</link>
      <description>arXiv:2507.13933v1 Announce Type: new 
Abstract: Increasingly, web content is automatically generated by large language models (LLMs) with little human input. We call this "LLM-dominant" content. Since LLMs plagiarize and hallucinate, LLM-dominant content can be unreliable and unethical. Yet, websites rarely disclose such content, and human readers struggle to distinguish it. Thus, we must develop reliable detectors for LLM-dominant content. However, state-of-the-art LLM detectors are insufficient, because they perform well mainly on clean, prose-like text, while web content has complex markup and diverse genres.
  We propose a highly reliable, scalable pipeline that classifies entire websites. Instead of naively classifying text extracted from each page, we classify each site based on an LLM text detector's outputs of multiple prose-like pages. We train and evaluate our detector by collecting 2 distinct ground truth datasets totaling 120 sites, and obtain 100% accuracies testing across them. In the wild, we detect a sizable portion of sites as LLM-dominant among 10k sites in search engine results and 10k in Common Crawl archives. We find LLM-dominant sites are growing in prevalence and rank highly in search results, raising questions about their impact on end users and the overall Web ecosystem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13933v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.IR</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sichang "Steven" He, Ramesh Govindan, Harsha V. Madhyastha</dc:creator>
    </item>
    <item>
      <title>PHASE: Passive Human Activity Simulation Evaluation</title>
      <link>https://arxiv.org/abs/2507.13505</link>
      <description>arXiv:2507.13505v1 Announce Type: cross 
Abstract: Cybersecurity simulation environments, such as cyber ranges, honeypots, and sandboxes, require realistic human behavior to be effective, yet no quantitative method exists to assess the behavioral fidelity of synthetic user personas. This paper presents PHASE (Passive Human Activity Simulation Evaluation), a machine learning framework that analyzes Zeek connection logs and distinguishes human from non-human activity with over 90\% accuracy. PHASE operates entirely passively, relying on standard network monitoring without any user-side instrumentation or visible signs of surveillance. All network activity used for machine learning is collected via a Zeek network appliance to avoid introducing unnecessary network traffic or artifacts that could disrupt the fidelity of the simulation environment. The paper also proposes a novel labeling approach that utilizes local DNS records to classify network traffic, thereby enabling machine learning analysis. Furthermore, we apply SHAP (SHapley Additive exPlanations) analysis to uncover temporal and behavioral signatures indicative of genuine human users. In a case study, we evaluate a synthetic user persona and identify distinct non-human patterns that undermine behavioral realism. Based on these insights, we develop a revised behavioral configuration that significantly improves the human-likeness of synthetic activity yielding a more realistic and effective synthetic user persona.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13505v1</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Steven Lamp, Jason D. Hiser, Anh Nguyen-Tuong, Jack W. Davidson</dc:creator>
    </item>
    <item>
      <title>FedSkipTwin: Digital-Twin-Guided Client Skipping for Communication-Efficient Federated Learning</title>
      <link>https://arxiv.org/abs/2507.13624</link>
      <description>arXiv:2507.13624v1 Announce Type: cross 
Abstract: Communication overhead remains a primary bottleneck in federated learning (FL), particularly for applications involving mobile and IoT devices with constrained bandwidth. This work introduces FedSkipTwin, a novel client-skipping algorithm driven by lightweight, server-side digital twins. Each twin, implemented as a simple LSTM, observes a client's historical sequence of gradient norms to forecast both the magnitude and the epistemic uncertainty of its next update. The server leverages these predictions, requesting communication only when either value exceeds a predefined threshold; otherwise, it instructs the client to skip the round, thereby saving bandwidth. Experiments are conducted on the UCI-HAR and MNIST datasets with 10 clients under a non-IID data distribution. The results demonstrate that FedSkipTwin reduces total communication by 12-15.5% across 20 rounds while simultaneously improving final model accuracy by up to 0.5 percentage points compared to the standard FedAvg algorithm. These findings establish that prediction-guided skipping is a practical and effective strategy for resource-aware FL in bandwidth-constrained edge environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13624v1</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Commey, Kamel Abbad, Garth V. Crosby, Lyes Khoukhi</dc:creator>
    </item>
    <item>
      <title>Quantum Blockchain Survey: Foundations, Trends, and Gaps</title>
      <link>https://arxiv.org/abs/2507.13720</link>
      <description>arXiv:2507.13720v1 Announce Type: cross 
Abstract: Quantum computing poses fundamental risks to classical blockchain systems by undermining widely used cryptographic primitives. In response, two major research directions have emerged: post-quantum blockchains, which integrate quantum-resistant algorithms, and quantum blockchains, which leverage quantum properties such as entanglement and quantum key distribution. This survey reviews key developments in both areas, analyzing their cryptographic foundations, architectural designs, and implementation challenges. This work provides a comparative overview of technical proposals, highlight trade-offs in security, scalability, and deployment, and identify open research problems across hardware, consensus, and network design. The goal is to offer a structured and comprehensive reference for advancing secure blockchain systems in the quantum era.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13720v1</guid>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <category>cs.NI</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Saurav Ghosh</dc:creator>
    </item>
    <item>
      <title>The Proportional Fair Scheduler in Wavelength-Multiplexed Quantum Networks</title>
      <link>https://arxiv.org/abs/2507.13999</link>
      <description>arXiv:2507.13999v1 Announce Type: cross 
Abstract: We address the problem of optimal pumping strategies in quantum networks. These networks enable secure communication by distributing entangled photon pairs to user (or node) pairs. Quantum Key Distribution (QKD) protocols, like BBM92, generate secret keys from entangled photons. While secure communication and error correction are essential for any quantum communication channel, resource contention, optimization, and fairness issues are critical for networks. In this article, we analyze the performance of quantum networks, proposing simple distributed algorithms for QKD networks generating secret keys.
  There are significant advantages of pumping entangled photons in QKD networks, but challenges arise in practical implementations. The underlying channels are inherently time-varying, and thus data rates fluctuate between nodes. Moreover, multiple edges (node pairs) can be pumped simultaneously, albeit at the cost of a reduced secret key rate (SKR). These temporal and spatial constraints yield a complex decision-making problem whose solutions may favor a small set of user pairs to the detriment of overall, long-run network performance.
  We design adaptive pumping strategies that address these challenges in QKD networks. In particular, we find that a proportional fairness pumping strategy (PF-PS) stands out by dynamically prioritizing users with lower average secret key rates and optimally balancing fairness with throughput. The proposed algorithm is a natural extension to quantum networks of the Proportional Fair Scheduler deployed in 4G LTE and 5G mobile networks. Both theoretical analysis and numerical simulations confirm that PF-PS is optimal for entangled state distribution, and thus, when adapted appropriately, proportional fair pumping is a strong candidate for efficient resource allocation in quantum networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13999v1</guid>
      <category>quant-ph</category>
      <category>cs.NI</category>
      <category>cs.PF</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:journal_reference>IEEE International Conference on Quantum Computing &amp; Engineering (QCE) 2025</arxiv:journal_reference>
      <dc:creator>Sanidhay Bhambay, Siddarth Koduru Joshi, Thirupathaiah Vasantam, Neil Walton</dc:creator>
    </item>
    <item>
      <title>Towards Practical Operation of Deep Reinforcement Learning Agents in Real-World Network Management at Open RAN Edges</title>
      <link>https://arxiv.org/abs/2410.23086</link>
      <description>arXiv:2410.23086v2 Announce Type: replace 
Abstract: Deep Reinforcement Learning (DRL) has emerged as a powerful solution for meeting the growing demands for connectivity, reliability, low latency and operational efficiency in advanced networks. However, most research has focused on theoretical analysis and simulations, with limited investigation into real-world deployment. To bridge the gap and support practical DRL deployment for network management, we first present an orchestration framework that integrates ETSI Multi-access Edge Computing (MEC) with Open RAN, enabling seamless adoption of DRL-based strategies across different time scales while enhancing agent lifecycle management. We then identify three critical challenges hindering DRL's real-world deployment, including (1) asynchronous requests from unpredictable or bursty traffic, (2) adaptability and generalization across heterogeneous topologies and evolving service demands, and (3) prolonged convergence and service interruptions due to exploration in live operational environments. To address these challenges, we propose a three-fold solution strategy: (a) advanced time-series integration for handling asynchronized traffic, (b) flexible architecture design such as multi-agent DRL and incremental learning to support heterogeneous scenarios, and (c) simulation-driven deployment with transfer learning to reduce convergence time and service disruptions. Lastly, the feasibility of the MEC-O-RAN architecture is validated on an urban-wide testing infrastructure, and two real-world use cases are presented, showcasing the three identified challenges and demonstrating the effectiveness of the proposed solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23086v2</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/MCOM.001.2500207</arxiv:DOI>
      <dc:creator>Haiyuan Li, Hari Madhukumar, Peizheng Li, Yuelin Liu, Yiran Teng, Yulei Wu, Ning Wang, Shuangyi Yan, Dimitra Simeonidou</dc:creator>
    </item>
    <item>
      <title>ZKP-FedEval: Verifiable and Privacy-Preserving Federated Evaluation using Zero-Knowledge Proofs</title>
      <link>https://arxiv.org/abs/2507.11649</link>
      <description>arXiv:2507.11649v2 Announce Type: replace-cross 
Abstract: Federated Learning (FL) enables collaborative model training on decentralized data without exposing raw data. However, the evaluation phase in FL may leak sensitive information through shared performance metrics. In this paper, we propose a novel protocol that incorporates Zero-Knowledge Proofs (ZKPs) to enable privacy-preserving and verifiable evaluation for FL. Instead of revealing raw loss values, clients generate a succinct proof asserting that their local loss is below a predefined threshold. Our approach is implemented without reliance on external APIs, using self-contained modules for federated learning simulation, ZKP circuit design, and experimental evaluation on both the MNIST and Human Activity Recognition (HAR) datasets. We focus on a threshold-based proof for a simple Convolutional Neural Network (CNN) model (for MNIST) and a multi-layer perceptron (MLP) model (for HAR), and evaluate the approach in terms of computational overhead, communication cost, and verifiability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.11649v2</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Commey, Benjamin Appiah, Griffith S. Klogo, Garth V. Crosby</dc:creator>
    </item>
  </channel>
</rss>
