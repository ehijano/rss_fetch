<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 17 Oct 2024 04:00:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Quantum Computing for Multi Period Asset Allocation</title>
      <link>https://arxiv.org/abs/2410.11997</link>
      <description>arXiv:2410.11997v1 Announce Type: new 
Abstract: Portfolio construction has been a long-standing topic of research in finance. The computational complexity and the time taken both increase rapidly with the number of investments in the portfolio. It becomes difficult, even impossible for classic computers to solve. Quantum computing is a new way of computing which takes advantage of quantum superposition and entanglement. It changes how such problems are approached and is not constrained by some of the classic computational complexity. Studies have shown that quantum computing can offer significant advantages over classical computing in many fields. The application of quantum computing has been constrained by the unavailability of actual quantum computers. In the past decade, there has been the rapid development of the large-scale quantum computer. However, software development for quantum computing is slow in many fields. In our study, we apply quantum computing to a multi-asset portfolio simulation. The simulation is based on historic data, covariance, and expected returns, all calculated using quantum computing. Although technically a solvable problem for classical computing, we believe the software development is important to the future application of quantum computing in finance. We conducted this study through simulation of a quantum computer and the use of Rensselaer Polytechnic Institute's IBM quantum computer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11997v1</guid>
      <category>cs.CE</category>
      <category>q-fin.CP</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Queenie Sun, Nicholas Grablevsky, Huaizhang Deng, Pooya Azadi</dc:creator>
    </item>
    <item>
      <title>Embedded Model Bias Quantification with Measurement Noise for Bayesian Model Calibration</title>
      <link>https://arxiv.org/abs/2410.12037</link>
      <description>arXiv:2410.12037v1 Announce Type: new 
Abstract: The use of computer simulations to model physical systems has gained significant traction in recent years. A key factor in ensuring the accuracy of these models is the proper calibration of model parameters based on real-world observations or experimental data. Inevitably, uncertainties arise, and Bayesian methods provide a robust framework for quantifying and propagating these uncertainties to model predictions. However, predictions can become inaccurate if model errors are neglected. A promising approach to address this issue involves embedding a bias term in the inference parameters, allowing the quantified bias to influence non-observed Quantities of Interest (QoIs). This paper introduces a more interpretable framework for bias embedding compared to existing methods. Current likelihood formulations that incorporate embedded bias often fail when measurement noise is present. To overcome these limitations, we adapt the existing likelihood models to properly account for noise and propose two new formulations designed to address the shortcomings of the previous approaches. Moreover, we evaluate the performance of this bias-embedding approach in the presence of discrepancies between measurements and model predictions, including noise and outliers. Particular attention is given to how the uncertainty associated with the bias term propagates to the QoIs, enabling a more comprehensive statistical analysis of prediction reliability. Finally, the proposed embedded bias model is applied to estimate the uncertainty in the predicted heat flux from a transient thermal simulation, using temperature observations to illustrate its effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12037v1</guid>
      <category>cs.CE</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Andr\'es Arcones, Martin Weiser, Phaedon-Stelios Koutsourelakis, J\"org F. Unger</dc:creator>
    </item>
    <item>
      <title>Multimodal Fusion with Relational Learning for Molecular Property Prediction</title>
      <link>https://arxiv.org/abs/2410.12128</link>
      <description>arXiv:2410.12128v1 Announce Type: new 
Abstract: Graph based molecular representation learning is essential for accurately predicting molecular properties in drug discovery and materials science; however, it faces significant challenges due to the intricate relationships among molecules and the limited chemical knowledge utilized during training. While contrastive learning is often employed to handle molecular relationships, its reliance on binary metrics is insufficient for capturing the complexity of these interactions. Multimodal fusion has gained attention for property reasoning, but previous work has explored only a limited range of modalities, and the optimal stages for fusing different modalities in molecular property tasks remain underexplored. In this paper, we introduce MMFRL (Multimodal Fusion with Relational Learning for Molecular Property Prediction), a novel framework designed to overcome these limitations. Our method enhances embedding initialization through multimodal pretraining using relational learning. We also conduct a systematic investigation into the impact of modality fusion at different stages such as early, intermediate, and late, highlighting their advantages and shortcomings. Extensive experiments on MoleculeNet benchmarks demonstrate that MMFRL significantly outperforms existing methods. Furthermore, MMFRL enables task-specific optimizations. Additionally, the explainability of MMFRL provides valuable chemical insights, emphasizing its potential to enhance real-world drug discovery applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12128v1</guid>
      <category>cs.CE</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhengyang Zhou, Hao Xu, Pengyu Hong</dc:creator>
    </item>
    <item>
      <title>SELF-BART : A Transformer-based Molecular Representation Model using SELFIES</title>
      <link>https://arxiv.org/abs/2410.12348</link>
      <description>arXiv:2410.12348v1 Announce Type: new 
Abstract: Large-scale molecular representation methods have revolutionized applications in material science, such as drug discovery, chemical modeling, and material design. With the rise of transformers, models now learn representations directly from molecular structures. In this study, we develop an encoder-decoder model based on BART that is capable of leaning molecular representations and generate new molecules. Trained on SELFIES, a robust molecular string representation, our model outperforms existing baselines in downstream tasks, demonstrating its potential in efficient and effective molecular data analysis and manipulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12348v1</guid>
      <category>cs.CE</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Indra Priyadarsini, Seiji Takeda, Lisa Hamada, Emilio Vital Brazil, Eduardo Soares, Hajime Shinohara</dc:creator>
    </item>
    <item>
      <title>Private Order Flows and Builder Bidding Dynamics: The Road to Monopoly in Ethereum's Block Building Market</title>
      <link>https://arxiv.org/abs/2410.12352</link>
      <description>arXiv:2410.12352v1 Announce Type: new 
Abstract: Ethereum, as a representative of Web3, adopts a novel framework called Proposer Builder Separation (PBS) to prevent the centralization of block profits in the hands of institutional Ethereum stakers. Introducing builders to generate blocks based on public transactions, PBS aims to ensure that block profits are distributed among all stakers. Through the auction among builders, only one will win the block in each slot. Ideally, the equilibrium strategy of builders under public information would lead them to bid all block profits. However, builders are now capable of extracting profits from private order flows. In this paper, we explore the effect of PBS with private order flows. Specifically, we propose the asymmetry auction model of MEV-Boost auction. Moreover, we conduct empirical study on Ethereum blocks from January 2023 to May 2024. Our analysis indicates that private order flows contribute to 54.59% of the block value, indicating that different builders will build blocks with different valuations. Interestingly, we find that builders with more private order flows (i.e., higher block valuations) are more likely to win the block, while retain larger proportion of profits. In return, such builders will further attract more private order flows, resulting in a monopolistic market gradually. Our findings reveal that PBS in current stage is unable to balance the profit distribution, which just transits the centralization of block profits from institutional stakers to the monopolistic builder.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12352v1</guid>
      <category>cs.CE</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shuzheng Wang, Yue Huang, Wenqin Zhang, Yuming Huang, Xuechao Wang, Jing Tang</dc:creator>
    </item>
    <item>
      <title>HELM: Hierarchical Encoding for mRNA Language Modeling</title>
      <link>https://arxiv.org/abs/2410.12459</link>
      <description>arXiv:2410.12459v1 Announce Type: cross 
Abstract: Messenger RNA (mRNA) plays a crucial role in protein synthesis, with its codon structure directly impacting biological properties. While Language Models (LMs) have shown promise in analyzing biological sequences, existing approaches fail to account for the hierarchical nature of mRNA's codon structure. We introduce Hierarchical Encoding for mRNA Language Modeling (HELM), a novel pre-training strategy that incorporates codon-level hierarchical structure into language model training. HELM modulates the loss function based on codon synonymity, aligning the model's learning process with the biological reality of mRNA sequences. We evaluate HELM on diverse mRNA datasets and tasks, demonstrating that HELM outperforms standard language model pre-training as well as existing foundation model baselines on six diverse downstream property prediction tasks and an antibody region annotation tasks on average by around 8\%. Additionally, HELM enhances the generative capabilities of language model, producing diverse mRNA sequences that better align with the underlying true data distribution compared to non-hierarchical baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12459v1</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mehdi Yazdani-Jahromi, Mangal Prakash, Tommaso Mansi, Artem Moskalev, Rui Liao</dc:creator>
    </item>
    <item>
      <title>Graph-accelerated non-intrusive polynomial chaos expansion using partially tensor-structured quadrature rules for uncertainty quantification</title>
      <link>https://arxiv.org/abs/2403.15614</link>
      <description>arXiv:2403.15614v2 Announce Type: replace 
Abstract: Recently, the graph-accelerated non-intrusive polynomial chaos (NIPC) method has been proposed for solving uncertainty quantification (UQ) problems. This method leverages the full-grid integration-based NIPC method to address UQ problems while employing the computational graph transformation approach, AMTC, to accelerate the tensor-grid evaluations. This method exhibits remarkable efficacy on a broad range of low-dimensional (three dimensions or less) UQ problems featuring multidisciplinary models. However, it often does not scale well with problem dimensions due to the exponential increase in the number of quadrature points when using the full-grid quadrature rule. To expand the applicability of this method to a broader range of UQ problems, this paper introduces a new framework for generating a tailored, partially tensor-structured quadrature rule to use with the graph-accelerated NIPC method. This quadrature rule, generated through the designed quadrature approach, possesses a tensor structure that is tailored for the computational model. The selection of the tensor structure is guided by an analysis of the computational graph, ensuring that the quadrature rule effectively capitalizes on the sparsity within the computational graph when paired with the AMTC method. This method has been tested on one 4D and one 6D UQ problem, both originating from aircraft design scenarios and featuring multidisciplinary models. Numerical results show that, when using with graph-accelerated NIPC method, our approach generates a partially tensor-structured quadrature rule that outperforms the full-grid Gauss quadrature and the designed quadrature methods (more than 40% reduction in computational costs) in both of the test problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15614v2</guid>
      <category>cs.CE</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.ast.2024.109607</arxiv:DOI>
      <dc:creator>Bingran Wang, Nicholas C. Orndorff, John T. Hwang</dc:creator>
    </item>
    <item>
      <title>A gradient-enhanced univariate dimension reduction method for uncertainty propagation</title>
      <link>https://arxiv.org/abs/2403.15622</link>
      <description>arXiv:2403.15622v2 Announce Type: replace 
Abstract: The univariate dimension reduction (UDR) method stands as a way to estimate the statistical moments of the output that is effective in a large class of uncertainty quantification (UQ) problems. UDR's fundamental strategy is to approximate the original function using univariate functions so that the UQ cost only scales linearly with the dimension of the problem. Nonetheless, UDR's effectiveness can diminish when uncertain inputs have high variance, particularly when assessing the output's second and higher-order statistical moments. This paper proposes a new method, gradient-enhanced univariate dimension reduction (GUDR), that enhances the accuracy of UDR by incorporating univariate gradient function terms into the UDR approximation function. Theoretical results indicate that the GUDR approximation is expected to be one order more accurate than UDR in approximating the original function, and it is expected to generate more accurate results in computing the output's second and higher-order statistical moments. Our proposed method uses a computational graph transformation strategy to efficiently evaluate the GUDR approximation function on tensor-grid quadrature inputs, and use the tensor-grid input-output data to compute the statistical moments of the output. With an efficient automatic differentiation method to compute the gradients, our method preserves UDR's linear scaling of computation time with problem dimension. Numerical results show that the GUDR is more accurate than UDR in estimating the standard deviation of the output and has a performance comparable to the method of moments using a third-order Taylor series expansion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15622v2</guid>
      <category>cs.CE</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.ast.2024.109602</arxiv:DOI>
      <arxiv:journal_reference>Aerospace Science and Technology vol. 155, 2024, 109602</arxiv:journal_reference>
      <dc:creator>Bingran Wang, Nicholas C. Orndorff, Mark Sperry, John T. Hwang</dc:creator>
    </item>
    <item>
      <title>Towards Robust Blockchain Price Oracle: A Study on Human-Centric Node Selection Strategy and Incentive Mechanism</title>
      <link>https://arxiv.org/abs/2309.04689</link>
      <description>arXiv:2309.04689v2 Announce Type: replace-cross 
Abstract: As a trusted middleware connecting the blockchain and the real world, the blockchain oracle can obtain trusted real-time price information for financial applications such as payment and settlement, and asset valuation on the blockchain. However, the current oracle schemes face the dilemma of security and service quality in the process of node selection, and the implicit interest relationship in financial applications leads to a significant conflict of interest between the task publisher and the executor, which reduces the participation enthusiasm of both parties and system security. Therefore, this paper proposes an anonymous node selection scheme that anonymously selects nodes with high reputations to participate in tasks to ensure the security and service quality of nodes. Then, this paper also details the interest requirements and behavioral motives of all parties in the payment settlement and asset valuation scenarios. Under the hypothesis of rational man, an incentive mechanism based on the Stackelberg game is proposed. It can achieve equilibrium under the pursuit of the revenue of task publishers and executors, thereby ensuring the revenue of all types of users and improving the enthusiasm for participation. Finally, we verify the security of the proposed scheme through security analysis. The experimental results show that the proposed scheme can reduce the variance of obtaining price data by about 55\% while ensuring security, and meeting the revenue of all parties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.04689v2</guid>
      <category>cs.CR</category>
      <category>cs.CE</category>
      <category>cs.DC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Youquan Xian, Xueying Zeng, Hao Wu, Danping Yang, Peng Wang, Peng Liu</dc:creator>
    </item>
    <item>
      <title>Mechanistic interpretability of large language models with applications to the financial services industry</title>
      <link>https://arxiv.org/abs/2407.11215</link>
      <description>arXiv:2407.11215v2 Announce Type: replace-cross 
Abstract: Large Language Models such as GPTs (Generative Pre-trained Transformers) exhibit remarkable capabilities across a broad spectrum of applications. Nevertheless, due to their intrinsic complexity, these models present substantial challenges in interpreting their internal decision-making processes. This lack of transparency poses critical challenges when it comes to their adaptation by financial institutions, where concerns and accountability regarding bias, fairness, and reliability are of paramount importance. Mechanistic interpretability aims at reverse engineering complex AI models such as transformers. In this paper, we are pioneering the use of mechanistic interpretability to shed some light on the inner workings of large language models for use in financial services applications. We offer several examples of how algorithmic tasks can be designed for compliance monitoring purposes. In particular, we investigate GPT-2 Small's attention pattern when prompted to identify potential violation of Fair Lending laws. Using direct logit attribution, we study the contributions of each layer and its corresponding attention heads to the logit difference in the residual stream. Finally, we design clean and corrupted prompts and use activation patching as a causal intervention method to localize our task completion components further. We observe that the (positive) heads $10.2$ (head $2$, layer $10$), $10.7$, and $11.3$, as well as the (negative) heads $9.6$ and $10.6$ play a significant role in the task completion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11215v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.CL</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3677052.3698612</arxiv:DOI>
      <arxiv:journal_reference>5th ACM International Conference on AI in Finance (ICAIF 2024)</arxiv:journal_reference>
      <dc:creator>Ashkan Golgoon, Khashayar Filom, Arjun Ravi Kannan</dc:creator>
    </item>
  </channel>
</rss>
