<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.TH</link>
    <description>stat.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 26 Jun 2025 04:05:57 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 26 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>On unbiased estimators for functions of the rate parameter of the exponential distribution</title>
      <link>https://arxiv.org/abs/2506.20005</link>
      <description>arXiv:2506.20005v1 Announce Type: new 
Abstract: In this paper, we explicitly derive unbiased estimators for various functions of the rate parameter of the exponential distribution, including powers of the rate parameter, the $q$th quantile, the $p$th moment, the survival function, the maximum, minimum, probability density function, mean past lifetime, moment generating function, and others. It is also noteworthy that this work corrects a general formula originally proposed by Tate, R. F. (Ann. Math. Statist., 30(2): 341-366, 1959) for constructing unbiased estimators of functions of the exponential distribution's rate parameter in the absence of a location parameter. Additionally, we establish a result demonstrating the asymptotic normality of the proposed unbiased estimators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.20005v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Thu, 26 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roberto Vila, Eduardo Yoshio Nakano</dc:creator>
    </item>
    <item>
      <title>Modifications of the BIC for order selection in finite mixture models</title>
      <link>https://arxiv.org/abs/2506.20124</link>
      <description>arXiv:2506.20124v1 Announce Type: new 
Abstract: Finite mixture models are ubiquitous tools in modern statistical modeling, and a frequently encountered problem that arises in their implementation is the choice of model order. In Kerebin (2000, Sankhya: The Indian Journal of Statistics, Series A, 62, pp. 49-66), the frequently used Bayesian information criterion (BIC) was proved to provide consistent order estimation in the mixture model setting. However, the result requires particularly strong model regularity, including the existence of higher moments and higher derivatives of the component density function. We introduce the $\nu$-BIC and $\epsilon$-BIC, which modifies the BIC by weighting the penalty by a negligibly small logarithmic factors that are immaterial in practice. We prove that the minor modification enables consistency guarantees under weaker conditions, particularly without differentiability and with minimal moment assumptions. We demonstrate how our theory apply to obtaining order selection consistency for Gaussian mixtures, non-differentiable Laplace mixtures, and mixtures of regression models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.20124v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 26 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hien Duy Nguyen, TrungTin Nguyen</dc:creator>
    </item>
    <item>
      <title>Affine invariant interacting Langevin dynamics in Markov chain importance sampling for rare event estimation</title>
      <link>https://arxiv.org/abs/2506.20185</link>
      <description>arXiv:2506.20185v1 Announce Type: new 
Abstract: This work considers the framework of Markov chain importance sampling~(MCIS), in which one employs a Markov chain Monte Carlo~(MCMC) scheme to sample particles approaching the optimal distribution for importance sampling, prior to estimating the quantity of interest through importance sampling. In rare event estimation, the optimal distribution admits a non-differentiable log-density, thus gradient-based MCMC can only target a smooth approximation of the optimal density. We propose a new gradient-based MCIS scheme for rare event estimation, called affine invariant interacting Langevin dynamics for importance sampling~(ALDI-IS), in which the affine invariant interacting Langevin dynamics~(ALDI) is used to sample particles according to the smoothed zero-variance density. We establish a non-asymptotic error bound when importance sampling is used in conjunction with samples independently and identically distributed according to the smoothed optiaml density to estimate a rare event probability, and an error bound on the sampling bias when a simplified version of ALDI, the unadjusted Langevin algorithm, is used to sample from the smoothed optimal density. We show that the smoothing parameter of the optimal density has a strong influence and exhibits a trade-off between a low importance sampling error and the ease of sampling using ALDI. We perform a numerical study of ALDI-IS and illustrate this trade-off phenomenon on standard rare event estimation test cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.20185v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 26 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jason Beh, J\'er\^ome Morio, Florian Simatos, Simon Weissmann</dc:creator>
    </item>
    <item>
      <title>A model-based approach to density estimation in sup-norm</title>
      <link>https://arxiv.org/abs/2506.20239</link>
      <description>arXiv:2506.20239v1 Announce Type: new 
Abstract: We define a general method for finding a quasi-best approximant in sup-norm to a target density belonging to a given model, based on independent samples drawn from distributions which average to the target (which does not necessarily belong to the model). We also provide a general method for selecting among a countable family of such models. These estimators satisfy oracle inequalities in the general setting. The quality of the bounds depends on the volume of sets on which $|p-q|$ is close to its maximum, where $p,q$ belong to the model (or possibly to two different models, in the case of model selection). This leads to optimal results in a number of settings, including piecewise polynomials on a given partition and anisotropic smoothness classes. Particularly interesting is the case of the single index model with fixed smoothness $\beta$, where we recover the one-dimensional rate: this was an open problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.20239v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 26 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guillaume Maillard (uni.lu, ENSAI)</dc:creator>
    </item>
    <item>
      <title>Robust estimation of a Markov chain transition matrix from multiple sample paths</title>
      <link>https://arxiv.org/abs/2506.20325</link>
      <description>arXiv:2506.20325v1 Announce Type: new 
Abstract: Markov chains are fundamental models for stochastic dynamics, with applications in a wide range of areas such as population dynamics, queueing systems, reinforcement learning, and Monte Carlo methods. Estimating the transition matrix and stationary distribution from observed sample paths is a core statistical challenge, particularly when multiple independent trajectories are available. While classical theory typically assumes identical chains with known stationary distributions, real-world data often arise from heterogeneous chains whose transition kernels and stationary measures might differ from a common target. We analyse empirical estimators for such parallel Markov processes and establish sharp concentration inequalities that generalise Bernstein-type bounds from standard time averages to ensemble-time averages. Our results provide nonasymptotic error bounds and consistency guarantees in high-dimensional regimes, accommodating sparse or weakly mixing chains, model mismatch, nonstationary initialisations, and partially corrupted data. These findings offer rigorous foundations for statistical inference in heterogeneous Markov chain settings common in modern computational applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.20325v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Thu, 26 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lasse Leskel\"a, Maximilien Dreveton</dc:creator>
    </item>
    <item>
      <title>On Exponential Random Graph Models with Dyadic Independence</title>
      <link>https://arxiv.org/abs/2506.20458</link>
      <description>arXiv:2506.20458v1 Announce Type: new 
Abstract: We show that the only exponential random graph model with n nodal parameters, dyads being independent, and the natural assumption of permutation-equivariant nodal parametrization is the \b{eta} model. In addition, we show that an exponential random graph model with similar assumptions but with fewer than n block parameters is the additive stochastic block model. We also provide similar results for directed networks</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.20458v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 26 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Kayvan Sadeghi</dc:creator>
    </item>
    <item>
      <title>A High-Dimensional Statistical Theory for Convex and Nonconvex Matrix Sensing</title>
      <link>https://arxiv.org/abs/2506.20659</link>
      <description>arXiv:2506.20659v1 Announce Type: new 
Abstract: The problem of matrix sensing, or trace regression, is a problem wherein one wishes to estimate a low-rank matrix from linear measurements perturbed with noise. A number of existing works have studied both convex and nonconvex approaches to this problem, establishing minimax error rates when the number of measurements is sufficiently large relative to the rank and dimension of the low-rank matrix, though a precise comparison of these procedures still remains unexplored. In this work we provide a high-dimensional statistical analysis for symmetric low-rank matrix sensing observed under Gaussian measurements and noise. Our main result describes a novel phenomenon: in this statistical model and in an appropriate asymptotic regime, the behavior of any local minimum of the nonconvex factorized approach (with known rank) is approximately equivalent to that of the matrix hard-thresholding of a corresponding matrix denoising problem, and the behavior of the convex nuclear-norm regularized least squares approach is approximately equivalent to that of matrix soft-thresholding of the same matrix denoising problem. Here "approximately equivalent" is understood in the sense of concentration of Lipchitz functions. As a consequence, the nonconvex procedure uniformly dominates the convex approach in mean squared error. Our arguments are based on a matrix operator generalization of the Convex Gaussian Min-Max Theorem (CGMT) together with studying the interplay between local minima of the convex and nonconvex formulations and their "debiased" counterparts, and several of these results may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.20659v1</guid>
      <category>math.ST</category>
      <category>math.OC</category>
      <category>stat.TH</category>
      <pubDate>Thu, 26 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joshua Agterberg, Ren\'e Vidal</dc:creator>
    </item>
    <item>
      <title>Maximal Counts in the Stopped Occupancy Problem</title>
      <link>https://arxiv.org/abs/2506.20411</link>
      <description>arXiv:2506.20411v1 Announce Type: cross 
Abstract: We revisit a version of the classic occupancy scheme, where balls are thrown until almost all boxes receive a given number of balls. Special cases are widely known as coupon-collectors and dixie cup problems. We show that as the number of boxes tends to infinity, the distribution of the maximal occupancy count does not converge, but can be approximated by a convolution of two Gumbel distributions, with the approximating distribution having oscillations close to periodic on a logarithmic scale. We pursue two approaches: one relies on lattice point processes obtained by poissonisation of the number of balls and boxes, and the other employs interpolation of the multiset of occupancy counts to a point process on reals. This way we gain considerable insight in known asymptotics obtained previously by mostly analytic tools. Further results concern the moments of maximal occupancy counts and ties for the maximum.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.20411v1</guid>
      <category>math.PR</category>
      <category>cs.DM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 26 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Gnedin, Svante Janson, Yaakov Malinovsky</dc:creator>
    </item>
    <item>
      <title>A New Regression Model for Analyzing Non-Stationary Extremes in Response and Covariate Variables with an Application in Meteorology</title>
      <link>https://arxiv.org/abs/2506.20615</link>
      <description>arXiv:2506.20615v1 Announce Type: cross 
Abstract: The paper introduces a new regression model designed for situations where both the response and covariates are non-stationary extremes. This method is specifically designed for situations where both the response variable and covariates are represented as block maxima, as the limiting distribution of suitably standardized componentwise maxima follows an extreme value copula. The framework focuses on the regression manifold, which consists of a collection of regression lines aligned with the asymptotic result. A Logistic-normal prior is applied to the space of spectral densities to gain insights into the model based on the data, resulting in an induced prior on the regression manifolds. Numerical studies demonstrate the effectiveness of the proposed method, and an analysis of real meteorological data provides intriguing insights into the relationships between extreme losses in precipitation and temperature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.20615v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 26 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Amina El Bernoussi, Mohamed El Arrouchi</dc:creator>
    </item>
    <item>
      <title>Dimension-free Bounds for Sum of Dependent Matrices and Operators with Heavy-Tailed Distribution</title>
      <link>https://arxiv.org/abs/2210.09756</link>
      <description>arXiv:2210.09756v3 Announce Type: replace 
Abstract: We prove deviation inequalities for sums of high-dimensional random matrices and operators with dependence and {\rc heavy tails}. Estimation of high-dimensional matrices is a concern for numerous modern applications. However, most results are stated for independent observations. Therefore, it is critical to derive results for dependent and heavy-tailed matrices. In this paper, we derive a dimension-free upper bound on the deviation of the sums. Thus, the bound does not depend explicitly on the dimension of the matrices but rather on their effective rank. Our result generalizes several existing studies on the deviation of sums of matrices. It relies on two techniques: (i) a variational approximation of the dual of moment generating functions, and (ii) robustification through the truncation of the eigenvalues of the matrices. We reveal that our results are applicable to several problems, such as covariance matrix estimation, hidden Markov models, and overparameterized linear regression.
  At the beginning, we have attached a corrigendum of the original paper. We correct Theorem 4 of the original paper by introducing a log-Sobolev inequality in place of the boundedness condition. We show that the examples discussed in the original paper can be recovered under new conditions. The original paper, uncorrected version -- which includes the aforementioned error -- is appended after this corrigendum for transparency and comparison.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.09756v3</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 26 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Electron. J. Statist. 18(1): 1130-1159 (2024)</arxiv:journal_reference>
      <dc:creator>Shogo Nakakita, Pierre Alquier, Masaaki Imaizumi</dc:creator>
    </item>
    <item>
      <title>Adaptive Bayesian Regression on Data with Low Intrinsic Dimensionality</title>
      <link>https://arxiv.org/abs/2407.09286</link>
      <description>arXiv:2407.09286v3 Announce Type: replace 
Abstract: We study how the posterior contraction rate under a Gaussian process (GP) prior depends on the intrinsic dimension of the predictors and the smoothness of the regression function. An open question is whether a generic GP prior that does not incorporate knowledge of the intrinsic lower-dimensional structure of the predictors can attain an adaptive rate for a broad class of such structures. We show that this is indeed the case, establishing conditions under which the posterior contraction rates become adaptive to the intrinsic dimension in terms of the covering number of the data domain (the Minkowski dimension) and prove the nonparametric posterior contraction rate, up to a logarithmic factor. When the domain is a compact manifold, we prove the RKHS approximation to intrinsically defined H\"older functions on the manifold of any order of smoothness by a novel analysis, leading to the optimal adaptive posterior contraction rate. We propose an empirical Bayes prior on the kernel bandwidth using kernel affinity and $k$-nearest neighbor statistics, bypassing explicit estimation of the intrinsic dimension. The efficiency of the proposed Bayesian regression approach is demonstrated in various numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09286v3</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 26 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tao Tang, Nan Wu, Xiuyuan Cheng, David Dunson</dc:creator>
    </item>
    <item>
      <title>Asymptotically distribution-free goodness-of-fit testing for point processes</title>
      <link>https://arxiv.org/abs/2503.24197</link>
      <description>arXiv:2503.24197v2 Announce Type: replace 
Abstract: Consider an observation of a multivariate temporal point process $N$ with law $\mathcal P$ on the time interval $[0,T]$. To test the null hypothesis that $\mathcal P$ belongs to a given parametric family, we construct a convergent compensated counting process to which we apply an innovation martingale transformation. We prove that the resulting process converges weakly to a standard Wiener process. Consequently, taking a suitable functional of this process yields an asymptotically distribution-free goodness-of-fit test for point processes. For several standard tests based on the increments of this transformed process, we establish consistency under alternative hypotheses. Finally, we assess the performance of the proposed testing procedure through a Monte Carlo simulation study and illustrate its practical utility with two real-data examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.24197v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 26 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Justin Baars, Sami Umut Can, Roger J. A. Laeven</dc:creator>
    </item>
    <item>
      <title>GMM with Many Weak Moment Conditions and Nuisance Parameters: General Theory and Applications to Causal Inference</title>
      <link>https://arxiv.org/abs/2505.07295</link>
      <description>arXiv:2505.07295v2 Announce Type: replace 
Abstract: Weak identification is a common issue for many statistical problems -- for example, when instrumental variables are weakly correlated with treatment, or when proxy variables are weakly correlated with unmeasured confounders. Under weak identification, standard estimation methods, such as the generalized method of moments (GMM), can have sizeable bias in finite samples or even asymptotically. In addition, many practical settings involve a growing number of nuisance parameters, adding further complexity to the problem. In this paper, we study estimation and inference under a general nonlinear moment model with many weak moment conditions and many nuisance parameters. To obtain debiased inference for finite-dimensional target parameters, we demonstrate that Neyman orthogonality plays a stronger role than in conventional settings with strong identification. We study a general two-step debiasing estimator that allows for possibly nonparametric first-step estimation of nuisance parameters, and we establish its consistency and asymptotic normality under a many weak moment asymptotic regime. Our theory accommodates both high-dimensional moment conditions and function-valued nuisance parameters. We provide high-level assumptions for a general setting and discuss specific applications to the problems of estimation and inference with weak instruments and weak proxies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07295v2</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Thu, 26 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rui Wang, Kwun Chuen Gary Chan, Ting Ye</dc:creator>
    </item>
    <item>
      <title>$L_2$-norm posterior contraction in Gaussian models with unknown variance</title>
      <link>https://arxiv.org/abs/2506.00401</link>
      <description>arXiv:2506.00401v2 Announce Type: replace 
Abstract: The testing-based approach is a fundamental tool for establishing posterior contraction rates. Although the Hellinger metric is attractive owing to the existence of a desirable test function, it is not directly applicable in Gaussian models, because translating the Hellinger metric into more intuitive metrics typically requires strong boundedness conditions. When the variance is known, this issue can be addressed by directly constructing a test function relative to the $L_2$-metric using the likelihood ratio test. However, when the variance is unknown, existing results are limited and rely on restrictive assumptions. To overcome this limitation, we derive a test function tailored to an unknown variance setting with respect to the $L_2$-metric and provide sufficient conditions for posterior contraction based on the testing-based approach. We apply this result to analyze high-dimensional regression and nonparametric regression.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00401v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 26 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Seonghyun Jeong</dc:creator>
    </item>
    <item>
      <title>GIST: Gibbs self-tuning for locally adaptive Hamiltonian Monte Carlo</title>
      <link>https://arxiv.org/abs/2404.15253</link>
      <description>arXiv:2404.15253v4 Announce Type: replace-cross 
Abstract: We introduce a novel and flexible framework for constructing locally adaptive Hamiltonian Monte Carlo (HMC) samplers by Gibbs sampling the algorithm's tuning parameters conditionally based on the position and momentum at each step. For adaptively sampling path lengths, our Gibbs self-tuning (GIST) approach encompasses randomized HMC, multinomial HMC, the No-U-Turn Sampler (NUTS), and the Apogee-to-Apogee Path Sampler as special cases. We exemplify the GIST framework with a novel alternative to NUTS for locally adapting path lengths, evaluated with an exact Hamiltonian for a high-dimensional, ill-conditioned Gaussian measure and with the leapfrog integrator for a suite of diverse models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15253v4</guid>
      <category>stat.CO</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Thu, 26 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nawaf Bou-Rabee, Bob Carpenter, Milo Marsden</dc:creator>
    </item>
    <item>
      <title>Asymptotic Expansions of Gaussian and Laguerre Ensembles at the Soft Edge II: Level Densities</title>
      <link>https://arxiv.org/abs/2503.12644</link>
      <description>arXiv:2503.12644v2 Announce Type: replace-cross 
Abstract: We continue our work [arXiv:2403.07628] on asymptotic expansions at the soft edge for the classical $n$-dimensional Gaussian and Laguerre random matrix ensembles. By revisiting the construction of the associated skew-orthogonal polynomials in terms of wave functions, we obtain concise expressions for the level densities that are well suited for proving asymptotic expansions in powers of a certain parameter $h \asymp n^{-2/3}$. In the unitary case, the expansion for the level density can be used to reconstruct the first correction term in an established asymptotic expansion of the associated generating function. In the orthogonal and symplectic cases, we can even reconstruct the conjectured first and second correction terms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.12644v2</guid>
      <category>math.PR</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 26 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Folkmar Bornemann</dc:creator>
    </item>
  </channel>
</rss>
