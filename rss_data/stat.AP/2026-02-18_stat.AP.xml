<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 19 Feb 2026 02:32:24 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>From Chain-Ladder to Individual Claims Reserving</title>
      <link>https://arxiv.org/abs/2602.15385</link>
      <description>arXiv:2602.15385v2 Announce Type: new 
Abstract: The chain-ladder (CL) method is the most widely used claims reserving technique in non-life insurance. This manuscript introduces a novel approach to computing the CL reserves based on a fundamental restructuring of the data utilization for the CL prediction procedure. Instead of rolling forward the cumulative claims with estimated CL factors, we estimate multi-period factors that project the latest observations directly to the ultimate claims. This alternative perspective on CL reserving creates a natural pathway for the application of machine learning techniques to individual claims reserving. As a proof of concept, we present a small-scale real data application employing neural networks for individual claims reserving.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15385v2</guid>
      <category>stat.AP</category>
      <category>q-fin.RM</category>
      <category>stat.ML</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ronald Richman, Mario V. W\"uthrich</dc:creator>
    </item>
    <item>
      <title>Deep description of static and dynamic network ties in Honduran villages</title>
      <link>https://arxiv.org/abs/2602.15429</link>
      <description>arXiv:2602.15429v1 Announce Type: new 
Abstract: We examine static and dynamic social network structure in 176 villages within the Copan Department of Honduras across two data waves (2016, 2019), using detailed data on multiplex networks for 20,232 individuals enrolled in a longitudinal survey. These networks capture friendship, health advice, financial help, and adversarial relationships, allowing us to show how cooperation and conflict jointly shape social structure. Using node-level network measures derived from near-census sociocentric village networks, we leverage mixed-effects zero-inflated negative binomial models to assess the influence of individual attributes, such as gender, marital status, education, religion, and indigenous status, and of village characteristics, on the dynamics of social networks over time. We complement these node-level models with dyadic assortativity (odds-ratio-based homophily) and community-level measures to describe how sorting by key attributes differs across network types and between waves. Our results demonstrate significant assortativity based on gender and religion, particularly within health and financial networks. Across networks, gender and religion exhibit the most consistent assortative mixing. Additionally, community-level assortativity metrics indicate that educational and financial factors increasingly influence social ties over time. Our findings provide insights into how personal attributes and community dynamics interact to shape network formation and socio-economic relationships in rural settings over time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15429v1</guid>
      <category>stat.AP</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marios Papamichalis, Nikolaos Nakis, Nicholas A. Christakis</dc:creator>
    </item>
    <item>
      <title>Reproducibility and Statistical Methodology</title>
      <link>https://arxiv.org/abs/2602.15697</link>
      <description>arXiv:2602.15697v1 Announce Type: new 
Abstract: In 2015 the Open Science Collaboration (OSC) (Nosek et al 2015) published a highly influential paper which claimed that a large fraction of published results in the psychological sciences were not reproducible. In this article we review this claim from several points of view. We first offer an extended analysis of the methods used in that study. We show that the OSC methodology induces a bias that is able by itself to explain the discrepancy between the OSC estimates of reproducibility and other more optimistic estimates made by similar studies.
  The article also offers a more general literature review and discussion of reproducibility in experimental science. We argue, for both scientific and ethical reasons, that a considered balance of false positive and false negative rates is preferable to a single-minded concentration on false positive rates alone.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15697v1</guid>
      <category>stat.AP</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anthony Almudevar, Jacob Almudevar</dc:creator>
    </item>
    <item>
      <title>Decision Quality Evaluation Framework at Pinterest</title>
      <link>https://arxiv.org/abs/2602.15809</link>
      <description>arXiv:2602.15809v1 Announce Type: new 
Abstract: Online platforms require robust systems to enforce content safety policies at scale. A critical component of these systems is the ability to evaluate the quality of moderation decisions made by both human agents and Large Language Models (LLMs). However, this evaluation is challenging due to the inherent trade-offs between cost, scale, and trustworthiness, along with the complexity of evolving policies. To address this, we present a comprehensive Decision Quality Evaluation Framework developed and deployed at Pinterest. The framework is centered on a high-trust Golden Set (GDS) curated by subject matter experts (SMEs), which serves as a ground truth benchmark. We introduce an automated intelligent sampling pipeline that uses propensity scores to efficiently expand dataset coverage. We demonstrate the framework's practical application in several key areas: benchmarking the cost-performance trade-offs of various LLM agents, establishing a rigorous methodology for data-driven prompt optimization, managing complex policy evolution, and ensuring the integrity of policy content prevalence metrics via continuous validation. The framework enables a shift from subjective assessments to a data-driven and quantitative practice for managing content safety systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15809v1</guid>
      <category>stat.AP</category>
      <category>cs.AI</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuqi Tian, Robert Paine, Attila Dobi, Kevin O'Sullivan, Aravindh Manickavasagam, Faisal Farooq</dc:creator>
    </item>
    <item>
      <title>Natural direct effects of vaccines and post-vaccination behaviour</title>
      <link>https://arxiv.org/abs/2602.15095</link>
      <description>arXiv:2602.15095v1 Announce Type: cross 
Abstract: Knowledge of the protection afforded by vaccines might, in some circumstances, modify a vaccinated individual's behaviour, potentially increasing exposure to pathogens and hindering effectiveness. Although vaccine studies typically do not explicitly account for this possibility in their analyses, we argue that natural direct effects might represent appropriate causal estimands when an objective is to quantify the effect of vaccination on disease while blocking its influence on behaviour. There are, however, complications of a practical nature for the estimation of natural direct effects in this context. Here, we discuss some of these issues, including exposure-outcome and mediator-outcome confounding by healthcare seeking behaviour, and possible approaches to facilitate estimates of these effects. This work highlights the importance of data collection on behaviour, of assessing whether vaccination induces riskier behaviour, and of understanding the potential effects of interventions on vaccination that could turn off vaccine's influence on behaviour.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15095v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bronner P. Gon\c{c}alves, Piero L. Olliaro, Sheena G. Sullivan, Benjamin J. Cowling</dc:creator>
    </item>
    <item>
      <title>Distributional Deep Learning for Super-Resolution of 4D Flow MRI under Domain Shift</title>
      <link>https://arxiv.org/abs/2602.15167</link>
      <description>arXiv:2602.15167v1 Announce Type: cross 
Abstract: Super-resolution is widely used in medical imaging to enhance low-quality data, reducing scan time and improving abnormality detection. Conventional super-resolution approaches typically rely on paired datasets of downsampled and original high resolution images, training models to reconstruct high resolution images from their artificially degraded counterparts. However, in real-world clinical settings, low resolution data often arise from acquisition mechanisms that differ significantly from simple downsampling. As a result, these inputs may lie outside the domain of the training data, leading to poor model generalization due to domain shift. To address this limitation, we propose a distributional deep learning framework that improves model robustness and domain generalization. We develop this approch for enhancing the resolution of 4D Flow MRI (4DF). This is a novel imaging modality that captures hemodynamic flow velocity and clinically relevant metrics such as vessel wall stress. These metrics are critical for assessing aneurysm rupture risk. Our model is initially trained on high resolution computational fluid dynamics (CFD) simulations and their downsampled counterparts. It is then fine-tuned on a small, harmonized dataset of paired 4D Flow MRI and CFD samples. We derive the theoretical properties of our distributional estimators and demonstrate that our framework significantly outperforms traditional deep learning approaches through real data applications. This highlights the effectiveness of distributional learning in addressing domain shift and improving super-resolution performance in clinically realistic scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15167v1</guid>
      <category>cs.CV</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Xiaoyi Wen, Fei Jiang</dc:creator>
    </item>
    <item>
      <title>Sample size and power determination for assessing overall SNP effects in joint modeling of longitudinal and time-to-event data</title>
      <link>https://arxiv.org/abs/2602.15247</link>
      <description>arXiv:2602.15247v1 Announce Type: cross 
Abstract: Longitudinal biomarkers are frequently collected in clinical studies due to their strong association with time-to-event outcomes. While considerable progress has been made in methods for jointly modeling longitudinal and survival data, comparatively little attention has been paid to statistical design considerations, particularly sample size and power calculations, in genetic studies. Yet, appropriate sample size estimation is essential for ensuring adequate power and valid inference. Genetic variants may influence event risk through both direct effects and indirect effects mediated by longitudinal biomarkers. In this paper, we derive a closed-form sample size formula for testing the overall effect of a single nucleotide polymorphism within a joint modeling framework. Simulation studies demonstrate that the proposed formula yields accurate and robust performance in finite samples. We illustrate the practical utility of our method using data from the Diabetes Control and Complications Trial.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15247v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuan Bian, Shelley B. Bull</dc:creator>
    </item>
    <item>
      <title>Bayesian Inference for Joint Tail Risk in Paired Biomarkers via Archimedean Copulas with Restricted Jeffreys Priors</title>
      <link>https://arxiv.org/abs/2602.15319</link>
      <description>arXiv:2602.15319v1 Announce Type: cross 
Abstract: We propose a Bayesian copula-based framework to quantify clinically interpretable joint tail risks from paired continuous biomarkers. After converting each biomarker margin to rank-based pseudo-observations, we model dependence using one-parameter Archimedean copulas and focus on three probability-scale summaries at tail level $\alpha$: the lower-tail joint risk $R_L(\theta)=C_\theta(\alpha,\alpha)$, the upper-tail joint risk $R_U(\theta)=2\alpha-1+C_\theta(1-\alpha,1-\alpha)$, and the conditional lower-tail risk $R_C(\theta)=R_L(\theta)/\alpha$. Uncertainty is quantified via a restricted Jeffreys prior on the copula parameter and grid-based posterior approximation, which induces an exact posterior for each tail-risk functional. In simulations from Clayton and Gumbel copulas across multiple dependence strengths, posterior credible intervals achieve near-nominal coverage for $R_L$, $R_U$, and $R_C$. We then analyze NHANES 2017--2018 fasting glucose (GLU) and HbA1c (GHB) ($n=2887$) at $\alpha=0.05$, obtaining tight posterior credible intervals for both the dependence parameter and induced tail risks. The results reveal markedly elevated extremal co-movement relative to independence; under the Gumbel model, the posterior mean joint upper-tail risk is $R_U(\alpha)=0.0286$, approximately $11.46\times$ the independence benchmark $\alpha^2=0.0025$. Overall, the proposed approach provides a principled, dependence-aware method for reporting joint and conditional extremal-risk summaries with Bayesian uncertainty quantification in biomedical applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15319v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Agnideep Aich, Md. Monzur Murshed, Sameera Hewage, Ashit Baran Aich</dc:creator>
    </item>
    <item>
      <title>Joint Modeling of Longitudinal EHR Data with Shared Random Effects for Informative Visiting and Observation Processes</title>
      <link>https://arxiv.org/abs/2602.15374</link>
      <description>arXiv:2602.15374v1 Announce Type: cross 
Abstract: Longitudinal electronic health record (EHR) data offer opportunities to study biomarker trajectories; however, association estimates-the primary inferential target-from standard models designed for regular observation times may be biased by a two-stage hierarchical missingness mechanism. The first stage is the visiting process (informative presence), where encounters occur at irregular times driven by patient health status; the second is the observation process (informative observation), where biomarkers are selectively measured during visits. To address these mechanisms, we propose a unified semiparametric joint modeling framework that simultaneously characterizes the visiting, biomarker observation, and longitudinal outcome processes. Central to this framework is a shared subject-specific Gaussian latent variable that captures unmeasured frailty and induces dependence across all components. We develop a three-stage estimation procedure and establish the consistency and asymptotic normality of our estimators. We also introduce a sequential procedure that imputes missing biomarkers prior to adjusting for irregular visiting and examine its performance. Simulation results demonstrate that our method yields unbiased estimates under this mechanism, whereas existing approaches can be substantially biased; notably, methods adjusting only for irregular visiting may exhibit even greater bias than those ignoring both mechanisms. We apply our framework to data from the All of Us Research Program to investigate associations between neighborhood-level socioeconomic status indicators and six blood-based biomarker trajectories, providing a robust tool for outpatient settings where irregular monitoring and selective measurement are prevalent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15374v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cheng-Han Yang, Xu Shi, Bhramar Mukherjee</dc:creator>
    </item>
    <item>
      <title>Bayesian Nonparametrics for Gene-Gene and Gene-Environment Interactions in Case-Control Studies: A Synthesis and Extension</title>
      <link>https://arxiv.org/abs/2602.15387</link>
      <description>arXiv:2602.15387v1 Announce Type: cross 
Abstract: Gene-gene and gene-environment interactions are widely believed to play significant roles in explaining the variability of complex traits. While substantial research exists in this area, a comprehensive statistical framework that addresses multiple sources of uncertainty simultaneously remains lacking. In this article, we synthesize and propose extension of a novel class of Bayesian nonparametric approaches that account for interactions among genes, loci, and environmental factors while accommodating uncertainty about population substructure. Our contribution is threefold: (1) We provide a unified exposition of hierarchical Bayesian models driven by Dirichlet processes for genetic interactions, clarifying their conceptual advantages over traditional regression approaches; (2) We shed light on new computational strategies that combine transformation-based MCMC with parallel processing for scalable inference; and (3) We present enhanced hypothesis testing procedures for identifying disease-predisposing loci.Through applications to myocardial infarction data, we demonstrate how these methods offer biological insights not readily obtainable from standard approaches. Our synthesis highlights the advantages of Bayesian nonparametric thinking in genetic epidemiology while providing practical guidance for implementation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15387v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Durba Bhattacharya, Sourabh Bhattacharya</dc:creator>
    </item>
    <item>
      <title>The geometry of online conversations and the causal antecedents of conflictual discourse</title>
      <link>https://arxiv.org/abs/2602.15600</link>
      <description>arXiv:2602.15600v1 Announce Type: cross 
Abstract: This article investigates the causal antecedents of conflictual language and the geometry of interaction in online threaded conversations related to climate change. We employ three annotation dimensions, inferred through LLM prompting and averaging, to capture complementary aspects of discursive conflict (such as stance: agreement vs disagreement; tone: attacking vs respectful; and emotional versus factual framing) and use data from a threaded online forum to examine how these dimensions respond to temporal, conversational, and arborescent structural features of discussions. We show that, as suggested by the literature, longer delays between successive posts in a thread are associated with replies that are, on average, more respectful, whereas longer delays relative to the parent post are associated with slightly less disagreement but more emotional (less factual) language. Second, we characterize alignment with the local conversational environment and find strong convergence both toward the average stance, tone and emotional framing of older sibling posts replying to the same parent and toward those of the parent post itself, with parent post effects generally stronger than sibling effects. We further show that early branch-level responses condition these alignment dynamics, such that parent-child stance alignment is amplified or attenuated depending on whether a branch is initiated in agreement or disagreement with the discussion's root message. These influences are largely additive for civility-related dimensions (attacking vs respectful, disagree vs agree), whereas for emotional versus factual framing there is a significant interaction: alignment with the parent's emotionality is amplified when older siblings are similarly aligned.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15600v1</guid>
      <category>cs.SI</category>
      <category>cs.AI</category>
      <category>econ.EM</category>
      <category>stat.AP</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.13140/RG.2.2.34796.22409</arxiv:DOI>
      <dc:creator>Carlo Santagiustina, Caterina Cruciani</dc:creator>
    </item>
    <item>
      <title>Comprehensive and Spatially Detailed Passenger Vehicle and Truck Traffic Volume Data for the United States Estimated by Machine Learning</title>
      <link>https://arxiv.org/abs/2502.05161</link>
      <description>arXiv:2502.05161v4 Announce Type: replace 
Abstract: The Highway Performance Monitoring System, managed by the Federal Highway Administration, provides data on average annual daily traffic volume across roadways in the United States, but it has limited representation of medium- and heavy-duty vehicle traffic on lower-volume roadways that are not part of the national highway system. This gap limits research and policy analysis on the community impacts of truck traffic, especially concerning air quality and public health. To address this, we use random forest regression to estimate medium- and heavy-duty vehicle traffic volumes on network links where these data are missing. The result is a comprehensive vehicle traffic dataset that covers 85.2% of public roadways in the United States. From these data, we also calculate traffic density values for each census block and vehicle class that can serve as a high-resolution surrogate for traffic-related air pollution exposure in public health studies and policy analysis. Our high-resolution spatial data products are rigorously validated and provide a more complete representation of truck traffic than any existing publicly available dataset. These datasets are valuable for transportation planning, public health research, and policy decisions aimed at understanding and mitigating the effects of truck traffic on communities that are disproportionately exposed to air pollution from vehicle traffic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05161v4</guid>
      <category>stat.AP</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.dib.2026.112451</arxiv:DOI>
      <arxiv:journal_reference>Antonczak, B., Fay, M., Chawla, A., &amp; Rowangould, G. (2026). Comprehensive and spatially detailed passenger vehicle and truck traffic volume data for the United States estimated by machine learning. Data in Brief, 64, 112451</arxiv:journal_reference>
      <dc:creator>Brittany Antonczak, Meg Fay, Aviral Chawla, Gregory Rowangould</dc:creator>
    </item>
    <item>
      <title>Two-Part Forecasting for Time-Shifted Metrics</title>
      <link>https://arxiv.org/abs/2504.11194</link>
      <description>arXiv:2504.11194v2 Announce Type: replace 
Abstract: Katz, Savage, and Brusch propose a two-part forecasting method for sectors where event timing differs from recording time. They treat forecasting as a time-shift operation, using univariate time series for total bookings and a Bayesian Dirichlet Auto-Regressive Moving Average (B-DARMA) model to allocate bookings across trip dates based on lead time. Analysis of Airbnb data shows that this approach is interpretable, flexible, and potentially more accurate for forecasting demand across multiple time axes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11194v2</guid>
      <category>stat.AP</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Foresight 2025: Q2</arxiv:journal_reference>
      <dc:creator>Harrison Katz, Erica Savage, Kai Thomas Brusch</dc:creator>
    </item>
    <item>
      <title>Language Markers of Emotion Flexibility Predict Depression and Anxiety Treatment Outcomes</title>
      <link>https://arxiv.org/abs/2601.07961</link>
      <description>arXiv:2601.07961v2 Announce Type: replace 
Abstract: Predicting treatment non-response for anxiety and depression is challenging, in part because of sparse symptom assessments in real-world care. We examined whether passively captured, fine-grained emotions serve as linguistic markers of treatment outcomes by analyzing 12 weeks of de-identified teletherapy transcripts from 12,043 U.S. patients with moderate-to-severe anxiety and depression symptoms. A transformer-based small language model extracted patients' emotions at the talk-turn level; a state-space model (VISTA-SSM) clustered subgroups based on emotion dynamics over time and produced temporal networks. Two groups emerged: an improving group (n=8,230) and a non-response group (n=3,813) showing increased odds of symptom deterioration, and lower likelihood of clinically significant improvement. Temporal networks indicated that sadness and fear exerted most influence on emotion dynamics in non-responders, whereas improving patients showed balanced joy, sadness, and neutral expressions. Findings suggest that linguistic markers of emotional inflexibility can serve as scalable, interpretable, and theoretically grounded indicators for treatment risk stratification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07961v2</guid>
      <category>stat.AP</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Benjamin Brindle, George A. Bonanno, Thomas Derrick Hull, Nicolas Charon, Matteo Malgaroli</dc:creator>
    </item>
    <item>
      <title>Index insurance under demand and solvency constraints</title>
      <link>https://arxiv.org/abs/2507.18240</link>
      <description>arXiv:2507.18240v3 Announce Type: replace-cross 
Abstract: Index insurance is often proposed to reduce protection gaps, especially for emerging risks. Unlike traditional insurance, it bases compensation on a measurable index, enabling faster payouts and lower claim management costs. This approach benefits both policyholders, through quick payments, and insurers, through reduced costs and better risk control due to reliable data and robust statistical estimates. An important difference with the concept of Cat Bonds is that the feasibility of such coverage relies on the possibility of mutualization. Mutualization, in turn, is achieved only if a sufficiently high number of policyholders agree to subscribe. The purpose of this paper is to introduce a model for the demand for index insurance and to provide conditions under which the solvency of the portfolio is achieved. From these conditions, we deduce a product that combines index and traditional indemnity insurance in order to benefit from the best of both approaches. We illustrate our results with a practical example involving the design of an index insurance product in the field of cyber insurance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.18240v3</guid>
      <category>q-fin.RM</category>
      <category>stat.AP</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Olivier Lopez (CREST), Daniel Nkameni (CREST)</dc:creator>
    </item>
    <item>
      <title>Correlation-Weighted Communicability Curvature as a Structural Driver of Dengue Spread: A Bayesian Spatial Analysis of Recife (2015-2024)</title>
      <link>https://arxiv.org/abs/2512.00315</link>
      <description>arXiv:2512.00315v3 Announce Type: replace-cross 
Abstract: We investigate whether the structural connectivity of urban road networks helps explain dengue incidence in Recife, Brazil (2015--2024). For each neighborhood, we compute the average \emph{communicability curvature}, a graph-theoretic measure capturing the ability of a locality to influence others through multiple network paths. We integrate this metric into Negative Binomial models, fixed-effects regressions, SAR/SAC spatial models, and a hierarchical INLA/BYM2 specification. Across all frameworks, curvature is the strongest and most stable predictor of dengue risk. In the BYM2 model, the structured spatial component collapses ($\phi \approx 0$), indicating that functional network connectivity explains nearly all spatial dependence typically attributed to adjacency-based CAR terms. The results show that dengue spread in Recife is driven less by geographic contiguity and more by network-mediated structural flows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00315v3</guid>
      <category>physics.soc-ph</category>
      <category>math.PR</category>
      <category>q-bio.PE</category>
      <category>stat.AP</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marc\'ilio Ferreira dos Santos, Cleiton de Lima Ricardo, Andreza dos Santos Rodrigues de Melo</dc:creator>
    </item>
    <item>
      <title>Topological Percolation in Urban Dengue Transmission: A Multi-Scale Analysis of Spatial Connectivity</title>
      <link>https://arxiv.org/abs/2601.09747</link>
      <description>arXiv:2601.09747v2 Announce Type: replace-cross 
Abstract: We investigate the spatial organization of dengue cases in the city of Recife, Brazil, from 2015 to 2024, using tools from statistical physics and topological data analysis. Reported cases are modeled as point clouds in a metric space, and their spatial connectivity is studied through Vietoris-Rips filtrations and zero-dimensional persistent homology, which captures the emergence and collapse of connected components across spatial scales. By parametrizing the filtration using percentiles of the empirical distance distribution, we identify critical percolation thresholds associated with abrupt growth of the largest connected component. These thresholds define distinct geometric regimes, ranging from fragmented spatial patterns to highly concentrated, percolated structures. Remarkably, years with similar incidence levels exhibit qualitatively different percolation behavior, demonstrating that case counts alone do not determine the spatial organization of transmission. Our analysis further reveals pronounced temporal heterogeneity in the percolation properties of dengue spread, including a structural rupture in 2020 characterized by delayed or absent spatial percolation. These findings highlight percolation-based topological observables as physically interpretable and sensitive descriptors of urban epidemic structure, offering a complementary perspective to traditional spatial and epidemiological analyses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09747v2</guid>
      <category>q-bio.PE</category>
      <category>math.GT</category>
      <category>stat.AP</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marc\'ilio Ferreira dos Santos, Cleiton de Lima Ricardo</dc:creator>
    </item>
    <item>
      <title>Perfect Clustering for Sparse Directed Stochastic Block Models</title>
      <link>https://arxiv.org/abs/2601.16427</link>
      <description>arXiv:2601.16427v2 Announce Type: replace-cross 
Abstract: Exact recovery in stochastic block models (SBMs) is well understood in undirected settings, but remains considerably less developed for directed and sparse networks, particularly when the number of communities diverges. Spectral methods for directed SBMs often lack stability in asymmetric, low-degree regimes, and existing non-spectral approaches focus primarily on undirected or dense settings.
  We propose a fully non-spectral, two-stage procedure for community detection in sparse directed SBMs with potentially growing numbers of communities. The method first estimates the directed probability matrix using a neighborhood-smoothing scheme tailored to the asymmetric setting, and then applies $K$-means clustering to the estimated rows, thereby avoiding the limitations of eigen- or singular value decompositions in sparse, asymmetric networks. Our main theoretical contribution is a uniform row-wise concentration bound for the smoothed estimator, obtained through new arguments that control asymmetric neighborhoods and separate in- and out-degree effects. These results imply the exact recovery of all community labels with probability tending to one, under mild sparsity and separation conditions that allow both $\gamma_n \to 0$ and $K_n \to \infty$.
  Simulation studies, including highly directed, sparse, and non-symmetric block structures, demonstrate that the proposed procedure performs reliably in regimes where directed spectral and score-based methods deteriorate. To the best of our knowledge, this provides the first exact recovery guarantee for this class of non-spectral, neighborhood-smoothing methods in the sparse, directed setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16427v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Behzad Aalipur, Yichen Qin</dc:creator>
    </item>
  </channel>
</rss>
