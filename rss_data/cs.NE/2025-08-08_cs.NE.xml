<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NE</link>
    <description>cs.NE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 08 Aug 2025 04:01:15 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Optimality Principles and Neural Ordinary Differential Equations-based Process Modeling for Distributed Control</title>
      <link>https://arxiv.org/abs/2508.04799</link>
      <description>arXiv:2508.04799v1 Announce Type: new 
Abstract: Most recent advances in machine learning and analytics for process control pose the question of how to naturally integrate new data-driven methods with classical process models and control. We propose a process modeling framework enabling integration of data-driven algorithms through consistent topological properties and conservation of extensive quantities. Interconnections among process network units are represented through connectivity matrices and network graphs. We derive the system's natural objective function equivalent to the non-equilibrium entropy production in a steady state system as a driving force for the process dynamics. We illustrate how distributed control and optimization can be implemented into process network structures and how control laws and algorithms alter the system's natural equilibrium towards engineered objectives. The basic requirement is that the flow conditions can be expressed in terms of conic sector (passivity) conditions. Our formalism allows integration of fundamental conservation properties from topology with learned dynamic relations from data through sparse deep neural networks.
  We demonstrate in a practical example of a simple inventory control system how to integrate the basic topology of a process with a neural network ordinary differential equation model. The system specific constitutive equations are left undescribed and learned by the neural ordinary differential equation algorithm using the adjoint method in combination with an adaptive ODE solver from synthetic time-series data. The resulting neural network forms a state space model for use in e.g. a model predictive control algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04799v1</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Michael R. Wartmann, B. Erik Ydstie</dc:creator>
    </item>
    <item>
      <title>Modelling the emergence of open-ended technological evolution</title>
      <link>https://arxiv.org/abs/2508.04828</link>
      <description>arXiv:2508.04828v1 Announce Type: new 
Abstract: Humans stand alone in terms of their potential to collectively and cumulatively improve technologies in an open-ended manner. This open-endedness provides societies with the ability to continually expand their resources and to increase their capacity to store, transmit and process information at a collective-level. Here, we propose that the production of resources arises from the interaction between technological systems (a society's repertoire of interdependent skills, techniques and artifacts) and search spaces (the aggregate collection of needs, problems and goals within a society). Starting from this premise we develop a macro-level model wherein both technological systems and search spaces are subject to cultural evolutionary dynamics. By manipulating the extent to which these dynamics are characterised by stochastic or selection-like processes, we demonstrate that open-ended growth is extremely rare, historically contingent and only possible when technological systems and search spaces co-evolve. Here, stochastic factors must be strong enough to continually perturb the dynamics into a far-from-equilibrium state, whereas selection-like factors help maintain effectiveness and ensure the sustained production of resources. Only when this co-evolutionary dynamic maintains effective technological systems, supports the ongoing expansion of the search space and leads to an increased provision of resources do we observe open-ended technological evolution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04828v1</guid>
      <category>cs.NE</category>
      <category>q-bio.PE</category>
      <category>stat.CO</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>James Winters, Mathieu Charbonneau</dc:creator>
    </item>
    <item>
      <title>Harmonic fractal transformation for modeling complex neuronal effects: from bursting and noise shaping to waveform sensitivity and noise-induced subthreshold spiking</title>
      <link>https://arxiv.org/abs/2508.05341</link>
      <description>arXiv:2508.05341v1 Announce Type: cross 
Abstract: We propose the first fractal frequency mapping, which in a simple form enables to replicate complex neuronal effects. Unlike the conventional filters, which suppress or amplify the input spectral components according to the filter weights, the transformation excites novel components by a fractal recomposition of the input spectra resulting in a formation of spikes at resonant frequencies that are optimal for sampling. This enables high sensitivity detection, robustness to noise and noise-induced signal amplification. The proposed model illustrates that a neuronal functionality can be viewed as a linear summation of spectrum over nonlinearly transformed frequency domain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05341v1</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mariia Sorokina</dc:creator>
    </item>
    <item>
      <title>Echo State Networks for Bitcoin Time Series Prediction</title>
      <link>https://arxiv.org/abs/2508.05416</link>
      <description>arXiv:2508.05416v1 Announce Type: cross 
Abstract: Forecasting stock and cryptocurrency prices is challenging due to high volatility and non-stationarity, influenced by factors like economic changes and market sentiment. Previous research shows that Echo State Networks (ESNs) can effectively model short-term stock market movements, capturing nonlinear patterns in dynamic data. To the best of our knowledge, this work is among the first to explore ESNs for cryptocurrency forecasting, especially during extreme volatility. We also conduct chaos analysis through the Lyapunov exponent in chaotic periods and show that our approach outperforms existing machine learning methods by a significant margin. Our findings are consistent with the Lyapunov exponent analysis, showing that ESNs are robust during chaotic periods and excel under high chaos compared to Boosting and Na\"ive methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05416v1</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <category>cs.NE</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mansi Sharma, Enrico Sartor, Marc Cavazza, Helmut Prendinger</dc:creator>
    </item>
    <item>
      <title>Discovering Interpretable Programmatic Policies via Multimodal LLM-assisted Evolutionary Search</title>
      <link>https://arxiv.org/abs/2508.05433</link>
      <description>arXiv:2508.05433v1 Announce Type: cross 
Abstract: Interpretability and high performance are essential goals in designing control policies, particularly for safety-critical tasks. Deep reinforcement learning has greatly enhanced performance, yet its inherent lack of interpretability often undermines trust and hinders real-world deployment. This work addresses these dual challenges by introducing a novel approach for programmatic policy discovery, called Multimodal Large Language Model-assisted Evolutionary Search (MLES). MLES utilizes multimodal large language models as policy generators, combining them with evolutionary mechanisms for automatic policy optimization. It integrates visual feedback-driven behavior analysis within the policy generation process to identify failure patterns and facilitate targeted improvements, enhancing the efficiency of policy discovery and producing adaptable, human-aligned policies. Experimental results show that MLES achieves policy discovery capabilities and efficiency comparable to Proximal Policy Optimization (PPO) across two control tasks, while offering transparent control logic and traceable design processes. This paradigm overcomes the limitations of predefined domain-specific languages, facilitates knowledge transfer and reuse, and is scalable across various control tasks. MLES shows promise as a leading approach for the next generation of interpretable control policy discovery.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05433v1</guid>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qinglong Hu, Xialiang Tong, Mingxuan Yuan, Fei Liu, Zhichao Lu, Qingfu Zhang</dc:creator>
    </item>
    <item>
      <title>TrajEvo: Trajectory Prediction Heuristics Design via LLM-driven Evolution</title>
      <link>https://arxiv.org/abs/2508.05616</link>
      <description>arXiv:2508.05616v1 Announce Type: cross 
Abstract: Trajectory prediction is a critical task in modeling human behavior, especially in safety-critical domains such as social robotics and autonomous vehicle navigation. Traditional heuristics based on handcrafted rules often lack accuracy and generalizability. Although deep learning approaches offer improved performance, they typically suffer from high computational cost, limited explainability, and, importantly, poor generalization to out-of-distribution (OOD) scenarios. In this paper, we introduce TrajEvo, a framework that leverages Large Language Models (LLMs) to automatically design trajectory prediction heuristics. TrajEvo employs an evolutionary algorithm to generate and refine prediction heuristics from past trajectory data. We propose two key innovations: Cross-Generation Elite Sampling to encourage population diversity, and a Statistics Feedback Loop that enables the LLM to analyze and improve alternative predictions. Our evaluations demonstrate that TrajEvo outperforms existing heuristic methods across multiple real-world datasets, and notably surpasses both heuristic and deep learning methods in generalizing to an unseen OOD real-world dataset. TrajEvo marks a promising step toward the automated design of fast, explainable, and generalizable trajectory prediction heuristics. We release our source code to facilitate future research at https://github.com/ai4co/trajevo.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05616v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <category>cs.RO</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhikai Zhao, Chuanbo Hua, Federico Berto, Kanghoon Lee, Zihan Ma, Jiachen Li, Jinkyoo Park</dc:creator>
    </item>
    <item>
      <title>Vector Quantized-Elites: Unsupervised and Problem-Agnostic Quality-Diversity Optimization</title>
      <link>https://arxiv.org/abs/2504.08057</link>
      <description>arXiv:2504.08057v2 Announce Type: replace 
Abstract: Quality-Diversity algorithms have transformed optimization by prioritizing the discovery of diverse, high-performing solutions over a single optimal result. However, traditional Quality-Diversity methods, such as MAP-Elites, rely heavily on predefined behavior descriptors and complete prior knowledge of the task to define the behavior space grid, limiting their flexibility and applicability. In this work, we introduce Vector Quantized-Elites (VQ-Elites), a novel Quality-Diversity algorithm that autonomously constructs a structured behavior space grid using unsupervised learning, eliminating the need for prior task-specific knowledge. At the core of VQ-Elites is the integration of Vector Quantized Variational Autoencoders, which enables the dynamic learning of behavior descriptors and the generation of a structured, rather than unstructured, behavior space grid -- a significant advancement over existing unsupervised Quality-Diversity approaches. This design establishes VQ-Elites as a flexible, robust, and task-agnostic optimization framework. To further enhance the performance of unsupervised Quality-Diversity algorithms, we introduce behavior space bounding and cooperation mechanisms, which significantly improve convergence and performance, as well as the Effective Diversity Ratio and Coverage Diversity Score, two novel metrics that quantify the actual diversity in the unsupervised setting. We validate VQ-Elites on robotic arm pose-reaching, mobile robot space-covering, and MiniGrid exploration tasks. The results demonstrate its ability to efficiently generate diverse, high-quality solutions, emphasizing its adaptability, scalability, robustness to hyperparameters, and potential to extend Quality-Diversity optimization to complex, previously inaccessible domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.08057v2</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.RO</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Constantinos Tsakonas, Konstantinos Chatzilygeroudis</dc:creator>
    </item>
    <item>
      <title>STF: Shallow-Level Temporal Feedback to Enhance Spiking Transformers</title>
      <link>https://arxiv.org/abs/2508.00387</link>
      <description>arXiv:2508.00387v2 Announce Type: replace 
Abstract: Transformer-based Spiking Neural Networks (SNNs) suffer from a great performance gap compared to floating-point \mbox{Artificial} Neural Networks (ANNs) due to the binary nature of spike trains. Recent efforts have introduced deep-level feedback loops to transmit high-level semantic information to narrow this gap. However, these designs often span \mbox{multiple} deep layers, resulting in costly feature transformations, higher parameter overhead, increased energy consumption, and longer inference latency. To address this issue, we propose Shallow-level Temporal Feedback (STF), a lightweight plug-and-play module for the encoding layer, which consists of Temporal-Spatial Position Embedding (TSPE) and Temporal Feedback (TF). Extensive experiments show that STF consistently improves performance across various Transformer-based SNN backbones on static datasets, including CIFAR-10, CIFAR-100, and ImageNet-1K, under different spike timestep settings. Further analysis reveals that STF enhances the diversity of spike patterns, which is key to performance gain. Moreover, evaluations on adversarial robustness and temporal sensitivity confirm that STF outperforms direct coding and its variants, highlighting its potential as a new spike encoding scheme for static scenarios. Our code will be released upon acceptance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00387v2</guid>
      <category>cs.NE</category>
      <category>cs.CV</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zeqi Zheng, Zizheng Zhu, Yingchao Yu, Yanchen Huang, Changze Lv, Junfeng Tang, Zhaofei Yu, Yaochu Jin</dc:creator>
    </item>
    <item>
      <title>Proof-of-Useful-Work Blockchain for Trustworthy Biomedical Hyperdimensional Computing</title>
      <link>https://arxiv.org/abs/2202.02964</link>
      <description>arXiv:2202.02964v2 Announce Type: replace-cross 
Abstract: Hyperdimensional Computing (HDC) is a promising bio-inspired learning paradigm for its advantage of balancing performance and efficiency and has been increasingly applied to the bio-medical domain. In bio-medical applications, trustworthiness such as replicability and verifiability of the trained learning models is crucial. In this work, we introduce HDCoin, the first proof-of-useful-work blockchain framework for HDC. With HDCoin, we transform the conventional energy-wasteful mining process into a competitive process for developing high accuracy, trustworthy and verifiable hyperdimensional models. We explore four diverse biomedical datasets, and conduct an extensive design-space exploration of key HDC hyperparameters of blockchain miners such as dimensionality, learning rate, and retraining iterations for model performance, adaptive mining difficulty and fairness on proof-of-useful-work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2202.02964v2</guid>
      <category>cs.CR</category>
      <category>cs.NE</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jinghao Wen, Dongning Ma, Sizhe Zhang, Hasshi Sudler, Xun Jiao</dc:creator>
    </item>
    <item>
      <title>Adam assisted Fully informed Particle Swarm Optimization ( Adam-FIPSO ) based Parameter Prediction for the Quantum Approximate Optimization Algorithm (QAOA)</title>
      <link>https://arxiv.org/abs/2506.06790</link>
      <description>arXiv:2506.06790v2 Announce Type: replace-cross 
Abstract: The Quantum Approximate Optimization Algorithm (QAOA) is a prominent variational algorithm used for solving combinatorial optimization problems such as the Max-Cut problem. A key challenge in QAOA lies in efficiently identifying suitable parameters (gamma, beta) that lead to high-quality solutions. In this paper, we propose a framework that combines Fully Informed Particle Swarm Optimization (FIPSO) with adaptive gradient correction using the Adam Optimizer to navigate the QAOA parameter space. This approach aims to avoid issues such as barren plateaus and convergence to local minima. The proposed algorithm is evaluated against two classes of graph instances, Erdos Renyi and Watts-Strogatz. Experimental results across multiple QAOA depths consistently demonstrate superior performance compared to random initialization, underscoring the effectiveness and robustness of the proposed optimization framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.06790v2</guid>
      <category>quant-ph</category>
      <category>cs.NE</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shashank Sanjay Bhat, Peiyong Wang, Udaya Parampalli</dc:creator>
    </item>
    <item>
      <title>Neuromorphic Cybersecurity with Semi-supervised Lifelong Learning</title>
      <link>https://arxiv.org/abs/2508.04610</link>
      <description>arXiv:2508.04610v2 Announce Type: replace-cross 
Abstract: Inspired by the brain's hierarchical processing and energy efficiency, this paper presents a Spiking Neural Network (SNN) architecture for lifelong Network Intrusion Detection System (NIDS). The proposed system first employs an efficient static SNN to identify potential intrusions, which then activates an adaptive dynamic SNN responsible for classifying the specific attack type. Mimicking biological adaptation, the dynamic classifier utilizes Grow When Required (GWR)-inspired structural plasticity and a novel Adaptive Spike-Timing-Dependent Plasticity (Ad-STDP) learning rule. These bio-plausible mechanisms enable the network to learn new threats incrementally while preserving existing knowledge. Tested on the UNSW-NB15 benchmark in a continual learning setting, the architecture demonstrates robust adaptation, reduced catastrophic forgetting, and achieves $85.3$\% overall accuracy. Furthermore, simulations using the Intel Lava framework confirm high operational sparsity, highlighting the potential for low-power deployment on neuromorphic hardware.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04610v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.NE</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Md Zesun Ahmed Mia, Malyaban Bal, Sen Lu, George M. Nishibuchi, Suhas Chelian, Srini Vasan, Abhronil Sengupta</dc:creator>
    </item>
  </channel>
</rss>
