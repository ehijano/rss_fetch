<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.IT</link>
    <description>math.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 10 Feb 2026 05:01:14 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Single-shot lossy compression: mutual information bounds</title>
      <link>https://arxiv.org/abs/2602.07280</link>
      <description>arXiv:2602.07280v1 Announce Type: new 
Abstract: For several styles of fidelity constraints -- guaranteed distortion, conditional excess distortion, excess distortion -- we show mutual information upper bounds on the minimum expected description length needed to represent a random variable. Coupled with the corresponding converses, these results attest that as long as the information content in the data is not too low, minimizing the mutual information under an appropriate fidelity constraint serves as a reasonable proxy for the minimum description length of the data. We provide alternative characterizations of all three convex proxies, shedding light on the structure of their solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07280v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>2026 International Zurich Seminar on Information and Communication</arxiv:journal_reference>
      <dc:creator>Victoria Kostina</dc:creator>
    </item>
    <item>
      <title>Network function computation with vector linear target function and security function</title>
      <link>https://arxiv.org/abs/2602.07316</link>
      <description>arXiv:2602.07316v1 Announce Type: new 
Abstract: In this paper, we study the problem of securely computing a function over a network, where both the target function and the security function are vector linear. The network is modeled as a directed acyclic graph. A sink node wishes to compute a function of messages generated by multiple distributed sources, while an eavesdropper can access exactly one wiretap set from a given collection. The eavesdropper must be prevented from obtaining any information about a specified security function of the source messages. The secure computing capacity is the maximum average number of times that the target function can be securely computed with zero error at the sink node with the given collection of wiretap sets and security function for one use of the network. We establish two upper bounds on this capacity, which hold for arbitrary network topologies and for any vector linear target and security functions. These bounds generalize existing results and also lead to a new upper bound when the target function is the sum over a finite field. For the lower bound, when the target function is the sum, we extend an existing method, which transforms a non-secure network code into a secure one, to the case where the security function is vector linear. Furthermore, for a particular class of networks and a vector linear target function, we characterize the required properties of the global encoding matrix to construct a secure vector linear network code.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07316v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Min Xu, Qian Chen, Gennian Ge</dc:creator>
    </item>
    <item>
      <title>Multicasting Pinching Antenna Systems With LoS Blockage</title>
      <link>https://arxiv.org/abs/2602.07421</link>
      <description>arXiv:2602.07421v1 Announce Type: new 
Abstract: Pinching-antenna systems (PASS) represent a promising customizable wireless access mechanism in high-frequency bands, enabled by dielectric waveguides and movable dielectric particles, called pinching antennas (PAs). In this work, we study optimal position allocation of PAs in PASS for multicasting in the downlink when a line-of-sight (LoS) link does not necessarily exist between all users and the PAs. The multicasting problem is solved by leveraging minorization-maximization (MM) principle to yield a provably convergent algorithm. In each run of the MM based procedure, we solve a convex surrogate problem using two methods called the candidate search method (CSM) and the bisection search method (BSM). With both BSM and CSM, we not only report superior performance of the multicasting PASS in non-LoS environments compared to conventional antenna systems (CAS), but also determine that BSM yields better overall computational complexity when the number of users and PAs increases. For example, we report that when we have 8 PAs and 25 users, the execution time with the CSM is approximately 2.5 times that with the BSM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07421v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Muhammad Fainan Hanif, Yuanwei Liu</dc:creator>
    </item>
    <item>
      <title>Information Theoretic Modeling of Interspecies Molecular Communication</title>
      <link>https://arxiv.org/abs/2602.07474</link>
      <description>arXiv:2602.07474v1 Announce Type: new 
Abstract: Plants and insects communicate using chemical signals like volatile organic compounds (VOCs). A plant encodes information using different blends of VOCs, which propagate through the air to represent different symbolic information. This communication occurs in a noisy environment, characterized by wind, distance, and complex biological reactions. At the receiver, cross-reactive olfactory receptors produce stochastic binding events whose discretized durations form the receiver observation. In this paper, an information-theoretic framework is developed to model interspecies molecular communication (MC), where receptor responses are modeled probabilistically using a multinomial distribution. Numerical results show that the communication depends on environmental parameters such as wind speed, distance, and the number of released molecules. The proposed framework provides fundamental insights into the VOC-based interspecies communication under realistic biological and environmental conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07474v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bitop Maitra, Murat Kuscu, Ozgur B. Akan</dc:creator>
    </item>
    <item>
      <title>Transformer-based Hybrid Beamforming with Dynamic Subarray for Near-Space Airship-Borne Communications</title>
      <link>https://arxiv.org/abs/2602.07509</link>
      <description>arXiv:2602.07509v1 Announce Type: new 
Abstract: This paper proposes a hybrid beamforming framework for massive multiple-input multiple-output (MIMO) in near-space airship-borne communications. To achieve high energy efficiency (EE) in energy-constraint airships, a dynamic subarray structure is introduced, where each radio frequency chain (RFC) is connected to a disjoint subset of the antennas according to channel state information (CSI). The proposed joint dynamic hybrid beamforming network (DyHBFNet) comprises three key components: 1) An analog beamforming network (ABFNet) that optimizes the analog beamforming matrices and provides auxiliary information for the antenna selection network (ASNet) design, 2) an ASNet that dynamically optimizes the connections between antennas and RFCs, and 3) a digital beamforming network (DBFNet) that optimizes digital beamforming matrices by employing a model-driven weighted minimum mean square error algorithm for improving beamforming performance and convergence speed. The proposed ABFNet, ASNet, and DBFNet are all designed based on advanced Transformer encoders. Simulation results demonstrate that the proposed framework significantly enhances spectral efficiency and EE compared to baseline schemes. Additionally, its robust performance under imperfect CSI makes it a scalable solution for practical implementations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07509v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ruiqi Wang, Zhen Gao, Keke Ying, Ziwei Wan, Symeon Chatzinotas, Mohamed-Slim Alouini</dc:creator>
    </item>
    <item>
      <title>Expected Recovery Time in DNA-based Distributed Storage Systems</title>
      <link>https://arxiv.org/abs/2602.07601</link>
      <description>arXiv:2602.07601v1 Announce Type: new 
Abstract: We initiate the study of DNA-based distributed storage systems, where information is encoded across multiple DNA data storage containers to achieve robustness against container failures. In this setting, data are distributed over $M$ containers, and the objective is to guarantee that the contents of any failed container can be reliably reconstructed from the surviving ones. Unlike classical distributed storage systems, DNA data storage containers are fundamentally constrained by sequencing technology, since each read operation yields the content of a uniformly random sampled strand from the container. Within this framework, we consider several erasure-correcting codes and analyze the expected recovery time of the data stored in a failed container. Our results are obtained by analyzing generalized versions of the classical Coupon Collector's Problem, which may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07601v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adi Levy, Roni Con, Eitan Yaakobi, Han Mao Kiah</dc:creator>
    </item>
    <item>
      <title>Wireless Streamlet: A Spectrum-Aware and Cognitive Consensus Protocol for Edge IoT</title>
      <link>https://arxiv.org/abs/2602.07630</link>
      <description>arXiv:2602.07630v1 Announce Type: new 
Abstract: Blockchain offers a decentralized trust framework for the Internet of Things (IoT), yet deploying consensus in spectrum-congested and dynamic wireless edge IoT networks faces fundamental obstacles: traditional BFT protocols are spectrum-ignorant, leading to inefficient resource utilization and fragile progress under time-varying interference. This paper presents \textit{Wireless Streamlet}, a spectrum-aware and cognitive consensus protocol tailored for wireless edge IoT. Building on Streamlet's streamlined structure, we introduce a \textit{Channel-Aware Leader Election (CALE)} mechanism. CALE serves as a verifiable cross-layer cognitive engine that leverages receiver-measured channel state information (CSI) piggybacked in signed votes to derive Byzantine-robust connectivity scores from notarization certificates, and deterministically selects a unique weighted leader per epoch from finalized history, thereby improving proposal dissemination reliability under deep fading. Complementing this cognitive adaptation, Wireless Streamlet exploits the single-hop broadcast medium and a deterministic TDMA voting schedule to achieve linear per-epoch on-air transmissions (slot complexity), ensuring deterministic spectral access. To address the communication-storage trade-off, we further propose a coded dual-chain architecture that decouples header-only consensus (State Chain) from payload data (Data Chain). By employing erasure coding and on-chain integrity commitments, the system minimizes redundant spectrum usage for data retrieval while ensuring availability. Experiments show that Wireless Streamlet achieves higher throughput and lower confirmation latency than representative baselines in lossy environments, while substantially reducing per-node storage, demonstrating the efficacy of integrating cognitive sensing into consensus logic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07630v1</guid>
      <category>cs.IT</category>
      <category>cs.DC</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Taotao Wang, Long Shi, Fang Liu, Qing Yang, Shengli Zhang</dc:creator>
    </item>
    <item>
      <title>Data Compression with Stochastic Codes</title>
      <link>https://arxiv.org/abs/2602.07635</link>
      <description>arXiv:2602.07635v1 Announce Type: new 
Abstract: Machine learning has had a major impact on data compression over the last decade and inspired many new, exciting theoretical and applied questions.
  This paper describes one such direction -- relative entropy coding -- which focuses on constructing stochastic codes, primarily as an alternative to quantisation and entropy coding in lossy source coding. Our primary aim is to provide a broad overview of the topic, with an emphasis on the computational and practical aspects currently missing from the literature.
  Our goal is threefold: for the curious reader, we aim to provide an intuitive picture of the field and convince them that relative entropy coding is a simple yet exciting emerging field in data compression research. For a reader interested in applied research on lossy data compression, we provide an account of the most salient contemporary applications. Finally, for the reader who has heard of relative entropy coding but has never been quite sure what it is or how the algorithms fit together, we hope to illustrate how simple and elegant the underlying constructions are.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07635v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gergely Flamich, Deniz G\"und\"uz</dc:creator>
    </item>
    <item>
      <title>Spectral Graph Analysis for Predicting QoE Fairness Sensitivity in Wireless Communication Networks</title>
      <link>https://arxiv.org/abs/2602.07855</link>
      <description>arXiv:2602.07855v1 Announce Type: new 
Abstract: The evaluation of Quality of Experience (QoE) fairness depends not only on its current state but, more critically, on its sensitivity to changes in Service Level Agreement (SLA) parameters. However, the academic community has long lacked a predictive method connecting underlying topology to high-level service fairness. To bridge this gap, this paper analyzes a QoE imbalance index ($I$) through the lens of spectral graph theory.Our core contribution is the proof of a novel exponential spectral upper bound. This bound reveals that the improvement of QoE fairness exhibits an exponential decay behavior only above a performance threshold determined jointly by network size and connectivity. Its core decay rate is dominated by the weaker of two factors: the SLA stringency ($a$) and the network's spectral gap ($c\lambda_2$). The upper bound unifies the service protocol and the topological bottleneck within a single performance bound formula for the first time.This theoretical relationship also reveals a clear bottleneck effect, where the system's fairness ceiling is determined by the weaker link between service parameters and network structure. This finding provides a bottleneck-driven principle for resource optimization in network design and enables goal-driven reverse engineering. Extensive numerical experiments on various random graph models and real-world network topologies robustly validate the correctness and universality of our analytical framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07855v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinke Jian, Zhiyuan Ren, Wenchi Cheng</dc:creator>
    </item>
    <item>
      <title>Capacity Scaling Laws for Boundary-Induced Drift-Diffusion Noise Channels</title>
      <link>https://arxiv.org/abs/2602.07866</link>
      <description>arXiv:2602.07866v1 Announce Type: new 
Abstract: This paper studies the high-power capacity scaling of additive noise channels whose noise arises from the first-hitting location of a multidimensional drift-diffusion process on an absorbing hyperplane. By identifying the underlying stochastic transport mechanism as a Gaussian variance-mixture, we introduce and analyze the Normally-Drifted First-Hitting Location (NDFHL) family as a geometry-driven model for boundary-induced noise. Under a second-moment constraint, we derive an exact high-SNR capacity expansion and show that the asymptotic upper and lower bounds coincide at the constant level, yielding a vanishing capacity gap. As a consequence, isotropic Gaussian signaling is asymptotically capacity-achieving for all fixed drift strengths, despite the non-Gaussian and semi-heavy-tailed nature of the noise. The pre-log factor is determined solely by the dimension of the receiving boundary, revealing a geometric origin of the channel's degrees of freedom. The refined expansion further uncovers an entropy-dominant universality, whereby all physical parameters of the transport process -- including drift strength, diffusion coefficient, and boundary separation -- affect the capacity only through the differential entropy of the induced noise. Although the NDFHL density does not admit a simple closed form, its entropy is shown to be finite and to vary continuously as the drift vanishes, thereby connecting the finite-variance regime with the singular infinite-variance Cauchy limit. Together, these results provide a unified geometric and information-theoretic characterization of boundary-hitting channels across both regular and singular transport regimes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07866v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yen-Chi Lee</dc:creator>
    </item>
    <item>
      <title>Deep learning based Channel Estimation and Beamforming in Movable Antenna Systems</title>
      <link>https://arxiv.org/abs/2602.07870</link>
      <description>arXiv:2602.07870v1 Announce Type: new 
Abstract: Movable antenna (MA) has emerged as a promising technology for future wireless systems. Compared with traditional fixed-position antennas, MA improves system performance by antenna movement to optimize channel conditions. For multiuser wideband MA systems, this paper proposes deep learning-based framework integrating channel estimation (CE), antenna position optimization, and beamforming, with a clear workflow and enhanced efficiency. Specifically, to obtain accurate channel state information (CSI), we design a two-stage CE mechanism: first reconstructing the channel matrix from limited measurements via compressive sensing, then introducing a Swin-Transformer-based denoising network to refine CE accuracy for subsequent optimization. Building on this, we address the joint optimization challenge by proposing a Transformer-based network that intelligently maps CSI sequences of candidate positions to optimal MA positions while combining a model-driven weighted minimum mean square error (WMMSE) beamforming approach to achieve better performance. Simulation results demonstrate that the proposed methods achieve superior performance compared with existing counterparts under various conditions. The codes about this work are available at https://github.com/ZiweiWan/Code-4-DL-MA-CE-BF.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07870v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Kaijun Feng, Ziwei Wan, Anwen Liao, Wenyan Ma, Lipeng Zhu, Zhenyu Xiao, Zhen Gao, Rui Zhang</dc:creator>
    </item>
    <item>
      <title>Deep Variable-Length Feedback Codes</title>
      <link>https://arxiv.org/abs/2602.07881</link>
      <description>arXiv:2602.07881v1 Announce Type: new 
Abstract: Deep learning has enabled significant advances in feedback-based channel coding, yet existing learned schemes remain fundamentally limited: they employ fixed block lengths, suffer degraded performance at high rates, and cannot fully exploit the adaptive potential of feedback. This paper introduces Deep Variable-Length Feedback (DeepVLF) coding, a flexible coding framework that dynamically adjusts transmission length via learned feedback. We propose two complementary architectures: DeepVLF-R, where termination is receiver-driven, and DeepVLF-T, where the transmitter controls termination. Both architectures leverage bit-group partitioning and transformer-based encoder-decoder networks to enable fine-grained rate adaptation in response to feedback. Evaluations over AWGN and 5G-NR fading channels demonstrate that DeepVLF substantially outperforms state-of-the-art learned feedback codes. It achieves the same block error rate with 20%-55% fewer channel uses and lowers error floors by orders of magnitude, particularly in high-rate regimes. Encoding dynamics analysis further reveals that the models autonomously learn a two-phase strategy analogous to classical Schalkwijk-Kailath coding: an initial information-carrying phase followed by a noise-cancellation refinement phase. This emergent behavior underscores the interpretability and information-theoretic alignment of the learned codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07881v1</guid>
      <category>cs.IT</category>
      <category>cs.AI</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu Ding, Yulin Shao</dc:creator>
    </item>
    <item>
      <title>Rich-ARQ: From 1-bit Acknowledgment to Rich Neural Coded Feedback</title>
      <link>https://arxiv.org/abs/2602.07886</link>
      <description>arXiv:2602.07886v1 Announce Type: new 
Abstract: This paper reimagines the foundational feedback mechanism in wireless communication, transforming the prevailing 1-bit binary ACK/NACK with a high-dimensional, information-rich vector to transform passive acknowledgment into an active collaboration. We present Rich-ARQ, a paradigm that introduces neural-coded feedback for collaborative physical-layer channel coding between transmitter and receiver. To realize this vision in practice, we develop a novel asynchronous feedback code that eliminates stalling from feedback delays, adapts dynamically to channel fluctuations, and features a lightweight encoder suitable for on-device deployment. We materialize this concept into the first full-stack, standard-compliant software-defined radio prototype, which decouples AI inference from strict radio timing. Comprehensive over-the-air experiments demonstrate that Rich-ARQ achieves significant SNR gains over conventional 1-bit hybrid ARQ and remarkable latency reduction over prior learning-based feedback codes, moving the promise of intelligent feedback from theory to a practical, high-performance reality for next-generation networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07886v1</guid>
      <category>cs.IT</category>
      <category>cs.AI</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Enhao Chen, Yulin Shao</dc:creator>
    </item>
    <item>
      <title>OFDM Enabled Over-the-Air Computation Systems with Two-Dimensional Fluid Antennas</title>
      <link>https://arxiv.org/abs/2602.07953</link>
      <description>arXiv:2602.07953v1 Announce Type: new 
Abstract: Fluid antenna system (FAS) is able to exploit spatial degrees of freedom (DoFs) in wireless channels. In this letter, to exploit spatial DoFs in frequency-selective environments, we investigate an orthogonal frequency division multiplexing enabled over-the-air computation system, where the access point is equipped with a two-dimensional FAS to enhance performance. We solve the computation mean square error (MSE) minimization problem by transforming the original problem into transmit precoders optimization problem and antenna positions optimization along with receive combiners optimization problem. The latter is solved via a majorization-minimization approach combined with sequential optimization. Numerical results confirm that the proposed scheme achieves MSE reduction over the scheme with fixed position antennas.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07953v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Heyang Xiong, Quanzhong Li, Qi Zhang</dc:creator>
    </item>
    <item>
      <title>Tighter Information-Theoretic Generalization Bounds via a Novel Class of Change of Measure Inequalities</title>
      <link>https://arxiv.org/abs/2602.07999</link>
      <description>arXiv:2602.07999v1 Announce Type: new 
Abstract: In this paper, we propose a novel class of change of measure inequalities via a unified framework based on the data processing inequality for $f$-divergences, which is surprisingly elementary yet powerful enough to yield tighter inequalities. We provide change of measure inequalities in terms of a broad family of information measures, including $f$-divergences (with Kullback-Leibler divergence and $\chi^2$-divergence as special cases), R\'enyi divergence, and $\alpha$-mutual information (with maximal leakage as a special case). We then embed these inequalities into the analysis of generalization error for stochastic learning algorithms, yielding novel and tighter high-probability information-theoretic generalization bounds, while also recovering several best-known results via simplified analyses. A key advantage of our framework is its flexibility: it readily adapts to a range of settings, including the conditional mutual information framework, PAC-Bayesian theory, and differential privacy mechanisms, for which we derive new generalization bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07999v1</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yanxiao Liu, Yijun Fan an Deniz G\"und\"uz</dc:creator>
    </item>
    <item>
      <title>Term Coding and Dispersion: A Perfect-vs-Rate Complexity Dichotomy for Information Flow</title>
      <link>https://arxiv.org/abs/2602.08110</link>
      <description>arXiv:2602.08110v1 Announce Type: new 
Abstract: We introduce a new framework term coding for extremal problems in discrete mathematics and information flow, where one chooses interpretations of function symbols so as to maximise the number of satisfying assignments of a finite system of term equations.
  We then focus on dispersion, the special case in which the system defines a term map $\Theta^\mathcal I:\A^k\to\A^r$ and the objective is the size of its image. Writing $n:=|\A|$, we show that the maximum dispersion is $\Theta(n^D)$ for an integer exponent $D$ equal to the guessing number of an associated directed graph, and we give a polynomial-time algorithm to compute $D$. In contrast, deciding whether \emph{perfect dispersion} ever occurs (i.e.\ whether $\Disp_n(\mathbf t)=n^r$ for some finite $n\ge 2$) is undecidable once $r\ge 3$, even though the corresponding asymptotic rate-threshold questions are polynomial-time decidable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08110v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>S{\o}ren Riis</dc:creator>
    </item>
    <item>
      <title>Optimal Transmit Beamforming for MIMO ISAC with Unknown Target and User Locations</title>
      <link>https://arxiv.org/abs/2602.08255</link>
      <description>arXiv:2602.08255v1 Announce Type: new 
Abstract: This paper studies a challenging scenario in a multiple-input multiple-output (MIMO) integrated sensing and communication (ISAC) system where the locations of the sensing target and the communication user are both unknown and random, while only their probability distribution information is known. In this case, how to fully utilize the spatial resources by designing the transmit beamforming such that both sensing and communication can achieve satisfactory performance statistically is a difficult problem, which motivates the study in this paper. Moreover, we aim to reveal if it is desirable to have similar probability distributions for the target and user locations in terms of the ISAC performance. Firstly, based on only probability distribution information, we establish communication and sensing performance metrics via deriving the expected rate or posterior Cram\'{e}r-Rao bound (PCRB). Then, we formulate the transmit beamforming optimization problem to minimize the PCRB subject to the expected rate constraint, for which the optimal solution is derived. It is unveiled that the rank of the optimal transmit covariance matrix is upper bounded by the summation of MIMO communication channel matrices for all possible user locations. Furthermore, due to the need to cater to multiple target/user locations, we investigate whether dynamically employing different beamforming designs over different time slots improves the performance. It is proven that using a static beamforming strategy is sufficient for achieving the optimal performance. Numerical results validate our analysis, show that ISAC performance improves as the target/user location distributions become similar, and provide useful insights on the BS-user/-target association strategy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08255v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yizhuo Wang, Shuowen Zhang</dc:creator>
    </item>
    <item>
      <title>Hierarchical Subcode Ensemble Decoding of Polar Codes</title>
      <link>https://arxiv.org/abs/2602.08391</link>
      <description>arXiv:2602.08391v1 Announce Type: new 
Abstract: Subcode-ensemble decoders improve iterative decoding by running multiple decoders in parallel over carefully chosen subcodes, increasing the likelihood that at least one decoder avoids the dominant trapping structures. Achieving strong diversity gains, however, requires constructing many subcodes that satisfy a linear covering property-yet existing approaches lack a systematic way to scale the ensemble size while preserving this property. This paper introduces hierarchical subcode ensemble decoding (HSCED), a new ensemble decoding framework that expands the number of constituent decoders while still guaranteeing linear covering. The key idea is to recursively generate subcode parity constraints in a hierarchical structure so that coverage is maintained at every level, enabling large ensembles with controlled complexity. To demonstrate its effectiveness, we apply HSCED to belief propagation (BP) decoding of polar codes, where dense parity-check matrices induce severe stopping-set effects that limit conventional BP. Simulations confirm that HSCED delivers significant block-error-rate improvements over standard BP and conventional subcode-ensemble decoding under the same decoding-latency constraint.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08391v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yubeen Jo, Geon Choi, Chanho Park, Namyoon Lee</dc:creator>
    </item>
    <item>
      <title>Multipoint Code-Weight Sphere Decoding: Parallel Near-ML Decoding for Short-Blocklength Codes</title>
      <link>https://arxiv.org/abs/2602.08501</link>
      <description>arXiv:2602.08501v1 Announce Type: new 
Abstract: Ultra-reliable low-latency communications (URLLC) operate with short packets, where finite-blocklength effects make near-maximum-likelihood (near-ML) decoding desirable but often too costly. This paper proposes a two-stage near-ML decoding framework that applies to any linear block code. In the first stage, we run a low-complexity decoder to produce a candidate codeword and a cyclic redundancy check. When this stage succeeds, we terminate immediately. When it fails, we invoke a second-stage decoder, termed multipoint code-weight sphere decoding (MP-WSD). The central idea behind {MP-WSD} is to concentrate the ML search where it matters. We pre-compute a set of low-weight codewords and use them to generate structured local perturbations of the current estimate. Starting from the first-stage output, MP-WSD iteratively explores a small Euclidean sphere of candidate codewords formed by adding selected low-weight codewords, tightening the search region as better candidates are found. This design keeps the average complexity low: at high signal-to-noise ratio, the first stage succeeds with high probability and the second stage is rarely activated; when it is activated, the search remains localized. Simulation results show that the proposed decoder attains near-ML performance for short-blocklength, low-rate codes while maintaining low decoding latency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08501v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yubeen Jo, Geon Choi, Yongjune Kim, Namyoon Lee</dc:creator>
    </item>
    <item>
      <title>Reliable one-bit quantization of bandlimited graph data via single-shot noise shaping</title>
      <link>https://arxiv.org/abs/2602.08669</link>
      <description>arXiv:2602.08669v1 Announce Type: new 
Abstract: Graph data are ubiquitous in natural sciences and machine learning. In this paper, we consider the problem of quantizing graph structured, bandlimited data to few bits per entry while preserving its information under low-pass filtering. We propose an efficient single-shot noise shaping method that achieves state-of-the-art performance and comes with rigorous error bounds. In contrast to existing methods it allows reliable quantization to arbitrary bit-levels including the extreme case of using a single bit per data coefficient.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08669v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Johannes Maly, Anna Veselovska</dc:creator>
    </item>
    <item>
      <title>Trellis codes with a good distance profile constructed from expander graphs</title>
      <link>https://arxiv.org/abs/2602.08718</link>
      <description>arXiv:2602.08718v1 Announce Type: new 
Abstract: We derive Singleton-type bounds on the free distance and column distances of trellis codes. Our results show that, at a given time instant, the maximum attainable column distance of trellis codes can exceed that of convolutional codes. Moreover, using expander graphs, we construct trellis codes over constant-size alphabets that achieve a rate-distance trade-off arbitrarily close to that of convolutional codes with a maximum distance profile. By comparison, all known constructions of convolutional codes with a maximum distance profile require working over alphabets whose size grows at least exponentially with the number of output symbols per time instant.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08718v1</guid>
      <category>cs.IT</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yubin Zhu, Zitan Chen</dc:creator>
    </item>
    <item>
      <title>Clique-Based Deletion-Correcting Codes via Penalty-Guided Clique Search</title>
      <link>https://arxiv.org/abs/2602.08952</link>
      <description>arXiv:2602.08952v1 Announce Type: new 
Abstract: We study the construction of $d$-deletion-correcting binary codes by formulating the problem as a Maximum Clique Problem (MCP). In this formulation, vertices represent candidate codewords and edges connect pairs whose longest common subsequence (LCS) distance guarantees correction of up to $d$ deletions. A valid codebook corresponds to a clique in the resulting graph, and finding the largest codebook is equivalent to identifying a maximum clique. While MCP-based formulations for deletion-correcting codes have previously been explored, we demonstrate that applying Penalty-Guided Clique Search (PGCS), a lightweight stochastic clique-search heuristic inspired by Dynamic Local Search (DLS), consistently yields larger codebooks than existing graph-based heuristics, including minimum-degree and coloring methods, for block lengths $n = 8,9,\dots,14$ and deletion parameters $d = 1,2,3$. In several finite-length regimes, the resulting codebooks match known optimal sizes and outperform classical constructions such as Helberg codes. For decoding under segmented reception, where codeword boundaries are known, we propose an optimized LCS-based decoder that exploits symbol-count filtering and early termination to substantially reduce the number of LCS evaluations while preserving exact decoding guarantees. These optimizations lead to significantly lower average-case decoding complexity than the baseline $O(|C| n^2)$ approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08952v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aniruddh Pandav, Rajshekhar V Bhat</dc:creator>
    </item>
    <item>
      <title>Code-Weight Sphere Decoding</title>
      <link>https://arxiv.org/abs/2508.19631</link>
      <description>arXiv:2508.19631v3 Announce Type: cross 
Abstract: Ultra-reliable low-latency communications (URLLC) demand high-performance error-correcting codes and decoders in the finite blocklength regime. This letter introduces a novel two-stage near-maximum likelihood (near-ML) decoding framework applicable to any linear block code. Our approach first employs a low-complexity initial decoder. If this initial stage fails a cyclic redundancy check, it triggers a second stage: the proposed code-weight sphere decoding (WSD). WSD iteratively refines the codeword estimate by exploring a localized sphere of candidates constructed from pre-computed low-weight codewords. This strategy adaptively minimizes computational overhead at high signal-to-noise ratios while achieving near-ML performance, especially for low-rate codes. Extensive simulations demonstrate that our two-stage decoder provides an excellent trade-off between decoding reliability and complexity, establishing it as a promising solution for next-generation URLLC systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.19631v3</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yubeen Jo, Geon Choi, Yongjune Kim, Namyoon Lee</dc:creator>
    </item>
    <item>
      <title>Deep Reinforcement Learning for Interference Suppression in RIS-Aided Space-Air-Ground Integrated Networks</title>
      <link>https://arxiv.org/abs/2602.06982</link>
      <description>arXiv:2602.06982v1 Announce Type: cross 
Abstract: Future 6G networks envision ubiquitous connectivity through space-air-ground integrated networks (SAGINs), where high-altitude platform stations (HAPSs) and satellites complement terrestrial systems to provide wide-area, low-latency coverage. However, the rapid growth of terrestrial devices intensifies spectrum sharing between terrestrial and non-terrestrial segments, resulting in severe cross-tier interference. In particular, frequency sharing between the HAPS satellite uplink and HAPS ground downlink improves spectrum efficiency but suffers from interference caused by the HAPS antenna back-lobe. Existing approaches relying on zero-forcing (ZF) codebooks have limited performance under highly dynamic channel conditions. To overcome this limitation, we employ a reconfigurable intelligent surface (RIS)-aided HAPS-based SAGIN framework with a deep deterministic policy gradient (DDPG) algorithm. The proposed DDPG framework optimizes the HAPS beamforming weights to form spatial nulls toward interference sources while maintaining robust links to the desired signals. Simulation results demonstrate that the DDPG framework consistently outperforms conventional ZF beamforming among different RIS configurations, achieving up to \(11.3\%\) throughput improvement for a \(4\times4\) RIS configuration, validating its adaptive capability to enhance spectral efficiency in dynamic HAPS-based SAGINs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.06982v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pujitha Mamillapalli, Shikhar Verma, Tiago Koketsu Rodrigues, Abhinav Kumar</dc:creator>
    </item>
    <item>
      <title>When Simultaneous Localization and Mapping Meets Wireless Communications: A Survey</title>
      <link>https://arxiv.org/abs/2602.06995</link>
      <description>arXiv:2602.06995v1 Announce Type: cross 
Abstract: The availability of commercial wireless communication and sensing equipment combined with the advancements in intelligent autonomous systems paves the way towards robust joint communications and simultaneous localization and mapping (SLAM). This paper surveys the state-of-the-art in the nexus of SLAM and Wireless Communications, attributing the bidirectional impact of each with a focus on visual SLAM (V-SLAM) integration. We provide an overview of key concepts related to wireless signal propagation, geometric channel modeling, and radio frequency (RF)-based localization and sensing. In addition to this, we show image processing techniques that can detect landmarks, proactively predicting optimal paths for wireless channels. Several dimensions are considered, including the prerequisites, techniques, background, and future directions and challenges of the intersection between SLAM and wireless communications. We analyze mathematical approaches such as probabilistic models, and spatial methods for signal processing, as well as key technological aspects. We expose techniques and items towards enabling a highly effective retrieval of the autonomous robot state. Among other interesting findings, we observe that monocular V-SLAM would benefit from RF relevant information, as the latter can serve as a proxy for the scale ambiguity resolution. Conversely, we find that wireless communications in the context of 5G and beyond can potentially benefit from visual odometry that is central in SLAM. Moreover, we examine other sources besides the camera for SLAM and describe the twofold relation with wireless communications. Finally, integrated solutions performing joint communications and SLAM are still in their infancy: theoretical and practical advancements are required to add higher-level localization and semantic perception capabilities to RF and multi-antenna technologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.06995v1</guid>
      <category>cs.RO</category>
      <category>cs.CV</category>
      <category>cs.IT</category>
      <category>cs.MA</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Konstantinos Gounis, Sotiris A. Tegos, Dimitrios Tyrovolas, Panagiotis D. Diamantoulakis, George K. Karagiannidis</dc:creator>
    </item>
    <item>
      <title>OTFS-based Integrated Positioning and Communication Systems with Low-Resolution ADCs</title>
      <link>https://arxiv.org/abs/2602.07001</link>
      <description>arXiv:2602.07001v1 Announce Type: cross 
Abstract: This paper proposes a two-phase orthogonal time frequency space (OTFS)-based integrated positioning and communication (IPAC) framework under realistic low-resolution analog-to-digital converters (ADCs). In the uplink phase, the positioning signal is used to estimate channel parameters, which are subsequently used to determine the user's position. The spatial smoothing-multiple signal classification algorithm is introduced to estimate the angle-of-arrival, whereas an iterative interference cancellation scheme is conceived for the remaining parameters' estimation. The corresponding Cramer-Rao lower bounds of channel parameters and user position are also derived. During the downlink communication phase, the estimated parameters are exploited to improve beamforming at the base station. Simulation results evaluate the impact of ADC quantizer resolutions. Specifically, it is shown that enhanced downlink bit error rate performance can be achieved with improved uplink positioning, while the use of low-resolution ADCs induces noticeable performance degradation in the OTFS-IPAC system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07001v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yueyi Yang, Zeping Sui, Zilong Liu, Leila Musavian</dc:creator>
    </item>
    <item>
      <title>Information Theory: An X-ray Microscopy Perspective</title>
      <link>https://arxiv.org/abs/2602.07168</link>
      <description>arXiv:2602.07168v1 Announce Type: cross 
Abstract: X-ray microscopy (XRM) is commonly used to obtain three-dimensional information on internal microstructure, but the imaging pipeline introduces noise, redundancy and information loss at multiple stages. This paper treats the XRM workflow as an information-processing system acting on a finite information budget. Using entropy, mutual information and Kullback-Leibler divergence, we quantify how acquisition, denoising, alignment, sparse-angle sampling, dose variation and reconstruction reshape the statistical structure of projection data and reconstructed volumes. Case studies based on the Walnut 1 dataset illustrate how these processes redistribute information and impose bottlenecks. We summarise the workflow using a unified information budget and show that mutual information provides a reconstruction-agnostic indicator of fidelity, supporting quantitative comparison and optimisation of XRM protocols, particularly under low-dose or time-constrained conditions</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07168v1</guid>
      <category>eess.IV</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>physics.ins-det</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Charles Wood</dc:creator>
    </item>
    <item>
      <title>An Information-Theoretic Framework for Comparing Voice and Text Explainability</title>
      <link>https://arxiv.org/abs/2602.07179</link>
      <description>arXiv:2602.07179v1 Announce Type: cross 
Abstract: Explainable Artificial Intelligence (XAI) aims to make machine learning models transparent and trustworthy, yet most current approaches communicate explanations visually or through text. This paper introduces an information theoretic framework for analyzing how explanation modality specifically, voice versus text affects user comprehension and trust calibration in AI systems. The proposed model treats explanation delivery as a communication channel between model and user, characterized by metrics for information retention, comprehension efficiency (CE), and trust calibration error (T CE). A simulation framework implemented in Python was developed to evaluate these metrics using synthetic SHAP based feature attributions across multiple modality style configurations (brief, detailed, and analogy based). Results demonstrate that text explanations achieve higher comprehension efficiency, while voice explanations yield improved trust calibration, with analogy based delivery achieving the best overall trade off. This framework provides a reproducible foundation for designing and benchmarking multimodal explainability systems and can be extended to empirical studies using real SHAP or LIME outputs on open datasets such as the UCI Credit Approval or Kaggle Financial Transactions datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07179v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mona Rajhans, Vishal Khawarey</dc:creator>
    </item>
    <item>
      <title>ArcMark: Multi-bit LLM Watermark via Optimal Transport</title>
      <link>https://arxiv.org/abs/2602.07235</link>
      <description>arXiv:2602.07235v1 Announce Type: cross 
Abstract: Watermarking is an important tool for promoting the responsible use of language models (LMs). Existing watermarks insert a signal into generated tokens that either flags LM-generated text (zero-bit watermarking) or encodes more complex messages (multi-bit watermarking). Though a number of recent multi-bit watermarks insert several bits into text without perturbing average next-token predictions, they largely extend design principles from the zero-bit setting, such as encoding a single bit per token. Notably, the information-theoretic capacity of multi-bit watermarking -- the maximum number of bits per token that can be inserted and detected without changing average next-token predictions -- has remained unknown. We address this gap by deriving the first capacity characterization of multi-bit watermarks. Our results inform the design of ArcMark: a new watermark construction based on coding-theoretic principles that, under certain assumptions, achieves the capacity of the multi-bit watermark channel. In practice, ArcMark outperforms competing multi-bit watermarks in terms of bit rate per token and detection accuracy. Our work demonstrates that LM watermarking is fundamentally a channel coding problem, paving the way for principled coding-theoretic approaches to watermark design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07235v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Atefeh Gilani, Carol Xuan Long, Sajani Vithana, Oliver Kosut, Lalitha Sankar, Flavio P. Calmon</dc:creator>
    </item>
    <item>
      <title>Performance Evaluation of V2X Communication Using Large-Scale Traffic Data</title>
      <link>https://arxiv.org/abs/2602.07244</link>
      <description>arXiv:2602.07244v1 Announce Type: cross 
Abstract: Vehicular communication (V2X) technologies are widely regarded as a cornerstone for cooperative and automated driving, yet their large-scale real-world deployment remains limited. As a result, understanding V2X performance under realistic, full-scale traffic conditions continues to be relevant. Most existing performance evaluations rely on synthetic traffic scenarios generated by simulators, which, while useful, may not fully capture the features of real-world traffic. In this paper, we present a large-scale, data-driven evaluation of V2X communication performance using real-world traffic datasets. Vehicle trajectories derived from the Highway Drone (HighD) and Intersection Drone (InD) datasets are converted into simulation-ready formats and coupled with a standardized V2X networking stack to enable message-level performance analysis for entire traffic populations comprising over hundred thousands vehicles across multiple locations. We evaluate key V2X performance indicators, including inter-generation gap, inter-packet gap, packet delivery ratio, and channel busy ratio, across both highway and urban intersection environments. Our results show that cooperative awareness services remain feasible at scale under realistic traffic conditions. In addition, the findings highlight how traffic density, mobility patterns, and communication range influence V2X performance and how synthetic traffic assumptions may overestimate channel congestion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07244v1</guid>
      <category>cs.NI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>John Pravin Arockiasamy, Alexey Vinel</dc:creator>
    </item>
    <item>
      <title>ODELoRA: Training Low-Rank Adaptation by Solving Ordinary Differential Equations</title>
      <link>https://arxiv.org/abs/2602.07479</link>
      <description>arXiv:2602.07479v1 Announce Type: cross 
Abstract: Low-rank adaptation (LoRA) has emerged as a widely adopted parameter-efficient fine-tuning method in deep transfer learning, due to its reduced number of trainable parameters and lower memory requirements enabled by Burer-Monteiro factorization on adaptation matrices. However, classical LoRA training methods treat the low-rank factor matrices individually and optimize them using standard gradient-based algorithms. Such decoupled optimization schemes are theoretically and empirically suboptimal, as they fail to fully exploit the intrinsic structure of the LoRA parameterization. In this work, we propose a novel continuous-time optimization dynamic for LoRA factor matrices in the form of an ordinary differential equation (ODE) that emulates the gradient flow of full fine-tuning on the balanced manifold. We term this approach ODELoRA. To faithfully track the trajectories of ODELoRA, we adopt well-established and theoretically grounded time-discretization schemes, including Euler and Runge--Kutta methods. Our framework provides a unified ODE-based perspective for understanding and designing LoRA training algorithms. We establish linear convergence of the proposed method under strongly convex objectives for certain discretization schemes under mild conditions, and further extend our analysis to the matrix sensing setting. Moreover, we show that ODELoRA achieves stable feature learning, a property that is crucial for training deep neural networks at different scales of problem dimensionality. Empirical results on matrix sensing tasks confirm the derived linear convergence behavior, and experiments on training physics-informed neural networks further demonstrate the superiority of ODELoRA over existing baselines, especially in the training stability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07479v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yihang Gao, Vincent Y. F. Tan</dc:creator>
    </item>
    <item>
      <title>Don't Always Pick the Highest-Performing Model: An Information Theoretic View of LLM Ensemble Selection</title>
      <link>https://arxiv.org/abs/2602.08003</link>
      <description>arXiv:2602.08003v1 Announce Type: cross 
Abstract: Large language models (LLMs) are often ensembled together to improve overall reliability and robustness, but in practice models are strongly correlated. This raises a fundamental question: which models should be selected when forming an LLM ensemble? We formulate budgeted ensemble selection as maximizing the mutual information between the true label and predictions of the selected models. Furthermore, to explain why performance can saturate even with many models, we model the correlated errors of the models using Gaussian-copula and show an information-theoretic error floor for the performance of the ensemble. Motivated by these, we propose a simple greedy mutual-information selection algorithm that estimates the required information terms directly from data and iteratively builds an ensemble under a query budget. We test our approach in two question answering datasets and one binary sentiment classification dataset: MEDMCQA, MMLU, and IMDB movie reviews. Across all datasets, we observe that our method consistently outperforms strong baselines under the same query budget.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08003v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yigit Turkmen, Baturalp Buyukates, Melih Bastopcu</dc:creator>
    </item>
    <item>
      <title>Fundamental Limits of Community Detection in Contextual Multi-Layer Stochastic Block Models</title>
      <link>https://arxiv.org/abs/2602.08173</link>
      <description>arXiv:2602.08173v1 Announce Type: cross 
Abstract: We consider the problem of community detection from the joint observation of a high-dimensional covariate matrix and $L$ sparse networks, all encoding noisy, partial information about the latent community labels of $n$ subjects. In the asymptotic regime where the networks have constant average degree and the number of features $p$ grows proportionally with $n$, we derive a sharp threshold under which detecting and estimating the subject labels is possible. Our results extend the work of \cite{MN23} to the constant-degree regime with noisy measurements, and also resolve a conjecture in \cite{YLS24+} when the number of networks is a constant.
  Our information-theoretic lower bound is obtained via a novel comparison inequality between Bernoulli and Gaussian moments, as well as a statistical variant of the ``recovery to chi-square divergence reduction'' argument inspired by \cite{DHSS25}. On the algorithmic side, we design efficient algorithms based on counting decorated cycles and decorated paths and prove that they achieve the sharp threshold for both detection and weak recovery. In particular, our results show that there is no statistical-computational gap in this setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08173v1</guid>
      <category>math.ST</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuyang Gong, Dong Huang, Zhangsong Li</dc:creator>
    </item>
    <item>
      <title>Asymptotically Minimax Robust Likelihood Ratio Test</title>
      <link>https://arxiv.org/abs/2602.08174</link>
      <description>arXiv:2602.08174v1 Announce Type: cross 
Abstract: This paper develops a unified framework for asymptotically minimax robust hypothesis testing under distributional uncertainty, applicable to both Bayesian and Neyman--Pearson formulations (Type-I and Type-II). Uncertainty classes based on the KL-divergence, $\alpha$-divergence, and its symmetrized variant are considered. Using Sion's minimax theorem and Karush-Kuhn-Tucker conditions, the existence and uniqueness of the resulting robust tests are established. The least favorable distributions and corresponding robust likelihood ratio functions are derived in closed parametric forms, enabling computation via systems of nonlinear equations. It is proven that Dabak's approach does not yield an asymptotically minimax robust test. The proposed theory generalizes earlier work by offering a more systematic and comprehensive derivation of robust tests. Numerical simulations confirm the theoretical results and illustrate the behavior of the derived robust tests.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08174v1</guid>
      <category>math.ST</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.TH</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>G\"okhan G\"ul</dc:creator>
    </item>
    <item>
      <title>Characterizations of Conditional Mutual Independence: Equivalence and Implication</title>
      <link>https://arxiv.org/abs/2602.08279</link>
      <description>arXiv:2602.08279v1 Announce Type: cross 
Abstract: Conditional independence, and more generally conditional mutual independence, are central notions in probability theory. In their general forms, they include functional dependence as a special case. In this paper, we tackle two fundamental problems related to conditional mutual independence. Let $K$ and $K'$ be two conditional mutual independncies (CMIs) defined on a finite set of discrete random variables. We have obtained a necessary and sufficient condition for i) $K$ is equivalent to $K'$; ii) $K$ implies $K'$. These characterizations are in terms of a canonical form introduced for conditional mutual independence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08279v1</guid>
      <category>math.PR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Laigang Guo, Tao Guo, Raymond W. Yeung</dc:creator>
    </item>
    <item>
      <title>Near-Oracle KV Selection via Pre-hoc Sparsity for Long-Context Inference</title>
      <link>https://arxiv.org/abs/2602.08329</link>
      <description>arXiv:2602.08329v1 Announce Type: cross 
Abstract: A core bottleneck in large language model (LLM) inference is the cost of attending over the ever-growing key-value (KV) cache. Although near-oracle top-k KV selection can preserve the quality of dense attention while sharply reducing computation and bandwidth, existing sparse methods generally rely on posterior heuristics, i.e., selectors conditioned on observed attention or proxy scores. Such conditioning introduces posterior bias: it tends to distort true token importance and miss salient tokens, thereby impairing long-range reasoning. To tackle this problem, we propose Pre-hoc Sparsity (PrHS), which selects KV entries before attention scoring and provides explicit accuracy control. Let the attention mass of discarded entries be delta (the dropped mass). Through a marginal-to-mutual-information analysis, we derive an upper bound on the mutual-information loss that depends only on the dropped mass. This relation explains failure modes of posterior heuristics and enables verifiable guarantees by controlling the dropped mass in advance. Within PrHS, we instantiate three orthogonal pre-hoc selectors along the axes of time, depth, and layer. Extensive experiments on LLaMA and Mistral families validate PrHS. Across GSM8K and CoQA, PrHS reduces retrieval overhead by over 90%, achieving 3x higher retrieval sparsity than HShare at matched or better accuracy. It incurs under 1% average degradation on LongBench, lowers attention FLOPs by about 15% versus prior sparse baselines, and yields a 9.9x speedup in attention-operator latency and 2.8x higher throughput on NVIDIA A100-80GB GPUs than the dense baseline.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08329v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yifei Gao, Lei Wang, Rong-Cheng Tu, Qixin Zhang, Jun Cheng, Dacheng Tao</dc:creator>
    </item>
    <item>
      <title>The Redundancy of Non-Singular Channel Simulation</title>
      <link>https://arxiv.org/abs/2501.14053</link>
      <description>arXiv:2501.14053v3 Announce Type: replace 
Abstract: Channel simulation is an alternative to quantization and entropy coding for performing lossy source coding. Recently, channel simulation has gained significant traction in both the machine learning and information theory communities, as it integrates better with machine learning-based data compression algorithms and has better rate-distortion-perception properties than quantization. As the practical importance of channel simulation increases, it is vital to understand its fundamental limitations. Recently, Sriramu and Wagner provided an almost complete characterisation of the redundancy of channel simulation algorithms. In this paper, we complete this characterisation. First, we significantly extend a result of Li and El Gamal, and show that the redundancy of any instance of a channel simulation problem is lower bounded by the channel simulation divergence. Second, we give two proofs that the asymptotic redundancy of simulating iid non-singular channels is lower-bounded by $1/2$: one using a direct approach based on the asymptotic expansion of the channel simulation divergence and one using large deviations theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14053v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gergely Flamich, Sharang M. Sriramu, Aaron B. Wagner</dc:creator>
    </item>
    <item>
      <title>From Freshness to Effectiveness: Goal-Oriented Sampling for Remote Decision Making</title>
      <link>https://arxiv.org/abs/2504.19507</link>
      <description>arXiv:2504.19507v3 Announce Type: replace 
Abstract: Data freshness, measured by Age of Information (AoI), is highly relevant in networked applications such as Vehicle to Everything (V2X), smart health systems, and Industrial Internet of Things (IIoT). However, freshness alone does not always equate to utility in decision-making. In decision-critical settings, some stale data may be more valuable than fresh updates. Motivated by this, we move beyond AoI-centric policies and investigate how data staleness affects remote decision-making effectiveness under random delay and limited communication resources. To this end, we propose AR-MDP, an Age-aware Remote Markov Decision Process framework, which co-designs optimal sampling and remote decision-making under a sampling frequency constraint and random delay. To efficiently solve this problem, we design a new two-stage hierarchical algorithm, namely Quick Bellman-Linear-Program (QuickBLP), where the first stage involves solving the Dinkelbach root of a Bellman variant and the second stage involves solving a streamlined linear program (LP). For the tricky first stage, we propose a new One-layer Primal-Dinkelbach Synchronous Iteration (OnePDSI) method, which overcomes the re-convergence and non-expansive divergence present in existing per-sample multi-layer algorithms. Through rigorous convergence analysis of our proposed algorithms, we establish that the worst-case optimality gap in OnePDSI exhibits exponential decay with respect to iteration $K$ at a rate of $\mathcal{O}(\frac{1}{R^K})$. Through sensitivity analysis, we derive a threshold for the sampling frequency, beyond which additional sampling does not yield further gains in decision-making. Simulation results validate our analyses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19507v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aimin Li, Shaohua Wu, Gary C. F. Lee, Sumei Sun</dc:creator>
    </item>
    <item>
      <title>Data Compression with Relative Entropy Coding</title>
      <link>https://arxiv.org/abs/2506.16309</link>
      <description>arXiv:2506.16309v3 Announce Type: replace 
Abstract: Over the last few years, machine learning unlocked previously infeasible features for compression, such as providing guarantees for users' privacy or tailoring compression to specific data statistics (e.g., satellite images or audio recordings of animals) or users' audiovisual perception. This, in turn, has led to an explosion of theoretical investigations and insights that aim to develop new fundamental theories, methods and algorithms better suited for machine learning-based compressors.
  In this thesis, I contribute to this trend by investigating relative entropy coding, a mathematical framework that generalises classical source coding theory. Concretely, relative entropy coding deals with the efficient communication of uncertain or randomised information. One of its key advantages is that it extends compression methods to continuous spaces and can thus be integrated more seamlessly into modern machine learning pipelines than classical quantisation-based approaches. Furthermore, it is a natural foundation for developing advanced compression methods that are privacy-preserving or account for the perceptual quality of the reconstructed data.
  The thesis considers relative entropy coding at three conceptual levels: After introducing the basics of the framework, (1) I prove results that provide new, maximally tight fundamental limits to the communication and computational efficiency of relative entropy coding; (2) I use the theory of Poisson point processes to develop and analyse new relative entropy coding algorithms, whose performance attains the theoretic optima and (3) I showcase the strong practical performance of relative entropy coding by applying it to image, audio, video and protein data compression using small, energy-efficient, probabilistic neural networks called Bayesian implicit neural representations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16309v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.17863/CAM.118972</arxiv:DOI>
      <dc:creator>Gergely Flamich</dc:creator>
    </item>
    <item>
      <title>The Universal Language of Mathematics (Introduction to Binary Principle)</title>
      <link>https://arxiv.org/abs/2512.11279</link>
      <description>arXiv:2512.11279v3 Announce Type: replace 
Abstract: This book invites readers to see mathematics not just as formulas and rules, but as the deepest expression of human thought. It begins by exploring the timeless idea of mathematics as a universal language, contrasting its precision with the richness of natural speech. From the foundations of pure and applied mathematics to the revolutionary insights of Claude Shannon's information theory, the narrative shows how numbers, symbols, and structures have shaped science, technology, and communication. At the heart of the work lies the Binary Principle -- the idea that zero and one are not merely digits, but primitive building blocks of all mathematical reasoning. By treating absence and presence as fundamental units, the book reveals how complex theories and applications emerge from the simplest distinctions. This perspective makes mathematics more intuitive, more engaging, and more accessible, transforming how it can be taught and understood. Discover the Binary Principle: Mathematics as the True Universal Language. This book invites readers to see mathematics not just as formulas and rules, but as the deepest expression of human thought.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11279v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bruno Macchiavello</dc:creator>
    </item>
    <item>
      <title>A Local Characterization of $f$-Divergences Yielding PSD Mutual-Information Matrices</title>
      <link>https://arxiv.org/abs/2601.08929</link>
      <description>arXiv:2601.08929v2 Announce Type: replace 
Abstract: We study when the variable-indexed matrix of pairwise $f$-mutual informations $M^{(f)}_{ij} = I_f(X_i;X_j)$ is positive semidefinite (PSD). Let $f:(0,\infty)\to R$ be convex with $f(1)=0$, finite in a neighborhood of $1$, and with $f(0)&lt;\infty$ so that diagonal terms are finite. We give a sharp local characterization around independence: there exists $\delta=\delta(f)&gt;0$ such that for every $n$ and every finite-alphabet family $(X_1,\ldots,X_n)$ whose pairwise joint-to-product ratios lie in $(1-\delta,1+\delta)$, the matrix $M^{(f)}$ is PSD if and only if $f$ is analytic at $1$ with a convergent expansion $f(t)=\sum_{m\ge 2} a_m (t-1)^m$ and $a_m\ge 0$ on a neighborhood of $1$. Consequently, any negative Taylor coefficient yields an explicit finite-alphabet counterexample under arbitrarily weak dependence, and non-analytic convex divergences (e.g., total variation) are excluded. This PSD requirement is distinct from Hilbertian or metric properties of divergences between distributions (e.g., $\sqrt{JS}$): we study PSD of the variable-indexed mutual-information matrix. The proof combines a replica embedding that turns monomial terms into Gram matrices with a replica-forcing reduction to positive-definite dot-product kernels, enabling an application of the Schoenberg--Berg--Christensen--Ressel classification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08929v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zachary Robertson</dc:creator>
    </item>
    <item>
      <title>An Elementary Approach to Scheduling in Generative Diffusion Models</title>
      <link>https://arxiv.org/abs/2601.13602</link>
      <description>arXiv:2601.13602v2 Announce Type: replace 
Abstract: An elementary approach to characterizing the impact of noise scheduling and time discretization in generative diffusion models is developed. We first utilize the Cram\'er-Rao bound to identify the Gaussian setting as a fundamental performance limit, necessitating its study as a reference. Building on this insight, we consider a simplified model in which the source distribution is a multivariate Gaussian with a given covariance matrix, together with the deterministic reverse sampling process. The explicit closed-form evolution trajectory of the distributions across reverse sampling steps is derived, and consequently, the Kullback-Leibler (KL) divergence between the source distribution and the reverse sampling output is obtained. The effect of the number of time discretization steps on the convergence of this KL divergence is studied via the Euler-Maclaurin expansion. An optimization problem is formulated, and its solution noise schedule is obtained via calculus of variations, shown to follow a tangent law whose coefficient is determined by the eigenvalues of the source covariance matrix. For an alternative scenario, more realistic in practice, where pretrained models have been obtained for some given noise schedules, the KL divergence also provides a measure to compare different time discretization strategies in reverse sampling. Experiments across different datasets and pretrained models demonstrate that the time discretization strategy selected by our approach consistently outperforms baseline and search-based strategies, particularly when the budget on the number of function evaluations is very tight.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.13602v2</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiang Sun, H. Vincent Poor, Wenyi Zhang</dc:creator>
    </item>
    <item>
      <title>Enabling Large-Scale Channel Sounding for 6G: A Framework for Sparse Sampling and Multipath Component Extraction</title>
      <link>https://arxiv.org/abs/2602.05405</link>
      <description>arXiv:2602.05405v2 Announce Type: replace 
Abstract: Realizing the 6G vision of artificial intelligence (AI) and integrated sensing and communication (ISAC) critically requires large-scale real-world channel datasets for channel modeling and data-driven AI models. However, traditional frequency-domain channel sounding methods suffer from low efficiency due to a prohibitive number of frequency points to avoid delay ambiguity. This paper proposes a novel channel sounding framework involving sparse nonuniform sampling along with a likelihood-rectified space-alternating generalized expectation-maximization (LR-SAGE) algorithm for multipath component extraction. This framework enables the acquisition of channel datasets that are tens or even hundreds of times larger within the same channel measurement duration, thereby providing the massive data required to harness the full potential of AI scaling laws. Specifically, we propose a Parabolic Frequency Sampling (PFS) strategy that non-uniformly distributes frequency points, effectively eliminating delay ambiguity while reducing sampling overhead by orders of magnitude. To efficiently extract multipath components (MPCs) from the channel data measured by PFS, we develop a LR-SAGE algorithm, rectifying the likelihood distortion caused by nonuniform sampling and molecular absorption effect. Simulation results and experimental validation at 280--300~GHz confirm that the proposed PFS and LR-SAGE algorithm not only achieve 50$\times$ faster measurement, a 98\% reduction in data volume and a 99.96\% reduction in post-processing computational complexity, but also successfully captures MPCs and channel characteristics consistent with traditional exhaustive measurements, demonstrating its potential as a fundamental enabler for constructing the massive ISAC datasets required by AI-native 6G systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05405v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yi Chen, Mling Li, Chong Han</dc:creator>
    </item>
    <item>
      <title>Explicit List-Decodable Linearized Reed-Solomon and Folded Linearized Reed-Solomon Subcodes</title>
      <link>https://arxiv.org/abs/2602.05462</link>
      <description>arXiv:2602.05462v2 Announce Type: replace 
Abstract: The sum-rank metric is the mixture of the Hamming and rank metrics. The sum-rank metric found its application in network coding, locally repairable codes, space-time coding, and quantum-resistant cryptography. Linearized Reed-Solomon (LRS) codes are the sum-rank analogue of Reed-Solomon codes and strictly generalize both Reed-Solomon and Gabidulin codes.
  In this work, we construct an explicit family of $\mathbb{F}_h$-linear sum-rank metric codes over arbitrary fields $\mathbb{F}_h$. Our construction enables efficient list decoding up to a fraction $\rho$ of errors in the sum-rank metric with rate $1-\rho-\varepsilon$, for any desired $\rho \in (0,1)$ and $\varepsilon&gt;0$. Our codes are subcodes of LRS codes, obtained by restricting message polynomials to an $\mathbb{F}_h$-subspace derived from subspace designs, and the decoding list size is bounded by $h^{\mathrm{poly}(1/\varepsilon)}$.
  Beyond the standard LRS setting, we further extend our linear-algebraic decoding framework to folded Linearized Reed-Solomon (FLRS) codes. We show that folded evaluations satisfy appropriate interpolation conditions and that the corresponding solution space forms a low-dimensional, structured affine subspace. This structure enables effective control of the list size and yields the first explicit positive-rate FLRS subcodes that are efficiently list decodable beyond the unique-decoding radius. To the best of our knowledge, this also constitutes the first explicit construction of positive-rate sum-rank metric codes that admit efficient list decoding beyond the unique decoding radius, thereby providing a new general framework for constructing efficiently decodable codes under the sum-rank metric.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05462v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kuo Shang, Chen Yuan, Ruiqi Zhu</dc:creator>
    </item>
    <item>
      <title>CoinPress: Practical Private Mean and Covariance Estimation</title>
      <link>https://arxiv.org/abs/2006.06618</link>
      <description>arXiv:2006.06618v3 Announce Type: replace-cross 
Abstract: We present simple differentially private estimators for the mean and covariance of multivariate sub-Gaussian data that are accurate at small sample sizes. We demonstrate the effectiveness of our algorithms both theoretically and empirically using synthetic and real-world datasets -- showing that their asymptotic error rates match the state-of-the-art theoretical bounds, and that they concretely outperform all previous methods. Specifically, previous estimators either have weak empirical accuracy at small sample sizes, perform poorly for multivariate data, or require the user to provide strong a priori estimates for the parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2006.06618v3</guid>
      <category>stat.ML</category>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sourav Biswas, Yihe Dong, Gautam Kamath, Jonathan Ullman</dc:creator>
    </item>
    <item>
      <title>Nearly-Linear Time Seeded Extractors with Short Seeds</title>
      <link>https://arxiv.org/abs/2411.07473</link>
      <description>arXiv:2411.07473v2 Announce Type: replace-cross 
Abstract: Seeded extractors are fundamental objects in pseudorandomness and cryptography, and a deep line of work has designed polynomial-time seeded extractors with nearly-optimal parameters. However, existing constructions of seeded extractors with short seed length and large output length run in time $\Omega(n \log(1/\varepsilon))$ and often slower, where $n$ is the input source length and $\varepsilon$ is the error of the extractor. Since cryptographic applications of extractors require $\varepsilon$ to be small, the resulting runtime makes these extractors impractical.
  Motivated by this, we explore constructions of strong seeded extractors with short seeds computable in nearly-linear time $O(n \log^c n)$, for any error $\varepsilon$. We show that an appropriate combination of modern condensers and classical approaches for constructing seeded extractors for high min-entropy sources yields such extractors. More precisely, we obtain strong extractors for $n$-bit sources with any min-entropy $k$ and any target error $\varepsilon$ with seed length $d=O(\log(n/\varepsilon))$ and output length $m=(1-\eta)k$ for an arbitrarily small constant $\eta&gt;0$, running in nearly-linear time. When $k$ or $\varepsilon$ are very small, our construction requires a reasonable one-time preprocessing step. These extractors directly yield privacy amplification protocols with nearly-linear time complexity (possibly after a one-time preprocessing step), large output length, and low communication complexity. As a second contribution, we give an instantiation of Trevisan's extractor that can be evaluated in truly linear time in the RAM model, as long as the number of output bits is at most $\frac{n}{\log(1/\varepsilon)polylog(n)}$. Previous fast implementations of Trevisan's extractor ran in $\widetilde{O}(n)$ time in this setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07473v2</guid>
      <category>cs.CC</category>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TIT.2025.3605160</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Information Theory, Volume 71, Issue 11, November 2025</arxiv:journal_reference>
      <dc:creator>Dean Doron, Jo\~ao Ribeiro</dc:creator>
    </item>
    <item>
      <title>FMMI: Flow Matching Mutual Information Estimation</title>
      <link>https://arxiv.org/abs/2511.08552</link>
      <description>arXiv:2511.08552v2 Announce Type: replace-cross 
Abstract: We introduce a novel Mutual Information (MI) estimator that fundamentally reframes the discriminative approach. Instead of training a classifier to discriminate between joint and marginal distributions, we learn a normalizing flow that transforms one into the other. This technique produces a computationally efficient and precise MI estimate that scales well to high dimensions and across a wide range of ground-truth MI values.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.08552v2</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ivan Butakov, Alexander Semenenko, Valeriya Kirova, Alexey Frolov, Ivan Oseledets</dc:creator>
    </item>
    <item>
      <title>A Design Framework that Unifies 6G Modulation Schemes for Double Selectivity</title>
      <link>https://arxiv.org/abs/2511.09418</link>
      <description>arXiv:2511.09418v2 Announce Type: replace-cross 
Abstract: There is significant recent interest in designing new modulation schemes for doubly-selective channels with large delay and Doppler spreads, where legacy modulation schemes based on time-frequency signal representations underperform. Multiple modulation schemes, e.g., in the delay-Doppler, chirp, time-sequency, and other domains, have been proposed in the literature for this purpose, with varying implementation details. In this letter, we establish that all previously proposed modulation schemes for doubly-selective signaling are instances of a single family of complex Hadamard-modulated pulse trains. When the delay and Doppler spread of the doubly-selective channel is limited to a certain support, all modulation schemes in this waveform family offer equivalent, full diversity achieving performance with no symbol fading and low channel estimation overhead. The existence of this waveform family also enables flexible, multi-waveform co-existence -- allowing a common transceiver architecture to generate multiple waveforms in the family, that may each be flexibly allocated to different users and services.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.09418v2</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nishant Mehrotra, Sandesh Rao Mattu, Robert Calderbank</dc:creator>
    </item>
    <item>
      <title>Trust Region Masking for Long-Horizon LLM Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2512.23075</link>
      <description>arXiv:2512.23075v3 Announce Type: replace-cross 
Abstract: Policy gradient methods for Large Language Models optimize a policy $\pi_\theta$ via a surrogate objective computed from samples of a rollout policy $\pi_{\text{roll}}$. However, modern LLM-RL pipelines suffer from unavoidable implementation divergences -- backend discrepancies, Mixture-of-Experts routing discontinuities, and distributed training staleness -- causing off-policy mismatch ($\pi_{\text{roll}} \neq \pi_\theta$) and approximation errors between the surrogate and the true objective. We demonstrate that classical trust region bounds on this error scale as $O(T^2)$ with sequence length $T$, rendering them vacuous for long-horizon tasks. To address this, we derive a family of bounds -- both KL-based and TV-based -- including a Pinsker-Marginal bound ($O(T^{3/2})$), a Mixed bound ($O(T)$), and an Adaptive bound that strictly generalizes the Pinsker-Marginal bound via per-position importance-ratio decomposition. Taking the minimum over all bounds yields the tightest known guarantee across all divergence regimes. Crucially, all bounds depend on the maximum token-level divergence $D_{\mathrm{KL}}^{\mathrm{tok,max}}$ (or $D_{\mathrm{TV}}^{\mathrm{tok,max}}$), a sequence-level quantity that cannot be controlled by token-independent methods like PPO clipping. We propose Trust Region Masking (TRM), which masks entire sequences violating the trust region, enabling the first non-vacuous monotonic improvement guarantees for long-horizon LLM-RL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23075v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yingru Li, Jiacai Liu, Jiawei Xu, Yuxuan Tong, Ziniu Li, Qian Liu, Baoxiang Wang</dc:creator>
    </item>
    <item>
      <title>Cell-Free Massive MIMO with Hardware-Impaired Wireless Fronthaul</title>
      <link>https://arxiv.org/abs/2601.06486</link>
      <description>arXiv:2601.06486v2 Announce Type: replace-cross 
Abstract: Cell-free massive MIMO (multiple-input multiple-output) enhances spectral and energy efficiency compared to conventional cellular networks by enabling joint transmission and reception across a large number of distributed access points (APs). Since these APs are envisioned to be low-cost and densely deployed, hardware impairments, stemming from non-ideal radio-frequency (RF) chains, are unavoidable. While existing studies primarily address hardware impairments on the access side, the impact of hardware impairments on the wireless fronthaul link has remained largely unexplored. In this work, we fill this important gap by introducing a novel amplify-and-forward (AF) based wireless fronthauling scheme tailored for cell-free massive MIMO. Focusing on the uplink, we develop an analytical framework that jointly models the hardware impairments at both the APs and the fronthaul transceivers, derives the resulting end-to-end distorted signal expression, and quantifies the individual contribution of each impairment to the spectral efficiency. Furthermore, we design distortion-aware linear combiners that optimally mitigate these effects. Numerical results demonstrate significant performance gains from distortion-aware processing and illustrate the potential of the proposed AF fronthauling scheme as a cost-effective enabler for future cell-free architectures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06486v2</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>\"Ozlem Tu\u{g}fe Demir, Emil Bj\"ornson</dc:creator>
    </item>
  </channel>
</rss>
