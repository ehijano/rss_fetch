<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 14 Oct 2025 03:09:45 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Unending Sequential Auctions</title>
      <link>https://arxiv.org/abs/2510.08742</link>
      <description>arXiv:2510.08742v1 Announce Type: new 
Abstract: Sequential auctions for identical items with unit-demand, private-value buyers are common and often occur periodically without end, as new bidders replace departing ones. We model bidder uncertainty by introducing a probability that a bidder must exit the auction in each period. Treating the sequential auction as a Markov process, we demonstrate the existence of a unique steady state.
  In the absence of uncertainty, the steady state resembles a posted-price mechanism: bidders with values above a threshold almost surely win items by repeatedly bidding the threshold price, while those below the threshold almost surely do not. The equilibrium price corresponds to the threshold value that balances supply (bidders with values above the threshold) and demand (auction winners).
  When uncertainty is introduced, the threshold value persists but becomes less precise, growing "fuzzier" as uncertainty increases. This uncertainty benefits low-value bidders, those below the threshold, by giving them a significant chance of winning. Surprisingly, high-value bidders also benefit from uncertainty, up to a certain value limit, as it lowers equilibrium bids and increases their expected utility. On the other hand, this bidder uncertainty often reduces the auctioneer's utility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08742v1</guid>
      <category>cs.GT</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Amir Ban</dc:creator>
    </item>
    <item>
      <title>Robust autobidding for noisy conversion prediction models</title>
      <link>https://arxiv.org/abs/2510.08788</link>
      <description>arXiv:2510.08788v1 Announce Type: new 
Abstract: Managing millions of digital auctions is an essential task for modern advertising auction systems. The main approach to managing digital auctions is an autobidding approach, which depends on the Click-Through Rate and Conversion Rate values. While these quantities are estimated with ML models, their prediction uncertainty directly impacts advertisers' revenue and bidding strategies. To address this issue, we propose RobustBid, an efficient method for robust autobidding taking into account uncertainty in CTR and CVR predictions. Our approach leverages advanced, robust optimization techniques to prevent large errors in bids if the estimates of CTR/CVR are perturbed. We derive the analytical solution of the stated robust optimization problem, which leads to the runtime efficiency of the RobustBid method. The synthetic, iPinYou, and BAT benchmarks are used in our experimental evaluation of RobustBid. We compare our method with the non-robust baseline and the RiskBid algorithm in terms of total conversion volume (TCV) and average cost-per-click ($CPC_{avg}$) performance metrics. The experiments demonstrate that RobustBid provides bids that yield larger TCV and smaller $CPC_{avg}$ than competitors in the case of large perturbations in CTR/CVR predictions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08788v1</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Andrey Pudovikov, Alexandra Khirianova, Ekaterina Solodneva, Gleb Molodtsov, Aleksandr Katrutsa, Yuriy Dorn, Egor Samosvat</dc:creator>
    </item>
    <item>
      <title>Measuring the Hidden Cost of Data Valuation through Collective Disclosure</title>
      <link>https://arxiv.org/abs/2510.08869</link>
      <description>arXiv:2510.08869v1 Announce Type: new 
Abstract: Data valuation methods assign marginal utility to each data point that has contributed to the training of a machine learning model. If used directly as a payout mechanism, this creates a hidden cost of valuation, in which contributors with near-zero marginal value would receive nothing, even though their data had to be collected and assessed. To better formalize this cost, we introduce a conceptual and game-theoretic model, the Information Disclosure Game, between a Data Union (sometimes also called a data trust), a member-run agent representing contributors, and a Data Consumer (e.g., a platform). After first aggregating members' data, the DU releases information progressively by adding Laplacian noise under a differentially-private mechanism. Through simulations with strategies guided by data Shapley values and multi-armed bandit exploration, we demonstrate on a Yelp review helpfulness prediction task that data valuation inherently incurs an explicit acquisition cost and that the DU's collective disclosure policy changes how this cost is distributed across members.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08869v1</guid>
      <category>cs.GT</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Patrick Mesana, Gilles Caporossi, Sebastien Gambs</dc:creator>
    </item>
    <item>
      <title>Approximately Bisubmodular Regret Minimization in Billboard and Social Media Advertising</title>
      <link>https://arxiv.org/abs/2510.09084</link>
      <description>arXiv:2510.09084v1 Announce Type: new 
Abstract: In a typical \emph{billboard advertisement} technique, a number of digital billboards are owned by an \emph{influence provider}, and several commercial houses approach the influence provider for a specific number of views of their advertisement content on a payment basis. If the influence provider provides the demanded or more influence, then he will receive the full payment else a partial payment. In the context of an influence provider, if he provides more or less than the advertisers demanded influence, it is a loss for him. This is formalized as 'Regret', and naturally, in the context of the influence provider, the goal will be to allocate the billboard slots among the advertisers such that the total regret is minimized. In this paper, we study this problem as a discrete optimization problem and propose two solution approaches. The first one selects the billboard slots from the available ones in an incremental greedy manner, and we call this method the Budget Effective Greedy approach. In the second one, we introduce randomness in the first one, where we do it for a sample of slots instead of calculating the marginal gains of all the billboard slots. We analyze both algorithms to understand their time and space complexity. We implement them with real-life datasets and conduct a number of experiments. We observe that the randomized budget effective greedy approach takes reasonable computational time while minimizing the regret.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.09084v1</guid>
      <category>cs.GT</category>
      <category>cs.DB</category>
      <category>cs.DS</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dildar Ali, Suman Benerjee, Yamuna Prasad</dc:creator>
    </item>
    <item>
      <title>GRPO-GCC: Enhancing Cooperation in Spatial Public Goods Games via Group Relative Policy Optimization with Global Cooperation Constraint</title>
      <link>https://arxiv.org/abs/2510.08607</link>
      <description>arXiv:2510.08607v1 Announce Type: cross 
Abstract: Inspired by the principle of self-regulating cooperation in collective institutions, we propose the Group Relative Policy Optimization with Global Cooperation Constraint (GRPO-GCC) framework. This work is the first to introduce GRPO into spatial public goods games, establishing a new deep reinforcement learning baseline for structured populations. GRPO-GCC integrates group relative policy optimization with a global cooperation constraint that strengthens incentives at intermediate cooperation levels while weakening them at extremes. This mechanism aligns local decision making with sustainable collective outcomes and prevents collapse into either universal defection or unconditional cooperation. The framework advances beyond existing approaches by combining group-normalized advantage estimation, a reference-anchored KL penalty, and a global incentive term that dynamically adjusts cooperative payoffs. As a result, it achieves accelerated cooperation onset, stabilized policy adaptation, and long-term sustainability. GRPO-GCC demonstrates how a simple yet global signal can reshape incentives toward resilient cooperation, and provides a new paradigm for multi-agent reinforcement learning in socio-technical systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08607v1</guid>
      <category>cs.MA</category>
      <category>cs.GT</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaoqilin Yang, Chanchan Li, Tianqi Liu, Hongxin Zhao, Youliang Tian</dc:creator>
    </item>
    <item>
      <title>GTAlign: Game-Theoretic Alignment of LLM Assistants for Mutual Welfare</title>
      <link>https://arxiv.org/abs/2510.08872</link>
      <description>arXiv:2510.08872v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) have achieved remarkable progress in reasoning, yet sometimes produce responses that are suboptimal for users in tasks such as writing, information seeking, or providing practical guidance. Conventional alignment practices typically assume that maximizing model reward also maximizes user welfare, but this assumption frequently fails in practice: models may over-clarify or generate overly verbose reasoning when users prefer concise answers. Such behaviors resemble the prisoner's dilemma, where individually rational choices lead to socially suboptimal outcomes. The fundamental challenge is the lack of a principled decision making mechanism that mutually benefits both the LLM and the user. We propose Game-Theoretic Alignment (GTAlign), an alignment framework that integrates game-theoretic decision making into both reasoning and training. During reasoning, the model explicitly treats user-LLM interaction as a strategic game: it constructs payoff matrices within its reasoning chain to estimate welfare for both itself and the user, and then selects actions that are mutually beneficial. During training, we introduce a mutual welfare reward that reinforces cooperative responses, aligning model behavior with socially efficient outcomes. In addition, we introduce an inference technique that leverages game-theoretic reasoning to dynamically adapt LLM's response when pricing policies of LLM service change. Extensive experiments demonstrate that GTAlign substantially improves reasoning efficiency, answer quality, and mutual welfare compared to baselines across diverse tasks. The code is available at https://github.com/ulab-uiuc/GTAlign .</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08872v1</guid>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siqi Zhu, David Zhang, Pedro Cisneros-Velarde, Jiaxuan You</dc:creator>
    </item>
    <item>
      <title>Incentivizing Time-Aware Fairness in Data Sharing</title>
      <link>https://arxiv.org/abs/2510.09240</link>
      <description>arXiv:2510.09240v1 Announce Type: cross 
Abstract: In collaborative data sharing and machine learning, multiple parties aggregate their data resources to train a machine learning model with better model performance. However, as the parties incur data collection costs, they are only willing to do so when guaranteed incentives, such as fairness and individual rationality. Existing frameworks assume that all parties join the collaboration simultaneously, which does not hold in many real-world scenarios. Due to the long processing time for data cleaning, difficulty in overcoming legal barriers, or unawareness, the parties may join the collaboration at different times. In this work, we propose the following perspective: As a party who joins earlier incurs higher risk and encourages the contribution from other wait-and-see parties, that party should receive a reward of higher value for sharing data earlier. To this end, we propose a fair and time-aware data sharing framework, including novel time-aware incentives. We develop new methods for deciding reward values to satisfy these incentives. We further illustrate how to generate model rewards that realize the reward values and empirically demonstrate the properties of our methods on synthetic and real-world datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.09240v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Jiangwei Chen, Kieu Thao Nguyen Pham, Rachael Hwee Ling Sim, Arun Verma, Zhaoxuan Wu, Chuan-Sheng Foo, Bryan Kian Hsiang Low</dc:creator>
    </item>
    <item>
      <title>Finite-memory Strategies for Almost-sure Energy-MeanPayoff Objectives in MDPs</title>
      <link>https://arxiv.org/abs/2404.14522</link>
      <description>arXiv:2404.14522v2 Announce Type: replace 
Abstract: We consider finite-state Markov decision processes with the combined Energy-MeanPayoff objective. The controller tries to avoid running out of energy while simultaneously attaining a strictly positive mean payoff in a second dimension. We show that finite memory suffices for almost surely winning strategies for the Energy-MeanPayoff objective. This is in contrast to the closely related Energy-Parity objective, where almost surely winning strategies require infinite memory in general. We show that exponential memory is sufficient (even for deterministic strategies) and necessary (even for randomized strategies) for almost surely winning Energy-MeanPayoff. The upper bound holds even if the strictly positive mean payoff part of the objective is generalized to multidimensional strictly positive mean payoff. Finally, it is decidable in pseudo-polynomial time whether an almost surely winning strategy exists.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14522v2</guid>
      <category>cs.GT</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4230/LIPIcs.ICALP.2024.133</arxiv:DOI>
      <dc:creator>Mohan Dantam, Richard Mayr</dc:creator>
    </item>
    <item>
      <title>Fair Division in a Variable Setting</title>
      <link>https://arxiv.org/abs/2410.14421</link>
      <description>arXiv:2410.14421v3 Announce Type: replace 
Abstract: We study the classic problem of fairly dividing a set of indivisible items among a set of agents and consider the popular fairness notion of envy-freeness up to one item (EF1). While in reality, the set of agents and items may vary, previous works have studied static settings, where no change can occur in the system. We initiate and develop a formal model to understand fair division under a variable input setting: here, there is an EF1 allocation that is disrupted due to the loss/deletion of some item(s), or the arrival of new agent(s). The objective is to regain EF1 by performing a sequence of valid transfers of items between agents - no transfer creates any new EF1-envy in the system. We call this the EF1-Restoration problem.
  In this work, we develop efficient algorithms for the EF1-Restoration problem when the agents have identical monotone valuations and the items are either all goods or all chores. Both of these algorithms achieve an optimal number of transfers (at most $km/n$, where $m$, $n$, and $k$ denote the number of items, agents, and EF1-unhappy agents respectively) for identical additive valuations.
  Next, we consider a valuation class with graphical structure, introduced by Christodoulou et al. (EC 2023), where each item is valued by at most two agents, and can be seen as an edge between these two agents in a graph. Here, we consider EF1 orientations on multigraphs - allocations where each item is allocated to an agent who values it. When the valuations are also additive and binary, we present an optimal algorithm for the EF1-Restoration problem. We also consider pairwise-homogeneous graphical valuations (all items between a pair of agents are valued the same), and develop an optimal algorithm when the graph is a multipath.
  Finally, for monotone binary valuations, we show that the problem of deciding whether EF1-Restoration is possible is PSPACE-complete.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14421v3</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Harish Chandramouleeswaran, Prajakta Nimbhorkar, Nidhi Rathi</dc:creator>
    </item>
    <item>
      <title>Meta-rotations and the Structure of Stable Matchings in the Student Project Allocation Problem</title>
      <link>https://arxiv.org/abs/2505.13428</link>
      <description>arXiv:2505.13428v2 Announce Type: replace 
Abstract: We study the Student Project Allocation problem with lecturer preferences over Students (SPA-S), an extension of the well-known Stable Marriage and Hospital Residents problem. In this model, students have preferences over projects, each project is offered by a single lecturer, and lecturers have preferences over students. The goal is to compute a stable matching which is an assignment of students to projects (and thus to lecturers) such that no student or lecturer has an incentive to deviate from their current assignment. While motivated by the university setting, this problem arises in many allocation settings where limited resources are offered by agents with their own preferences, such as in wireless networks.
  We establish new structural results for the set of stable matchings in SPA-S by developing the theory of meta-rotations, a generalisation of the well-known notion of rotations from the Stable Marriage problem. Each meta-rotation corresponds to a minimal set of changes that transforms one stable matching into another within the lattice of stable matchings. The set of meta-rotations, ordered by their precedence relations, forms the meta-rotation poset. We prove that there is a one-to-one correspondence between the set of stable matchings and the closed subsets of the meta-rotation poset. By developing this structure, we provide a foundation for the design of efficient algorithms for enumerating and counting stable matchings, and for computing other optimal stable matchings, such as egalitarian or minimum-cost matchings, which have not been previously studied in SPA-S.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13428v2</guid>
      <category>cs.GT</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Peace Ayegba, Sofiat Olaosebikan</dc:creator>
    </item>
    <item>
      <title>Game of Trust: How Trustworthy Does Your Blockchain Think You Are?</title>
      <link>https://arxiv.org/abs/2505.14551</link>
      <description>arXiv:2505.14551v2 Announce Type: replace 
Abstract: We investigate how a blockchain can distill the collective belief of its nodes regarding the trustworthiness of a (sub)set of nodes into a {\em reputation system} that reflects the probability of correctly performing a task. To address this question, we introduce a framework that breaks it down into two sub-problems:
  1. (Information Extraction): How can the system distill trust information from a function of the nodes' true beliefs?
  2. (Incentive Design): How can we incentivize nodes to truthfully report such information?
  To tackle the first sub-problem, we adapt, in a non-trivial manner, the well-known PageRank algorithm to our problem. For the second, we define a new class of games, called Trustworthy Reputation games (TRep games), which aim to extract the collective beliefs on trust from the actions of rational participants. We then propose a concrete TRep game whose utility function leverages Personalized PageRank and can be instantiated through a straightforward blockchain rewards mechanism. Building on this, we show how the TRep game enables the design of a reputation system. Such systems can enhance the robustness, scalability, and efficiency of blockchain and DeFi solutions. For instance, we demonstrate how such a system can be used within a Proof-of-Reputation blockchain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.14551v2</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.CR</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Petros Drineas, Rohit Nema, Rafail Ostrovsky, Vassilis Zikas</dc:creator>
    </item>
    <item>
      <title>Coordinating Charitable Donations with Leontief Preferences</title>
      <link>https://arxiv.org/abs/2305.10286</link>
      <description>arXiv:2305.10286v4 Announce Type: replace-cross 
Abstract: We consider the problem of funding public goods that are complementary in nature. Examples include charities handling different needs (e.g., protecting animals vs. providing healthcare), charitable donations to different individuals, or municipal units handling different issues (e.g., security vs. transportation). We model these complementarities by assuming Leontief preferences; that is, each donor seeks to maximize an individually weighted minimum of all contributions across the charities. Decentralized funding may be inefficient due to a lack of coordination among the donors; centralized funding may be undesirable as it ignores the preferences of individual donors. We present a mechanism that combines the advantages of both methods. The mechanism efficiently distributes each donor's contribution so that no subset of donors has an incentive to redistribute their donations. Moreover, it is group-strategyproof, satisfies desirable monotonicity properties, maximizes Nash welfare, returns a unique Lindahl equilibrium, and can be implemented via natural best-response spending dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.10286v4</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.jet.2025.106096</arxiv:DOI>
      <arxiv:journal_reference>Journal of Economic Theory, 230:106096 (2025)</arxiv:journal_reference>
      <dc:creator>Felix Brandt, Matthias Greger, Erel Segal-Halevi, Warut Suksompong</dc:creator>
    </item>
    <item>
      <title>Networked Information Aggregation via Machine Learning</title>
      <link>https://arxiv.org/abs/2507.09683</link>
      <description>arXiv:2507.09683v2 Announce Type: replace-cross 
Abstract: We study a distributed learning problem in which learning agents are embedded in a directed acyclic graph (DAG). There is a fixed and arbitrary distribution over feature/label pairs, and each agent or vertex in the graph is able to directly observe only a subset of the features -- potentially a different subset for every agent. The agents learn sequentially in some order consistent with a topological sort of the DAG, committing to a model mapping observations to predictions of the real-valued label. Each agent observes the predictions of their parents in the DAG, and trains their model using both the features of the instance that they directly observe, and the predictions of their parents as additional features. We ask when this process is sufficient to achieve \emph{information aggregation}, in the sense that some agent in the DAG is able to learn a model whose error is competitive with the best model that could have been learned (in some hypothesis class) with direct access to \emph{all} features, despite the fact that no single agent in the network has such access. We give upper and lower bounds for this problem for both linear and general hypothesis classes. Our results identify the \emph{depth} of the DAG as the key parameter: information aggregation can occur over sufficiently long paths in the DAG, assuming that all of the relevant features are well represented along the path, and there are distributions over which information aggregation cannot occur even in the linear case, and even in arbitrarily large DAGs that do not have sufficient depth (such as a hub-and-spokes topology in which the spoke vertices collectively see all the features). We complement our theoretical results with a comprehensive set of experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09683v2</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Kearns, Aaron Roth, Emily Ryu</dc:creator>
    </item>
  </channel>
</rss>
