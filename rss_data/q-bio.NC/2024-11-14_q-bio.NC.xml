<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 14 Nov 2024 05:00:16 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>ConFER: A Neurally Constrained Computational Model of Context-Dependent Fear Extinction Recall and Relapse</title>
      <link>https://arxiv.org/abs/2411.08140</link>
      <description>arXiv:2411.08140v1 Announce Type: new 
Abstract: Exposure therapy, a standard treatment for anxiety disorders, relies on fear extinction. However, extinction recall is often limited to the spatial and temporal context in which it is learned leading to fear relapse in novel contexts or after delays. While animal studies provide valuable insights into the mechanisms underlying extinction recall, their invasive nature limits direct applicability to human research. Computational models that incorporate findings from animal research and generate testable hypotheses for human studies can bridge this gap. Current models, however, often focus either on detailed neuron-level activity, limiting their scope, or simulate behavior by abstracting away from neural mechanisms. Moreover, they tend not to disentangle the distinct roles of cue and context information in fear extinction and recall. To address these limitations, we present the Context-Dependent Fear Extinction Recall Model (ConFER), a systems-level, neurally constrained model of fear extinction and recall, and fear relapse. ConFER integrates findings from the neural fear circuit, including distinct pathways for processing cue and context information and valence-based stimulus-responsive regions in the basolateral amygdala (BLA) that encode extinction and fear memories. These pathways independently activate positive and/or negative BLA representations based on learned associations, which compete to produce the final fear response. ConFER simulates fear renewal across various contexts and spontaneous recovery after delays, while also generating novel, testable predictions. Notably, it predicts that counterconditioning may confer greater resilience than extinction in preventing relapse in new contexts or after delays. By providing a mechanistic view of the relapse of fear, ConFER offers potential insights to enhance clinical interventions by improving exposure therapy outcomes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08140v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shreya K. Rajagopal, Thad A. Polk</dc:creator>
    </item>
    <item>
      <title>SynapsNet: Enhancing Neuronal Population Dynamics Modeling via Learning Functional Connectivity</title>
      <link>https://arxiv.org/abs/2411.08221</link>
      <description>arXiv:2411.08221v1 Announce Type: new 
Abstract: The availability of large-scale neuronal population datasets necessitates new methods to model population dynamics and extract interpretable, scientifically translatable insights. Existing deep learning methods often overlook the biological mechanisms underlying population activity and thus exhibit suboptimal performance with neuronal data and provide little to no interpretable information about neurons and their interactions. In response, we introduce SynapsNet, a novel deep-learning framework that effectively models population dynamics and functional interactions between neurons. Within this biologically realistic framework, each neuron, characterized by a latent embedding, sends and receives currents through directed connections. A shared decoder uses the input current, previous neuronal activity, neuron embedding, and behavioral data to predict the population activity in the next time step. Unlike common sequential models that treat population activity as a multichannel time series, SynapsNet applies its decoder to each neuron (channel) individually, with the learnable functional connectivity serving as the sole pathway for information flow between neurons. Our experiments, conducted on mouse cortical activity from publicly available datasets and recorded using the two most common population recording modalities (Ca imaging and Neuropixels) across three distinct tasks, demonstrate that SynapsNet consistently outperforms existing models in forecasting population activity. Additionally, our experiments on both real and synthetic data showed that SynapsNet accurately learns functional connectivity that reveals predictive interactions between neurons.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08221v1</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Parsa Delavari, Ipek Oruc, Timothy H Murphy</dc:creator>
    </item>
    <item>
      <title>Rethinking category-selectivity in human visual cortex</title>
      <link>https://arxiv.org/abs/2411.08251</link>
      <description>arXiv:2411.08251v1 Announce Type: new 
Abstract: A wealth of studies report evidence that occipitotemporal cortex tessellates into "category-selective" brain regions that are apparently specialized for representing ecologically important visual stimuli like faces, bodies, scenes, and tools. Here, we argue that while valuable insights have been gained through the lens of category-selectivity, a more complete view of visual function in occipitotemporal cortex requires centering the behavioral relevance of visual properties in real-world environments rather than stimulus category. Focusing on behavioral relevance challenges a simple mapping between stimulus and visual function in occipitotemporal cortex because the environmental properties relevant to a behavior are visually diverse and how a given property is represented is modulated by our goals. Grounding our thinking in behavioral relevance rather than category-selectivity raises a host of theoretical and empirical issues that we discuss while providing proposals for how existing tools can be harnessed in this light to better understand visual function in occipitotemporal cortex.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08251v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>J. Brendan Ritchie, Susan G. Wardle, Maryam Vaziri-Pashkam, Dwight J. Kravitz, Chris I. Baker</dc:creator>
    </item>
    <item>
      <title>Brain Treebank: Large-scale intracranial recordings from naturalistic language stimuli</title>
      <link>https://arxiv.org/abs/2411.08343</link>
      <description>arXiv:2411.08343v1 Announce Type: new 
Abstract: We present the Brain Treebank, a large-scale dataset of electrophysiological neural responses, recorded from intracranial probes while 10 subjects watched one or more Hollywood movies. Subjects watched on average 2.6 Hollywood movies, for an average viewing time of 4.3 hours, and a total of 43 hours. The audio track for each movie was transcribed with manual corrections. Word onsets were manually annotated on spectrograms of the audio track for each movie. Each transcript was automatically parsed and manually corrected into the universal dependencies (UD) formalism, assigning a part of speech to every word and a dependency parse to every sentence. In total, subjects heard over 38,000 sentences (223,000 words), while they had on average 168 electrodes implanted. This is the largest dataset of intracranial recordings featuring grounded naturalistic language, one of the largest English UD treebanks in general, and one of only a few UD treebanks aligned to multimodal features. We hope that this dataset serves as a bridge between linguistic concepts, perception, and their neural representations. To that end, we present an analysis of which electrodes are sensitive to language features while also mapping out a rough time course of language processing across these electrodes. The Brain Treebank is available at https://BrainTreebank.dev/</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08343v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christopher Wang, Adam Uri Yaari, Aaditya K Singh, Vighnesh Subramaniam, Dana Rosenfarb, Jan DeWitt, Pranav Misra, Joseph R. Madsen, Scellig Stone, Gabriel Kreiman, Boris Katz, Ignacio Cases, Andrei Barbu</dc:creator>
    </item>
    <item>
      <title>A Novel Approach to Characterize Dynamics of ECG-Derived Skin Nerve Activity via Time-Varying Spectral Analysis</title>
      <link>https://arxiv.org/abs/2411.08308</link>
      <description>arXiv:2411.08308v1 Announce Type: cross 
Abstract: Assessment of the sympathetic nervous system (SNS) is one of the major approaches for studying affective states. Skin nerve activity (SKNA) derived from high-frequency components of electrocardiogram (ECG) signals has been a promising surrogate for assessing the SNS. However, current SKNA analysis tools have shown high variability across study protocols and experiments. Hence, we propose a time-varying spectral approach based on SKNA to assess the SNS with higher sensitivity and reliability. We collected ECG signals at a sampling frequency of 10 KHz from sixteen subjects who underwent various SNS stimulations. Our spectral analysis revealed that frequency bands between 150 - 1,000 Hz showed significant increases in power during SNS stimulations. Using this information, we developed a time-varying index of sympathetic function measurement based on SKNA, termed, Time-Varying Skin Nerve Activity (TVSKNA). TVSKNA is calculated in three steps: time-frequency decomposition, reconstruction using selected frequency bands, and smoothing. TVSKNA indices exhibited generally higher Youden's J, balanced accuracy, and area under the receiver operating characteristic curve, indicating higher sensitivity. The coefficient of variance was lower with TVSKNA indices for most SNS tasks. TVSKNA can serve as a highly sensitive and reliable marker of quantitative assessment of sympathetic function, especially during emotion and stress.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08308v1</guid>
      <category>eess.SP</category>
      <category>q-bio.NC</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Youngsun Kong, Farnoush Baghestani, William D'Angelo, I-Ping Chen, Ki H. Chon</dc:creator>
    </item>
    <item>
      <title>Mathematical representation of the structure of neuron-glia networks</title>
      <link>https://arxiv.org/abs/2111.10719</link>
      <description>arXiv:2111.10719v4 Announce Type: replace 
Abstract: Network representations of the nervous system have been useful for the understanding of brain phenomena such as perception, motor coordination, and memory. Although brains are composed of both neurons and glial cells, neuron-glial networks have been little studied so far. Given the emergent role of glial cells in information transmission in the brain, we developed a mathematical representation for neuron-glial networks ($\Upsilon$-graph). We also defined the concepts of isomorphisms, unnested form (multidigraph) and matrix equation for $\Upsilon$-graphs. Although we found several network motives where the isomorphism between unnested forms does not guarantees the isomorphism between their respective $\Upsilon$-graphs, we found that if the matrix equations satisfy some conditions, the unnested forms isomorphism guarantees the isomorphism between $\Upsilon$-graphs. Finally, we introduced a novel approach to modeling the network shape. Our work presents a mathematical framework for working with neuron-glia networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2111.10719v4</guid>
      <category>q-bio.NC</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marco Pe\~na-Garcia, Francesco Pe\~na-Garcia, Nelson Castro, Walter Cabrera-Febola</dc:creator>
    </item>
  </channel>
</rss>
