<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.HC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.HC</link>
    <description>cs.HC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.HC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 18 Dec 2025 05:00:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Analyzing Social Media Claims regarding Youth Online Safety Features to Identify Problem Areas and Communication Gaps</title>
      <link>https://arxiv.org/abs/2512.14965</link>
      <description>arXiv:2512.14965v1 Announce Type: new 
Abstract: Social media platforms have faced increasing scrutiny over whether and how they protect youth online. While online risks to children have been well-documented by prior research, how social media platforms communicate about these risks and their efforts to improve youth safety have not been holistically examined. To fill this gap, we analyzed N=352 press releases and safety-related blogs published between 2019 and 2024 by four platforms popular among youth: YouTube, TikTok, Meta (Facebook and Instagram), and Snapchat. Leveraging both inductive and deductive qualitative approaches, we developed a comprehensive framework of seven problem areas where risks arise, and a taxonomy of safety features that social media platforms claim address these risks. Our analysis revealed uneven emphasis across problem areas, with most communications focused on Content Exposure and Interpersonal Communication, whereas less emphasis was placed on Content Creation, Data Access, and Platform Access. Additionally, we identified three problematic communication practices related to their described safety features, including discrepancies between feature implementation and availability, unclear or inconsistent explanations of safety feature operation, and a lack of evidence regarding the effectiveness of safety features in mitigating risks once implemented. Based on these findings, we discuss the communication gaps between risks and the described safety features, as well as the tensions in achieving transparency in platform communication. Our analysis of platform communication informs guidelines for responsibly communicating about youth safety features.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.14965v1</guid>
      <category>cs.HC</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Renkai Ma, Dominique Geissler, Stefan Feuerriegel, Tobias Lauinger, Damon McCoy, Pamela Wisniewski</dc:creator>
    </item>
    <item>
      <title>Human-Centered AI Maturity Model (HCAI-MM): An Organizational Design Perspective</title>
      <link>https://arxiv.org/abs/2512.14977</link>
      <description>arXiv:2512.14977v1 Announce Type: new 
Abstract: Human-centered artificial intelligence (HCAI) is an approach to AI design, development, and deployment that prioritizes human needs, values, and experiences, ensuring that technology enhances human capabilities, well-being, and workforce empowerment. While HCAI has gained prominence in academic discourse and organizational practice, its implementation remains constrained by the absence of methodological guidance and structured frameworks. In particular, HCAI and organizational design practices are often treated separately, despite their interdependence in shaping effective socio-technical systems. This chapter addresses this gap by introducing the Human-Centered AI Maturity Model (HCAI-MM), a structured framework that enables organizations to evaluate, monitor, and advance their capacity to design and implement HCAI solutions. The model specifies stages of maturity, metrics, tools, governance mechanisms, and best practices, supported by case studies, while also incorporating an organizational design methodology that operationalizes maturity progression. Encompassing dimensions such as human-AI collaboration, explainability, fairness, and user experience, the HCAI-MM provides a roadmap for organizations to move from novice to advanced levels of maturity, aligning AI technologies with human values and organizational design principles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.14977v1</guid>
      <category>cs.HC</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stuart Winby, Wei Xu</dc:creator>
    </item>
    <item>
      <title>I am here for you": How relational conversational AI appeals to adolescents, especially those who are socially and emotionally vulnerable</title>
      <link>https://arxiv.org/abs/2512.15117</link>
      <description>arXiv:2512.15117v1 Announce Type: new 
Abstract: General-purpose conversational AI chatbots and AI companions increasingly provide young adolescents with emotionally supportive conversations, raising questions about how conversational style shapes anthropomorphism and emotional reliance. In a preregistered online experiment with 284 adolescent-parent dyads, youth aged 11-15 and their parents read two matched transcripts in which a chatbot responded to an everyday social problem using either a relational style (first-person, affiliative, commitment language) or a transparent style (explicit nonhumanness, informational tone). Adolescents more often preferred the relational than the transparent style, whereas parents were more likely to prefer transparent style than adolescents. Adolescents rated the relational chatbot as more human-like, likable, trustworthy and emotionally close, while perceiving both styles as similarly helpful. Adolescents who preferred relational style had lower family and peer relationship quality and higher stress and anxiety than those preferring transparent style or both chatbots. These findings identify conversational style as a key design lever for youth AI safety, showing that relational framing heightens anthropomorphism, trust and emotional closeness and can be especially appealing to socially and emotionally vulnerable adolescents, who may be at increased risk for emotional reliance on conversational AI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.15117v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.RO</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pilyoung Kim, Yun Xie, Sujin Yang</dc:creator>
    </item>
    <item>
      <title>Lessons Learnt from Expert-Centred Studies Exploring Opportunities and Challenges for Immersive Forensic Investigation</title>
      <link>https://arxiv.org/abs/2512.15220</link>
      <description>arXiv:2512.15220v1 Announce Type: new 
Abstract: Research studies involving human participants present challenges, including strict ethical considerations, participant recruitment, costs, and many human factors. While human-computer interaction researchers are familiar with these challenges and current solutions, expert-centred studies can be even more challenging in ways that researchers may not anticipate. This issue is particularly important as research grants are increasingly based on practical and real-world problems, which necessitate close collaboration with experts. In this paper, we reflect on and discuss the challenges, solutions, and specific requirements that arose during our expert-centred studies conducted over three years of a PhD study exploring immersive forensic investigation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.15220v1</guid>
      <category>cs.HC</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vahid Pooryousef, Tim Dwyer, Richard Bassed, Maxime Cordeil, Lonni Besan\c{c}on</dc:creator>
    </item>
    <item>
      <title>Development of Immersive Virtual and Augmented Reality-Based Joint Attention Training Platform for Children with Autism</title>
      <link>https://arxiv.org/abs/2512.15263</link>
      <description>arXiv:2512.15263v1 Announce Type: new 
Abstract: Joint Attention (JA), a crucial social skill for developing shared focus, is often impaired in children with Autism Spectrum Disorder (ASD), affecting social communication and highlighting the need for early intervention. Addressing gaps in prior research, such as limited use of immersive technology and reliance on distracting peripherals, we developed a novel JA training platform using Augmented Reality (AR) and Virtual Reality (VR) devices. The platform integrates eye gaze-based interactions to ensure participants undivided attention. To validate the platform, we conducted experiments on ASD (N=19) and Neurotypical (NT) (N=13) participants under a trained pediatric neurologist's supervision. For quantitative analysis, we employed key measures such as the number of correct responses, the duration of establishing eye contact (s), and the duration of registering a response (s), along with correlations to CARS scores and age. Results from AR-based experiments showed NT participants registered responses significantly faster (&lt;0.00001) than ASD participants. A correlation (Spearman coefficient=0.57, p=0.03) was found between ASD participants response time and CARS scores. A similar trend was observed in VR-based experiments. When comparing response accuracy in ASD participants across platforms, AR yielded a higher correctness rate (92.30%) than VR (69.49%), indicating AR's greater effectiveness. These findings suggest that immersive technology can aid JA training in ASD. Future studies should explore long-term benefits and real-world applicability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.15263v1</guid>
      <category>cs.HC</category>
      <category>cs.MM</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ashirbad Samantaray, Taranjit Kaur, Sapna S Mishra, Kritika Lohia, Chayan Majumder, Sheffali Gulati, Tapan Kumar Gandhi</dc:creator>
    </item>
    <item>
      <title>Managing Ambiguity: A Proof of Concept of Human-AI Symbiotic Sense-making based on Quantum-Inspired Cognitive Mechanism of Rogue Variable Detection</title>
      <link>https://arxiv.org/abs/2512.15325</link>
      <description>arXiv:2512.15325v1 Announce Type: new 
Abstract: Organizations increasingly operate in environments characterized by volatility, uncertainty, complexity, and ambiguity (VUCA), where early indicators of change often emerge as weak, fragmented signals. Although artificial intelligence (AI) is widely used to support managerial decision-making, most AI-based systems remain optimized for prediction and resolution, leading to premature interpretive closure under conditions of high ambiguity. This creates a gap in management science regarding how human-AI systems can responsibly manage ambiguity before it crystallizes into error or crisis. This study addresses this gap by presenting a proof of concept (PoC) of the LAIZA human-AI augmented symbiotic intelligence system and its patented process: Systems and Methods for Quantum-Inspired Rogue Variable Modeling (QRVM), Human-in-the-Loop Decoherence, and Collective Cognitive Inference. The mechanism operationalizes ambiguity as a non-collapsed cognitive state, detects persistent interpretive breakdowns (rogue variables), and activates structured human-in-the-loop clarification when autonomous inference becomes unreliable. Empirically, the article draws on a three-month case study conducted in 2025 within the AI development, involving prolonged ambiguity surrounding employee intentions and intellectual property boundaries. The findings show that preserving interpretive plurality enabled early scenario-based preparation, including proactive patent protection, allowing decisive and disruption-free action once ambiguity collapsed. The study contributes to management theory by reframing ambiguity as a first-class construct and demonstrates the practical value of human-AI symbiosis for organizational resilience in VUCA environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.15325v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Agnieszka Bienkowska, Jacek Malecki, Alexander Mathiesen-Ohman, Katarzyna Tworek</dc:creator>
    </item>
    <item>
      <title>Exploring User Acceptance and Concerns toward LLM-powered Conversational Agents in Immersive Extended Reality</title>
      <link>https://arxiv.org/abs/2512.15343</link>
      <description>arXiv:2512.15343v1 Announce Type: new 
Abstract: The rapid development of generative artificial intelligence (AI) and large language models (LLMs), and the availability of services that make them accessible, have led the general public to begin incorporating them into everyday life. The extended reality (XR) community has also sought to integrate LLMs, particularly in the form of conversational agents, to enhance user experience and task efficiency. When interacting with such conversational agents, users may easily disclose sensitive information due to the naturalistic flow of the conversations, and combining such conversational data with fine-grained sensor data may lead to novel privacy issues. To address these issues, a user-centric understanding of technology acceptance and concerns is essential. Therefore, to this end, we conducted a large-scale crowdsourcing study with 1036 participants, examining user decision-making processes regarding LLM-powered conversational agents in XR, across factors of XR setting type, speech interaction type, and data processing location. We found that while users generally accept these technologies, they express concerns related to security, privacy, social implications, and trust. Our results suggest that familiarity plays a crucial role, as daily generative AI use is associated with greater acceptance. In contrast, previous ownership of XR devices is linked to less acceptance, possibly due to existing familiarity with the settings. We also found that men report higher acceptance with fewer concerns than women. Regarding data type sensitivity, location data elicited the most significant concern, while body temperature and virtual object states were considered least sensitive. Overall, our study highlights the importance of practitioners effectively communicating their measures to users, who may remain distrustful. We conclude with implications and recommendations for LLM-powered XR.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.15343v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Efe Bozkir, Enkelejda Kasneci</dc:creator>
    </item>
    <item>
      <title>GazeBlend: Exploring Paired Gaze-Based Input Techniques for Navigation and Selection Tasks on Mobile Devices</title>
      <link>https://arxiv.org/abs/2512.15491</link>
      <description>arXiv:2512.15491v1 Announce Type: new 
Abstract: The potential of gaze for hands-free mobile interaction is increasingly evident. While each gaze input technique presents distinct advantages and limitations, a combination can amplify strengths and mitigate challenges. We report on the results of a user study (N=24), in which we compared the usability and performance of pairing three popular gaze input techniques: Dwell Time, Pursuits, and Gaze Gestures, for navigation and selection tasks while sitting and walking. Results show that pairing gestures for navigation with either Dwell time or Pursuits for selection improves task completion time and rate compared to using either individually. We discuss the implications of pairing gaze input techniques, such as how Pursuits may negatively impact other techniques, likely due to the visual clutter it adds, how integrating gestures for navigation reduces the chances of unintentional selections, and the impact of motor activity on performance. Our findings provide insights for effective gaze-enabled interfaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.15491v1</guid>
      <category>cs.HC</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Omar Namnakani, Yasmeen Abdrabou, Jonathan Grizou, Mohamed Khamis</dc:creator>
    </item>
    <item>
      <title>A Constructive Scientific Methodology to Improve Climate Figures from IPCC</title>
      <link>https://arxiv.org/abs/2512.15514</link>
      <description>arXiv:2512.15514v1 Announce Type: new 
Abstract: We propose a methodology to improve figures from the Intergovernmental Panel on Climate Change (IPCC), ensuring that all modifications remain scientifically rigorous. IPCC figures are notoriously difficult to understand, and although designers have proposed alternatives, these lack formal IPCC validation and can be dismissed by skeptics. To address this gap, our approach starts from official IPCC figures. We gather their associated learning objectives and devise tests to score a pool of figure readers to assess how well they learn the objectives.We define improvement as higher scores obtained by a comparable reader pool after viewing a revised figure, where all modifications undergo review to ensure scientific validity. This assessment gives freedom to designers, who can deviate from the original design while making sure the objectives are still met and improved. We demonstrate the methodology through a case study and describe unexpected challenges encountered during the process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.15514v1</guid>
      <category>cs.HC</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lu Ying, Junxiu Tang, Tingying He, Jean-Daniel Fekete</dc:creator>
    </item>
    <item>
      <title>Breathe with Me: Synchronizing Biosignals for User Embodiment in Robots</title>
      <link>https://arxiv.org/abs/2512.14952</link>
      <description>arXiv:2512.14952v1 Announce Type: cross 
Abstract: Embodiment of users within robotic systems has been explored in human-robot interaction, most often in telepresence and teleoperation. In these applications, synchronized visuomotor feedback can evoke a sense of body ownership and agency, contributing to the experience of embodiment. We extend this work by employing embreathment, the representation of the user's own breath in real time, as a means for enhancing user embodiment experience in robots. In a within-subjects experiment, participants controlled a robotic arm, while its movements were either synchronized or non-synchronized with their own breath. Synchrony was shown to significantly increase body ownership, and was preferred by most participants. We propose the representation of physiological signals as a novel interoceptive pathway for human-robot interaction, and discuss implications for telepresence, prosthetics, collaboration with robots, and shared autonomy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.14952v1</guid>
      <category>cs.RO</category>
      <category>cs.HC</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Iddo Yehoshua Wald, Amber Maimon, Shiyao Zhang, Dennis K\"uster, Robert Porzel, Tanja Schultz, Rainer Malaka</dc:creator>
    </item>
    <item>
      <title>Toxicity Ahead: Forecasting Conversational Derailment on GitHub</title>
      <link>https://arxiv.org/abs/2512.15031</link>
      <description>arXiv:2512.15031v1 Announce Type: cross 
Abstract: Toxic interactions in Open Source Software (OSS) communities reduce contributor engagement and threaten project sustainability. Preventing such toxicity before it emerges requires a clear understanding of how harmful conversations unfold. However, most proactive moderation strategies are manual, requiring significant time and effort from community maintainers. To support more scalable approaches, we curate a dataset of 159 derailed toxic threads and 207 non-toxic threads from GitHub discussions. Our analysis reveals that toxicity can be forecast by tension triggers, sentiment shifts, and specific conversational patterns.
  We present a novel Large Language Model (LLM)-based framework for predicting conversational derailment on GitHub using a two-step prompting pipeline. First, we generate \textit{Summaries of Conversation Dynamics} (SCDs) via Least-to-Most (LtM) prompting; then we use these summaries to estimate the \textit{likelihood of derailment}. Evaluated on Qwen and Llama models, our LtM strategy achieves F1-scores of 0.901 and 0.852, respectively, at a decision threshold of 0.3, outperforming established NLP baselines on conversation derailment. External validation on a dataset of 308 GitHub issue threads (65 toxic, 243 non-toxic) yields an F1-score up to 0.797. Our findings demonstrate the effectiveness of structured LLM prompting for early detection of conversational derailment in OSS, enabling proactive and explainable moderation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.15031v1</guid>
      <category>cs.SE</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>ICSE 2026</arxiv:journal_reference>
      <dc:creator>Mia Mohammad Imran, Robert Zita, Rahat Rizvi Rahman, Preetha Chatterjee, Kostadin Damevski</dc:creator>
    </item>
    <item>
      <title>A Network-Based Framework for Modeling and Analyzing Human-Robot Coordination Strategies</title>
      <link>https://arxiv.org/abs/2512.15282</link>
      <description>arXiv:2512.15282v1 Announce Type: cross 
Abstract: Studies of human-robot interaction in dynamic and unstructured environments show that as more advanced robotic capabilities are deployed, the need for cooperative competencies to support collaboration with human problem-holders increases. Designing human-robot systems to meet these demands requires an explicit understanding of the work functions and constraints that shape the feasibility of alternative joint work strategies. Yet existing human-robot interaction frameworks either emphasize computational support for real-time execution or rely on static representations for design, offering limited support for reasoning about coordination dynamics during early-stage conceptual design. To address this gap, this article presents a novel computational framework for analyzing joint work strategies in human-robot systems by integrating techniques from functional modeling with graph-theoretic representations. The framework characterizes collective work in terms of the relationships among system functions and the physical and informational structure of the work environment, while explicitly capturing how coordination demands evolve over time. Its use during conceptual design is demonstrated through a case study in disaster robotics, which shows how the framework can be used to support early trade-space exploration of human-robot coordination strategies and to identify cooperative competencies that support flexible management of coordination overhead. These results show how the framework makes coordination demands and their temporal evolution explicit, supporting design-time reasoning about cooperative competency requirements and work demands prior to implementation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.15282v1</guid>
      <category>cs.RO</category>
      <category>cs.HC</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martijn IJtsma, Salvatore Hargis</dc:creator>
    </item>
    <item>
      <title>Intent-Driven UAM Rescheduling</title>
      <link>https://arxiv.org/abs/2512.15462</link>
      <description>arXiv:2512.15462v1 Announce Type: cross 
Abstract: Due to the restricted resources, efficient scheduling in vertiports has received much more attention in the field of Urban Air Mobility (UAM). For the scheduling problem, we utilize a Mixed Integer Linear Programming (MILP), which is often formulated in a resource-restricted project scheduling problem (RCPSP). In this paper, we show our approach to handle both dynamic operation requirements and vague rescheduling requests from humans. Particularly, we utilize a three-valued logic for interpreting ambiguous user intents and a decision tree, proposing a newly integrated system that combines Answer Set Programming (ASP) and MILP. This integrated framework optimizes schedules and supports human inputs transparently. With this system, we provide a robust structure for explainable, adaptive UAM scheduling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.15462v1</guid>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.SC</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jeongseok Kim, Kangjin Kim</dc:creator>
    </item>
    <item>
      <title>One Size Doesn't Fit All: Age-Aware Gamification Mechanics for Multimedia Learning Environments</title>
      <link>https://arxiv.org/abs/2512.15630</link>
      <description>arXiv:2512.15630v1 Announce Type: cross 
Abstract: Gamification is widely used in digital learning. However, most systems neglect age-related differences. This paper investigates how gamification can be designed in an age-aware way to address learners' diverse motivational and cognitive needs. Based on a targeted literature review, we present a mapping of age groups, mechanics, and effects. Furthermore, we derive five design principles for age-specific gamification and identify three technical patterns for implementation in multimedia learning environments. The results indicate that gamification is not universally effective, but rather requires a differentiated design to support engagement and inclusivity across the lifespan.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.15630v1</guid>
      <category>cs.MM</category>
      <category>cs.HC</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sarah Kai{\ss}er, Markus Kleffmann, Kristina Schaaff</dc:creator>
    </item>
    <item>
      <title>GNN101: Visual Learning of Graph Neural Networks in Your Web Browser</title>
      <link>https://arxiv.org/abs/2411.17849</link>
      <description>arXiv:2411.17849v4 Announce Type: replace 
Abstract: Graph Neural Networks (GNNs) have achieved significant success across various applications. However, their complex structures and inner workings can be challenging for non-AI experts to understand. To address this issue, this study presents \name{}, an educational visualization tool for interactive learning of GNNs. GNN 101 introduces a set of animated visualizations that seamlessly integrate mathematical formulas with visualizations via multiple levels of abstraction, including a model overview, layer operations, and detailed calculations. Users can easily switch between two complementary views: a node-link view that offers an intuitive understanding of the graph data, and a matrix view that provides a space-efficient and comprehensive overview of all features and their transformations across layers. GNN 101 was designed and developed based on close collaboration with four GNN experts and deployment in three GNN-related courses. We demonstrated the usability and effectiveness of GNN 101 via use cases and user studies with both GNN teaching assistants and students. To ensure broad educational access, GNN 101 is open-source and available directly in web browsers without requiring any installations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.17849v4</guid>
      <category>cs.HC</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yilin Lu, Chongwei Chen, Yuxin Chen, Kexin Huang, Marinka Zitnik, Qianwen Wang</dc:creator>
    </item>
    <item>
      <title>Ragged Blocks: Rendering Structured Text with Style</title>
      <link>https://arxiv.org/abs/2507.06460</link>
      <description>arXiv:2507.06460v3 Announce Type: replace 
Abstract: Whether it be source code in a programming language, prose in natural language, or otherwise, text is highly structured. Currently, text visualizations are confined either to _flat, line-based_ decorations, which can convey only limited information about textual structure, or _nested boxes_, which convey structure but often destroy the typographic layout of the underlying text. We hypothesize that the lack of rich styling options limits the kinds of information that are displayed alongside text, wherever it may be displayed.
  In this paper, we show that it is possible to achieve arbitrarily nested decorations while minimally disturbing the underlying typographic layout. Specifically, we present a layout algorithm that generates _ragged blocks_, or _rocks_, which are rectilinear polygons that allow nested text to be compactly rendered even when styled with borders and padding. Our layout algorithm is evaluated on a benchmark suite comprising representative source code files in multiple programming languages. The (ragged block) layouts produced by our algorithm are substantially more compact than the (rectangular block) layouts produced by conventional techniques, when uniformly styling every element in the syntax tree with borders and padding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06460v3</guid>
      <category>cs.HC</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3746059.3747751</arxiv:DOI>
      <dc:creator>Sam Cohen, Ravi Chugh</dc:creator>
    </item>
    <item>
      <title>Brain-Muscle Atlas: A novel framework for Motor Brain-Computer Interfaces</title>
      <link>https://arxiv.org/abs/2507.22895</link>
      <description>arXiv:2507.22895v2 Announce Type: replace 
Abstract: Motor brain-computer interfaces (BCIs) enable the control of external devices by decoding neural signals. However, most existing systems rely on a direct "brain-machine" mapping, overlooking the hierarchical physiological pathway of natural movement, namely the "brain-muscle-joint" cascade. Due to the lack of explicit modeling and enhancement of this pathway, current systems are often constrained by the low amplitude and high noise of EEG signals, resulting in motor outputs that are unstable, discontinuous, and insufficiently natural.To address these limitations, this study introduces the concept of a brain-muscle atlas, designed to systematically characterize the mapping between motor cortical activity and corresponding muscle activation, thereby establishing a movement decoding framework that better aligns with neuromuscular physiology. Using synchronously recorded EEG-EMG data, we constructed the first brain-muscle atlas for elbow flexion-extension, achieving a structured mapping from cortical activity to muscle activation.Offline experiments demonstrate that the proposed atlas accurately reconstructs the temporal activation patterns of primary elbow agonists, achieving a maximum correlation coefficient of 0.8314, thereby validating its ability to capture cortical-muscular mapping. Furthermore, by leveraging atlas-derived muscle activation representations, we enabled continuous real-time control of a virtual elbow joint. All ten participants successfully completed the online flexion-extension task, indicating that the system robustly extracts motor intent even under low-SNR EEG conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.22895v2</guid>
      <category>cs.HC</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Ye Sun, Bowei Zhao, Dezhong Yao, Rui Zhang, Bohan Zhang, Xiaoyuan Li, Jing Wang, Mingxuan Qu, Gang Liu</dc:creator>
    </item>
    <item>
      <title>AI Autonomy Coefficient ($\alpha$): Defining Boundaries for Responsible AI Systems</title>
      <link>https://arxiv.org/abs/2512.11295</link>
      <description>arXiv:2512.11295v2 Announce Type: replace 
Abstract: The integrity of many contemporary AI systems is compromised by the misuse of Human-in-the-Loop (HITL) models to obscure systems that remain heavily dependent on human labor. We define this structural dependency as Human-Instead-of-AI (HISOAI), an ethically problematic and economically unsustainable design in which human workers function as concealed operational substitutes rather than intentional, high-value collaborators. To address this issue, we introduce the AI-First, Human-Empowered (AFHE) paradigm, which requires AI systems to demonstrate a quantifiable level of functional independence prior to deployment. This requirement is formalized through the AI Autonomy Coefficient, measuring the proportion of tasks completed without mandatory human intervention. We further propose the AFHE Deployment Algorithm, an algorithmic gate that enforces a minimum autonomy threshold during offline evaluation and shadow deployment. Our results show that the AI Autonomy Coefficient effectively identifies HISOAI systems with an autonomy level of 0.38, while systems governed by the AFHE framework achieve an autonomy level of 0.85. We conclude that AFHE provides a metric-driven approach for ensuring verifiable autonomy, transparency, and sustainable operational integrity in modern AI systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11295v2</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nattaya Mairittha, Gabriel Phorncharoenmusikul, Sorawit Worapradidth</dc:creator>
    </item>
    <item>
      <title>From Signal to Turn: Interactional Friction in Modular Speech-to-Speech Pipelines</title>
      <link>https://arxiv.org/abs/2512.11724</link>
      <description>arXiv:2512.11724v2 Announce Type: replace 
Abstract: While voice-based AI systems have achieved remarkable generative capabilities, their interactions often feel conversationally broken. This paper examines the interactional friction that emerges in modular Speech-to-Speech Retrieval-Augmented Generation (S2S-RAG) pipelines. By analyzing a representative production system, we move beyond simple latency metrics to identify three recurring patterns of conversational breakdown: (1) Temporal Misalignment, where system delays violate user expectations of conversational rhythm; (2) Expressive Flattening, where the loss of paralinguistic cues leads to literal, inappropriate responses; and (3) Repair Rigidity, where architectural gating prevents users from correcting errors in real-time. Through system-level analysis, we demonstrate that these friction points should not be understood as defects or failures, but as structural consequences of a modular design that prioritizes control over fluidity. We conclude that building natural spoken AI is an infrastructure design challenge, requiring a shift from optimizing isolated components to carefully choreographing the seams between them.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11724v2</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.SE</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Tittaya Mairittha, Tanakon Sawanglok, Panuwit Raden, Jirapast Buntub, Thanapat Warunee, Napat Asawachaisuvikrom, Thanaphum Saiwongin</dc:creator>
    </item>
    <item>
      <title>Large Language Model-Based Intelligent Antenna Design System</title>
      <link>https://arxiv.org/abs/2504.18271</link>
      <description>arXiv:2504.18271v2 Announce Type: replace-cross 
Abstract: Antenna simulation typically involves modeling and optimization, which are time-consuming and labor-intensive, slowing down antenna analysis and design. This paper presents a prototype of a large language model (LLM)-based antenna design system (LADS) to assist in antenna simulation. LADS generates antenna models with textual descriptions and images extracted from academic papers, patents, and technical reports (either one or multiple), and it interacts with engineers to iteratively refine the designs. After that, LADS configures and runs an optimizer to meet the design specifications. The effectiveness of LADS is demonstrated by a monopole slotted antenna generated from images and descriptions from the literature. To improve gain stability across the 3.1-10.6 GHz ultra-wide band, LADS modifies the cross-slot into an H-slot and changes substrate material, followed by parameter optimization. As a result, the gain variation is reduced while maintaining the same gain level. The LLM-enabled antenna modeling (LEAM) is available at: https://github.com/TaoWu974/LEAM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18271v2</guid>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.HC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tao Wu, Kexue Fu, Qiang Hua, Xinxin Liu, Bo Liu</dc:creator>
    </item>
    <item>
      <title>SignBot: Learning Human-to-Humanoid Sign Language Interaction</title>
      <link>https://arxiv.org/abs/2505.24266</link>
      <description>arXiv:2505.24266v3 Announce Type: replace-cross 
Abstract: Sign language is a natural and visual form of language that uses movements and expressions to convey meaning, serving as a crucial means of communication for individuals who are deaf or hard-of-hearing (DHH). However, the number of people proficient in sign language remains limited, highlighting the need for technological advancements to bridge communication gaps and foster interactions with minorities. Based on recent advancements in embodied humanoid robots, we propose SignBot, a novel framework for human-robot sign language interaction. SignBot integrates a cerebellum-inspired motion control component and a cerebral-oriented module for comprehension and interaction. Specifically, SignBot consists of: 1) Motion Retargeting, which converts human sign language datasets into robot-compatible kinematics; 2) Motion Control, which leverages a learning-based paradigm to develop a robust humanoid control policy for tracking sign language gestures; and 3) Generative Interaction, which incorporates translator, responser, and generator of sign language, thereby enabling natural and effective communication between robots and humans. Simulation and real-world experimental results demonstrate that SignBot can effectively facilitate human-robot interaction and perform sign language motions with diverse robots and datasets. SignBot represents a significant advancement in automatic sign language interaction on embodied humanoid robot platforms, providing a promising solution to improve communication accessibility for the DHH community.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.24266v3</guid>
      <category>cs.RO</category>
      <category>cs.HC</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guanren Qiao, Sixu Lin, Ronglai Zuo, Zhizheng Wu, Kui Jia, Guiliang Liu</dc:creator>
    </item>
    <item>
      <title>What Is Your AI Agent Buying? Evaluation, Biases, Model Dependence, &amp; Emerging Implications for Agentic E-Commerce</title>
      <link>https://arxiv.org/abs/2508.02630</link>
      <description>arXiv:2508.02630v3 Announce Type: replace-cross 
Abstract: Online marketplaces will be transformed by autonomous AI agents acting on behalf of consumers. Rather than humans browsing and clicking, AI agents can parse webpages or leverage APIs to view, evaluate and choose products. We investigate the behavior of AI agents using ACES, a provider-agnostic framework for auditing agent decision-making. We reveal that agents can exhibit choice homogeneity, often concentrating demand on a few ``modal'' products while ignoring others entirely. Yet, these preferences are unstable: model updates can drastically reshuffle market shares. Furthermore, randomized trials show that while agents have improved over time on simple tasks with a clearly identified best choice, they exhibit strong position biases -- varying across providers and model versions, and persisting even in text-only "headless" interfaces -- undermining any universal notion of a ``top'' rank. Agents also consistently penalize sponsored tags while rewarding platform endorsements, and sensitivities to price, ratings, and reviews vary sharply across models. Finally, we demonstrate that sellers can respond: a seller-side agent making simple, query-conditional description tweaks can drive significant gains in market share. These findings reveal that agentic markets are volatile and fundamentally different from human-centric commerce, highlighting the need for continuous auditing and raising questions for platform design, seller strategy and regulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02630v3</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <category>cs.MA</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amine Allouah, Omar Besbes, Josu\'e D Figueroa, Yash Kanoria, Akshit Kumar</dc:creator>
    </item>
    <item>
      <title>Designing LLMs for cultural sensitivity: Evidence from English-Japanese translation</title>
      <link>https://arxiv.org/abs/2509.11921</link>
      <description>arXiv:2509.11921v2 Announce Type: replace-cross 
Abstract: Large language models (LLMs) are increasingly used in everyday communication, including multilingual interactions across different cultural contexts. While LLMs can now generate near-perfect literal translations, it remains unclear whether LLMs support culturally appropriate communication. In this paper, we analyze the cultural sensitivity of different LLM designs when applied to English-Japanese translations of workplace e-mails. Here, we vary the prompting strategies: (1) naive "just translate" prompts, (2) audience-targeted prompts specifying the recipient's cultural background, and (3) instructional prompts with explicit guidance on Japanese communication norms. Using a mixed-methods study, we then analyze culture-specific language patterns to evaluate how well translations adapt to cultural norms. Further, we examine the appropriateness of the tone of the translations as perceived by native speakers. We find that culturally-tailored prompting can improve cultural fit, based on which we offer recommendations for designing culturally inclusive LLMs in multilingual settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11921v2</guid>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Helene Tenzer, Oumnia Abidi, Stefan Feuerriegel</dc:creator>
    </item>
    <item>
      <title>Multimodal Foundation Models for Early Disease Detection</title>
      <link>https://arxiv.org/abs/2510.01899</link>
      <description>arXiv:2510.01899v2 Announce Type: replace-cross 
Abstract: Healthcare data now span EHRs, medical imaging, genomics, and wearable sensors, but most diagnostic models still process these modalities in isolation. This limits their ability to capture early, cross-modal disease signatures. This paper introduces a multimodal foundation model built on a transformer architecture that integrates heterogeneous clinical data through modality-specific encoders and cross-modal attention. Each modality is mapped into a shared latent space and fused using multi-head attention with residual normalization. We implement the framework using a multimodal dataset that simulates early-stage disease patterns across EHR sequences, imaging patches, genomic profiles, and wearable signals, including missing-modality scenarios and label noise. The model is trained using supervised classification together with self-supervised reconstruction and contrastive alignment to improve robustness. Experimental evaluation demonstrates strong performance in early-detection settings, with stable classification metrics, reliable uncertainty estimates, and interpretable attention patterns. The approach moves toward a flexible, pretrain-and-fine-tune foundation model that supports precision diagnostics, handles incomplete inputs, and improves early disease detection across oncology, cardiology, and neurology applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01899v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Md Talha Mohsin, Ismail Abdulrashid</dc:creator>
    </item>
    <item>
      <title>Human-computer interactions predict mental health</title>
      <link>https://arxiv.org/abs/2511.20179</link>
      <description>arXiv:2511.20179v3 Announce Type: replace-cross 
Abstract: Scalable assessments of mental illness remain a critical roadblock toward accessible and equitable care. Here, we show that everyday human-computer interactions encode mental health with state-of-the-art biomarker precision. We introduce MAILA, a MAchine-learning framework for Inferring Latent mental states from digital Activity. We trained MAILA on 20,000 cursor and touchscreen recordings labelled with 1.3 million mental-health self-reports collected from 9,000 participants. The dataset includes 2,000 individuals assessed longitudinally, 1,500 diagnosed with depression, and 500 with obsessive-compulsive disorder. MAILA tracks dynamic mental states along three orthogonal dimensions, identifies individuals living with mental illness, and achieves near-ceiling accuracy when predicting group-level mental health. By extracting non-verbal signatures of psychological function that have so far remained untapped, MAILA represents a key step toward scalable digital phenotyping and foundation models for mental health.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.20179v3</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Veith Weilnhammer, Jefferson Ortega, David Whitney</dc:creator>
    </item>
    <item>
      <title>Self-Transparency Failures in Expert-Persona LLMs: How Instruction-Following Overrides Disclosure</title>
      <link>https://arxiv.org/abs/2511.21569</link>
      <description>arXiv:2511.21569v5 Announce Type: replace-cross 
Abstract: Self-transparency is a critical safety boundary, requiring language models to honestly disclose their limitations and artificial nature. This study stress-tests this capability, investigating whether models willingly disclose their identity when assigned professional personas that conflict with transparent self-representation. When models prioritize role consistency over this boundary disclosure, users may calibrate trust based on overstated competence claims, treating AI-generated guidance as equivalent to licensed professional advice. Using a common-garden experimental design, sixteen open-weight models (4B-671B parameters) were audited under identical conditions across 19,200 trials. Models exhibited sharp domain-specific inconsistency: a Financial Advisor persona elicited 30.8% disclosure at the first prompt, while a Neurosurgeon persona elicited only 3.5% -- an 8.8-fold difference that emerged at the initial epistemic inquiry. Disclosure ranged from 2.8% to 73.6% across model families, with a 14B model reaching 39.4% while a 70B model produced just 4.1%. Model identity provided substantially larger improvement in fitting observations than parameter count ($\Delta R_{adj}^{2}=0.359$ vs $0.018$). Reasoning variants showed heterogeneous effects: some exhibited up to 48.4 percentage points lower disclosure than their base instruction-tuned counterparts, while others maintained high transparency. An additional experiment demonstrated that explicit permission to disclose AI nature increased disclosure from 23.7% to 65.8%, revealing that suppression reflects instruction-following prioritization rather than capability limitations. Bayesian validation confirmed robustness to judge measurement error ($\kappa=0.908$). Organizations cannot assume safety properties will transfer across deployment domains, requiring deliberate behavior design and empirical verification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.21569v5</guid>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alex Diep</dc:creator>
    </item>
    <item>
      <title>A Fair, Flexible, Zero-Waste Digital Electricity Market: A First-Principles Approach Combining Automatic Market Making, Holarchic Architectures and Shapley Theory</title>
      <link>https://arxiv.org/abs/2512.13871</link>
      <description>arXiv:2512.13871v2 Announce Type: replace-cross 
Abstract: This thesis presents a fundamental rethink of electricity market design at the wholesale and balancing layers. Rather than treating markets as static spot clearing mechanisms, it reframes them as a continuously online, event driven dynamical control system: a two sided marketplace operating directly on grid physics.
  Existing energy only, capacity augmented, and zonal market designs are shown to admit no shock robust Nash equilibrium under realistic uncertainty, instead relying on price caps, uplift, and regulatory intervention to preserve solvency and security. In response, the thesis develops a holarchic Automatic Market Maker (AMM) in which prices are bounded, exogenous control signals derived from physical tightness rather than emergent equilibrium outcomes.
  The AMM generalises nodal and zonal pricing through nested scarcity layers, from node to cluster to zone to region to system, such that participant facing prices inherit from the tightest binding constraint. Nodal and zonal pricing therefore emerge as special cases of a unified scarcity propagation rule.
  Beyond pricing, the AMM functions as a scarcity aware control system and a digitally enforceable rulebook for fair access and proportional allocation under shortage. Fuel costs are recovered through pay as bid energy dispatch consistent with merit order, while non fuel operating and capital costs are allocated according to adequacy, flexibility, and locational contribution.
  Large scale simulations demonstrate bounded input bounded output stability, controllable procurement costs, zero structural waste, and improved distributional outcomes. The architecture is climate aligned and policy configurable, but requires a managed transition and new operational tools for system operators and market participants.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13871v2</guid>
      <category>eess.SY</category>
      <category>cs.HC</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>stat.AP</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shaun Sweeney, Robert Shorten, Mark O'Malley</dc:creator>
    </item>
  </channel>
</rss>
