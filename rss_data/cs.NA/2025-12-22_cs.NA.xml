<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NA</link>
    <description>cs.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 22 Dec 2025 05:00:32 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 22 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>An Explicit Sixth Order Runge-Kutta Method for Simple Lawson Integration</title>
      <link>https://arxiv.org/abs/2512.17006</link>
      <description>arXiv:2512.17006v1 Announce Type: new 
Abstract: Explicit Runge-Kutta schemes become impractical when a stiff linear operator is present in the dynamics. This failure mode is quite common in numerical simulations of fluids and plasmas. Lawson proposed Generalized Runge-Kutta Processes for stiff problems in 1967, in which the stiff linear operator is treated fully implicitly via matrix exponentiation. Any Runge-Kutta scheme induces valid Lawson integration, but a scheme is exceptionally simple to implement if the abscissa $c_i$ are ordered and equally spaced. Classical RK4 satisfies this requirement, but it is difficult to derive efficient higher order schemes with this constraint. Here I present an explicit sixth order method identified with Newton-Raphson iteration that provides simple Lawson integration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.17006v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>nlin.CD</category>
      <pubDate>Mon, 22 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthew Golden</dc:creator>
    </item>
    <item>
      <title>Beyond Low Rank: Fast Low-Rank + Diagonal Decomposition with a Spectral Approach</title>
      <link>https://arxiv.org/abs/2512.17120</link>
      <description>arXiv:2512.17120v1 Announce Type: new 
Abstract: Low-rank plus diagonal (LRPD) decompositions provide a powerful structural model for large covariance matrices, simultaneously capturing global shared factors and localized corrections that arise in covariance estimation, factor analysis, and large-scale kernel learning. We introduce an alternating low-rank then diagonal (Alt) algorithm that provably reduces approximation error and significantly outperforms gradient descent while remaining cheaper than majorization-minimization methods~\cite{sun2016majorization}. To scale to large matrices, we develop a randomized LRPD variant that combines fixed-rank Nystrom sketching~\cite{tropp2017fixed} for the low-rank component with Diag++ stochastic diagonal estimation~\cite{baston2022stochastic}. This hybrid algorithm achieves machine precision decomposition error using a number of matrix-vector products far smaller than the ambient dimension, and comes with rigorous non-asymptotic error bounds. On synthetic data, it exactly recovers LRPD structured matrices with high efficiency, and on real-world S&amp;P 500 stock return covariances, where the spectrum decays slowly and strong sector structure exists, it achieves substantially lower error than pure low-rank approximations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.17120v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 22 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kingsley Yeon, Mihai Anitescu</dc:creator>
    </item>
    <item>
      <title>Long-time stability and convergence analysis of an IMEX BDF3 scheme for 2-D incompressible Navier-Stokes equation</title>
      <link>https://arxiv.org/abs/2512.17182</link>
      <description>arXiv:2512.17182v1 Announce Type: new 
Abstract: High-order time-stepping schemes are crucial for simulating incompressible fluid flows due to their ability to capture complex turbulent behavior and unsteady motion. In this work, we propose a third-order accurate numerical scheme for the two-dimensional incompressible Navier-Stokes equation. Spatial and temporal discretization is achieved using Fourier pseudo-spectral approximation and the BDF3 stencil, combined with the Adams-Bashforth extrapolation for the nonlinear convection term, resulting in a semi-implicit, fully discrete formulation. This approach requires solving only a single Poisson-like equation per time step while maintaining the desired temporal accuracy. Classical numerical experiments demonstrate the advantage of our scheme in terms of permissible time step sizes. Moreover, we establish uniform-in-time bounds for the vorticity in both $L^2$ and higher-order $H^m$ norms ($m \geq 1$), provided the time step is sufficiently small. These bounds, in turn, facilitate the derivation of optimal convergence rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.17182v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 22 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kelong Cheng, Jingwei Sun, Hong Zhang</dc:creator>
    </item>
    <item>
      <title>Sobolev Algorithm for Local Smoothness Analysis (SALSA) via Sharp Direct and Inverse Statements</title>
      <link>https://arxiv.org/abs/2512.17377</link>
      <description>arXiv:2512.17377v1 Announce Type: new 
Abstract: We extend sharp direct and inverse approximation statements for kernel-based methods for finitely smooth kernels, i.e. those whose native spaces are norm-equivalent to Sobolev spaces. In particular, our inverse results are now formulated for a broad class of approximation schemes beyond interpolation, extending existing theory. Building on these results, we propose a novel Sobolev Algorithm for Local Smoothness Analysis (SALSA) for detecting local smoothness properties of target data, including their degree of smoothness and non-smoothness. The method is rigorously grounded based on the sharp direct and inverse statements. Numerical experiments in various settings highlight the effectiveness of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.17377v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 22 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sara Avesani, Leevan Ling, Francesco Marchetti, Tizian Wenzel</dc:creator>
    </item>
    <item>
      <title>A cut finite element method for the Biot system of poroelasticity</title>
      <link>https://arxiv.org/abs/2512.17521</link>
      <description>arXiv:2512.17521v1 Announce Type: new 
Abstract: We propose a novel cut finite element method for the numerical solution of the Biot system of poroelasticity. The Biot system couples elastic deformation of a porous solid with viscous fluid flow and commonly arises on domains with complex geometries that make high-quality volumetric meshing challenging. To address this issue, we employ the cut finite element framework, where the domain boundary is represented independently of the background mesh, which significantly simplifies the meshing process. Our approach builds upon a parameter robust total pressure formulation of the Biot system, which we combine with the cut finite element method to develop a geometrically robust solution scheme, while preserving the parameter robustness. A key ingredient in the theoretical analysis is a modified inf-sup condition which also holds for mixed boundary conditions, leading to stability and optimal error estimates for the proposed formulation. Finally, we provide numerical evidence demonstrating the theoretical properties of the method and showcasing its capabilities by solving the Biot system on a realistic brain geometry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.17521v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 22 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nanna Berre, Kent-Andre Mardal, Andr\'e Massing, Ivan Yotov</dc:creator>
    </item>
    <item>
      <title>Comparison of two statistical image reconstruction algorithms for quantitative assessment of pathological lesions using gamma emission tomography</title>
      <link>https://arxiv.org/abs/2512.17523</link>
      <description>arXiv:2512.17523v1 Announce Type: new 
Abstract: This study compares two statistical approaches to image reconstruction in single-photon emission computed tomography (SPECT). We evaluated the widely used Ordered Subset Expectation Maximization (OSEM) algorithm and the newer Maximum a Posteriori approach with Entropy prior (MAP-Ent) approach in the context of quantifying radiopharmaceutical uptake in pathological lesions. Numerical experiments were performed using a digital twin of the standardized NEMA IEC phantom, which contains six spheres of varying diameters to simulate lesions. Quantitative accuracy was assessed using the maximum recovery coefficient (RCmax), defined as the ratio of the reconstructed maximum activity to the true value. The study shows that OSEM exhibits unstable convergence during iterations, leading to noise and edge artifacts in lesion images. Post-filtering stabilizes the reconstruction and ensures convergence, producing RCmax-size curves that could be used as correction factors in clinical evaluations. However, this approach significantly underestimates uptake in small lesions and may even lead to the complete loss of small lesions on reconstructed images. In contrast, MAP-Ent demonstrates fundamentally different behavior: it achieves stable convergence and preserves quantitative accuracy without post-filtering, while maintaining the contrast of even the smallest lesions. However, the iteration number at which accurate reconstruction is achieved depends strongly on the choice of a single global regularization parameter, which limits optimal performance across lesions of different sizes. These results demonstrate the need for locally adaptive regularization in MAP-Ent to improve quantitative accuracy in lesion reconstruction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.17523v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 22 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>A. V. Nesterova, N. V. Denisova</dc:creator>
    </item>
    <item>
      <title>Local h-, p-, and k-Refinement Strategies for the Isogeometric Shifted Boundary Method Using THB-Splines</title>
      <link>https://arxiv.org/abs/2512.17666</link>
      <description>arXiv:2512.17666v1 Announce Type: new 
Abstract: The concept of trimming, embedding, or immersing geometries into a computational background mesh has gained considerable attention in recent years, particularly in isogeometric analysis (IGA). In this approach, the physical domain is represented independently from the computational mesh, allowing the latter to be generated more easily compared with body-fitted meshes. While this facilitates the treatment of complex geometries, it also introduces challenges, such as ill-conditioning of the stiffness matrix caused by small cut elements and difficulties in accurately enforcing boundary conditions. A recently proposed technique to address these issues is the Shifted Boundary Method (SBM), which represents the computational domain solely through uncut elements and enforces boundary conditions via a Taylor expansion from a surrogate boundary to the true boundary. Previous studies have shown that, for Neumann boundary conditions, the flux evaluation requires additional derivatives in the Taylor expansion, effectively reducing the order of convergence by one. In this work, we investigate for the first time the performance of SBM combined with Truncated Hierarchical B-splines (THB-splines) under various local refinement strategies. In particular, we propose local p- and k-refinement schemes for THB-splines and compare them with local h-refinement and the unmodified SBM. Furthermore, we propose an enhanced shift operator that incorporates mixed partial derivatives, in contrast to the standard operator. The study assesses accuracy, stability, and computational efficiency for benchmark problems on trimmed domains. The results highlight how different refinement strategies affect convergence behavior in trimmed IGA formulations using SBM and demonstrate that targeted degree elevation can mitigate the Neumann boundary limitations of the standard method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.17666v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 22 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christoph Hollweck, Andrea Gorgi, Nicolo Antonelli, Marcus Wagner, Roland W\"uchner</dc:creator>
    </item>
    <item>
      <title>Study of a TPFA scheme for the stochastic Allen-Cahn equation with constraint though numerical experiments</title>
      <link>https://arxiv.org/abs/2512.17712</link>
      <description>arXiv:2512.17712v1 Announce Type: new 
Abstract: This contribution provides numerical experiments for a finite volume scheme for an approximation of the stochastic Allen-Cahn equation with homogeneous Neumann boundary conditions. The approximation is done by a Yosida approximation of the subdifferential operator. The problem is set on a polygonal bounded domain in two or three dimensions. The non-linear character of the projection term induces challenges to implement the scheme. To this end, we provide a splitting method for the finite volume scheme. We show that the splitting method is accurate. The computational error estimates induce that the squared $L^2$-error w.r.t. time is of order $1$ as long as the noise term is small enough. For larger noise terms the order of convergence w.r.t. time might become worse.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.17712v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.PR</category>
      <pubDate>Mon, 22 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Niklas Sapountzoglou, Aleksandra Zimmermann</dc:creator>
    </item>
    <item>
      <title>Preconditioning for the high-order sampling of the invariant distribution of parabolic semilinear SPDEs</title>
      <link>https://arxiv.org/abs/2512.17714</link>
      <description>arXiv:2512.17714v1 Announce Type: new 
Abstract: For a class of ergodic parabolic semilinear stochastic partial differential equations (SPDEs) with gradient structure, we introduce a preconditioning technique and design high-order integrators for the approximation of the invariant distribution. The preconditioning yields improved temporal regularity of the dynamics while preserving the invariant distribution and allows the application of postprocessed integrators. For the semilinear heat equation driven by space-time white noise in dimension $1$, we obtain new temporal integrators with orders $1$ and $2$ for sampling the invariant distribution with a minor overcost compared to the standard semilinear implicit Euler method of order $1/2$. Numerical experiments confirm the theoretical findings and illustrate the efficiency of the approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.17714v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.PR</category>
      <pubDate>Mon, 22 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Charles-Edouard Br\'ehier, Adrien Busnot Laurent, Arnaud Debussche, Gilles Vilmart</dc:creator>
    </item>
    <item>
      <title>Convergence rates for a finite volume scheme of a stochastic non-linear parabolic equation</title>
      <link>https://arxiv.org/abs/2512.17728</link>
      <description>arXiv:2512.17728v1 Announce Type: new 
Abstract: In this contribution, we provide convergence rates for a finite volume scheme of a stochastic non-linear parabolic equation with multiplicative Lipschitz noise and homogeneous Neumann boundary conditions. More precisely, we give an error estimate for the $L^2$-norm of the space-time discretization by a semi-implicit Euler scheme with respect to time and a two-point flux approximation finite volume scheme with respect to space and the variational solution. The only regularity assumptions additionally needed is spatial regularity of the initial datum and smoothness of the diffusive term.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.17728v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.PR</category>
      <pubDate>Mon, 22 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kavin Rajasekaran, Niklas Sapountzoglou</dc:creator>
    </item>
    <item>
      <title>A Short Report on Importance Sampling for Rare Event Simulation in Diffusions</title>
      <link>https://arxiv.org/abs/2512.17766</link>
      <description>arXiv:2512.17766v1 Announce Type: new 
Abstract: In this manuscript, we investigate importance sampling methods for rare-event simulation in diffusion processes. We show, from a large-deviation perspective, that the resulting importance sampling estimator is log-efficient. This connection is established via a stochastic optimal control formulation, and the associated Hamilton--Jacobi--Bellman (HJB) equation is derived using dynamic programming. To approximate the optimal control, we adopt a spectral parameterization and employ the cross-entropy method to estimate the parameters by solving a least-squares problem. Finally, we present a numerical example to validate the effectiveness of the cross-entropy approach and the efficiency of the resulting importance sampling estimator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.17766v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.PR</category>
      <pubDate>Mon, 22 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Zhiwei Gao</dc:creator>
    </item>
    <item>
      <title>On General Linearly Implicit Quantized State System Methods</title>
      <link>https://arxiv.org/abs/2512.17855</link>
      <description>arXiv:2512.17855v1 Announce Type: new 
Abstract: This work proposes a methodology to develop new numerical integration algorithms for ordinary differential equations based on state quantization, generalizing the notions of Linearly Implicit Quantized State Systems (LIQSS) methods. Using this idea, two novel sub-families of algorithms are designed that improve the performance of current LIQSS methods while preserving their properties regarding stability, global error bound and efficient event handling capabilities. The features of the new algorithms are studied in two application examples where the advantages over classic numerical integration algorithms is also analyzed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.17855v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>cs.PF</category>
      <pubDate>Mon, 22 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mariana Bergonzi, Joaqu\'in Fern\'andez, Ernesto Kofman</dc:creator>
    </item>
    <item>
      <title>Learning solution operator of dynamical systems with diffusion maps kernel ridge regression</title>
      <link>https://arxiv.org/abs/2512.17203</link>
      <description>arXiv:2512.17203v1 Announce Type: cross 
Abstract: Many scientific and engineering systems exhibit complex nonlinear dynamics that are difficult to predict accurately over long time horizons. Although data-driven models have shown promise, their performance often deteriorates when the geometric structures governing long-term behavior are unknown or poorly represented. We demonstrate that a simple kernel ridge regression (KRR) framework, when combined with a dynamics-aware validation strategy, provides a strong baseline for long-term prediction of complex dynamical systems. By employing a data-driven kernel derived from diffusion maps, the proposed Diffusion Maps Kernel Ridge Regression (DM-KRR) method implicitly adapts to the intrinsic geometry of the system's invariant set, without requiring explicit manifold reconstruction or attractor modeling, procedures that often limit predictive performance. Across a broad range of systems, including smooth manifolds, chaotic attractors, and high-dimensional spatiotemporal flows, DM-KRR consistently outperforms state-of-the-art random feature, neural-network and operator-learning methods in both accuracy and data efficiency. These findings underscore that long-term predictive skill depends not only on model expressiveness, but critically on respecting the geometric constraints encoded in the data through dynamically consistent model selection. Together, simplicity, geometry awareness, and strong empirical performance point to a promising path for reliable and efficient learning of complex dynamical systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.17203v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 22 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiwoo Song, Daning Huang, John Harlim</dc:creator>
    </item>
    <item>
      <title>Approximating geodesics of hyperbolic type metrics on planar domains</title>
      <link>https://arxiv.org/abs/2512.17211</link>
      <description>arXiv:2512.17211v1 Announce Type: cross 
Abstract: We study planar domains $G$ equipped with a hyperbolic type metric and approximate geodesics that join two points $x,y \in G$ and their lengths. We present an algorithm that enables one to approximate the shortest distance in polygonal domains taken with respect to the quasihyperbolic metric. The method is based on Dijkstra's algorithm, and we give several examples demonstrating how the algorithm works and analyze its accuracy. We experimentally demonstrate several previously theoretically observed features of geodesics, such as the relationship between hyperbolic and quasihyperbolic distance in the unit disk. We also investigate bifurcation of geodesics and the connection of this phenomenon to the medial axis of the domain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.17211v1</guid>
      <category>math.MG</category>
      <category>cs.NA</category>
      <category>math.CV</category>
      <category>math.NA</category>
      <pubDate>Mon, 22 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuliang Gao, Anni Hakanen, Antti Rasila, Matti Vuorinen</dc:creator>
    </item>
    <item>
      <title>MINPO: Memory-Informed Neural Pseudo-Operator to Resolve Nonlocal Spatiotemporal Dynamics</title>
      <link>https://arxiv.org/abs/2512.17273</link>
      <description>arXiv:2512.17273v1 Announce Type: cross 
Abstract: Many physical systems exhibit nonlocal spatiotemporal behaviors described by integro-differential equations (IDEs). Classical methods for solving IDEs require repeatedly evaluating convolution integrals, whose cost increases quickly with kernel complexity and dimensionality. Existing neural solvers can accelerate selected instances of these computations, yet they do not generalize across diverse nonlocal structures. In this work, we introduce the Memory-Informed Neural Pseudo-Operator (MINPO), a unified framework for modeling nonlocal dynamics arising from long-range spatial interactions and/or long-term temporal memory. MINPO, employing either Kolmogorov-Arnold Networks (KANs) or multilayer perceptron networks (MLPs) as encoders, learns the nonlocal operator and its inverse directly through neural representations, and then explicitly reconstruct the unknown solution fields. The learning is guarded by a lightweight nonlocal consistency loss term to enforce coherence between the learned operator and reconstructed solution. The MINPO formulation allows to naturally capture and efficiently resolve nonlocal spatiotemporal dependencies governed by a wide spectrum of IDEs and their subsets, including fractional PDEs. We evaluate the efficacy of MINPO in comparison with classical techniques and state-of-the-art neural-based strategies based on MLPs, such as A-PINN and fPINN, along with their newly-developed KAN variants, A-PIKAN and fPIKAN, designed to facilitate a fair comparison. Our study offers compelling evidence of the accuracy of MINPO and demonstrates its robustness in handling (i) diverse kernel types, (ii) different kernel dimensionalities, and (iii) the substantial computational demands arising from repeated evaluations of kernel integrals. MINPO, thus, generalizes beyond problem-specific formulations, providing a unified framework for systems governed by nonlocal operators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.17273v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.NA</category>
      <pubDate>Mon, 22 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Farinaz Mostajeran, Aruzhan Tleubek, Salah A Faroughi</dc:creator>
    </item>
    <item>
      <title>Polyharmonic Cascade</title>
      <link>https://arxiv.org/abs/2512.17671</link>
      <description>arXiv:2512.17671v1 Announce Type: cross 
Abstract: This paper presents a deep machine learning architecture, the "polyharmonic cascade" -- a sequence of packages of polyharmonic splines, where each layer is rigorously derived from the theory of random functions and the principles of indifference. This makes it possible to approximate nonlinear functions of arbitrary complexity while preserving global smoothness and a probabilistic interpretation. For the polyharmonic cascade, a training method alternative to gradient descent is proposed: instead of directly optimizing the coefficients, one solves a single global linear system on each batch with respect to the function values at fixed "constellations" of nodes. This yields synchronized updates of all layers, preserves the probabilistic interpretation of individual layers and theoretical consistency with the original model, and scales well: all computations reduce to 2D matrix operations efficiently executed on a GPU. Fast learning without overfitting on MNIST is demonstrated.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.17671v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 22 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuriy N. Bakhvalov</dc:creator>
    </item>
    <item>
      <title>Towards Sharp Minimax Risk Bounds for Operator Learning</title>
      <link>https://arxiv.org/abs/2512.17805</link>
      <description>arXiv:2512.17805v1 Announce Type: cross 
Abstract: We develop a minimax theory for operator learning, where the goal is to estimate an unknown operator between separable Hilbert spaces from finitely many noisy input-output samples. For uniformly bounded Lipschitz operators, we prove information-theoretic lower bounds together with matching or near-matching upper bounds, covering both fixed and random designs under Hilbert-valued Gaussian noise and Gaussian white noise errors. The rates are controlled by the spectrum of the covariance operator of the measure that defines the error metric. Our setup is very general and allows for measures with unbounded support. A key implication is a curse of sample complexity which shows that the minimax risk for generic Lipschitz operators cannot decay at any algebraic rate in the sample size. We obtain essentially sharp characterizations when the covariance spectrum decays exponentially and provide general upper and lower bounds in slower-decay regimes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.17805v1</guid>
      <category>math.ST</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Mon, 22 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ben Adcock, Gregor Maier, Rahul Parhi</dc:creator>
    </item>
    <item>
      <title>Regularized Random Fourier Features and Finite Element Reconstruction for Operator Learning in Sobolev Space</title>
      <link>https://arxiv.org/abs/2512.17884</link>
      <description>arXiv:2512.17884v1 Announce Type: cross 
Abstract: Operator learning is a data-driven approximation of mappings between infinite-dimensional function spaces, such as the solution operators of partial differential equations. Kernel-based operator learning can offer accurate, theoretically justified approximations that require less training than standard methods. However, they can become computationally prohibitive for large training sets and can be sensitive to noise. We propose a regularized random Fourier feature (RRFF) approach, coupled with a finite element reconstruction map (RRFF-FEM), for learning operators from noisy data. The method uses random features drawn from multivariate Student's $t$ distributions, together with frequency-weighted Tikhonov regularization that suppresses high-frequency noise. We establish high-probability bounds on the extreme singular values of the associated random feature matrix and show that when the number of features $N$ scales like $m \log m$ with the number of training samples $m$, the system is well-conditioned, which yields estimation and generalization guarantees. Detailed numerical experiments on benchmark PDE problems, including advection, Burgers', Darcy flow, Helmholtz, Navier-Stokes, and structural mechanics, demonstrate that RRFF and RRFF-FEM are robust to noise and achieve improved performance with reduced training time compared to the unregularized random feature model, while maintaining competitive accuracy relative to kernel and neural operator tests.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.17884v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Mon, 22 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xinyue Yu, Hayden Schaeffer</dc:creator>
    </item>
    <item>
      <title>openCFS-Data: Data Pre-Post-Processing Tool for openCFS</title>
      <link>https://arxiv.org/abs/2302.03637</link>
      <description>arXiv:2302.03637v3 Announce Type: replace 
Abstract: Many numerical simulation tools have been developed and are on the market, but there is still a strong need for appropriate tools capable to simulate multi-field problems, especially in aeroacoustics. Therefore, openCFS provides an open-source framework for implementing partial differential equations using the finite element method. Since 2000, the software has been developed continuously. The result of is openCFS (before 2020 known as CFS++ Coupled Field Simulations written in C++). In this paper, we present for the first time the CFS-Data, the open-source pre-post-processing part of openCFS with a focus on the aeroacoustic source computation (called filters).</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.03637v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 22 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefan Schoder, Klaus Roppert</dc:creator>
    </item>
    <item>
      <title>Expression Rates of Neural Operators for Linear Elliptic PDEs in Polytopes</title>
      <link>https://arxiv.org/abs/2409.17552</link>
      <description>arXiv:2409.17552v3 Announce Type: replace 
Abstract: We study the approximation rates of a class of deep neural network approximations of operators which arise as data-to-solution maps $\mathcal{S}$ of linear elliptic partial differential equations (PDEs), and act between pairs $X,Y$ of suitable infinite-dimensional spaces. We prove expression rate bounds for approximate neural operators $\mathcal{G}$ with the structure $\mathcal{G} = \mathcal{R} \circ \mathcal{A} \circ \mathcal{E}$, with linear encoders $\mathcal{E}$ and decoders $\mathcal{R}$. We focus in particular on deepONets emulating the coefficient-to-solution maps for elliptic PDEs set in polygons and in some polyhedra. Exploiting the regularity of the solution sets of elliptic PDEs in polytopes, we show algebraic rates of convergence for problems with data with finite regularity, and exponential rates for analytic data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.17552v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 22 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Carlo Marcati, Christoph Schwab</dc:creator>
    </item>
    <item>
      <title>Unified interface flux evaluation in a general discontinuous Galerkin spectral element framework</title>
      <link>https://arxiv.org/abs/2504.03573</link>
      <description>arXiv:2504.03573v2 Announce Type: replace 
Abstract: High-order discontinuous Galerkin spectral element methods (DGSEM) have received growing attention and development, especially in the regime of computational fluid dynamics in recent years. The inherent flexibility of the discontinuous Galerkin approach in handling non-conforming interfaces, such as those encountered in moving geometries or hp-refinement, presents a significant advantage for real-world simulations. Despite the well-established mathematical framework of DG methods, practical implementation challenges persist to boost performance and capability. Most previous studies only focus on certain choices of element shape or basis type in a structured mesh, although they have demonstrated the capability of DGSEM in complex flow simulations. This work discusses the low-cost and unified interface flux evaluation approaches for general spectral elements in unstructured meshes, alongside their implementations in the open-source spectral element framework, Nektar++. The initial motivation arises from the discretization of Helmholtz equations by the symmetric interior penalty method, in which the system matrix can easily become non-symmetric if the flux is not properly evaluated on non-conforming interfaces. We focus on the polynomial non-conforming case in this work but extending to the geometric non-conforming case is theoretically possible. Comparisons of different approaches, trade-offs, and performance of benchmark of our initial matrix-free implementation are also included, contributing to the broader discourse on high-performance spectral element method implementations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03573v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 22 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Boyang Xia, David Moxey</dc:creator>
    </item>
    <item>
      <title>BOLT: Block-Orthonormal Lanczos for Trace estimation of matrix functions</title>
      <link>https://arxiv.org/abs/2505.12289</link>
      <description>arXiv:2505.12289v2 Announce Type: replace 
Abstract: Efficient matrix trace estimation is essential for scalable computation of log-determinants, matrix norms, and distributional divergences. In many large-scale applications, the matrices involved are too large to store or access in full, making even a single matrix-vector (mat-vec) product infeasible. Instead, one often has access only to small subblocks of the matrix or localized matrix-vector products on restricted index sets. Hutch++ achieves optimal convergence rate but relies on randomized SVD and assumes full mat-vec access, making it difficult to apply in these constrained settings. We propose the Block-Orthonormal Stochastic Lanczos Quadrature (BOLT), which matches Hutch++ accuracy with a simpler implementation based on orthonormal block probes and Lanczos iterations. BOLT builds on the Stochastic Lanczos Quadrature (SLQ) framework, which combines random probing with Krylov subspace methods to efficiently approximate traces of matrix functions, and performs better than Hutch++ in near flat-spectrum regimes. To address memory limitations and partial access constraints, we introduce Subblock SLQ, a variant of BOLT that operates only on small principal submatrices. As a result, this framework yields a proxy KL divergence estimator and an efficient method for computing the Wasserstein-2 distance between Gaussians - both compatible with low-memory and partial-access regimes. We provide theoretical guarantees and demonstrate strong empirical performance across a range of high-dimensional settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12289v2</guid>
      <category>math.NA</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Mon, 22 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kingsley Yeon, Promit Ghosal, Mihai Anitescu</dc:creator>
    </item>
    <item>
      <title>Optimal solutions employing an algebraic Variational Multiscale approach Part II: Application to Navier-Stokes</title>
      <link>https://arxiv.org/abs/2506.21395</link>
      <description>arXiv:2506.21395v3 Announce Type: replace 
Abstract: This work presents a non-linear extension of the high-order discretisation framework based on the Variational Multiscale (VMS) method previously introduced for steady linear problems. We build on the concept of an optimal projector defined via the symmetric part of the governing operator. Using this idea, we generalise the formulation to the two-dimensional incompressible Navier-Stokes equations. The approach maintains a clear separation between resolved and unresolved scales, with the fine-scale contribution approximated through the approximate Fine-Scale Greens' operator of the associated symmetric operator. This enables a consistent variational treatment of non-linearity while preserving high-order accuracy. We show that the method yields numerical solutions that closely approximate the optimal projection of the continuous/highly-resolved solution and inherits desirable conservation properties. Particularly, the formulation guarantees discrete conservation of mass, energy, and vorticity, where enstrophy conservation is also achieved when exact or over-integration is employed. Numerical results confirm the methodology's robustness and accuracy, while also demonstrating its computational cost advantage compared to the baseline Galerkin approach for the same accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.21395v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 22 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Suyash Shrestha, Marc Gerritsma, Gonzalo Rubio, Steven Hulshoff, Esteban Ferrer</dc:creator>
    </item>
    <item>
      <title>Multi-Order Runge-Kutta Methods or how to numerically solve initial value problems of any order</title>
      <link>https://arxiv.org/abs/2509.23513</link>
      <description>arXiv:2509.23513v3 Announce Type: replace 
Abstract: When one wishes to numerically solve an initial value problem, it is customary to rewrite it as an equivalent first-order system to which a method, usually from the class of Runge-Kutta methods, is applied. Directly treating higher-order initial value problems without such rewriting, however, allows for significantly greater accuracy. We therefore introduce a new generalization of Runge-Kutta methods, called multi-order Runge-Kutta methods, designed to solve initial value problems of arbitrary order. We establish fundamental properties of these methods, including convergence, order of consistency, and linear stability. We also analyze the structure of the system satisfied by the approximations of a method, which enables us to provide a proper definition of explicit methods and to gain a finer understanding of implicit methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23513v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 22 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Loris Petronijevic</dc:creator>
    </item>
    <item>
      <title>Refinement-based Christoffel sampling for least squares approximation in non-orthogonal bases</title>
      <link>https://arxiv.org/abs/2510.08461</link>
      <description>arXiv:2510.08461v2 Announce Type: replace 
Abstract: We introduce a refinement-based Christoffel sampling (RCS) algorithm for least squares approximation in the span of a given, generally non-orthogonal set of functions $\Phi_n = \{\phi_1, \dots, \phi_n\}$. A standard sampling strategy for this problem is Christoffel sampling, which achieves near-best approximations in probability using only $\mathcal{O}(n \log(n))$ samples. However, it requires i.i.d. sampling from a distribution whose density is proportional to the inverse Christoffel function $k_n$, the computation of which requires an orthonormal basis. As a result, existing approaches for non-orthogonal bases $\Phi_n$ typically rely on costly discrete orthogonalization. We propose a new iterative algorithm, inspired by recent advances in approximate leverage score sampling, that avoids this bottleneck. Crucially, while the computational cost of discrete orthogonalization grows proportionally with $\|k_n\|_{L^\infty(X)}$, the cost of our approach increases only logarithmically in $\|k_n\|_{L^\infty(X)}$. In addition, we account for finite-precision effects by considering a numerical variant of the Christoffel function, ensuring that the algorithm relies only on computable quantities. Alongside a convergence proof, we present extensive numerical experiments demonstrating the efficiency and robustness of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08461v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 22 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Astrid Herremans, Ben Adcock</dc:creator>
    </item>
    <item>
      <title>Fast operator learning for mapping correlations</title>
      <link>https://arxiv.org/abs/2512.09286</link>
      <description>arXiv:2512.09286v2 Announce Type: replace 
Abstract: We propose a fast, optimization-free method for learning the transition operators of high-dimensional Markov processes. The central idea is to perform a Galerkin projection of the transition operator to a suitable set of low-order bases that capture the correlations between the dimensions. Such a discretized operator can be obtained from moments corresponding to our choice of basis without curse of dimensionality. Furthermore, by exploiting its low-rank structure and the spatial decay of correlations, we can obtain a compressed representation with computational complexity of order $\mathcal{O}(dN)$, where $d$ is the dimensionality and $N$ is the sample size. We further theoretically analyze the approximation error of the proposed compressed representation. We numerically demonstrate that the learned operator allows efficient prediction of future events and solving high-dimensional boundary value problems. This gives rise to a simple linear algebraic method for high-dimensional rare-events simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.09286v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 22 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuehaw Khoo, Yuguan Wang, Siyao Yang</dc:creator>
    </item>
    <item>
      <title>Optimization of gridding algorithms for FFT by vector optimization</title>
      <link>https://arxiv.org/abs/2512.14914</link>
      <description>arXiv:2512.14914v3 Announce Type: replace 
Abstract: The Fast Fourier Transform (FFT) is widely used in applications such as MRI, CT, and interferometry; however, because of its dependence on uniformly sampled data, it requires the use of gridding techniques for practical implementation. The performance of these algorithms strongly depends on the choice of the gridding kernel, with the first prolate spheroidal wave function (PSWF) regarded as optimal. This work redefines kernel optimality through the lens of vector optimization (VO), introducing a rigorous framework that characterizes optimal kernels as Pareto-efficient solutions of an error shape operator. We establish the continuity of such operator, study the existence of solutions, and propose a novel methodology to construct kernels tailored to a desired target error function. The approach is implemented numerically via interior-point optimization. Comparative experiments demonstrate that the proposed kernels outperform both the PSWF and the state-of-the-art methods (MIRT-NUFFT) in specific regions of interest, achieving orders-of-magnitude improvements in mean absolute errors. These results confirm the potential of VO-based kernel design to provide customized accuracy profiles aligned with application-specific requirements. Future research will extend this framework to multidimensional cases and relative error minimization, with potential integration of machine learning for adaptive target error selection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.14914v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 22 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Federico Achini, Paola Causin, Sara Vanini, Ke Chen, Simone Scacchi</dc:creator>
    </item>
    <item>
      <title>A New Fast Finite Difference Scheme for Tempered Time Fractional Advection-Dispersion Equation with a Weak Singularity at Initial Time</title>
      <link>https://arxiv.org/abs/2512.15141</link>
      <description>arXiv:2512.15141v3 Announce Type: replace 
Abstract: In this paper, we propose a new second-order fast finite difference scheme in time for solving the Tempered Time Fractional Advection-Dispersion Equation. Under the assumption that the solution is nonsmooth at the initial time, we investigate the uniqueness, stability, and convergence of the scheme. Furthermore, we prove that the scheme achieves second-order convergence in both time and space. Finally, corresponding numerical examples are provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.15141v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <pubDate>Mon, 22 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liangcai Huang, Shujuan L\"u</dc:creator>
    </item>
    <item>
      <title>Incremental Generation is Necessary and Sufficient for Universality in Flow-Based Modelling</title>
      <link>https://arxiv.org/abs/2511.09902</link>
      <description>arXiv:2511.09902v2 Announce Type: replace-cross 
Abstract: Incremental flow-based denoising models have reshaped generative modelling, but their empirical advantage still lacks a rigorous approximation-theoretic foundation. We show that incremental generation is necessary and sufficient for universal flow-based generation on the largest natural class of self-maps of $[0,1]^d$ compatible with denoising pipelines, namely the orientation-preserving homeomorphisms of $[0,1]^d$. All our guarantees are uniform on the underlying maps and hence imply approximation both samplewise and in distribution.
  Using a new topological-dynamical argument, we first prove an impossibility theorem: the class of all single-step autonomous flows, independently of the architecture, width, depth, or Lipschitz activation of the underlying neural network, is meagre and therefore not universal in the space of orientation-preserving homeomorphisms of $[0,1]^d$. By exploiting algebraic properties of autonomous flows, we conversely show that every orientation-preserving Lipschitz homeomorphism on $[0,1]^d$ can be approximated at rate $O(n^{-1/d})$ by a composition of at most $K_d$ such flows, where $K_d$ depends only on the dimension. Under additional smoothness assumptions, the approximation rate can be made dimension-free, and $K_d$ can be chosen uniformly over the class being approximated. Finally, by linearly lifting the domain into one higher dimension, we obtain structured universal approximation results for continuous functions and for probability measures on $[0,1]^d$, the latter realized as pushforwards of empirical measures with vanishing $1$-Wasserstein error.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.09902v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.CA</category>
      <category>math.DS</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Mon, 22 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hossein Rouhvarzi, Anastasis Kratsios</dc:creator>
    </item>
    <item>
      <title>Multiscale modeling of blood circulation with cerebral autoregulation and network pathway analysis for hemodynamic redistribution in the vascular network with anatomical variations and stenosis conditions</title>
      <link>https://arxiv.org/abs/2512.15482</link>
      <description>arXiv:2512.15482v2 Announce Type: replace-cross 
Abstract: Cerebral hemodynamics is fundamentally regulated by the Circle of Willis (CoW), which redistributes flow through communicating arteries to stabilize perfusion under anatomical variations and vascular stenosis. In this study, we develop a multiscale circulation model by coupling a systemic hemodynamic framework with a cerebral arterial network reconstructed from medical imaging. The model incorporates a cerebral autoregulation mechanism (CAM) and enables quantitative simulation of flow redistribution within the CoW under normal, anatomically varied, and stenotic conditions. Baseline simulations reproduce physiological flow distributions in which communicating arteries remain nearly inactive, showing negligible cross-flow and agreement with clinical measurements. In contrast, anatomical variations reveal distinct collateral activation patterns: the anterior communicating artery (ACoA) emerges as the earliest and most sensitive functional collateral, whereas the posterior communicating arteries (PCoAs) exhibit structure-dependent engagement. Progressive stenosis simulations further demonstrate a transition from a complete CoW to a fetal-type posterior cerebral artery (PCA) configuration, characterized by early ACoA flow reversal followed by ipsilateral PCoA activation, consistent with experimental and transcranial Doppler observations. Finally, a path-based quantitative analysis is introduced to illustrate how the cerebral vascular network dynamically reconfigures collateral pathways in response to structural changes. Overall, the proposed framework provides a physiologically interpretable, image-informed tool for investigating cerebral flow regulation through functional collaterals within the CoW, with potential applications in the diagnosis and treatment planning of cerebrovascular diseases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.15482v2</guid>
      <category>physics.med-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 22 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiawei Liu, Atsushi Kanoke, Hidenori Endo, Kuniyasu Niizuma, Hiroshi Suito</dc:creator>
    </item>
  </channel>
</rss>
