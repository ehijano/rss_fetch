<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 03 Jul 2024 01:47:38 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 02 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Distributed Systems in Fintech</title>
      <link>https://arxiv.org/abs/2407.00034</link>
      <description>arXiv:2407.00034v1 Announce Type: cross 
Abstract: The emergence of distributed systems has revolutionized the financial technology (Fintech) landscape, offering unprecedented opportunities for enhancing security, scalability, and efficiency in financial operations. This paper explores the role of distributed systems in Fintech, analyzing their architecture, benefits, challenges, and applications. It examines key distributed technologies such as blockchain, decentralized finance (DeFi), and distributed ledger technology (DLT), and their impact on various aspects of the financial industry, and future directions for distributed systems in Fintech.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00034v1</guid>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.13140/RG.2.2.12897.11368</arxiv:DOI>
      <dc:creator>Anurag Mashruwala</dc:creator>
    </item>
    <item>
      <title>Combinatorial Reasoning: Selecting Reasons in Generative AI Pipelines via Combinatorial Optimization</title>
      <link>https://arxiv.org/abs/2407.00071</link>
      <description>arXiv:2407.00071v1 Announce Type: cross 
Abstract: Recent Large Language Models (LLMs) have demonstrated impressive capabilities at tasks that require human intelligence and are a significant step towards human-like artificial intelligence (AI). Yet the performance of LLMs at reasoning tasks have been subpar and the reasoning capability of LLMs is a matter of significant debate. While it has been shown that the choice of the prompting technique to the LLM can alter its performance on a multitude of tasks, including reasoning, the best performing techniques require human-made prompts with the knowledge of the tasks at hand. We introduce a framework for what we call Combinatorial Reasoning (CR), a fully-automated prompting method, where reasons are sampled from an LLM pipeline and mapped into a Quadratic Unconstrained Binary Optimization (QUBO) problem. The framework investigates whether QUBO solutions can be profitably used to select a useful subset of the reasons to construct a Chain-of-Thought style prompt. We explore the acceleration of CR with specialized solvers. We also investigate the performance of simpler zero-shot strategies such as linear majority rule or random selection of reasons. Our preliminary study indicates that coupling a combinatorial solver to generative AI pipelines is an interesting avenue for AI reasoning and elucidates design principles for future CR methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00071v1</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mert Esencan, Tarun Advaith Kumar, Ata Akbari Asanjan, P. Aaron Lott, Masoud Mohseni, Can Unlu, Davide Venturelli, Alan Ho</dc:creator>
    </item>
    <item>
      <title>Semantic Revolution from Communications to Orchestration for 6G: Challenges, Enablers, and Research Directions</title>
      <link>https://arxiv.org/abs/2407.00081</link>
      <description>arXiv:2407.00081v1 Announce Type: cross 
Abstract: In the context of emerging 6G services, the realization of everything-to-everything interactions involving a myriad of physical and digital entities presents a crucial challenge. This challenge is exacerbated by resource scarcity in communication infrastructures, necessitating innovative solutions for effective service implementation. Exploring the potential of Semantic Communications (SemCom) to enhance point-to-point physical layer efficiency shows great promise in addressing this challenge. However, achieving efficient SemCom requires overcoming the significant hurdle of knowledge sharing between semantic decoders and encoders, particularly in the dynamic and non-stationary environment with stringent end-to-end quality requirements. To bridge this gap in existing literature, this paper introduces the Knowledge Base Management And Orchestration (KB-MANO) framework. Rooted in the concepts of Computing-Network Convergence (CNC) and lifelong learning, KB-MANO is crafted for the allocation of network and computing resources dedicated to updating and redistributing KBs across the system. The primary objective is to minimize the impact of knowledge management activities on actual service provisioning. A proof-of-concept is proposed to showcase the integration of KB-MANO with resource allocation in radio access networks. Finally, the paper offers insights into future research directions, emphasizing the transformative potential of semantic-oriented communication systems in the realm of 6G technology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00081v1</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Masoud Shokrnezhad, Hamidreza Mazandarani, Tarik Taleb, Jaeseung Song, Richard Li</dc:creator>
    </item>
    <item>
      <title>Visual Reasoning and Multi-Agent Approach in Multimodal Large Language Models (MLLMs): Solving TSP and mTSP Combinatorial Challenges</title>
      <link>https://arxiv.org/abs/2407.00092</link>
      <description>arXiv:2407.00092v1 Announce Type: cross 
Abstract: Multimodal Large Language Models (MLLMs) harness comprehensive knowledge spanning text, images, and audio to adeptly tackle complex problems, including zero-shot in-context learning scenarios. This study explores the ability of MLLMs in visually solving the Traveling Salesman Problem (TSP) and Multiple Traveling Salesman Problem (mTSP) using images that portray point distributions on a two-dimensional plane. We introduce a novel approach employing multiple specialized agents within the MLLM framework, each dedicated to optimizing solutions for these combinatorial challenges. Our experimental investigation includes rigorous evaluations across zero-shot settings and introduces innovative multi-agent zero-shot in-context scenarios. The results demonstrated that both multi-agent models. Multi-Agent 1, which includes the Initializer, Critic, and Scorer agents, and Multi-Agent 2, which comprises only the Initializer and Critic agents; significantly improved solution quality for TSP and mTSP problems. Multi-Agent 1 excelled in environments requiring detailed route refinement and evaluation, providing a robust framework for sophisticated optimizations. In contrast, Multi-Agent 2, focusing on iterative refinements by the Initializer and Critic, proved effective for rapid decision-making scenarios. These experiments yield promising outcomes, showcasing the robust visual reasoning capabilities of MLLMs in addressing diverse combinatorial problems. The findings underscore the potential of MLLMs as powerful tools in computational optimization, offering insights that could inspire further advancements in this promising field. Project link: https://github.com/ahmed-abdulhuy/Solving-TSP-and-mTSP-Combinatorial-Challenges-using-Visual-Reasoning-and-Multi-Agent-Approach-MLLMs-.git</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00092v1</guid>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammed Elhenawy, Ahmad Abutahoun, Taqwa I. Alhadidi, Ahmed Jaber, Huthaifa I. Ashqar, Shadi Jaradat, Ahmed Abdelhay, Sebastien Glaser, Andry Rakotonirainy</dc:creator>
    </item>
    <item>
      <title>Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach</title>
      <link>https://arxiv.org/abs/2407.00167</link>
      <description>arXiv:2407.00167v1 Announce Type: cross 
Abstract: In recent years, the United States has witnessed a significant surge in the popularity of vaping or e-cigarette use, leading to a notable rise in cases of e-cigarette and vaping use-associated lung injury (EVALI) that caused hospitalizations and fatalities during the EVALI outbreak in 2019, highlighting the urgency to comprehend vaping behaviors and develop effective strategies for cessation. Due to the ubiquity of social media platforms, over 4.7 billion users worldwide use them for connectivity, communications, news, and entertainment with a significant portion of the discourse related to health, thereby establishing social media data as an invaluable organic data resource for public health research. In this study, we extracted a sample dataset from one vaping sub-community on Reddit to analyze users' quit-vaping intentions. Leveraging OpenAI's latest large language model GPT-4 for sentence-level quit vaping intention detection, this study compares the outcomes of this model against layman and clinical expert annotations. Using different prompting strategies such as zero-shot, one-shot, few-shot and chain-of-thought prompting, we developed 8 prompts with varying levels of detail to explain the task to GPT-4 and also evaluated the performance of the strategies against each other. These preliminary findings emphasize the potential of GPT-4 in social media data analysis, especially in identifying users' subtle intentions that may elude human detection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00167v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.HC</category>
      <category>cs.SI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sai Krishna Revanth Vuruma, Dezhi Wu, Saborny Sen Gupta, Lucas Aust, Valerie Lookingbill, Wyatt Bellamy, Yang Ren, Erin Kasson, Li-Shiun Chen, Patricia Cavazos-Rehg, Dian Hu, Ming Huang</dc:creator>
    </item>
    <item>
      <title>Assistive Image Annotation Systems with Deep Learning and Natural Language Capabilities: A Review</title>
      <link>https://arxiv.org/abs/2407.00252</link>
      <description>arXiv:2407.00252v1 Announce Type: cross 
Abstract: While supervised learning has achieved significant success in computer vision tasks, acquiring high-quality annotated data remains a bottleneck. This paper explores both scholarly and non-scholarly works in AI-assistive deep learning image annotation systems that provide textual suggestions, captions, or descriptions of the input image to the annotator. This potentially results in higher annotation efficiency and quality. Our exploration covers annotation for a range of computer vision tasks including image classification, object detection, regression, instance, semantic segmentation, and pose estimation. We review various datasets and how they contribute to the training and evaluation of AI-assistive annotation systems. We also examine methods leveraging neuro-symbolic learning, deep active learning, and self-supervised learning algorithms that enable semantic image understanding and generate free-text output. These include image captioning, visual question answering, and multi-modal reasoning. Despite the promising potential, there is limited publicly available work on AI-assistive image annotation with textual output capabilities. We conclude by suggesting future research directions to advance this field, emphasizing the need for more publicly accessible datasets and collaborative efforts between academia and industry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00252v1</guid>
      <category>cs.CV</category>
      <category>cs.ET</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Moseli Mots'oehli</dc:creator>
    </item>
    <item>
      <title>Extracting Equations of Motion from Superconducting Circuits</title>
      <link>https://arxiv.org/abs/2307.01926</link>
      <description>arXiv:2307.01926v4 Announce Type: replace-cross 
Abstract: Alternative computing paradigms open the door to exploiting recent innovations in computational hardware to probe the fundamental thermodynamic limits of information processing. One such paradigm employs superconducting quantum interference devices (SQUIDs) to execute classical computations. This, though, requires constructing sufficiently complex superconducting circuits that support a suite of useful information processing tasks and storage operations, as well as understanding these circuits' energetics. First-principle circuit design, though, leads to prohibitive algebraic complications when deriving the effective equations of motion -- complications that to date have precluded achieving these goals, let alone doing so efficiently. We circumvent these complications by (i) specializing our class of circuits and physical operating regimes, (ii) synthesizing existing derivation techniques to suit these specializations, and (iii) implementing solution-finding optimizations which facilitate physically interpreting circuit degrees of freedom that respect physically-grounded constraints. This leads to efficient, practical circuit prototyping and access to scalable circuit architectures. The analytical efficiency is demonstrated by reproducing the potential energy landscape generated by the quantum flux parametron (QFP). We then show how inductively coupling two QFPs produces a device that is capable of executing 2-bit computations via its composite potential energy landscape. More generally, the synthesis methods detailed here provide a basis for constructing universal logic gates and investigating their thermodynamic performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.01926v4</guid>
      <category>cond-mat.stat-mech</category>
      <category>cs.ET</category>
      <category>nlin.CD</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christian Z. Pratt, Kyle J. Ray, James P. Crutchfield</dc:creator>
    </item>
    <item>
      <title>$Classi|Q\rangle$ Towards a Translation Framework To Bridge The Classical-Quantum Programming Gap</title>
      <link>https://arxiv.org/abs/2406.06764</link>
      <description>arXiv:2406.06764v3 Announce Type: replace-cross 
Abstract: Quantum computing, albeit readily available as hardware or emulated on the cloud, is still far from being available in general regarding complex programming paradigms and learning curves. This vision paper introduces $Classi|Q\rangle$, a translation framework idea to bridge Classical and Quantum Computing by translating high-level programming languages, e.g., Python or C++, into a low-level language, e.g., Quantum Assembly. Our idea paper serves as a blueprint for ongoing efforts in quantum software engineering, offering a roadmap for further $Classi|Q\rangle$ development to meet the diverse needs of researchers and practitioners. $Classi|Q\rangle$ is designed to empower researchers and practitioners with no prior quantum experience to harness the potential of hybrid quantum computation. We also discuss future enhancements to $Classi|Q\rangle$, including support for additional quantum languages, improved optimization strategies, and integration with emerging quantum computing platforms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06764v3</guid>
      <category>cs.SE</category>
      <category>cs.CL</category>
      <category>cs.ET</category>
      <category>cs.PL</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3663531.3664752</arxiv:DOI>
      <dc:creator>Matteo Esposito, Maryam Tavassoli Sabzevari, Boshuai Ye, Davide Falessi, Arif Ali Khan, Davide Taibi</dc:creator>
    </item>
    <item>
      <title>Aerial Push-Button with Two-Stage Tactile Feedback using Reflected Airborne Ultrasound Focus</title>
      <link>https://arxiv.org/abs/2406.19663</link>
      <description>arXiv:2406.19663v2 Announce Type: replace-cross 
Abstract: We developed a new aerial push-button with tactile feedback using focused airborne ultrasound. This study has two significant novelties compared to past related studies: 1) ultrasound emitters are equipped behind the user's finger and reflected ultrasound emission that is focused just above the solid plane placed under the finger presents tactile feedback to a finger pad, and 2) tactile feedback is presented at two stages during pressing motion; at the time of pushing the button and withdrawing the finger from it. The former has a significant advantage in apparatus implementation in that the input surface of the device can be composed of a generic thin plane including touch panels, potentially capable of presenting input touch feedback only when the user touches objects on the screen. We experimentally found that the two-stage tactile presentation is much more effective in strengthening perceived tactile stimulation and feeling of input completion when compared with a conventional single-stage method. This study proposes a composition of an aerial push-button in much more practical use than ever. The proposed system composition is expected to be one of the simplest frameworks in the airborne ultrasound tactile interface.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19663v2</guid>
      <category>cs.HC</category>
      <category>cs.ET</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hiroya Sugawara, Masaya Takasaki, Keisuke Hasegawa</dc:creator>
    </item>
  </channel>
</rss>
