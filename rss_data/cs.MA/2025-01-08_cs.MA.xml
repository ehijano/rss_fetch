<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.MA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.MA</link>
    <description>cs.MA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.MA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 09 Jan 2025 02:31:17 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Applying Large Language Models in Knowledge Graph-based Enterprise Modeling: Challenges and Opportunities</title>
      <link>https://arxiv.org/abs/2501.03566</link>
      <description>arXiv:2501.03566v1 Announce Type: new 
Abstract: The role of large language models (LLMs) in enterprise modeling has recently started to shift from academic research to that of industrial applications. Thereby, LLMs represent a further building block for the machine-supported generation of enterprise models. In this paper we employ a knowledge graph-based approach for enterprise modeling and investigate the potential benefits of LLMs in this context. In addition, the findings of an expert survey and ChatGPT-4o-based experiments demonstrate that LLM-based model generations exhibit minimal variability, yet remain constrained to specific tasks, with reliability declining for more intricate tasks. The survey results further suggest that the supervision and intervention of human modeling experts are essential to ensure the accuracy and integrity of the generated models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03566v1</guid>
      <category>cs.MA</category>
      <category>cs.AI</category>
      <category>cs.SE</category>
      <pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Benedikt Reitemeyer, Hans-Georg Fill</dc:creator>
    </item>
    <item>
      <title>Toward Inclusive Educational AI: Auditing Frontier LLMs through a Multiplexity Lens</title>
      <link>https://arxiv.org/abs/2501.03259</link>
      <description>arXiv:2501.03259v1 Announce Type: cross 
Abstract: As large language models (LLMs) like GPT-4 and Llama 3 become integral to educational contexts, concerns are mounting over the cultural biases, power imbalances, and ethical limitations embedded within these technologies. Though generative AI tools aim to enhance learning experiences, they often reflect values rooted in Western, Educated, Industrialized, Rich, and Democratic (WEIRD) cultural paradigms, potentially sidelining diverse global perspectives. This paper proposes a framework to assess and mitigate cultural bias within LLMs through the lens of applied multiplexity. Multiplexity, inspired by Senturk et al. and rooted in Islamic and other wisdom traditions, emphasizes the coexistence of diverse cultural viewpoints, supporting a multi-layered epistemology that integrates both empirical sciences and normative values. Our analysis reveals that LLMs frequently exhibit cultural polarization, with biases appearing in both overt responses and subtle contextual cues. To address inherent biases and incorporate multiplexity in LLMs, we propose two strategies: \textit{Contextually-Implemented Multiplex LLMs}, which embed multiplex principles directly into the system prompt, influencing LLM outputs at a foundational level and independent of individual prompts, and \textit{Multi-Agent System (MAS)-Implemented Multiplex LLMs}, where multiple LLM agents, each representing distinct cultural viewpoints, collaboratively generate a balanced, synthesized response. Our findings demonstrate that as mitigation strategies evolve from contextual prompting to MAS-implementation, cultural inclusivity markedly improves, evidenced by a significant rise in the Perspectives Distribution Score (PDS) and a PDS Entropy increase from 3.25\% at baseline to 98\% with the MAS-Implemented Multiplex LLMs. Sentiment analysis further shows a shift towards positive sentiment across cultures,...</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03259v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abdullah Mushtaq, Muhammad Rafay Naeem, Muhammad Imran Taj, Ibrahim Ghaznavi, Junaid Qadir</dc:creator>
    </item>
    <item>
      <title>A review on reinforcement learning methods for mobility on demand systems</title>
      <link>https://arxiv.org/abs/2501.02569</link>
      <description>arXiv:2501.02569v2 Announce Type: replace 
Abstract: Mobility on Demand (MoD) refers to mobility systems that operate on the basis of immediate travel demand. Typically, such a system consists of a fleet of vehicles that can be booked by customers when needed. The operation of these services consists of two main tasks: deciding how vehicles are assigned to requests (vehicle assignment); and deciding where vehicles move (including charging stations) when they are not serving a request (rebalancing). A field of research is emerging around the design of operation strategies for MoD services, and an increasingly popular trend is the use of learning based (most often Reinforcement Learning) approaches. We review, in this work, the literature on algorithms for operation strategies of MoD systems that use approaches based on Reinforcement Learning with a focus on the types of algorithms being used. The novelty of our review stands in three aspects: First, the algorithmic details are discussed and the approaches classified in a unified framework for sequential decision-making. Second, the use cases on which approaches are tested and their features are taken into account. Finally, validation methods that can be found across the literature are discussed. The review aims at advancing the state of the art by identifying similarities and differences between approaches and highlighting current research directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.02569v2</guid>
      <category>cs.MA</category>
      <pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tarek Chouaki, Sebastian H\"orl, Jakob Puchinger</dc:creator>
    </item>
    <item>
      <title>A Survey on LLM-based Multi-Agent System: Recent Advances and New Frontiers in Application</title>
      <link>https://arxiv.org/abs/2412.17481</link>
      <description>arXiv:2412.17481v2 Announce Type: replace-cross 
Abstract: LLM-based Multi-Agent Systems ( LLM-MAS ) have become a research hotspot since the rise of large language models (LLMs). However, with the continuous influx of new related works, the existing reviews struggle to capture them comprehensively. This paper presents a comprehensive survey of these studies. We first discuss the definition of LLM-MAS, a framework encompassing much of previous work. We provide an overview of the various applications of LLM-MAS in (i) solving complex tasks, (ii) simulating specific scenarios, and (iii) evaluating generative agents. Building on previous studies, we also highlight several challenges and propose future directions for research in this field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17481v2</guid>
      <category>cs.CL</category>
      <category>cs.MA</category>
      <pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuaihang Chen, Yuanxing Liu, Wei Han, Weinan Zhang, Ting Liu</dc:creator>
    </item>
  </channel>
</rss>
