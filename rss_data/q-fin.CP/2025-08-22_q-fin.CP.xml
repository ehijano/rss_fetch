<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.CP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.CP</link>
    <description>q-fin.CP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.CP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 22 Aug 2025 04:00:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 22 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Fast reliable pricing and calibration of the rough Heston model</title>
      <link>https://arxiv.org/abs/2508.15080</link>
      <description>arXiv:2508.15080v1 Announce Type: new 
Abstract: The paper is an extended and modified version of the preprint S.Boyarchenko and S.Levendorski\u{i} ``Correct implied volatility shapes and reliable pricing in the rough Heston model". We combine a modification of the Adams method with the SINH-acceleration method S.Boyarchenko and S.Levendorskii (IJTAF 2019, v.22) of Fourier inversion (iFT) to price vanilla options under the rough Heston model. For moderate or long maturities and strikes near spot, thousands of prices are computed in several milliseconds (ms) in Matlab on a Mac with moderate specs, with relative errors $\lesssim 10^{-4}$. Even for options close to expiry and far-OTM, the pricing takes a few tens or hundreds of ms. We show that, for the calibrated parameters in El Euch and Rosenbaum (Math.Finance 2019, v.29), the model implied vol surface is much flatter and fits the market data poorly; thus the calibration in op.cit. is a case of ``ghost calibration'' (M.Boyarchenko and S.Levendorski\u{i}, Quant. Finance 2015, v.15): numerical error and model specification error offset each other, creating an apparently good fit that vanishes when a more accurate pricer is used. We explain how such errors arise in popular iFT implementations that use fixed numerical parameters, yielding spurious smiles/skews, and provide numerical evidence that SINH acceleration is faster and more accurate than competing methods. Robust error control is ensured by a general Conformal Bootstrap principle that we formulate; the principle is applicable to many Fourier-pricing methods. We outline how this principle and our method enable accurate calibration procedures that are hundreds of times faster than approaches commonly used in the industry. Disclaimer: The views expressed herein are those of the authors only. No other representation should be attributed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.15080v1</guid>
      <category>q-fin.CP</category>
      <pubDate>Fri, 22 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Svetlana Boyarchenko, Marco de Innocentis, Sergei Levendorski\u{i}</dc:creator>
    </item>
    <item>
      <title>Non-parametric Causal Discovery for EU Allowances Returns Through the Information Imbalance</title>
      <link>https://arxiv.org/abs/2508.15667</link>
      <description>arXiv:2508.15667v1 Announce Type: new 
Abstract: We propose to use a recently introduced non-parametric tool named Differentiable Information Imbalance (DII) to identify variables that are causally related -- potentially through non-linear relationships -- to the financial returns of the European Union Allowances (EUAs) within the EU Emissions Trading System (EU ETS). We examine data from January 2013 to April 2024 and compare the DII approach with multivariate Granger causality, a well-known linear approach based on VAR models. We find significant overlap among the causal variables identified by linear and non-linear methods, such as the coal futures prices and the IBEX35 index. We also find important differences between the two causal sets identified. On two synthetic datasets, we show how these differences could originate from limitations of the linear methodology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.15667v1</guid>
      <category>q-fin.CP</category>
      <pubDate>Fri, 22 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cristiano Salvagnin, Vittorio del Tatto, Maria Elena De Giuli, Antonietta Mira, Aldo Glielmo</dc:creator>
    </item>
    <item>
      <title>Generative Neural Operators of Log-Complexity Can Simultaneously Solve Infinitely Many Convex Programs</title>
      <link>https://arxiv.org/abs/2508.14995</link>
      <description>arXiv:2508.14995v1 Announce Type: cross 
Abstract: Neural operators (NOs) are a class of deep learning models designed to simultaneously solve infinitely many related problems by casting them into an infinite-dimensional space, whereon these NOs operate. A significant gap remains between theory and practice: worst-case parameter bounds from universal approximation theorems suggest that NOs may require an unrealistically large number of parameters to solve most operator learning problems, which stands in direct opposition to a slew of experimental evidence. This paper closes that gap for a specific class of {NOs}, generative {equilibrium operators} (GEOs), using (realistic) finite-dimensional deep equilibrium layers, when solving families of convex optimization problems over a separable Hilbert space $X$. Here, the inputs are smooth, convex loss functions on $X$, and outputs are the associated (approximate) solutions to the optimization problem defined by each input loss.
  We show that when the input losses lie in suitable infinite-dimensional compact sets, our GEO can uniformly approximate the corresponding solutions to arbitrary precision, with rank, depth, and width growing only logarithmically in the reciprocal of the approximation error. We then validate both our theoretical results and the trainability of GEOs on three applications: (1) nonlinear PDEs, (2) stochastic optimal control problems, and (3) hedging problems in mathematical finance under liquidity constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.14995v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>q-fin.CP</category>
      <pubDate>Fri, 22 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anastasis Kratsios, Ariel Neufeld, Philipp Schmocker</dc:creator>
    </item>
  </channel>
</rss>
