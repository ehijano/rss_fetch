<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CY updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CY</link>
    <description>cs.CY updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CY" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 20 Aug 2025 07:11:07 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Toward an African Agenda for AI Safety</title>
      <link>https://arxiv.org/abs/2508.13179</link>
      <description>arXiv:2508.13179v1 Announce Type: new 
Abstract: This paper maps Africa's distinctive AI risk profile, from deepfake fuelled electoral interference and data colonial dependency to compute scarcity, labour disruption and disproportionate exposure to climate driven environmental costs. While major benefits are promised to accrue, the availability, development and adoption of AI also mean that African people and countries face particular AI safety risks, from large scale labour market disruptions to the nefarious use of AI to manipulate public opinion. To date, African perspectives have not been meaningfully integrated into global debates and processes regarding AI safety, leaving African stakeholders with limited influence over the emerging global AI safety governance agenda. While there are Computer Incident Response Teams on the continent, none hosts a dedicated AI Safety Institute or office. We propose a five-point action plan centred on (i) a policy approach that foregrounds the protection of the human rights of those most vulnerable to experiencing the harmful socio-economic effects of AI; (ii) the establishment of an African AI Safety Institute; (iii) promote public AI literacy and awareness; (iv) development of early warning system with inclusive benchmark suites for 25+ African languages; and (v) an annual AU-level AI Safety &amp; Security Forum.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13179v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Samuel T. Segun, Rachel Adams, Ana Florido, Scott Timcke, Jonathan Shock, Leah Junck, Fola Adeleke, Nicolas Grossman, Ayantola Alayande, Jerry John Kponyo, Matthew Smith, Dickson Marfo Fosu, Prince Dawson Tetteh, Juliet Arthur, Stephanie Kasaon, Odilile Ayodele, Laetitia Badolo, Paul Plantinga, Michael Gastrow, Sumaya Nur Adan, Joanna Wiaterek, Cecil Abungu, Kojo Apeagyei, Luise Eder, Tegawende Bissyande</dc:creator>
    </item>
    <item>
      <title>Digital-GenAI-Enhanced HCI in DevOps as a Driver of Sustainable Innovation: An Empirical Framework</title>
      <link>https://arxiv.org/abs/2508.13185</link>
      <description>arXiv:2508.13185v1 Announce Type: new 
Abstract: This study examines the impact of Digital-GenAI-Enhanced Human-Computer Interaction (HCI) in DevOps on sustainable innovation performance among Chinese A-share internet technology firms. Using panel data from 2018-2024, we analyze 5,560 firm-year observations from CNRDS and CSMAR databases. Our empirical framework reveals significant positive associations between AI-enhanced HCI implementation and sustainable innovation outcomes. Results demonstrate that firms adopting advanced HCI technologies achieve 23.7% higher innovation efficiency. The study contributes to understanding digital transformation's role in sustainable business practices. We identify three key mechanisms: operational efficiency enhancement, knowledge integration facilitation, and stakeholder engagement improvement. Findings provide practical implications for technology adoption strategies in emerging markets</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13185v1</guid>
      <category>cs.CY</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Jun Cui</dc:creator>
    </item>
    <item>
      <title>Combating Homelessness Stigma with LLMs: A New Multi-Modal Dataset for Bias Detection</title>
      <link>https://arxiv.org/abs/2508.13187</link>
      <description>arXiv:2508.13187v1 Announce Type: new 
Abstract: Homelessness is a persistent social challenge, impacting millions worldwide. Over 770,000 people experienced homelessness in the U.S. in 2024. Social stigmatization is a significant barrier to alleviation, shifting public perception, and influencing policymaking. Given that online and city council discourse reflect and influence part of public opinion, it provides valuable insights to identify and track social biases. This research contributes to alleviating homelessness by acting on public opinion. It introduces novel methods, building on natural language processing (NLP) and large language models (LLMs), to identify and measure PEH social bias expressed in digital spaces. We present a new, manually-annotated multi-modal dataset compiled from Reddit, X (formerly Twitter), news articles, and city council meeting minutes across 10 U.S. cities. This unique dataset provides evidence of the typologies of homelessness bias described in the literature. In order to scale up and automate the detection of homelessness bias online, we evaluate LLMs as classifiers. We applied both zero-shot and few-shot classification techniques to this data. We utilized local LLMs (Llama 3.2 3B Instruct, Qwen 2.5 7B Instruct, and Phi4 Instruct Mini) as well as closed-source API models (GPT-4.1, Gemini 2.5 Pro, and Grok-4). Our findings reveal that although there are significant inconsistencies in local LLM zero-shot classification, the in-context learning classification scores of local LLMs approach the classification scores of closed-source LLMs. Furthermore, LLMs outperform BERT when averaging across all categories. This work aims to raise awareness about the pervasive bias against PEH, develop new indicators to inform policy, and ultimately enhance the fairness and ethical application of Generative AI technologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13187v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonathan A. Karr Jr., Benjamin F. Herbst, Ting Hua, Matthew Hauenstein, Georgina Curto, Nitesh V. Chawla</dc:creator>
    </item>
    <item>
      <title>When AI Writes Back: Ethical Considerations by Physicians on AI-Drafted Patient Message Replies</title>
      <link>https://arxiv.org/abs/2508.13217</link>
      <description>arXiv:2508.13217v1 Announce Type: new 
Abstract: The increasing burden of responding to large volumes of patient messages has become a key factor contributing to physician burnout. Generative AI (GenAI) shows great promise to alleviate this burden by automatically drafting patient message replies. The ethical implications of this use have however not been fully explored. To address this knowledge gap, we conducted a semi-structured interview study with 21 physicians who participated in a GenAI pilot program. We found that notable ethical considerations expressed by the physician participants included human oversight as ethical safeguard, transparency and patient consent of AI use, patient misunderstanding of AI's role, and patient privacy and data security as prerequisites. Additionally, our findings suggest that the physicians believe the ethical responsibility of using GenAI in this context primarily lies with users, not with the technology. These findings may provide useful insights into guiding the future implementation of GenAI in clinical practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13217v1</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Di Hu (University of California, Irvine, Irvine, CA, USA), Yawen Guo (University of California, Irvine, Irvine, CA, USA), Ha Na Cho (University of California, Irvine, Irvine, CA, USA), Emilie Chow (University of California, Irvine, Irvine, CA, USA), Dana B. Mukamel (University of California, Irvine, Irvine, CA, USA), Dara Sorkin (University of California, Irvine, Irvine, CA, USA), Andrew Reikes (University of California, Irvine, Irvine, CA, USA), Danielle Perret (University of California, Irvine, Irvine, CA, USA), Deepti Pandita (University of California, Irvine, Irvine, CA, USA), Kai Zheng (University of California, Irvine, Irvine, CA, USA)</dc:creator>
    </item>
    <item>
      <title>The Course Difficulty Analysis Cookbook</title>
      <link>https://arxiv.org/abs/2508.13218</link>
      <description>arXiv:2508.13218v1 Announce Type: new 
Abstract: Curriculum analytics (CA) studies curriculum structure and student data to ensure the quality of educational programs. An essential aspect is studying course properties, which involves assigning each course a representative difficulty value. This is critical for several aspects of CA, such as quality control (e.g., monitoring variations over time), course comparisons (e.g., articulation), and course recommendation (e.g., advising). Measuring course difficulty requires careful consideration of multiple factors: First, when difficulty measures are sensitive to the performance level of enrolled students, it can bias interpretations by overlooking student diversity. By assessing difficulty independently of enrolled students' performances, we can reduce the risk of bias and enable fair, representative assessments of difficulty. Second, from a measurement theoretic perspective, the measurement must be reliable and valid to provide a robust basis for subsequent analyses. Third, difficulty measures should account for covariates, such as the characteristics of individual students within a diverse populations (e.g., transfer status). In recent years, various notions of difficulty have been proposed. This paper provides the first comprehensive review and comparison of existing approaches for assessing course difficulty based on grade point averages and latent trait modeling. It further offers a hands-on tutorial on model selection, assumption checking, and practical CA applications. These applications include monitoring course difficulty over time and detecting courses with disparate outcomes between distinct groups of students (e.g., dropouts vs. graduates), ultimately aiming to promote high-quality, fair, and equitable learning experiences. To support further research and application, we provide an open-source software package and artificial datasets, facilitating reproducibility and adoption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13218v1</guid>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Frederik Baucks, Robin Schmucker, Laurenz Wiskott</dc:creator>
    </item>
    <item>
      <title>Consumer Autonomy or Illusion? Rethinking Consumer Agency in the Age of Algorithms</title>
      <link>https://arxiv.org/abs/2508.13440</link>
      <description>arXiv:2508.13440v1 Announce Type: new 
Abstract: Consumer agency in the digital age is increasingly constrained by systemic barriers and algorithmic manipulation, raising concerns about the authenticity of consumption choices. Nowadays, financial decisions are shaped by external pressures like obligatory consumption, algorithmic persuasion, and unstable work schedules that erode financial autonomy. Obligatory consumption (like hidden fees) is intensified by digital ecosystems. Algorithmic tactics like personalized recommendations lead to impulsive purchases. Unstable work schedules also undermine financial planning. Thus, it is important to study how these factors impact consumption agency. To do so, we examine formal models grounded in discounted consumption with constraints that bound agency. We construct analytical scenarios in which consumers face obligatory payments, algorithm-influenced impulsive expenses, or unpredictable income due to temporal instability. Using this framework, we demonstrate that even rational, utility-maximizing agents can experience early financial ruin when agency is limited across structural, behavioral, or temporal dimensions and how diminished autonomy impacts long-term financial well-being. Our central argument is that consumer agency must be treated as a value (not a given) requiring active cultivation, especially in digital ecosystems. The connection between our formal modeling and this argument allows us to indicate that limitations on agency (whether structural, behavioral, or temporal) can be rigorously linked to measurable risks like financial instability. This connection is also a basis for normative claims about consumption as a value, by anchoring them in a formally grounded analysis of consumer behavior. As solutions, we study systemic interventions and consumer education to support value deliberation and informed choices. We formally demonstrate how these measures strengthen agency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13440v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pegah Nokhiz, Aravinda Kanchana Ruwanpathirana</dc:creator>
    </item>
    <item>
      <title>The AI Risk Spectrum: From Dangerous Capabilities to Existential Threats</title>
      <link>https://arxiv.org/abs/2508.13700</link>
      <description>arXiv:2508.13700v1 Announce Type: new 
Abstract: As AI systems become more capable, integrated, and widespread, understanding the associated risks becomes increasingly important. This paper maps the full spectrum of AI risks, from current harms affecting individual users to existential threats that could endanger humanity's survival. We organize these risks into three main causal categories. Misuse risks, which occur when people deliberately use AI for harmful purposes - creating bioweapons, launching cyberattacks, adversarial AI attacks or deploying lethal autonomous weapons. Misalignment risks happen when AI systems pursue outcomes that conflict with human values, irrespective of developer intentions. This includes risks arising through specification gaming (reward hacking), scheming and power-seeking tendencies in pursuit of long-term strategic goals. Systemic risks, which arise when AI integrates into complex social systems in ways that gradually undermine human agency - concentrating power, accelerating political and economic disempowerment, creating overdependence that leads to human enfeeblement, or irreversibly locking in current values curtailing future moral progress. Beyond these core categories, we identify risk amplifiers - competitive pressures, accidents, corporate indifference, and coordination failures - that make all risks more likely and severe. Throughout, we connect today's existing risks and empirically observable AI behaviors to plausible future outcomes, demonstrating how existing trends could escalate to catastrophic outcomes. Our goal is to help readers understand the complete landscape of AI risks. Good futures are possible, but they don't happen by default. Navigating these challenges will require unprecedented coordination, but an extraordinary future awaits if we do.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13700v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Markov Grey, Charbel-Rapha\"el Segerie</dc:creator>
    </item>
    <item>
      <title>Exit Stories: Using Reddit Self-Disclosures to Understand Disengagement from Problematic Communities</title>
      <link>https://arxiv.org/abs/2508.13837</link>
      <description>arXiv:2508.13837v1 Announce Type: new 
Abstract: Online platforms like Reddit are increasingly becoming popular for individuals sharing personal experiences of leaving behind social, ideological, and political groups. Specifically, a series of "ex-" subreddits on Reddit allow users to recount their departures from commitments such as religious affiliations, manosphere communities, conspiracy theories or political beliefs, and lifestyle choices. Understanding the natural process through which users exit, especially from problematic groups such as conspiracy theory communities and the manosphere, can provide valuable insights for designing interventions targeting disengagement from harmful ideologies. This paper presents an in-depth exploration of 15K exit stories across 131 subreddits, focusing on five key areas: religion, manosphere, conspiracy theories, politics, and lifestyle. Using a transdisciplinary framework that incorporates theories from social psychology, organizational behavior, and violent extremism studies, this work identifies a range of factors contributing to disengagement. The results describe how disengagement from problematic groups, such as conspiracy theories and the manosphere, is a multi-faceted process that is qualitatively different than disengaging from more established social structures, such as religions or political ideologies. This research further highlights the need for moving beyond interventions that treat conspiracy theorizing solely as an information problem and contributes insights for future research focusing on offering mental health interventions and support in exit communities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13837v1</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <category>cs.SI</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:journal_reference>Proc. ACM Hum.-Comput. Interact. 9, 7, Article CSCW411 2025</arxiv:journal_reference>
      <dc:creator>Shruti Phadke</dc:creator>
    </item>
    <item>
      <title>The AI-Fraud Diamond: A Novel Lens for Auditing Algorithmic Deception</title>
      <link>https://arxiv.org/abs/2508.13984</link>
      <description>arXiv:2508.13984v1 Announce Type: new 
Abstract: As artificial intelligence (AI) systems become increasingly integral to organizational processes, they introduce new forms of fraud that are often subtle, systemic, and concealed within technical complexity. This paper introduces the AI-Fraud Diamond, an extension of the traditional Fraud Triangle that adds technical opacity as a fourth condition alongside pressure, opportunity, and rationalization. Unlike traditional fraud, AI-enabled deception may not involve clear human intent but can arise from system-level features such as opaque model behavior, flawed training data, or unregulated deployment practices. The paper develops a taxonomy of AI-fraud across five categories: input data manipulation, model exploitation, algorithmic decision manipulation, synthetic misinformation, and ethics-based fraud. To assess the relevance and applicability of the AI-Fraud Diamond, the study draws on expert interviews with auditors from two of the Big Four consulting firms. The findings underscore the challenges auditors face when addressing fraud in opaque and automated environments, including limited technical expertise, insufficient cross-disciplinary collaboration, and constrained access to internal system processes. These conditions hinder fraud detection and reduce accountability. The paper argues for a shift in audit methodology-from outcome-based checks to a more diagnostic approach focused on identifying systemic vulnerabilities. Ultimately, the work lays a foundation for future empirical research and audit innovation in a rapidly evolving AI governance landscape.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13984v1</guid>
      <category>cs.CY</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Benjamin Zweers, Diptish Dey, Debarati Bhaumik</dc:creator>
    </item>
    <item>
      <title>Fair Play in the Newsroom: Actor-Based Filtering Gender Discrimination in Text Corpora</title>
      <link>https://arxiv.org/abs/2508.13169</link>
      <description>arXiv:2508.13169v1 Announce Type: cross 
Abstract: Large language models are increasingly shaping digital communication, yet their outputs often reflect structural gender imbalances that originate from their training data. This paper presents an extended actor-level pipeline for detecting and mitigating gender discrimination in large-scale text corpora. Building on prior work in discourse-aware fairness analysis, we introduce new actor-level metrics that capture asymmetries in sentiment, syntactic agency, and quotation styles. The pipeline supports both diagnostic corpus analysis and exclusion-based balancing, enabling the construction of fairer corpora. We apply our approach to the taz2024full corpus of German newspaper articles from 1980 to 2024, demonstrating substantial improvements in gender balance across multiple linguistic dimensions. Our results show that while surface-level asymmetries can be mitigated through filtering and rebalancing, subtler forms of bias persist, particularly in sentiment and framing. We release the tools and reports to support further research in discourse-based fairness auditing and equitable corpus construction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13169v1</guid>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stefanie Urchs, Veronika Thurner, Matthias A{\ss}enmacher, Christian Heumann, Stephanie Thiemichen</dc:creator>
    </item>
    <item>
      <title>A Recurrent Neural Network based Clustering Method for Binary Data Sets in Education</title>
      <link>https://arxiv.org/abs/2508.13224</link>
      <description>arXiv:2508.13224v1 Announce Type: cross 
Abstract: This paper studies an application of a recurrent neural network to clustering method for the S-P chart: a binary data set used widely in education. As the number of students increases, the S-P chart becomes hard to handle. In order to classify the large chart into smaller charts, we present a simple clustering method based on the network dynamics. In the method, the network has multiple fixed points and basins of attraction give clusters corresponding to small S-P charts. In order to evaluate the clustering performance, we present an important feature quantity: average caution index that characterizes singularity of students answer oatterns. Performing fundamental experiments, effectiveness of the method is confirmed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13224v1</guid>
      <category>cs.LG</category>
      <category>cs.CY</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mizuki Ohira, Toshimichi Saito</dc:creator>
    </item>
    <item>
      <title>The Role of AI in Facilitating Interdisciplinary Collaboration: Evidence from AlphaFold</title>
      <link>https://arxiv.org/abs/2508.13234</link>
      <description>arXiv:2508.13234v1 Announce Type: cross 
Abstract: The acceleration of artificial intelligence (AI) in science is recognized and many scholars have begun to explore its role in interdisciplinary collaboration. However, the mechanisms and extent of this impact are still unclear. This study, using AlphaFold's impact on structural biologists, examines how AI technologies influence interdisciplinary collaborative patterns. By analyzing 1,247 AlphaFold-related papers and 7,700 authors from Scopus, we employ bibliometric analysis and causal inference to compare interdisciplinary collaboration between AlphaFold adopters and non-adopters. Contrary to the widespread belief that AI facilitates interdisciplinary collaboration, our findings show that AlphaFold increased structural biology-computer science collaborations by just 0.48%, with no measurable effect on other disciplines. Specifically, AI creates interdisciplinary collaboration demands with specific disciplines due to its technical characteristics, but this demand is weakened by technological democratization and other factors. These findings demonstrate that artificial intelligence (AI) alone has limited efficacy in bridging disciplinary divides or fostering meaningful interdisciplinary collaboration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13234v1</guid>
      <category>cs.DL</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Naixuan Zhao, Chunli Wei, Xinyan Zhang, Jiang Li</dc:creator>
    </item>
    <item>
      <title>CardAIc-Agents: A Multimodal Framework with Hierarchical Adaptation for Cardiac Care Support</title>
      <link>https://arxiv.org/abs/2508.13256</link>
      <description>arXiv:2508.13256v1 Announce Type: cross 
Abstract: Cardiovascular diseases (CVDs) remain the foremost cause of mortality worldwide, a burden worsened by a severe deficit of healthcare workers. Artificial intelligence (AI) agents have shown potential to alleviate this gap via automated early detection and proactive screening, yet their clinical application remains limited by: 1) prompt-based clinical role assignment that relies on intrinsic model capabilities without domain-specific tool support; or 2) rigid sequential workflows, whereas clinical care often requires adaptive reasoning that orders specific tests and, based on their results, guides personalised next steps; 3) general and static knowledge bases without continuous learning capability; and 4) fixed unimodal or bimodal inputs and lack of on-demand visual outputs when further clarification is needed. In response, a multimodal framework, CardAIc-Agents, was proposed to augment models with external tools and adaptively support diverse cardiac tasks. Specifically, a CardiacRAG agent generated general plans from updatable cardiac knowledge, while the chief agent integrated tools to autonomously execute these plans and deliver decisions. To enable adaptive and case-specific customization, a stepwise update strategy was proposed to dynamically refine plans based on preceding execution results, once the task was assessed as complex. In addition, a multidisciplinary discussion tool was introduced to interpret challenging cases, thereby supporting further adaptation. When clinicians raised concerns, visual review panels were provided to assist final validation. Experiments across three datasets showed the efficiency of CardAIc-Agents compared to mainstream Vision-Language Models (VLMs), state-of-the-art agentic systems, and fine-tuned VLMs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13256v1</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.MA</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuting Zhang, Karina V. Bunting, Asgher Champsi, Xiaoxia Wang, Wenqi Lu, Alexander Thorley, Sandeep S Hothi, Zhaowen Qiu, Dipak Kotecha, Jinming Duan</dc:creator>
    </item>
    <item>
      <title>Time Profile of U.S. Neighborhoods: Datasets of Time Use at Social Infrastructure Places</title>
      <link>https://arxiv.org/abs/2508.13295</link>
      <description>arXiv:2508.13295v1 Announce Type: cross 
Abstract: Social infrastructure plays a critical role in shaping neighborhood well-being by fostering social and cultural interaction, enabling service provision, and encouraging exposure to diverse environments. Despite the growing knowledge of its spatial accessibility, time use at social infrastructure places is underexplored due to the lack of a spatially resolved national dataset. We address this gap by developing scalable Social-Infrastructure Time Use measures (STU) that capture length and depth of engagement, activity diversity, and spatial inequality, supported by first-of-their-kind datasets spanning multiple geographic scales from census tracts to metropolitan areas. Our datasets leverage anonymized and aggregated foot traffic data collected between 2019 and 2024 across 49 continental U.S. states. The data description reveals variances in STU across time, space, and differing neighborhood sociodemographic characteristics. Validation demonstrates generally robust population representation, consistent with established national survey findings while revealing more nuanced patterns. Future analyses could link STU with public health outcomes and environmental factors to inform targeted interventions aimed at enhancing population well-being and guiding social infrastructure planning and usage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13295v1</guid>
      <category>cs.SI</category>
      <category>cs.CY</category>
      <category>stat.AP</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1038/s41597-025-05504-9</arxiv:DOI>
      <arxiv:journal_reference>Sci. Data (2025)</arxiv:journal_reference>
      <dc:creator>Yan Wang, Ziyi Guo</dc:creator>
    </item>
    <item>
      <title>Trust and Reputation in Data Sharing: A Survey</title>
      <link>https://arxiv.org/abs/2508.14028</link>
      <description>arXiv:2508.14028v1 Announce Type: cross 
Abstract: Data sharing is the fuel of the galloping artificial intelligence economy, providing diverse datasets for training robust models. Trust between data providers and data consumers is widely considered one of the most important factors for enabling data sharing initiatives. Concerns about data sensitivity, privacy breaches, and misuse contribute to reluctance in sharing data across various domains. In recent years, there has been a rise in technological and algorithmic solutions to measure, capture and manage trust, trustworthiness, and reputation in what we collectively refer to as Trust and Reputation Management Systems (TRMSs). Such approaches have been developed and applied to different domains of computer science, such as autonomous vehicles, or IoT networks, but there have not been dedicated approaches to data sharing and its unique characteristics. In this survey, we examine TRMSs from a data-sharing perspective, analyzing how they assess the trustworthiness of both data and entities across different environments. We develop novel taxonomies for system designs, trust evaluation framework, and evaluation metrics for both data and entity, and we systematically analyze the applicability of existing TRMSs in data sharing. Finally, we identify open challenges and propose future research directions to enhance the explainability, comprehensiveness, and accuracy of TRMSs in large-scale data-sharing ecosystems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.14028v1</guid>
      <category>cs.SI</category>
      <category>cs.CY</category>
      <category>cs.IR</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenbo Wu, George Konstantinidis</dc:creator>
    </item>
    <item>
      <title>Investigating the importance of county-level characteristics in opioid-related mortality across the United States</title>
      <link>https://arxiv.org/abs/2412.15218</link>
      <description>arXiv:2412.15218v3 Announce Type: replace 
Abstract: The opioid crisis remains a critical public health challenge in the United States. Despite national efforts which reduced opioid prescribing rates by nearly 45\% between 2011 and 2021, opioid-related overdose deaths more than tripled during the same period. This alarming trend reflects a major shift in the crisis, with illegal opioids now driving the majority of overdose deaths instead of prescription opioids. Although much attention has been given to supply-side factors fueling this transition, the underlying structural conditions that perpetuate and exacerbate opioid misuse remain less understood. Moreover, the COVID-19 pandemic intensified the opioid crisis through widespread social isolation and record-high unemployment; consequently, understanding the underlying drivers of this epidemic has become even more crucial in recent years. To address this need, our study examines the correlation between opioid-related mortality and thirteen county-level characteristics related to population traits, economic stability, and infrastructure. Leveraging a nationwide county-level dataset spanning consecutive years from 2010 to 2022, this study integrates empirical insights from exploratory data analysis with feature importance metrics derived from machine learning models. Our findings highlight critical regional characteristics strongly correlated with opioid-related mortality, emphasizing their potential roles in worsening the epidemic when their levels are high and mitigating it when their levels are low.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.15218v3</guid>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrew Deas, Adam Spannaus, Dakotah D. Maguire, Jodie Trafton, Anuj J. Kapadia, Vasileios Maroulas</dc:creator>
    </item>
    <item>
      <title>Experimental Evidence for the Propagation and Preservation of Machine Discoveries in Human Populations</title>
      <link>https://arxiv.org/abs/2506.17741</link>
      <description>arXiv:2506.17741v2 Announce Type: replace 
Abstract: Intelligent machines with superhuman capabilities have the potential to uncover problem-solving strategies beyond human discovery. Emerging evidence from competitive gameplay, such as Go and chess, demonstrates that AI systems are evolving from mere tools to sources of cultural innovation adopted by humans. However, the conditions under which intelligent machines transition from tools to drivers of persistent cultural change remain unclear. We identify three key conditions for machines to fundamentally influence human problem-solving: the discovered strategies must be non-trivial, learnable, and offer a clear advantage. Using a cultural transmission experiment and an agent-based simulation, we demonstrate that when these conditions are met, machine-discovered strategies can be transmitted, understood, and preserved by human populations, leading to enduring cultural shifts. These findings provide a framework for understanding how machines can persistently expand human cognitive skills and underscore the need to consider their broader implications for human cognition and cultural evolution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.17741v2</guid>
      <category>cs.CY</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Levin Brinkmann, Thomas F. Eisenmann, Anne-Marie Nussberger, Maxime Derex, Sara Bonati, Valerii Chirkov, Iyad Rahwan</dc:creator>
    </item>
    <item>
      <title>Characterizing Community Formation in Response to Extreme Weather Events through Human Mobility Networks</title>
      <link>https://arxiv.org/abs/2205.04981</link>
      <description>arXiv:2205.04981v2 Announce Type: replace-cross 
Abstract: Community formation in socio-spatial human networks is one of the important mechanisms for mitigating hazard impacts of extreme weather events. Research is scarce regarding latent network characteristics shaping community formation in human mobility networks during natural disasters. Here, we examined human mobility networks in Harris County, Texas, in the context of the managed power outage forced by 2021 Winter Storm Uri to detect communities and to evaluate latent characteristics in those communities. We examined three characteristics in the communities formed within human mobility networks: hazard-exposure heterophily, socio-demographic homophily, and social-connectedness strength. The results show that population movements were shaped by socio-demographic homophily, heterophilic hazard exposure, and social connectedness strength. Our results also indicate that a community encompassing more high-impact areas would motivate population movements to areas with weaker social connectedness. Our findings reveal important characteristics shaping community formation in human mobility networks in hazard response. Specific to managed power outages, formed communities are spatially co-located, underscoring a best management practice to avoid prolonged power outages among areas within communities, thus improving hazard exposure heterophily. The findings have implications for power utility operators to account for the characteristics of socio-spatial human networks when determining the patterns of managed power outages.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.04981v2</guid>
      <category>cs.SI</category>
      <category>cs.CY</category>
      <category>physics.soc-ph</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Cheng-Chun Lee, Junwei Ma, Kai Yin, Siri Namburi, Xin Xiao, Ali Mostafavi</dc:creator>
    </item>
    <item>
      <title>Exploring LLMs for Automated Generation and Adaptation of Questionnaires</title>
      <link>https://arxiv.org/abs/2501.05985</link>
      <description>arXiv:2501.05985v2 Announce Type: replace-cross 
Abstract: Effective questionnaire design improves the validity of the results, but creating and adapting questionnaires across contexts is challenging due to resource constraints and limited expert access. Recently, the emergence of LLMs has led researchers to explore their potential in survey research. In this work, we focus on the suitability of LLMs in assisting the generation and adaptation of questionnaires. We introduce a novel pipeline that leverages LLMs to create new questionnaires, pretest with a target audience to determine potential issues and adapt existing standardized questionnaires for different contexts. We evaluated our pipeline for creation and adaptation through two studies on Prolific, involving 238 participants from the US and 118 participants from South Africa. Our findings show that participants found LLM-generated text clearer, LLM-pretested text more specific, and LLM-adapted questions slightly clearer and less biased than traditional ones. Our work opens new opportunities for LLM-driven questionnaire support in survey research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.05985v2</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3719160.3736606</arxiv:DOI>
      <dc:creator>Divya Mani Adhikari, Alexander Hartland, Ingmar Weber, Vikram Kamath Cannanure</dc:creator>
    </item>
    <item>
      <title>Content and Quality Analysis of Parent-Facing Applications for Feeding Children with Autism Spectrum Disorder</title>
      <link>https://arxiv.org/abs/2505.01520</link>
      <description>arXiv:2505.01520v2 Announce Type: replace-cross 
Abstract: Approximately 1 in 100 children worldwide are diagnosed with Autism Spectrum Disorder (ASD), and 46% to 89% experience significant feeding difficulties. Although mobile health (mHealth) applications offer potential support for caregivers, the quality and relevance of apps targeting autism-related feeding issues remain unclear. This systematic review evaluated mobile applications available on the Apple App Store and the Google Play Store between September and October 2024. The searches were carried out using 15 predefined terms (e.g., "child autism feeding", "child autism food"). Applications were eligible if they were in English, free to download, updated within the past year, explicitly addressed feeding in children with autism, accessible in Africa, and had more than 100 downloads. Of the 326 apps identified, only two iOS applications met all inclusion criteria; no Android apps qualified. Behavior Change Wheel (BCW) analysis showed that the selected applications incorporated multiple intervention functions, such as education, training, enablement, incentivization, and modeling, though none addressed the full spectrum of behavioral strategies. Mobile App Rating Scale (MARS) indicated moderate to high usability, with features such as sensory-friendly food routines and structured caregiver tools. However, both apps lacked clinical validation and comprehensive customization. These findings highlight a critical gap in the availability of evidence-based high-quality mHealth tools for caregivers managing ASD-related feeding challenges and underscore the need for professionally developed and culturally sensitive digital solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01520v2</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christopher Cofie Kuzagbe (Carnegie Mellon University Africa, Kigali, Rwanda), Fabrice Mukarage (Carnegie Mellon University Africa, Kigali, Rwanda), Skye Nandi Adams (University of the Witwatersrand, Johannesburg, South Africa), N'guessan Yves-Roland Douha (Carnegie Mellon University Africa, Kigali, Rwanda), Edith Talina Luhanga (Carnegie Mellon University Africa, Kigali, Rwanda)</dc:creator>
    </item>
    <item>
      <title>Harnessing Structured Knowledge: A Concept Map-Based Approach for High-Quality Multiple Choice Question Generation with Effective Distractors</title>
      <link>https://arxiv.org/abs/2505.02850</link>
      <description>arXiv:2505.02850v2 Announce Type: replace-cross 
Abstract: Generating high-quality MCQs, especially those targeting diverse cognitive levels and incorporating common misconceptions into distractor design, is time-consuming and expertise-intensive, making manual creation impractical at scale. Current automated approaches typically generate questions at lower cognitive levels and fail to incorporate domain-specific misconceptions. This paper presents a hierarchical concept map-based framework that provides structured knowledge to guide LLMs in generating MCQs with distractors. We chose high-school physics as our test domain and began by developing a hierarchical concept map covering major Physics topics and their interconnections with an efficient database design. Next, through an automated pipeline, topic-relevant sections of these concept maps are retrieved to serve as a structured context for the LLM to generate questions and distractors that specifically target common misconceptions. Lastly, an automated validation is completed to ensure that the generated MCQs meet the requirements provided. We evaluate our framework against two baseline approaches: a base LLM and a RAG-based generation. We conducted expert evaluations and student assessments of the generated MCQs. Expert evaluation shows that our method significantly outperforms the baseline approaches, achieving a success rate of 75.20% in meeting all quality criteria compared to approximately 37% for both baseline methods. Student assessment data reveal that our concept map-driven approach achieved a significantly lower guess success rate of 28.05% compared to 37.10% for the baselines, indicating a more effective assessment of conceptual understanding. The results demonstrate that our concept map-based approach enables robust assessment across cognitive levels and instant identification of conceptual gaps, facilitating faster feedback loops and targeted interventions at scale.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02850v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.DB</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Nicy Scaria, Silvester John Joseph Kennedy, Diksha Seth, Ananya Thakur, Deepak Subramani</dc:creator>
    </item>
    <item>
      <title>Position: We Need Responsible, Application-Driven (RAD) AI Research</title>
      <link>https://arxiv.org/abs/2505.04104</link>
      <description>arXiv:2505.04104v3 Announce Type: replace-cross 
Abstract: This position paper argues that achieving meaningful scientific and societal advances with artificial intelligence (AI) requires a responsible, application-driven approach (RAD) to AI research. As AI is increasingly integrated into society, AI researchers must engage with the specific contexts where AI is being applied. This includes being responsive to ethical and legal considerations, technical and societal constraints, and public discourse. We present the case for RAD-AI to drive research through a three-staged approach: (1) building transdisciplinary teams and people-centred studies; (2) addressing context-specific methods, ethical commitments, assumptions, and metrics; and (3) testing and sustaining efficacy through staged testbeds and a community of practice. We present a vision for the future of application-driven AI research to unlock new value through technically feasible methods that are adaptive to the contextual needs and values of the communities they ultimately serve.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.04104v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sarah Hartman, Cheng Soon Ong, Julia Powles, Petra Kuhnert</dc:creator>
    </item>
    <item>
      <title>Towards Immersive Mixed Reality Street Play: Understanding Co-located Bodily Play with See-through Head-mounted Displays in Public Spaces</title>
      <link>https://arxiv.org/abs/2505.12516</link>
      <description>arXiv:2505.12516v2 Announce Type: replace-cross 
Abstract: As see-through Mixed Reality Head-Mounted Displays (MRHMDs) proliferate, their usage is gradually shifting from controlled, private settings to spontaneous, public contexts. While location-based augmented reality mobile games such as Pokemon GO have been successful, the embodied interaction afforded by MRHMDs moves play beyond phone-based screen-tapping toward co-located, bodily, movement-based play. In anticipation of widespread MRHMD adoption, major technology companies have teased concept videos envisioning urban streets as vast mixed reality playgrounds-imagine Harry Potter-style wizard duels in city streets-which we term Immersive Mixed Reality Street Play (IMRSP). However, few real-world studies examine such scenarios. Through empirical, in-the-wild studies of our research-through-design game probe, Multiplayer Omnipresent Fighting Arena (MOFA), deployed across diverse public venues, we offer initial insights into the social implications, challenges, opportunities, and design recommendations of IMRSP. The MOFA framework, which includes three gameplay modes-"The Training," "The Duel," and "The Dragon"-is open-sourced at https://github.com/realitydeslab/mofa.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12516v2</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3757679</arxiv:DOI>
      <dc:creator>Botao Amber Hu, Rem Rungu Lin, Yilan Elan Tao, Samuli Laato, Yue Li</dc:creator>
    </item>
    <item>
      <title>Measurement as Bricolage: Examining How Data Scientists Construct Target Variables for Predictive Modeling Tasks</title>
      <link>https://arxiv.org/abs/2507.02819</link>
      <description>arXiv:2507.02819v3 Announce Type: replace-cross 
Abstract: Data scientists often formulate predictive modeling tasks involving fuzzy, hard-to-define concepts, such as the "authenticity" of student writing or the "healthcare need" of a patient. Yet the process by which data scientists translate fuzzy concepts into a concrete, proxy target variable remains poorly understood. We interview fifteen data scientists in education (N=8) and healthcare (N=7) to understand how they construct target variables for predictive modeling tasks. Our findings suggest that data scientists construct target variables through a bricolage process, in which they use creative and pragmatic approaches to make do with the limited data at hand. Data scientists attempt to satisfy five major criteria for a target variable through bricolage: validity, simplicity, predictability, portability, and resource requirements. To achieve this, data scientists adaptively apply problem (re)formulation strategies, such as swapping out one candidate target variable for another when the first fails to meet certain criteria (e.g., predictability), or composing multiple outcomes into a single target variable to capture a more holistic set of modeling objectives. Based on our findings, we present opportunities for future HCI, CSCW, and ML research to better support the art and science of target variable construction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.02819v3</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luke Guerdan, Devansh Saxena, Stevie Chancellor, Zhiwei Steven Wu, Kenneth Holstein</dc:creator>
    </item>
  </channel>
</rss>
