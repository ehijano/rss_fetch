<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CY updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CY</link>
    <description>cs.CY updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CY" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 09 Jul 2024 02:37:20 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 08 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Towards Asimov's Psychohistory: Harnessing Topological Data Analysis, Artificial Intelligence and Social Media data to Forecast Societal Trends</title>
      <link>https://arxiv.org/abs/2407.03446</link>
      <description>arXiv:2407.03446v1 Announce Type: new 
Abstract: In the age of big data and advanced computational methods, the prediction of large-scale social behaviors, reminiscent of Isaac Asimov's fictional science of Psychohistory, is becoming increasingly feasible. This paper consists of a theoretical exploration of the integration of computational power and mathematical frameworks, particularly through Topological Data Analysis (TDA) (Carlsson, Vejdemo-Johansson, 2022) and Artificial Intelligence (AI), to forecast societal trends through social media data analysis. By examining social media as a reflective surface of collective human behavior through the systematic behaviorist approach (Glenn, et al., 2016), I argue that these tools provide unprecedented clarity into the dynamics of large communities. This study dialogues with Asimov's work, drawing parallels between his visionary concepts and contemporary methodologies, illustrating how modern computational techniques can uncover patterns and predict shifts in social behavior, contributing to the emerging field of digital sociology -- or even, Psychohistory itself.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03446v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.SI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Isabela Rocha</dc:creator>
    </item>
    <item>
      <title>Exploring LGBTQ+ Bias in Generative AI Answers across Different Country and Religious Contexts</title>
      <link>https://arxiv.org/abs/2407.03473</link>
      <description>arXiv:2407.03473v1 Announce Type: new 
Abstract: Previous discussions have highlighted the need for generative AI tools to become more culturally sensitive, yet often neglect the complexities of handling content about minorities, who are perceived differently across cultures and religions. Our study examined how two generative AI systems respond to homophobic statements with varying cultural and religious context information. Findings showed ChatGPT 3.5's replies exhibited cultural relativism, in contrast to Bard's, which stressed human rights and provided more support for LGBTQ+ issues. Both demonstrated significant change in responses based on contextual information provided in the prompts, suggesting that AI systems may adjust in their responses the degree and forms of support for LGBTQ+ people according to information they receive about the user's background. The study contributes to understanding the social and ethical implications of AI responses and argues that any work to make generative AI outputs more culturally diverse requires a grounding in fundamental human rights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03473v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lilla Vicsek, Anna Vancs\'o, Mike Zajko, Judit Takacs</dc:creator>
    </item>
    <item>
      <title>How high-status women promote repeated collaboration among women in male-dominated contexts</title>
      <link>https://arxiv.org/abs/2407.03474</link>
      <description>arXiv:2407.03474v1 Announce Type: new 
Abstract: Male-dominated contexts pose a dilemma: they increase the benefits of repeated collaboration among women, yet at the same time, make such collaborations less likely. This paper seeks to understand the conditions that foster repeated collaboration among women versus men in male-dominated settings by examining the critical role of status hierarchies. Using collaboration data on 8,232,769 computer science research teams, we found that when a woman holds the top-ranking position in a steep status hierarchy, other women on that team are more likely than men to collaborate again, as compared to when the hierarchy is flat, and compared to when men occupy the top-ranking position. In steep hierarchies, top-ranking women but not top-ranking men foster conditions in which junior women are more likely to collaborate again than junior men of similar status levels. Our research suggests that whereas status hierarchies are especially detrimental to repeated collaboration among underrepresented individuals, top-ranking women in steep status hierarchies mitigate these negative impacts between women in male-dominated settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03474v1</guid>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Huimin Xu, Jamie Strassman, Ying Ding, Steven Gray, Maytal Saar-Tsechansky</dc:creator>
    </item>
    <item>
      <title>Use of Mobile Devices in the Classroom to Increase Motivation and Participation of Engineering University Students</title>
      <link>https://arxiv.org/abs/2407.03820</link>
      <description>arXiv:2407.03820v1 Announce Type: new 
Abstract: The aim of this study was to see whether student participation increased when mobile devices were used in the classroom. We measured the amount of student participative actions when the Socrative tool was used and when it was not used. Our experiment involved a total of 192 students, corresponding to 4 different subjects of Computer Engineering at the Universitat de les Illes Balears, during 2012/2013 and 2013/2014 courses. An independent paired t-test was performed on the measurements. The analysis results show that student participation increases with the use of mobile devices for theory classes and students are willing to participate in class activities and share their own results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03820v1</guid>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TLA.2016.7430109</arxiv:DOI>
      <arxiv:journal_reference>IEEE Latin America Transactions. Volume: 14, Issue: 1, January 2016. Pages 411 - 416. ISSN: 1548-0992</arxiv:journal_reference>
      <dc:creator>Carlos Guerrero, Antoni Jaume-i-Cap\'o, Carlos Juiz, Isaac Lera</dc:creator>
    </item>
    <item>
      <title>Google Topics as a way out of the cookie dilemma?</title>
      <link>https://arxiv.org/abs/2407.03846</link>
      <description>arXiv:2407.03846v1 Announce Type: new 
Abstract: The paper discusses the legal requirements and implications of the processing of information and personal data for advertising purposes, particularly in the light of the "Planet49" decision of the European Court of Justice (ECJ) and the "Cookie Consent II" decision by the German Federal Court (Bundesgerichtshof, BGH). It emphasises that obtaining explicit consent of individuals is necessary for setting cookies. The introduction of the German Telecommunication Telemedia Data Protection Act (Telekommunikation-Telemedien-Datenschutzgesetz, TTDSG) has replaced the relevant section of the German Telemedia Act (Telemediengesetz, TMG) and transpose the concept of informed consent for storing and accessing information on terminal equipment, aligning with Article 5(3) ePrivacy Directive. To meet these requirements, companies exploring alternatives to obtaining consent are developing technical mechanisms that rely on a legal basis. Google tested initially "Federated Learning of Cohorts" (FLoC) as part of their "Privacy Sandbox" strategy. This technology was significantly criticized, Google introduced a new project called "Google Topics", which aims to personalize advertising by categorizing users into interest groups, called topics. Implementation of this technology began in July 2023.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03846v1</guid>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marius K\"oppel (n\'e Stroscher), Jan-Philipp Muttach (n\'e Stroscher), Gerrit Hornung</dc:creator>
    </item>
    <item>
      <title>How to Evaluate Games in Education: A Literature Review</title>
      <link>https://arxiv.org/abs/2407.03879</link>
      <description>arXiv:2407.03879v1 Announce Type: new 
Abstract: Adding game elements to higher education is an increasingly common practice. As a result, many recent empirical studies focus on studying the effectiveness of gamified or game-based educational experiences. The findings of these studies are very diverse, showing both positive and negative effects, and thus calling for comparative meta-studies. In this paper we review and analyze different studies, aiming to summarise and evaluate controlled experiments conducted within different scientific disciplines. We focus on the clarity of non-experimental conditions' descriptions and show that in most cases a. educational methods used in control groups' activities are poorly described, b. educational materials used in control groups' activities are often unclear, and c. the starting conditions are unclear. We also noticed that studies in the fields of computer science and engineering, in general, report results more clearly than in other fields. Based on the above finding, we conclude with a few recommendations for the execution of future empirical studies of games in education for the sake of allowing a more structured comparison.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03879v1</guid>
      <category>cs.CY</category>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/978-981-99-5961-7_4</arxiv:DOI>
      <arxiv:journal_reference>Smart Learning for A Sustainable Society: Proceedings of the 7th International Conference on Smart Learning Environments Aug 2023</arxiv:journal_reference>
      <dc:creator>Giulio Barbero, Marcello M. Bonsangue, Felienne F. J. Hermans</dc:creator>
    </item>
    <item>
      <title>Understanding the Landscape of Leveraging IoT for Sustainable Growth in Saudi Arabia</title>
      <link>https://arxiv.org/abs/2407.04273</link>
      <description>arXiv:2407.04273v1 Announce Type: new 
Abstract: The integration of Internet of Things (IoT) technologies in agriculture holds promise for transforming farming practices, particularly in the Kingdom of Saudi Arabia (KSA). This study explores the adoption of smart farming practices among KSA farmers. Due to the geographical location and nature of KSA, it faces significant challenges in agriculture. The objective of this research is to discuss how IoT will enhance agriculture in KSA and identify its current usage by conducting a study on Saudi farmers with varying ages, regions, and years of experience. The results indicate that 90% of the farmers encounter challenges in farming, and all of them express interest in adopting smart farming to address these issues. While 60% of farmers are currently utilizing IoT technologies, they encounter challenges in implementing smart farming practices. Thus, smart farming presents solutions to prevalent challenges including adverse weather, water scarcity, and labor shortages, though barriers include cost and educational challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04273v1</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Manal Alshehri, Ohoud Alharbi</dc:creator>
    </item>
    <item>
      <title>Challenges for Real-Time Toxicity Detection in Online Games</title>
      <link>https://arxiv.org/abs/2407.04383</link>
      <description>arXiv:2407.04383v1 Announce Type: new 
Abstract: Online multiplayer games like League of Legends, Counter Strike, and Skribbl.io create experiences through community interactions. Providing players with the ability to interact with each other through multiple modes also opens a Pandora box. Toxic behaviour and malicious players can ruin the experience, reduce the player base and potentially harming the success of the game and the studio. This article will give a brief overview of the challenges faced in toxic content detection in terms of text, audio and image processing problems, and behavioural toxicity. It also discusses the current practices in company-directed and user-directed content detection and discuss the values and limitations of automated content detection in the age of artificial intelligence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04383v1</guid>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Lynnette Hui Xian Ng, Adrian Xuan Wei Lim, Michael Miller Yoder</dc:creator>
    </item>
    <item>
      <title>How to Drill Into Silos: Creating a Free-to-Use Dataset of Data Subject Access Packages</title>
      <link>https://arxiv.org/abs/2407.04470</link>
      <description>arXiv:2407.04470v1 Announce Type: new 
Abstract: The European Union's General Data Protection Regulation (GDPR) strengthened several rights for individuals (data subjects). One of these is the data subjects' right to access their personal data being collected by services (data controllers), complemented with a new right to data portability. Based on these, data controllers are obliged to provide respective data and allow data subjects to use them at their own discretion.
  However, the subjects' possibilities for actually using and harnessing said data are severely limited so far. Among other reasons, this can be attributed to a lack of research dedicated to the actual use of controller-provided subject access request packages (SARPs). To open up and facilitate such research, we outline a general, high-level method for generating, pre-processing, publishing, and finally using SARPs of different providers. Furthermore, we establish a realistic dataset comprising two users' SARPs from five services. This dataset is publicly provided and shall, in the future, serve as a starting and reference point for researching and comparing novel approaches for the practically viable use of SARPs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04470v1</guid>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicola Leschke, Daniela P\"ohn, Frank Pallas</dc:creator>
    </item>
    <item>
      <title>ML Updates for OpenStreetMap: Analysis of Research Gaps and Future Directions</title>
      <link>https://arxiv.org/abs/2407.03365</link>
      <description>arXiv:2407.03365v1 Announce Type: cross 
Abstract: Maintaining accurate, up-to-date maps is important in any dynamic urban landscape, supporting various aspects of modern society, such as urban planning, navigation, and emergency response. However, traditional (i.e. largely manual) map production and crowdsourced mapping methods still struggle to keep pace with rapid changes in the built environment. Such manual mapping workflows are time-consuming and prone to human errors, leading to early obsolescence and/or the need for extensive auditing. The current map updating process in OpenStreetMap provides an example of this limitation, relying on numerous manual steps in its online map updating workflow. To address this, there is a need to explore automating the entire end-to-end map up-dating process. Tech giants such as Google and Microsoft have already started investigating Machine Learning (ML) techniques to tackle this contemporary mapping problem. This paper offers an analysis of these ML approaches, focusing on their application to updating Open-StreetMap in particular. By analysing the current state-of-the-art in this field, this study identi-fies some key research gaps and introduces DeepMapper as a practical solution for advancing the automatic online map updating process in the future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03365v1</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lasith Niroshan, James D. Carswell</dc:creator>
    </item>
    <item>
      <title>Feelings about Bodies: Emotions on Diet and Fitness Forums Reveal Gendered Stereotypes and Body Image Concerns</title>
      <link>https://arxiv.org/abs/2407.03551</link>
      <description>arXiv:2407.03551v1 Announce Type: cross 
Abstract: The gendered expectations about ideal body types can lead to body image concerns, dissatisfaction, and in extreme cases, disordered eating and other psychopathologies across the gender spectrum. While research has focused on pro-anorexia online communities that glorify the 'thin ideal', less attention has been given to the broader spectrum of body image concerns or how emerging disorders like muscle dysmorphia ('bigorexia') present in online discussions. To address these gaps, we analyze 46 Reddit discussion forums related to diet, fitness, and associated mental health challenges. Using membership structure analysis and transformer-based language models, we project these communities along gender and body ideal axes, revealing complex interactions between gender, body ideals, and emotional expression. Our findings show that feminine-oriented communities generally express more negative emotions, particularly in thinness-promoting forums. Conversely, communities focused on the muscular ideal exhibit less negativity, regardless of gender orientation. We also uncover a gendered pattern in emotional indicators of mental health challenges, with communities discussing serious issues aligning more closely with thinness-oriented, predominantly feminine-leaning communities. By revealing the gendered emotional dynamics of online communities, our findings can inform the development of more effective content moderation approaches that facilitate supportive interactions, while minimizing exposure to potentially harmful content.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03551v1</guid>
      <category>cs.SI</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cinthia S\'anchez, Minh Duc Chu, Zihao He, Rebecca Dorn, Stuart Murray, Kristina Lerman</dc:creator>
    </item>
    <item>
      <title>Reviewers of Educational Immersive and Extended Reality (XR) experiences: Who is creating these reviews and why?</title>
      <link>https://arxiv.org/abs/2407.03650</link>
      <description>arXiv:2407.03650v1 Announce Type: cross 
Abstract: This paper presents a scoping review of literature to examine who is reviewing educational immersive or extended reality - eduXR experiences and why. EduXR experiences in augmented, virtual or mixed reality take many forms, from supporting manual training, engaging learners in conservation, to provide opportunities for social connection. For users of eduXR, reviews of an experience can provide information that helps them determine whether it will meet their learning needs or not. The source of the review, that is, who they are and why they have conducted the review, is critical in helping the user judge the reviews quality and relevance. At present, there is no settled review system in place for eduXR, though relevant frameworks exist for serious games review with relevance and overlap for some, but not all, eduXR experiences. While some authors have engaged in preparing a detailed review structure for eduXR, there remains a need for a clear and simple way for users of eduXR to know details about reviewers, e.g., who and why, to help make it easier for users to identify relevant reviews and gain useful insight about eduXR experiences. To help address this issue, we conducted a scoping review asking the question; Who is creating eduXR reviews, and why? We identified 16 papers that present an academic evaluation on the review process of eduXR reviews. The 16 papers were analysed, coding for who themes and why themes over two separate cycles, using thematic analysis. An analysis looked to examine what we know regarding who is providing the reviews, and why, to help us to understand what enables, inhibits and what is yet unknown about how the eduXR community goes about making informed choices regarding the eduXR experiences they engage with.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03650v1</guid>
      <category>cs.IR</category>
      <category>cs.CY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Sophie McKenzie, Shaun Bangay, Maria Nicholas, Adam Cardilini, Majeet Singh</dc:creator>
    </item>
    <item>
      <title>Quantifying Prediction Consistency Under Model Multiplicity in Tabular LLMs</title>
      <link>https://arxiv.org/abs/2407.04173</link>
      <description>arXiv:2407.04173v1 Announce Type: cross 
Abstract: Fine-tuning large language models (LLMs) on limited tabular data for classification tasks can lead to \textit{fine-tuning multiplicity}, where equally well-performing models make conflicting predictions on the same inputs due to variations in the training process (i.e., seed, random weight initialization, retraining on additional or deleted samples). This raises critical concerns about the robustness and reliability of Tabular LLMs, particularly when deployed for high-stakes decision-making, such as finance, hiring, education, healthcare, etc. This work formalizes the challenge of fine-tuning multiplicity in Tabular LLMs and proposes a novel metric to quantify the robustness of individual predictions without expensive model retraining. Our metric quantifies a prediction's stability by analyzing (sampling) the model's local behavior around the input in the embedding space. Interestingly, we show that sampling in the local neighborhood can be leveraged to provide probabilistic robustness guarantees against a broad class of fine-tuned models. By leveraging Bernstein's Inequality, we show that predictions with sufficiently high robustness (as defined by our measure) will remain consistent with high probability. We also provide empirical evaluation on real-world datasets to support our theoretical results. Our work highlights the importance of addressing fine-tuning instabilities to enable trustworthy deployment of LLMs in high-stakes and safety-critical applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04173v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Faisal Hamman, Pasan Dissanayake, Saumitra Mishra, Freddy Lecue, Sanghamitra Dutta</dc:creator>
    </item>
    <item>
      <title>Seeing Like an AI: How LLMs Apply (and Misapply) Wikipedia Neutrality Norms</title>
      <link>https://arxiv.org/abs/2407.04183</link>
      <description>arXiv:2407.04183v1 Announce Type: cross 
Abstract: Large language models (LLMs) are trained on broad corpora and then used in communities with specialized norms. Is providing LLMs with community rules enough for models to follow these norms? We evaluate LLMs' capacity to detect (Task 1) and correct (Task 2) biased Wikipedia edits according to Wikipedia's Neutral Point of View (NPOV) policy. LLMs struggled with bias detection, achieving only 64% accuracy on a balanced dataset. Models exhibited contrasting biases (some under- and others over-predicted bias), suggesting distinct priors about neutrality. LLMs performed better at generation, removing 79% of words removed by Wikipedia editors. However, LLMs made additional changes beyond Wikipedia editors' simpler neutralizations, resulting in high-recall but low-precision editing. Interestingly, crowdworkers rated AI rewrites as more neutral (70%) and fluent (61%) than Wikipedia-editor rewrites. Qualitative analysis found LLMs sometimes applied NPOV more comprehensively than Wikipedia editors but often made extraneous non-NPOV-related changes (such as grammar). LLMs may apply rules in ways that resonate with the public but diverge from community experts. While potentially effective for generation, LLMs may reduce editor agency and increase moderation workload (e.g., verifying additions). Even when rules are easy to articulate, having LLMs apply them like community members may still be difficult.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04183v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joshua Ashkinaze, Ruijia Guan, Laura Kurek, Eytan Adar, Ceren Budak, Eric Gilbert</dc:creator>
    </item>
    <item>
      <title>FUTURE-AI: International consensus guideline for trustworthy and deployable artificial intelligence in healthcare</title>
      <link>https://arxiv.org/abs/2309.12325</link>
      <description>arXiv:2309.12325v3 Announce Type: replace 
Abstract: Despite major advances in artificial intelligence (AI) for medicine and healthcare, the deployment and adoption of AI technologies remain limited in real-world clinical practice. In recent years, concerns have been raised about the technical, clinical, ethical and legal risks associated with medical AI. To increase real world adoption, it is essential that medical AI tools are trusted and accepted by patients, clinicians, health organisations and authorities. This work describes the FUTURE-AI guideline as the first international consensus framework for guiding the development and deployment of trustworthy AI tools in healthcare. The FUTURE-AI consortium was founded in 2021 and currently comprises 118 inter-disciplinary experts from 51 countries representing all continents, including AI scientists, clinicians, ethicists, and social scientists. Over a two-year period, the consortium defined guiding principles and best practices for trustworthy AI through an iterative process comprising an in-depth literature review, a modified Delphi survey, and online consensus meetings. The FUTURE-AI framework was established based on 6 guiding principles for trustworthy AI in healthcare, i.e. Fairness, Universality, Traceability, Usability, Robustness and Explainability. Through consensus, a set of 28 best practices were defined, addressing technical, clinical, legal and socio-ethical dimensions. The recommendations cover the entire lifecycle of medical AI, from design, development and validation to regulation, deployment, and monitoring. FUTURE-AI is a risk-informed, assumption-free guideline which provides a structured approach for constructing medical AI tools that will be trusted, deployed and adopted in real-world practice. Researchers are encouraged to take the recommendations into account in proof-of-concept stages to facilitate future translation towards clinical practice of medical AI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.12325v3</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Karim Lekadir, Aasa Feragen, Abdul Joseph Fofanah, Alejandro F Frangi, Alena Buyx, Anais Emelie, Andrea Lara, Antonio R Porras, An-Wen Chan, Arcadi Navarro, Ben Glocker, Benard O Botwe, Bishesh Khanal, Brigit Beger, Carol C Wu, Celia Cintas, Curtis P Langlotz, Daniel Rueckert, Deogratias Mzurikwao, Dimitrios I Fotiadis, Doszhan Zhussupov, Enzo Ferrante, Erik Meijering, Eva Weicken, Fabio A Gonz\'alez, Folkert W Asselbergs, Fred Prior, Gabriel P Krestin, Gary Collins, Geletaw S Tegenaw, Georgios Kaissis, Gianluca Misuraca, Gianna Tsakou, Girish Dwivedi, Haridimos Kondylakis, Harsha Jayakody, Henry C Woodruf, Horst Joachim Mayer, Hugo JWL Aerts, Ian Walsh, Ioanna Chouvarda, Ir\`ene Buvat, Isabell Tributsch, Islem Rekik, James Duncan, Jayashree Kalpathy-Cramer, Jihad Zahir, Jinah Park, John Mongan, Judy W Gichoya, Julia A Schnabel, Kaisar Kushibar, Katrine Riklund, Kensaku Mori, Kostas Marias, Lameck M Amugongo, Lauren A Fromont, Lena Maier-Hein, Leonor Cerd\'a Alberich, Leticia Rittner, Lighton Phiri, Linda Marrakchi-Kacem, Llu\'is Donoso-Bach, Luis Mart\'i-Bonmat\'i, M Jorge Cardoso, Maciej Bobowicz, Mahsa Shabani, Manolis Tsiknakis, Maria A Zuluaga, Maria Bielikova, Marie-Christine Fritzsche, Marina Camacho, Marius George Linguraru, Markus Wenzel, Marleen De Bruijne, Martin G Tolsgaard, Marzyeh Ghassemi, Md Ashrafuzzaman, Melanie Goisauf, Mohammad Yaqub, M\'onica Cano Abad\'ia, Mukhtar M E Mahmoud, Mustafa Elattar, Nicola Rieke, Nikolaos Papanikolaou, Noussair Lazrak, Oliver D\'iaz, Olivier Salvado, Oriol Pujol, Ousmane Sall, Pamela Guevara, Peter Gordebeke, Philippe Lambin, Pieta Brown, Purang Abolmaesumi, Qi Dou, Qinghua Lu, Richard Osuala, Rose Nakasi, S Kevin Zhou, Sandy Napel, Sara Colantonio, Shadi Albarqouni, Smriti Joshi, Stacy Carter, Stefan Klein, Steffen E Petersen, Susanna Auss\'o, Suyash Awate, Tammy Riklin Raviv, Tessa Cook, Tinashe E M Mutsvangwa, Wendy A Rogers, Wiro J Niessen, X\`enia Puig-Bosch, Yi Zeng, Yunusa G Mohammed, Yves Saint James Aquino, Zohaib Salahuddin, Martijn P A Starmans</dc:creator>
    </item>
    <item>
      <title>Characteristics and prevalence of fake social media profiles with AI-generated faces</title>
      <link>https://arxiv.org/abs/2401.02627</link>
      <description>arXiv:2401.02627v2 Announce Type: replace 
Abstract: Recent advancements in generative artificial intelligence (AI) have raised concerns about their potential to create convincing fake social media accounts, but empirical evidence is lacking. In this paper, we present a systematic analysis of Twitter (X) accounts using human faces generated by Generative Adversarial Networks (GANs) for their profile pictures. We present a dataset of 1,420 such accounts and show that they are used to spread scams, spam, and amplify coordinated messages, among other inauthentic activities. Leveraging a feature of GAN-generated faces -- consistent eye placement -- and supplementing it with human annotation, we devise an effective method for identifying GAN-generated profiles in the wild. Applying this method to a random sample of active Twitter users, we estimate a lower bound for the prevalence of profiles using GAN-generated faces between 0.021% and 0.044% -- around 10K daily active accounts. These findings underscore the emerging threats posed by multimodal generative AI. We release the source code of our detection method and the data we collect to facilitate further investigation. Additionally, we provide practical heuristics to assist social media users in recognizing such accounts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.02627v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.SI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kai-Cheng Yang, Danishjeet Singh, Filippo Menczer</dc:creator>
    </item>
    <item>
      <title>How AI Ideas Affect the Creativity, Diversity, and Evolution of Human Ideas: Evidence From a Large, Dynamic Experiment</title>
      <link>https://arxiv.org/abs/2401.13481</link>
      <description>arXiv:2401.13481v2 Announce Type: replace 
Abstract: Exposure to large language model output is rapidly increasing. How will seeing AI-generated ideas affect human ideas? We conducted an experiment (800+ participants, 40+ countries) where participants viewed creative ideas that were from ChatGPT or prior experimental participants and then brainstormed their own idea. We varied the number of AI-generated examples (none, low, or high exposure) and if the examples were labeled as 'AI' (disclosure). Our dynamic experiment design -- ideas from prior participants in an experimental condition are used as stimuli for future participants in the same experimental condition -- speaks to the interdependent process of cultural creation: creative ideas are built upon prior ideas. Hence, we capture the compounding effects of having LLMs 'in the culture loop'. We find that high AI exposure (but not low AI exposure) did not affect the creativity of individual ideas but did increase the average amount and rate of change of collective idea diversity. AI made ideas different, not better. There were no main effects of disclosure. We also found that self-reported creative people were less influenced by knowing an idea was from AI and that participants may knowingly adopt AI ideas when the task is difficult. Our findings suggest that introducing AI ideas may increase collective diversity but not individual creativity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.13481v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.HC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joshua Ashkinaze, Julia Mendelsohn, Li Qiwei, Ceren Budak, Eric Gilbert</dc:creator>
    </item>
    <item>
      <title>Integration of Artificial Intelligence in Educational Measurement: Efficacy of ChatGPT in Data Generation within the Scope of Item Response Theory</title>
      <link>https://arxiv.org/abs/2402.01731</link>
      <description>arXiv:2402.01731v2 Announce Type: replace 
Abstract: The aim of this study is to investigate the effectiveness of ChatGPT 3.5 in developing algorithms for data generation within the framework of Item Response Theory (IRT) using the R programming language. In this context, validity examinations were conducted on data sets generated according to the Two-Parameter Logistic Model (2PLM) with algorithms written by ChatGPT 3.5 and researchers. These examinations considered whether the data sets met the IRT assumptions and the simulation conditions of the item parameters. As a result, it was determined that while ChatGPT 3.5 was quite successful in generating data that met the IRT assumptions, it was less effective in meeting the simulation conditions of the item parameters compared to the algorithm developed by the researchers. In this regard, ChatGPT 3.5 is recommended as a useful tool that researchers can use in developing data generation algorithms for IRT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.01731v2</guid>
      <category>cs.CY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hatice Gurdil, Yesim Beril Soguksu, Salih Salihoglu, Fatma Coskun</dc:creator>
    </item>
    <item>
      <title>Improving Low-Resource Knowledge Tracing Tasks by Supervised Pre-training and Importance Mechanism Fine-tuning</title>
      <link>https://arxiv.org/abs/2403.06725</link>
      <description>arXiv:2403.06725v3 Announce Type: replace 
Abstract: Knowledge tracing (KT) aims to estimate student's knowledge mastery based on their historical interactions. Recently, the deep learning based KT (DLKT) approaches have achieved impressive performance in the KT task. These DLKT models heavily rely on the large number of available student interactions. However, due to various reasons such as budget constraints and privacy concerns, observed interactions are very limited in many real-world scenarios, a.k.a, low-resource KT datasets. Directly training a DLKT model on a low-resource KT dataset may lead to overfitting and it is difficult to choose the appropriate deep neural architecture. Therefore, in this paper, we propose a low-resource KT framework called LoReKT to address above challenges. Inspired by the prevalent "pre-training and fine-tuning" paradigm, we aim to learn transferable parameters and representations from rich-resource KT datasets during the pre-training stage and subsequently facilitate effective adaptation to low-resource KT datasets. Specifically, we simplify existing sophisticated DLKT model architectures with purely a stack of transformer decoders. We design an encoding mechanism to incorporate student interactions from multiple KT data sources and develop an importance mechanism to prioritize updating parameters with high importance while constraining less important ones during the fine-tuning stage. We evaluate LoReKT on six public KT datasets and experimental results demonstrate the superiority of our approach in terms of AUC and Accuracy. To encourage reproducible research, we make our data and code publicly available at https://anonymous.4open.science/r/LoReKT-C619.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06725v3</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hengyuan Zhang, Zitao Liu, Shuyan Huang, Chenming Shang, Bojun Zhan, Yong Jiang</dc:creator>
    </item>
    <item>
      <title>A Question-centric Multi-experts Contrastive Learning Framework for Improving the Accuracy and Interpretability of Deep Sequential Knowledge Tracing Models</title>
      <link>https://arxiv.org/abs/2403.07322</link>
      <description>arXiv:2403.07322v3 Announce Type: replace 
Abstract: Knowledge tracing (KT) plays a crucial role in predicting students' future performance by analyzing their historical learning processes. Deep neural networks (DNNs) have shown great potential in solving the KT problem. However, there still exist some important challenges when applying deep learning techniques to model the KT process. The first challenge lies in taking the individual information of the question into modeling. This is crucial because, despite questions sharing the same knowledge component (KC), students' knowledge acquisition on homogeneous questions can vary significantly. The second challenge lies in interpreting the prediction results from existing deep learning-based KT models. In real-world applications, while it may not be necessary to have complete transparency and interpretability of the model parameters, it is crucial to present the model's prediction results in a manner that teachers find interpretable. This makes teachers accept the rationale behind the prediction results and utilize them to design teaching activities and tailored learning strategies for students. However, the inherent black-box nature of deep learning techniques often poses a hurdle for teachers to fully embrace the model's prediction results. To address these challenges, we propose a Question-centric Multi-experts Contrastive Learning framework for KT called Q-MCKT. We have provided all the datasets and code on our website at https://github.com/rattlesnakey/Q-MCKT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07322v3</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hengyuan Zhang, Zitao Liu, Chenming Shang, Dawei Li, Yong Jiang</dc:creator>
    </item>
    <item>
      <title>Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health</title>
      <link>https://arxiv.org/abs/2406.07114</link>
      <description>arXiv:2406.07114v2 Announce Type: replace 
Abstract: The concept of Metaverse has attracted a lot of attention in various fields and one of its important applications is health and treatment. The Metaverse has enormous potential to transform healthcare by changing patient care, medical education, and the way teaching/learning and research are done. The purpose of this research is to provide an introduction to the basic concepts and fundamental technologies of the Metaverse. This paper examines the pros and cons of the Metaverse in healthcare context and analyzes its potential from the technology and AI perspective. In particular, the role of machine learning methods is discussed; We will explain how machine learning algorithms can be applied to the Metaverse generated data to gain better insights in healthcare applications. Additionally, we examine the future visions of the Metaverse in health delivery, by examining emerging technologies such as blockchain and also addressing privacy concerns. The findings of this study contribute to a deeper understanding of the applications of Metaverse in healthcare and its potential to revolutionize the delivery of medical services.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.07114v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.IR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Fatemeh Ebrahimzadeh, Ramin Safa</dc:creator>
    </item>
    <item>
      <title>Holistic view of the road transportation system based on real-time data sharing mechanism</title>
      <link>https://arxiv.org/abs/2407.03187</link>
      <description>arXiv:2407.03187v2 Announce Type: replace 
Abstract: Traditional manual driving and single-vehicle-based intelligent driving have limitations in real-time and accurate acquisition of the current driving status and intentions of surrounding vehicles, leading to vehicles typically maintaining appropriate safe distances from each other. Yet, accidents still frequently occur, especially in merging areas; meanwhile, it is difficult to comprehensively obtain the conditions of road infrastructure. These limitations not only restrict the further improvement of road capacity but also result in irreparable losses of life and property. To overcome this bottleneck, this paper constructs a space-time global view of the road traffic system based on a real-time sharing mechanism, enabling both road users and managers to timely access the driving intentions of nearby vehicles and the real-time status of road infrastructure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03187v2</guid>
      <category>cs.CY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Li Tao, Dong Xiang, Hao Junfeng, Yin Ping, Xu Xiaoxue, Lai Maokai, Li Yuan, Peng Ting</dc:creator>
    </item>
    <item>
      <title>From Representational Harms to Quality-of-Service Harms: A Case Study on Llama 2 Safety Safeguards</title>
      <link>https://arxiv.org/abs/2403.13213</link>
      <description>arXiv:2403.13213v4 Announce Type: replace-cross 
Abstract: Recent progress in large language models (LLMs) has led to their widespread adoption in various domains. However, these advancements have also introduced additional safety risks and raised concerns regarding their detrimental impact on already marginalized populations. Despite growing mitigation efforts to develop safety safeguards, such as supervised safety-oriented fine-tuning and leveraging safe reinforcement learning from human feedback, multiple concerns regarding the safety and ingrained biases in these models remain. Furthermore, previous work has demonstrated that models optimized for safety often display exaggerated safety behaviors, such as a tendency to refrain from responding to certain requests as a precautionary measure. As such, a clear trade-off between the helpfulness and safety of these models has been documented in the literature. In this paper, we further investigate the effectiveness of safety measures by evaluating models on already mitigated biases. Using the case of Llama 2 as an example, we illustrate how LLMs' safety responses can still encode harmful assumptions. To do so, we create a set of non-toxic prompts, which we then use to evaluate Llama models. Through our new taxonomy of LLMs responses to users, we observe that the safety/helpfulness trade-offs are more pronounced for certain demographic groups which can lead to quality-of-service harms for marginalized populations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.13213v4</guid>
      <category>cs.LG</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Khaoula Chehbouni, Megha Roshan, Emmanuel Ma, Futian Andrew Wei, Afaf Taik, Jackie CK Cheung, Golnoosh Farnadi</dc:creator>
    </item>
    <item>
      <title>Predicting the duration of traffic incidents for Sydney greater metropolitan area using machine learning methods</title>
      <link>https://arxiv.org/abs/2406.18861</link>
      <description>arXiv:2406.18861v2 Announce Type: replace-cross 
Abstract: This research presents a comprehensive approach to predicting the duration of traffic incidents and classifying them as short-term or long-term across the Sydney Metropolitan Area. Leveraging a dataset that encompasses detailed records of traffic incidents, road network characteristics, and socio-economic indicators, we train and evaluate a variety of advanced machine learning models including Gradient Boosted Decision Trees (GBDT), Random Forest, LightGBM, and XGBoost. The models are assessed using Root Mean Square Error (RMSE) for regression tasks and F1 score for classification tasks.
  Our experimental results demonstrate that XGBoost and LightGBM outperform conventional models with XGBoost achieving the lowest RMSE of 33.7 for predicting incident duration and highest classification F1 score of 0.62 for a 30-minute duration threshold. For classification, the 30-minute threshold balances performance with 70.84% short-term duration classification accuracy and 62.72% long-term duration classification accuracy. Feature importance analysis, employing both tree split counts and SHAP values, identifies the number of affected lanes, traffic volume, and types of primary and secondary vehicles as the most influential features.
  The proposed methodology not only achieves high predictive accuracy but also provides stakeholders with vital insights into factors contributing to incident durations. These insights enable more informed decision-making for traffic management and response strategies. The code is available by the link: https://github.com/Future-Mobility-Lab/SydneyIncidents</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.18861v2</guid>
      <category>cs.LG</category>
      <category>cs.CY</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Artur Grigorev, Sajjad Shafiei, Hanna Grzybowska, Adriana-Simona Mihaita</dc:creator>
    </item>
    <item>
      <title>Using Large Language Models to Assist Video Content Analysis: An Exploratory Study of Short Videos on Depression</title>
      <link>https://arxiv.org/abs/2406.19528</link>
      <description>arXiv:2406.19528v2 Announce Type: replace-cross 
Abstract: Despite the growing interest in leveraging Large Language Models (LLMs) for content analysis, current studies have primarily focused on text-based content. In the present work, we explored the potential of LLMs in assisting video content analysis by conducting a case study that followed a new workflow of LLM-assisted multimodal content analysis. The workflow encompasses codebook design, prompt engineering, LLM processing, and human evaluation. We strategically crafted annotation prompts to get LLM Annotations in structured form and explanation prompts to generate LLM Explanations for a better understanding of LLM reasoning and transparency. To test LLM's video annotation capabilities, we analyzed 203 keyframes extracted from 25 YouTube short videos about depression. We compared the LLM Annotations with those of two human coders and found that LLM has higher accuracy in object and activity Annotations than emotion and genre Annotations. Moreover, we identified the potential and limitations of LLM's capabilities in annotating videos. Based on the findings, we explore opportunities and challenges for future research and improvements to the workflow. We also discuss ethical concerns surrounding future studies based on LLM-assisted video analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19528v2</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiaying Liu, Yunlong Wang, Yao Lyu, Yiheng Su, Shuo Niu, Xuhai Orson Xu, Yan Zhang</dc:creator>
    </item>
  </channel>
</rss>
