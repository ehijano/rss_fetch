<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cond-mat.dis-nn updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cond-mat.dis-nn</link>
    <description>cond-mat.dis-nn updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cond-mat.dis-nn" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 28 May 2024 04:01:57 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 28 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Using continuation methods to analyse the difficulty of problems solved by Ising machines</title>
      <link>https://arxiv.org/abs/2405.17112</link>
      <description>arXiv:2405.17112v1 Announce Type: new 
Abstract: Ising machines are dedicated hardware solvers of NP-hard optimization problems. However, they do not always find the most optimal solution. The probability of finding this optimal solution depends on the problem at hand. Using continuation methods, we show that this is closely linked to the bifurcation sequence of the optimal solution. From this bifurcation analysis, we can determine the effectiveness of solution schemes. Moreover, we find that the proper choice of implementation of the Ising machine can drastically change this bifurcation sequence and therefore vastly increase the probability of finding the optimal solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17112v1</guid>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.CC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jacob Lamers, Guy Verschaffelt, Guy Van der Sande</dc:creator>
    </item>
    <item>
      <title>Coupling Light with Matter for Identifying Dominant Subnetworks</title>
      <link>https://arxiv.org/abs/2405.17296</link>
      <description>arXiv:2405.17296v1 Announce Type: new 
Abstract: We present a novel light-matter platform that uses complex-valued oscillator networks, a form of physical neural networks, to identify dominant subnetworks and uncover indirect correlations within larger networks. This approach offers significant advantages, including low energy consumption, high processing speed, and the immediate identification of co- and counter-regulated nodes without post-processing. The effectiveness of this approach is demonstrated through its application to biological networks, and we also propose its applicability to a wide range of other network types.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17296v1</guid>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.other</category>
      <category>cs.ET</category>
      <category>physics.optics</category>
      <category>quant-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Airat Kamaletdinov, Natalia G. Berloff</dc:creator>
    </item>
    <item>
      <title>Magnetic properties of diluted hexaferrites</title>
      <link>https://arxiv.org/abs/2405.17328</link>
      <description>arXiv:2405.17328v1 Announce Type: new 
Abstract: We revisit the magnetic properties of the hexagonal ferrite PbFe$_{12-x}$Ga$_x$O$_{19}$. Recent experiments have reported puzzling dependencies of the ordering temperature and the saturation magnetization on the Ga concentration $x$. To explain these observations, we perform large-scale Monte Carlo simulations, focusing on the effects of an unequal distribution of the Ga impurities over the five distinct Fe sublattices. Ab-initio density-functional calculations predict that the Ga ions preferably occupy the $12k$ sublattice and (to a lesser extent) the $2a$ sublattice. We incorporate this insight into a nonuniform model of the Ga distribution. Monte Carlo simulations using this model lead to an excellent agreement between the theoretical and experimental values of the ordering temperature and saturation magnetization, indicating that the unequal distribution of the Ga impurities is the main reason for the unusual magnetic properties of PbFe$_{12-x}$Ga$_x$O$_{19}$. We also compute the temperature and concentration dependencies of the sublattice magnetizations, and we study the character of the zero-temperature transition that takes place when the ordering temperature is tuned to zero.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17328v1</guid>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.mtrl-sci</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Logan Sowadski, Sean Anderson, Cameron Lerch, Julia Medvedeva, Thomas Vojta</dc:creator>
    </item>
    <item>
      <title>Dissecting the Interplay of Attention Paths in a Statistical Mechanics Theory of Transformers</title>
      <link>https://arxiv.org/abs/2405.15926</link>
      <description>arXiv:2405.15926v1 Announce Type: cross 
Abstract: Despite the remarkable empirical performance of Transformers, their theoretical understanding remains elusive. Here, we consider a deep multi-head self-attention network, that is closely related to Transformers yet analytically tractable. We develop a statistical mechanics theory of Bayesian learning in this model, deriving exact equations for the network's predictor statistics under the finite-width thermodynamic limit, i.e., $N,P\rightarrow\infty$, $P/N=\mathcal{O}(1)$, where $N$ is the network width and $P$ is the number of training examples. Our theory shows that the predictor statistics are expressed as a sum of independent kernels, each one pairing different 'attention paths', defined as information pathways through different attention heads across layers. The kernels are weighted according to a 'task-relevant kernel combination' mechanism that aligns the total kernel with the task labels. As a consequence, this interplay between attention paths enhances generalization performance. Experiments confirm our findings on both synthetic and real-world sequence classification tasks. Finally, our theory explicitly relates the kernel combination mechanism to properties of the learned weights, allowing for a qualitative transfer of its insights to models trained via gradient descent. As an illustration, we demonstrate an efficient size reduction of the network, by pruning those attention heads that are deemed less relevant by our theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15926v1</guid>
      <category>cs.LG</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lorenzo Tiberi, Francesca Mignacco, Kazuki Irie, Haim Sompolinsky</dc:creator>
    </item>
    <item>
      <title>A Topological Classification of Finite Chiral Structures using Complete Matchings</title>
      <link>https://arxiv.org/abs/2405.16274</link>
      <description>arXiv:2405.16274v1 Announce Type: cross 
Abstract: We present the theory and experimental demonstration of a topological classification of finite tight binding Hamiltonians with chiral symmetry. Using the graph-theoretic notion of complete matchings, we show that many chiral tight binding structures can be divided into a number of sections, each of which has independent topological phases. Hence the overall classification is $N\mathbb{Z}_2$, corresponding to $2^N$ distinct phases, where $N$ is the number of sections with a non-trivial $\mathbb{Z}_2$ classification. In our classification, distinct topological phases are separated by exact closures in the energy spectrum of the Hamiltonian, with degenerate pairs of zero energy states. We show that that these zero energy states have an unusual localisation across distinct regions of the structure, determined by the manner in which the sections are connected together. We use this localisation to provide an experimental demonstration of the validity of the classification, through radio frequency measurements on a coaxial cable network which maps onto a tight binding system. The structure we investigate is a cable analogue of an ideal graphene ribbon, which divides into four sections and has a $4\mathbb{Z}_2$ topological classification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16274v1</guid>
      <category>cond-mat.mes-hall</category>
      <category>cond-mat.dis-nn</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maxine M. McCarthy, D. M. Whittaker</dc:creator>
    </item>
    <item>
      <title>Generating configurations of increasing lattice size with machine learning and the inverse renormalization group</title>
      <link>https://arxiv.org/abs/2405.16288</link>
      <description>arXiv:2405.16288v1 Announce Type: cross 
Abstract: We review recent developments of machine learning algorithms pertinent to the inverse renormalization group, which was originally established as a generative numerical method by Ron-Swendsen-Brandt via the implementation of compatible Monte Carlo simulations. Inverse renormalization group methods enable the iterative generation of configurations for increasing lattice size without the critical slowing down effect. We discuss the construction of inverse renormalization group transformations with the use of convolutional neural networks and present applications in models of statistical mechanics, lattice field theory, and disordered systems. We highlight the case of the three-dimensional Edwards-Anderson spin glass, where the inverse renormalization group can be employed to construct configurations for lattice volumes that have not yet been accessed by dedicated supercomputers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16288v1</guid>
      <category>hep-lat</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.LG</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dimitrios Bachtis</dc:creator>
    </item>
    <item>
      <title>Metric structural human connectomes: localization and multifractality of eigenmodes</title>
      <link>https://arxiv.org/abs/2405.17349</link>
      <description>arXiv:2405.17349v1 Announce Type: cross 
Abstract: In this study, we explore the fundamental principles behind the architecture of the human brain's structural connectome, from the perspective of spectral analysis of Laplacian and adjacency matrices. Building on the idea that the brain strikes a balance between efficient information processing and minimizing wiring costs, we aim to understand the impact of the metric properties of the connectome and how they relate to the existence of an inherent scale. We demonstrate that a simple generative model, combining nonlinear preferential attachment with an exponential penalty for spatial distance between nodes, can effectively reproduce several key characteristics of the human connectome, including spectral density, edge length distribution, eigenmode localization and local clustering properties. We also delve into the finer spectral properties of the human structural connectomes by evaluating the inverse participation ratios ($\text{IPR}_q$) across various parts of the spectrum. Our analysis reveals that the level statistics in the soft cluster region of the Laplacian spectrum deviate from a purely Poisson distribution due to interactions between clusters. Additionally, we identified scar-like localized modes with large IPR values in the continuum spectrum. We identify multiple fractal eigenmodes distributed across different parts of the spectrum, evaluate their fractal dimensions and find a power-law relationship in the return probability, which is a hallmark of critical behavior. We discuss the conjectures that a brain operates in the Griffiths or multifractal phases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17349v1</guid>
      <category>q-bio.NC</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anna Bobyleva, Alexander Gorsky, Sergei Nechaev, Olga Valba, Nikita Pospelov</dc:creator>
    </item>
    <item>
      <title>Dynamical Theory for Adaptive Systems</title>
      <link>https://arxiv.org/abs/2306.01403</link>
      <description>arXiv:2306.01403v4 Announce Type: replace-cross 
Abstract: The investigation of adaptive dynamics, involving many degrees of freedom on two separated timescales, one for fast changes of state variables and another for the slow adaptation of parameters controlling the former's dynamics is crucial for understanding feedback mechanisms underlying evolutionary and learning processes. We present an extension of the Martin-Siggia-Rose-DeDominicis-Janssen (MSRDJ) path-integral approach to the study of nonequilibrium phase transitions in such dynamical systems. As an illustration, we apply our framework to biological adaptation under the genotype-phenotype feedback: phenotypic variations are shaped by the fast stochastic gene-expression dynamics and are coupled to the slow evolution of the distribution of genotypes, each encoded by a gene-regulatory network architecture. We establish that under this coevolution, genotypes responsible for high fitness are selected, leading to the emergence of phenotypic robustness within an intermediate level of environmental noise in reciprocal genetic networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.01403v4</guid>
      <category>q-bio.PE</category>
      <category>cond-mat.dis-nn</category>
      <category>nlin.AO</category>
      <category>physics.bio-ph</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tuan Minh Pham, Kunihiko Kaneko</dc:creator>
    </item>
    <item>
      <title>Theory of Difference Frequency Quantum Oscillations</title>
      <link>https://arxiv.org/abs/2306.10760</link>
      <description>arXiv:2306.10760v2 Announce Type: replace-cross 
Abstract: Quantum oscillations (QO) describe the periodic variation of physical observables as a function of inverse magnetic field in metals. The Onsager relation connects the basic QO frequencies with the extremal areas of closed Fermi surface pockets, and the theory of magnetic breakdown explains the observation of sums of QO frequencies at high magnetic fields. Here we develop a quantitative theory of difference frequency QOs in two- and three-dimensional metals with multiple Fermi pockets with parabolic or linearly dispersing excitations. We show that a non-linear interband coupling, e.g. in the form of interband impurity scattering, can give rise to otherwise forbidden QO frequencies which can persist to much higher temperatures compared to the basis frequencies. We discuss the experimental implications of our findings for various material candidates, for example multi-fold fermion systems, and the relation to magneto intersubband oscillations known for coupled two-dimensional electron gases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.10760v2</guid>
      <category>cond-mat.str-el</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.mtrl-sci</category>
      <category>cond-mat.other</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1103/PhysRevB.108.054202</arxiv:DOI>
      <dc:creator>Valentin Leeb, Johannes Knolle</dc:creator>
    </item>
    <item>
      <title>Ancilla quantum measurements on interacting chains: Sensitivity of entanglement dynamics to the type and concentration of detectors</title>
      <link>https://arxiv.org/abs/2311.13011</link>
      <description>arXiv:2311.13011v2 Announce Type: replace-cross 
Abstract: We consider a quantum many-body lattice system that is coupled to ancillary degrees of freedom (``detectors''), which are periodically measured by means of strong projective measurements. The concentration $\rho_a$ of ancillae and their coupling $M$ to the main system are considered as parameters. We explore the dynamics of density and of entanglement entropy in the chain, for various values of $\rho_a$ and $M$ for two models of the detector-chain interaction that couple the local density in the chain to a detector degree of freedom. It is found that, for the density-density ($S_z s_z$-type in spin language) coupling, the critical values $M_c$ for the measurement-induced entanglement transition depends sensitively on $\rho_a$. Moreover, our results indicate that for a sufficiently small $\rho_a$ the transition in this model disappears, i.e., a finite density of detectors is needed to reach a disentangling phase. The behavior is qualitatively different for the second model, with density-hopping ($S_z s_x$-type) coupling. Specifically, the dynamics is much less sensitive to the concentration $\rho_a$ of detectors than in the first model. Furthermore, the dependence of entanglement on the coupling strength $M$ is strongly non-monotonic, indicating re-entrance of the entangling phase at large $M$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.13011v2</guid>
      <category>quant-ph</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.mes-hall</category>
      <category>cond-mat.str-el</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elmer V. H. Doggen, Igor V. Gornyi, Alexander D. Mirlin</dc:creator>
    </item>
    <item>
      <title>Deep Learning Methods for Colloidal Silver Nanoparticle Concentration and Size Distribution Determination from UV-Vis Extinction Spectra</title>
      <link>https://arxiv.org/abs/2404.10891</link>
      <description>arXiv:2404.10891v2 Announce Type: replace-cross 
Abstract: Electron microscopy, while reliable, is an expensive, slow, and inefficient technique for thorough size distribution characterization of both mono- and polydisperse colloidal nanoparticles. If rapid in-situ characterization of colloid samples is to be achieved, a different approach, based on fast, widely accessible, and inexpensive optical measurements such as UV-Vis spectroscopy in combination with spectra interpretation related to Mie scattering theory, is needed. In this article, we present a tandem deep neural network (DNN) for the size distribution and concentration prediction of close to spherical silver colloidal nanoparticle batches synthesized via the seeded growth method. The first DNN identified the dipole component of the localized surface plasmon resonance and the second one determined the size distribution from the isolated spectral component. The training data was engineered to be bias-free and generated numerically. High prediction accuracy with root mean square percentage error of mean size down to 1.2% was achieved, spanning the entire prediction range from 1 nm up to 150 nm in radius, suggesting the possible extension limits of the effective medium theory used for simulating the spectra. The DNN-predicted nanoparticle concentrations also were very close to the ones expected based on synthesis precursor contents as well as measured by atomic absorption spectroscopy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10891v2</guid>
      <category>physics.comp-ph</category>
      <category>cond-mat.dis-nn</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tomas Klinavi\v{c}ius (- Institute of Materials Science of Kaunas University of Technology), Nadzeya Khinevich (- Institute of Materials Science of Kaunas University of Technology), Asta Tamulevi\v{c}ien\.e (- Institute of Materials Science of Kaunas University of Technology), Loic Vidal (- Institut de Science des Materiaux de Mulhouse IS2M UMR 7361), Sigitas Tamulevi\v{c}ius (- Institute of Materials Science of Kaunas University of Technology), Tomas Tamulevi\v{c}ius (- Institute of Materials Science of Kaunas University of Technology)</dc:creator>
    </item>
    <item>
      <title>KAN: Kolmogorov-Arnold Networks</title>
      <link>https://arxiv.org/abs/2404.19756</link>
      <description>arXiv:2404.19756v3 Announce Type: replace-cross 
Abstract: Inspired by the Kolmogorov-Arnold representation theorem, we propose Kolmogorov-Arnold Networks (KANs) as promising alternatives to Multi-Layer Perceptrons (MLPs). While MLPs have fixed activation functions on nodes ("neurons"), KANs have learnable activation functions on edges ("weights"). KANs have no linear weights at all -- every weight parameter is replaced by a univariate function parametrized as a spline. We show that this seemingly simple change makes KANs outperform MLPs in terms of accuracy and interpretability. For accuracy, much smaller KANs can achieve comparable or better accuracy than much larger MLPs in data fitting and PDE solving. Theoretically and empirically, KANs possess faster neural scaling laws than MLPs. For interpretability, KANs can be intuitively visualized and can easily interact with human users. Through two examples in mathematics and physics, KANs are shown to be useful collaborators helping scientists (re)discover mathematical and physical laws. In summary, KANs are promising alternatives for MLPs, opening opportunities for further improving today's deep learning models which rely heavily on MLPs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.19756v3</guid>
      <category>cs.LG</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.AI</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziming Liu, Yixuan Wang, Sachin Vaidya, Fabian Ruehle, James Halverson, Marin Solja\v{c}i\'c, Thomas Y. Hou, Max Tegmark</dc:creator>
    </item>
    <item>
      <title>Smooth Kolmogorov Arnold networks enabling structural knowledge representation</title>
      <link>https://arxiv.org/abs/2405.11318</link>
      <description>arXiv:2405.11318v2 Announce Type: replace-cross 
Abstract: Kolmogorov-Arnold Networks (KANs) offer an efficient and interpretable alternative to traditional multi-layer perceptron (MLP) architectures due to their finite network topology. However, according to the results of Kolmogorov and Vitushkin, the representation of generic smooth functions by KAN implementations using analytic functions constrained to a finite number of cutoff points cannot be exact. Hence, the convergence of KAN throughout the training process may be limited. This paper explores the relevance of smoothness in KANs, proposing that smooth, structurally informed KANs can achieve equivalence to MLPs in specific function classes. By leveraging inherent structural knowledge, KANs may reduce the data required for training and mitigate the risk of generating hallucinated predictions, thereby enhancing model reliability and performance in computational biomedicine.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11318v2</guid>
      <category>cs.LG</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.AI</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Moein E. Samadi, Younes M\"uller, Andreas Schuppert</dc:creator>
    </item>
  </channel>
</rss>
