<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.GN updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.GN</link>
    <description>q-fin.GN updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.GN" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 22 Jan 2026 03:00:42 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Autonomous Market Intelligence: Agentic AI Nowcasting Predicts Stock Returns</title>
      <link>https://arxiv.org/abs/2601.11958</link>
      <description>arXiv:2601.11958v1 Announce Type: new 
Abstract: Can fully agentic AI nowcast stock returns? We deploy a state-of-the-art Large Language Model to evaluate the attractiveness of each Russell 1000 stock daily, starting from April 2025 when AI web interfaces enabled real-time search. Our data contribution is unique along three dimensions. First, the nowcasting framework is completely out-of-sample and free of look-ahead bias by construction: predictions are collected at the current edge of time, ensuring the AI has no knowledge of future outcomes. Second, this temporal design is irreproducible -- once the information environment passes, it can never be recreated. Third, our framework is 100% agentic: we do not feed the model news, disclosures, or curated text; it autonomously searches the web, filters sources, and synthesises information into quantitative predictions. We find that AI possesses genuine stock selection ability, but only for identifying top winners. Longing the 20 highest-ranked stocks generates a daily Fama-French five-factor plus momentum alpha of 18.4 basis points and an annualised Sharpe ratio of 2.43. Critically, these returns derive from an implementable strategy trading highly liquid Russell 1000 constituents, with transaction costs representing less than 10\% of gross alpha. However, this predictability is highly concentrated: expanding beyond the top tier rapidly dilutes alpha, and bottom-ranked stocks exhibit returns statistically indistinguishable from the market. We hypothesise that this asymmetry reflects online information structure: genuinely positive news generates coherent signals, while negative news is contaminated by strategic corporate obfuscation and social media noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.11958v1</guid>
      <category>q-fin.GN</category>
      <category>q-fin.PM</category>
      <category>q-fin.TR</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zefeng Chen, Darcy Pu</dc:creator>
    </item>
    <item>
      <title>Look-Ahead-Bench: a Standardized Benchmark of Look-ahead Bias in Point-in-Time LLMs for Finance</title>
      <link>https://arxiv.org/abs/2601.13770</link>
      <description>arXiv:2601.13770v1 Announce Type: cross 
Abstract: We introduce Look-Ahead-Bench, a standardized benchmark measuring look-ahead bias in Point-in-Time (PiT) Large Language Models (LLMs) within realistic and practical financial workflows. Unlike most existing approaches that primarily test inner lookahead knowledge via Q\\&amp;A, our benchmark evaluates model behavior in practical scenarios. To distinguish genuine predictive capability from memorization-based performance, we analyze performance decay across temporally distinct market regimes, incorporating several quantitative baselines to establish performance thresholds. We evaluate prominent open-source LLMs -- Llama 3.1 (8B and 70B) and DeepSeek 3.2 -- against a family of Point-in-Time LLMs (Pitinf-Small, Pitinf-Medium, and frontier-level model Pitinf-Large) from PiT-Inference. Results reveal significant lookahead bias in standard LLMs, as measured with alpha decay, unlike Pitinf models, which demonstrate improved generalization and reasoning abilities as they scale in size. This work establishes a foundation for the standardized evaluation of temporal bias in financial LLMs and provides a practical framework for identifying models suitable for real-world deployment. Code is available on GitHub: https://github.com/benstaf/lookaheadbench</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.13770v1</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <category>q-fin.CP</category>
      <category>q-fin.GN</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mostapha Benhenda (LAGA)</dc:creator>
    </item>
    <item>
      <title>Market-Based Asset Price Probability</title>
      <link>https://arxiv.org/abs/2205.07256</link>
      <description>arXiv:2205.07256v5 Announce Type: replace-cross 
Abstract: The random values and volumes of consecutive trades made at the exchange with shares of security determine its mean, variance, and higher statistical moments. The volume weighted average price (VWAP) is the simplest example of such a dependence. We derive the dependence of the market-based variance and 3rd statistical moment of prices on the means, variances, covariances, and 3rd moments of the values and volumes of market trades. The usual frequency-based assessments of statistical moments of prices are the limited case of market-based statistical moments if we assume that all volumes of consecutive trades with security are constant during the averaging interval. To forecast market-based variance of price, one should predict the first two statistical moments and the correlation of values and volumes of consecutive trades at the same horizon. We explain how that limits the number of predicted statistical moments of prices by the first two and the accuracy of the forecasts of the price probability by the Gaussian distribution. This limitation also reduces the reliability of Value-at-Risk by Gaussian approximation. The accounting for the randomness of trade volumes and the use of VWAP results in zero price-volume correlations. To study the price-volume empirical statistical dependence, one should calculate correlations of prices and squares of trade volumes or correlations of squares of prices and volumes. To improve the accuracy and reliability of large macroeconomic and market models like those developed by BlackRock's Aladdin, JP Morgan, and the U.S. Fed., the developers should explicitly account for the impact of random trade volumes and use market-based statistical moments of asset prices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.07256v5</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <category>q-fin.GN</category>
      <category>q-fin.PR</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Victor Olkhov</dc:creator>
    </item>
  </channel>
</rss>
