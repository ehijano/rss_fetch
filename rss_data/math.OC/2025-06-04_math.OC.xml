<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 05 Jun 2025 01:38:49 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>An Overview of GPU-based First-Order Methods for Linear Programming and Extensions</title>
      <link>https://arxiv.org/abs/2506.02174</link>
      <description>arXiv:2506.02174v1 Announce Type: new 
Abstract: The rapid progress in GPU computing has revolutionized many fields, yet its potential in mathematical programming, such as linear programming (LP), has only recently begun to be realized. This survey aims to provide a comprehensive overview of recent advancements in GPU-based first-order methods for LP, with a particular focus on the design and development of cuPDLP. We begin by presenting the design principles and algorithmic foundation of the primal-dual hybrid gradient (PDHG) method, which forms the core of the solver. Practical enhancements, such as adaptive restarts, preconditioning, Halpern-type acceleration and infeasibility detection, are discussed in detail, along with empirical comparisons against industrial-grade solvers, highlighting the scalability and efficiency of cuPDLP. We also provide a unified theoretical framework for understanding PDHG, covering both classical and recent results on sublinear and linear convergence under sharpness conditions. Finally, we extend the discussion to GPU-based optimization beyond LP, including quadratic, semidefinite, conic, and nonlinear programming.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02174v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haihao Lu, Jinwen Yang</dc:creator>
    </item>
    <item>
      <title>Human-in-the-loop: Real-time Preference Optimization</title>
      <link>https://arxiv.org/abs/2506.02225</link>
      <description>arXiv:2506.02225v1 Announce Type: new 
Abstract: Human-aware controllers play an important role in engineering systems for improving productivity, efficiency, and sustainability. It is essential to design such a controller that optimizes user utility while adhering to plant dynamics. While most online optimization algorithms rely on first-order or zeroth-order oracles, human feedback often appears as pairwise comparisons. In this work, we propose an online feedback optimization algorithm that leverages such preference feedback. We design a controller that estimates the gradient based on the binary pairwise comparison result between two consecutive points and study its coupled behavior with a nonlinear plant. Under mild assumptions on both the utility and the plant dynamics, we establish explicit stability criteria and quantify sub-optimality. The theoretical findings are further supported through numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02225v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenbin Wang, Wenjie Xu, Colin N. Jones</dc:creator>
    </item>
    <item>
      <title>Lie algebra rank condition for bilinear control systems on $\mathbb{R}^2$</title>
      <link>https://arxiv.org/abs/2506.02428</link>
      <description>arXiv:2506.02428v1 Announce Type: new 
Abstract: We will study the controllability problem of a bilinear control system on $\mathbb{R}^2:$ the main result is the characterization of the Lie algebra rank condition for the system. On the other hand, using elementary techniques, we recover conditions for the controllability of the induced angular system on the projective space. Finally, we will give controllability criteria for the system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02428v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Efrain Cruz-Mullisaca, Victor H. Patty-Yujra</dc:creator>
    </item>
    <item>
      <title>Mirror descent for constrained stochastic control problems</title>
      <link>https://arxiv.org/abs/2506.02564</link>
      <description>arXiv:2506.02564v1 Announce Type: new 
Abstract: Mirror descent is a well established tool for solving convex optimization problems with convex constraints. This article introduces continuous-time mirror descent dynamics for approximating optimal Markov controls for stochastic control problems with the action space being bounded and convex. We show that if the Hamiltonian is uniformly convex in its action variable then mirror descent converges linearly while if it is uniformly strongly convex relative to an appropriate Bregman divergence, then the mirror flow converges exponentially. The two fundamental difficulties that must be overcome to prove such results are: first, the inherent lack of convexity of the map from Markov controls to the corresponding value function. Second, maintaining sufficient regularity of the value function and the Markov controls along the mirror descent updates. The first issue is handled using the performance difference lemma, while the second using careful Sobolev space estimates for the solutions of the associated linear PDEs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02564v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Deven Sethi, David \v{S}i\v{s}ka</dc:creator>
    </item>
    <item>
      <title>Learning-based primal-dual optimal control of discrete-time stochastic systems with multiplicative noise</title>
      <link>https://arxiv.org/abs/2506.02613</link>
      <description>arXiv:2506.02613v1 Announce Type: new 
Abstract: Reinforcement learning (RL) is an effective approach for solving optimal control problems without knowing the exact information of the system model. However, the classical Q-learning method, a model-free RL algorithm, has its limitations, such as lack of strict theoretical analysis and the need for artificial disturbances during implementation. This paper explores the partially model-free stochastic linear quadratic regulator (SLQR) problem for a system with multiplicative noise from the primal-dual perspective to address these challenges. This approach lays a strong theoretical foundation for understanding the intrinsic mechanisms of classical RL algorithms. We reformulate the SLQR into a non-convex primal-dual optimization problem and derive a strong duality result, which enables us to provide model-based and model-free algorithms for SLQR optimal policy design based on the Karush-Kuhn-Tucker (KKT) conditions. An illustrative example demonstrates the proposed model-free algorithm's validity, showcasing the central nervous system's learning mechanism in human arm movement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02613v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiushan Jiang, Weihai Zhang</dc:creator>
    </item>
    <item>
      <title>Efficient Quadratic Corrections for Frank-Wolfe Algorithms</title>
      <link>https://arxiv.org/abs/2506.02635</link>
      <description>arXiv:2506.02635v2 Announce Type: new 
Abstract: We develop a Frank-Wolfe algorithm with corrective steps, generalizing previous algorithms including blended pairwise conditional gradients and fully-corrective Frank-Wolfe, and propose a highly efficient corrective algorithm in the case of convex quadratic objectives based on linear optimization or linear system solving, akin to Wolfe's minimum-norm point. Beyond optimization problems that are directly quadratic, we revisit two algorithms, split conditional gradient for the intersection of two sets accessible through linear oracles, and second-order conditional gradient sliding, which approximately solves Variable-Metric projection subproblems, proposing improvement of the algorithms and their guarantees that may be of interest beyond our work, and we leverage quadratic corrections to accelerate the quadratic subproblems they solve. We show significant computational acceleration of Frank-Wolfe-based algorithms equipped with the quadratic correction on the considered problem classes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02635v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jannis Halbey, Seta Rakotomandimby, Mathieu Besan\c{c}on, S\'ebastien Designolle, Sebastian Pokutta</dc:creator>
    </item>
    <item>
      <title>Non-exchangeable evolutionary and mean field games and their applications</title>
      <link>https://arxiv.org/abs/2506.02644</link>
      <description>arXiv:2506.02644v2 Announce Type: new 
Abstract: A replicator dynamic for non-exchangeable agents in a continuous action space is formulated and its well-posedness is proven in a space of probability measures. The non-exchangeability allows for the analysis of evolutionary games involving agents with distinct (and possibly infinitely many) types. We also explicitly connect this replicator dynamic to a stationary mean field game, which determines the pairwise actions of the heterogeneous agents. Moreover, as a byproduct of our theoretical results, we show that a class of nonlinear voter models, recently the subject of increasing interest, called q-voter models, can be viewed as a replicator dynamic driven by a utility that is a power of the probability density. This implies that non-exchangeable and/or mean-field game formulations of these models can also be constructed. We also present computational examples of evolutionary and mean field game models using a finite difference method, focusing on tragedy of the commons and the q-voter model with non-exchangeable agents, of which are interesting cases from theoretical and computational perspectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02644v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>H. Yoshioka, M. Tsujimura, T. Tanaka</dc:creator>
    </item>
    <item>
      <title>Multilevel Stochastic Gradient Descent for Optimal Control Under Uncertainty</title>
      <link>https://arxiv.org/abs/2506.02647</link>
      <description>arXiv:2506.02647v1 Announce Type: new 
Abstract: We present a multilevel stochastic gradient descent method for the optimal control of systems governed by partial differential equations under uncertain input data. The gradient descent method used to find the optimal control leverages a parallel multilevel Monte Carlo method as stochastic gradient estimator. As a result, we achieve precise control over the stochastic gradient's bias, introduced by numerical approximation, and its sampling error, arising from the use of incomplete gradients, while optimally managing computational resources. We show that the method exhibits linear convergence in the number of optimization steps while avoiding the cost of computing the full gradient at the highest fidelity. Numerical experiments demonstrate that the method significantly outperforms the standard (mini-) batched stochastic gradient descent method in terms of convergence speed and accuracy. The method is particularly well-suited for high-dimensional control problems, taking advantage of parallel computing resources and a distributed multilevel data structure. Additionally, we evaluate and implement different step size strategies, optimizer schemes, and budgeting techniques. The method's performance is studied using a two-dimensional elliptic subsurface diffusion problem with log-normal coefficients and Mat\'ern covariance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02647v1</guid>
      <category>math.OC</category>
      <category>cs.MS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Niklas Baumgarten, David Schneiderhan</dc:creator>
    </item>
    <item>
      <title>BenLOC: A Benchmark for Learning to Configure MIP Optimizers</title>
      <link>https://arxiv.org/abs/2506.02752</link>
      <description>arXiv:2506.02752v1 Announce Type: new 
Abstract: The automatic configuration of Mixed-Integer Programming (MIP) optimizers has become increasingly critical as the large number of configurations can significantly affect solver performance. Yet the lack of standardized evaluation frameworks has led to data leakage and over-optimistic claims, as prior studies often rely on homogeneous datasets and inconsistent experimental setups. To promote a fair evaluation process, we present BenLOC, a comprehensive benchmark and open-source toolkit, which not only offers an end-to-end pipeline for learning instance-wise MIP optimizer configurations, but also standardizes dataset selection, train-test splits, feature engineering and baseline choice for unbiased and comprehensive evaluations. Leveraging this framework, we conduct an empirical analysis on five well-established MIP datasets and compare classical machine learning models with handcrafted features against state-of-the-art deep-learning techniques. The results demonstrate the importance of datasets, features and baseline criteria proposed by BenLOC and the effectiveness of BenLOC in providing unbiased and comprehensive evaluations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02752v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hongpei Li, Ziyan He, Yufei Wang, Wenting Tu, Shanwen Pu, Qi Deng, Dongdong Ge</dc:creator>
    </item>
    <item>
      <title>A Hierarchical Integer Linear Programming Approach for Optimizing Team Formation in Education</title>
      <link>https://arxiv.org/abs/2506.02756</link>
      <description>arXiv:2506.02756v1 Announce Type: new 
Abstract: Teamwork is integral to higher education, fostering students' interpersonal skills, improving learning outcomes, and preparing them for professional collaboration later in their careers. While team formation has traditionally been managed by humans, either instructors or students, algorithmic approaches have recently emerged to optimize this process. However, existing algorithmic team formation methods often focus on expert teams, overlook agency in choosing one's teammates, and are limited to a single team formation setting. These limitations make them less suitable for education, where no student can be left out, student agency is crucial for motivation, and team formation needs vary across courses and programs. In this paper, we introduce the EDUCATIONAL TEAM FORMATION problem (EDU-TF), a partitioning optimization problem model tailored to the unique needs of education, integrating both teacher and student requirements. To solve EDU-TF, we propose a modular optimization approach, one of the first to allow the flexible adjustment of objectives according to educational needs, enhancing the method's applicability across various classroom settings rather than just research environments. Results from evaluating ten strategies derived from our model on real-world university datasets indicate that our approach outperforms heuristic teacher-assigned teams by better accommodating student preferences. Our study contributes a new modular approach to partition-based algorithmic team formation and provides valuable insights for future research on team formation in educational settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02756v1</guid>
      <category>math.OC</category>
      <category>cs.CY</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Aaron Kessler, Tim Scheiber, Heinz Schmitz, Ioanna Lykourentzou</dc:creator>
    </item>
    <item>
      <title>Optimization of Robotic Liquid Handling as a Capacitated Vehicle Routing Problem</title>
      <link>https://arxiv.org/abs/2506.02795</link>
      <description>arXiv:2506.02795v1 Announce Type: new 
Abstract: We present an optimization strategy to reduce the execution time of liquid handling operations in the context of an automated chemical laboratory. By formulating the task as a capacitated vehicle routing problem (CVRP), we leverage heuristic solvers traditionally used in logistics and transportation planning to optimize task execution times. As exemplified using an 8-channel pipette with individually controllable tips, our approach demonstrates robust optimization performance across different labware formats (e.g., well-plates, vial holders), achieving up to a 37% reduction in execution time for randomly generated tasks compared to the baseline sorting method. We further apply the method to a real-world high-throughput materials discovery campaign and observe that 3 minutes of optimization time led to a reduction of 61 minutes in execution time compared to the best-performing sorting-based strategy. Our results highlight the potential for substantial improvements in throughput and efficiency in automated laboratories without any hardware modifications. This optimization strategy offers a practical and scalable solution to accelerate combinatorial experimentation in areas such as drug combination screening, reaction condition optimization, materials development, and formulation engineering.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02795v1</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guangqi Wu, Runzhong Wang, Connor W. Coley</dc:creator>
    </item>
    <item>
      <title>Optimal control of the Poisson equation with transport regularization: Properties of optimal transport plans and transport map</title>
      <link>https://arxiv.org/abs/2506.02808</link>
      <description>arXiv:2506.02808v1 Announce Type: new 
Abstract: An optimal control problem in the space of Borel measures governed by the Poisson equation is investigated. The characteristic feature of the problem under consideration is the Tikhonov regularization term in form of the transportation distance of the control to a given prior. Existence of optimal solutions is shown and first-order necessary optimality conditions are derived. The latter are used to deduce structural a priori information about the optimal control and its support based on properties of the associated optimal transport plan.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02808v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christian Meyer, Gerd Wachsmuth</dc:creator>
    </item>
    <item>
      <title>Optimal BESS Scheduling for Multi-Market Participation in the Nordics</title>
      <link>https://arxiv.org/abs/2506.02837</link>
      <description>arXiv:2506.02837v1 Announce Type: new 
Abstract: Battery energy storage systems BESSs can provide fast frequency reserves and energy arbitrage in Nordic electricity markets but their limited energy capacity requires accurate revenue forecasts and coordinated bidding across multiple submarkets. This paper introduces a unified framework that employs generalized additive models GAMs to generate one week ahead forecasts of spot and FCRN revenues in Denmark, Finland, and Norway using three years of hourly price and volume data. Forecast outputs feed a stochastic mixed integer optimizer that co-optimizes BESS participation in FCRN, FCRD, spot markets, subject to state of charge constraints, inverter losses, and differing pay as bid and pay as clear rules. Comparative analyses evaluate forecast accuracy and quantify the impact of forecast errors on BESS bid acceptance, market selection, and profitability under realistic seasonal price patterns. Results demonstrate that spot markets exhibit consistently higher predictability than frequency markets, and that forecast errors modestly affect bid acceptance but do not alter overall market participation. The proposed approach provides BESS operators and investors with a tool to assess revenue uncertainty and optimize multi market strategies in Nordic power systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02837v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zeenat Hameed, Chresten Traeholt</dc:creator>
    </item>
    <item>
      <title>Distributed Retraction-Free and Communication-Efficient Optimization on the Stiefel Manifold</title>
      <link>https://arxiv.org/abs/2506.02879</link>
      <description>arXiv:2506.02879v1 Announce Type: new 
Abstract: Optimization problems on the Stiefel manifold, ranging from principal component analysis to enhancing neural network robustness, are ubiquitous in machine learning. The Landing algorithm avoids computationally expensive retraction operations on manifolds, making it highly competitive for large-scale problems. This paper extends this method to distributed settings, introducing *EF-Landing*, the first retraction-free and communication-efficient algorithm for distributed stochastic optimization on the Stiefel manifold. By incorporating communication compression and error feedback, EF-Landing ensures convergence and constraint feasibility while significantly reducing communication overhead. We provide sharp convergence guarantees, demonstrating that EF-Landing achieves the same asymptotic linear speedup convergence rate as existing methods without communication compression. Furthermore, our analysis is highly versatile, applying to both deterministic and stochastic settings and encompassing algorithms based on gradient descent or momentum-based gradient descent. We also generalize EF-Landing to operate on block-wise Stiefel manifolds, enabling greater flexibility for structured constraints. Extensive numerical experiments validate our theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02879v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yilong Song, Peijin Li, Bin Gao, Kun Yuan</dc:creator>
    </item>
    <item>
      <title>Random-key genetic algorithms: Principles and applications</title>
      <link>https://arxiv.org/abs/2506.02120</link>
      <description>arXiv:2506.02120v2 Announce Type: cross 
Abstract: A random-key genetic algorithm is an evolutionary metaheuristic for discrete and global optimization. Each solution is encoded as a vector of N random keys, where a random key is a real number randomly generated in the continuous interval [0, 1). A decoder maps each vector of random keys to a solution of the optimization problem being solved and computes its cost. The benefit of this approach is that all genetic operators and transformations can be maintained within the unitary hypercube, regardless of the problem being addressed. This enhances the productivity and maintainability of the core framework. The algorithm starts with a population of P vectors of random keys. At each iteration, the vectors are partitioned into two sets: a smaller set of high-valued elite solutions and the remaining non-elite solutions. All elite elements are copied, without change, to the next population. A small number of random-key vectors (the mutants) is added to the population of the next iteration. The remaining elements of the population of the next iteration are generated by combining, with the parametrized uniform crossover of Spears and DeJong (1991), pairs of solutions. This chapter reviews random-key genetic algorithms and describes an effective variant called biased random-key genetic algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02120v2</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mariana A. Londe, Luciana S. Pessoa, Carlos E. Andrade, Jos\'e F. Gon\c{c}alves, Mauricio G. C. Resende</dc:creator>
    </item>
    <item>
      <title>Constrained Sliced Wasserstein Embedding</title>
      <link>https://arxiv.org/abs/2506.02203</link>
      <description>arXiv:2506.02203v1 Announce Type: cross 
Abstract: Sliced Wasserstein (SW) distances offer an efficient method for comparing high-dimensional probability measures by projecting them onto multiple 1-dimensional probability distributions. However, identifying informative slicing directions has proven challenging, often necessitating a large number of slices to achieve desirable performance and thereby increasing computational complexity. We introduce a constrained learning approach to optimize the slicing directions for SW distances. Specifically, we constrain the 1D transport plans to approximate the optimal plan in the original space, ensuring meaningful slicing directions. By leveraging continuous relaxations of these transport plans, we enable a gradient-based primal-dual approach to train the slicer parameters, alongside the remaining model parameters. We demonstrate how this constrained slicing approach can be applied to pool high-dimensional embeddings into fixed-length permutation-invariant representations. Numerical results on foundation models trained on images, point clouds, and protein sequences showcase the efficacy of the proposed constrained learning approach in learning more informative slicing directions. Our implementation code can be found at https://github.com/Stranja572/constrainedswe.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02203v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>q-bio.QM</category>
      <category>stat.ML</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Navid NaderiAlizadeh, Darian Salehi, Xinran Liu, Soheil Kolouri</dc:creator>
    </item>
    <item>
      <title>Second-order AAA algorithms for structured data-driven modeling</title>
      <link>https://arxiv.org/abs/2506.02241</link>
      <description>arXiv:2506.02241v1 Announce Type: cross 
Abstract: The data-driven modeling of dynamical systems has become an essential tool for the construction of accurate computational models from real-world data. In this process, the inherent differential structures underlying the considered physical phenomena are often neglected making the reinterpretation of the learned models in a physically meaningful sense very challenging. In this work, we present three data-driven modeling approaches for the construction of dynamical systems with second-order differential structure directly from frequency domain data. Based on the second-order structured barycentric form, we extend the well-known Adaptive Antoulas-Anderson algorithm to the case of second-order systems. Depending on the available computational resources, we propose variations of the proposed method that prioritize either higher computation speed or greater modeling accuracy, and we present a theoretical analysis for the expected accuracy and performance of the proposed methods. Three numerical examples demonstrate the effectiveness of our new structured approaches in comparison to classical unstructured data-driven modeling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02241v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael S. Ackermann, Ion Victor Gosea, Serkan Gugercin, Steffen W. R. Werner</dc:creator>
    </item>
    <item>
      <title>Branch-and-Cut for Mixed-Integer Generalized Nash Equilibrium Problems</title>
      <link>https://arxiv.org/abs/2506.02520</link>
      <description>arXiv:2506.02520v1 Announce Type: cross 
Abstract: Generalized Nash equilibrium problems with mixed-integer variables form an important class of games in which each player solves a mixed-integer optimization problem with respect to her own variables and the strategy space of each player depends on the strategies chosen by the rival players. In this work, we introduce a branch-and-cut algorithm to compute exact pure Nash equilibria for different classes of such mixed-integer games. The main idea is to reformulate the equilibrium problem as a suitable bilevel problem based on the Nikaido--Isoda function of the game. The proposed branch-and-cut method is applicable to generalized Nash equilibrium problems under quite mild assumptions. Depending on the specific setting, we use tailored equilibrium or intersection cuts. The latter are well-known in mixed-integer linear optimization and we adapt them to the game setting. We prove finite termination and correctness of the algorithm and present some first numerical results for two different types of knapsack games and another game based on capacitated flow problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02520v1</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alo\"is Duguet, Tobias Harks, Martin Schmidt, Julian Schwarz</dc:creator>
    </item>
    <item>
      <title>WeightLoRA: Keep Only Necessary Adapters</title>
      <link>https://arxiv.org/abs/2506.02724</link>
      <description>arXiv:2506.02724v1 Announce Type: cross 
Abstract: The widespread utilization of language models in modern applications is inconceivable without Parameter-Efficient Fine-Tuning techniques, such as low-rank adaptation ($\texttt{LoRA}$), which adds trainable adapters to selected layers. Although $\texttt{LoRA}$ may obtain accurate solutions, it requires significant memory to train large models and intuition on which layers to add adapters. In this paper, we propose a novel method, $\texttt{WeightLoRA}$, which overcomes this issue by adaptive selection of the most critical $\texttt{LoRA}$ heads throughout the optimization process. As a result, we can significantly reduce the number of trainable parameters while maintaining the capability to obtain consistent or even superior metric values. We conduct experiments for a series of competitive benchmarks and DeBERTa, BART, and Llama models, comparing our method with different adaptive approaches. The experimental results demonstrate the efficacy of $\texttt{WeightLoRA}$ and the superior performance of $\texttt{WeightLoRA+}$ in almost all cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02724v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrey Veprikov, Vladimir Solodkin, Alexander Zyl, Andrey Savchenko, Aleksandr Beznosikov</dc:creator>
    </item>
    <item>
      <title>Solving the Pod Repositioning Problem with Deep Reinforced Adaptive Large Neighborhood Search</title>
      <link>https://arxiv.org/abs/2506.02746</link>
      <description>arXiv:2506.02746v1 Announce Type: cross 
Abstract: The Pod Repositioning Problem (PRP) in Robotic Mobile Fulfillment Systems (RMFS) involves selecting optimal storage locations for pods returning from pick stations. This work presents an improved solution method that integrates Adaptive Large Neighborhood Search (ALNS) with Deep Reinforcement Learning (DRL). A DRL agent dynamically selects destroy and repair operators and adjusts key parameters such as destruction degree and acceptance thresholds during the search. Specialized heuristics for both operators are designed to reflect PRP-specific characteristics, including pod usage frequency and movement costs. Computational results show that this DRL-guided ALNS outperforms traditional approaches such as cheapest-place, fixed-place, binary integer programming, and static heuristics. The method demonstrates strong solution quality and illustrating the benefit of learning-driven control within combinatorial optimization for warehouse systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02746v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lin Xie, Hanyi Li</dc:creator>
    </item>
    <item>
      <title>Eigenvalue bounds for preconditioned symmetric multiple saddle-point matrices</title>
      <link>https://arxiv.org/abs/2506.02816</link>
      <description>arXiv:2506.02816v1 Announce Type: cross 
Abstract: We develop eigenvalue bounds for symmetric, block tridiagonal multiple saddle-point linear systems, preconditioned with block diagonal matrices. We extend known results for $3 \times 3$ block systems [Bradley and Greif, IMA J.\ Numer. Anal. 43 (2023)] and for $4 \times 4$ systems [Pearson and Potschka, IMA J. Numer. Anal. 44 (2024)] to an arbitrary number of blocks. Moreover, our results generalize the bounds in [Sogn and Zulehner, IMA J. Numer. Anal. 39 (2018)], developed for an arbitrary number of blocks with null diagonal blocks. Extension to the bounds when the Schur complements are approximated is also provided, using perturbation arguments. Practical bounds are also obtained for the double saddle-point linear system. Numerical experiments validate our findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02816v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>L. Bergamaschi, A. Martinez, J. W. Pearson, A. Potschka</dc:creator>
    </item>
    <item>
      <title>On dual-rate consensus under transmission delays</title>
      <link>https://arxiv.org/abs/2506.02840</link>
      <description>arXiv:2506.02840v1 Announce Type: cross 
Abstract: In this paper, we investigate the problem of dual-rate consensus under transmission delays, where the control updates happen at a faster rate than the measurements being received. We assume that the measurements are delayed by a fixed delay and show that for all delays and rates, the system reaches a consensus if and only if the communication graph of the agents is connected and the control gain is chosen in a specific interval. Based on these results we dive deeper into the convergence properties and investigate how the convergence changes when we change the rate for sending measurements. We observe that in certain cases there exists a sweet spot for choosing the sampling rate of the measurements, which can improve the convergence to the consensus point. We then formulate an optimization problem to find a sampling rate to improve the convergence speed and provide a necessary and sufficient condition for the existence of a finite optimizer of this problem. Our results are verified with numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02840v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Umsonst, Mina Ferizbegovic</dc:creator>
    </item>
    <item>
      <title>Backpressure-based Mean-field Type Game for Scheduling in Multi-Hop Wireless Sensor Networks</title>
      <link>https://arxiv.org/abs/2506.03059</link>
      <description>arXiv:2506.03059v1 Announce Type: cross 
Abstract: We propose a Mean-Field Type Game (MFTG) framework for effective scheduling in multi-hop wireless sensor networks (WSNs) using backpressure as a performance criterion. Traditional backpressure algorithms leverage queue differentials to regulate data flow and maintain network stability. In this work, we extend the backpressure framework by incorporating a mean-field term into the cost functional, capturing the global behavior of the system alongside local dynamics. The resulting model utilizes the strengths of non-cooperative mean-field type games, enabling nodes to make decentralized decisions based on both individual queue states and system mean-field effects while accounting for stochastic network interactions. By leveraging the interplay between backpressure dynamics and mean-field coupling, the approach balances local optimization with global efficiency. Numerical simulations demonstrate the efficacy of the proposed method in handling congestion and scheduling in large-scale WSNs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03059v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Salah Eddine Choutri, Boualem Djehiche, Prajwal Chauhan, Saif Eddin Jabari</dc:creator>
    </item>
    <item>
      <title>Higher Order Rigidity and Energy</title>
      <link>https://arxiv.org/abs/2506.03108</link>
      <description>arXiv:2506.03108v1 Announce Type: cross 
Abstract: In this paper, we revisit the notion of higher-order rigidity of a bar-and-joint framework. In particular, we provide a link between the rigidity properties of a framework, and the growth order of an energy function defined on that framework. Using our approach, we propose a general definition for the rigidity order of a framework, and we show that this definition does not depend on the details of the chosen energy function. Then we show how this order can be studied using higher order derivative tests. Doing so, we obtain a new proof that the lack of a second order flex implies rigidity. Our proof relies on our construction of a fourth derivative test, which may be applied to a critical point when the second derivative test fails. We also obtain a new proof that when the dimension of non-trivial first-order flexes equals $1$, then the lack of a $k$th order flex for some $k$ implies a framework is rigid. The higher order derivative tests that we study here may have applications beyond rigidity theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03108v1</guid>
      <category>math.MG</category>
      <category>math.OC</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Steven J. Gortler, Miranda Holmes-Cerfon, Louis Theran</dc:creator>
    </item>
    <item>
      <title>PoLAR: Polar-Decomposed Low-Rank Adapter Representation</title>
      <link>https://arxiv.org/abs/2506.03133</link>
      <description>arXiv:2506.03133v1 Announce Type: cross 
Abstract: We show that low-rank adaptation of large-scale models suffers from a low stable rank that is well below the linear algebraic rank of the subspace, degrading fine-tuning performance. To mitigate the underutilization of the allocated subspace, we propose PoLAR, a parameterization inspired by the polar decomposition that factorizes the low-rank update into two direction matrices constrained to Stiefel manifolds and an unconstrained scale matrix. Our theory shows that PoLAR yields an exponentially faster convergence rate on a canonical low-rank adaptation problem. Pairing the parameterization with Riemannian optimization leads to consistent gains on three different benchmarks testing general language understanding, commonsense reasoning, and mathematical problem solving with base model sizes ranging from 350M to 27B.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03133v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kai Lion, Liang Zhang, Bingcong Li, Niao He</dc:creator>
    </item>
    <item>
      <title>Complexity of Geometric programming in the Turing model and application to nonnegative tensors</title>
      <link>https://arxiv.org/abs/2301.10637</link>
      <description>arXiv:2301.10637v3 Announce Type: replace 
Abstract: We consider a version of geometric programming problem consisting in minimizing a function given by the maximum of finitely many log-Laplace transforms of discrete nonnegative measures on a Euclidean space. Under a coerciveness assumption, we show that an $\varepsilon$-minimizer can be computed in a time that is polynomial in the input size and in $|\log\varepsilon|$. This is obtained by establishing bit-size estimates on approximate minimizers and by applying the ellipsoid method. We also derive polynomial iteration complexity bounds for the interior-point method applied to the same class of problems. We deduce that the spectral radius of a partially symmetric, weakly irreducible nonnegative tensor can be approximated within an $\varepsilon$-error in polynomial time. For strongly irreducible tensors, we show in addition that the logarithm of the positive eigenvector is polynomial time approximable. Our results also yield that the the maximum of a nonnegative homogeneous $d$-form in the $\ell_d$ unit ball can be approximated in polynomial time. In particular, the spectral radius of uniform weighted hypergraphs and some known upper bounds for the clique number of uniform hypergraphs are polynomial time computable. In contrast, we provide an example showing that the Phase I approach needs exponentially many bits to solve the feasibility problem in geometric programming.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.10637v3</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shmuel Friedland, St\'ephane Gaubert</dc:creator>
    </item>
    <item>
      <title>Path constrained unbalanced optimal transport</title>
      <link>https://arxiv.org/abs/2402.15860</link>
      <description>arXiv:2402.15860v4 Announce Type: replace 
Abstract: Dynamical formulations of optimal transport (OT) frame the task of comparing distributions as a variational problem which searches for a path between distributions minimizing a kinetic energy functional. In applications, it is frequently natural to require paths of distributions to satisfy additional conditions. Inspired by this, we introduce a model for dynamical OT which incorporates constraints on the space of admissible paths into the framework of unbalanced OT, where the source and target measures are allowed to have a different total mass. Our main results establish, for several general families of constraints, the existence of solutions to the variational problem which defines this path constrained unbalanced optimal transport framework. These results are primarily concerned with distributions defined on a Euclidean space, but we extend them to distributions defined over parallelizable Riemannian manifolds as well. We also consider metric properties of our framework, showing that, for certain types of constraints, our model defines a metric on the relevant space of distributions. This metric is shown to arise as a geodesic distance of a Riemannian metric, obtained through an analogue of Otto's submersion in the classical OT setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.15860v4</guid>
      <category>math.OC</category>
      <category>math.DG</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martin Bauer, Nicolas Charon, Tom Needham, Mao Nishino</dc:creator>
    </item>
    <item>
      <title>Existence of Optimal Stationary Singular Controls and Mean Field Game Equilibria</title>
      <link>https://arxiv.org/abs/2404.07945</link>
      <description>arXiv:2404.07945v3 Announce Type: replace 
Abstract: In this paper, we examine the stationary relaxed singular control problem within a multi-dimensional framework for a single agent, as well as its mean field game equivalent. We demonstrate that optimal relaxed controls exist for two problem classes: one driven by queueing control and the other by harvesting models. These relaxed controls are defined by random measures across the state and control spaces, with the state process described as a solution to the associated martingale problem. By leveraging findings from [Kurtz-Stockbridge 2001], we establish the equivalence between the martingale problem and the stationary forward equation. This allows us to reformulate the relaxed control problem into a linear programming problem within the measure space. We prove the sequential compactness of these measures, thereby confirming the feasibility of achieving an optimal solution. Subsequently, our focus shifts to mean field games. Drawing on insights from the single-agent problem and employing Kakutani--Glicksberg--Fan fixed point theorem, we derive the existence of a mean field game equilibria.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07945v3</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Asaf Cohen, Chuhao Sun</dc:creator>
    </item>
    <item>
      <title>Joint Learning of Linear Dynamical Systems under Smoothness Constraints</title>
      <link>https://arxiv.org/abs/2406.01094</link>
      <description>arXiv:2406.01094v2 Announce Type: replace 
Abstract: We consider the problem of joint learning of multiple linear dynamical systems. This has received significant attention recently under different types of assumptions on the model parameters. The setting we consider involves a collection of $m$ linear systems, each of which resides on a node of a given undirected graph $G = ([m], \mathcal{E})$. We assume that the system matrices are marginally stable, and satisfy a smoothness constraint w.r.t $G$ -- akin to the quadratic variation of a signal on a graph. Given access to the states of the nodes over $T$ time points, we then propose two estimators for joint estimation of the system matrices, along with non-asymptotic error bounds on the mean-squared error (MSE). In particular, we show conditions under which the MSE converges to zero as $m$ increases, typically polynomially fast w.r.t $m$. The results hold under mild (i.e., $T \sim \log m$), or sometimes, even no assumption on $T$ (i.e. $T \geq 2$).</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01094v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hemant Tyagi</dc:creator>
    </item>
    <item>
      <title>Distributionally Robust Newsvendor on a Metric</title>
      <link>https://arxiv.org/abs/2410.12134</link>
      <description>arXiv:2410.12134v2 Announce Type: replace 
Abstract: We consider a fundamental generalization of the classical newsvendor problem where the seller needs to decide on the inventory of a product jointly for multiple locations on a metric as well as a fulfillment policy to satisfy the uncertain demand that arises sequentially over time after the inventory decisions have been made. To address the distributional ambiguity, we consider a distributionally robust setting where the decision-maker only knows the mean and variance of the demand, and the goal is to make inventory and fulfillment decisions to minimize the worst-case expected inventory and fulfillment cost. We design a near-optimal policy for the problem with theoretical guarantees on its performance. Our policy generalizes the classical solution of Scarf (1957), maintaining its simplicity and interpretability: it identifies a hierarchical set of clusters, assigns a ``virtual" underage cost to each cluster, then makes sure that each cluster holds at least the inventory suggested by Scarf's solution if the cluster behaved as a single point with ``virtual" underage cost. As demand arrives sequentially, our policy fulfills orders from nearby clusters, minimizing fulfilment costs, while balancing inventory consumption across the clusters to avoid depleting any single one. We show that the policy achieves a poly-logarithmic approximation. To the best of our knowledge, this is the first algorithm with provable performance guarantees. Furthermore, our numerical experiments show that the policy performs well in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12134v2</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ayoub Foussoul, Vineet Goyal</dc:creator>
    </item>
    <item>
      <title>Optimal investment problem in a renewal risk model with generalized Erlang distributed interarrival times</title>
      <link>https://arxiv.org/abs/2411.13111</link>
      <description>arXiv:2411.13111v2 Announce Type: replace 
Abstract: This paper explores the optimal investment problem of a renewal risk model with generalized Erlang distributed interarrival times. The phases of the Erlang interarrival time is assumed to be observable. The price of the risky asset is driven by the constant elasticity of variance model (CEV) and the insurer aims to maximize the exponential utility of the terminal wealth by asset allocation. By solving the corresponding Hamilton-Jacobi-Bellman (HJB) equation, we establish the concavity of the value function and derive an explicit expression for the optimal investment policy when the interest rate is zero. When the interest rate is nonzero, we obtain an explicit form of the optimal investment strategy, along with a semi-explicit expression of the value function, whose concavity is also rigorously proven.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13111v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Linlin Tian, Yixuan Tian, Bohan Li, Guoqing Li</dc:creator>
    </item>
    <item>
      <title>Relaxed Lagrangian Approach to First-Order Non-Convex Mean Field Type Control Problem</title>
      <link>https://arxiv.org/abs/2412.03308</link>
      <description>arXiv:2412.03308v2 Announce Type: replace 
Abstract: This paper addresses the existence of equilibria for Mean Field type Control problems of first-order with non-convex action functional. Introducing a relaxed Lagrangian approach on the Wasserstein space to handle the lack of convexity. we prove the existence of new relaxed Nash equilibria and we show that our existence result encompasses the classical Mean Field Control problem's existence result under convex data conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.03308v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cristian Mendico, Kaizhi Wang, Yuchen Xu</dc:creator>
    </item>
    <item>
      <title>Mirror Descent Methods with Weighting Scheme for Outputs for Constrained Variational Inequality Problems</title>
      <link>https://arxiv.org/abs/2501.04034</link>
      <description>arXiv:2501.04034v2 Announce Type: replace 
Abstract: This paper is devoted to the variational inequality problems. We consider two classes of problems, the first is classical constrained variational inequality and the second is the same problem with functional (inequality type) constraints. To solve these problems, we propose mirror descent-type methods with a weighting scheme for the generated points in each iteration of the algorithms. This scheme assigns smaller weights to the initial points and larger weights to the most recent points, thus it improves the convergence rate of the proposed methods. For the variational inequality problem with functional constraints, the proposed method switches between adaptive and non-adaptive steps in the dependence on the values of the functional constraints at iterations. We analyze the proposed methods for the time-varying step sizes and prove the optimal convergence rate for variational inequality problems with bounded and monotone operators. The results of numerical experiments of the proposed methods for classical constrained variational inequality problems show a significant improvement over the modified projection method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04034v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad S. Alkousa, Belal A. Alashqar, Fedor S. Stonyakin, Tarek Nabhani, Seydamet S. Ablaev</dc:creator>
    </item>
    <item>
      <title>First-ish Order Methods: Hessian-aware Scalings of Gradient Descent</title>
      <link>https://arxiv.org/abs/2502.03701</link>
      <description>arXiv:2502.03701v2 Announce Type: replace 
Abstract: Gradient descent is the primary workhorse for optimizing large-scale problems in machine learning. However, its performance is highly sensitive to the choice of the learning rate. A key limitation of gradient descent is its lack of natural scaling, which often necessitates expensive line searches or heuristic tuning to determine an appropriate step size. In this paper, we address this limitation by incorporating Hessian information to scale the gradient direction. By accounting for the curvature of the function along the gradient, our adaptive, Hessian-aware scaling method ensures a local unit step size guarantee, even in nonconvex settings. Near a local minimum that satisfies the second-order sufficient conditions, our approach achieves linear convergence with a unit step size. We show that our method converges globally under a significantly weaker version of the standard Lipschitz gradient smoothness assumption. Even when Hessian information is inexact, the local unit step size guarantee and global convergence properties remain valid under mild conditions. Finally, we validate our theoretical results empirically on a range of convex and nonconvex machine learning tasks, showcasing the effectiveness of the approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03701v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Oscar Smee, Fred Roosta, Stephen J. Wright</dc:creator>
    </item>
    <item>
      <title>Convergence of Clipped SGD on Convex $(L_0,L_1)$-Smooth Functions</title>
      <link>https://arxiv.org/abs/2502.16492</link>
      <description>arXiv:2502.16492v2 Announce Type: replace 
Abstract: We study stochastic gradient descent (SGD) with gradient clipping on convex functions under a generalized smoothness assumption called $(L_0,L_1)$-smoothness. Using gradient clipping, we establish a high probability convergence rate that matches the SGD rate in the $L$ smooth case up to polylogarithmic factors and additive terms. We also propose a variation of adaptive SGD with gradient clipping, which achieves the same guarantee. We perform empirical experiments to examine our theory and algorithmic choices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16492v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ofir Gaash, Kfir Yehuda Levy, Yair Carmon</dc:creator>
    </item>
    <item>
      <title>Learning to Specialize: Joint Gating-Expert Training for Adaptive MoEs in Decentralized Settings</title>
      <link>https://arxiv.org/abs/2306.08586</link>
      <description>arXiv:2306.08586v3 Announce Type: replace-cross 
Abstract: Mixture-of-Experts (MoEs) achieve scalability by dynamically activating subsets of their components. Yet, understanding how expertise emerges through joint training of gating mechanisms and experts remains incomplete, especially in scenarios without clear task partitions. Motivated by inference costs and data heterogeneity, we study how joint training of gating functions and experts can dynamically allocate domain-specific expertise across multiple underlying data distributions. As an outcome of our framework, we develop an instance tailored specifically to decentralized training scenarios, introducing \textit{Dynamically Decentralized Orchestration of MoEs} or \texttt{DDOME}. \texttt{DDOME} leverages heterogeneity emerging from distributional shifts across decentralized data sources to specialize experts dynamically. By integrating a pretrained common expert to inform a gating function, \texttt{DDOME} achieves personalized expert subset selection on-the-fly, facilitating just-in-time personalization. We empirically validate \texttt{DDOME} within a Federated Learning (FL) context: \texttt{DDOME} attains from 4\% up to an 24\% accuracy improvement over state-of-the-art FL baselines in image and text classification tasks, while maintaining competitive zero-shot generalization capabilities. Furthermore, we provide theoretical insights confirming that the joint gating-experts training is critical for achieving meaningful expert specialization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.08586v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yehya Farhat, Hamza ElMokhtar Shili, Fangshuo Liao, Chen Dun, Mirian Hipolito Garcia, Guoqing Zheng, Ahmed Hassan Awadallah, Robert Sim, Dimitrios Dimitriadis, Anastasios Kyrillidis</dc:creator>
    </item>
    <item>
      <title>Grace Period is All You Need: Individual Fairness without Revenue Loss in Revenue Management</title>
      <link>https://arxiv.org/abs/2402.08533</link>
      <description>arXiv:2402.08533v3 Announce Type: replace-cross 
Abstract: Imagine you and a friend purchase identical items at a store, yet only your friend received a discount. Would your friend's discount make you feel unfairly treated by the store? And would you be less willing to purchase from that store again in the future? Based on a large-scale online survey that we ran on Prolific, it turns out that the answers to the above questions are positive. Therefore, when allocating resources to different customers, sellers should consider both the total reward and individual fairness. Motivated by these findings, in this work we propose a notion of individual fairness in online revenue management and an algorithmic module (called ``Grace Period'') that can be embedded in traditional revenue management algorithms and guarantee individual fairness. Specifically, we show how to embed the Grace Period in five common revenue management algorithms including Deterministic Linear Programming with Probabilistic Assignment, Resolving Deterministic Linear Programming with Probabilistic Assignment, Static Bid Price Control, Booking Limit, and Nesting, thus covering both stochastic and adversarial customer arrival settings. Embedding the Grace Period does not incur additional regret for any of these algorithms. This finding indicates that, in an asymptotic regime, there is no tradeoff between a seller maximizing their revenue and guaranteeing that each customer feels fairly treated. The core intuition behind the Grace Period is that independent randomized decisions for each customer often lead to unfair outcomes. However, we cannot eliminate the randomness, as it plays a crucial role in maximizing profit. The Grace Period addresses this by shifting randomness away from individual decisions and applying it instead to the total number of customers receiving a particular decision. This approach preserves revenue potential while mitigating fairness issues.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.08533v3</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Patrick Jaillet, Chara Podimata, Zijie Zhou</dc:creator>
    </item>
    <item>
      <title>A Hessian-Aware Stochastic Differential Equation for Modelling SGD</title>
      <link>https://arxiv.org/abs/2405.18373</link>
      <description>arXiv:2405.18373v3 Announce Type: replace-cross 
Abstract: Continuous-time approximation of Stochastic Gradient Descent (SGD) is a crucial tool to study its escaping behaviors from stationary points. However, existing stochastic differential equation (SDE) models fail to fully capture these behaviors, even for simple quadratic objectives. Built on a novel stochastic backward error analysis framework, we derive the Hessian-Aware Stochastic Modified Equation (HA-SME), an SDE that incorporates Hessian information of the objective function into both its drift and diffusion terms. Our analysis shows that HA-SME achieves the order-best approximation error guarantee among existing SDE models in the literature, while significantly reducing the dependence on the smoothness parameter of the objective. Empirical experiments on neural network-based loss functions further validate this improvement. Further, for quadratic objectives, under mild conditions, HA-SME is proved to be the first SDE model that recovers exactly the SGD dynamics in the distributional sense. Consequently, when the local landscape near a stationary point can be approximated by quadratics, HA-SME provides a more precise characterization of the local escaping behaviors of SGD. With the enhanced approximation guarantee, we further conduct an escape time analysis using HA-SME, showcasing how it can be employed to analytically study the escaping behavior of SGD for general function classes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18373v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiang Li, Zebang Shen, Liang Zhang, Niao He</dc:creator>
    </item>
    <item>
      <title>Changing the ranking in eigenvector centrality of a weighted graph by small perturbations</title>
      <link>https://arxiv.org/abs/2501.10745</link>
      <description>arXiv:2501.10745v2 Announce Type: replace-cross 
Abstract: In this article, we consider eigenvector centrality for the nodes of a graph and study the robustness (and stability) of this popular centrality measure. For a given weighted graph ${\mathcal G}$ (both directed and undirected), we consider the associated weighted adjacency matrix $A$, which by definition is a non-negative matrix. The eigenvector centralities of the nodes of ${\mathcal G}$ are the entries of the Perron eigenvector of $A$, which is the (positive) eigenvector associated with the eigenvalue with largest modulus. They provide a ranking of the nodes according to the corresponding centralities. An indicator of the robustness of eigenvector centrality consists in looking for a nearby perturbed graph $\widetilde{\mathcal G}$, with the same structure as ${\mathcal G}$ (i.e., with the same vertices and edges), but with a weighted adjacency matrix $\widetilde A$ such that the highest $m$ entries ($m \ge 2$) of the Perron eigenvector of $\widetilde A$ coalesce, making the ranking at the highest level ambiguous. To compute a solution to this matrix nearness problem, a nested iterative algorithm is proposed that makes use of a constrained gradient system of matrix differential equations in the inner iteration and a one-dimensional optimization of the perturbation size in the outer iteration.
  The proposed algorithm produces the {\em optimal} perturbation (i.e., the one with smallest Frobenius norm) of the $A$ which causes the looked-for coalescence, which is a measure of the sensitivity of the graph. Our numerical experiments indicate that the proposed strategy outperforms more standard approaches based on algorithms for constrained optimization. The methodology is formulated in terms of graphs but applies to any nonnegative matrix, with potential applications in fields like population models, consensus dynamics, economics, etc.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10745v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Michele Benzi, Nicola Guglielmi</dc:creator>
    </item>
    <item>
      <title>Ringmaster ASGD: The First Asynchronous SGD with Optimal Time Complexity</title>
      <link>https://arxiv.org/abs/2501.16168</link>
      <description>arXiv:2501.16168v3 Announce Type: replace-cross 
Abstract: Asynchronous Stochastic Gradient Descent (Asynchronous SGD) is a cornerstone method for parallelizing learning in distributed machine learning. However, its performance suffers under arbitrarily heterogeneous computation times across workers, leading to suboptimal time complexity and inefficiency as the number of workers scales. While several Asynchronous SGD variants have been proposed, recent findings by Tyurin &amp; Richt\'arik (NeurIPS 2023) reveal that none achieve optimal time complexity, leaving a significant gap in the literature. In this paper, we propose Ringmaster ASGD, a novel Asynchronous SGD method designed to address these limitations and tame the inherent challenges of Asynchronous SGD. We establish, through rigorous theoretical analysis, that Ringmaster ASGD achieves optimal time complexity under arbitrarily heterogeneous and dynamically fluctuating worker computation times. This makes it the first Asynchronous SGD method to meet the theoretical lower bounds for time complexity in such scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16168v3</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Artavazd Maranjyan, Alexander Tyurin, Peter Richt\'arik</dc:creator>
    </item>
    <item>
      <title>Armijo Line-search Can Make (Stochastic) Gradient Descent Provably Faster</title>
      <link>https://arxiv.org/abs/2503.00229</link>
      <description>arXiv:2503.00229v2 Announce Type: replace-cross 
Abstract: Armijo line-search (Armijo-LS) is a standard method to set the step-size for gradient descent (GD). For smooth functions, Armijo-LS alleviates the need to know the global smoothness constant L and adapts to the ``local'' smoothness, enabling GD to converge faster. Existing theoretical analyses show that GD with Armijo-LS (GD-LS) can result in constant factor improvements over GD with a 1/L step-size (denoted as GD(1/L)). We strengthen these results and show that if the objective function satisfies a certain non-uniform smoothness condition, GD-LS can result in a faster convergence rate than GD(1/L). In particular, we prove that for convex objectives corresponding to logistic regression and multi-class classification, GD-LS can converge to the optimum at a linear rate, and hence improves over the sublinear convergence of GD(1/L). Furthermore, for non-convex objectives satisfying gradient domination (e.g., those corresponding to the softmax policy gradient in RL or generalized linear models with a logistic link function), GD-LS can match the fast convergence of algorithms tailored for these specific settings. Finally, we prove that under the interpolation assumption, for convex losses, stochastic GD with a stochastic line-search can match the fast convergence of GD-LS</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00229v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sharan Vaswani, Reza Babanezhad</dc:creator>
    </item>
    <item>
      <title>The Polar Express: Optimal Matrix Sign Methods and Their Application to the Muon Algorithm</title>
      <link>https://arxiv.org/abs/2505.16932</link>
      <description>arXiv:2505.16932v2 Announce Type: replace-cross 
Abstract: Computing the polar decomposition and the related matrix sign function, has been a well-studied problem in numerical analysis for decades. More recently, it has emerged as an important subroutine in deep learning, particularly within the Muon optimization framework. However, the requirements in this setting differ significantly from those of traditional numerical analysis. In deep learning, methods must be highly efficient and GPU-compatible, but high accuracy is often unnecessary. As a result, classical algorithms like Newton-Schulz (which suffers from slow initial convergence) and methods based on rational functions (which rely on QR decompositions or matrix inverses) are poorly suited to this context. In this work, we introduce Polar Express, a GPU-friendly algorithm for computing the polar decomposition. Like classical polynomial methods such as Newton-Schulz, our approach uses only matrix-matrix multiplications, making it GPU-compatible. Motivated by earlier work of Chen &amp; Chow and Nakatsukasa &amp; Freund, Polar Express adapts the polynomial update rule at each iteration by solving a minimax optimization problem, and we prove that it enjoys a strong worst-case optimality guarantee. This property ensures both rapid early convergence and fast asymptotic convergence. We also address finite-precision issues, making it stable in bfloat16 in practice. We apply Polar Express within the Muon optimization framework and show consistent improvements in validation loss on large-scale models such as GPT-2, outperforming recent alternatives across a range of learning rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.16932v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Noah Amsel, David Persson, Christopher Musco, Robert M. Gower</dc:creator>
    </item>
    <item>
      <title>MLorc: Momentum Low-rank Compression for Large Language Model Adaptation</title>
      <link>https://arxiv.org/abs/2506.01897</link>
      <description>arXiv:2506.01897v2 Announce Type: replace-cross 
Abstract: With increasing size of large language models (LLMs), full-parameter fine-tuning imposes substantial memory demands. To alleviate this, we propose a novel memory-efficient training paradigm called Momentum Low-rank compression (MLorc). By directly compressing and reconstructing momentum rather than gradients, MLorc avoids imposing a fixed-rank constraint on weight update matrices and better preserves the training dynamics of full-parameter fine-tuning, in contrast to existing low-rank approaches such as LoRA and GaLore. Empirically, MLorc consistently outperforms other memory-efficient training methods, matches or even exceeds the performance of full fine-tuning with a small rank (e.g., $r=4$), and generalizes well across different optimizers -- all while not compromising time or memory efficiency. Furthermore, we provide a theoretical guarantee for its convergence under reasonable assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01897v2</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wei Shen, Zhang Yaxiang, Minhui Huang, Mengfan Xu, Jiawei Zhang, Cong Shen</dc:creator>
    </item>
  </channel>
</rss>
