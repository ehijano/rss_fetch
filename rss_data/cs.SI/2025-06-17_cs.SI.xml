<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SI</link>
    <description>cs.SI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 17 Jun 2025 04:00:54 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Joint UAV Trajectory Planning and LEO Satellite Selection for Data Offloading in Space-Air-Ground Integrated Networks</title>
      <link>https://arxiv.org/abs/2506.12750</link>
      <description>arXiv:2506.12750v1 Announce Type: new 
Abstract: With the development of low earth orbit (LEO) satellites and unmanned aerial vehicles (UAVs), the space-air-ground integrated network (SAGIN) becomes a major trend in the next-generation networks. However, due to the instability of heterogeneous communication and time-varying characteristics of SAGIN, it is challenging to meet the remote Internet of Things (IoT) demands for data collection and offloading. In this paper, we investigate a two-phase hierarchical data uplink model in SAGIN. Specifically, UAVs optimize trajectories to enable efficient data collection from IoT devices, and then they transmit the data to LEO satellites with computing capabilities for further processing. The problem is formulated to minimize the total energy consumption for IoT devices, UAVs, and LEO satellites. Since the problem is in the form of mixed-integer nonlinear programming and intractable to solve directly, we decompose it into two phases. In the IoT-UAV phase, we design the algorithm to jointly optimize the IoT pairing, power allocation, and UAVs trajectories. Considering the high dynamic characteristics of LEO satellites, a real-time LEO satellite selection mechanism joint with the Satellite Tool Kit is proposed in the UAV-LEO phase. Finally, simulation results show the effectiveness of the proposed algorithms, with about 10% less energy consumption compared with the benchmark algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.12750v1</guid>
      <category>cs.SI</category>
      <pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Boran Wang, Ziye Jia, Can Cui, Qihui Wu</dc:creator>
    </item>
    <item>
      <title>Governments Should Mandate Tiered Anonymity on Social-Media Platforms to Counter Deepfakes and LLM-Driven Mass Misinformation</title>
      <link>https://arxiv.org/abs/2506.12814</link>
      <description>arXiv:2506.12814v1 Announce Type: new 
Abstract: This position paper argues that governments should mandate a three-tier anonymity framework on social-media platforms as a reactionary measure prompted by the ease-of-production of deepfakes and large-language-model-driven misinformation. The tiers are determined by a given user's $\textit{reach score}$: Tier 1 permits full pseudonymity for smaller accounts, preserving everyday privacy; Tier 2 requires private legal-identity linkage for accounts with some influence, reinstating real-world accountability at moderate reach; Tier 3 would require per-post, independent, ML-assisted fact-checking, review for accounts that would traditionally be classed as sources-of-mass-information.
  An analysis of Reddit shows volunteer moderators converge on comparable gates as audience size increases -- karma thresholds, approval queues, and identity proofs -- demonstrating operational feasibility and social legitimacy. Acknowledging that existing engagement incentives deter voluntary adoption, we outline a regulatory pathway that adapts existing US jurisprudence and recent EU-UK safety statutes to embed reach-proportional identity checks into existing platform tooling, thereby curbing large-scale misinformation while preserving everyday privacy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.12814v1</guid>
      <category>cs.SI</category>
      <category>cs.CY</category>
      <pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David Khachaturov, Roxanne Schnyder, Robert Mullins</dc:creator>
    </item>
    <item>
      <title>Uncovering Social Network Activity Using Joint User and Topic Interaction</title>
      <link>https://arxiv.org/abs/2506.12842</link>
      <description>arXiv:2506.12842v1 Announce Type: new 
Abstract: The emergence of online social platforms, such as social networks and social media, has drastically affected the way people apprehend the information flows to which they are exposed. In such platforms, various information cascades spreading among users is the main force creating complex dynamics of opinion formation, each user being characterized by their own behavior adoption mechanism. Moreover, the spread of multiple pieces of information or beliefs in a networked population is rarely uncorrelated. In this paper, we introduce the Mixture of Interacting Cascades (MIC), a model of marked multidimensional Hawkes processes with the capacity to model jointly non-trivial interaction between cascades and users. We emphasize on the interplay between information cascades and user activity, and use a mixture of temporal point processes to build a coupled user/cascade point process model. Experiments on synthetic and real data highlight the benefits of this approach and demonstrate that MIC achieves superior performance to existing methods in modeling the spread of information cascades. Finally, we demonstrate how MIC can provide, through its learned parameters, insightful bi-layered visualizations of real social network activity data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.12842v1</guid>
      <category>cs.SI</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gaspard Abel, Argyris Kalogeratos, Jean-Pierre Nadal, Julien Randon-Furling</dc:creator>
    </item>
    <item>
      <title>Discovering Coordinated Processes From Social Online Networks</title>
      <link>https://arxiv.org/abs/2506.12988</link>
      <description>arXiv:2506.12988v1 Announce Type: new 
Abstract: The rapid growth of social media presents a unique opportunity to study coordinated agent behavior in an unfiltered environment. Online processes often exhibit complex structures that reflect the nature of the user behavior, whether it is authentic and genuine, or part of a coordinated effort by malicious agents to spread misinformation and disinformation. Detection of AI-generated content can be extremely challenging due to the high quality of large language model-generated text. Therefore, approaches that use metadata like post timings are required to effectively detect coordinated AI-driven campaigns. Existing work that models the spread of information online is limited in its ability to represent different control flows that occur within the network in practice. Process mining offers techniques for the discovery of process models with different routing constructs and are yet to be applied to social networks. We propose to leverage process mining methods for the discovery of AI and human agent behavior within social networks. Applying process mining techniques to real-world Twitter (now X) event data, we demonstrate how the structural and behavioral properties of discovered process models can reveal coordinated AI and human behaviors online.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.12988v1</guid>
      <category>cs.SI</category>
      <pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Anna Kalenkova, Lewis Mitchell, Ethan Johnson</dc:creator>
    </item>
    <item>
      <title>Dynamic Evolution of Cooperation Based on Adaptive Reputation Threshold and Game Transition</title>
      <link>https://arxiv.org/abs/2506.13319</link>
      <description>arXiv:2506.13319v1 Announce Type: new 
Abstract: In real-world social systems, individual interactions are frequently shaped by reputation, which not only influences partner selection but also affects the nature and benefits of the interactions themselves. We propose a heterogeneous game transition model that incorporates a reputation-based dynamic threshold mechanism to investigate how reputation regulates game evolution. In our framework, individuals determine the type of game they engage in according to their own and their neighbors' reputation levels. In turn, the outcomes of these interactions modify their reputations, thereby driving the adaptation and evolution of future strategies in a feedback-informed manner. Through simulations on two representative topological structures, square lattice and small-world networks, we find that network topology exerts a profound influence on the evolutionary dynamics. Due to its localized connection characteristics, the square lattice network fosters the long-term coexistence of competing strategies. In contrast, the small-world network is more susceptible to changes in system parameters due to the efficiency of information dissemination and the sensitivity of strategy evolution. Additionally, the reputation mechanism is significant in promoting the formation of a dominant state of cooperation, especially in contexts of high sensitivity to reputation. Although the initial distribution of reputation influences the early stage of the evolutionary path, it has little effect on the final steady state of the system. Hence, we can conclude that the ultimate steady state of evolution is primarily determined by the reputation mechanism and the network structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.13319v1</guid>
      <category>cs.SI</category>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongyu Yue, Xiaojin Xiong, Minyu Feng, Attila Szolnoki</dc:creator>
    </item>
    <item>
      <title>TwiUSD: A Benchmark Dataset and Structure-Aware LLM Framework for User Stance Detection</title>
      <link>https://arxiv.org/abs/2506.13343</link>
      <description>arXiv:2506.13343v1 Announce Type: new 
Abstract: User-level stance detection (UserSD) remains challenging due to the lack of high-quality benchmarks that jointly capture linguistic and social structure. In this paper, we introduce TwiUSD, the first large-scale, manually annotated UserSD benchmark with explicit followee relationships, containing 16,211 users and 47,757 tweets. TwiUSD enables rigorous evaluation of stance models by integrating tweet content and social links, with superior scale and annotation quality. Building on this resource, we propose MRFG: a structure-aware framework that uses LLM-based relevance filtering and feature routing to address noise and context heterogeneity. MRFG employs multi-scale filtering and adaptively routes features through graph neural networks or multi-layer perceptrons based on topological informativeness. Experiments show MRFG consistently outperforms strong baselines (including PLMs, graph-based models, and LLM prompting) in both in-target and cross-target evaluation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.13343v1</guid>
      <category>cs.SI</category>
      <pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fuaing Niu, Zini Chen, Zhiyu Xie, Genan Dai, Bowen Zhang</dc:creator>
    </item>
    <item>
      <title>Modeling Earth-Scale Human-Like Societies with One Billion Agents</title>
      <link>https://arxiv.org/abs/2506.12078</link>
      <description>arXiv:2506.12078v1 Announce Type: cross 
Abstract: Understanding how complex societal behaviors emerge from individual cognition and interactions requires both high-fidelity modeling of human behavior and large-scale simulations. Traditional agent-based models (ABMs) have been employed to study these dynamics for decades, but are constrained by simplified agent behaviors that fail to capture human complexity. Recent advances in large language models (LLMs) offer new opportunities by enabling agents to exhibit sophisticated social behaviors that go beyond rule-based logic, yet face significant scaling challenges. Here we present Light Society, an agent-based simulation framework that advances both fronts, efficiently modeling human-like societies at planetary scale powered by LLMs. Light Society formalizes social processes as structured transitions of agent and environment states, governed by a set of LLM-powered simulation operations, and executed through an event queue. This modular design supports both independent and joint component optimization, supporting efficient simulation of societies with over one billion agents. Large-scale simulations of trust games and opinion propagation--spanning up to one billion agents--demonstrate Light Society's high fidelity and efficiency in modeling social trust and information diffusion, while revealing scaling laws whereby larger simulations yield more stable and realistic emergent behaviors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.12078v1</guid>
      <category>cs.MA</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haoxiang Guan, Jiyan He, Liyang Fan, Zhenzhen Ren, Shaobin He, Xin Yu, Yuan Chen, Shuxin Zheng, Tie-Yan Liu, Zhen Liu</dc:creator>
    </item>
    <item>
      <title>Understanding the Effect of Knowledge Graph Extraction Error on Downstream Graph Analyses: A Case Study on Affiliation Graphs</title>
      <link>https://arxiv.org/abs/2506.12367</link>
      <description>arXiv:2506.12367v1 Announce Type: cross 
Abstract: Knowledge graphs (KGs) are useful for analyzing social structures, community dynamics, institutional memberships, and other complex relationships across domains from sociology to public health. While recent advances in large language models (LLMs) have improved the scalability and accessibility of automated KG extraction from large text corpora, the impacts of extraction errors on downstream analyses are poorly understood, especially for applied scientists who depend on accurate KGs for real-world insights. To address this gap, we conducted the first evaluation of KG extraction performance at two levels: (1) micro-level edge accuracy, which is consistent with standard NLP evaluations, and manual identification of common error sources; (2) macro-level graph metrics that assess structural properties such as community detection and connectivity, which are relevant to real-world applications. Focusing on affiliation graphs of person membership in organizations extracted from social register books, our study identifies a range of extraction performance where biases across most downstream graph analysis metrics are near zero. However, as extraction performance declines, we find that many metrics exhibit increasingly pronounced biases, with each metric tending toward a consistent direction of either over- or under-estimation. Through simulations, we further show that error models commonly used in the literature do not capture these bias patterns, indicating the need for more realistic error models for KG extraction. Our findings provide actionable insights for practitioners and underscores the importance of advancing extraction methods and error modeling to ensure reliable and meaningful downstream analyses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.12367v1</guid>
      <category>cs.CL</category>
      <category>cs.SI</category>
      <pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Erica Cai, Brendan O'Connor</dc:creator>
    </item>
    <item>
      <title>Circular Directional Flow Decomposition of Networks</title>
      <link>https://arxiv.org/abs/2506.12546</link>
      <description>arXiv:2506.12546v1 Announce Type: cross 
Abstract: We introduce the Circular Directional Flow Decomposition (CDFD), a new framework for analyzing circularity in weighted directed networks. CDFD separates flow into two components: a circular (divergence-free) component and an acyclic component that carries all nett directional flow. This yields a normalized circularity index between 0 (fully acyclic) and 1 (for networks formed solely by the superposition of cycles), with the complement measuring directionality. This index captures the proportion of flow involved in cycles, and admits a range of interpretations - such as system closure, feedback, weighted strong connectivity, structural redundancy, or inefficiency. Although the decomposition is generally non-unique, we show that the set of all decompositions forms a well-structured geometric space with favourable topological properties. Within this space, we highlight two benchmark decompositions aligned with distinct analytical goals: the maximum circularity solution, which minimizes nett flow, and the Balanced Flow Forwarding (BFF) solution, a unique, locally computable decomposition that distributes circular flow across all feasible cycles in proportion to the original network structure. We demonstrate the interpretive value and computational tractability of both decompositions on synthetic and empirical networks. They outperform existing circularity metrics in detecting meaningful structural variation. The decomposition also enables structural analysis - such as mapping the distribution of cyclic flow - and supports practical applications that require explicit flow allocation or routing, including multilateral netting and efficient transport.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.12546v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.DM</category>
      <category>cs.SI</category>
      <category>math.CO</category>
      <category>q-fin.RM</category>
      <pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marc Homs-Dones, Robert S. MacKay, Bazil Sansom, Yijie Zhou</dc:creator>
    </item>
    <item>
      <title>Prosocial Design in Trust and Safety</title>
      <link>https://arxiv.org/abs/2506.12792</link>
      <description>arXiv:2506.12792v1 Announce Type: cross 
Abstract: This chapter presents an overview of Prosocial Design, an approach to platform design and governance that recognizes design choices influence behavior and that those choices can or should be made toward supporting healthy interactions and other prosocial outcomes. The authors discuss several core principles of Prosocial Design and its relationship to Trust and Safety and other related fields. As a primary contribution, the chapter reviews relevant research to demonstrate how Prosocial Design can be an effective approach to reducing rule-breaking and other harmful behavior and how it can help to stem the spread of harmful misinformation. Prosocial Design is a nascent and evolving field and research is still limited. The authors hope this chapter will not only inspire more research and the adoption of a prosocial design approach, but that it will also provoke discussion about the principles of Prosocial Design and its potential to support Trust and Safety.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.12792v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David Gr\"uning, Julia Kamin</dc:creator>
    </item>
    <item>
      <title>Efficient Approximate Temporal Triangle Counting in Streaming with Predictions</title>
      <link>https://arxiv.org/abs/2506.13173</link>
      <description>arXiv:2506.13173v1 Announce Type: cross 
Abstract: Triangle counting is a fundamental and widely studied problem on static graphs, and recently on temporal graphs, where edges carry information on the timings of the associated events. Streaming processing and resource efficiency are crucial requirements for counting triangles in modern massive temporal graphs, with millions of nodes and up to billions of temporal edges. However, current exact and approximate algorithms are unable to handle large-scale temporal graphs. To fill such a gap, we introduce STEP, a scalable and efficient algorithm to approximate temporal triangle counts from a stream of temporal edges. STEP combines predictions to the number of triangles a temporal edge is involved in, with a simple sampling strategy, leading to scalability, efficiency, and accurate approximation of all eight temporal triangle types simultaneously. We analytically prove that, by using a sublinear amount of memory, STEP obtains unbiased and very accurate estimates. In fact, even noisy predictions can significantly reduce the variance of STEP's estimates. Our extensive experiments on massive temporal graphs with up to billions of edges demonstrate that STEP outputs high-quality estimates and is more efficient than state-of-the-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.13173v1</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Giorgio Venturin, Ilie Sarpe, Fabio Vandin</dc:creator>
    </item>
    <item>
      <title>A data-driven analysis of the impact of non-compliant individuals on epidemic diffusion in urban settings</title>
      <link>https://arxiv.org/abs/2506.13325</link>
      <description>arXiv:2506.13325v1 Announce Type: cross 
Abstract: Individuals who do not comply with public health safety measures pose a significant challenge to effective epidemic control, as their risky behaviours can undermine public health interventions. This is particularly relevant in urban environments because of their high population density and complex social interactions. In this study, we employ detailed contact networks, built using a data-driven approach, to examine the impact of non-compliant individuals on epidemic dynamics in three major Italian cities: Torino, Milano, and Palermo. We use a heterogeneous extension of the Susceptible-Infected-Recovered model that distinguishes between ordinary and non-compliant individuals, who are more infectious and/or more susceptible. By combining electoral data with recent findings on vaccine hesitancy, we obtain spatially heterogeneous distributions of non-compliance. Epidemic simulations demonstrate that even a small proportion of non-compliant individuals in the population can substantially increase the number of infections and accelerate the timing of their peak. Furthermore, the impact of non-compliance is greatest when disease transmission rates are moderate. Including the heterogeneous, data-driven distribution of non-compliance in the simulations results in infection hotspots forming with varying intensity according to the disease transmission rate. Overall, these findings emphasise the importance of monitoring behavioural compliance and tailoring public health interventions to address localised risks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.13325v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.SI</category>
      <category>q-bio.PE</category>
      <pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fabio Mazza, Marco Brambilla, Carlo Piccardi, Francesco Pierri</dc:creator>
    </item>
    <item>
      <title>The Best Soules Basis for the Estimation of a Spectral Barycentre Network</title>
      <link>https://arxiv.org/abs/2502.00038</link>
      <description>arXiv:2502.00038v2 Announce Type: replace 
Abstract: The main contribution of this work is a fast algorithm to compute the barycentre of a set of networks based on a Laplacian spectral pseudo-distance. The core engine for the reconstruction of the barycentre is an algorithm that explores the large library of Soules bases, and returns a basis that yields a sparse approximation of the sample mean adjacency matrix. We prove that when the networks are random realizations of stochastic block models, then our algorithm reconstructs the population mean adjacency matrix. In addition to the theoretical analysis of the estimator of the barycentre network, we perform Monte Carlo simulations to validate the theoretical properties of the estimator. This work is significant because it opens the door to the design of new spectral-based network synthesis that have theoretical guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00038v2</guid>
      <category>cs.SI</category>
      <category>cs.LG</category>
      <category>physics.data-an</category>
      <category>stat.ML</category>
      <pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fran\c{c}ois G. Meyer</dc:creator>
    </item>
    <item>
      <title>Design of A* based heuristic algorithm for efficient interdiction in multi-Layer networks</title>
      <link>https://arxiv.org/abs/2506.10017</link>
      <description>arXiv:2506.10017v2 Announce Type: replace 
Abstract: Intercepting a criminal using limited police resources presents a significant challenge in dynamic crime environments, where the criminal's location continuously changes over time. The complexity is further heightened by the vastness of the transportation network. To tackle this problem, we propose a layered graph representation, in which each time step is associated with a duplicate of the transportation network. For any given set of attacker strategies, a near-optimal defender strategy is computed using the A-Star heuristic algorithm applied to the layered graph. The defender's goal is to maximize the probability of successful interdiction. We evaluate the performance of the proposed method by comparing it with a Mixed-Integer Linear Programming (MILP) approach used for the defender. The comparison considers both computational efficiency and solution quality. The results demonstrate that our approach effectively addresses the complexity of the problem and delivers high-quality solutions within a short computation time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10017v2</guid>
      <category>cs.SI</category>
      <category>cs.MA</category>
      <category>math.OC</category>
      <pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sukanya Samanta</dc:creator>
    </item>
    <item>
      <title>Inference of Hierarchical Core-Periphery Structure in Temporal Networks</title>
      <link>https://arxiv.org/abs/2506.10135</link>
      <description>arXiv:2506.10135v2 Announce Type: replace 
Abstract: Networks can have various types of mesoscale structures. One type of mesoscale structure in networks is core-periphery structure, which consists of densely-connected core nodes and sparsely-connected peripheral nodes. The core nodes are connected densely to each other and can be connected to the peripheral nodes, which are connected sparsely to other nodes. There has been much research on core-periphery structure in time-independent networks, but few core-periphery detection methods have been developed for time-dependent (i.e., ``temporal") networks. Using a multilayer-network representation of temporal networks and an inference approach that employs stochastic block models, we generalize a recent method for detecting hierarchical core-periphery structure \cite{Polanco23} from time-independent networks to temporal networks. In contrast to ``onion-like'' nested core-periphery structures (where each node is assigned to a group according to how deeply it is nested in a network's core), hierarchical core-periphery structures encompass networks with nested structures, tree-like structures (where any two groups must either be disjoint or have one as a strict subset of the other), and general non-nested mesoscale structures (where the group assignments of nodes do not have to be nested in any way). To perform statistical inference and thereby identify core-periphery structure, we use a Markov-chain Monte Carlo (MCMC) approach. We illustrate our method for detecting hierarchical core-periphery structure in two real-world temporal networks, and we briefly discuss the structures that we identify in these networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10135v2</guid>
      <category>cs.SI</category>
      <category>math.CO</category>
      <category>physics.data-an</category>
      <category>physics.soc-ph</category>
      <category>stat.ME</category>
      <pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Theodore Y. Faust, Mason A. Porter</dc:creator>
    </item>
    <item>
      <title>Disentangling Codemixing in Chats: The NUS ABC Codemixed Corpus</title>
      <link>https://arxiv.org/abs/2506.00332</link>
      <description>arXiv:2506.00332v2 Announce Type: replace-cross 
Abstract: Code-mixing involves the seamless integration of linguistic elements from multiple languages within a single discourse, reflecting natural multilingual communication patterns. Despite its prominence in informal interactions such as social media, chat messages and instant-messaging exchanges, there has been a lack of publicly available corpora that are author-labeled and suitable for modeling human conversations and relationships. This study introduces the first labeled and general-purpose corpus for understanding code-mixing in context while maintaining rigorous privacy and ethical standards. Our live project will continuously gather, verify, and integrate code-mixed messages into a structured dataset released in JSON format, accompanied by detailed metadata and linguistic statistics. To date, it includes over 355,641 messages spanning various code-mixing patterns, with a primary focus on English, Mandarin, and other languages. We expect the Codemix Corpus to serve as a foundational dataset for research in computational linguistics, sociolinguistics, and NLP applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00332v2</guid>
      <category>cs.CL</category>
      <category>cs.SI</category>
      <pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Svetlana Churina, Akshat Gupta, Insyirah Mujtahid, Kokil Jaidka</dc:creator>
    </item>
    <item>
      <title>H$^2$GFM: Towards unifying Homogeneity and Heterogeneity on Text-Attributed Graphs</title>
      <link>https://arxiv.org/abs/2506.08298</link>
      <description>arXiv:2506.08298v2 Announce Type: replace-cross 
Abstract: The growing interests and applications of graph learning in diverse domains have propelled the development of a unified model generalizing well across different graphs and tasks, known as the Graph Foundation Model (GFM). Existing research has leveraged text-attributed graphs (TAGs) to tackle the heterogeneity in node features among graphs. However, they primarily focus on homogeneous TAGs (HoTAGs), leaving heterogeneous TAGs (HeTAGs), where multiple types of nodes/edges reside, underexplored. To enhance the capabilities and applications of GFM, we introduce H$^2$GFM, a novel framework designed to generalize across both HoTAGs and HeTAGs. Our model projects diverse meta-relations among graphs under a unified textual space, and employs a context encoding to capture spatial and higher-order semantic relationships. To achieve robust node representations, we propose a novel context-adaptive graph transformer (CGT), effectively capturing information from both context neighbors and their relationships. Furthermore, we employ a mixture of CGT experts to capture the heterogeneity in structural patterns among graph types. Comprehensive experiments on a wide range of HoTAGs and HeTAGs as well as learning scenarios demonstrate the effectiveness of our model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.08298v2</guid>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Trung-Kien Nguyen, Heng Ping, Shixuan Li, Peiyu Zhang, Nikos Kanakaris, Nicholas Kotov, Paul Bogdan</dc:creator>
    </item>
    <item>
      <title>KI4Demokratie: An AI-Based Platform for Monitoring and Fostering Democratic Discourse</title>
      <link>https://arxiv.org/abs/2506.09947</link>
      <description>arXiv:2506.09947v2 Announce Type: replace-cross 
Abstract: Social media increasingly fuel extremism, especially right-wing extremism, and enable the rapid spread of antidemocratic narratives. Although AI and data science are often leveraged to manipulate political opinion, there is a critical need for tools that support effective monitoring without infringing on freedom of expression. We present KI4Demokratie, an AI-based platform that assists journalists, researchers, and policymakers in monitoring right-wing discourse that may undermine democratic values. KI4Demokratie applies machine learning models to a large-scale German online data gathered on a daily basis, providing a comprehensive view of trends in the German digital sphere. Early analysis reveals both the complexity of tracking organized extremist behavior and the promise of our integrated approach, especially during key events.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09947v2</guid>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rudy Alexandro Garrido Veliz, Till Nikolaus Schaland, Simon Bergmoser, Florian Horwege, Somya Bansal, Ritesh Nahar, Martin Semmann, J\"org Forthmann, Seid Muhie Yimam</dc:creator>
    </item>
  </channel>
</rss>
