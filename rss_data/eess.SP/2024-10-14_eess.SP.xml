<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>eess.SP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/eess.SP</link>
    <description>eess.SP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/eess.SP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 15 Oct 2024 03:31:47 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Variational Source-Channel Coding for Semantic Communication</title>
      <link>https://arxiv.org/abs/2410.08222</link>
      <description>arXiv:2410.08222v1 Announce Type: new 
Abstract: Semantic communication technology emerges as a pivotal bridge connecting AI with classical communication. The current semantic communication systems are generally modeled as an Auto-Encoder (AE). AE lacks a deep integration of AI principles with communication strategies due to its inability to effectively capture channel dynamics. This gap makes it difficult to justify the need for joint source-channel coding (JSCC) and to explain why performance improves. This paper begins by exploring lossless and lossy communication, highlighting that the inclusion of data distortion distinguishes semantic communication from classical communication. It breaks the conditions for the separation theorem to hold and explains why the amount of data transferred by semantic communication is less. Therefore, employing JSCC becomes imperative for achieving optimal semantic communication. Moreover, a Variational Source-Channel Coding (VSCC) method is proposed for constructing semantic communication systems based on data distortion theory, integrating variational inference and channel characteristics. Using a deep learning network, we develop a semantic communication system employing the VSCC method and demonstrate its capability for semantic transmission. We also establish semantic communication systems of equivalent complexity employing the AE method and the VAE method. Experimental results reveal that the VSCC model offers superior interpretability compared to AE model, as it clearly captures the semantic features of the transmitted data, represented as the variance of latent variables in our experiments. In addition, VSCC model exhibits superior semantic transmission capabilities compared to VAE model. At the same level of data distortion evaluated by PSNR, VSCC model exhibits stronger human interpretability, which can be partially assessed by SSIM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08222v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yulong Feng, Jing Xu, Liujun Hu, Guanghui Yu</dc:creator>
    </item>
    <item>
      <title>A Survey of Spatio-Temporal EEG data Analysis: from Models to Applications</title>
      <link>https://arxiv.org/abs/2410.08224</link>
      <description>arXiv:2410.08224v1 Announce Type: new 
Abstract: In recent years, the field of electroencephalography (EEG) analysis has witnessed remarkable advancements, driven by the integration of machine learning and artificial intelligence. This survey aims to encapsulate the latest developments, focusing on emerging methods and technologies that are poised to transform our comprehension and interpretation of brain activity. We delve into self-supervised learning methods that enable the robust representation of brain signals, which are fundamental for a variety of downstream applications. We also explore emerging discriminative methods, including graph neural networks (GNN), foundation models, and large language models (LLMs)-based approaches. Furthermore, we examine generative technologies that harness EEG data to produce images or text, offering novel perspectives on brain activity visualization and interpretation. The survey provides an extensive overview of these cutting-edge techniques, their current applications, and the profound implications they hold for future research and clinical practice. The relevant literature and open-source materials have been compiled and are consistently being refreshed at \url{https://github.com/wpf535236337/LLMs4TS}</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08224v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pengfei Wang, Huanran Zheng, Silong Dai, Yiqiao Wang, Xiaotian Gu, Yuanbin Wu, Xiaoling Wang</dc:creator>
    </item>
    <item>
      <title>Designing Unimodular Waveforms with Good Correlation Properties for Large-Scale MIMO Radar via Manifold Optimization Method</title>
      <link>https://arxiv.org/abs/2410.08287</link>
      <description>arXiv:2410.08287v1 Announce Type: new 
Abstract: In this paper, we design constant modulus probing waveforms with good correlation properties for large-scale collocated multi-input multi-output (MIMO) radar systems. The main content is as follows: First, we formulate the design problem as a fourth-order polynomial minimization problem with unimodulus constraints. Then, by analyzing the geometric properties of the unimodulus constraints through Riemannian geometry theory and embedding them into the search space, we transform the original non-convex optimization problem into an unconstrained problem on a Riemannian manifold for solution. Second, we convert the objective function into the form of a large but finite number of loss functions and employ a customized R-SVRG algorithm to solve it. Third, we prove that the customized R-SVRG algorithm is theoretically guaranteed to converge if appropriate parameters are chosen. Numerical examples demonstrate the effectiveness of the proposed R-SVRG algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08287v1</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xuyang Zhao, Jiangtao Wang, Yongchao Wang</dc:creator>
    </item>
    <item>
      <title>Meta-Learning-Driven Adaptive Codebook Design for Near-Field Communications</title>
      <link>https://arxiv.org/abs/2410.08318</link>
      <description>arXiv:2410.08318v1 Announce Type: new 
Abstract: Extremely large-scale arrays (XL-arrays) and ultra-high frequencies are two key technologies for sixth-generation (6G) networks, offering higher system capacity and expanded bandwidth resources. To effectively combine these technologies, it is necessary to consider the near-field spherical-wave propagation model, rather than the traditional far-field planar-wave model. In this paper, we explore a near-field communication system comprising a base station (BS) with hybrid analog-digital beamforming and multiple mobile users. Our goal is to maximize the system's sum-rate by optimizing the near-field codebook design for hybrid precoding. To enable fast adaptation to varying user distributions, we propose a meta-learning-based framework that integrates the model-agnostic meta-learning (MAML) algorithm with a codebook learning network. Specifically, we first design a deep neural network (DNN) to learn the near-field codebook. Then, we combine the MAML algorithm with the DNN to allow rapid adaptation to different channel conditions by leveraging a well-initialized model from the outer network. Simulation results demonstrate that our proposed framework outperforms conventional algorithms, offering improved generalization and better overall performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08318v1</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mianyi Zhang, Yunlong Cai, Jiaqi Xu, A. Lee Swindlehurst</dc:creator>
    </item>
    <item>
      <title>Beamforming Design for Intelligent Reffecting Surface Aided Near-Field THz Communications</title>
      <link>https://arxiv.org/abs/2410.08459</link>
      <description>arXiv:2410.08459v1 Announce Type: new 
Abstract: Intelligent reflecting surface (IRS) operating in the terahertz (THz) band has recently gained considerable interest due to its high spectrum bandwidth. Due to the exploitation of large scale of IRS, there is a high probability that the transceivers will be situated within the near-field region of the IRS. Thus, the near-field beam split effect poses a major challenge for the design of wideband IRS beamforming, which causes the radiation beam to deviate from its intended location, leading to significant gain losses and limiting the efficient use of available bandwidths. While delay-based IRS has emerged as a potential solution, current beamforming schemes generally assume unbounded range time delays (TDs). In this letter, we first investigate the near-field beam split issue at the IRS. Then, we extend the piece-wise far-field model to the IRS, based on which, a double-layer delta-delay (DLDD) IRS beamforming scheme is proposed. Specifically, we employ an element-grouping strategy and the TD imposed on each sub-surface of IRS is achieved by a series of TD modules. This method significantly reduces the required range of TDs. Numerical results show that the proposed DLDD IRS beamforming scheme can effectively mitigate the near-field beam split and achieve near-optimal performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08459v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chi Qiu, Qingqing Wu, Wen Chen, Meng Hua, Wanming Hao, Mengnan Jian, Fen Hou</dc:creator>
    </item>
    <item>
      <title>High-Efficient Near-Field Channel Characteristics Analysis for Large-Scale MIMO Communication Systems</title>
      <link>https://arxiv.org/abs/2410.08463</link>
      <description>arXiv:2410.08463v1 Announce Type: new 
Abstract: Large-scale multiple-input multiple-output (MIMO) holds great promise for the fifth-generation (5G) and future communication systems. In near-field scenarios, the spherical wavefront model is commonly utilized to accurately depict the propagation characteristics of large-scale MIMO communication channels. However, employing this modeling method necessitates the computation of angle and distance parameters for each antenna element, resulting in challenges regarding computational complexity. To solve this problem, we introduce a subarray decomposition scheme with the purpose of dividing the whole large-scale antenna array into several smaller subarrays. This scheme is implemented in the near-field channel modeling for large-scale MIMO communications between the base stations (BS) and the mobile receiver (MR). Essential channel propagation statistics, such as spatial cross-correlation functions (CCFs), temporal auto-correlation functions (ACFs), frequency correlation functions (CFs), and channel capacities, are derived and discussed. A comprehensive analysis is conducted to investigate the influence of the height of the BS, motion characteristics of the MR, and antenna configurations on the channel statistics. The proposed channel model criterions, such as the modeling precision and computational complexity, are also theoretically compared. Numerical results demonstrate the effectiveness of the presented communication model in obtaining a good tradeoff between modeling precision and computational complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08463v1</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Jiang, Wangqi Shi, Xiao Chen, Qiuming Zhu, Zhen Chen</dc:creator>
    </item>
    <item>
      <title>FMCW Radar Principles and Human Activity Recognition Systems: Foundations, Techniques, and Applications</title>
      <link>https://arxiv.org/abs/2410.08483</link>
      <description>arXiv:2410.08483v1 Announce Type: new 
Abstract: This book introduces the theoretical foundations of FMCW radar systems, including range and velocity estimation, signal processing techniques, and the generation of radar point clouds. A detailed discussion of Python and MATLAB as the primary programming tools for radar signal processing is provided, including the integration of libraries like NumPy, Matplotlib, and SciPy for data analysis and visualization. In addition, the book covers advanced techniques such as deep learning applications for radar signal processing, focusing on Convolutional Neural Networks (CNNs), Long Short-Term Memory (LSTM) networks, and Transformers for analyzing radar data. Furthermore, it highlights state-of-the-art methods for human activity recognition using radar, leveraging a combination of traditional signal processing techniques and machine learning models. The book is designed to cater to both beginners and experts in radar signal processing, offering practical examples, code implementations, and insights into the future of radar technology in various domains, including autonomous systems and security applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08483v1</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziqian Bi, Jiawei Xu, Ming Liu</dc:creator>
    </item>
    <item>
      <title>Blind and robust reconstruction of adaptive optics point spread functions for asteroid deconvolution and moon detection</title>
      <link>https://arxiv.org/abs/2410.08585</link>
      <description>arXiv:2410.08585v1 Announce Type: new 
Abstract: Initially designed to detect and characterize exoplanets, extreme adaptive optics systems (AO) open a new window on the solar system by resolving its small bodies. Nonetheless, despite the always increasing performances of AO systems, the correction is not perfect, degrading their image and producing a bright halo that can hide faint and close moons. Using a reference point spread function (PSF) is not always sufficient due to the random nature of the turbulence. In this work, we present our method to overcome this limitation. It blindly reconstructs the AO-PSF directly in the data of interest, without any prior on the instrument nor the asteroid's shape. This is done by first estimating the PSF core parameters under the assumption of a sharp-edge and flat object, allowing the image of the main body to be deconvolved. Then, the PSF faint extensions are reconstructed with a robust penalization optimization, discarding outliers on-the-fly such as cosmic rays, defective pixels and moons. This allows to properly model and remove the asteroid's halo. Finally, moons can be detected in the residuals, using the reconstructed PSF and the knowledge of the outliers learned with the robust method. We show that our method can be easily applied to different instruments (VLT/SPHERE, Keck/NIRC2), efficiently retrieving the features of AO-PSFs. Compared with state-of-the-art moon enhancement algorithms, moon signal is greatly improved and our robust detection method manages to discriminate faint moons from outliers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08585v1</guid>
      <category>eess.SP</category>
      <category>astro-ph.IM</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1117/12.3019874</arxiv:DOI>
      <arxiv:journal_reference>Adaptive Optics Systems IX, Jun 2024, Yokohama, Japan. pp.235</arxiv:journal_reference>
      <dc:creator>Anthony Berdeu (LESIA), F\'err\'eol Soulez (CRAL), Kate Minker (OCA), Benoit Carry (OCA), Guillaume Bourdarot (MPE), Antoine Kaszczyc (CRAL), Maud Langlois (CRAL)</dc:creator>
    </item>
    <item>
      <title>radarODE-MTL: A Multi-Task Learning Framework with Eccentric Gradient Alignment for Robust Radar-Based ECG Reconstruction</title>
      <link>https://arxiv.org/abs/2410.08656</link>
      <description>arXiv:2410.08656v1 Announce Type: new 
Abstract: Millimeter-wave radar is promising to provide robust and accurate vital sign monitoring in an unobtrusive manner. However, the radar signal might be distorted in propagation by ambient noise or random body movement, ruining the subtle cardiac activities and destroying the vital sign recovery. In particular, the recovery of electrocardiogram (ECG) signal heavily relies on the deep-learning model and is sensitive to noise. Therefore, this work creatively deconstructs the radar-based ECG recovery into three individual tasks and proposes a multi-task learning (MTL) framework, radarODE-MTL, to increase the robustness against consistent and abrupt noises. In addition, to alleviate the potential conflicts in optimizing individual tasks, a novel multi-task optimization strategy, eccentric gradient alignment (EGA), is proposed to dynamically trim the task-specific gradients based on task difficulties in orthogonal space. The proposed radarODE-MTL with EGA is evaluated on the public dataset with prominent improvements in accuracy, and the performance remains consistent under noises. The experimental results indicate that radarODE-MTL could reconstruct accurate ECG signals robustly from radar signals and imply the application prospect in real-life situations. The code is available at: http://github.com/ZYY0844/radarODE-MTL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08656v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuanyuan Zhang, Rui Yang, Yutao Yue, Eng Gee Lim</dc:creator>
    </item>
    <item>
      <title>Multi-Functional RIS for a Multi-Functional System: Integrating Sensing, Communication, and Wireless Power Transfer</title>
      <link>https://arxiv.org/abs/2410.08715</link>
      <description>arXiv:2410.08715v1 Announce Type: new 
Abstract: Communication networks are evolving from solely emphasizing communication to facilitating multiple functionalities. In this regard, integrated sensing, communication, and powering (ISCAP) provides an efficient way of enabling data transmission, radar sensing, and wireless power transfer simultaneously. Such a multi-functional network requires a multi-functional architectural solution. Toward this end, sensor-aided zero-energy reconfigurable intelligent surfaces (SAZE-RISs) offer an energy-efficient solution for ISCAP by meeting the requirements of the end users as well as supplying power for the RIS. This paper explores the use of SAZE-RIS within the ISCAP framework. First, we present the general system architecture, operational protocols, and main application scenarios for employing SAZE-RIS in ISCAP. Next, we discuss methods for managing the conflicting requirements of communication, sensing, and powering within ISCAP and the role of SAZE-RIS in this process. We then provide a detailed case study complete with simulation results, offering valuable insights into the design choices and tradeoffs that come into play when adopting this technology. Furthermore, we discuss the related challenges and open research avenues, highlighting areas that require further exploration to fully realize the potential of SAZE-RIS within this ISCAP framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08715v1</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ahmed Magbool, Vaibhav Kumar, Ahmad Bazzi, Mark F. Flanagan, Marwa Chafii</dc:creator>
    </item>
    <item>
      <title>I-SCOUT: Integrated Sensing and Communications to Uncover Moving Targets in NextG Networks</title>
      <link>https://arxiv.org/abs/2410.08999</link>
      <description>arXiv:2410.08999v1 Announce Type: new 
Abstract: Integrated Sensing and Communication (ISAC) represents a transformative approach within 5G and beyond, aiming to merge wireless communication and sensing functionalities into a unified network infrastructure. This integration offers enhanced spectrum efficiency, real-time situational awareness, cost and energy reductions, and improved operational performance. ISAC provides simultaneous communication and sensing capabilities, enhancing the ability to detect, track, and respond to spectrum dynamics and potential threats in complex environments. In this paper, we introduce I-SCOUT, an innovative ISAC solution designed to uncover moving targets in NextG networks. We specifically repurpose the Positioning Reference Signal (PRS) of the 5G waveform, exploiting its distinctive autocorrelation characteristics for environment sensing. The reflected signals from moving targets are processed to estimate both the range and velocity of these targets using the cross ambiguity function (CAF). We conduct an in-depth analysis of the tradeoff between sensing and communication functionalities, focusing on the allocation of PRSs for ISAC purposes. Our study reveals that the number of PRSs dedicated to ISAC has a significant impact on the system's performance, necessitating a careful balance to optimize both sensing accuracy and communication efficiency. Our results demonstrate that I-SCOUT effectively leverages ISAC to accurately determine the range and velocity of moving targets. Moreover, I-SCOUT is capable of distinguishing between multiple targets within a group, showcasing its potential for complex scenarios. These findings underscore the viability of ISAC in enhancing the capabilities of NextG networks, for both commercial and tactical applications where precision and reliability are critical.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08999v1</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Utku Demir, Kemal Davaslioglu, Yalin E. Sagduyu, Tugba Erpek, Gustave Anderson, Sastry Kompella</dc:creator>
    </item>
    <item>
      <title>Towards a Health-Based Power Grid Optimization in the Artificial Intelligence Era</title>
      <link>https://arxiv.org/abs/2410.09029</link>
      <description>arXiv:2410.09029v1 Announce Type: new 
Abstract: The electric power sector is one of the largest contributors to greenhouse gas emissions in the world. In recent years, there has been an unprecedented increase in electricity demand driven by the so-called Artificial Intelligence (AI) revolution. Although AI has and will continue to have a transformative impact, its environmental and health impacts are often overlooked. The standard approach to power grid optimization aims to minimize CO$_2$ emissions. In this paper, we propose a new holistic paradigm. Our proposed optimization directly targets the minimization of adverse health outcomes under energy efficiency and emission constraints. We show the first example of an optimal fuel mix allocation problem aiming to minimize the average number of adverse health effects resulting from exposure to hazardous air pollutants with constraints on the average and marginal emissions. We argue that this new health-based power grid optimization is essential to promote truly sustainable technological advances that align both with global climate goals and public health priorities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09029v1</guid>
      <category>eess.SP</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>stat.AP</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Claudio Battiloro, Gianluca Guidi, Falco J. Bargagli-Stoffi, Francesca Dominici</dc:creator>
    </item>
    <item>
      <title>Physics and Deep Learning in Computational Wave Imaging</title>
      <link>https://arxiv.org/abs/2410.08329</link>
      <description>arXiv:2410.08329v1 Announce Type: cross 
Abstract: Computational wave imaging (CWI) extracts hidden structure and physical properties of a volume of material by analyzing wave signals that traverse that volume. Applications include seismic exploration of the Earth's subsurface, acoustic imaging and non-destructive testing in material science, and ultrasound computed tomography in medicine. Current approaches for solving CWI problems can be divided into two categories: those rooted in traditional physics, and those based on deep learning. Physics-based methods stand out for their ability to provide high-resolution and quantitatively accurate estimates of acoustic properties within the medium. However, they can be computationally intensive and are susceptible to ill-posedness and nonconvexity typical of CWI problems. Machine learning-based computational methods have recently emerged, offering a different perspective to address these challenges. Diverse scientific communities have independently pursued the integration of deep learning in CWI. This review delves into how contemporary scientific machine-learning (ML) techniques, and deep neural networks in particular, have been harnessed to tackle CWI problems. We present a structured framework that consolidates existing research spanning multiple domains, including computational imaging, wave physics, and data science. This study concludes with important lessons learned from existing ML-based methods and identifies technical hurdles and emerging trends through a systematic analysis of the extensive literature on this topic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08329v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Youzuo Lin, Shihang Feng, James Theiler, Yinpeng Chen, Umberto Villa, Jing Rao, John Greenhall, Cristian Pantea, Mark A. Anastasio, Brendt Wohlberg</dc:creator>
    </item>
    <item>
      <title>Slow Convergence of Interacting Kalman Filters in Word-of-Mouth Social Learning</title>
      <link>https://arxiv.org/abs/2410.08447</link>
      <description>arXiv:2410.08447v1 Announce Type: cross 
Abstract: We consider word-of-mouth social learning involving $m$ Kalman filter agents that operate sequentially. The first Kalman filter receives the raw observations, while each subsequent Kalman filter receives a noisy measurement of the conditional mean of the previous Kalman filter. The prior is updated by the $m$-th Kalman filter. When $m=2$, and the observations are noisy measurements of a Gaussian random variable, the covariance goes to zero as $k^{-1/3}$ for $k$ observations, instead of $O(k^{-1})$ in the standard Kalman filter. In this paper we prove that for $m$ agents, the covariance decreases to zero as $k^{-(2^m-1)}$, i.e, the learning slows down exponentially with the number of agents. We also show that by artificially weighing the prior at each time, the learning rate can be made optimal as $k^{-1}$. The implication is that in word-of-mouth social learning, artificially re-weighing the prior can yield the optimal learning rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08447v1</guid>
      <category>cs.LG</category>
      <category>econ.TH</category>
      <category>eess.SP</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vikram Krishnamurthy, Cristian Rojas</dc:creator>
    </item>
    <item>
      <title>Goal-Oriented Communications for Real-time Inference with Two-Way Delay</title>
      <link>https://arxiv.org/abs/2410.08706</link>
      <description>arXiv:2410.08706v1 Announce Type: cross 
Abstract: We design a goal-oriented communication strategy for remote inference, where an intelligent model (e.g., a pre-trained neural network) at the receiver side predicts the real-time value of a target signal based on data packets transmitted from a remote location. The inference error depends on both the Age of Information (AoI) and the length of the data packets. Previous formulations of this problem either assumed IID transmission delays with immediate feedback or focused only on monotonic relations where inference performance degrades as the input data ages. In contrast, we consider a possibly non-monotonic relationship between the inference error and AoI. We show how to minimize the expected time-average inference error under two-way delay, where the delay process can have memory. Simulation results highlight the significant benefits of adopting such a goal-oriented communication strategy for remote inference, especially under highly variable delay scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08706v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cagri Ari, Md Kamran Chowdhury Shisher, Yin Sun, Elif Uysal</dc:creator>
    </item>
    <item>
      <title>Smart PRACH Jamming: A Serious Threat for 5G Campus Networks</title>
      <link>https://arxiv.org/abs/2410.08729</link>
      <description>arXiv:2410.08729v1 Announce Type: cross 
Abstract: Smart jamming attacks on cellular campus networks represent an enormous potential threat, especially in the industrial environment. In complex production processes, the disruption of a single wireless connected Cyber-Physical System (CPS) is enough to cause a large-scale failure. In this paper, a smart jamming attack on the Physical Random Access Channel (PRACH) of a 5G system is modeled. This is followed by a practical implementation of the jammer on a testbed based on Open Air Interface (OAI) and Software Defined Radios (SDRs). It is shown that the designed jammer design can interfere a legitimate transmission of a PRACH preamble with a ratio of more than 99.9%. While less than one percent of the cell resources are interfered compared to broadband jamming. In addition, two different types of jamming signal spectra are compared in relation to their interference capacity. The developed attack can be re-implemented based on publicly available source code and Commercial Off-The-Shelf (COTS) hardware.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08729v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>J. R. Stegmann, M. Gundall, H. D. Schotten</dc:creator>
    </item>
    <item>
      <title>Online Learning for Intelligent Thermal Management of Interference-coupled and Passively Cooled Base Stations</title>
      <link>https://arxiv.org/abs/2410.08799</link>
      <description>arXiv:2410.08799v1 Announce Type: cross 
Abstract: Passively cooled base stations (PCBSs) have emerged to deliver better cost and energy efficiency. However, passive cooling necessitates intelligent thermal control via traffic management, i.e., the instantaneous data traffic or throughput of a PCBS directly impacts its thermal performance. This is particularly challenging for outdoor deployment of PCBSs because the heat dissipation efficiency is uncertain and fluctuates over time. What is more, the PCBSs are interference-coupled in multi-cell scenarios. Thus, a higher-throughput PCBS leads to higher interference to the other PCBSs, which, in turn, would require more resource consumption to meet their respective throughput targets. In this paper, we address online decision-making for maximizing the total downlink throughput for a multi-PCBS system subject to constraints related on operating temperature. We demonstrate that a reinforcement learning (RL) approach, specifically soft actor-critic (SAC), can successfully perform throughput maximization while keeping the PCBSs cool, by adapting the throughput to time-varying heat dissipation conditions. Furthermore, we design a denial and reward mechanism that effectively mitigates the risk of overheating during the exploration phase of RL. Simulation results show that our approach achieves up to 88.6% of the global optimum. This is very promising, as our approach operates without prior knowledge of future heat dissipation efficiency, which is required by the global optimum.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08799v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhanwei Yu, Yi Zhao, Xiaoli Chu, Di Yuan</dc:creator>
    </item>
    <item>
      <title>Exploiting Multiple Polarizations in Extra Large Holographic MIMO</title>
      <link>https://arxiv.org/abs/2410.08839</link>
      <description>arXiv:2410.08839v1 Announce Type: cross 
Abstract: The proliferation of large multi-antenna configurations operating in high frequency bands has recently challenged the conventional far-field, rich-scattering paradigm of wireless channels. Extra large antenna arrays must usually work in the near field and in the absence of multipath, which are far from traditional assumptions in conventional wireless communication systems. The present study proposes to analyze the spatial multiplexing capabilities of large multi-antenna configurations under line-of-sight, near field conditions by considering the use of multiple orthogonal diversities at both transmitter and receiver. The analysis is carried out using a holographic approximation to the problem, whereby the number of radiating elements is assumed to become large while their separation becomes asymptotically negligible. This emulates the operation of a continuous aperture of infinitesimal radiating elements, also recently known as holographic surfaces. The present study characterizes the asymptotic MIMO channel as seen by extra large uniform linear and planar arrays, as well as their associated achievable rates assuming access to perfect channel state information (CSI). It is shown, in particular, that for a given distance between the receiver and the center of the array and a given signal quality, there exists an optimum dimension of the multi-antenna surface that maximizes the spectral efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08839v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adrian Agustin, Xavier Mestre</dc:creator>
    </item>
    <item>
      <title>BrainIB: Interpretable Brain Network-based Psychiatric Diagnosis with Graph Information Bottleneck</title>
      <link>https://arxiv.org/abs/2205.03612</link>
      <description>arXiv:2205.03612v4 Announce Type: replace 
Abstract: Developing a new diagnostic models based on the underlying biological mechanisms rather than subjective symptoms for psychiatric disorders is an emerging consensus. Recently, machine learning-based classifiers using functional connectivity (FC) for psychiatric disorders and healthy controls are developed to identify brain markers. However, existing machine learning-based diagnostic models are prone to over-fitting (due to insufficient training samples) and perform poorly in new test environment. Furthermore, it is difficult to obtain explainable and reliable brain biomarkers elucidating the underlying diagnostic decisions. These issues hinder their possible clinical applications. In this work, we propose BrainIB, a new graph neural network (GNN) framework to analyze functional magnetic resonance images (fMRI), by leveraging the famed Information Bottleneck (IB) principle. BrainIB is able to identify the most informative edges in the brain (i.e., subgraph) and generalizes well to unseen data. We evaluate the performance of BrainIB against 3 baselines and 7 state-of-the-art brain network classification methods on three psychiatric datasets and observe that our BrainIB always achieves the highest diagnosis accuracy. It also discovers the subgraph biomarkers which are consistent to clinical and neuroimaging findings. The source code and implementation details of BrainIB are freely available at GitHub repository (https://github.com/SJYuCNEL/brain-and-Information-Bottleneck/).</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.03612v4</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TNNLS.2024.3449419</arxiv:DOI>
      <dc:creator>Kaizhong Zheng, Shujian Yu, Baojuan Li, Robert Jenssen, Badong Chen</dc:creator>
    </item>
    <item>
      <title>Activity Detection for Massive Random Access using Covariance-based Matching Pursuit</title>
      <link>https://arxiv.org/abs/2405.02741</link>
      <description>arXiv:2405.02741v2 Announce Type: replace 
Abstract: The Internet of Things paradigm heavily relies on a network of a massive number of machine-type devices (MTDs) that monitor various phenomena. Consequently, MTDs are randomly activated at different times whenever a change occurs. In general, fewer MTDs are activated at the same time relative to the whole network, which resembles targeted sampling in compressed sensing. Therefore, signal recovery in machine-type communications is addressed through joint user activity detection and channel estimation algorithms built using compressed sensing theory. However, most of these algorithms follow a two-stage procedure in which a channel is first estimated and later mapped to find active users. This approach is inefficient because the estimated channel information is subsequently discarded. To overcome this limitation, we introduce a novel covariance-learning matching pursuit algorithm that bypasses explicit channel estimation. Instead, it focuses on estimating the indices of the active users greedily. Simulation results presented in terms of probability of miss detection, exact recovery rate, and computational complexity validate the proposed technique's superior performance and efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02741v2</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Leatile Marata, Esa Ollila, Hirley Alves</dc:creator>
    </item>
    <item>
      <title>Target Detection in Sea Clutter with Application to Spaceborne SAR Imaging</title>
      <link>https://arxiv.org/abs/2409.02155</link>
      <description>arXiv:2409.02155v3 Announce Type: replace 
Abstract: In this paper, the challenging task of target detection in sea clutter is addressed. We analyze the statistical properties of the signals which have been received from the scene and based on that, we model the amplitude of the signals that have been reflected from the sea clutter according to several well-known probability distributions. Next, by exploiting the Kullback-Leibler (KL) divergence metric as a goodness-of-fit test, we will demonstrate that among the proposed probability distributions, the Weibull distribution can model the statistical properties of the sea clutter with higher accuracy. Subsequently, we utilize the aforementioned information to design an adaptive threshold based on the Constant False Alarm Rate (CFAR) algorithm to detect the energy of the targets which have been buried in the sea clutter. Thorough analysis of the experimental data gathered from the Canadian RADARSAT-1 satellite demonstrates the overall effectiveness of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02155v3</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shahrokh Hamidi</dc:creator>
    </item>
    <item>
      <title>Anti-jamming Transmission of Downlink Cell Free Millimeter-Wave MIMO System</title>
      <link>https://arxiv.org/abs/2409.13261</link>
      <description>arXiv:2409.13261v5 Announce Type: replace 
Abstract: In this letter, the maximization of resistible jamming power is studied for multi-user downlink millimeter-wave cell-free multiple-input-multiple-output (CF-MIMO) systems. We propose an alternate optimization-based anti-jamming hybrid beamforming (AO-AJHBF) scheme. For receiving beamforming, more practical prior about the jamming channel, i.e., second-order statistics rather than instantaneous information, is exploited via maximizing the generalized Rayleigh quotient. For transmitting beamforming, we use the max-min fairness principle and propose a low-complexity projected gradient ascent-based method to circumvent the excessive computation of semi-definite relaxation (SDR). Simulations verify the performance advantage of proposed AO-AJHBF over schemes based on weighted minimum mean square error and SDR methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.13261v5</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zilong Wang, Cheng Zhang, Changwei Zhang, Yongming Huang</dc:creator>
    </item>
    <item>
      <title>A novel hybrid and publicly available model for spur gear vibrations based on an efficient dynamic model</title>
      <link>https://arxiv.org/abs/2410.05073</link>
      <description>arXiv:2410.05073v2 Announce Type: replace 
Abstract: Dynamic models hold great potential for research and development in signal processing, machine learning, and digital twin algorithms for diagnosing rotating machinery. Various studies have suggested dynamic models of gears, employing many model approaches. However, there is currently a lack of a computationally efficient and publicly accessible model that accurately represents real-world data. In this study, we propose a novel hybrid model that integrates a realistic and efficiently validated dynamic model of spur gear vibrations with an enhancement process aimed at bridging the gap between simulation and reality. This process minimizes discrepancies between features extracted from simulated and measured data through fine-tuning of the model hyperparameters. The effectiveness of this hybrid model is demonstrated across numerous test apparatuses, encompassing several types of faults, severities, and speeds. The new hybrid model, inclusive of an upgraded dynamic model, generates data swiftly within seconds and is made publicly available with a user-friendly application programming interface and a detailed user manual. The novel suggested hybrid model has great potential to enhance future research in model-based studies, including machine learning, signal processing, and digital twin approaches.
  The user manual can be found in the following link: https://github.com/PHM-BGU/public_dynamic_model_for_gear_vibrations</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05073v2</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Omri Matania, Lior Bachar, Roee Cohen, Jacob Bortman</dc:creator>
    </item>
    <item>
      <title>Optimization of the Downlink Spectral- and Energy-Efficiency of RIS-aided Multi-user URLLC MIMO Systems</title>
      <link>https://arxiv.org/abs/2402.16434</link>
      <description>arXiv:2402.16434v2 Announce Type: replace-cross 
Abstract: Modern wireless communication systems are expected to provide improved latency and reliability. To meet these expectations, a short packet length is needed, which makes the first-order Shannon rate an inaccurate performance metric for such communication systems. A more accurate approximation of the achievable rates of finite-block-length (FBL) coding regimes is known as the normal approximation (NA). It is therefore of substantial interest to study the optimization of the FBL rate in multi-user multiple-input multiple-output (MIMO) systems, in which each user may transmit and/or receive multiple data streams. Hence, we formulate a general optimization problem for improving the spectral and energy efficiency of multi-user MIMO-aided ultra-reliable low-latency communication (URLLC) systems, which are assisted by reconfigurable intelligent surfaces (RISs). We show that an RIS is capable of substantially improving the performance of multi-user MIMO-aided URLLC systems. Moreover, the benefits of RIS increase as the packet length and/or the tolerable bit error rate are reduced. This reveals that RISs can be even more beneficial in URLLC systems for improving the FBL rates than in conventional systems approaching Shannon rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.16434v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammad Soleymani, Ignacio Santamaria, Eduard Jorswieck, Robert Schober, Lajos Hanzo</dc:creator>
    </item>
    <item>
      <title>BiomedBench: A benchmark suite of TinyML biomedical applications for low-power wearables</title>
      <link>https://arxiv.org/abs/2406.03886</link>
      <description>arXiv:2406.03886v3 Announce Type: replace-cross 
Abstract: The design of low-power wearables for the biomedical domain has received a lot of attention in recent decades, as technological advances in chip manufacturing have allowed real-time monitoring of patients using low-complexity ML within the mW range. Despite advances in application and hardware design research, the domain lacks a systematic approach to hardware evaluation. In this work, we propose BiomedBench, a new benchmark suite composed of complete end-to-end TinyML biomedical applications for real-time monitoring of patients using wearable devices. Each application presents different requirements during typical signal acquisition and processing phases, including varying computational workloads and relations between active and idle times. Furthermore, our evaluation of five state-of-the-art low-power platforms in terms of energy efficiency shows that modern platforms cannot effectively target all types of biomedical applications. BiomedBench is released as an open-source suite to standardize hardware evaluation and guide hardware and application design in the TinyML wearable domain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03886v3</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Dimitrios Samakovlis, Stefano Albini, Rub\'en Rodr\'iguez \'Alvarez, Denisa-Andreea Constantinescu, Pasquale Davide Schiavone, Miguel Pe\'on Quir\'os, David Atienza</dc:creator>
    </item>
  </channel>
</rss>
