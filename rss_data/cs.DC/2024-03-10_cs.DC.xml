<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DC</link>
    <description>cs.DC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 11 Mar 2024 04:00:06 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 11 Mar 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Optimizing CNN Using HPC Tools</title>
      <link>https://arxiv.org/abs/2403.04870</link>
      <description>arXiv:2403.04870v1 Announce Type: new 
Abstract: This paper optimizes the Convolutional Neural Network (CNN) algorithm using high-performance computing (HPC) technologies. It uses multi-core processors, GPUs, and parallel computing frameworks like OpenMPI and CUDA to speed up CNN model training. The approach improves performance and training time and is superior to alternative strategies. The study demonstrates how HPC technologies can refine the CNN method, resulting in faster and more accurate training of large-scale CNN models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.04870v1</guid>
      <category>cs.DC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Shahrin Rahman</dc:creator>
    </item>
    <item>
      <title>Towards Data-center Level Carbon Modeling and Optimization for Deep Learning Inference</title>
      <link>https://arxiv.org/abs/2403.04976</link>
      <description>arXiv:2403.04976v1 Announce Type: new 
Abstract: Recently, the increasing need for computing resources has led to the prosperity of data centers, which poses challenges to the environmental impacts and calls for improvements in data center provisioning strategies. In this work, we show a comprehensive analysis based on profiling a variety of deep-learning inference applications on different generations of GPU servers. Our analysis reveals several critical factors which can largely affect the design space of provisioning strategies including the hardware embodied cost estimation, application-specific features, and the distribution of carbon cost each year, which prior works have omitted. Based on the observations, we further present a first-order modeling and optimization tool for data center provisioning and scheduling and highlight the importance of environmental impacts from data center management.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.04976v1</guid>
      <category>cs.DC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shixin Ji, Zhuoping Yang, Xingzhen Chen, Jingtong Hu, Yiyu Shi, Alex K. Jones, Peipei Zhou</dc:creator>
    </item>
    <item>
      <title>Enhancing Security in Federated Learning through Adaptive Consensus-Based Model Update Validation</title>
      <link>https://arxiv.org/abs/2403.04803</link>
      <description>arXiv:2403.04803v1 Announce Type: cross 
Abstract: This paper introduces an advanced approach for fortifying Federated Learning (FL) systems against label-flipping attacks. We propose a simplified consensus-based verification process integrated with an adaptive thresholding mechanism. This dynamic thresholding is designed to adjust based on the evolving landscape of model updates, offering a refined layer of anomaly detection that aligns with the real-time needs of distributed learning environments. Our method necessitates a majority consensus among participating clients to validate updates, ensuring that only vetted and consensual modifications are applied to the global model. The efficacy of our approach is validated through experiments on two benchmark datasets in deep learning, CIFAR-10 and MNIST. Our results indicate a significant mitigation of label-flipping attacks, bolstering the FL system's resilience. This method transcends conventional techniques that depend on anomaly detection or statistical validation by incorporating a verification layer reminiscent of blockchain's participatory validation without the associated cryptographic overhead. The innovation of our approach rests in striking an optimal balance between heightened security measures and the inherent limitations of FL systems, such as computational efficiency and data privacy. Implementing a consensus mechanism specifically tailored for FL environments paves the way for more secure, robust, and trustworthy distributed machine learning applications, where safeguarding data integrity and model robustness is critical.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.04803v1</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zahir Alsulaimawi</dc:creator>
    </item>
    <item>
      <title>Load Balancing For High Performance Computing Using Quantum Annealing</title>
      <link>https://arxiv.org/abs/2403.05278</link>
      <description>arXiv:2403.05278v1 Announce Type: cross 
Abstract: With the advent of exascale computing, effective load balancing in massively parallel software applications is critically important for leveraging the full potential of high performance computing systems. Load balancing is the distribution of computational work between available processors. Here, we investigate the application of quantum annealing to load balance two paradigmatic algorithms in high performance computing. Namely, adaptive mesh refinement and smoothed particle hydrodynamics are chosen as representative grid and off-grid target applications. While the methodology for obtaining real simulation data to partition is application specific, the proposed balancing protocol itself remains completely general. In a grid based context, quantum annealing is found to outperform classical methods such as the round robin protocol but lacks a decisive advantage over more advanced methods such as steepest descent or simulated annealing despite remaining competitive. The primary obstacle to scalability is found to be limited coupling on current quantum annealing hardware. However, for the more complex particle formulation, approached as a multi-objective optimization, quantum annealing solutions are demonstrably Pareto dominant to state of the art classical methods across both objectives. This signals a noteworthy advancement in solution quality which can have a large impact on effective CPU usage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05278v1</guid>
      <category>quant-ph</category>
      <category>cs.DC</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Omer Rathore, Alastair Basden, Nicholas Chancellor, Halim Kusumaatmaja</dc:creator>
    </item>
    <item>
      <title>FedFMS: Exploring Federated Foundation Models for Medical Image Segmentation</title>
      <link>https://arxiv.org/abs/2403.05408</link>
      <description>arXiv:2403.05408v1 Announce Type: cross 
Abstract: Medical image segmentation is crucial for clinical diagnosis. The Segmentation Anything Model (SAM) serves as a powerful foundation model for visual segmentation and can be adapted for medical image segmentation. However, medical imaging data typically contain privacy-sensitive information, making it challenging to train foundation models with centralized storage and sharing. To date, there are few foundation models tailored for medical image deployment within the federated learning framework, and the segmentation performance, as well as the efficiency of communication and training, remain unexplored. In response to these issues, we developed Federated Foundation models for Medical image Segmentation (FedFMS), which includes the Federated SAM (FedSAM) and a communication and training-efficient Federated SAM with Medical SAM Adapter (FedMSA). Comprehensive experiments on diverse datasets are conducted to investigate the performance disparities between centralized training and federated learning across various configurations of FedFMS. The experiments revealed that FedFMS could achieve performance comparable to models trained via centralized training methods while maintaining privacy. Furthermore, FedMSA demonstrated the potential to enhance communication and training efficiency. Our model implementation codes are available at https://github.com/LIU-YUXI/FedFMS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05408v1</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>cs.DC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuxi Liu, Guibo Luo, Yuesheng Zhu</dc:creator>
    </item>
    <item>
      <title>We Know I Know You Know; Choreographic Programming With Multicast and Multiply Located Values</title>
      <link>https://arxiv.org/abs/2403.05417</link>
      <description>arXiv:2403.05417v1 Announce Type: cross 
Abstract: Concurrent distributed systems are notoriously difficult to construct and reason about. Choreographic programming is a recent paradigm that describes a distributed system in a single global program called a choreography. Choreographies simplify reasoning about distributed systems and can ensure deadlock freedom by static analysis. In previous choreographic programming languages, each value is located at a single party, and the programmer is expected to insert special untyped "select" operations to ensure that all parties follow the same communication pattern.
  We present He-Lambda-Small, a new choreographic programming language with Multiply Located Values. He-Lambda-Small allows multicasting to a set of parties, and the resulting value will be located at all of them. This approach enables a simple and elegant alternative to "select": He-Lambda-Small requires that the guard for a conditional be located at all of the relevant parties. In He-Lambda-Small, checking that a choreography is well-typed suffices to show that it is deadlock-free. We present several case studies that demonstrate the use of multiply-located values to concisely encode tricky communication patterns described in previous work without the use of "select" or redundant communication.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05417v1</guid>
      <category>cs.PL</category>
      <category>cs.DC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mako Bates, Joe Near</dc:creator>
    </item>
    <item>
      <title>Design, Configuration, Implementation, and Performance of a Simple 32 Core Raspberry Pi Cluster</title>
      <link>https://arxiv.org/abs/1708.05264</link>
      <description>arXiv:1708.05264v2 Announce Type: replace 
Abstract: In this report, I describe the design and implementation of an inexpensive, eight node, 32 core, cluster of raspberry pi single board computers, as well as the performance of this cluster on two computational tasks, one that requires significant data transfer relative to computational time requirements, and one that does not. We have two use-cases for the cluster: (a) as an educational tool for classroom usage, such as covering parallel algorithms in an algorithms course; and (b) as a test system for use during the development of parallel metaheuristics, essentially serving as a personal desktop parallel computing cluster. Our preliminary results show that the slow 100 Mbps networking of the raspberry pi significantly limits such clusters to parallel computational tasks that are either long running relative to data communications requirements, or that which requires very little internode communications. Additionally, although the raspberry pi 3 has a quad-core processor, parallel speedup degrades during attempts to utilize all four cores of all cluster nodes for a parallel computation, likely due to resource contention with operating system level processes. However, distributing a task across three cores of each cluster node does enable linear (or near linear) speedup.</description>
      <guid isPermaLink="false">oai:arXiv.org:1708.05264v2</guid>
      <category>cs.DC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vincent A. Cicirello</dc:creator>
    </item>
    <item>
      <title>Energy Efficient Offloading Policies in Multi-Access Edge Computing Systems with Task Handover</title>
      <link>https://arxiv.org/abs/2306.15185</link>
      <description>arXiv:2306.15185v2 Announce Type: replace 
Abstract: We study energy-efficient offloading strategies in a large-scale MEC system with heterogeneous mobile users and network components. The system is considered with enabled user-task handovers that capture the mobility of various mobile users. We focus on a long-run objective and online algorithms that are applicable to realistic systems. The problem is significantly complicated by the large problem size, the heterogeneity of user tasks and network components, and the mobility of the users, for which conventional optimizers cannot reach optimum with a reasonable amount of computational and storage power. We formulate the problem in the vein of the restless multi-armed bandit process that enables the decomposition of high-dimensional state spaces and then achieves near-optimal algorithms applicable to realistically large problems in an online manner. Following the restless bandit technique, we propose two offloading policies by prioritizing the least marginal costs of selecting the corresponding computing and communication resources in the edge and cloud networks. This coincides with selecting the resources with the highest energy efficiency. Both policies are scalable to the offloading problem with a great potential to achieve proved asymptotic optimality - approach optimality as the problem size tends to infinity. With extensive numerical simulations, the proposed policies are demonstrated to clearly outperform baseline policies with respect to power conservation and robust to the tested heavy-tailed lifespan distributions of the offloaded tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.15185v2</guid>
      <category>cs.DC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ling Hou, Jingjin Wu, Jing Fu</dc:creator>
    </item>
    <item>
      <title>Process-Commutative Distributed Objects: From Cryptocurrencies to Byzantine-Fault-Tolerant CRDTs</title>
      <link>https://arxiv.org/abs/2311.13936</link>
      <description>arXiv:2311.13936v2 Announce Type: replace 
Abstract: This paper explores the territory that lies between best-effort Byzantine-Fault-Tolerant Conflict-free Replicated Data Types (BFT CRDTs) and totally ordered distributed ledgers, such as those implemented by Blockchains. It formally characterizes a novel class of distributed objects that only requires a First In First Out (FIFO) order on the object operations from each process (taken individually). The formalization leverages Mazurkiewicz traces to define legal sequences of operations and ensure both Strong Eventual Consistency (SEC) and Pipleline Consistency (PC). The paper presents a generic algorithm that implements this novel class of distributed objects both in a crash- and Byzantine setting. It also illustrates the practical interest of the proposed approach using four instances of this class of objects, namely money transfer, Petri nets, multi-sets, and concurrent work stealing dequeues.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.13936v2</guid>
      <category>cs.DC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Davide Frey, Lucie Guillou, Michel Raynal, Fran\c{c}ois Ta\"iani</dc:creator>
    </item>
    <item>
      <title>Junctiond: Extending FaaS Runtimes with Kernel-Bypass</title>
      <link>https://arxiv.org/abs/2403.03377</link>
      <description>arXiv:2403.03377v2 Announce Type: replace 
Abstract: This report explores the use of kernel-bypass networking in FaaS runtimes and demonstrates how using Junction, a novel kernel-bypass system, as the backend for executing components in faasd can enhance performance and isolation. Junction achieves this by reducing network and compute overheads and minimizing interactions with the host operating system. Junctiond, the integration of Junction with faasd, reduces median and P99 latency by 37.33% and 63.42%, respectively, and can handle 10 times more throughput while decreasing latency by 2x at the median and 3.5 times at the tail.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.03377v2</guid>
      <category>cs.DC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Enrique Saurez, Joshua Fried, Gohar Irfan Chaudhry, Esha Choukse, \'I\~nigo Goiri, Sameh Elnikety, Adam Belay, Rodrigo Fonseca</dc:creator>
    </item>
    <item>
      <title>Portable, heterogeneous ensemble workflows at scale using libEnsemble</title>
      <link>https://arxiv.org/abs/2403.03709</link>
      <description>arXiv:2403.03709v2 Announce Type: replace 
Abstract: libEnsemble is a Python-based toolkit for running dynamic ensembles, developed as part of the DOE Exascale Computing Project. The toolkit utilizes a unique generator-simulator-allocator paradigm, where generators produce input for simulators, simulators evaluate those inputs, and allocators decide whether and when a simulator or generator should be called. The generator steers the ensemble based on simulation results.
  libEnsemble communicates between a manager and workers. Flexibility is provided through multiple manager-worker communication substrates each of which has different benefits. These include Python's multiprocessing, mpi4py, and TCP. Multisite ensembles are supported using Balsam or Globus Compute.
  We overview the unique characteristics of libEnsemble as well as current and potential interoperability with other packages in the workflow ecosystem. We highlight libEnsemble's dynamic resource features: libEnsemble can detect system resources (nodes, cores, and GPUs) and assign these in a portable way. These features allow users to specify resources required for each simulation automatically on a range of systems, including Frontier, Aurora, and Perlmutter. Such ensembles can include multiple simulation types, some using GPUs and others using only CPUs, sharing nodes for maximum efficiency.
  We demonstrate libEnsemble's capabilities, scalability, and scientific impact via a Gaussian process surrogate training problem for the longitudinal density profile at the exit of a plasma accelerator stage using Wake-T and WarpX simulations. We also describe the benefits of libEnsemble's generator-simulator coupling, which easily exposes to the user the ability to cancel, and portably kill, running simulations. Such control can be directed from the generator or allocator based on models that are updated with intermediate simulation output.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.03709v2</guid>
      <category>cs.DC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stephen Hudson, Jeffrey Larson, John-Luke Navarro, Stefan M. Wild</dc:creator>
    </item>
  </channel>
</rss>
