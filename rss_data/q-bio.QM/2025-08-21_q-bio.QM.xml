<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.QM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.QM</link>
    <description>q-bio.QM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.QM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 21 Aug 2025 04:01:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 21 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>High-Throughput Low-Cost Segmentation of Brightfield Microscopy Live Cell Images</title>
      <link>https://arxiv.org/abs/2508.14106</link>
      <description>arXiv:2508.14106v1 Announce Type: new 
Abstract: Live cell culture is crucial in biomedical studies for analyzing cell properties and dynamics in vitro. This study focuses on segmenting unstained live cells imaged with bright-field microscopy. While many segmentation approaches exist for microscopic images, none consistently address the challenges of bright-field live-cell imaging with high throughput, where temporal phenotype changes, low contrast, noise, and motion-induced blur from cellular movement remain major obstacles. We developed a low-cost CNN-based pipeline incorporating comparative analysis of frozen encoders within a unified U-Net architecture enhanced with attention mechanisms, instance-aware systems, adaptive loss functions, hard instance retraining, dynamic learning rates, progressive mechanisms to mitigate overfitting, and an ensemble technique. The model was validated on a public dataset featuring diverse live cell variants, showing consistent competitiveness with state-of-the-art methods, achieving 93% test accuracy and an average F1-score of 89% (std. 0.07) on low-contrast, noisy, and blurry images. Notably, the model was trained primarily on bright-field images with limited exposure to phase-contrast microscopy (&lt;10%), yet it generalized effectively to the phase-contrast LIVECell dataset, demonstrating modality, robustness and strong performance. This highlights its potential for real-world laboratory deployment across imaging conditions. The model requires minimal compute power and is adaptable using basic deep learning setups such as Google Colab, making it practical for training on other cell variants. Our pipeline outperforms existing methods in robustness and precision for bright-field microscopy segmentation. The code and dataset are available for reproducibility</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.14106v1</guid>
      <category>q-bio.QM</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>eess.IV</category>
      <pubDate>Thu, 21 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Surajit Das, Gourav Roy, Pavel Zun</dc:creator>
    </item>
    <item>
      <title>piCurve: an R package for modeling photosynthesis-irradiance curves</title>
      <link>https://arxiv.org/abs/2508.14321</link>
      <description>arXiv:2508.14321v1 Announce Type: cross 
Abstract: Photosynthesis-irradiance (PI) curves are foundational for quantifying primary production, parameterizing ecosystem and biogeochemical models, and interpreting physiological acclimation to light. Despite their broad use, researchers lack a unified, reproducible toolkit to fit, compare, and diagnose the many PI formulations that have accumulated over the last century. We introduce piCurve, an R package that standardizes the modeling of PI relationships, with a library of widely used light-limited, light-saturated, and photoinhibited formulations and a consistent statistical framework for estimation and comparison. With the total of 24 PI models, piCurve supports mean squared error (MSE) and maximum likelihood estimation (MLE), provides uncertainty quantification via information matrix (Hessian), and includes automated, data-informed initialization to improve convergence. Utilities classify PI data into light-limited, light-saturated, and photoinhibited regions, while plotting and 'tidy' helpers streamline workflow and reporting. Together, these features enable reproducible analyses and fair model comparisons, including for curves exhibiting a plateau followed by photoinhibition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.14321v1</guid>
      <category>stat.AP</category>
      <category>q-bio.QM</category>
      <category>stat.CO</category>
      <pubDate>Thu, 21 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad M. Amirian, Andrew J. Irwin</dc:creator>
    </item>
    <item>
      <title>DeepRetro: Retrosynthetic Pathway Discovery using Iterative LLM Reasoning</title>
      <link>https://arxiv.org/abs/2507.07060</link>
      <description>arXiv:2507.07060v2 Announce Type: replace 
Abstract: The synthesis of complex natural products remains one of the grand challenges of organic chemistry. We present DeepRetro, a major advancement in computational retrosynthesis that enables the discovery of viable synthetic routes for complex molecules typically considered beyond the reach of existing retrosynthetic methods. DeepRetro is a novel, open-source framework that tightly integrates large language models (LLMs), traditional retrosynthetic engines, and expert human feedback in an iterative design loop. Prior approaches rely solely on template-based methods or unconstrained LLM outputs. In contrast, DeepRetro combines the precision of template-based methods with the generative flexibility of LLMs, controlled by rigorous chemical validity checks and enhanced by recursive refinement. This hybrid system dynamically explores and revises synthetic pathways, guided by both algorithmic checks and expert chemist feedback through an interactive user interface. While DeepRetro achieves strong performance on standard retrosynthesis benchmarks, its true strength lies in its ability to propose novel, viable pathways to highly complex natural products-targets that have historically eluded automated planning. Through detailed case studies, we illustrate how this approach enables new routes for total synthesis and facilitates human-machine collaboration in organic chemistry. Beyond retrosynthesis, DeepRetro represents a working model for how to leverage LLMs in scientific discovery. We provide a transparent account of the system's design, algorithms, and human-feedback loop, enabling broad adaptation across scientific domains. By releasing DeepRetro as an open-source tool, we aim to empower chemists to tackle increasingly ambitious synthetic targets, accelerating progress in drug discovery, materials design, and beyond.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07060v2</guid>
      <category>q-bio.QM</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <category>q-bio.BM</category>
      <category>q-bio.MN</category>
      <pubDate>Thu, 21 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shreyas Vinaya Sathyanarayana, Sharanabasava D. Hiremath, Rahil Shah, Rishikesh Panda, Rahul Jana, Riya Singh, Rida Irfan, Ashwin Murali, Bharath Ramsundar</dc:creator>
    </item>
    <item>
      <title>A likelihood-based Bayesian inference framework for the calibration of and selection between stochastic velocity-jump models</title>
      <link>https://arxiv.org/abs/2505.19292</link>
      <description>arXiv:2505.19292v2 Announce Type: replace-cross 
Abstract: Advances in experimental techniques allow the collection of high-resolution spatio-temporal data that track individual motile entities. These tracking data can be used to calibrate mathematical models describing the motility of individual entities. The challenges in calibrating models for single-agent motion derive from the intrinsic characteristics of experimental data, collected at discrete time steps and with measurement noise. We consider motion of individual agents that can be described by velocity-jump models in one spatial dimension. These agents transition between a network of \textit{n} states, in which each state is associated with a fixed velocity and fixed rates of switching to every other state. Exploiting approximate solutions to the resultant stochastic process, we develop a Bayesian inference framework to calibrate these models to discrete-time noisy data. We first demonstrate that the framework can be used to effectively recover the model parameters of data simulated from two-state and three-state models. Finally, we explore the question of model selection first using simulated data and then using experimental data tracking mRNA transport inside \textit{Drosophila} neurons. Overall, our results demonstrate that the framework is effective and efficient in calibrating and selecting between velocity-jump models and it can be applied to a range of motion processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19292v2</guid>
      <category>stat.ME</category>
      <category>q-bio.QM</category>
      <pubDate>Thu, 21 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arianna Ceccarelli, Alexander P. Browning, Tai Chaiamarit, Ilan Davis, Ruth E. Baker</dc:creator>
    </item>
  </channel>
</rss>
