<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DM</link>
    <description>cs.DM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 28 Jan 2025 03:45:51 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Low rank matrix completion and realization of graphs: results and problems</title>
      <link>https://arxiv.org/abs/2501.13935</link>
      <description>arXiv:2501.13935v1 Announce Type: cross 
Abstract: The Netflix problem (from machine learning) asks the following. Given a ratings matrix in which each entry $(i,j)$ represents the rating of movie $j$ by customer $i$, if customer $i$ has watched movie $j$, and is otherwise missing, we would like to predict the remaining entries in order to make good recommendations to customers on what to watch next. The remaining entries are predicted so as to minimize the {\it rank} of the completed matrix.
  In this survey we study a more general problem, in which instead of knowing specific matrix elements, we know linear relations on such elements. We describe applications of these results to embeddings of graphs in surfaces (more precisely, embeddings with rotation systems, and embeddings modulo 2).</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13935v1</guid>
      <category>math.HO</category>
      <category>cs.DM</category>
      <category>cs.LG</category>
      <category>math.CO</category>
      <category>math.GT</category>
      <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>S. Dzhenzher, T. Garaev, O. Nikitenko, A. Petukhov, A. Skopenkov, A. Voropaev</dc:creator>
    </item>
    <item>
      <title>Incremental SAT-Based Enumeration of Solutions to the Yang-Baxter Equation</title>
      <link>https://arxiv.org/abs/2501.14363</link>
      <description>arXiv:2501.14363v1 Announce Type: cross 
Abstract: We tackle the problem of enumerating set-theoretic solutions to the Yang-Baxter equation. This equation originates from statistical and quantum mechanics, but also has applications in knot theory, cryptography, quantum computation and group theory. Non-degenerate, involutive solutions have been enumerated for sets up to size 10 using constraint programming with partial static symmetry breaking; for general non-involutive solutions, a similar approach was used to enumerate solutions for sets up to size 8. In this paper, we use and extend the SAT Modulo Symmetries framework (SMS), to expand the boundaries for which solutions are known. The SMS framework relies on a minimality check; we present two solutions to this, one that stays close to the original one designed for enumerating graphs and a new incremental, SAT-based approach. With our new method, we can reproduce previously known results much faster and also report on results for sizes that have remained out of reach so far. This is an extended version of a paper to appear in the proceedings of the 31st International Conference on Tools and Algorithms for the Construction and Analysis of Systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14363v1</guid>
      <category>cs.LO</category>
      <category>cs.DM</category>
      <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daimy Van Caudenberg, Bart Bogaerts, Leandro Vendramin</dc:creator>
    </item>
    <item>
      <title>Convergence of gradient based training for linear Graph Neural Networks</title>
      <link>https://arxiv.org/abs/2501.14440</link>
      <description>arXiv:2501.14440v1 Announce Type: cross 
Abstract: Graph Neural Networks (GNNs) are powerful tools for addressing learning problems on graph structures, with a wide range of applications in molecular biology and social networks. However, the theoretical foundations underlying their empirical performance are not well understood. In this article, we examine the convergence of gradient dynamics in the training of linear GNNs. Specifically, we prove that the gradient flow training of a linear GNN with mean squared loss converges to the global minimum at an exponential rate. The convergence rate depends explicitly on the initial weights and the graph shift operator, which we validate on synthetic datasets from well-known graph models and real-world datasets. Furthermore, we discuss the gradient flow that minimizes the total weights at the global minimum. In addition to the gradient flow, we study the convergence of linear GNNs under gradient descent training, an iterative scheme viewed as a discretization of gradient flow.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14440v1</guid>
      <category>cs.LG</category>
      <category>cs.DM</category>
      <category>cs.NA</category>
      <category>cs.SI</category>
      <category>math.NA</category>
      <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dhiraj Patel, Anton Savostianov, Michael T. Schaub</dc:creator>
    </item>
    <item>
      <title>Open Problems in Continuous Graphs</title>
      <link>https://arxiv.org/abs/2501.14554</link>
      <description>arXiv:2501.14554v1 Announce Type: cross 
Abstract: Inspired by notorious combinatorial optimization problems on graphs, in this paper we propose a series of related problems defined using a metric space and topology determined by a graph. Particularly, we present Independent Set, Vertex Cover, Chromatic Number and Treewidth problems on, so-called, continuous graphs where every edge is represented by a unit-length continuous interval rather than by a pair of vertices. If any point of any unit-interval edge is considered as a possible member of a hitting set or a cover, the classical combinatorial problems become trickier and many open questions arise. Notably, in many real-life applications, such continuous view on a graph is more natural than the classic combinatorial definition of a graph.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14554v1</guid>
      <category>math.CO</category>
      <category>cs.DM</category>
      <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Grigoriev, Katherine Faulkner</dc:creator>
    </item>
    <item>
      <title>Tree independence number V. Walls and claws</title>
      <link>https://arxiv.org/abs/2501.14658</link>
      <description>arXiv:2501.14658v1 Announce Type: cross 
Abstract: Given a family $\mathcal{H}$ of graphs, we say that a graph $G$ is $\mathcal{H}$-free if no induced subgraph of $G$ is isomorphic to a member of $\mathcal{H}$. Let $S_{t,t,t}$ be the graph obtained from $K_{1,3}$ by subdividing each edge $t-1$ times, and let $W_{t\times t}$ be the $t$-by-$t$ hexagonal grid. Let $\mathcal{L}_t$ be the family of all graphs $G$ such that $G$ is the line graph of some subdivision of $W_{t \times t}$. We prove that for every positive integer $t$ there exists $c(t)$ such that every $\mathcal{L}_t \cup \{S_{t,t,t}, K_{t,t}\}$-free $n$-vertex graph admits a tree decomposition in which the maximum size of an independent set in each bag is at most $c(t)\log^4n$. This is a variant of a conjecture of Dallard, Krnc, Kwon, Milani\v{c}, Munaro, \v{S}torgel, and Wiederrecht from 2024. This implies that the Maximum Weight Independent Set problem, as well as many other natural algorithmic problems, that are known to be NP-hard in general, can be solved in quasi-polynomial time if the input graph is $\mathcal{L}_t \cup \{S_{t,t,t},K_{t,t}\}$-free. As part of our proof, we show that for every positive integer $t$ there exists an integer $d$ such that every $\mathcal{L}_t \cup \{S_{t,t,t}\}$-free graph admits a balanced separator that is contained in the neighborhood of at most $d$ vertices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14658v1</guid>
      <category>math.CO</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maria Chudnovsky, Julien Codsi, Daniel Lokshtanov, Martin Milani\v{c}, Varun Sivashankar</dc:creator>
    </item>
    <item>
      <title>Efficient Sparse Flow Decomposition Methods for RNA Multi-Assembly</title>
      <link>https://arxiv.org/abs/2501.14662</link>
      <description>arXiv:2501.14662v1 Announce Type: cross 
Abstract: Decomposing a flow on a Directed Acyclic Graph (DAG) into a weighted sum of a small number of paths is an essential task in operations research and bioinformatics. This problem, referred to as Sparse Flow Decomposition (SFD), has gained significant interest, in particular for its application in RNA transcript multi-assembly, the identification of the multiple transcripts corresponding to a given gene and their relative abundance. Several recent approaches cast SFD variants as integer optimization problems, motivated by the NP-hardness of the formulations they consider. We propose an alternative formulation of SFD as a fitting problem on the conic hull of the flow polytope. By reformulating the problem on the flow polytope for compactness and solving it using specific variants of the Frank-Wolfe algorithm, we obtain a method converging rapidly to the minimizer of the chosen loss function while producing a parsimonious decomposition. Our approach subsumes previous formulations of SFD with exact and inexact flows and can model different priors on the error distributions. Computational experiments show that our method outperforms recent integer optimization approaches in runtime, but is also highly competitive in terms of reconstruction of the underlying transcripts, despite not explicitly minimizing the solution cardinality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14662v1</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mathieu Besan\c{c}on</dc:creator>
    </item>
    <item>
      <title>Certificates in P and Subquadratic-Time Computation of Radius, Diameter, and all Eccentricities in Graphs</title>
      <link>https://arxiv.org/abs/1803.04660</link>
      <description>arXiv:1803.04660v4 Announce Type: replace 
Abstract: In the context of fine-grained complexity, we investigate the notion of certificate enabling faster polynomial-time algorithms. We specifically target radius (minimum eccentricity), diameter (maximum eccentricity), and all-eccentricity computations for which quadratic-time lower bounds are known under plausible conjectures. In each case, we introduce a notion of certificate as a specific set of nodes from which appropriate bounds on all eccentricities can be derived in subquadratic time when this set has sublinear size. The existence of small certificates is a barrier against SETH-based lower bounds for these problems. We indeed prove that for graph classes with small certificates, there exist randomized subquadratic-time algorithms for computing the radius, the diameter, and all eccentricities respectively.Moreover, these notions of certificates are tightly related to algorithms probing the graph through one-to-all distance queries and allow to explain the efficiency of practical radius and diameter algorithms from the literature. Our formalization enables a novel primal-dual analysis of a classical approach for diameter computation that leads to algorithms for radius, diameter and all eccentricities with theoretical guarantees with respect to certain graph parameters. This is complemented by experimental results on various types of real-world graphs showing that these parameters appear to be low in practice. Finally, we obtain refined results for several graph classes.</description>
      <guid isPermaLink="false">oai:arXiv.org:1803.04660v4</guid>
      <category>cs.DM</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>cs.NI</category>
      <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1137/1.9781611978322.70</arxiv:DOI>
      <arxiv:journal_reference>Proceedings of the 2025 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), Jan 2025, New Orleans (LA), United States. pp.2157-2193</arxiv:journal_reference>
      <dc:creator>Feodor F. Dragan (UniBuc, ICI), Guillaume Ducoffe (UniBuc, ICI), Michel Habib (IRIF), Laurent Viennot (DI-ENS, ARGO)</dc:creator>
    </item>
    <item>
      <title>SDPs and Robust Satisfiability of Promise CSP</title>
      <link>https://arxiv.org/abs/2211.08373</link>
      <description>arXiv:2211.08373v4 Announce Type: replace-cross 
Abstract: For a constraint satisfaction problem (CSP), a robust satisfaction algorithm is one that outputs an assignment satisfying most of the constraints on instances that are near-satisfiable. It is known that the CSPs that admit efficient robust satisfaction algorithms are precisely those of bounded width, i.e., CSPs whose satisfiability can be checked by a simple local consistency algorithm (eg., 2-SAT or Horn-SAT in the Boolean case). While the exact satisfiability of a bounded width CSP can be checked by combinatorial algorithms, the robust algorithm is based on rounding a canonical Semidefinite Programming (SDP) relaxation.
  In this work, we initiate the study of robust satisfaction algorithms for promise CSPs, which are a vast generalization of CSPs that have received much attention recently. The motivation is to extend the theory beyond CSPs, as well as to better understand the power of SDPs. We present robust SDP rounding algorithms under some general conditions, namely the existence of particular high-dimensional Boolean symmetries known as majority or alternating threshold polymorphisms. On the hardness front, we prove that the lack of such polymorphisms makes the PCSP hard for all pairs of symmetric Boolean predicates. Our approach relies on SDP integrality gaps argued via the absence of certain colorings of the sphere, with connections to sphere Ramsey theory.
  We conjecture that PCSPs with robust satisfaction algorithms are precisely those for which the feasibility of the canonical SDP implies (exact) satisfiability. We also give a precise algebraic condition, known as a minion characterization, of which PCSPs have the latter property.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.08373v4</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>cs.LO</category>
      <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joshua Brakensiek, Venkatesan Guruswami, Sai Sandeep</dc:creator>
    </item>
    <item>
      <title>Discrete Single-Parameter Optimal Auction Design</title>
      <link>https://arxiv.org/abs/2406.08125</link>
      <description>arXiv:2406.08125v2 Announce Type: replace-cross 
Abstract: We study the classic single-item auction setting of Myerson, but under the assumption that the buyers' values for the item are distributed over finite supports. Using strong LP duality and polyhedral theory, we rederive various key results regarding the revenue-maximizing auction, including the characterization through virtual welfare maximization and the optimality of deterministic mechanisms, as well as a novel, generic equivalence between dominant-strategy and Bayesian incentive compatibility.
  Inspired by this, we abstract our approach to handle more general auction settings, where the feasibility space can be given by arbitrary convex constraints, and the objective is a convex combination of revenue and social welfare. We characterize the optimal auctions of such systems as generalized virtual welfare maximizers, by making use of their KKT conditions, and we present an analogue of Myerson's payment formula for general discrete single-parameter auction settings. Additionally, we prove that total unimodularity of the feasibility space is a sufficient condition to guarantee the optimality of auctions with integral allocation rules.
  Finally, we demonstrate this KKT approach by applying it to a setting where bidders are interested in buying feasible flows on trees with capacity constraints, and provide a combinatorial description of the (randomized, in general) optimal auction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.08125v2</guid>
      <category>cs.GT</category>
      <category>cs.DM</category>
      <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yiannis Giannakopoulos, Johannes Hahn</dc:creator>
    </item>
    <item>
      <title>Color Refinement for Relational Structures</title>
      <link>https://arxiv.org/abs/2407.16022</link>
      <description>arXiv:2407.16022v2 Announce Type: replace-cross 
Abstract: Color Refinement, also known as Naive Vertex Classification, is a classical method to distinguish graphs by iteratively computing a coloring of their vertices. While it is mainly used as an imperfect way to test for isomorphism, the algorithm permeated many other, seemingly unrelated, areas of computer science. The method is algorithmically simple, and it has a well-understood distinguishing power: It is logically characterized by Cai, F\"urer and Immerman (1992), who showed that it distinguishes precisely those graphs that can be distinguished by a sentence of first-order logic with counting quantifiers and only two variables. A combinatorial characterization is given by Dvo\v{r}\'ak (2010), who shows that it distinguishes precisely those graphs that can be distinguished by the number of homomorphisms from some tree.
  In this paper, we introduce Relational Color Refinement (RCR, for short), a generalization of the Color Refinement method from graphs to arbitrary relational structures, whose distinguishing power admits the equivalent combinatorial and logical characterizations as Color Refinement has on graphs: We show that RCR distinguishes precisely those structures that can be distinguished by the number of homomorphisms from an acyclic relational structure. Further, we show that RCR distinguishes precisely those structures that can be distinguished by a sentence of the guarded fragment of first-order logic with counting quantifiers.
  Additionally, we show that for every fixed finite relational signature, RCR can be implemented to run on structures of that signature in time $O(N\cdot \log N)$, where $N$ denotes the number of tuples present in the structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16022v2</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>cs.LO</category>
      <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Benjamin Scheidt, Nicole Schweikardt</dc:creator>
    </item>
  </channel>
</rss>
