<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 29 Mar 2024 04:00:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 29 Mar 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Primer on Gibsonian Information</title>
      <link>https://arxiv.org/abs/2403.18829</link>
      <description>arXiv:2403.18829v1 Announce Type: new 
Abstract: Across the scientific literature, information measurement in the nervous system is posed as a problem of information processing internal to the brain by constructs such as neuronal populations, sensory surprise, or cognitive models. Application of information theory in the nervous system has focused on measuring phenomena such as capacity and integration. Yet the ecological perspective suggests that information is a product of active perception and interactions with the environment. Here, we propose Gibsonian Information (GI), relevant to both the study of cognitive agents and single cell systems that exhibit cognitive behaviors. We propose a formal model of GI that characterizes how agents extract environmental information in a dynamic fashion. GI demonstrates how sensory information guides information processing within individual nervous system representations of motion and continuous multisensory integration, as well as representations that guide collective behaviors. GI is useful for understanding first-order sensory inputs in terms of agent interactions with naturalistic contexts and simple internal representations and can be extended to cybernetic or symbolic representations. Statistical affordances, or clustered information that is spatiotemporally dependent perceptual input, facilitate extraction of GI from the environment. As a quantitative accounting of perceptual information, GI provides a means to measure a generalized indicator of nervous system input and can be characterized by three scenarios: disjoint distributions, contingent action, and coherent movement. By applying this framework to a variety of specific contexts, including a four-channel model of multisensory embodiment, we demonstrate how GI is essential to understanding the full scope of cognitive information processing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18829v1</guid>
      <category>q-bio.NC</category>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bradly Alicea, Daniela Cialfi, Avery Lim, Jesse Parent</dc:creator>
    </item>
    <item>
      <title>Are Colors Quanta of Light for Human Vision? A Quantum Cognition Study of Visual Perception</title>
      <link>https://arxiv.org/abs/2403.18850</link>
      <description>arXiv:2403.18850v1 Announce Type: new 
Abstract: We study the phenomenon of categorical perception within the quantum measurement process. The mechanism underlying this phenomenon consists in dilating stimuli being perceived to belong to different categories and contracting stimuli being perceived to belong to the same category. We show that, due to the naturally different way in determining the distance between pure states compared to the distance between density states, the phenomenon of categorical perception is rooted in the structure of the quantum measurement process itself. We apply our findings to the situation of visual perception of colors and argue that it is possible to consider colors as light quanta for human visual perception in a similar way as photons are light quanta for physical measurements of light frequencies. In our approach we see perception as a complex encounter between the existing physical reality, the stimuli, and the reality expected by the perciever, resulting in the experience of the percepts. We investigate what that means for the situation of two colors, which we call Light and Dark, given our findings on categorical perception within the quantum measurement process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18850v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>quant-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonito Aerts Argu\"elles</dc:creator>
    </item>
    <item>
      <title>Structural Brain Connectivity and Treatment Improvement in Mood Disorder</title>
      <link>https://arxiv.org/abs/2403.18862</link>
      <description>arXiv:2403.18862v1 Announce Type: new 
Abstract: Background: The treatment of depressive episodes is well established, with clearly demonstrated effectiveness of antidepressants and psychotherapies. However, more than one-third of depressed patients do not respond to treatment. Identifying the brain structural basis of treatment-resistant depression could prevent useless pharmacological prescriptions,adverse events, and lost therapeutic opportunities.Methods: Using diffusion magnetic resonance imaging, we performed structural connectivity analyses on a cohort of 154 patients with mood disorder (MD) -- and 77 sex- and age-matched healthy control (HC) participants. To assess illness improvement, the MD patients went through two clinical interviews at baseline and at 6-month follow-up and were classified based on the Clinical Global Impression-Improvement score into improved or not-improved. First, the threshold-free network-based statistics was conducted to measure the differences in regional network architecture. Second, nonparametric permutations tests were performed on topological metrics based on graph theory to examine differences in connectome organization. Results: The threshold-free network-based statistics revealed impaired connections involvingregions of the basal ganglia in MD patients compared to HC. Significant increase of local efficiency and clustering coefficient was found in the lingual gyrus, insula and amygdala in the MD group. Compared with the not-improved, the improved displayed significantly reduced network integration and segregation, predominately in the default-mode regions, including the precuneus, middle temporal lobe and rostral anterior cingulate.Conclusions: This study highlights the involvement of regions belonging to the basal ganglia, the fronto-limbic network and the default mode network, leading to a better understanding of MD disease and its unfavorable outcome.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18862v1</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>S\'ebastien Dam (UR, Inria, CNRS, IRISA, EMPENN), Jean-Marie Batail (CHGR), Gabriel H Robert (UR, Inria, CNRS, IRISA, EMPENN, CHGR), Dominique Drapier (CHGR), Pierre Maurel (UR, Inria, CNRS, IRISA, EMPENN), Julie Coloigner (UR, Inria, CNRS, IRISA, EMPENN)</dc:creator>
    </item>
    <item>
      <title>In the driver's mind: modeling the dynamics of human overtaking decisions in interactions with oncoming automated vehicles</title>
      <link>https://arxiv.org/abs/2403.19637</link>
      <description>arXiv:2403.19637v1 Announce Type: new 
Abstract: Understanding human behavior in overtaking scenarios is crucial for enhancing road safety in mixed traffic with automated vehicles (AVs). Computational models of behavior play a pivotal role in advancing this understanding, as they can provide insight into human behavior generalizing beyond empirical studies. However, existing studies and models of human overtaking behavior have mostly focused on scenarios with simplistic, constant-speed dynamics of oncoming vehicles, disregarding the potential of AVs to proactively influence the decision-making process of the human drivers via implicit communication. Furthermore, so far it remained unknown whether overtaking decisions of human drivers are affected by whether they are interacting with an AV or a human-driven vehicle (HDV). To address these gaps, we conducted a "reverse Wizard-of-Oz" driving simulator experiment with 30 participants who repeatedly interacted with oncoming AVs and HDVs, measuring the drivers' gap acceptance decisions and response times. The oncoming vehicles featured time-varying dynamics designed to influence the overtaking decisions of the participants by briefly decelerating and then recovering to their initial speed. We found that participants did not alter their overtaking behavior when interacting with oncoming AVs compared to HDVs. Furthermore, we did not find any evidence of brief decelerations of the oncoming vehicle affecting the decisions or response times of the participants. Cognitive modeling of the obtained data revealed that a generalized drift-diffusion model with dynamic drift rate and velocity-dependent decision bias best explained the gap acceptance outcomes and response times observed in the experiment. Overall, our findings highlight the potential of cognitive models for further advancing the ongoing development of safer interactions between human drivers and AVs during overtaking maneuvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.19637v1</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Samir H. A. Mohammad, Haneen Farah, Arkady Zgonnikov</dc:creator>
    </item>
    <item>
      <title>Intuitive control of myoelectric prostheses with agonist-antagonist interface and magnetomicrometery: narrative review</title>
      <link>https://arxiv.org/abs/2403.18824</link>
      <description>arXiv:2403.18824v1 Announce Type: cross 
Abstract: Proprioception is crucial in intuitive control of prosthetic limbs and therefor contributes to intuitive prosthetic use. The agonist-antagonist myoneural interface (AMI) is an prosthetic innovation with enhanced control, reduced pain, and heightened proprioceptive sensation in clinical experiments. Furthermore, studies have addressed surgical techniques to make this myoelectric interface available to a larger group of patients. A narrative review on AMI developmental process, surgical implementations, and validation has been conducted for clinical and pre-clinical experimental research, embedded in a theoretical background on feedback control and proprioception. The closing chapter on magnetomicrometery serves to illustrate how motor control reading, as an example component, can benefit from technical innovations to enhance intuitive prosthetic control in AMI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18824v1</guid>
      <category>physics.med-ph</category>
      <category>physics.bio-ph</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ivan R. Slootweg</dc:creator>
    </item>
    <item>
      <title>Bridging Generative Networks with the Common Model of Cognition</title>
      <link>https://arxiv.org/abs/2403.18827</link>
      <description>arXiv:2403.18827v1 Announce Type: cross 
Abstract: This article presents a theoretical framework for adapting the Common Model of Cognition to large generative network models within the field of artificial intelligence. This can be accomplished by restructuring modules within the Common Model into shadow production systems that are peripheral to a central production system, which handles higher-level reasoning based on the shadow productions' output. Implementing this novel structure within the Common Model allows for a seamless connection between cognitive architectures and generative neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18827v1</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Robert L. West, Spencer Eckler, Brendan Conway-Smith, Nico Turcas, Eilene Tomkins-Flanagan, Mary Alexandria Kelly</dc:creator>
    </item>
    <item>
      <title>Using Quantum Computing to Infer Dynamic Behaviors of Biological and Artificial Neural Networks</title>
      <link>https://arxiv.org/abs/2403.18963</link>
      <description>arXiv:2403.18963v1 Announce Type: cross 
Abstract: The exploration of new problem classes for quantum computation is an active area of research. An essentially completely unexplored topic is the use of quantum algorithms and computing to explore and ask questions \textit{about} the functional dynamics of neural networks. This is a component of the still-nascent topic of applying quantum computing to the modeling and simulations of biological and artificial neural networks. In this work, we show how a carefully constructed set of conditions can use two foundational quantum algorithms, Grover and Deutsch-Josza, in such a way that the output measurements admit an interpretation that guarantees we can infer if a simple representation of a neural network (which applies to both biological and artificial networks) after some period of time has the potential to continue sustaining dynamic activity. Or whether the dynamics are guaranteed to stop either through 'epileptic' dynamics or quiescence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18963v1</guid>
      <category>quant-ph</category>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gabriel A. Silva</dc:creator>
    </item>
    <item>
      <title>Cross--domain Fiber Cluster Shape Analysis for Language Performance Cognitive Score Prediction</title>
      <link>https://arxiv.org/abs/2403.19001</link>
      <description>arXiv:2403.19001v1 Announce Type: cross 
Abstract: Shape plays an important role in computer graphics, offering informative features to convey an object's morphology and functionality. Shape analysis in brain imaging can help interpret structural and functionality correlations of the human brain. In this work, we investigate the shape of the brain's 3D white matter connections and its potential predictive relationship to human cognitive function. We reconstruct brain connections as sequences of 3D points using diffusion magnetic resonance imaging (dMRI) tractography. To describe each connection, we extract 12 shape descriptors in addition to traditional dMRI connectivity and tissue microstructure features. We introduce a novel framework, Shape--fused Fiber Cluster Transformer (SFFormer), that leverages a multi-head cross-attention feature fusion module to predict subject-specific language performance based on dMRI tractography. We assess the performance of the method on a large dataset including 1065 healthy young adults. The results demonstrate that both the transformer-based SFFormer model and its inter/intra feature fusion with shape, microstructure, and connectivity are informative, and together, they improve the prediction of subject-specific language performance scores. Overall, our results indicate that the shape of the brain's connections is predictive of human language function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.19001v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>eess.IV</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yui Lo, Yuqian Chen, Dongnan Liu, Wan Liu, Leo Zekelman, Fan Zhang, Yogesh Rathi, Nikos Makris, Alexandra J. Golby, Weidong Cai, Lauren J. O'Donnell</dc:creator>
    </item>
    <item>
      <title>Topological Cycle Graph Attention Network for Brain Functional Connectivity</title>
      <link>https://arxiv.org/abs/2403.19149</link>
      <description>arXiv:2403.19149v1 Announce Type: cross 
Abstract: This study, we introduce a novel Topological Cycle Graph Attention Network (CycGAT), designed to delineate a functional backbone within brain functional graph--key pathways essential for signal transmissio--from non-essential, redundant connections that form cycles around this core structure. We first introduce a cycle incidence matrix that establishes an independent cycle basis within a graph, mapping its relationship with edges. We propose a cycle graph convolution that leverages a cycle adjacency matrix, derived from the cycle incidence matrix, to specifically filter edge signals in a domain of cycles. Additionally, we strengthen the representation power of the cycle graph convolution by adding an attention mechanism, which is further augmented by the introduction of edge positional encodings in cycles, to enhance the topological awareness of CycGAT. We demonstrate CycGAT's localization through simulation and its efficacy on an ABCD study's fMRI data (n=8765), comparing it with baseline models. CycGAT outperforms these models, identifying a functional backbone with significantly fewer cycles, crucial for understanding neural circuits related to general intelligence. Our code will be released once accepted.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.19149v1</guid>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinghan Huang, Nanguang Chen, Anqi Qiu</dc:creator>
    </item>
    <item>
      <title>Scaling up ridge regression for brain encoding in a massive individual fMRI dataset</title>
      <link>https://arxiv.org/abs/2403.19421</link>
      <description>arXiv:2403.19421v1 Announce Type: cross 
Abstract: Brain encoding with neuroimaging data is an established analysis aimed at predicting human brain activity directly from complex stimuli features such as movie frames. Typically, these features are the latent space representation from an artificial neural network, and the stimuli are image, audio, or text inputs. Ridge regression is a popular prediction model for brain encoding due to its good out-of-sample generalization performance. However, training a ridge regression model can be highly time-consuming when dealing with large-scale deep functional magnetic resonance imaging (fMRI) datasets that include many space-time samples of brain activity. This paper evaluates different parallelization techniques to reduce the training time of brain encoding with ridge regression on the CNeuroMod Friends dataset, one of the largest deep fMRI resource currently available. With multi-threading, our results show that the Intel Math Kernel Library (MKL) significantly outperforms the OpenBLAS library, being 1.9 times faster using 32 threads on a single machine. We then evaluated the Dask multi-CPU implementation of ridge regression readily available in scikit-learn (MultiOutput), and we proposed a new "batch" version of Dask parallelization, motivated by a time complexity analysis. In line with our theoretical analysis, MultiOutput parallelization was found to be impractical, i.e., slower than multi-threading on a single machine. In contrast, the Batch-MultiOutput regression scaled well across compute nodes and threads, providing speed-ups of up to 33 times with 8 compute nodes and 32 threads compared to a single-threaded scikit-learn execution. Batch parallelization using Dask thus emerges as a scalable approach for brain encoding with ridge regression on high-performance computing systems using scikit-learn and large fMRI datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.19421v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <category>q-bio.QM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sana Ahmadi, Pierre Bellec, Tristan Glatard</dc:creator>
    </item>
    <item>
      <title>The Idea of Exo-brain</title>
      <link>https://arxiv.org/abs/2210.11474</link>
      <description>arXiv:2210.11474v5 Announce Type: replace 
Abstract: In this paper I examine the process of getting affected by and the process of making sense of non-language sounds and propose the idea of the contextual cognitive apparatus or exo-brain. We are affected by a singing voice even when we do not fully understand the sounds produced by it. When the listener starts hearing words in the sung song and/or starts interpreting the heard words he recreates the sense and meaning of the song based on a context which either preexists in a culture or gets formed due to his extended engagement with a nebulous auditory stimulus that is perceived as meaningful. This is what I call the work of the creative ear. The affective power of the song comes from an affective reaction between the singing voice, especially the sung non-language sounds, and the linguistic and cultural contexts of the singer and the listener and out this affective reaction something emerges which constitutes the meaning, sensible or affective, of the non-language sound. I show how the cognitive contexts of the production and the reception of the non-language sounds, and the song, play a central role in our apprehension of the sounds and propose the existence of an extra-bodily sense making organ of our cognitive system, the extension of our brain and sense organs, which I call contextual cognitive apparatus or exo-brain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.11474v5</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ankur Betageri</dc:creator>
    </item>
    <item>
      <title>Brant-2: Foundation Model for Brain Signals</title>
      <link>https://arxiv.org/abs/2402.10251</link>
      <description>arXiv:2402.10251v4 Announce Type: replace 
Abstract: Foundational models benefit from pre-training on large amounts of unlabeled data and enable strong performance in a wide variety of applications with a small amount of labeled data. Such models can be particularly effective in analyzing brain signals, as this field encompasses numerous application scenarios, and it is costly to perform large-scale annotation. In this work, we present the largest foundation model in brain signals, Brant-2. Compared to Brant, a foundation model designed for intracranial neural signals, Brant-2 not only exhibits robustness towards data variations and modeling scales but also can be applied to a broader range of brain neural data. By experimenting on an extensive range of tasks, we demonstrate that Brant-2 is adaptive to various application scenarios in brain signals. Further analyses reveal the scalability of the Brant-2, validate each component's effectiveness, and showcase our model's ability to maintain performance in scenarios with scarce labels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.10251v4</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhizhang Yuan, Daoze Zhang, Junru Chen, Gefei Gu, Yang Yang</dc:creator>
    </item>
    <item>
      <title>Targeted collapse regularized autoencoder for anomaly detection: black hole at the center</title>
      <link>https://arxiv.org/abs/2306.12627</link>
      <description>arXiv:2306.12627v2 Announce Type: replace-cross 
Abstract: Autoencoders have been extensively used in the development of recent anomaly detection techniques. The premise of their application is based on the notion that after training the autoencoder on normal training data, anomalous inputs will exhibit a significant reconstruction error. Consequently, this enables a clear differentiation between normal and anomalous samples. In practice, however, it is observed that autoencoders can generalize beyond the normal class and achieve a small reconstruction error on some of the anomalous samples. To improve the performance, various techniques propose additional components and more sophisticated training procedures. In this work, we propose a remarkably straightforward alternative: instead of adding neural network components, involved computations, and cumbersome training, we complement the reconstruction loss with a computationally light term that regulates the norm of representations in the latent space. The simplicity of our approach minimizes the requirement for hyperparameter tuning and customization for new applications which, paired with its permissive data modality constraint, enhances the potential for successful adoption across a broad range of applications. We test the method on various visual and tabular benchmarks and demonstrate that the technique matches and frequently outperforms more complex alternatives. We further demonstrate that implementing this idea in the context of state-of-the-art methods can further improve their performance. We also provide a theoretical analysis and numerical simulations that help demonstrate the underlying process that unfolds during training and how it helps with anomaly detection. This mitigates the black-box nature of autoencoder-based anomaly detection algorithms and offers an avenue for further investigation of advantages, fail cases, and potential new directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.12627v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>q-bio.NC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amin Ghafourian, Huanyi Shui, Devesh Upadhyay, Rajesh Gupta, Dimitar Filev, Iman Soltani Bozchalooi</dc:creator>
    </item>
  </channel>
</rss>
