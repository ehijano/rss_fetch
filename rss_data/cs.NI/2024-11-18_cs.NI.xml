<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 19 Nov 2024 03:49:26 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Edge Caching Optimization with PPO and Transfer Learning for Dynamic Environments</title>
      <link>https://arxiv.org/abs/2411.09812</link>
      <description>arXiv:2411.09812v1 Announce Type: new 
Abstract: This paper addresses the challenge of edge caching in dynamic environments, where rising traffic loads strain backhaul links and core networks. We propose a Proximal Policy Optimization (PPO)-based caching strategy that fully incorporates key file attributes such as size, lifetime, importance, and popularity, while also considering random file request arrivals, reflecting more realistic edge caching scenarios. In dynamic environments, changes such as shifts in content popularity and variations in request rates frequently occur, making previously learned policies less effective as they were optimized for earlier conditions. Without adaptation, caching efficiency and response times can degrade. While learning a new policy from scratch in a new environment is an option, it is highly inefficient and computationally expensive. Thus, adapting an existing policy to these changes is critical. To address this, we develop a mechanism that detects changes in content popularity and request rates, ensuring timely adjustments to the caching strategy. We also propose a transfer learning-based PPO algorithm that accelerates convergence in new environments by leveraging prior knowledge. Simulation results demonstrate the significant effectiveness of our approach, outperforming a recent Deep Reinforcement Learning (DRL)-based method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.09812v1</guid>
      <category>cs.NI</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Farnaz Niknia, Ping Wang</dc:creator>
    </item>
    <item>
      <title>O-RAN and 6G: The Future of Wireless Innovation?</title>
      <link>https://arxiv.org/abs/2411.09959</link>
      <description>arXiv:2411.09959v1 Announce Type: new 
Abstract: The emergence of 6G technology represents a significant advancement in wireless communications, providing unprecedented speed, extremely low latency, and pioneering applications. In light of this development, an important question arises: Can the Open Radio Access Network (O-RAN), with its emphasis on openness, flexibility, RAN slicing, RAN Intelligent Controller (RIC), and cost-effectiveness, fulfill the complex requirements of 6G? This paper delves into the potential synergy between O-RAN and 6G, illustrating how O-RAN can facilitate customization, reduce expenses, and stimulate innovation in next-generation networks. We also tackle the challenges associated with 6G, such as the need for exceptional performance, integration with non-terrestrial networks, and heightened security. By examining the interaction between O-RAN and 6G, we underscore their joint role in shaping the future of wireless communication. Lastly, we demonstrate the potential of O-RAN through a unique, learning-based spectrum-sharing solution that aligns with the objectives of 6G for efficient spectrum usage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.09959v1</guid>
      <category>cs.NI</category>
      <category>cs.ET</category>
      <pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sneihil Gopal, Aziz Kord, Richard A. Rouil</dc:creator>
    </item>
    <item>
      <title>Architecture Proposal for 6G Systems Integrating Sensing and Communication</title>
      <link>https://arxiv.org/abs/2411.10138</link>
      <description>arXiv:2411.10138v1 Announce Type: new 
Abstract: Integrating sensing functionality into 6G communication networks requires some changes to existing components as well as new entities processing the radar sensing signals received by the communication antennas. This whitepaper provides a comprehensive overview of the 6G design proposal for ISaC (Integrated Sensing and Communication). The whitepaper has been created by the architecture group of the KOMSENS-6G project. It represents an intermediate state of the work, as the KOMSENS-6G project is still ongoing. The proposal should serve as a basis for further discussions and alignment across innovative 6G projects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10138v1</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Peter Gersing, Mark Doll, Joerg Huschke, Oliver Holschke</dc:creator>
    </item>
    <item>
      <title>Path Assignment in Mesh Networks at the Edge of Wireless Networks</title>
      <link>https://arxiv.org/abs/2411.10228</link>
      <description>arXiv:2411.10228v1 Announce Type: new 
Abstract: We consider a mesh network at the edge of a wireless network that connects users with the core network via multiple base stations. For this scenario we present a novel tree-search based algorithm that determines the optimal communication path to the core network for each user by maximizing the signal-to-noise-plus-interference ratio (SNIR) for each chosen path. We show that for three mesh networks with differing sizes, our algorithm chooses paths whose minimum SNIR is 3 dB to 18 dB better than that obtained via an algorithm that disregards the effect of interference within the network, 16 dB to 20 dB better than a random algorithm that chooses the paths randomly, and 0.5 dB to 7 dB better compared to a recently introduced genetic algorithm (GA). Furthermore, we show that our algorithm has a lower complexity compared to the GA in networks where its performance is within 2 dB.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10228v1</guid>
      <category>cs.NI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Siddhartha Kumar, Mohammad Hossein Moghaddam, Andreas Wolfgang, Tommy Svensson</dc:creator>
    </item>
    <item>
      <title>Self-Supervised Radio Pre-training: Toward Foundational Models for Spectrogram Learning</title>
      <link>https://arxiv.org/abs/2411.09849</link>
      <description>arXiv:2411.09849v1 Announce Type: cross 
Abstract: Foundational deep learning (DL) models are general models, trained on large, diverse, and unlabelled datasets, typically using self-supervised learning techniques have led to significant advancements especially in natural language processing. These pretrained models can be fine-tuned for related downstream tasks, offering faster development and reduced training costs, while often achieving improved performance. In this work, we introduce Masked Spectrogram Modeling, a novel self-supervised learning approach for pretraining foundational DL models on radio signals. Adopting a Convolutional LSTM architecture for efficient spatio-temporal processing, we pretrain the model with an unlabelled radio dataset collected from over-the-air measurements. Subsequently, the pretrained model is fine-tuned for two downstream tasks: spectrum forecasting and segmentation. Experimental results demonstrate that our methodology achieves competitive performance in both forecasting accuracy and segmentation, validating its effectiveness for developing foundational radio models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.09849v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ahmed Aboulfotouh, Ashkan Eshaghbeigi, Dimitrios Karslidis, Hatem Abou-Zeid</dc:creator>
    </item>
    <item>
      <title>A Graph-based Strategic Sensor Deployment Approach for k-coverage in WSN</title>
      <link>https://arxiv.org/abs/2411.09913</link>
      <description>arXiv:2411.09913v1 Announce Type: cross 
Abstract: This paper studies a graph-based sensor deployment approach in wireless sensor networks (WSNs). Specifically, in today's world, where sensors are everywhere, detecting various attributes like temperature and movement, their deteriorating lifetime is indeed a very concerning issue. In many scenarios, these sensors are placed in extremely remote areas, where maintenance becomes challenging. As a result, it is not very wise to depend on a single sensor to obtain data from a particular terrain or place. Hence, multiple sensors are deployed in these places, such that no problem arises if one or few of them fail. In this work, this problem of intelligent placement of sensors is modelled from the graph theoretic point of view. We propose a new sensor deployment approach here, which results in lesser sensor density per unit area and less number of sensors as compared to the existing benchmark schemes. Finally, the numerical results also support our claims and provide insights regarding the selection of parameters that enhance the system performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.09913v1</guid>
      <category>eess.SY</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Lakshmikanta Sau, Priyadarshi Mukherjee, Sasthi C. Ghosh</dc:creator>
    </item>
    <item>
      <title>Building 6G Radio Foundation Models with Transformer Architectures</title>
      <link>https://arxiv.org/abs/2411.09996</link>
      <description>arXiv:2411.09996v1 Announce Type: cross 
Abstract: Foundation deep learning (DL) models are general models, designed to learn general, robust and adaptable representations of their target modality, enabling finetuning across a range of downstream tasks. These models are pretrained on large, unlabeled datasets using self-supervised learning (SSL). Foundation models have demonstrated better generalization than traditional supervised approaches, a critical requirement for wireless communications where the dynamic environment demands model adaptability. In this work, we propose and demonstrate the effectiveness of a Vision Transformer (ViT) as a radio foundation model for spectrogram learning. We introduce a Masked Spectrogram Modeling (MSM) approach to pretrain the ViT in a self-supervised fashion. We evaluate the ViT-based foundation model on two downstream tasks: Channel State Information (CSI)-based Human Activity sensing and Spectrogram Segmentation. Experimental results demonstrate competitive performance to supervised training while generalizing across diverse domains. Notably, the pretrained ViT model outperforms a four-times larger model that is trained from scratch on the spectrogram segmentation task, while requiring significantly less training time, and achieves competitive performance on the CSI-based human activity sensing task. This work demonstrates the effectiveness of ViT with MSM for pretraining as a promising technique for scalable foundation model development in future 6G networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.09996v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ahmed Aboulfotouh, Ashkan Eshaghbeigi, Hatem Abou-Zeid</dc:creator>
    </item>
    <item>
      <title>MDHP-Net: Detecting Injection Attacks on In-vehicle Network using Multi-Dimensional Hawkes Process and Temporal Model</title>
      <link>https://arxiv.org/abs/2411.10258</link>
      <description>arXiv:2411.10258v1 Announce Type: cross 
Abstract: The integration of intelligent and connected technologies in modern vehicles, while offering enhanced functionalities through Electronic Control Unit and interfaces like OBD-II and telematics, also exposes the vehicle's in-vehicle network (IVN) to potential cyberattacks. In this paper, we consider a specific type of cyberattack known as the injection attack. As demonstrated by empirical data from real-world cybersecurity adversarial competitions(available at https://mimic2024.xctf.org.cn/race/qwmimic2024 ), these injection attacks have excitation effect over time, gradually manipulating network traffic and disrupting the vehicle's normal functioning, ultimately compromising both its stability and safety. To profile the abnormal behavior of attackers, we propose a novel injection attack detector to extract long-term features of attack behavior. Specifically, we first provide a theoretical analysis of modeling the time-excitation effects of the attack using Multi-Dimensional Hawkes Process (MDHP). A gradient descent solver specifically tailored for MDHP, MDHP-GDS, is developed to accurately estimate optimal MDHP parameters. We then propose an injection attack detector, MDHP-Net, which integrates optimal MDHP parameters with MDHP-LSTM blocks to enhance temporal feature extraction. By introducing MDHP parameters, MDHP-Net captures complex temporal features that standard Long Short-Term Memory (LSTM) cannot, enriching temporal dependencies within our customized structure. Extensive evaluations demonstrate the effectiveness of our proposed detection approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10258v1</guid>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qi Liu, Yanchen Liu, Ruifeng Li, Chenhong Cao, Yufeng Li, Xingyu Li, Peng Wang, Runhan Feng</dc:creator>
    </item>
    <item>
      <title>Low-Latency Task-Oriented Communications with Multi-Round, Multi-Task Deep Learning</title>
      <link>https://arxiv.org/abs/2411.10385</link>
      <description>arXiv:2411.10385v1 Announce Type: cross 
Abstract: In this paper, we address task-oriented (or goal-oriented) communications where an encoder at the transmitter learns compressed latent representations of data, which are then transmitted over a wireless channel. At the receiver, a decoder performs a machine learning task, specifically for classifying the received signals. The deep neural networks corresponding to the encoder-decoder pair are jointly trained, taking both channel and data characteristics into account. Our objective is to achieve high accuracy in completing the underlying task while minimizing the number of channel uses determined by the encoder's output size. To this end, we propose a multi-round, multi-task learning (MRMTL) approach for the dynamic update of channel uses in multi-round transmissions. The transmitter incrementally sends an increasing number of encoded samples over the channel based on the feedback from the receiver, and the receiver utilizes the signals from a previous round to enhance the task performance, rather than only considering the latest transmission. This approach employs multi-task learning to jointly optimize accuracy across varying number of channel uses, treating each configuration as a distinct task. By evaluating the confidence of the receiver in task decisions, MRMTL decides on whether to allocate additional channel uses in multiple rounds. We characterize both the accuracy and the delay (total number of channel uses) of MRMTL, demonstrating that it achieves the accuracy close to that of conventional methods requiring large numbers of channel uses, but with reduced delay by incorporating signals from a prior round. We consider the CIFAR-10 dataset, convolutional neural network architectures, and AWGN and Rayleigh channel models for performance evaluation. We show that MRMTL significantly improves the efficiency of task-oriented communications, balancing accuracy and latency effectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10385v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yalin E. Sagduyu, Tugba Erpek, Aylin Yener, Sennur Ulukus</dc:creator>
    </item>
    <item>
      <title>Fine-grained Distributed Data Plane Verification with Intent-based Slicing</title>
      <link>https://arxiv.org/abs/2405.20982</link>
      <description>arXiv:2405.20982v2 Announce Type: replace 
Abstract: Data plane verification has grown into a powerful tool to ensure network correctness. However, existing methods with monolithic models have memory requirements tied to network sizes, and the existing method of scaling out is too limited in expressiveness to capture practical network features. In this paper, we describe Scylla, a general data plane verifier that provides fine-grained scale-out without the need for a monolithic network model. Scylla creates models for what we call intent-based slices, each of which is constructed at the rule-level granularity with only enough to verify a given set of intents. The sliced models are retained and incrementally updated in memory across a distributed compute cluster in response to network updates. Our experiments show that Scylla makes the scaling problem more granular -- tied to the size of the intent-based slices rather than that of the overall network. This enables Scylla to verify large, complex networks in minimum units of work that are significantly smaller (in both memory and time) than past techniques, enabling fast scale-out verification with minimal resource requirement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20982v2</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kuan-Yen Chou, Santhosh Prabhu, Giri Subramanian, Wenxuan Zhou, Aanand Nayyar, Brighten Godfrey, Matthew Caesar</dc:creator>
    </item>
    <item>
      <title>AdapShare: An RL-Based Dynamic Spectrum Sharing Solution for O-RAN</title>
      <link>https://arxiv.org/abs/2408.16842</link>
      <description>arXiv:2408.16842v2 Announce Type: replace 
Abstract: The Open Radio Access Network (O-RAN) initiative, characterized by open interfaces and AI/ML-capable RAN Intelligent Controller (RIC), facilitates effective spectrum sharing among RANs. In this context, we introduce AdapShare, an ORAN-compatible solution leveraging Reinforcement Learning (RL) for intent-based spectrum management, with the primary goal of minimizing resource surpluses or deficits in RANs. By employing RL agents, AdapShare intelligently learns network demand patterns and uses them to allocate resources. We demonstrate the efficacy of AdapShare in the spectrum sharing scenario between LTE and NR networks, incorporating real-world LTE resource usage data and synthetic NR usage data to demonstrate its practical use. We use the average surplus or deficit and fairness index to measure the system's performance in various scenarios. AdapShare outperforms a quasi-static resource allocation scheme based on long-term network demand statistics, particularly when available resources are scarce or exceed the aggregate demand from the networks. Lastly, we present a high-level O-RAN compatible architecture using RL agents, which demonstrates the seamless integration of AdapShare into real-world deployment scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16842v2</guid>
      <category>cs.NI</category>
      <category>cs.LG</category>
      <pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sneihil Gopal, David Griffith, Richard A. Rouil, Chunmei Liu</dc:creator>
    </item>
    <item>
      <title>On-demand 5G Private Networks using a Mobile Cell</title>
      <link>https://arxiv.org/abs/2411.06597</link>
      <description>arXiv:2411.06597v2 Announce Type: replace 
Abstract: This paper proposes the Mobile Cell (MC) concept for on-demand 5G private networks. The MC is designed to extend, restore, and reinforce 5G wireless coverage and network capacity on-demand, especially in areas with temporary communications needs or where it is costly or not possible to deploy a permanent fixed infrastructure. The design of the MC as well as the development, integration, and deployment in 5G private networks are discussed.
  The Mobile Cell concept can be applied in multiple real-world environments, including seaports and application scenarios. Similarly to critical hubs in the global supply chain, seaports require reliable, high-performance wireless communications to increase efficiency and manage dynamic operations in real-time. Current communications solutions in seaports typically rely on Wi-Fi and wired-based technologies. Wired-based technologies lack the necessary flexibility for dynamic environments. Wi-Fi is susceptible to interference from other systems operating in the same frequency bands. An MC operating in a licensed, interference-free spectrum is a promising solution to overcome these limitations and provide improved Quality of Service when using the 5G technology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.06597v2</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Andr\'e Coelho, Jos\'e Ruela, Gon\c{c}alo Queir\'os, Ricardo Trancoso, Paulo Furtado Correia, Filipe Ribeiro, Helder Fontes, Rui Campos, Manuel Ricardo</dc:creator>
    </item>
    <item>
      <title>KeySpace: Public Key Infrastructure Considerations in Interplanetary Networks</title>
      <link>https://arxiv.org/abs/2408.10963</link>
      <description>arXiv:2408.10963v3 Announce Type: replace-cross 
Abstract: As satellite networks expand to encompass megaconstellations and interplanetary communication, the need for effective Public Key Infrastructure (PKI) becomes increasingly pressing. This paper addresses the challenge of implementing PKI in these complex networks, identifying the essential goals and requirements.
  We develop a standardized framework for comparing PKI systems across various network topologies, enabling the evaluation of their performance and security. Our results demonstrate that terrestrial PKI techniques can be adapted for use in highly distributed interplanetary networks, achieving efficient low-latency connection establishment and minimizing the impact of attacks through effective revocation mechanisms. This result has significant implications for the design of future satellite networks, as it enables the reuse of existing PKI solutions to provide increased compatibility with terrestrial networks.
  We evaluate this by building the Deep Space Network Simulator (DSNS), a novel tool for efficiently simulating large space networks. Using DSNS, we conduct comprehensive simulations of connection establishment and key revocation under a range of network topologies and PKI configurations. Furthermore, we propose and evaluate two new configuration options: OCSP Hybrid, and the use of relay nodes as a firewall. Together these minimize the extent of the network an attacker can reach with a compromised key, and reduce the attacker's load on interplanetary relay links.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10963v3</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joshua Smailes, Sebastian K\"ohler, Simon Birnbach, Martin Strohmeier, Ivan Martinovic</dc:creator>
    </item>
    <item>
      <title>Exploring GPU-to-GPU Communication: Insights into Supercomputer Interconnects</title>
      <link>https://arxiv.org/abs/2408.14090</link>
      <description>arXiv:2408.14090v2 Announce Type: replace-cross 
Abstract: Multi-GPU nodes are increasingly common in the rapidly evolving landscape of exascale supercomputers. On these systems, GPUs on the same node are connected through dedicated networks, with bandwidths up to a few terabits per second. However, gauging performance expectations and maximizing system efficiency is challenging due to different technologies, design options, and software layers. This paper comprehensively characterizes three supercomputers - Alps, Leonardo, and LUMI - each with a unique architecture and design. We focus on performance evaluation of intra-node and inter-node interconnects on up to 4096 GPUs, using a mix of intra-node and inter-node benchmarks. By analyzing its limitations and opportunities, we aim to offer practical guidance to researchers, system architects, and software developers dealing with multi-GPU supercomputing. Our results show that there is untapped bandwidth, and there are still many opportunities for optimization, ranging from network to software optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.14090v2</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <category>cs.AR</category>
      <category>cs.NI</category>
      <category>cs.PF</category>
      <pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/SC41406.2024.00039</arxiv:DOI>
      <arxiv:journal_reference>Published in Proceedings of The International Conference for High Performance Computing Networking, Storage, and Analysis (SC '24) (2024)</arxiv:journal_reference>
      <dc:creator>Daniele De Sensi, Lorenzo Pichetti, Flavio Vella, Tiziano De Matteis, Zebin Ren, Luigi Fusco, Matteo Turisini, Daniele Cesarini, Kurt Lust, Animesh Trivedi, Duncan Roweth, Filippo Spiga, Salvatore Di Girolamo, Torsten Hoefler</dc:creator>
    </item>
  </channel>
</rss>
