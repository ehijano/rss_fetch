<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.OT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.OT</link>
    <description>stat.OT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.OT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 30 Dec 2025 13:04:56 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>LLteacher: A Tool for the Integration of Generative AI into Statistics Assignments</title>
      <link>https://arxiv.org/abs/2512.23053</link>
      <description>arXiv:2512.23053v1 Announce Type: new 
Abstract: As generative AI becomes increasingly embedded in everyday life, the thoughtful and intentional integration of AI-based tools into statistics education has become essential. We address this need with a focus on homework assignments and we propose the use of LLMs as a companion to complete homework by developing an open-source tool named LLteacher. This LLM-based tool preserves learning processes and it guides students to engage with AI in ways that support their learning, while ensuring alignment with course content and equitable access. We illustrate LLteacher's design and functionality with examples from an undergraduate Statistical Computing course in R, showing how it supports two distinct pedagogical goals: recalling prior knowledge and discovering new concepts. While this is an initial version, LLteacher demonstrates one possible pathway for integrating generative AI into statistics courses, with strong potential for adaptation to other types of classes and assignments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23053v1</guid>
      <category>stat.OT</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Emanuela Furfaro, Simone Mosciatti</dc:creator>
    </item>
    <item>
      <title>Domain matters: Towards domain-informed evaluation for link prediction</title>
      <link>https://arxiv.org/abs/2512.23371</link>
      <description>arXiv:2512.23371v1 Announce Type: new 
Abstract: Link prediction, a foundational task in complex network analysis, has extensive applications in critical scenarios such as social recommendation, drug target discovery, and knowledge graph completion. However, existing evaluations of algorithmic often rely on experiments conducted on a limited number of networks, assuming consistent performance rankings across domains. Despite the significant disparities in generative mechanisms and semantic contexts, previous studies often improperly highlight ``universally optimal" algorithms based solely on naive average over networks across domains. This paper systematically evaluates 12 mainstream link prediction algorithms across 740 real-world networks spanning seven domains. We present substantial empirical evidence elucidating the performance of algorithms in specific domains. This findings reveal a notably low degree of consistency in inter-domain algorithm rankings, a phenomenon that stands in stark contrast to the high degree of consistency observed within individual domains. Principal Component Analysis shows that response vectors formed by the rankings of the 12 algorithms cluster distinctly by domain in low-dimensional space, thus confirming domain attributes as a pivotal factor affecting algorithm performance. We propose a metric called Winner Score that could identify the superior algorithm in each domain: Non-Negative Matrix Factorization for social networks, Neighborhood Overlap-aware Graph Neural Networks for economics, Graph Convolutional Networks for chemistry, and L3-based Resource Allocation for biology. However, these domain-specific top-performing algorithms tend to exhibit suboptimal performance in other domains. This finding underscores the importance of aligning an algorithm's mechanism with the network structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23371v1</guid>
      <category>stat.OT</category>
      <category>cs.GR</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yilin Bi, Junhao Bian, Shuyan Wan, Shuaijia Wang, Tao Zhou</dc:creator>
    </item>
    <item>
      <title>Assessing the Effects of Macroeconomic Variables on Child Mortality in D-8 Countries Using Panel Data Analysis</title>
      <link>https://arxiv.org/abs/2512.23110</link>
      <description>arXiv:2512.23110v1 Announce Type: cross 
Abstract: This research analyses the axiomatic link among health expenditures, inflation rate, and gross national income (GNI) per capita concerning the child mortality (CMU5) rate in D-8 nations, employing panel data analysis from 1995 to 2014. Utilising conventional panel unit root tests and linear regression models, we establish that education expenditures, in conjunction with health expenditures, inflation rate, and GNI per capita, display stationarity at level. Additionally, we examine fixed effects and random effects estimators for the pertinent variables, utilising metrics such as the Hausman Test (HT) and comparisons with CCMR correlations. Our data demonstrate that the CMU5 rate in D-8 nations has steadily decreased, according to a somewhat negative linear regression model, therefore slightly undermining the fourth Millennium Development Goal (MDG4) of the World Health Organisation (WHO).</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23110v1</guid>
      <category>econ.TH</category>
      <category>stat.AP</category>
      <category>stat.OT</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>M. Waseem Akram, Binita Shahi, M. Javed Akram</dc:creator>
    </item>
    <item>
      <title>Change Point Detection and Mean-Field Dynamics of Variable Productivity Hawkes Processes</title>
      <link>https://arxiv.org/abs/2512.20068</link>
      <description>arXiv:2512.20068v2 Announce Type: replace 
Abstract: Many self-exciting systems change because endogenous amplification, as opposed to exogenous forcing, varies. We study a Hawkes process with fixed background rate and kernel, but piecewise time-varying productivity. For exponential kernels we derive closed-form mean-field relaxation after a change and a deterministic surrogate for post-change Fisher information, revealing a boundary layer in which change time information localises and saturates, while post-change level information grows linearly beyond a short transient. These results motivate a Bayesian change point procedure that stabilizes inference on finite windows. We illustrate the method on invasive pneumococcal disease incidence in The Gambia, identifying a decline in productivity aligned with pneumococcal conjugate vaccine rollout.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.20068v2</guid>
      <category>stat.OT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Conor Kresin, Boris Baeumer, Sophie Phillips</dc:creator>
    </item>
    <item>
      <title>Multivariate Conformal Prediction via Conformalized Gaussian Scoring</title>
      <link>https://arxiv.org/abs/2507.20941</link>
      <description>arXiv:2507.20941v2 Announce Type: replace-cross 
Abstract: While achieving exact conditional coverage in conformal prediction is unattainable without making strong, untestable regularity assumptions, the promise of conformal prediction hinges on finding approximations to conditional guarantees that are realizable in practice. A promising direction for obtaining conditional dependence for conformal sets--in particular capturing heteroskedasticity--is through estimating the conditional density $\mathbb{P}_{Y|X}$ and conformalizing its level sets. Previous work in this vein has focused on nonconformity scores based on the empirical cumulative distribution function (CDF). Such scores are, however, computationally costly, typically requiring expensive sampling methods. To avoid the need for sampling, we observe that the CDF-based score reduces to a Mahalanobis distance in the case of Gaussian scores, yielding a closed-form expression that can be directly conformalized. Moreover, the use of a Gaussian-based score opens the door to a number of extensions of the basic conformal method; in particular, we show how to construct conformal sets with missing output values, refine conformal sets as partial information about $Y$ becomes available, and construct conformal sets on transformations of the output space. Finally, empirical results indicate that our approach produces conformal sets that more closely approximate conditional coverage in multivariate settings compared to alternative methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.20941v2</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <category>stat.OT</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sacha Braun, Eug\`ene Berta, Michael I. Jordan, Francis Bach</dc:creator>
    </item>
  </channel>
</rss>
