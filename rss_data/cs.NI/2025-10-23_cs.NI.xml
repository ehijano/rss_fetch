<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 24 Oct 2025 04:00:03 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Tutorial on Cognitive Biases in Agentic AI-Driven 6G Autonomous Networks</title>
      <link>https://arxiv.org/abs/2510.19973</link>
      <description>arXiv:2510.19973v1 Announce Type: new 
Abstract: The path to higher network autonomy in 6G lies beyond the mere optimization of key performance indicators (KPIs). While KPIs have enabled automation gains under TM Forum Levels 1--3, they remain numerical abstractions that act only as proxies for the real essence of communication networks: seamless connectivity, fairness, adaptability, and resilience. True autonomy requires perceiving and reasoning over the network environment as it is. Such progress can be achieved through \emph{agentic AI}, where large language model (LLM)-powered agents perceive multimodal telemetry, reason with memory, negotiate across domains, and act via APIs to achieve multi-objective goals. However, deploying such agents introduces the challenge of cognitive biases inherited from human design, which can distort reasoning, negotiation, tool use, and actuation. Between neuroscience and AI, this paper provides a tutorial on a selection of well-known biases, including their taxonomy, definition, mathematical formulation, emergence in telecom systems and the commonly impacted agentic components. The tutorial also presents various mitigation strategies tailored to each type of bias. The article finally provides two practical use-cases, which tackle the emergence, impact and mitigation gain of some famous biases in 6G inter-slice and cross-domain management. In particular, anchor randomization, temporal decay and inflection bonus techniques are introduced to specifically address anchoring, temporal and confirmation biases. This avoids that agents stick to the initial high resource allocation proposal or decisions that are recent and/or confirming a prior hypothesis. By grounding decisions in a richer and fairer set of past experiences, the quality and bravery of the agentic agreements in the second use-case, for instance, are leading to $\times 5$ lower latency and around $40\%$ higher energy saving.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19973v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hatim Chergui, Farhad Rezazadeh, Merouane Debbah, Christos Verikoukis</dc:creator>
    </item>
    <item>
      <title>Rediscovering Recurring Routing Results</title>
      <link>https://arxiv.org/abs/2510.20297</link>
      <description>arXiv:2510.20297v1 Announce Type: new 
Abstract: Routing is central to networking performance, including: (1) latency in anycast services and websites served from multiple locations,(2) networking expenses and throughput in multi-homed enterprises, (3) the ability to keep traffic domestic when considering data sovereignty. However, understanding and managing how routing affects these services is challenging. Operators use Traffic Engineering (TE) with BGP to optimize network performance, but what they get is the result of all BGP policies throughout the Internet, not just their local choices. Our paper proposes Fenrir, a new system to rediscover recurring routing results. Fenrir can discover changes in network routing, even when it happens multiple hops away from the observer. Fenrir also provides new methods to quantify the degree of routing change, and to identify routing "modes" that may reappear. Second, we show that Fenrir can be applied to many different problems: we use five instances of three different types of systems to illustrate the generalization: anycast catchments showing in a root DNS service, route optimization for two multi-homed enterprises, and website selection for two of the top-10 web services. Each type requires different types of active measurements, data cleaning and weighting. We demonstrate Fenrir's methods of detecting and quantifying change are helpful because they all face similar operational questions: How much effect did traffic engineering have? Did a third-party change alter my routing? In either case, is the current routing new, or is it like a routing mode I saw before?</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20297v1</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Xiao Song, John Heidemann</dc:creator>
    </item>
    <item>
      <title>Multicast-partitioning in Time-triggered Stream Planning for Time-Sensitive Networks</title>
      <link>https://arxiv.org/abs/2510.20440</link>
      <description>arXiv:2510.20440v1 Announce Type: new 
Abstract: Multicast allows sending a message to multiple recipients without having to create and send a separate message for each recipient. This preserves network bandwidth, which is particularly important in time-sensitive networks. These networks are commonly used to provide latency-bounded communication for real-time systems in domains like automotive, avionics, industrial internet of things, automated shop floors, and smart energy grids. The preserved bandwidth can be used to admit additional real-time messages with specific quality of service requirements or to reduce the end-to-end latencies for messages of any type. However, using multicast communication can complicate traffic planning, as it requires free queues or available downstream egress ports on all branches of the multicast tree. In this work, we present a novel multicast partitioning technique to split multicast trees into smaller multicast or unicast trees. This allows for a more fine-grained trade-off between bandwidth utilization and traffic scheduling difficulty. Thus, schedulability in dynamic systems can be improved, in terms the number of admitted streams and the accumulated network throughput. We evaluated the multicast partitioning on different network topologies and with three different scheduling algorithms. With the partitioning, 5-15\% fewer streams were rejected, while achieving 5-125\% more network throughput, depending on the scheduling algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20440v1</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Heiko Geppert, Frank D\"urr, Simon Na{\ss}, Kurt Rothermel</dc:creator>
    </item>
    <item>
      <title>Trust, But Verify: An Empirical Evaluation of AI-Generated Code for SDN Controllers</title>
      <link>https://arxiv.org/abs/2510.20703</link>
      <description>arXiv:2510.20703v1 Announce Type: new 
Abstract: Generative Artificial Intelligence (AI) tools have been used to generate human-like content across multiple domains (e.g., sound, image, text, and programming). However, their reliability in terms of correctness and functionality in novel contexts such as programmable networks remains unclear. Hence, this paper presents an empirical evaluation of the source code of a POX controller generated by different AI tools, namely ChatGPT, Copilot, DeepSeek, and BlackBox.ai. To evaluate such a code, three networking tasks of increasing complexity were defined and for each task, zero-shot and few-shot prompting techniques were input to the tools. Next, the output code was tested in emulated network topologies with Mininet and analyzed according to functionality, correctness, and the need for manual fixes. Results show that all evaluated models can produce functional controllers. However, ChatGPT and DeepSeek exhibited higher consistency and code quality, while Copilot and BlackBox.ai required more adjustments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20703v1</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Felipe Avencourt Soares, Muriel F. Franco, Eder J. Scheid, Lisandro Z. Granville</dc:creator>
    </item>
    <item>
      <title>AI-Enabled Digital Twins for Next-Generation Networks: Forecasting Traffic and Resource Management in 5G/6G</title>
      <link>https://arxiv.org/abs/2510.20796</link>
      <description>arXiv:2510.20796v1 Announce Type: new 
Abstract: As 5G and future 6G mobile networks become increasingly more sophisticated, the requirements for agility, scalability, resilience, and precision in real-time service provisioning cannot be met using traditional and heuristic-based resource management techniques, just like any advancing technology. With the aim of overcoming such limitations, network operators are foreseeing Digital Twins (DTs) as key enablers, which are designed as dynamic and virtual replicas of network infrastructure, allowing operators to model, analyze, and optimize various operations without any risk of affecting the live network. However, for Digital Twin Networks (DTNs) to meet the challenges faced by operators especially in line with resource management, a driving engine is needed. In this paper, an AI (Artificial Intelligence)-driven approach is presented by integrating a Long Short-Term Memory (LSTM) neural network into the DT framework, aimed at forecasting network traffic patterns and proactively managing resource allocation. Through analytical experiments, the AI-Enabled DT framework demonstrates superior performance benchmarked against baseline methods. Our study concludes that embedding AI capabilities within DTs paves the way for fully autonomous, adaptive, and high-performance network management in future mobile networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20796v1</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>John Sengendo, Fabrizio Granelli</dc:creator>
    </item>
    <item>
      <title>Q-RAN: Quantum-Resilient O-RAN Architecture</title>
      <link>https://arxiv.org/abs/2510.19968</link>
      <description>arXiv:2510.19968v1 Announce Type: cross 
Abstract: The telecommunications industry faces a dual transformation: the architectural shift toward Open Radio Access Networks (O-RAN) and the emerging threat from quantum computing. O-RAN disaggregated, multi-vendor architecture creates a larger attack surface vulnerable to crypt-analytically relevant quantum computers(CRQCs) that will break current public key cryptography. The Harvest Now, Decrypt Later (HNDL) attack strategy makes this threat immediate, as adversaries can intercept encrypted data today for future decryption. This paper presents Q-RAN, a comprehensive quantum-resistant security framework for O-RAN networks using NIST-standardized Post-Quantum Cryptography (PQC). We detail the implementation of ML-KEM (FIPS 203) and ML-DSA (FIPS 204), integrated with Quantum Random Number Generators (QRNG) for cryptographic entropy. The solution deploys PQ-IPsec, PQ-DTLS, and PQ-mTLS protocols across all O-RAN interfaces, anchored by a centralized Post-Quantum Certificate Authority (PQ-CA) within the SMO framework. This work provides a complete roadmap for securing disaggregated O-RAN ecosystems against quantum adversaries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19968v1</guid>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vipin Rathi, Lakshya Chopra, Madhav Agarwal, Nitin Rajput, Kriish Sharma, Sushant Mundepi, Shivam Gangwar, Rudraksh Rawal,  Jishan</dc:creator>
    </item>
    <item>
      <title>QORE : Quantum Secure 5G/B5G Core</title>
      <link>https://arxiv.org/abs/2510.19982</link>
      <description>arXiv:2510.19982v1 Announce Type: cross 
Abstract: Quantum computing is reshaping the security landscape of modern telecommunications. The cryptographic foundations that secure todays 5G systems, including RSA, Elliptic Curve Cryptography (ECC), and Diffie-Hellman (DH), are all susceptible to attacks enabled by Shors algorithm. Protecting 5G networks against future quantum adversaries has therefore become an urgent engineering and research priority. In this paper we introduce QORE, a quantum-secure 5G and Beyond 5G (B5G) Core framework that provides a clear pathway for transitioning both the 5G Core Network Functions and User Equipment (UE) to Post-Quantum Cryptography (PQC). The framework uses the NIST-standardized lattice-based algorithms Module-Lattice Key Encapsulation Mechanism (ML-KEM) and Module-Lattice Digital Signature Algorithm (ML-DSA) and applies them across the 5G Service-Based Architecture (SBA). A Hybrid PQC (HPQC) configuration is also proposed, combining classical and quantum-safe primitives to maintain interoperability during migration. Experimental validation shows that ML-KEM achieves quantum security with minor performance overhead, meeting the low-latency and high-throughput requirements of carrier-grade 5G systems. The proposed roadmap aligns with ongoing 3GPP SA3 and SA5 study activities on the security and management of post-quantum networks as well as with NIST PQC standardization efforts, providing practical guidance for mitigating quantum-era risks while safeguarding long-term confidentiality and integrity of network data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19982v1</guid>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vipin Rathi, Lakshya Chopra, Rudraksh Rawal, Nitin Rajput, Shiva Valia, Madhav Aggarwal, Aditya Gairola</dc:creator>
    </item>
    <item>
      <title>Collective Communication for 100k+ GPUs</title>
      <link>https://arxiv.org/abs/2510.20171</link>
      <description>arXiv:2510.20171v1 Announce Type: cross 
Abstract: The increasing scale of large language models (LLMs) necessitates highly efficient collective communication frameworks, particularly as training workloads extend to hundreds of thousands of GPUs. Traditional communication methods face significant throughput and latency limitations at this scale, hindering both the development and deployment of state-of-the-art models. This paper presents the NCCLX collective communication framework, developed at Meta, engineered to optimize performance across the full LLM lifecycle, from the synchronous demands of large-scale training to the low-latency requirements of inference. The framework is designed to support complex workloads on clusters exceeding 100,000 GPUs, ensuring reliable, high-throughput, and low-latency data exchange. Empirical evaluation on the Llama4 model demonstrates substantial improvements in communication efficiency. This research contributes a robust solution for enabling the next generation of LLMs to operate at unprecedented scales.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20171v1</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Min Si, Pavan Balaji, Yongzhou Chen, Ching-Hsiang Chu, Adi Gangidi, Saif Hasan, Subodh Iyengar, Dan Johnson, Bingzhe Liu, Jingliang Ren, Ashmitha Jeevaraj Shetty, Greg Steinbrecher, Xinfeng Xie, Yulun Wang, Bruce Wu, Jingyi Yang, Mingran Yang, Minlan Yu, Cen Zhao, Wes Bland, Denis Boyda, Suman Gumudavelli, Cristian Lumezanu, Rui Miao, Zhe Qu, Venkat Ramesh, Maxim Samoylov, Jan Seidel, Feng Tian, Qiye Tan, Shuqiang Zhang, Yimeng Zhao, Shengbao Zheng, Art Zhu, Hongyi Zeng</dc:creator>
    </item>
    <item>
      <title>MAC Aggregation over Lossy Channels in DTLS 1.3</title>
      <link>https://arxiv.org/abs/2510.20419</link>
      <description>arXiv:2510.20419v1 Announce Type: cross 
Abstract: Aggregating Message Authentication Codes (MACs) promises to save valuable bandwidth in resource-constrained environments. The idea is simple: Instead of appending an authentication tag to each message in a communication stream, the integrity protection of multiple messages is aggregated into a single tag. Recent studies postulate, e.g., based on simulations, that these benefits also spread to wireless, and thus lossy, scenarios despite each lost packet typically resulting in the loss of integrity protection information for multiple messages. In this paper, we investigate these claims in a real deployment. Therefore, we first design a MAC aggregation extension for the Datagram Transport Layer Security (DTLS) 1.3 protocol. Afterward, we extensively evaluate the performance of MAC aggregation on a complete communication protocol stack on embedded hardware. We find that MAC aggregation can indeed increase goodput by up to 50% and save up to 17% of energy expenditure for the transmission of short messages, even in lossy channels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20419v1</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/ICNP65844.2025.11192339</arxiv:DOI>
      <dc:creator>Eric Wagner, David Heye, Jan Bauer, Klaus Wehrle, Martin Serror</dc:creator>
    </item>
    <item>
      <title>On the cybersecurity of LoRaWAN-based system: a Smart-Lighting case study</title>
      <link>https://arxiv.org/abs/2510.20494</link>
      <description>arXiv:2510.20494v1 Announce Type: cross 
Abstract: Cyber-physical systems and the Internet of Things (IoT) are key technologies in the Industry 4.0 vision. They incorporate sensors and actuators to interact with the physical environment. However, when creating and interconnecting components to form a heterogeneous smart systems architecture, these face challenges in cybersecurity. This paper presents an experimental investigation of architectural configurations for a LoRaWAN-based Smart-Lighting project, aimed at verifying and improving the system's robustness against attacks. We assess the system's robustness in a series of iterative experiments conducted both in-vitro and on-site. The results show that most attacks on a LoRaWAN network are unsuccessful, also highlighting unresolved issues with the installed products. The most successful attacks are high-power jamming attacks within a few meters of the target, which, in the case of gateways, can be mitigated through gateway redundancy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20494v1</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3770501.3770524</arxiv:DOI>
      <dc:creator>Florian Hofer, Barbara Russo</dc:creator>
    </item>
    <item>
      <title>Scrapers selectively respect robots.txt directives: evidence from a large-scale empirical study</title>
      <link>https://arxiv.org/abs/2505.21733</link>
      <description>arXiv:2505.21733v2 Announce Type: replace 
Abstract: Online data scraping has taken on new dimensions in recent years, as traditional scrapers have been joined by new AI-specific bots. To counteract unwanted scraping, many sites use tools like the Robots Exclusion Protocol (REP), which places a robots$.$txt file at the site root to dictate scraper behavior. Yet, the efficacy of the REP is not well-understood. Anecdotal evidence suggests some bots comply poorly with it, but no rigorous study exists to support (or refute) this claim. To understand the merits and limits of the REP, we conduct the first large-scale study of web scraper compliance with robots$.$txt directives using anonymized web logs from our institution. We analyze the behavior of 130 self-declared bots (and many anonymous ones) over 40 days, using a series of controlled robots$.$txt experiments. We find that bots are less likely to comply with stricter robots$.$txt directives, and that certain categories of bots, including AI search crawlers, rarely check robots$.$txt at all. These findings suggest that relying on robots$.$txt files to prevent unwanted scraping is risky and highlight the need for alternative approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21733v2</guid>
      <category>cs.NI</category>
      <category>cs.CR</category>
      <category>cs.CY</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Taein Kim, Karstan Bock, Claire Luo, Amanda Liswood, Chloe Poroslay, Emily Wenger</dc:creator>
    </item>
    <item>
      <title>Multi-Agent Reinforcement Learning for Task Offloading in Wireless Edge Networks</title>
      <link>https://arxiv.org/abs/2509.01257</link>
      <description>arXiv:2509.01257v2 Announce Type: replace-cross 
Abstract: In edge computing systems, autonomous agents must make fast local decisions while competing for shared resources. Existing MARL methods often resume to centralized critics or frequent communication, which fail under limited observability and communication constraints. We propose a decentralized framework in which each agent solves a constrained Markov decision process (CMDP), coordinating implicitly through a shared constraint vector. For the specific case of offloading, e.g., constraints prevent overloading shared server resources. Coordination constraints are updated infrequently and act as a lightweight coordination mechanism. They enable agents to align with global resource usage objectives but require little direct communication. Using safe reinforcement learning, agents learn policies that meet both local and global goals. We establish theoretical guarantees under mild assumptions and validate our approach experimentally, showing improved performance over centralized and independent baselines, especially in large-scale settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.01257v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrea Fox, Francesco De Pellegrini, Eitan Altman</dc:creator>
    </item>
    <item>
      <title>RailS: Load Balancing for All-to-All Communication in Distributed Mixture-of-Experts Training</title>
      <link>https://arxiv.org/abs/2510.19262</link>
      <description>arXiv:2510.19262v2 Announce Type: replace-cross 
Abstract: Training Mixture-of-Experts (MoE) models introduces sparse and highly imbalanced all-to-all communication that dominates iteration time. Conventional load-balancing methods fail to exploit the deterministic topology of Rail architectures, leaving multi-NIC bandwidth underutilized. We present RailS, a distributed load-balancing framework that minimizes all-to-all completion time in MoE training. RailS leverages the Rail topology's symmetry to prove that uniform sending ensures uniform receiving, transforming global coordination into local scheduling. Each node independently executes a Longest Processing Time First (LPT) spraying scheduler to proactively balance traffic using local information. RailS activates N parallel rails for fine-grained, topology-aware multipath transmission. Across synthetic and real-world MoE workloads, RailS improves bus bandwidth by 20%--78% and reduces completion time by 17%--78%. For Mixtral workloads, it shortens iteration time by 18%--40% and achieves near-optimal load balance, fully exploiting architectural parallelism in distributed training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19262v2</guid>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Heng Xu, Zhiwei Yu, Chengze Du, Ying Zhou, Letian Li, Haojie Wang, Weiqiang Cheng, Jialong Li</dc:creator>
    </item>
  </channel>
</rss>
