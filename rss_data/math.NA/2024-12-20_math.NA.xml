<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.NA</link>
    <description>math.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 20 Dec 2024 05:00:48 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Reaching the equilibrium: Long-term stable approximations for stochastic non-Newtonian Stokes equations with transport noise</title>
      <link>https://arxiv.org/abs/2412.14316</link>
      <description>arXiv:2412.14316v1 Announce Type: new 
Abstract: We propose and analyse a novel, fully discrete numerical algorithm for the approximation of the generalised Stokes system forced by transport noise -- a prototype model for non-Newtonian fluids including turbulence. Utilising the Gradient Discretisation Method, we show that the algorithm is long-term stable for a broad class of particular Gradient Discretisations. Building on the long-term stability and the derived continuity of the algorithm's solution operator, we construct two sequences of approximate invariant measures. At the moment, each sequence lacks one important feature: either the existence of a limit measure, or the invariance with respect to the discrete semigroup. We derive an abstract condition that merges both properties, recovering the existence of an invariant measure. We provide an example for which invariance and existence hold simultaneously, and characterise the invariant measure completely. We close the article by conducting two numerical experiments that show the influence of transport noise on the dynamics of power-law fluids; in particular, we find that transport noise enhances the dissipation of kinetic energy, the mixing of particles, as well as the size of vortices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.14316v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.PR</category>
      <pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jerome Droniou, Kim-Ngan Le, J\"orn Wichmann</dc:creator>
    </item>
    <item>
      <title>Gaussian-convolution-invariant shell approximation to spherically-symmetric functions</title>
      <link>https://arxiv.org/abs/2412.14350</link>
      <description>arXiv:2412.14350v1 Announce Type: new 
Abstract: We develop a class of functions Omega_N(x; mu, nu) in N-dimensional space concentrated around a spherical shell of the radius mu and such that, being convoluted with an isotropic Gaussian function, these functions do not change their expression but only a value of its 'width' parameter, nu. Isotropic Gaussian functions are a particular case of Omega_N(x; mu, nu) corresponding to mu = 0. Due to their features, these functions are an efficient tool to build approximations to smooth and continuous spherically-symmetric functions including oscillating ones. Atomic images in limited-resolution maps of the electron density, electrostatic scattering potential and other scalar fields studied in physics, chemistry, biology, and other natural sciences are examples of such functions. We give simple analytic expressions of Omega_N(x; mu, nu) for N = 1, 2, 3 and analyze properties of these functions. Representation of oscillating functions by a sum of Omega_N(x; mu, nu) allows calculating distorted maps for the same cost as the respective theoretical fields. We give practical examples of such representation for the interference functions of the uniform unit spheres for N = 1, 2, 3 that define the resolution of the respective images. Using the chain rule and analytic expressions of the Omega_N(x; mu, nu) derivatives makes simple refinement of parameters of the models which describe these fields.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.14350v1</guid>
      <category>math.NA</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>q-bio.BM</category>
      <pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexandre G. Urzhumtsev, Vladimir Y. Lunin</dc:creator>
    </item>
    <item>
      <title>A Fully Adaptive Radau Method for the Efficient Solution of Stiff Ordinary Differential Equations at Low Tolerances</title>
      <link>https://arxiv.org/abs/2412.14362</link>
      <description>arXiv:2412.14362v1 Announce Type: new 
Abstract: Radau IIA methods, specifically the adaptive order radau method in Fortran due to Hairer, are known to be state-of-the-art for the high-accuracy solution of highly stiff ordinary differential equations (ODEs). However, the traditional implementation was specialized to a specific range of tolerance, in particular only supporting 5th, 9th, and 13th order versions of the tableau and only derived in double precision floating point, thus limiting the ability to be truly general purpose for highly accurate scenarios. To alleviate these constraints, we implement an adaptive-time adaptive-order Radau method which can derive the coefficients for the Radau IIA embedded tableau to any order on the fly to any precision. Additionally, our Julia-based implementation includes many modernizations to improve performance, including improvements to the order adaptation scheme and improved linear algebra integrations. In a head-to-head benchmark against the classic Fortran implementation, we demonstrate our implementation is approximately 2x across a range of stiff ODEs. We benchmark our algorithm against several well-reputed numerical integrators for stiff ODEs and find state-of-the-art performance on several test problems, with a 1.5-times speed-up over common numerical integrators for stiff ODEs when low error tolerance is required. The newly implemented method is distributed in open source software for free usage on stiff ODEs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.14362v1</guid>
      <category>math.NA</category>
      <category>cs.MS</category>
      <category>cs.NA</category>
      <pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Shreyas Ekanathan, Oscar Smith, Christopher Rackauckas</dc:creator>
    </item>
    <item>
      <title>A tensor-train reduced basis solver for parameterized partial differential equations</title>
      <link>https://arxiv.org/abs/2412.14460</link>
      <description>arXiv:2412.14460v1 Announce Type: new 
Abstract: In this manuscript we present the tensor-train reduced basis method, a novel projection-based reduced-order model for the efficient solution of parameterized partial differential equations. Despite their popularity and considerable computational advantages with respect to their full order counterparts, reduced-order models are typically characterized by a considerable offline computational cost. The proposed approach addresses this issue by efficiently representing high dimensional finite element quantities with the tensor train format. This method entails numerous benefits, namely, the smaller number of operations required to compute the reduced subspaces, the cheaper hyper-reduction strategy employed to reduce the complexity of the PDE residual and Jacobian, and the decreased dimensionality of the projection subspaces for a fixed accuracy. We provide a posteriori estimates that demonstrate the accuracy of the proposed method, we test its computational performance for the heat equation and transient linear elasticity on three-dimensional Cartesian geometries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.14460v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicholas Mueller, Yiran Zhao, Santiago Badia, Tiangang Cui</dc:creator>
    </item>
    <item>
      <title>On the Lebesgue constant of the Morrow-Patterson points</title>
      <link>https://arxiv.org/abs/2412.14595</link>
      <description>arXiv:2412.14595v1 Announce Type: new 
Abstract: The study of interpolation nodes and their associated Lebesgue constants are central to numerical analysis, impacting the stability and accuracy of polynomial approximations. In this paper, we will explore the Morrow-Patterson points, a set of interpolation nodes introduced to construct cubature formulas of a minimum number of points in the square for a fixed degree $n$. We prove that their Lebesgue constant growth is ${\cal O}(n^2)$ as was conjectured based on numerical evidence about twenty years ago in the paper by Caliari, M., De Marchi, S., Vianello, M., {\it Bivariate polynomial interpolation on the square at new nodal sets}, Appl. Math. Comput. 165(2) (2005), 261--274.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.14595v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.CA</category>
      <pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tomasz Beberok, Leokadia Bia{\l}as-Cie\.z, Stefano De Marchi</dc:creator>
    </item>
    <item>
      <title>Computing rough solutions of the stochastic nonlinear wave equation</title>
      <link>https://arxiv.org/abs/2412.14644</link>
      <description>arXiv:2412.14644v1 Announce Type: new 
Abstract: The regularity of solutions to the stochastic nonlinear wave equation plays a critical role in the accuracy and efficiency of numerical algorithms. Rough or discontinuous initial conditions pose significant challenges, often leading to a loss of accuracy and reduced computational efficiency in existing methods. In this study, we address these challenges by developing a novel and efficient numerical algorithm specifically designed for computing rough solutions of the stochastic nonlinear wave equation, while significantly relaxing the regularity requirements on the initial data. By leveraging the intrinsic structure of the stochastic nonlinear wave equation and employing advanced tools from harmonic analysis, we construct a time discretization method that achieves robust convergence for initial values \((u^{0}, v^{0}) \in H^{\gamma} \times H^{\gamma-1}\) for all \(\gamma &gt; 0\). Notably, our method attains an improved error rate of \(O(\tau^{2\gamma-})\) in one and two dimensions for \(\gamma \in (0, \frac{1}{2}]\), and \(O(\tau^{\max(\gamma, 2\gamma - \frac{1}{2}-)})\) in three dimensions for \(\gamma \in (0, \frac{3}{4}]\), where \(\tau\) denotes the time step size. These convergence rates surpass those of existing numerical methods under the same regularity conditions, underscoring the advantage of our approach. To validate the performance of our method, we present extensive numerical experiments that demonstrate its superior accuracy and computational efficiency compared to state-of-the-art methods. These results highlight the potential of our approach to enable accurate and efficient simulations of stochastic wave phenomena even in the presence of challenging initial conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.14644v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiachuan Cao, Buyang Li, Katharina Schratz</dc:creator>
    </item>
    <item>
      <title>A preconditioned inverse iteration with an improved convergence guarantee</title>
      <link>https://arxiv.org/abs/2412.14665</link>
      <description>arXiv:2412.14665v1 Announce Type: new 
Abstract: Preconditioned eigenvalue solvers offer the possibility to incorporate preconditioners for the solution of large-scale eigenvalue problems, as they arise from the discretization of partial differential equations. The convergence analysis of such methods is intricate. Even for the relatively simple preconditioned inverse iteration (PINVIT), which targets the smallest eigenvalue of a symmetric positive definite matrix, the celebrated analysis by Neymeyr is highly nontrivial and only yields convergence if the starting vector is fairly close to the desired eigenvector. In this work, we prove a new non-asymptotic convergence result for a variant of PINVIT. Our proof proceeds by analyzing an equivalent Riemannian steepest descent method and leveraging convexity-like properties. We show a convergence rate that nearly matches the one of PINVIT. As a major benefit, we require a condition on the starting vector that tends to be less stringent. This improved global convergence property is demonstrated for two classes of preconditioners with theoretical bounds and a range of numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.14665v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Foivos Alimisis, Daniel Kressner, Nian Shao, Bart Vandereycken</dc:creator>
    </item>
    <item>
      <title>Numerical Robustness of PINNs for Multiscale Transport Equations</title>
      <link>https://arxiv.org/abs/2412.14683</link>
      <description>arXiv:2412.14683v1 Announce Type: new 
Abstract: We investigate the numerical solution of multiscale transport equations using Physics Informed Neural Networks (PINNs) with ReLU activation functions. Therefore, we study the analogy between PINNs and Least-Squares Finite Elements (LSFE) which lies in the shared approach to reformulate the PDE solution as a minimization of a quadratic functional. We prove that in the diffusive regime, the correct limit is not reached, in agreement with known results for first-order LSFE. A diffusive scaling is introduced that can be applied to overcome this, again in full agreement with theoretical results for LSFE. We provide numerical results in the case of slab geometry that support our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.14683v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alexander Jesser, Kai Krycki, Ryan G. McClarren, Martin Frank</dc:creator>
    </item>
    <item>
      <title>Physics informed neural network for forward and inverse radiation heat transfer in graded-index medium</title>
      <link>https://arxiv.org/abs/2412.14699</link>
      <description>arXiv:2412.14699v1 Announce Type: new 
Abstract: Radiation heat transfer in a graded-index medium often suffers accuracy problems due to the gradual changes in the refractive index. The finite element method, meshfree, and other numerical methods often struggle to maintain accuracy when applied to this medium. To address this issue, we apply physics-informed neural networks (PINNs)-based machine learning algorithms to simulate forward and inverse problems for this medium. We also provide the theoretical upper bounds. This theoretical framework is validated through numerical experiments of predefined and newly developed models that demonstrate the accuracy and robustness of the algorithms in solving radiation transport problems in the medium. The simulations show that the novel algorithm goes on with numerical stability and effectively mitigates oscillatory errors, even in cases with more pronounced variations in the refractive index.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.14699v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>K. Murari, S. Sundar</dc:creator>
    </item>
    <item>
      <title>A Meshfree RBF-FD Constant along Normal Method for Solving PDEs on Surfaces</title>
      <link>https://arxiv.org/abs/2412.14761</link>
      <description>arXiv:2412.14761v1 Announce Type: new 
Abstract: This paper introduces a novel meshfree methodology based on Radial Basis Function-Finite Difference (RBF-FD) approximations for the numerical solution of partial differential equations (PDEs) on surfaces of codimension 1 embedded in $\mathbb{R}^3$. The method is built upon the principles of the closest point method, without the use of a grid or a closest point mapping. We show that the combination of local embedded stencils with these principles can be employed to approximate surface derivatives using polyharmonic spline kernels and polynomials (PHS+Poly) RBF-FD. Specifically, we show that it is enough to consider a constant extension along the normal direction only at a single node to overcome the rank deficiency of the polynomial basis. An extensive parameter analysis is presented to test the dependence of the approach. We demonstrate high-order convergence rates on problems involving surface advection and surface diffusion, and solve Turing pattern formations on surfaces defined either implicitly or by point clouds. Moreover, a simple coupling approach with a particle tracking method demonstrates the potential of the proposed method in solving PDEs on evolving surfaces in the normal direction. Our numerical results confirm the stability, flexibility, and high-order algebraic convergence of the approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.14761v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1137/23M1621265</arxiv:DOI>
      <arxiv:journal_reference>SIAM Journal on Scientific Computing, 46(6), A3897-A3921, 2024</arxiv:journal_reference>
      <dc:creator>V\'ictor Bayona, Argyrios Petras, C\'ecile Piret, Steven J. Ruuth</dc:creator>
    </item>
    <item>
      <title>Average case tractability of multivariate approximation with Gevrey type kernels</title>
      <link>https://arxiv.org/abs/2412.14791</link>
      <description>arXiv:2412.14791v1 Announce Type: new 
Abstract: We consider multivariate approximation problems in the average case setting with a zero mean Gaussian measure whose covariance kernel is a periodic Gevrey kernel. We investigate various notions of algebraic tractability and exponential tractability, and obtain necessary and sufficient conditions in terms of the parameters of the problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.14791v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wanting Lu, Heping Wang</dc:creator>
    </item>
    <item>
      <title>Projection-based preprocessing for electrical impedance tomography to reduce the effect of electrode contacts</title>
      <link>https://arxiv.org/abs/2412.15009</link>
      <description>arXiv:2412.15009v1 Announce Type: new 
Abstract: This work introduces a method for preprocessing measurements of electrical impedance tomography to considerably reduce the effect uncertainties in the electrode contacts have on the reconstruction quality, without a need to explicitly estimate the contacts. The idea is to compute the Jacobian matrix of the forward map with respect to the contact strengths and project the electrode measurements and the forward map onto the orthogonal complement of the range of this Jacobian. Using the smoothened complete electrode model as the forward model, it is demonstrated that inverting the resulting projected equation with respect to only the internal conductivity of the examined body results in good quality reconstructions both when resorting to a single step linearization with a smoothness prior and when combining lagged diffusivity iteration with total variation regularization. The quality of the reconstructions is further improved if the range of the employed projection is also orthogonal to that of the Jacobian with respect to the electrode positions. These results hold even if the projections are formed at internal and contact conductivities that significantly differ from the true ones; it is numerically demonstrated that the orthogonal complement of the range of the contact Jacobian is almost independent of the conductivity parameters at which it is evaluated. In particular, our observations introduce a numerical technique for inferring whether a change in the electrode measurements is caused by a change in the internal conductivity or alterations in the electrode contacts, which has potential applications, e.g., in bedside monitoring of stroke patients. The ideas are tested both on simulated data and on real-world water tank measurements with adjustable contact resistances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.15009v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Altti J\"a\"askel\"ainen, Jussi Toivanen, Asko H\"anninen, Ville Kolehmainen, Nuutti Hyv\"onen</dc:creator>
    </item>
    <item>
      <title>Numerical analysis and simulation of lateral memristive devices: Schottky, ohmic, and multi-dimensional electrode models</title>
      <link>https://arxiv.org/abs/2412.15065</link>
      <description>arXiv:2412.15065v1 Announce Type: new 
Abstract: In this paper, we present the numerical analysis and simulations of a multi-dimensional memristive device model. Memristive devices and memtransistors based on two-dimensional (2D) materials have demonstrated promising potential as components for next-generation artificial intelligence (AI) hardware and information technology. Our charge transport model describes the drift-diffusion of electrons, holes, and ionic defects self-consistently in an electric field. We incorporate two types of boundary models: ohmic and Schottky contacts. The coupled drift-diffusion partial differential equations are discretized using a physics-preserving Voronoi finite volume method. It relies on an implicit time-stepping scheme and the excess chemical potential flux approximation. We demonstrate that the fully discrete nonlinear scheme is unconditionally stable, preserving the free-energy structure of the continuous system and ensuring the non-negativity of carrier densities. Novel discrete entropy-dissipation inequalities for both boundary condition types in multiple dimensions allow us to prove the existence of discrete solutions. We perform multi-dimensional simulations to understand the impact of electrode configurations and device geometries, focusing on the hysteresis behavior in lateral 2D memristive devices. Three electrode configurations -- side, top, and mixed contacts -- are compared numerically for different geometries and boundary conditions. These simulations reveal the conditions under which a simplified one-dimensional electrode geometry can well represent the three electrode configurations. This work lays the foundations for developing accurate, efficient simulation tools for 2D memristive devices and memtransistors, offering tools and guidelines for their design and optimization in future applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.15065v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.app-ph</category>
      <pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dilara Abdel, Maxime Herda, Martin Ziegler, Claire Chainais-Hillairet, Benjamin Spetzler, Patricio Farrell</dc:creator>
    </item>
    <item>
      <title>A review of high order strong stability preserving two-derivative explicit, implicit, and IMEX methods</title>
      <link>https://arxiv.org/abs/2412.15142</link>
      <description>arXiv:2412.15142v1 Announce Type: new 
Abstract: High order strong stability preserving (SSP) time discretizations ensure the nonlinear non-inner-product strong stability properties of spatial discretizations suited for the stable simulation of hyperbolic PDEs. Over the past decade multiderivative time-stepping have been used for the time-evolution hyperbolic PDEs, so that the strong stability properties of these methods have become increasingly relevant. In this work we review sufficient conditions for a two-derivative multistage method to preserve the strong stability properties of spatial discretizations in a forward Euler and different conditions on the second derivative. In particular we present the SSP theory for explicit and implicit two-derivative Runge--Kutta schemes, and discuss a special condition on the second derivative under which these implicit methods may be unconditionally SSP. This condition is then used in the context of implicit-explicit (IMEX) multi-derivative Runge--Kutta schemes, where the time-step restriction is independent of the stiff term. Finally, we present the SSP theory for implicit-explicit (IMEX) multi-derivative general linear methods, and some novel second and third order methods where the time-step restriction is independent of the stiff term.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.15142v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sigal Gottlieb, Zachary J. Grant</dc:creator>
    </item>
    <item>
      <title>Long-time accuracy of ensemble Kalman filters for chaotic and machine-learned dynamical systems</title>
      <link>https://arxiv.org/abs/2412.14318</link>
      <description>arXiv:2412.14318v1 Announce Type: cross 
Abstract: Filtering is concerned with online estimation of the state of a dynamical system from partial and noisy observations. In applications where the state is high dimensional, ensemble Kalman filters are often the method of choice. This paper establishes long-time accuracy of ensemble Kalman filters. We introduce conditions on the dynamics and the observations under which the estimation error remains small in the long-time horizon. Our theory covers a wide class of partially-observed chaotic dynamical systems, which includes the Navier-Stokes equations and Lorenz models. In addition, we prove long-time accuracy of ensemble Kalman filters with surrogate dynamics, thus validating the use of machine-learned forecast models in ensemble data assimilation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.14318v1</guid>
      <category>math.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Sanz-Alonso, Nathan Waniorek</dc:creator>
    </item>
    <item>
      <title>MUSTER: Longitudinal Deformable Registration by Composition of Consecutive Deformations</title>
      <link>https://arxiv.org/abs/2412.14671</link>
      <description>arXiv:2412.14671v1 Announce Type: cross 
Abstract: Longitudinal imaging allows for the study of structural changes over time. One approach to detecting such changes is by non-linear image registration. This study introduces Multi-Session Temporal Registration (MUSTER), a novel method that facilitates longitudinal analysis of changes in extended series of medical images. MUSTER improves upon conventional pairwise registration by incorporating more than two imaging sessions to recover longitudinal deformations. Longitudinal analysis at a voxel-level is challenging due to effects of a changing image contrast as well as instrumental and environmental sources of bias between sessions. We show that local normalized cross-correlation as an image similarity metric leads to biased results and propose a robust alternative. We test the performance of MUSTER on a synthetic multi-site, multi-session neuroimaging dataset and show that, in various scenarios, using MUSTER significantly enhances the estimated deformations relative to pairwise registration. Additionally, we apply MUSTER on a sample of older adults from the Alzheimer's Disease Neuroimaging Initiative (ADNI) study. The results show that MUSTER can effectively identify patterns of neuro-degeneration from T1-weighted images and that these changes correlate with changes in cognition, matching the performance of state of the art segmentation methods. By leveraging GPU acceleration, MUSTER efficiently handles large datasets, making it feasible also in situations with limited computational resources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.14671v1</guid>
      <category>cs.CV</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Edvard O. S. Gr{\o}dem, Donatas Sederevi\v{c}ius, Esten H. Leonardsen, Bradley J. MacIntosh, Atle Bj{\o}rnerud, Till Schellhorn, {\O}ystein S{\o}rensen, Inge Amlien, Pablo F. Garrido, Anders M. Fjell</dc:creator>
    </item>
    <item>
      <title>Dimension reduction for path signatures</title>
      <link>https://arxiv.org/abs/2412.14723</link>
      <description>arXiv:2412.14723v1 Announce Type: cross 
Abstract: This paper focuses on the mathematical framework for reducing the complexity of models using path signatures. The structure of these signatures, which can be interpreted as collections of iterated integrals along paths, is discussed and their applications in areas such as stochastic differential equations (SDEs) and financial modeling are pointed out. In particular, exploiting the rough paths view, solutions of SDEs continuously depend on the lift of the driver. Such continuous mappings can be approximated using (truncated) signatures, which are solutions of high-dimensional linear systems. In order to lower the complexity of these models, this paper presents methods for reducing the order of high-dimensional truncated signature models while retaining essential characteristics. The derivation of reduced models and the universal approximation property of (truncated) signatures are treated in detail. Numerical examples, including applications to the (rough) Bergomi model in financial markets, illustrate the proposed reduction techniques and highlight their effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.14723v1</guid>
      <category>math.PR</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christian Bayer, Martin Redmann</dc:creator>
    </item>
    <item>
      <title>An analysis of the Rayleigh-Ritz and refined Rayleigh-Ritz methods for regular nonlinear eigenvalue problems</title>
      <link>https://arxiv.org/abs/2212.00302</link>
      <description>arXiv:2212.00302v3 Announce Type: replace 
Abstract: We establish a general convergence theory of the Rayleigh--Ritz method and the refined Rayleigh--Ritz method for computing some simple eigenpair $(\lambda_{*},x_{*})$ of a given analytic regular nonlinear eigenvalue problem (NEP). In terms of the deviation $\varepsilon$ of $x_{*}$ from a given subspace $\mathcal{W}$, we establish a priori convergence results on the Ritz value, the Ritz vector and the refined Ritz vector. The results show that, as $\varepsilon\rightarrow 0$, there exists a Ritz value that unconditionally converges to $\lambda_*$ and the corresponding refined Ritz vector does so too but the Ritz vector converges conditionally and it may fail to converge and even may not be unique. We also present an error bound for the approximate eigenvector in terms of the computable residual norm of a given approximate eigenpair, and give lower and upper bounds for the error of the refined Ritz vector and the Ritz vector as well as for that of the corresponding residual norms. These results nontrivially extend some convergence results on these two methods for the linear eigenvalue problem to the NEP. Examples are constructed to illustrate the main results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.00302v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhongxiao Jia, Qingqing Zheng</dc:creator>
    </item>
    <item>
      <title>Accuracy Controlled Schemes for the Eigenvalue Problem of the Radiative Transfer Equation</title>
      <link>https://arxiv.org/abs/2307.07780</link>
      <description>arXiv:2307.07780v4 Announce Type: replace 
Abstract: The criticality problem in nuclear engineering asks for the principal eigenpair of a Boltzmann operator describing neutron transport in a reactor core. Being able to reliably design, and control such reactors requires assessing these quantities within quantifiable accuracy tolerances. In this paper we propose a paradigm that deviates from the common practice of approximately solving the corresponding spectral problem with a fixed, presumably sufficiently fine discretization. Instead, the present approach is based on first contriving iterative schemes, formulated in function space, that are shown to converge at a quantitative rate without assuming any a priori excess regularity properties, and that exploit only properties of the optical parameters in the underlying radiative transfer model. We develop the analytical and numerical tools for approximately realizing each iteration step within judiciously chosen accuracy tolerances, verified by a posteriori estimates, so as to still warrant quantifiable convergence to the exact eigenpair. This is carried out in full first for a Newton scheme. Since this is only locally convergent we analyze in addition the convergence of a power iteration in function space to produce sufficiently accurate initial guesses. Here we have to deal with intrinsic difficulties posed by compact but unsymmetric operators preventing standard arguments used in the finite dimensional case. Our main point is that we can avoid any condition on an initial guess to be already in a small neighborhood of the exact solution. We close with a discussion of remaining intrinsic obstructions to a certifiable numerical implementation, mainly related to not knowing the gap between the principal eigenvalue and the next smaller one in modulus.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.07780v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.SP</category>
      <pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wolfgang Dahmen, Olga Mula</dc:creator>
    </item>
    <item>
      <title>A filtered multilevel Monte Carlo method for estimating the expectation of cell-centered discretized random fields</title>
      <link>https://arxiv.org/abs/2311.06069</link>
      <description>arXiv:2311.06069v2 Announce Type: replace 
Abstract: We investigate the use of multilevel Monte Carlo (MLMC) methods for estimating the expectation of discretized random fields. Specifically, we consider a setting in which the input and output vectors of numerical simulators have inconsistent dimensions across the multilevel hierarchy. This requires the introduction of grid transfer operators borrowed from multigrid methods. By adapting mathematical tools from multigrid methods, we perform a theoretical spectral analysis of the MLMC estimator of the expectation of discretized random fields, in the specific case of linear, symmetric and circulant simulators. We then propose filtered MLMC (F-MLMC) estimators based on a filtering mechanism similar to the smoothing process of multigrid methods, and we show that the filtering operators improve the estimation of both the small- and large-scale components of the variance, resulting in a reduction of the total variance of the estimator. Next, the conclusions of the spectral analysis are experimentally verified with a one-dimensional illustration. Finally, the proposed F-MLMC estimator is applied to the problem of estimating the discretized variance field of a diffusion-based covariance operator, which amounts to estimating the expectation of a discretized random field. The numerical experiments support the conclusions of the theoretical analysis even with non-linear simulators, and demonstrate the improvements brought by the F-MLMC estimator compared to both a crude MC and an unfiltered MLMC estimator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.06069v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>J\'er\'emy Briant (Irit CNRS-INP, CECI CNRS-Cerfacs), Paul Mycek (CECI CNRS-Cerfacs), Mayeul Destouches (Met Office), Olivier Goux (CECI CNRS-Cerfacs), Serge Gratton (Irit CNRS-INP, ANITI), Selime G\"urol (CECI CNRS-Cerfacs), Ehouarn Simon (Irit CNRS-INP), Anthony T. Weaver (CECI CNRS-Cerfacs)</dc:creator>
    </item>
    <item>
      <title>Contractivity of neural ODEs: an eigenvalue optimization problem</title>
      <link>https://arxiv.org/abs/2402.13092</link>
      <description>arXiv:2402.13092v3 Announce Type: replace 
Abstract: We propose a novel methodology to solve a key eigenvalue optimization problem which arises in the contractivity analysis of neural ODEs. When looking at contractivity properties of a one layer weight-tied neural ODE $\dot{u}(t)=\sigma(Au(t)+b)$ (with $u,b \in {\mathbb R}^n$, $A$ is a given $n \times n$ matrix, $\sigma : {\mathbb R} \to {\mathbb R}$ denotes an activation function and for a vector $z \in {\mathbb R}^n$, $\sigma(z) \in {\mathbb R}^n$ has to be interpreted entry-wise), we are led to study the logarithmic norm of a set of products of type $D A$, where $D$ is a diagonal matrix such that ${\mathrm{diag}}(D) \in \sigma'({\mathbb R}^n)$. Specifically, given a real number $c$ (usually $c=0$), the problem consists in finding the largest positive interval $\text{I}\subseteq \mathbb [0,\infty)$ such that the logarithmic norm $\mu(DA) \le c$ for all diagonal matrices $D$ with $D_{ii}\in \text{I}$. We propose a two-level nested methodology: an inner level where, for a given $\text{I}$, we compute an optimizer $D^\star(\text{I})$ by a gradient system approach, and an outer level where we tune $\text{I}$ so that the value $c$ is reached by $\mu(D^\star(\text{I})A)$. We extend the proposed two-level approach to the general multilayer, and possibly time-dependent, case $\dot{u}(t) = \sigma( A_k(t) \ldots \sigma ( A_{1}(t) u(t) + b_{1}(t) ) \ldots + b_{k}(t) )$ and we propose several numerical examples to illustrate its behaviour, including its stabilizing performance on a one-layer neural ODE applied to the classification of the MNIST handwritten digits dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.13092v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicola Guglielmi, Arturo De Marinis, Anton Savostianov, Francesco Tudisco</dc:creator>
    </item>
    <item>
      <title>Hessian-free force-gradient integrators</title>
      <link>https://arxiv.org/abs/2403.10370</link>
      <description>arXiv:2403.10370v2 Announce Type: replace 
Abstract: We propose a new framework of Hessian-free force-gradient integrators that do not require the analytical expression of the force-gradient term based on the Hessian of the potential. Due to that the new class of decomposition algorithms for separable Hamiltonian systems with quadratic kinetic energy may be particularly useful when applied to Hamiltonian systems where an evaluation of the Hessian is significantly more expensive than an evaluation of its gradient, e.g. in molecular dynamics simulations of classical systems. Numerical experiments of an N-body problem, as well as applications to the molecular dynamics step in the Hybrid Monte Carlo (HMC) algorithm for lattice simulations of the Schwinger model and Quantum Chromodynamics (QCD) verify these expectations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10370v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>hep-lat</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Kevin Sch\"afers, Jacob Finkenrath, Michael G\"unther, Francesco Knechtli</dc:creator>
    </item>
    <item>
      <title>Solution of parameter-dependent diffusion equation in layered media</title>
      <link>https://arxiv.org/abs/2407.02257</link>
      <description>arXiv:2407.02257v2 Announce Type: replace 
Abstract: This work studies the parameter-dependent diffusion equation in a two-dimensional domain consisting of locally mirror symmetric layers. It is assumed that the diffusion coefficient is a constant in each layer. The goal is to find approximate parameter-to-solution maps that have a small number of terms. It is shown that in the case of two layers one can find a solution formula consisting of three terms with explicit dependencies on the diffusion coefficient. The formula is based on decomposing the solution into orthogonal parts related to both of the layers and the interface between them. This formula is then expanded to an approximate one for the multi-layer case. We give an analytical formula for square layers and use the finite element formulation for more general layers. The results are illustrated with numerical examples and have applications for reduced basis methods by analyzing the Kolmogorov n-width.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02257v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Antti Autio, Antti Hannukainen</dc:creator>
    </item>
    <item>
      <title>Stable Rank and Intrinsic Dimension of Real and Complex Matrices</title>
      <link>https://arxiv.org/abs/2407.21594</link>
      <description>arXiv:2407.21594v2 Announce Type: replace 
Abstract: The notion of `stable rank' of a matrix is central to the analysis of randomized matrix algorithms, covariance estimation, deep neural networks, and recommender systems. We compare the properties of the stable rank and intrinsic dimension of real and complex matrices to those of the classical rank. Basic proofs and examples illustrate that the stable rank does not satisfy any of the fundamental rank properties, while the intrinsic dimension satisfies a few. In particular, the stable rank and intrinsic dimension of a submatrix can exceed those of the original matrix; adding a Hermitian positive semi-definite matrix can lower the intrinsic dimension of the sum; and multiplication by a nonsingular matrix can drastically change the stable rank and the intrinsic dimension. We generalize the concept of stable rank to the p-stable in any Schatten p-norm, thereby unifying the concepts of stable rank and intrinsic dimension: The stable rank is the 2-stable rank, while the intrinsic dimension is the 1-stable rank of a Hermitian positive semi-definite matrix. We derive sum and product inequalities for the pth root of the p-stable rank, and show that it is well-conditioned in the norm-wise absolute sense. The conditioning improves if the matrix and the perturbation are Hermitian positive semi-definite.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.21594v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ilse C. F. Ipsen, Arvind K. Saibaba</dc:creator>
    </item>
    <item>
      <title>Neural network approaches for variance reduction in fluctuation formulas</title>
      <link>https://arxiv.org/abs/2410.00278</link>
      <description>arXiv:2410.00278v2 Announce Type: replace 
Abstract: We propose a method utilizing physics-informed neural networks (PINNs) to solve Poisson equations that serve as control variates in the computation of transport coefficients via fluctuation formulas, such as the Green--Kubo and generalized Einstein-like formulas. By leveraging approximate solutions to the Poisson equation constructed through neural networks, our approach significantly reduces the variance of the estimator at hand. We provide an extensive numerical analysis of the estimators and detail a methodology for training neural networks to solve these Poisson equations. The approximate solutions are then incorporated into Monte Carlo simulations as effective control variates, demonstrating the suitability of the method for moderately high-dimensional problems where fully deterministic solutions are computationally infeasible.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00278v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Grigorios Pavliotis, Renato Spacek, Gabriel Stoltz, Urbain Vaes</dc:creator>
    </item>
    <item>
      <title>Asymptotic expansion for the Hartman-Watson distribution</title>
      <link>https://arxiv.org/abs/2001.09579</link>
      <description>arXiv:2001.09579v3 Announce Type: replace-cross 
Abstract: The Hartman-Watson distribution with density $f_r(t)$ is a probability distribution defined on $t \geq 0$ which appears in several problems of applied probability. The density of this distribution is expressed in terms of an integral $\theta(r,t)$ which is difficult to evaluate numerically for small $t\to 0$. Using saddle point methods, we obtain the first two terms of the $t\to 0$ expansion of $\theta(\rho/t,t)$ at fixed $\rho &gt;0$. An error bound is obtained by numerical estimates of the integrand, which is furthermore uniform in $\rho$. As an application we obtain the leading asymptotics of the density of the time average of the geometric Brownian motion as $t\to 0$. This has the form $\mathbb{P}(\frac{1}{t} \int_0^t e^{2(B_s+\mu s)} ds \in da) \sim (2\pi t)^{-1/2} g(a,\mu) e^{-\frac{1}{t} J(a)} da/a$, with an exponent $J(a)$ which reproduces the known result obtained previously using Large Deviations theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2001.09579v3</guid>
      <category>math.PR</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>q-fin.MF</category>
      <pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s11009-020-09827-5</arxiv:DOI>
      <dc:creator>Dan Pirjol</dc:creator>
    </item>
    <item>
      <title>Scalable Acceleration for Classification-Based Derivative-Free Optimization</title>
      <link>https://arxiv.org/abs/2309.11036</link>
      <description>arXiv:2309.11036v2 Announce Type: replace-cross 
Abstract: Derivative-free optimization algorithms play an important role in scientific and engineering design optimization problems, especially when derivative information is not accessible. In this paper, we study the framework of sequential classification-based derivative-free optimization algorithms. By introducing learning theoretic concept hypothesis-target shattering rate, we revisit the computational complexity upper bound of SRACOS (Hu, Qian, and Yu 2017). Inspired by the revisited upper bound, we propose an algorithm named RACE-CARS, which adds a random region-shrinking step compared with SRACOS. We further establish theorems showing the acceleration by region shrinking. Experiments on the synthetic functions as well as black-box tuning for language-model-as-a-service demonstrate empirically the efficiency of RACE-CARS. An ablation experiment on the introduced hyperparameters is also conducted, revealing the mechanism of RACE-CARS and putting forward an empirical hyper-parameter tuning guidance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.11036v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Tianyi Han, Jingya Li, Zhipeng Guo, Yuan Jin</dc:creator>
    </item>
    <item>
      <title>Covering convection with thermal blankets: fluid-structure interactions in thermal convection</title>
      <link>https://arxiv.org/abs/2404.01172</link>
      <description>arXiv:2404.01172v3 Announce Type: replace-cross 
Abstract: The continental plates of Earth are known to drift over a geophysical timescale, and their interactions have lead to some of the most spectacular geoformations of our planet while also causing natural disasters such as earthquakes and volcanic activity. Understanding the dynamics of interacting continental plates is thus significant. In this work, we present a fluid mechanical investigation of the plate motion, interaction, and dynamics. Through numerical experiments, we examine the coupling between a convective fluid and plates floating on top of it. With physical modeling, we show the coupling is both mechanical and thermal, leading to the thermal blanket effect: the floating plate is not only transported by the fluid flow beneath, it also prevents the heat from leaving the fluid, leading to a convective flow that further affects the plate motion. By adding several plates to such a coupled fluid-structure interaction, we also investigate how floating plates interact with each other and show that, under proper conditions, small plates can converge into a supercontinent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01172v3</guid>
      <category>physics.flu-dyn</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jinzi Mac Huang</dc:creator>
    </item>
    <item>
      <title>Learning from Linear Algebra: A Graph Neural Network Approach to Preconditioner Design for Conjugate Gradient Solvers</title>
      <link>https://arxiv.org/abs/2405.15557</link>
      <description>arXiv:2405.15557v2 Announce Type: replace-cross 
Abstract: Large linear systems are ubiquitous in modern computational science and engineering. The main recipe for solving them is the use of Krylov subspace iterative methods with well-designed preconditioners. Deep learning models can be used as nonlinear preconditioners during the iteration of linear solvers such as the conjugate gradient (CG) method. Neural network models require an enormous number of parameters to approximate well in this setup. Another approach is to take advantage of small graph neural networks (GNNs) to construct preconditioners with predefined sparsity patterns. Recently, GNNs have been shown to be a promising tool for designing preconditioners to reduce the overall computational cost of iterative methods by constructing them more efficiently than with classical linear algebra techniques. However, preconditioners designed with these approaches cannot outperform those designed with classical methods in terms of the number of iterations in CG. In our work, we recall well-established preconditioners from linear algebra and use them as a starting point for training the GNN to obtain preconditioners that reduce the condition number of the system more significantly. Numerical experiments show that our approach outperforms both classical and neural network-based methods for an important class of parametric partial differential equations. We also provide a heuristic justification for the loss function used and show that preconditioners obtained by learning with this loss function reduce the condition number in a more desirable way for CG.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15557v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vladislav Trifonov, Alexander Rudikov, Oleg Iliev, Yuri M. Laevsky, Ivan Oseledets, Ekaterina Muravleva</dc:creator>
    </item>
    <item>
      <title>Accelerating AI Performance using Anderson Extrapolation on GPUs</title>
      <link>https://arxiv.org/abs/2410.19460</link>
      <description>arXiv:2410.19460v2 Announce Type: replace-cross 
Abstract: We present a novel approach for accelerating AI performance by leveraging Anderson extrapolation, a vector-to-vector mapping technique based on a window of historical iterations. By identifying the crossover point (Fig. 1) where a mixing penalty is incurred, the method focuses on reducing iterations to convergence, with fewer more compute-intensive but generally cacheable iterations, balancing speed and memory usage with accuracy and algorithmic stability, respectively. We demonstrate significant improvements, in both training and inference, motivated by scalability and efficiency extensions to the realm of high-performance computing (HPC).</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19460v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>cs.PF</category>
      <category>math.NA</category>
      <pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Neural Information Processing Systems (NeurIPS). Machine Learning with New Compute Paradigms (MLNCP) Workshop, October 2024</arxiv:journal_reference>
      <dc:creator>Saleem Abdul Fattah Ahmed Al Dajani, David E. Keyes</dc:creator>
    </item>
    <item>
      <title>A subgradient splitting algorithm for optimization on nonpositively curved metric spaces</title>
      <link>https://arxiv.org/abs/2412.06730</link>
      <description>arXiv:2412.06730v2 Announce Type: replace-cross 
Abstract: Many of the primal ingredients of convex optimization extend naturally from Euclidean to Hadamard spaces $\unicode{x2014}$ nonpositively curved metric spaces like Euclidean, Hilbert, and hyperbolic spaces, metric trees, and more general CAT(0) cubical complexes. Linear structure, however, and the duality theory it supports are absent. Nonetheless, we introduce a new type of subgradient for convex functions on Hadamard spaces, based on Busemann functions. This notion supports a splitting subgradient method with guaranteed complexity bounds. In particular, the algorithm solves $p$-mean problems in general Hadamard spaces: we illustrate by computing medians in BHV tree space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06730v2</guid>
      <category>math.OC</category>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ariel Goodwin, Adrian S. Lewis, Genaro L\'opez-Acedo, Adriana Nicolae</dc:creator>
    </item>
  </channel>
</rss>
