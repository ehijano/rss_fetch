<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DL</link>
    <description>cs.DL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 29 Dec 2025 05:00:24 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 29 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Beyond Content: How Author Network Centrality Drives Citation Disparities in Top AI Conferences</title>
      <link>https://arxiv.org/abs/2512.21832</link>
      <description>arXiv:2512.21832v1 Announce Type: new 
Abstract: While scholarly citations are pivotal for assessing academic impact, they often reflect systemic biases beyond research quality. This study examines a critical yet underexplored driver of citation disparities: authors' structural positions within scientific collaboration networks. Through a large-scale analysis of 17,942 papers from three top-tier machine learning conferences (NeurIPS, ICML, ICLR) published between 2005 and 2024, we quantify the influence of author centrality on citations. Methodologically, we advance the field by employing beta regression to model citation percentiles, which appropriately accounts for the bounded nature of citation data. We also propose a novel centrality metric, Harmonic Closeness with Temporal and Collaboration Count Decay (HCTCD), which incorporates temporal decay and collaboration intensity. Our results robustly demonstrate that long-term centrality exerts a significantly stronger effect on citation percentiles than short-term metrics, with closeness centrality and HCTCD emerging as the most potent predictors. Importantly, team-level centrality aggregation, particularly through exponentially weighted summation, explains citation variance more effectively than conventional rank-based approaches, underscoring the primacy of collective network connectivity over individual prominence. Integrating centrality features into machine learning models yields a 2.4% to 4.8% reduction in prediction error (MSE), confirming their value beyond content-based benchmarks. These findings challenge entrenched evaluation paradigms and advocate for network-aware assessment frameworks to mitigate structural inequities in scientific recognition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.21832v1</guid>
      <category>cs.DL</category>
      <category>cs.SI</category>
      <pubDate>Mon, 29 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Renlong Jie, Longfeng Zhao, Chen Chu, Danyang Jia, Zhen Wang</dc:creator>
    </item>
  </channel>
</rss>
