<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 26 Jul 2024 01:40:52 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 25 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Distributed Difference of Convex Optimization</title>
      <link>https://arxiv.org/abs/2407.16728</link>
      <description>arXiv:2407.16728v1 Announce Type: new 
Abstract: In this article, we focus on solving a class of distributed optimization problems involving $n$ agents with the local objective function at every agent $i$ given by the difference of two convex functions $f_i$ and $g_i$ (difference-of-convex (DC) form), where $f_i$ and $g_i$ are potentially nonsmooth. The agents communicate via a directed graph containing $n$ nodes. We create smooth approximations of the functions $f_i$ and $g_i$ and develop a distributed algorithm utilizing the gradients of the smooth surrogates and a finite-time approximate consensus protocol. We term this algorithm as DDC-Consensus. The developed DDC-Consensus algorithm allows for non-symmetric directed graph topologies and can be synthesized distributively. We establish that the DDC-Consensus algorithm converges to a stationary point of the nonconvex distributed optimization problem. The performance of the DDC-Consensus algorithm is evaluated via a simulation study to solve a nonconvex DC-regularized distributed least squares problem. The numerical results corroborate the efficacy of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16728v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Vivek Khatana, Murti V. Salapaka</dc:creator>
    </item>
    <item>
      <title>Modeling and solving cascading failures across interdependent infrastructure systems</title>
      <link>https://arxiv.org/abs/2407.16796</link>
      <description>arXiv:2407.16796v1 Announce Type: new 
Abstract: Physical infrastructure systems supply crucial resources to residential, commercial, and industrial activities. These infrastructure systems generally consist of multiple types of infrastructure assets that are interdependent. In the event of a disaster, some of the infrastructure assets can be damaged and disabled, creating failures that propagate to other assets that depend on the disabled assets and cause a cascade of failures that may lead to a potential system collapse. We present a bilevel interdiction model in this paper to study this problem of cascading failures in a system of interdependent infrastructure systems with a nondeterministic dependency graph. We also propose a computationally tractable reformulation of the proposed bilevel model and utilize a Benders-type decomposition algorithm to solve the resulting formulation. Computational experiments are performed using infrastructure networks generated from anonymized real-world data to validate the performance of this algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16796v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yijiang Li, Kibaek Kim, Sven Leyffer, Matt Menickelly, Lawrence Paul Lewis, Joshua Bergerson</dc:creator>
    </item>
    <item>
      <title>Neural Network-Based Bandit: A Medium Access Control for the IIoT Alarm Scenario</title>
      <link>https://arxiv.org/abs/2407.16877</link>
      <description>arXiv:2407.16877v1 Announce Type: new 
Abstract: Efficient Random Access (RA) is critical for enabling reliable communication in Industrial Internet of Things (IIoT) networks. Herein, we propose a deep reinforcement learning based distributed RA scheme, entitled Neural Network-Based Bandit (NNBB), for the IIoT alarm scenario. In such a scenario, the devices may detect a common critical event, and the goal is to ensure the alarm information is delivered successfully from at least one device. The proposed NNBB scheme is implemented at each device, where it trains itself online and establishes implicit inter-device coordination to achieve the common goal. Devices can transmit simultaneously on multiple orthogonal channels and each possible transmission pattern constitutes a possible action for the NNBB, which uses a deep neural network to determine the action. Our simulation results show that as the number of devices in the network increases, so does the performance gain of the NNBB compared to the Multi-Armed Bandit (MAB) RA benchmark. For instance, NNBB experiences a 7% success rate drop when there are four channels and the number of devices increases from 10 to 60, while MAB faces a 25% drop.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16877v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Prasoon Raghuwanshi, Onel Luis Alcaraz L\'opez, Neelesh B. Mehta, Hirley Alves, Matti Latva-aho</dc:creator>
    </item>
    <item>
      <title>Opinion dynamics under common influencer assumption or leadership control</title>
      <link>https://arxiv.org/abs/2407.16901</link>
      <description>arXiv:2407.16901v1 Announce Type: new 
Abstract: We study Hegselmann-Krause type opinion formation models with non-universal interaction and time-delayed coupling. We assume the presence of a common influencer between two different agents. Moreover, we explore two cases in which such an assumption does not hold but leaders with independent opinion are present. By using careful estimates on the system's trajectories, we are able to prove asymptotic convergence to consensus estimates. Some numerical tests illustrate the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16901v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chiara Cicolani, Badis Ouahab, Cristina Pignotti</dc:creator>
    </item>
    <item>
      <title>Learning to Solve Bilevel Programs with Binary Tender</title>
      <link>https://arxiv.org/abs/2407.16914</link>
      <description>arXiv:2407.16914v1 Announce Type: new 
Abstract: Bilevel programs (BPs) find a wide range of applications in fields such as energy, transportation, and machine learning. As compared to BPs with continuous (linear/convex) optimization problems in both levels, the BPs with discrete decision variables have received much less attention, largely due to the ensuing computational intractability and the incapability of gradient-based algorithms for handling discrete optimization formulations. In this paper, we develop deep learning techniques to address this challenge. Specifically, we consider a BP with binary tender, wherein the upper and lower levels are linked via binary variables. We train a neural network to approximate the optimal value of the lower-level problem, as a function of the binary tender. Then, we obtain a single-level reformulation of the BP through a mixed-integer representation of the value function. Furthermore, we conduct a comparative analysis between two types of neural networks: general neural networks and the novel input supermodular neural networks, studying their representational capacities. To solve high-dimensional BPs, we introduce an enhanced sampling method to generate higher-quality samples and implement an iterative process to refine solutions. We demonstrate the performance of these approaches through extensive numerical experiments, whose lower-level problems are linear and mixed-integer programs, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16914v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bo Zhou, Ruiwei Jiang, Siqian Shen</dc:creator>
    </item>
    <item>
      <title>Proximal Projection Method for Stable Linearly Constrained Optimization</title>
      <link>https://arxiv.org/abs/2407.16998</link>
      <description>arXiv:2407.16998v1 Announce Type: new 
Abstract: Many applications using large datasets require efficient methods for minimizing a proximable convex function subject to satisfying a set of linear constraints within a specified tolerance. For this task, we present a proximal projection (PP) algorithm, which is an instance of Douglas-Rachford splitting that directly uses projections onto the set of constraints. Formal guarantees are presented to prove convergence of PP estimates to optimizers. Unlike many methods that obtain feasibility asymptotically, each PP iterate is feasible. Numerically, we show PP either matches or outperforms alternatives (e.g. linearized Bregman, primal dual hybrid gradient, proximal augmented Lagrangian, proximal gradient) on problems in basis pursuit, stable matrix completion, stable principal component pursuit, and the computation of earth mover's distances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16998v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Howard Heaton</dc:creator>
    </item>
    <item>
      <title>Strong Convergence of FISTA Iterates under H{\"o}lderian and Quadratic Growth Conditions</title>
      <link>https://arxiv.org/abs/2407.17063</link>
      <description>arXiv:2407.17063v1 Announce Type: new 
Abstract: Introduced by Beck and Teboulle, FISTA (for Fast Iterative Shrinkage-Thresholding Algorithm) is a first-order method widely used in convex optimization. Adapted from Nesterov's accelerated gradient method for convex functions, the generated sequence guarantees a decay of the function values of $\mathcal{O}\left(n^{-2}\right)$ in the convex setting. We show that for coercive functions satisfying some local growth condition (namely a H\''olderian or quadratic growth condition), this sequence strongly converges to a minimizer. This property, which has never been proved without assuming the uniqueness of the minimizer, is associated with improved convergence rates for the function values. The proposed analysis is based on a preliminary study of the Asymptotic Vanishing Damping system introduced by Su et al. in to modelNesterov's accelerated gradient method in a continuous setting. Novel improved convergence results are also shown for the solutions of this dynamical system, including the finite length of the trajectory under the aforementioned geometry conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17063v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jean-Fran\c{c}ois Aujol (IMB), Charles Dossal (INSA Toulouse), Hippolyte Labarri\`ere (UniGe, DIBRIS), Aude Rondepierre (INSA Toulouse, LAAS-ROC)</dc:creator>
    </item>
    <item>
      <title>Bounds on the infimum of polynomials over a generic semi-algebraic set using asymptotic critical values</title>
      <link>https://arxiv.org/abs/2407.17093</link>
      <description>arXiv:2407.17093v1 Announce Type: new 
Abstract: We present precise bit and degree estimates for the optimal value of the polynomial optimization problem $f^*:=\text{inf}_{x\in \mathscr{X}}~f(x)$, where $\mathscr{X}$ is a semi-algebraic set satisfying some non-degeneracy conditions. Our bounds depend on the degree, the bitsize of $f$, and the polynomials defining $\mathscr{X}$, and are single exponential with respect to the number of variables. They generalize the single exponential bounds from Jeronimo, Perrucci, and Tsigaridas (SIAM Journal on Optimization, 23(1):241--255, 2013) for the minimum of a polynomial function on a compact connected component of a basic closed semi-algebraic set.
  The tools that we use allow us to obtain specialized bounds and dedicated algorithms for two large families of polynomial optimization problems in which the optimum value might not be attained. The first family forms a dense set of real polynomial functions with a fixed collection of Newton polytopes; we provide the best approximation yet for the bifurcation set, which contains the optimal value, and we deduce an effective method for computations. As for the second family, we consider any unconstrained polynomial optimization problem; we present more precise bounds, together with a better bit complexity estimate of an algorithm to compute the optimal value.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17093v1</guid>
      <category>math.OC</category>
      <category>math.AG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Boulos El Hilany, Elias Tsigaridas</dc:creator>
    </item>
    <item>
      <title>Generalized Ordinal Priority Approach for Multi-Attribute Decision-Making under Incomplete Preference Information</title>
      <link>https://arxiv.org/abs/2407.17099</link>
      <description>arXiv:2407.17099v1 Announce Type: new 
Abstract: The Ordinal Priority Approach (OPA) is a multi-attribute decision-making (MADM) method to determine the relative importance (weights) of experts, attributes, and alternatives. This study formally establishes the fundamental properties of OPA, including solution efficiency, analytical solution expression, the decomposability of optimal decision weights, and its relationship with rank-based surrogate weights. Building on these properties, we propose a Generalized Ordinal Priority Approach (GOPA) based on an "estimate-then-optimize" contextual optimization framework for MADM when preference information is incomplete. In the first stage, we derive utility distributions for ranked alternatives in discrete and continuous prospects by minimizing cross-entropy utility under partial preference information, including weak order relations, absolute differences, ratio scales, and lower bounds. Rank-based surrogate weights and risk preference utility functions serve as the global utility structure for discrete and continuous prospects, respectively. The elicited utility information is then introduced into the second-stage problem to simultaneously optimize the weights of experts, attributes, and alternatives within a normalized weight space. Metrics for validating the group decision outcomes of GOPA, including percentage standard deviation, correlation coefficient, and confidence level measurement, are proposed. Theoretical analysis reveals several advantageous properties of GOPA, including model generalizability, analytical solvability, and risk preference independence. Furthermore, this study provides a lower bound reference for transforming the general optimization-based weight elicitation problems into optimization problems with stochastic dominance constraints. The applicability of GOPA is demonstrated through an improvisational emergency supplier selection problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17099v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Renlong Wang</dc:creator>
    </item>
    <item>
      <title>An Adaptive Second-order Method for a Class of Nonconvex Nonsmooth Composite Optimization</title>
      <link>https://arxiv.org/abs/2407.17216</link>
      <description>arXiv:2407.17216v1 Announce Type: new 
Abstract: This paper explores a specific type of nonconvex sparsity-promoting regularization problems, namely those involving $\ell_p$-norm regularization, in conjunction with a twice continuously differentiable loss function. We propose a novel second-order algorithm designed to effectively address this class of challenging nonconvex and nonsmooth problems, showcasing several innovative features: (i) The use of an alternating strategy to solve a reweighted $\ell_1$ regularized subproblem and the subspace approximate Newton step. (ii) The reweighted $\ell_1$ regularized subproblem relies on a convex approximation to the nonconvex regularization term, enabling a closed-form solution characterized by the soft-thresholding operator. This feature allows our method to be applied to various nonconvex regularization problems. (iii) Our algorithm ensures that the iterates maintain their sign values and that nonzero components are kept away from 0 for a sufficient number of iterations, eventually transitioning to a perturbed Newton method. (iv) We provide theoretical guarantees of global convergence, local superlinear convergence in the presence of the Kurdyka-\L ojasiewicz (KL) property, and local quadratic convergence when employing the exact Newton step in our algorithm. We also showcase the effectiveness of our approach through experiments on a diverse set of model prediction problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17216v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Wang, Xiangyu Yang, Yichen Zhu</dc:creator>
    </item>
    <item>
      <title>Second-Order Necessary Conditions, Constraint Qualifications and Exact Penalty for Mathematical Programs with Switching Constraints</title>
      <link>https://arxiv.org/abs/2407.17285</link>
      <description>arXiv:2407.17285v1 Announce Type: new 
Abstract: In this paper, we investigate second-order necessary conditions and exact penalty of mathematical programs with switching constraints (MPSC). Some new second-order constraint qualifications and second-order quasi-normality are introduced for (MPSC), which are crucial to establish the second-order necessary conditions and the error bound of (MPSC). We explore the relations among these constraint qualifications in term of (MPSC). The characterizations of Mordukhovich stationary point and strong stationary point of (MPSC) are derived under some mild conditions. A sufficient condition is provided for a Mordukhovich stationary point of (MPSC) being a strong stationary point. The strong second-order necessary conditions as well as weak second-order necessary conditions of (MPSC) are established under these weak constraint qualifications. Finally, we obtain the local exact penalty of (MPSC) under the local error bound or some constraint qualifications in term of (MPSC).</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17285v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiawei Chen, Luyu Liu, Yibing Lv, Kequan Zhao</dc:creator>
    </item>
    <item>
      <title>Mathematical programming algorithms for convex hull approximation with a hyperplane budget</title>
      <link>https://arxiv.org/abs/2407.17341</link>
      <description>arXiv:2407.17341v1 Announce Type: new 
Abstract: We consider the following problem in computational geometry: given, in the d-dimensional real space, a set of points marked as positive and a set of points marked as negative, such that the convex hull of the positive set does not intersect the negative set, find K hyperplanes that separate, if possible, all the positive points from the negative ones. That is, we search for a convex polyhedron with at most K faces, containing all the positive points and no negative point. The problem is known in the literature for pure convex polyhedral approximation; our interest stems from its possible applications in constraint learning, where points are feasible or infeasible solutions of a Mixed Integer Program, and the K hyperplanes are linear constraints to be found. We cast the problem as an optimization one, minimizing the number of negative points inside the convex polyhedron, whenever exact separation cannot be achieved. We introduce models inspired by support vector machines and we design two mathematical programming formulations with binary variables. We exploit Dantzig-Wolfe decomposition to obtain extended formulations, and we devise column generation algorithms with ad-hoc pricing routines. We compare computing time and separation error values obtained by all our approaches on synthetic datasets, with number of points from hundreds up to a few thousands, showing our approaches to perform better than existing ones from the literature. Furthermore, we observe that key computational differences arise, depending on whether the budget K is sufficient to completely separate the positive points from the negative ones or not. On 8-dimensional instances (and over), existing convex hull algorithms become computational inapplicable, while our algorithms allow to identify good convex hull approximations in minutes of computation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17341v1</guid>
      <category>math.OC</category>
      <category>cs.CG</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michele Barbato, Alberto Ceselli, Rosario Messana</dc:creator>
    </item>
    <item>
      <title>A particle consensus approach to solving nonconvex-nonconcave min-max problems</title>
      <link>https://arxiv.org/abs/2407.17373</link>
      <description>arXiv:2407.17373v1 Announce Type: new 
Abstract: We propose a zero-order optimization method for sequential min-max problems based on two populations of interacting particles. The systems are coupled so that one population aims to solve the inner maximization problem, while the other aims to solve the outer minimization problem. The dynamics are characterized by a consensus-type interaction with additional stochasticity to promote exploration of the objective landscape. Without relying on convexity or concavity assumptions, we establish theoretical convergence guarantees of the algorithm via a suitable mean-field approximation of the particle systems. Numerical experiments illustrate the validity of the proposed approach. In particular, the algorithm is able to identify a global min-max solution, in contrast to gradient-based methods, which typically converge to possibly suboptimal stationary points.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17373v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giacomo Borghi, Hui Huang, Jinniao Qiu</dc:creator>
    </item>
    <item>
      <title>$A^*$ for Graphs of Convex Sets</title>
      <link>https://arxiv.org/abs/2407.17413</link>
      <description>arXiv:2407.17413v2 Announce Type: new 
Abstract: We present a novel algorithm that fuses the existing convex-programming based approach with heuristic information to find optimality guarantees and near-optimal paths for the Shortest Path Problem in the Graph of Convex Sets (SPP-GCS). Our method, inspired by $A^*$, initiates a best-first-like procedure from a designated subset of vertices and iteratively expands it until further growth is neither possible nor beneficial. Traditionally, obtaining solutions with bounds for an optimization problem involves solving a relaxation, modifying the relaxed solution to a feasible one, and then comparing the two solutions to establish bounds. However, for SPP-GCS, we demonstrate that reversing this process can be more advantageous, especially with Euclidean travel costs. In other words, we initially employ $A^*$ to find a feasible solution for SPP-GCS, then solve a convex relaxation restricted to the vertices explored by $A^*$ to obtain a relaxed solution, and finally, compare the solutions to derive bounds. We present numerical results to highlight the advantages of our algorithm over the existing approach in terms of the sizes of the convex programs solved and computation time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17413v2</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.RO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kaarthik Sundar, Sivakumar Rathinam</dc:creator>
    </item>
    <item>
      <title>An Assessment of Ensemble Kalman Filter and Azouani-Olson-Titi Algorithms for Data Assimilation: A Comparative Study</title>
      <link>https://arxiv.org/abs/2407.17424</link>
      <description>arXiv:2407.17424v1 Announce Type: new 
Abstract: Continuous data assimilation (CDA) is a method that continuously integrates observational data into a dynamical system to improve model accuracy in real-time. The AOT algorithm is one of the most widely used methods in CDA due to its efficiency in incorporating observational data to enhance model accuracy. However, no research to date has evaluated the performance of the AOT algorithm compared to the most widely used DA method, the ensemble Kalman filter (EnKF). Hence, in this paper, we conduct an extensive numerical examination to evaluate and compare these two algorithms for CDA problems with measurement error, addressing this gap. By analyzing the one-dimensional Kuramoto-Sivashinsky equation and the two-dimensional Navier-Stokes equation, which are central to many applications and representative in CDA problems, we found a significant computational advantage of the AOT algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17424v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ning Ning, Collin Victor</dc:creator>
    </item>
    <item>
      <title>Wasserstein Distributionally Robust Shallow Convex Neural Networks</title>
      <link>https://arxiv.org/abs/2407.16800</link>
      <description>arXiv:2407.16800v1 Announce Type: cross 
Abstract: In this work, we propose Wasserstein distributionally robust shallow convex neural networks (WaDiRo-SCNNs) to provide reliable nonlinear predictions when subject to adverse and corrupted datasets. Our approach is based on a new convex training program for ReLU shallow neural networks which allows us to cast the problem as an exact, tractable reformulation of its order-1 Wasserstein distributionally robust equivalent. Our training procedure is conservative by design, has low stochasticity, is solvable with open-source solvers, and is scalable to large industrial deployments. We provide out-of-sample performance guarantees and show that hard convex physical constraints can be enforced in the training program. WaDiRo-SCNN aims to make neural networks safer for critical applications, such as in the energy sector. Finally, we numerically demonstrate the performance of our model on a synthetic experiment and a real-world power system application, i.e., the prediction of non-residential buildings' hourly energy consumption. The experimental results are convincing and showcase the strengths of the proposed model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16800v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julien Pallage, Antoine Lesage-Landry</dc:creator>
    </item>
    <item>
      <title>Convexification of the Quantum Network Utility Maximisation Problem</title>
      <link>https://arxiv.org/abs/2407.16808</link>
      <description>arXiv:2407.16808v1 Announce Type: cross 
Abstract: Network Utility Maximisation (NUM) addresses the problem of allocating resources fairly within a network and explores the ways to achieve optimal allocation in real-world networks. Although extensively studied in classical networks, NUM is an emerging area of research in the context of quantum networks. In this work, we consider the quantum network utility maximisation (QNUM) problem in a static setting, where a user's utility takes into account the assigned quantum quality (fidelity) via a generic entanglement measure as well as the corresponding rate of entanglement generation. Under certain assumptions, we demonstrate that the QNUM problem can be formulated as an optimisation problem with the rate allocation vector as the only decision variable. Using a change of variable technique known in the field of geometric programming, we then establish sufficient conditions under which this formulation can be reduced to a convex problem, a class of optimisation problems that can be solved efficiently and with certainty even in high dimensions. We further show that this technique preserves convexity, enabling us to formulate convex QNUM problems in networks where some routes have certain entanglement measures that do not readily admit convex formulation, while others do. This allows us to compute the optimal resource allocation in networks where heterogeneous applications run over different routes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16808v1</guid>
      <category>cs.NI</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Sounak Kar, Stephanie Wehner</dc:creator>
    </item>
    <item>
      <title>Generalization Bounds of Surrogate Policies for Combinatorial Optimization Problems</title>
      <link>https://arxiv.org/abs/2407.17200</link>
      <description>arXiv:2407.17200v1 Announce Type: cross 
Abstract: A recent stream of structured learning approaches has improved the practical state of the art for a range of combinatorial optimization problems with complex objectives encountered in operations research. Such approaches train policies that chain a statistical model with a surrogate combinatorial optimization oracle to map any instance of the problem to a feasible solution. The key idea is to exploit the statistical distribution over instances instead of dealing with instances separately. However learning such policies by risk minimization is challenging because the empirical risk is piecewise constant in the parameters, and few theoretical guarantees have been provided so far. In this article, we investigate methods that smooth the risk by perturbing the policy, which eases optimization and improves generalization. Our main contribution is a generalization bound that controls the perturbation bias, the statistical learning error, and the optimization error. Our analysis relies on the introduction of a uniform weak property, which captures and quantifies the interplay of the statistical model and the surrogate combinatorial optimization oracle. This property holds under mild assumptions on the statistical model, the surrogate optimization, and the instance data distribution. We illustrate the result on a range of applications such as stochastic vehicle scheduling. In particular, such policies are relevant for contextual stochastic optimization and our results cover this case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17200v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ME</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Pierre-Cyril Aubin-Frankowski, Yohann De Castro, Axel Parmentier, Alessandro Rudi</dc:creator>
    </item>
    <item>
      <title>Solving The Travelling Salesman Problem Using A Single Qubit</title>
      <link>https://arxiv.org/abs/2407.17207</link>
      <description>arXiv:2407.17207v1 Announce Type: cross 
Abstract: The travelling salesman problem (TSP) is a popular NP-hard-combinatorial optimization problem that requires finding the optimal way for a salesman to travel through different cities once and return to the initial city. The existing methods of solving TSPs on quantum systems are either gate-based or binary variable-based encoding. Both approaches are resource-expensive in terms of the number of qubits while performing worse compared to existing classical algorithms even for small-size problems. We present an algorithm that solves an arbitrary TSP using a single qubit by invoking the principle of quantum parallelism. The cities are represented as quantum states on the Bloch sphere while the preparation of superposition states allows us to traverse multiple paths at once. The underlying framework of our algorithm is a quantum version of the classical Brachistochrone approach. Optimal control methods are employed to create a selective superposition of the quantum states to find the shortest route of a given TSP. The numerical simulations solve a sample of four to nine cities for which exact solutions are obtained. The algorithm can be implemented on any quantum platform capable of efficiently rotating a qubit and allowing state tomography measurements. For the TSP problem sizes considered in this work, our algorithm is more resource-efficient and accurate than existing quantum algorithms with the potential for scalability. A potential speed-up of polynomial time over classical algorithms is discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17207v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kapil Goswami, Gagan Anekonda Veereshi, Peter Schmelcher, Rick Mukherjee</dc:creator>
    </item>
    <item>
      <title>From Data to Predictive Control: A Framework for Stochastic Linear Systems with Output Measurements</title>
      <link>https://arxiv.org/abs/2407.17277</link>
      <description>arXiv:2407.17277v1 Announce Type: cross 
Abstract: We introduce data to predictive control, D2PC, a framework to facilitate the design of robust and predictive controllers from data. The proposed framework is designed for discrete-time stochastic linear systems with output measurements and provides a principled design of a predictive controller based on data. The framework starts with a parameter identification method based on the Expectation-Maximization algorithm, which incorporates pre-defined structural constraints. Additionally, we provide an asymptotically correct method to quantify uncertainty in parameter estimates. Next, we develop a strategy to synthesize robust dynamic output-feedback controllers tailored to the derived uncertainty characterization. Finally, we introduce a predictive control scheme that guarantees recursive feasibility and satisfaction of chance constraints. This framework marks a significant advancement in integrating data into robust and predictive control schemes. We demonstrate the efficacy of D2PC through a numerical example involving a $10$-dimensional spring-mass-damper system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17277v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haldun Balim, Andrea Carron, Melanie N. Zeilinger, Johannes K\"ohler</dc:creator>
    </item>
    <item>
      <title>Neural field equations with time-periodic external inputs and some applications to visual processing</title>
      <link>https://arxiv.org/abs/2407.17294</link>
      <description>arXiv:2407.17294v1 Announce Type: cross 
Abstract: The aim of this work is to present a mathematical framework for the study of flickering inputs in visual processing tasks. When combined with geometric patterns, these inputs influence and induce interesting psychophysical phenomena, such as the MacKay and the Billock-Tsou effects, where the subjects perceive specific afterimages typically modulated by the flickering frequency. Due to the symmetry-breaking structure of the inputs, classical bifurcation theory and multi-scale analysis techniques are not very effective in our context. We thus take an approach based on the input-output framework of control theory for Amari-type neural fields. This allows us to prove that, when driven by periodic inputs, the dynamics converge to a periodic state. Moreover, we study under which assumptions these nonlinear dynamics can be effectively linearised, and in this case we present a precise approximation of the integral kernel for short-range excitatory and long-range inhibitory neuronal interactions. Finally, for inputs concentrated at the center of the visual field with a flickering background, we directly relate the width of the illusory contours appearing in the afterimage with both the flickering frequency and the strength of the inhibition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17294v1</guid>
      <category>q-bio.NC</category>
      <category>math.AP</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maria Virginia Bolelli, Dario Prandi</dc:creator>
    </item>
    <item>
      <title>Optimal Control of a Reaction-Diffusion Epidemic Model with Noncompliance</title>
      <link>https://arxiv.org/abs/2407.17298</link>
      <description>arXiv:2407.17298v1 Announce Type: cross 
Abstract: In this paper, we consider an optimal distributed control problem for a reaction-diffusion-based SIR epidemic model with human behavioral effects. We develop a model wherein non-pharmaceutical intervention methods are implemented, but a portion of the population does not comply with them, and this noncompliance affects the spread of the disease. Drawing from social contagion theory, our model allows for the spread of noncompliance parallel to the spread of the disease. The quantities of interest for control are the reduction in infection rate among the compliant population, the rate of spread of noncompliance, and the rate at which non-compliant individuals become compliant after, e.g., receiving more or better information about the underlying disease. We prove the existence of global-in-time solutions for fixed controls and study the regularity properties of the resulting control-to-state map. The existence of optimal control is then established in an abstract framework for a fairly general class of objective functions. Necessary first--order optimality conditions are obtained via a Lagrangian based stationarity system. We conclude with a discussion regarding minimization of the size of infected and non-compliant populations and present simulations with various parameters values to demonstrate the behavior of the model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17298v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marcelo Bongarti, Christian Parkinson, Weinan Wang</dc:creator>
    </item>
    <item>
      <title>Traversing Pareto Optimal Policies: Provably Efficient Multi-Objective Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2407.17466</link>
      <description>arXiv:2407.17466v1 Announce Type: cross 
Abstract: This paper investigates multi-objective reinforcement learning (MORL), which focuses on learning Pareto optimal policies in the presence of multiple reward functions. Despite MORL's significant empirical success, there is still a lack of satisfactory understanding of various MORL optimization targets and efficient learning algorithms. Our work offers a systematic analysis of several optimization targets to assess their abilities to find all Pareto optimal policies and controllability over learned policies by the preferences for different objectives. We then identify Tchebycheff scalarization as a favorable scalarization method for MORL. Considering the non-smoothness of Tchebycheff scalarization, we reformulate its minimization problem into a new min-max-max optimization problem. Then, for the stochastic policy class, we propose efficient algorithms using this reformulation to learn Pareto optimal policies. We first propose an online UCB-based algorithm to achieve an $\varepsilon$ learning error with an $\tilde{\mathcal{O}}(\varepsilon^{-2})$ sample complexity for a single given preference. To further reduce the cost of environment exploration under different preferences, we propose a preference-free framework that first explores the environment without pre-defined preferences and then generates solutions for any number of preferences. We prove that it only requires an $\tilde{\mathcal{O}}(\varepsilon^{-2})$ exploration complexity in the exploration phase and demands no additional exploration afterward. Lastly, we analyze the smooth Tchebycheff scalarization, an extension of Tchebycheff scalarization, which is proved to be more advantageous in distinguishing the Pareto optimal policies from other weakly Pareto optimal policies based on entry values of preference vectors. Furthermore, we extend our algorithms and theoretical analysis to accommodate this optimization target.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17466v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuang Qiu, Dake Zhang, Rui Yang, Boxiang Lyu, Tong Zhang</dc:creator>
    </item>
    <item>
      <title>Strategy Complexity of Limsup and Liminf Threshold Objectives in Countable MDPs, with Applications to Optimal Expected Payoffs</title>
      <link>https://arxiv.org/abs/2211.13259</link>
      <description>arXiv:2211.13259v3 Announce Type: replace 
Abstract: We study Markov decision processes (MDPs) with a countably infinite number of states. The $\limsup$ (resp. $\liminf$) threshold objective is to maximize the probability that the $\limsup$ (resp. $\liminf$) of the infinite sequence of directly seen rewards is non-negative. We establish the complete picture of the strategy complexity of these objectives, i.e., the upper and lower bounds on the memory required by $\varepsilon$-optimal (resp. optimal) strategies. We then apply these results to solve two open problems from (Sudderth, Decisions in Economics and Finance, 2020) about the strategy complexity of optimal strategies for the expected $\limsup$ (resp. $\liminf$) payoff.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.13259v3</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Richard Mayr, Eric Munday</dc:creator>
    </item>
    <item>
      <title>Integer Programming Approaches for Distributionally Robust Chance Constraints with Adjustable Risks</title>
      <link>https://arxiv.org/abs/2303.15282</link>
      <description>arXiv:2303.15282v2 Announce Type: replace 
Abstract: We study distributionally robust chance-constrained programs (DRCCPs) with individual chance constraints under a Wasserstein ambiguity. The DRCCPs treat the risk tolerances associated with the distributionally robust chance constraints (DRCCs) as decision variables to trade off between the system cost and risk of violations by penalizing the risk tolerances in the objective function. The introduction of adjustable risks, unfortunately, leads to NP-hard optimization problems. We develop integer programming approaches for individual chance constraints with uncertainty either on the right-hand side or on the left-hand side. In particular, we derive mixed integer programming reformulations for the two types of uncertainty to determine the optimal risk tolerance for the chance constraint. Valid inequalities are derived to strengthen the formulations. We test diverse instances of diverse sizes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.15282v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yiling Zhang</dc:creator>
    </item>
    <item>
      <title>High-Probability Convergence for Composite and Distributed Stochastic Minimization and Variational Inequalities with Heavy-Tailed Noise</title>
      <link>https://arxiv.org/abs/2310.01860</link>
      <description>arXiv:2310.01860v2 Announce Type: replace 
Abstract: High-probability analysis of stochastic first-order optimization methods under mild assumptions on the noise has been gaining a lot of attention in recent years. Typically, gradient clipping is one of the key algorithmic ingredients to derive good high-probability guarantees when the noise is heavy-tailed. However, if implemented na\"ively, clipping can spoil the convergence of the popular methods for composite and distributed optimization (Prox-SGD/Parallel SGD) even in the absence of any noise. Due to this reason, many works on high-probability analysis consider only unconstrained non-distributed problems, and the existing results for composite/distributed problems do not include some important special cases (like strongly convex problems) and are not optimal. To address this issue, we propose new stochastic methods for composite and distributed optimization based on the clipping of stochastic gradient differences and prove tight high-probability convergence results (including nearly optimal ones) for the new methods. Using similar ideas, we also develop new methods for composite and distributed variational inequalities and analyze the high-probability convergence of these methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.01860v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eduard Gorbunov, Abdurakhmon Sadiev, Marina Danilova, Samuel Horv\'ath, Gauthier Gidel, Pavel Dvurechensky, Alexander Gasnikov, Peter Richt\'arik</dc:creator>
    </item>
    <item>
      <title>Shortest-path recovery from signature with an optimal control approach</title>
      <link>https://arxiv.org/abs/2310.10619</link>
      <description>arXiv:2310.10619v4 Announce Type: replace 
Abstract: In this paper, we consider the signature-to-path reconstruction problem from the control theoretic perspective. Namely, we design an optimal control problem whose solution leads to the minimal-length path that generates a given signature. In order to do that, we minimize a cost functional consisting of two competing terms, i.e., a weighted final-time cost combined with the $L^2$-norm squared of the controls. Moreover, we can show that, by taking the limit to infinity of the parameter that tunes the final-time cost, the problem $\Gamma$-converges to the problem of finding a sub-Riemannian geodesic connecting two signatures. Finally, we provide an alternative reformulation of the latter problem, which is particularly suitable for the numerical implementation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.10619v4</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marco Rauscher, Alessandro Scagliotti, Felipe Pagginelli Patricio</dc:creator>
    </item>
    <item>
      <title>Limit Value in Zero-Sum Stochastic Games with Vanishing Stage Duration and Public Signals</title>
      <link>https://arxiv.org/abs/2403.07467</link>
      <description>arXiv:2403.07467v2 Announce Type: replace 
Abstract: We consider the behaviour of $\lambda$-discounted zero-sum games as the discount factor $\lambda$ approaches $0$ (that is, the players are more and more patient), in the context of games with stage duration. In stochastic games with stage duration $h$, players act at times $0, h, 2h,$ and so on. The payoff and leaving probabilities are proportional to $h$. When $h$ tends to $0$, such discrete-time games approximate games played in continuous time. The asymptotic behavior of the values (when both $\lambda$ and $h$ tend to $0$) was already studied in the case of stochastic games with perfect observation of the state and in the state-blind case. We consider the same question for the case of stochastic games with imperfect observation of the state. More precisely, we consider a particular case of such games, stochastic games with public signals, in which players are given at each stage a public signal that depends only on the current state. Our main result states that there exists a stochastic game with public signals, with no limit value (as the discount factor $\lambda$ goes to $0$) if stage duration is $1$, but with a limit value when stage duration $h$ and discount factor $\lambda$ both tend to $0$. Informally speaking, it means that the limit value in discrete time does not exist, but the limit value in continuous time (i.e. when $h$ approaches $0$) exists. Such a situation is impossible in the case of stochastic games with perfect observation of the state.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07467v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ivan Novikov (CEREMADE)</dc:creator>
    </item>
    <item>
      <title>The flying sidekick traveling salesman problem with multiple drops: A simple and effective heuristic approach</title>
      <link>https://arxiv.org/abs/2403.18091</link>
      <description>arXiv:2403.18091v3 Announce Type: replace 
Abstract: We study the Flying Sidekick Traveling Salesman Problem with Multiple Drops (FSTSP-MD), a multi-modal last-mile delivery model where a single truck and a single drone cooperatively deliver customer packages. In the FSTSP-MD, the drone can be launched from the truck to deliver multiple packages before it returns to the truck for a new delivery operation. The objective is to find the synchronized truck and drone delivery routes that minimize the completion time of the delivery process. We develop a simple and effective heuristic to solve the FSTSP-MD based on an order-first, split-second scheme. This heuristic combines standard local search and diversification techniques with a novel shortest-path problem that finds FSTSP-MD solutions in polynomial time. We show that our heuristic consistently outperforms state-of-the-art heuristics developed for the FSTSP-MD and the FSTSP (i.e., the single-drop case) through extensive numerical experiments. Based on both stylized and real-world instances, we also show that the FSTSP-MD substantially reduces completion times compared to traditional truck-only delivery systems. We provide extensive managerial insights into the impacts of drone capabilities and customer distribution on delivery efficiency. Our discussion compares the benefits of drones with greater payload capacity and those with greater speed. We highlight which service area characteristics increase savings but also require enhanced drone capabilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18091v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sarah K. Schaumann, Abhishake Kundu, Juan C. Pina-Pardo, Matthias Winkenbach, Ricardo A. Gatica, Stephan M. Wagner, Timothy I. Matis</dc:creator>
    </item>
    <item>
      <title>Computation of Robust Dynamic Operating Envelopes Based on Non-convex OPF for Unbalanced Distribution Networks</title>
      <link>https://arxiv.org/abs/2404.03355</link>
      <description>arXiv:2404.03355v2 Announce Type: replace 
Abstract: Robust dynamic operating envelopes (RDOEs) solve the problem of secure allocation of latent network capacity to flexible distributed energy resources (DER) in unbalanced distribution networks. As the computational complexity of RDOEs is much higher than that of dynamic operating envelopes (DOEs), which disregard uncertainties in network parameters and DER capacity utilisation, existing approaches to computing RDOEs have relied on linearised unbalanced three-phase optimal power flow (UTOPF) models to numerate the network feasible region approximately. The use of linearised models, however, risks producing RDOEs that undermine network integrity due to inherent errors in the approximation. This letter presents a practical sensitivity-filtering technique to simplify RDOE numerical computation based on non-convex UTOPF formulations. The accuracy and efficiency of the proposed approach are demonstrated on RDOE allocation with various fairness metrics by testing on representative Australian distribution networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03355v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Bin Liu, Julio H. Braslavsky</dc:creator>
    </item>
    <item>
      <title>Limit Value in Zero-Sum Stochastic Games with Vanishing Stage Duration and Public Signals</title>
      <link>https://arxiv.org/abs/2407.16282</link>
      <description>arXiv:2407.16282v2 Announce Type: replace 
Abstract: We consider the behaviour of $\lambda$-discounted zero-sum games as the discount factor $\lambda$ approaches 0 (that is, the players are more and more patient), in the context of games with stage duration. In stochastic games with stage duration h, players act at times 0, h, 2h, and so on. The payoff and leaving probabilities are proportional to h. When h tends to 0, such discrete-time games approximate games played in continuous time. The asymptotic behavior of the values (when both $\lambda$ and h tend to 0) was already studied in the case of stochastic games with perfect observation of the state and in the state-blind case.We consider the same question for the case of stochastic games with imperfect observation of the state. More precisely, we consider a particular case of such games, stochastic games with public signals, in which  players are given at each stage a public signal that depends only on the current state. Our main result states that there exists a stochastic game with public signals, with no limit value (as the discount factor $\lambda$ goes to 0) if stage duration is 1, but with a limit value when stage duration h and discount factor $\lambda$ both tend to 0. Informally speaking, it means that the limit value in discrete time does not exist, but the limit value in continuous time (i.e. when h approaches 0) exists. Such a situation is impossible in the case of stochastic games with perfect observation of the state.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16282v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ivan Novikov (CEREMADE)</dc:creator>
    </item>
    <item>
      <title>Efficient Convex Optimization Requires Superlinear Memory</title>
      <link>https://arxiv.org/abs/2203.15260</link>
      <description>arXiv:2203.15260v2 Announce Type: replace-cross 
Abstract: We show that any memory-constrained, first-order algorithm which minimizes $d$-dimensional, $1$-Lipschitz convex functions over the unit ball to $1/\mathrm{poly}(d)$ accuracy using at most $d^{1.25 - \delta}$ bits of memory must make at least $\tilde{\Omega}(d^{1 + (4/3)\delta})$ first-order queries (for any constant $\delta \in [0, 1/4]$). Consequently, the performance of such memory-constrained algorithms are a polynomial factor worse than the optimal $\tilde{O}(d)$ query bound for this problem obtained by cutting plane methods that use $\tilde{O}(d^2)$ memory. This resolves a COLT 2019 open problem of Woodworth and Srebro.</description>
      <guid isPermaLink="false">oai:arXiv.org:2203.15260v2</guid>
      <category>cs.LG</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Annie Marsden, Vatsal Sharan, Aaron Sidford, Gregory Valiant</dc:creator>
    </item>
    <item>
      <title>Frequency Stability-Constrained Unit Commitment: Tight Approximation using Bernstein Polynomials</title>
      <link>https://arxiv.org/abs/2212.12088</link>
      <description>arXiv:2212.12088v2 Announce Type: replace-cross 
Abstract: As we replace conventional synchronous generators with renewable energy, the frequency security of power systems is at higher risk. This calls for a more careful consideration of unit commitment (UC) and primary frequency response (PFR) reserves. This paper studies frequency-secured UC under significant wind power uncertainty. We coordinate the thermal units and wind farms to provide frequency support, wherein we optimize the variable inverter droop factors of the wind farms for higher economy. In addition, we adopt distributionally robust chance constraints (DRCCs) to handle the wind power uncertainty. To depict the frequency dynamics, we incorporate a differential-algebraic equation (DAE) with the dead band into the UC model. Notably, we apply Bernstein polynomials to derive tight inner approximation of the DAE and obtain mixed-integer linear constraints, which can be computed in off-the-shelf solvers. Case studies demonstrate the tightness and effectiveness of the proposed method in guaranteeing frequency security.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.12088v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TPWRS.2023.3335348</arxiv:DOI>
      <dc:creator>Bo Zhou, Ruiwei Jiang, Siqian Shen</dc:creator>
    </item>
    <item>
      <title>RIS-Assisted Interference Mitigation for Uplink NOMA</title>
      <link>https://arxiv.org/abs/2301.13841</link>
      <description>arXiv:2301.13841v2 Announce Type: replace-cross 
Abstract: Non-orthogonal multiple access (NOMA) has become a promising technology for next-generation wireless communications systems due to its capability to provide access for multiple users on the same resource. In this paper, we consider an uplink power-domain NOMA system aided by a reconfigurable intelligent surface (RIS) in the presence of a jammer that aims to maximize its interference on the base station (BS) uplink receiver. We consider two kinds of RISs, a regular RIS whose elements can only change the phase of the incoming wave, and an RIS whose elements can also attenuate the incoming wave. Our aim is to minimize the total power transmitted by the user terminals under quality-of-service constraints by controlling both the propagation from the users and the jammer to the BS with help of the RIS. The resulting objective function and constraints are both non-linear and non-convex, so we address this problem using numerical optimization. Our numerical results show that the RIS can help to dramatically reduce the per user required transmit power in an interference-limited scenario.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.13841v2</guid>
      <category>cs.IT</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Azadeh Tabeshnezhad, A. Lee Swindlehurst, Tommy Svensson</dc:creator>
    </item>
    <item>
      <title>Optimizer's Information Criterion: Dissecting and Correcting Bias in Data-Driven Optimization</title>
      <link>https://arxiv.org/abs/2306.10081</link>
      <description>arXiv:2306.10081v3 Announce Type: replace-cross 
Abstract: In data-driven optimization, the sample performance of the obtained decision typically incurs an optimistic bias against the true performance, a phenomenon commonly known as the Optimizer's Curse and intimately related to overfitting in machine learning. Common techniques to correct this bias, such as cross-validation, require repeatedly solving additional optimization problems and are therefore computationally expensive. We develop a general bias correction approach, building on what we call Optimizer's Information Criterion (OIC), that directly approximates the first-order bias and does not require solving any additional optimization problems. Our OIC generalizes the celebrated Akaike Information Criterion to evaluate the objective performance in data-driven optimization, which crucially involves not only model fitting but also its interplay with the downstream optimization. As such it can be used for decision selection instead of only model selection. We apply our approach to a range of data-driven optimization formulations comprising empirical and parametric models, their regularized counterparts, and furthermore contextual optimization. Finally, we provide numerical validation on the superior performance of our approach under synthetic and real-world datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.10081v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Garud Iyengar, Henry Lam, Tianyu Wang</dc:creator>
    </item>
    <item>
      <title>Boosting Gradient Ascent for Continuous DR-submodular Maximization</title>
      <link>https://arxiv.org/abs/2401.08330</link>
      <description>arXiv:2401.08330v2 Announce Type: replace-cross 
Abstract: Projected Gradient Ascent (PGA) is the most commonly used optimization scheme in machine learning and operations research areas. Nevertheless, numerous studies and examples have shown that the PGA methods may fail to achieve the tight approximation ratio for continuous DR-submodular maximization problems. To address this challenge, we present a boosting technique in this paper, which can efficiently improve the approximation guarantee of the standard PGA to \emph{optimal} with only small modifications on the objective function. The fundamental idea of our boosting technique is to exploit non-oblivious search to derive a novel auxiliary function $F$, whose stationary points are excellent approximations to the global maximum of the original DR-submodular objective $f$. Specifically, when $f$ is monotone and $\gamma$-weakly DR-submodular, we propose an auxiliary function $F$ whose stationary points can provide a better $(1-e^{-\gamma})$-approximation than the $(\gamma^2/(1+\gamma^2))$-approximation guaranteed by the stationary points of $f$ itself. Similarly, for the non-monotone case, we devise another auxiliary function $F$ whose stationary points can achieve an optimal $\frac{1-\min_{\boldsymbol{x}\in\mathcal{C}}\|\boldsymbol{x}\|_{\infty}}{4}$-approximation guarantee where $\mathcal{C}$ is a convex constraint set. In contrast, the stationary points of the original non-monotone DR-submodular function can be arbitrarily bad~\citep{chen2023continuous}. Furthermore, we demonstrate the scalability of our boosting technique on four problems. In all of these four problems, our resulting variants of boosting PGA algorithm beat the previous standard PGA in several aspects such as approximation ratio and efficiency. Finally, we corroborate our theoretical findings with numerical experiments, which demonstrate the effectiveness of our boosting PGA methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.08330v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qixin Zhang, Zongqi Wan, Zengde Deng, Zaiyi Chen, Xiaoming Sun, Jialin Zhang, Yu Yang</dc:creator>
    </item>
    <item>
      <title>Decision-Focused Learning with Directional Gradients</title>
      <link>https://arxiv.org/abs/2402.03256</link>
      <description>arXiv:2402.03256v3 Announce Type: replace-cross 
Abstract: We propose a novel family of decision-aware surrogate losses, called Perturbation Gradient (PG) losses, for the predict-then-optimize framework. The key idea is to connect the expected downstream decision loss with the directional derivative of a particular plug-in objective, and then approximate this derivative using zeroth order gradient techniques. Unlike the original decision loss which is typically piecewise constant and discontinuous, our new PG losses can be optimized using off-the-shelf gradient-based methods. Most importantly, unlike existing surrogate losses, the approximation error of our PG losses vanishes as the number of samples grows. Hence, optimizing our surrogate loss yields a best-in-class policy asymptotically, even in misspecified settings. This is the first such result in misspecified settings, and we provide numerical evidence confirming our PG losses substantively outperform existing proposals when the underlying model is misspecified.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.03256v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Huang, Vishal Gupta</dc:creator>
    </item>
    <item>
      <title>A Library of Mirrors: Deep Neural Nets in Low Dimensions are Convex Lasso Models with Reflection Features</title>
      <link>https://arxiv.org/abs/2403.01046</link>
      <description>arXiv:2403.01046v4 Announce Type: replace-cross 
Abstract: We prove that training neural networks on 1-D data is equivalent to solving convex Lasso problems with discrete, explicitly defined dictionary matrices. We consider neural networks with piecewise linear activations and depths ranging from 2 to an arbitrary but finite number of layers. We first show that two-layer networks with piecewise linear activations are equivalent to Lasso models using a discrete dictionary of ramp functions, with breakpoints corresponding to the training data points. In certain general architectures with absolute value or ReLU activations, a third layer surprisingly creates features that reflect the training data about themselves. Additional layers progressively generate reflections of these reflections. The Lasso representation provides valuable insights into the analysis of globally optimal networks, elucidating their solution landscapes and enabling closed-form solutions in certain special cases. Numerical results show that reflections also occur when optimizing standard deep networks using standard non-convex optimizers. Additionally, we demonstrate our theory with autoregressive time series models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01046v4</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Emi Zeger, Yifei Wang, Aaron Mishkin, Tolga Ergen, Emmanuel Cand\`es, Mert Pilanci</dc:creator>
    </item>
  </channel>
</rss>
