<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 15 Mar 2024 04:00:14 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 15 Mar 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Delay-independent dual-rate PID controller for a packetbased Networked Control System</title>
      <link>https://arxiv.org/abs/2403.08772</link>
      <description>arXiv:2403.08772v1 Announce Type: new 
Abstract: In this paper, a novel delay-independent control structure for a networked control system (NCS) is proposed, where packet-based control strategies with predictor-based and dual-rate control techniques are integrated. The control solution is able to cope with some networked communication problems such as time-varying delays, packet dropouts and packet disorder. In addition, the proposed approach enables to reduce network load, and usage of connected devices, while maintaining a satisfactory control performance. As a delayindependent control solution, no network-induced delay measurement is needed for controller implementation. In addition, the control scheme is applicable to open-loop unstable plants. Control system stability is ensured in terms of linear matrix inequalities (LMIs). Simulation results show the main benefits of the control approach, which are experimentally validated by means of a Cartesian-robot-based test-bed platform.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.08772v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.ins.2019.01.059</arxiv:DOI>
      <arxiv:journal_reference>Information Sciences, 2019</arxiv:journal_reference>
      <dc:creator>J. Alcaina, A. Cuenca, J. Salt, V. Casanovaa, R. Piz\'a</dc:creator>
    </item>
    <item>
      <title>Accurate and Warm-Startable Linear Cutting-Plane Relaxations for ACOPF</title>
      <link>https://arxiv.org/abs/2403.08800</link>
      <description>arXiv:2403.08800v1 Announce Type: new 
Abstract: We present a linear cutting-plane relaxation approach that rapidly proves tight lower bounds for the Alternating Current Optimal Power Flow Problem (ACOPF). Our method leverages outer-envelope linear cuts for well-known second-order cone relaxations for ACOPF along with modern cut management techniques. These techniques prove effective on a broad family of ACOPF instances, including the largest ones publicly available, quickly and robustly yielding sharp bounds. Our primary focus concerns the (frequent) case where an ACOPF instance is considered following a small or moderate change in problem data, e.g., load changes and generator or branch shut-offs. We provide significant computational evidence that the cuts computed on the prior instance provide an effective warm-start for our algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.08800v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Bienstock, Matias Villagra</dc:creator>
    </item>
    <item>
      <title>Stochastic controllability for a non-autonomous fractional neutral differential equation with infinite delay in abstract space</title>
      <link>https://arxiv.org/abs/2403.08825</link>
      <description>arXiv:2403.08825v1 Announce Type: new 
Abstract: This paper deals with the controllability for a class of non-autonomous neutral differential equations of fractional order with infinite delay in an abstract space. The semi-group theory of bounded linear operators, fractional calculus, and stochastic analysis techniques have been implemented to achieve the main result. We prove the existence of mild solution and controllability of the system by using the theory of measure of non-compactness, fixed point theorems, and $k$-set contractive mapping. An example is given to demonstrate the effectiveness of the abstract result.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.08825v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Areefa Khatoon, Abdur Raheem, Asma Afreen</dc:creator>
    </item>
    <item>
      <title>Locational Scenario-based Pricing in a Bilateral Distribution Energy Market under Uncertainty</title>
      <link>https://arxiv.org/abs/2403.08827</link>
      <description>arXiv:2403.08827v1 Announce Type: new 
Abstract: In recent years, there has been a significant focus on advancing the next generation of power systems. Despite these efforts, persistent challenges revolve around addressing the operational impact of uncertainty on predicted data, especially concerning economic dispatch and optimal power flow. To tackle these challenges, we introduce a stochastic day-ahead scheduling approach for a community. This method involves iterative improvements in economic dispatch and optimal power flow, aiming to minimize operational costs by incorporating quantile forecasting. Then, we present a real-time market and payment problem to handle optimization in real-time decision-making and payment calculation. We assess the effectiveness of our proposed method against benchmark results and conduct a test using data from 50 real households to demonstrate its practicality. Furthermore, we compare our method with existing studies in the field across two different seasons of the year. In the summer season, our method decreases optimality gap by 60% compared to the baseline, and in the winter season, it reduces optimality gap by 67%. Moreover, our proposed method mitigates the congestion of distribution network by 16.7\% within a day caused by uncertain energy, which is a crucial aspect for implementing energy markets in the real world.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.08827v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Hien Thanh Doan, Minsoo Kim, Keunju Song, Hongseok Kim</dc:creator>
    </item>
    <item>
      <title>Two-sided Assortment Optimization: Adaptivity Gaps and Approximation Algorithms</title>
      <link>https://arxiv.org/abs/2403.08929</link>
      <description>arXiv:2403.08929v1 Announce Type: new 
Abstract: To address the challenge of choice congestion in matching markets, in this work, we introduce a two-sided assortment optimization framework under general choice preferences. The goal in this problem is to maximize the expected number of matches by deciding which assortments are displayed to the agents and the order in which they are shown. In this context, we identify several classes of policies that platforms can use in their design. Our goals are: (1) to measure the value that one class of policies has over another one, and (2) to approximately solve the optimization problem itself for a given class. For (1), we define the adaptivity gap as the worst-case ratio between the optimal values of two different policy classes. First, we show that the gap between the class of policies that statically show assortments to one-side first and the class of policies that adaptively show assortments to one-side first is exactly $1-1/e$. Second, we show that the gap between the latter class of policies and the fully adaptive class of policies that show assortments to agents one by one is exactly $1/2$. We also note that the worst policies are those who simultaneously show assortments to all the agents, in fact, we show that their adaptivity gap even with respect to one-sided static policies can be arbitrarily small. For (2), we first show that there exists a polynomial time policy that achieves a $1/4$ approximation factor within the class of policies that adaptively show assortments to agents one by one. Finally, when agents' preferences are governed by multinomial-logit models, we show that a 0.066 approximation factor can be obtained within the class of policies that show assortments to all agents at once.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.08929v1</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Omar El Housni, Alfredo Torrico, Ulysse Hennebelle</dc:creator>
    </item>
    <item>
      <title>Necessary conditions for turnpike property for generalized linear-quadratic problems</title>
      <link>https://arxiv.org/abs/2403.08958</link>
      <description>arXiv:2403.08958v1 Announce Type: new 
Abstract: In this paper, we develop several necessary conditions of turnpike property for generalizaid linear-quadratic (LQ) optimal control problem in infinite dimensional setting. The term 'generalized' here means that both quadratic and linear terms are considered in the running cost. The turnpike property reflects the fact that over a sufficiently large time horizon, the optimal trajectories and optimal controls stay for most of the time close to a steady state of the system. We show that the turnpike property is strongly connected to certain system theoretical properties of the control system. We provide suitable conditions to characterize the turnpike property in terms of the detectability and stabilizability of the system. Subsequently, we show the equivalence between the exponential turnpike property for generalized LQ and LQ optimal control problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.08958v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Roberto Guglielmi, Zhuqing Li</dc:creator>
    </item>
    <item>
      <title>Managing Distributional Ambiguity in Stochastic Optimization through a Statistical Upper Bound Framework</title>
      <link>https://arxiv.org/abs/2403.08966</link>
      <description>arXiv:2403.08966v1 Announce Type: new 
Abstract: Stochastic optimization is often hampered by distributional ambiguity, where critical probability distributions are poorly characterized or unknown. Addressing this challenge, we introduce a new framework that targets the minimization of a statistical upper bound for the expected value of uncertain objectives, facilitating more statistically robust decision-making. Central to our approach is the Average Percentile Upper Bound (APUB), a novel construct that simultaneously delivers a statistically rigorous upper bound for the population mean and a meaningful risk metric for the sample mean. The integration of APUB into stochastic optimization not only fortifies the process against distributional ambiguity but also reinforces key data-driven decision-making attributes, such as reliability, consistency, and comprehensibility. Notably, APUB-enriched optimization problems feature tractability, with particular advantages in two-stage stochastic optimization with random recourse. Empirical demonstrations on two-stage product mix and multi-product newsvendor benchmark problems reveal the benefit of the APUB optimization framework, in comparison with conventional techniques such as sample average approximation and distributionally robust optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.08966v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shixin Liu, Jian Hu</dc:creator>
    </item>
    <item>
      <title>A Game Theoretic Approach to Sustainizability Over Sets and its application to a multi-species population model</title>
      <link>https://arxiv.org/abs/2403.08981</link>
      <description>arXiv:2403.08981v1 Announce Type: new 
Abstract: In this work, a theorem is first proved which presents a game theoretic formulation of a necessary and sufficient sustainizability over a set condition for a general system described by ordinary differential equations (ODEs). Then, two additional theorems are proved for the n-species Gause-Lotka-Volterra (GLV) population model, establishing necessary and sufficient sustainability and sustainizability conditions over rectangular sets. Three case studies on the May-Leonard, 3-species, GLV model are then presented to illustrate the power of the above Theorems. In two of these case studies (2 and 3), it is shown that a particular instance of the 3-species, GLV model is unsustainable but sustainizable through allowable action.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.08981v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>nlin.CD</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ioannis V. Manousiouthakis (Department of Chemical,Biomolecular Engineering, Hydrogen Engineering Research Consortium)</dc:creator>
    </item>
    <item>
      <title>A Constrained Tracking Controller for Ramp and Sinusoidal Reference Signals using Robust Positive Invariance</title>
      <link>https://arxiv.org/abs/2403.08987</link>
      <description>arXiv:2403.08987v1 Announce Type: new 
Abstract: This paper proposes an output feedback controller capable of ensuring steady-state offset-free tracking for ramp and sinusoidal reference signals while ensuring local stability and state and input constraints fulfillment. The proposed solution is derived by jointly exploiting the internal model principle, polyhedral robust positively invariant arguments, and the Extended Farkas' Lemma. In particular, by considering a generic class of output feedback controller equipped with a feedforward term, a proportional effect, and a double integrator, we offline design the controller's gains by means of a single bilinear optimization problem. A peculiar feature of the proposed design is that the sets of all the admissible reference signals and the plant's initial conditions are also offline determined. Simulation results are provided to testify to the effectiveness of the proposed tracking controller and its capability to deal with both state and input constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.08987v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Geovana Franca dos Santos, Eugenio B. Castelan, Walter Lucia</dc:creator>
    </item>
    <item>
      <title>Relationship between General MP and DPP for the Stochastic Recursive Optimal Control Problem With Jumps: Viscosity Solution Framework</title>
      <link>https://arxiv.org/abs/2403.09044</link>
      <description>arXiv:2403.09044v1 Announce Type: new 
Abstract: This paper is concerned with the relationship between general maximum principle and dynamic programming principle for the stochastic recursive optimal control problem with jumps, where the control domain is not necessarily convex. Relations among the adjoint processes, the generalized Hamiltonian function and the value function are proved, under the assumption of a smooth value function and within the framework of viscosity solutions, respectively. Some examples are given to illustrate the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09044v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Bin Wang, Jiingtao Shi</dc:creator>
    </item>
    <item>
      <title>Dissipative Gradient Descent Ascent Method: A Control Theory Inspired Algorithm for Min-max Optimization</title>
      <link>https://arxiv.org/abs/2403.09090</link>
      <description>arXiv:2403.09090v1 Announce Type: new 
Abstract: Gradient Descent Ascent (GDA) methods for min-max optimization problems typically produce oscillatory behavior that can lead to instability, e.g., in bilinear settings. To address this problem, we introduce a dissipation term into the GDA updates to dampen these oscillations. The proposed Dissipative GDA (DGDA) method can be seen as performing standard GDA on a state-augmented and regularized saddle function that does not strictly introduce additional convexity/concavity. We theoretically show the linear convergence of DGDA in the bilinear and strongly convex-strongly concave settings and assess its performance by comparing DGDA with other methods such as GDA, Extra-Gradient (EG), and Optimistic GDA. Our findings demonstrate that DGDA surpasses these methods, achieving superior convergence rates. We support our claims with two numerical examples that showcase DGDA's effectiveness in solving saddle point problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09090v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tianqi Zheng, Nicolas Loizou, Pengcheng You, Enrique Mallada</dc:creator>
    </item>
    <item>
      <title>A Low-Rank ADMM Splitting Approach for Semidefinite Programming</title>
      <link>https://arxiv.org/abs/2403.09133</link>
      <description>arXiv:2403.09133v1 Announce Type: new 
Abstract: We introduce a new first-order method for solving general semidefinite programming problems, based on the alternating direction method of multipliers (ADMM) and a matrix-splitting technique. Our algorithm has an advantage over the Burer-Monteiro approach as it only involves much easier quadratically regularized subproblems in each iteration. For a linear objective, the subproblems are well-conditioned quadratic programs that can be efficiently solved by the standard conjugate gradient method. We show that the ADMM algorithm achieves sublinear or linear convergence rates to the KKT solutions under different conditions. Building on this theoretical development, we present LoRADS, a new solver for linear SDP based on the \underline{\bf Lo}w-\underline{\bf R}ank \underline{\bf AD}MM \underline{\bf S}plitting approach. LoRADS incorporates several strategies that significantly increase its efficiency. Firstly, it initiates with a warm-start phase that uses the Burer-Monteiro approach. Moreover, motivated by the SDP low-rank theory (So et al. 2008), LoRADS chooses an initial rank of logarithmic order and then employs a dynamic approach to increase the rank. Numerical experiments indicate that LoRADS exhibits promising performance on large-scale SDP problems. A noteworthy achievement of LoRADS is its successful solving of a matrix completion problem with $15,694,167$ constraints and a matrix variable of size $40,000 \times 40,000$ in $351$ seconds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09133v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiushi Han, Chenxi Li, Zhenwei Lin, Caihua Chen, Qi Deng, Dongdong Ge, Huikang Liu, Yinyu Ye</dc:creator>
    </item>
    <item>
      <title>MPC without Terminal Ingredients Tailored to the SEIR Compartmental Epidemic Model</title>
      <link>https://arxiv.org/abs/2403.09151</link>
      <description>arXiv:2403.09151v1 Announce Type: new 
Abstract: We consider the SEIR epidemic model subject to state and input constraints (a cap on the proportion of infectuous individuals and limits on the allowed social distancing and quarantining measures, respectively). We present a model predictive control (MPC) formulation tailored to this system without terminal conditions in the recursively solved finite-horizon optimal control problem. We rigorously show recursive feasibility and asymptotic stability of the disease-free equilibrium w.r.t. the MPC closed loop for suitably designed quadratic running cost and a sufficiently long prediction horizon (forecast window). Moreover, we establish the viability kernel (a.k.a. the admissible set) as domain of attraction provided that the infection numbers that are not too small at the beginning, which corresponds to infection numbers noticeable by, e.g., policy makers or the general public.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09151v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Willem Esterhuizen, Philipp Sauerteig, Stefan Streif, Karl Worthmann</dc:creator>
    </item>
    <item>
      <title>On Discrete Subproblems in Integer Optimal Control with Total Variation Regularization in Two Dimensions</title>
      <link>https://arxiv.org/abs/2403.09213</link>
      <description>arXiv:2403.09213v1 Announce Type: new 
Abstract: We analyze integer linear programs which we obtain after discretizing two-dimensional subproblems arising from a trust-region algorithm for mixed integer optimal control problems with total variation regularization. We discuss NP-hardness of the discretized problems and the connection to graph-based problems. We show that the underlying polyhedron exhibits structural restrictions in its vertices with regards to which variables can attain fractional values at the same time. Based on this property, we derive cutting planes by employing a relation to shortest-path and minimum bisection problems. We propose a branching rule and a primal heuristic which improves previously found feasible points. We validate the proposed tools with a numerical benchmark in a standard integer programming solver. We observe a significant speedup for medium-sized problems. Our results give hints for scaling towards larger instances in the future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09213v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paul Manns, Marvin Severitt</dc:creator>
    </item>
    <item>
      <title>Ahlfors regularity of continua that minimize maxitive set functions</title>
      <link>https://arxiv.org/abs/2403.09251</link>
      <description>arXiv:2403.09251v1 Announce Type: new 
Abstract: The primary objective of this paper is to establish the Ahlfors regularity of minimizers of set functions that satisfy a suitable maxitive condition on disjoint unions of sets. Our analysis focuses on minimizers within continua of the plane with finite one-dimensional Hausdorff measure. Through quantitative estimates, we prove that the length of a minimizer inside the ball centered at one of its points is comparable to the radius of the ball. By operating within an abstract framework, we are able to encompass a diverse range of entities, including spectral functionals defined in terms of the eigenvalues of elliptic operators, the inradius, and the maximum of the torsion function. These entities are of interest for several applications, such as structural engineering, urban planning, and quantum mechanics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09251v1</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <category>math.MG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Davide Zucco</dc:creator>
    </item>
    <item>
      <title>Solvability of the Inverse Optimal Control problem based on the minimum principle</title>
      <link>https://arxiv.org/abs/2403.09375</link>
      <description>arXiv:2403.09375v1 Announce Type: new 
Abstract: In this paper, the solvability of the Inverse Optimal Control (IOC) problem based on two existing minimum principal methods, is analysed. The aim of this work is to answer the question regarding what kinds of trajectories, that is depending on the initial conditions of the closed-loop system and system dynamics, of the original optimal control problem, will result in the recovery of the true weights of the reward function for both the soft and the hard-constrained methods [1], [2]. Analytical conditions are provided which allow to verify if a trajectory is sufficiently conditioned, that is, holds sufficient information to recover the true weights of an optimal control problem. It was found that the open-loop system of the original optimal problem has a stronger influence on the solvability of the Inverse Optimal Control problem for the hard-constrained method as compared to the soft-constrained method. These analytical results were validated via simulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09375v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Afreen Islam, Guido Herrmann, Joaquin Carrasco</dc:creator>
    </item>
    <item>
      <title>Sequential optimal experimental design for vapor-liquid equilibrium modeling</title>
      <link>https://arxiv.org/abs/2403.09443</link>
      <description>arXiv:2403.09443v1 Announce Type: new 
Abstract: We propose a general methodology of sequential locally optimal design of experiments for explicit or implicit nonlinear models, as they abound in chemical engineering and, in particular, in vapor-liquid equilibrium modeling. As a sequential design method, our method iteratively alternates between performing experiments, updating parameter estimates, and computing new experiments. Specifically, our sequential design method computes a whole batch of new experiments in each iteration and this batch of new experiments is designed in a two-stage locally optimal manner. In essence, this means that in every iteration the combined information content of the newly proposed experiments and of the already performed experiments is maximized. In order to solve these two-stage locally optimal design problems, a recent and efficient adaptive discretization algorithm is used. We demonstrate the benefits of the proposed methodology on the example of of the parameter estimation for the non-random two-liquid model for narrow azeotropic vapor-liquid equilibria. As it turns out, our sequential optimal design method requires substantially fewer experiments than traditional factorial design to achieve the same model precision and prediction quality. Consequently, our method can contribute to a substantially reduced experimental effort in vapor-liquid equilibrium modeling and beyond.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09443v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martin Bubel, Jochen Schmid, Volodymyr Kozachynskyi, Erik Esche, Michael Bortz</dc:creator>
    </item>
    <item>
      <title>Analysis of a continuous opinion and discrete action dynamics model coupled with an external observation dynamics</title>
      <link>https://arxiv.org/abs/2403.09473</link>
      <description>arXiv:2403.09473v1 Announce Type: new 
Abstract: We consider a set of consumers in a city or town (who thus generate pollution) whose opinion is governed by a continuous opinion and discrete action (CODA) dynamics model. This dynamics is coupled with an observation signal dynamics, which defines the information the consumers have access to regarding the common pollution. We show that the external observation signal has a significant impact on the asymptotic behavior of the CODA model. When the coupling is strong, it induces either a chaotic behavior or convergence towards a limit cycle. When the coupling is weak, a more classical behavior characterized by local agreements in polarized clusters is observed. In both cases, conditions under which clusters of consumers don't change their actions are provided.Numerical examples are provided to illustrate the derived analytical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09473v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anthony Couthures, Thomas Mongaillard, Vineeth S. Varma, Samson Lasaulce, Irinel-Constantin Morarescu</dc:creator>
    </item>
    <item>
      <title>Robust SGLD algorithm for solving non-convex distributionally robust optimisation problems</title>
      <link>https://arxiv.org/abs/2403.09532</link>
      <description>arXiv:2403.09532v1 Announce Type: new 
Abstract: In this paper we develop a Stochastic Gradient Langevin Dynamics (SGLD) algorithm tailored for solving a certain class of non-convex distributionally robust optimisation problems. By deriving non-asymptotic convergence bounds, we build an algorithm which for any prescribed accuracy $\varepsilon&gt;0$ outputs an estimator whose expected excess risk is at most $\varepsilon$. As a concrete application, we employ our robust SGLD algorithm to solve the (regularised) distributionally robust Mean-CVaR portfolio optimisation problem using real financial data. We empirically demonstrate that the trading strategy obtained by our robust SGLD algorithm outperforms the trading strategy obtained when solving the corresponding non-robust Mean-CVaR portfolio optimisation problem using, e.g., a classical SGLD algorithm. This highlights the practical relevance of incorporating model uncertainty when optimising portfolios in real financial markets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09532v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>q-fin.MF</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ariel Neufeld, Matthew Ng Cheng En, Ying Zhang</dc:creator>
    </item>
    <item>
      <title>Commutation principles for nonsmooth variational problems on Euclidean Jordan algebras</title>
      <link>https://arxiv.org/abs/2403.09578</link>
      <description>arXiv:2403.09578v1 Announce Type: new 
Abstract: The commutation principle proved by Ram\'irez, Seeger, and Sossa (SIAM J Optim 23:687-694, 2013) in the setting of Euclidean Jordan algebras says that for a Fr\'echet differentiable function $\Theta$ and a spectral function $F$, any local minimizer or maximizer $a$ of $\Theta+F$ over a spectral set $\mathcal{E}$ operator commutes with the gradient of $\Theta$ at $a$. In this paper, we improve this commutation principle by allowing $\Theta$ to be nonsmooth with mild regularity assumptions over it. For example, for the case of local minimizer, we show that $a$ operator commutes with some element of the limiting (Mordukhovich) subdifferential of $\Theta$ at $a$ provided that $\Theta$ is subdifferentially regular at $a$ satisfying a qualification condition. For the case of local maximizer, we prove that $a$ operator commutes with each element of the (Fenchel) subdifferential of $\Theta$ at $a$ whenever this subdifferential is nonempty. As an application, we characterize the local optimizers of shifted strictly convex spectral functions and norms over automorphism invariant sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09578v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Juyoung Jeong, David Sossa</dc:creator>
    </item>
    <item>
      <title>Signal Recovery with Proximal Comixtures</title>
      <link>https://arxiv.org/abs/2403.09610</link>
      <description>arXiv:2403.09610v1 Announce Type: new 
Abstract: In variational signal processing and machine learning problems, loss functions and linear operators are typically aggregated as an average of composite terms. We propose an alternative formulation using proximal comixtures, an operation that combines functions and linear operators in such a way that the proximity operator of the resulting function is computable explicitly. The benefits of comixture formulations are illustrated through image recovery and machine learning applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09610v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Patrick L. Combettes, Diego J. Cornejo</dc:creator>
    </item>
    <item>
      <title>Interpolatory model order reduction of large-scale dynamical systems with root mean squared error measures</title>
      <link>https://arxiv.org/abs/2403.08894</link>
      <description>arXiv:2403.08894v1 Announce Type: cross 
Abstract: The root mean squared error is an important measure used in a variety of applications such as structural dynamics and acoustics to model averaged deviations from standard behavior. For large-scale systems, simulations of this quantity quickly become computationally prohibitive. Classical model order reduction techniques attempt to resolve this issue via the construction of surrogate models that emulate the root mean squared error measure using an intermediate linear system. However, this approach requires a potentially large number of linear outputs, which can be disadvantageous in the design of reduced-order models. In this work, we consider directly the root mean squared error as the quantity of interest using the concept of quadratic-output models and propose several new model reduction techniques for the construction of appropriate surrogates. We test the proposed methods on a model for the vibrational response of a plate with tuned vibration absorbers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.08894v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sean Reiter, Steffen W. R. Werner</dc:creator>
    </item>
    <item>
      <title>Strategizing against Q-learners: A Control-theoretical Approach</title>
      <link>https://arxiv.org/abs/2403.08906</link>
      <description>arXiv:2403.08906v1 Announce Type: cross 
Abstract: In this paper, we explore the susceptibility of the Q-learning algorithm (a classical and widely used reinforcement learning method) to strategic manipulation of sophisticated opponents in games. We quantify how much a strategically sophisticated agent can exploit a naive Q-learner if she knows the opponent's Q-learning algorithm. To this end, we formulate the strategic actor's problem as a Markov decision process (with a continuum state space encompassing all possible Q-values) as if the Q-learning algorithm is the underlying dynamical system. We also present a quantization-based approximation scheme to tackle the continuum state space and analyze its performance both analytically and numerically.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.08906v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuksel Arslantas, Ege Yuceel, Muhammed O. Sayin</dc:creator>
    </item>
    <item>
      <title>SINDy-RL: Interpretable and Efficient Model-Based Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2403.09110</link>
      <description>arXiv:2403.09110v1 Announce Type: cross 
Abstract: Deep reinforcement learning (DRL) has shown significant promise for uncovering sophisticated control policies that interact in environments with complicated dynamics, such as stabilizing the magnetohydrodynamics of a tokamak fusion reactor or minimizing the drag force exerted on an object in a fluid flow. However, these algorithms require an abundance of training examples and may become prohibitively expensive for many applications. In addition, the reliance on deep neural networks often results in an uninterpretable, black-box policy that may be too computationally expensive to use with certain embedded systems. Recent advances in sparse dictionary learning, such as the sparse identification of nonlinear dynamics (SINDy), have shown promise for creating efficient and interpretable data-driven models in the low-data regime. In this work we introduce SINDy-RL, a unifying framework for combining SINDy and DRL to create efficient, interpretable, and trustworthy representations of the dynamics model, reward function, and control policy. We demonstrate the effectiveness of our approaches on benchmark control environments and challenging fluids problems. SINDy-RL achieves comparable performance to state-of-the-art DRL algorithms using significantly fewer interactions in the environment and results in an interpretable control policy orders of magnitude smaller than a deep neural network policy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09110v1</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicholas Zolman, Urban Fasel, J. Nathan Kutz, Steven L. Brunton</dc:creator>
    </item>
    <item>
      <title>Synchronisation-Oriented Design Approach for Adaptive Control</title>
      <link>https://arxiv.org/abs/2403.09179</link>
      <description>arXiv:2403.09179v1 Announce Type: cross 
Abstract: This study presents a synchronisation-oriented perspective towards adaptive control which views model-referenced adaptation as synchronisation between actual and virtual dynamic systems. In the context of adaptation, model reference adaptive control methods make the state response of the actual plant follow a reference model. In the context of synchronisation, consensus methods involving diffusive coupling induce a collective behaviour across multiple agents. We draw from the understanding about the two time-scale nature of synchronisation motivated by the study of blended dynamics. The synchronisation-oriented approach consists in the design of a coupling input to achieve desired closed-loop error dynamics followed by the input allocation process to shape the collective behaviour. We suggest that synchronisation can be a reasonable design principle allowing a more holistic and systematic approach to the design of adaptive control systems for improved transient characteristics. Most notably, the proposed approach enables not only constructive derivation but also substantial generalisation of the previously developed closed-loop reference model adaptive control method. Practical significance of the proposed generalisation lies at the capability to improve the transient response characteristics and mitigate the unwanted peaking phenomenon at the same time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09179v1</guid>
      <category>eess.SY</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Namhoon Cho, Seokwon Lee, Hyo-Sang Shin</dc:creator>
    </item>
    <item>
      <title>Reverse em-problem based on Bregman divergence and its application to classical and quantum information theory</title>
      <link>https://arxiv.org/abs/2403.09252</link>
      <description>arXiv:2403.09252v1 Announce Type: cross 
Abstract: The recent paper (IEEE Trans. IT 69, 1680) introduced an analytical method for calculating the channel capacity without the need for iteration. This method has certain limitations that restrict its applicability. Furthermore, the paper does not provide an explanation as to why the channel capacity can be solved analytically in this particular case. In order to broaden the scope of this method and address its limitations, we turn our attention to the reverse em-problem, proposed by Toyota (Information Geometry, 3, 1355 (2020)). This reverse em-problem involves iteratively applying the inverse map of the em iteration to calculate the channel capacity, which represents the maximum mutual information. However, several open problems remained unresolved in Toyota's work. To overcome these challenges, we formulate the reverse em-problem based on Bregman divergence and provide solutions to these open problems. Building upon these results, we transform the reverse em-problem into em-problems and derive a non-iterative formula for the reverse em-problem. This formula can be viewed as a generalization of the aforementioned analytical calculation method. Importantly, this derivation sheds light on the information geometrical structure underlying this special case. By effectively addressing the limitations of the previous analytical method and providing a deeper understanding of the underlying information geometrical structure, our work significantly expands the applicability of the proposed method for calculating the channel capacity without iteration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09252v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>quant-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Masahito Hayashi</dc:creator>
    </item>
    <item>
      <title>Reducing Marketplace Interference Bias Via Shadow Prices</title>
      <link>https://arxiv.org/abs/2205.02274</link>
      <description>arXiv:2205.02274v4 Announce Type: replace 
Abstract: Marketplace companies rely heavily on experimentation when making changes to the design or operation of their platforms. The workhorse of experimentation is the randomized controlled trial (RCT), or A/B test, in which users are randomly assigned to treatment or control groups. However, marketplace interference causes the Stable Unit Treatment Value Assumption (SUTVA) to be violated, leading to bias in the standard RCT metric. In this work, we propose techniques for platforms to run standard RCTs and still obtain meaningful estimates despite the presence of marketplace interference. We specifically consider a generalized matching setting, in which the platform explicitly matches supply with demand via a linear programming algorithm. Our first proposal is for the platform to estimate the value of global treatment and global control via optimization. We prove that this approach is unbiased in the fluid limit. Our second proposal is to compare the average shadow price of the treatment and control groups rather than the total value accrued by each group. We prove that this technique corresponds to the correct first-order approximation (in a Taylor series sense) of the value function of interest even in a finite-size system. We then use this result to prove that, under reasonable assumptions, our estimator is less biased than the RCT estimator. At the heart of our result is the idea that it is relatively easy to model interference in matching-driven marketplaces since, in such markets, the platform mediates the spillover.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.02274v4</guid>
      <category>math.OC</category>
      <category>econ.EM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ido Bright, Arthur Delarue, Ilan Lobel</dc:creator>
    </item>
    <item>
      <title>Statistical and Computational Complexities of BFGS Quasi-Newton Method for Generalized Linear Models</title>
      <link>https://arxiv.org/abs/2206.00207</link>
      <description>arXiv:2206.00207v2 Announce Type: replace 
Abstract: The gradient descent (GD) method has been used widely to solve parameter estimation in generalized linear models (GLMs), a generalization of linear models when the link function can be non-linear. In GLMs with a polynomial link function, it has been shown that in the high signal-to-noise ratio (SNR) regime, due to the problem's strong convexity and smoothness, GD converges linearly and reaches the final desired accuracy in a logarithmic number of iterations. In contrast, in the low SNR setting, where the problem becomes locally convex, GD converges at a slower rate and requires a polynomial number of iterations to reach the desired accuracy. Even though Newton's method can be used to resolve the flat curvature of the loss functions in the low SNR case, its computational cost is prohibitive in high-dimensional settings as it is $\mathcal{O}(d^3)$, where $d$ the is the problem dimension. To address the shortcomings of GD and Newton's method, we propose the use of the BFGS quasi-Newton method to solve parameter estimation of the GLMs, which has a per iteration cost of $\mathcal{O}(d^2)$. When the SNR is low, for GLMs with a polynomial link function of degree $p$, we demonstrate that the iterates of BFGS converge linearly to the optimal solution of the population least-square loss function, and the contraction coefficient of the BFGS algorithm is comparable to that of Newton's method. Moreover, the contraction factor of the linear rate is independent of problem parameters and only depends on the degree of the link function $p$. Also, for the empirical loss with $n$ samples, we prove that in the low SNR setting of GLMs with a polynomial link function of degree $p$, the iterates of BFGS reach a final statistical radius of $\mathcal{O}((d/n)^{\frac{1}{2p+2}})$ after at most $\log(n/d)$ iterations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.00207v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qiujiang Jin, Tongzheng Ren, Nhat Ho, Aryan Mokhtari</dc:creator>
    </item>
    <item>
      <title>A modularized algorithmic framework for interface related optimization problems using characteristic functions</title>
      <link>https://arxiv.org/abs/2206.01876</link>
      <description>arXiv:2206.01876v2 Announce Type: replace 
Abstract: In this paper, we consider the algorithms and convergence for a general optimization problem, which has a wide range of applications in image segmentation, topology optimization, flow network formulation, and surface reconstruction. In particular, the problem focuses on interface related optimization problems where the interface is implicitly described by characteristic functions of the corresponding domains. Under such representation and discretization, the problem is then formulated into a discretized optimization problem where the objective function is concave with respect to characteristic functions and convex with respect to state variables. We show that under such structure, the iterative scheme based on alternative minimization can converge to a local minimizer. Extensive numerical examples are performed to support the theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.01876v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dong Wang, Shangzhi Zeng, Jin Zhang</dc:creator>
    </item>
    <item>
      <title>Stochastic Approximation with Decision-Dependent Distributions: Asymptotic Normality and Optimality</title>
      <link>https://arxiv.org/abs/2207.04173</link>
      <description>arXiv:2207.04173v3 Announce Type: replace 
Abstract: We analyze a stochastic approximation algorithm for decision-dependent problems, wherein the data distribution used by the algorithm evolves along the iterate sequence. The primary examples of such problems appear in performative prediction and its multiplayer extensions. We show that under mild assumptions, the deviation between the average iterate of the algorithm and the solution is asymptotically normal, with a covariance that clearly decouples the effects of the gradient noise and the distributional shift. Moreover, building on the work of H\'ajek and Le Cam, we show that the asymptotic performance of the algorithm with averaging is locally minimax optimal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.04173v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joshua Cutler, Mateo D\'iaz, Dmitriy Drusvyatskiy</dc:creator>
    </item>
    <item>
      <title>Inertial Quasi-Newton Methods for Monotone Inclusion: Efficient Resolvent Calculus and Primal-Dual Methods</title>
      <link>https://arxiv.org/abs/2209.14019</link>
      <description>arXiv:2209.14019v2 Announce Type: replace 
Abstract: We introduce an inertial quasi-Newton Forward-Backward Splitting Algorithm to solve a class of monotone inclusion problems. While the inertial step is computationally cheap, in general, the bottleneck is the evaluation of the resolvent operator. A change of the metric makes its computation hard even for (otherwise in the standard metric) simple operators. In order to fully exploit the advantage of adapting the metric, we develop a new efficient resolvent calculus for a low-rank perturbed standard metric, which accounts exactly for quasi-Newton metrics. Moreover, we prove the convergence of our algorithms, including linear convergence rates in case one of the two considered operators is strongly monotone. Beyond the general monotone inclusion setup, we instantiate a novel inertial quasi-Newton Primal-Dual Hybrid Gradient Method for solving saddle point problems. The favourable performance of our inertial quasi-Newton PDHG method is demonstrated on several numerical experiments in image processing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.14019v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shida Wang, Jalal Fadili, Peter Ochs</dc:creator>
    </item>
    <item>
      <title>A Stochastic-Gradient-based Interior-Point Algorithm for Solving Smooth Bound-Constrained Optimization Problems</title>
      <link>https://arxiv.org/abs/2304.14907</link>
      <description>arXiv:2304.14907v3 Announce Type: replace 
Abstract: A stochastic-gradient-based interior-point algorithm for minimizing a continuously differentiable objective function (that may be nonconvex) subject to bound constraints is presented, analyzed, and demonstrated through experimental results. The algorithm is unique from other interior-point methods for solving smooth nonconvex optimization problems since the search directions are computed using stochastic gradient estimates. It is also unique in its use of inner neighborhoods of the feasible region -- defined by a positive and vanishing neighborhood-parameter sequence -- in which the iterates are forced to remain. It is shown that with a careful balance between the barrier, step-size, and neighborhood sequences, the proposed algorithm satisfies convergence guarantees in both deterministic and stochastic settings. The results of numerical experiments show that in both settings the algorithm can outperform projection-based methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.14907v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Frank E. Curtis, Vyacheslav Kungurtsev, Daniel P. Robinson, Qi Wang</dc:creator>
    </item>
    <item>
      <title>An Inexact Conditional Gradient Method for Constrained Bilevel Optimization</title>
      <link>https://arxiv.org/abs/2306.02429</link>
      <description>arXiv:2306.02429v2 Announce Type: replace 
Abstract: Bilevel optimization is an important class of optimization problems where one optimization problem is nested within another. While various methods have emerged to address unconstrained general bilevel optimization problems, there has been a noticeable gap in research when it comes to methods tailored for the constrained scenario. The few methods that do accommodate constrained problems, often exhibit slow convergence rates or demand a high computational cost per iteration. To tackle this issue, our paper introduces a novel single-loop projection-free method employing a nested approximation technique. This innovative approach not only boasts an improved per-iteration complexity compared to existing methods but also achieves optimal convergence rate guarantees that match the best-known complexity of projection-free algorithms for solving convex constrained single-level optimization problems. In particular, when the hyper-objective function corresponding to the bilevel problem is convex, our method requires $\tilde{\mathcal{O}}(\epsilon^{-1})$ iterations to find an $\epsilon$-optimal solution. Moreover, when the hyper-objective function is non-convex, our method's complexity for finding an $\epsilon$-stationary point is $\mathcal{O}(\epsilon^{-2})$. To showcase the effectiveness of our approach, we present a series of numerical experiments that highlight its superior performance relative to state-of-the-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.02429v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nazanin Abolfazli, Ruichen Jiang, Aryan Mokhtari, Erfan Yazdandoost Hamedani</dc:creator>
    </item>
    <item>
      <title>Optimal Control of Stationary Doubly Diffusive Flows on Two and Three Dimensional Bounded Lipschitz Domains: A Theoretical Study</title>
      <link>https://arxiv.org/abs/2308.02178</link>
      <description>arXiv:2308.02178v2 Announce Type: replace 
Abstract: In this work, a theoretical framework is developed to study the control constrained distributed optimal control of a stationary double diffusion model presented in [Burger, Mendez, Ruiz-Baier, SINUM (2019), 57:1318-1343]. For the control problem, as the source term belongs to a weaker space, a new solvability analysis of the governing equation is presented using Faedo- Galerkin approximation techniques. Some new minimal regularity results for the governing equation are established on two and three-dimensional bounded Lipschitz domains and are of independent interest. Moreover, we show the existence of an optimal control with quadratic type cost functional, study the Frechet differentiability properties of the control-to-state map and establish the first-order necessary optimality conditions corresponding to the optimal control problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.02178v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Jai Tushar, Arbaz Khan, Manil T. Mohan</dc:creator>
    </item>
    <item>
      <title>PROMISE: Preconditioned Stochastic Optimization Methods by Incorporating Scalable Curvature Estimates</title>
      <link>https://arxiv.org/abs/2309.02014</link>
      <description>arXiv:2309.02014v3 Announce Type: replace 
Abstract: This paper introduces PROMISE ($\textbf{Pr}$econditioned Stochastic $\textbf{O}$ptimization $\textbf{M}$ethods by $\textbf{I}$ncorporating $\textbf{S}$calable Curvature $\textbf{E}$stimates), a suite of sketching-based preconditioned stochastic gradient algorithms for solving large-scale convex optimization problems arising in machine learning. PROMISE includes preconditioned versions of SVRG, SAGA, and Katyusha; each algorithm comes with a strong theoretical analysis and effective default hyperparameter values. In contrast, traditional stochastic gradient methods require careful hyperparameter tuning to succeed, and degrade in the presence of ill-conditioning, a ubiquitous phenomenon in machine learning. Empirically, we verify the superiority of the proposed algorithms by showing that, using default hyperparameter values, they outperform or match popular tuned stochastic gradient optimizers on a test bed of $51$ ridge and logistic regression problems assembled from benchmark machine learning repositories. On the theoretical side, this paper introduces the notion of quadratic regularity in order to establish linear convergence of all proposed methods even when the preconditioner is updated infrequently. The speed of linear convergence is determined by the quadratic regularity ratio, which often provides a tighter bound on the convergence rate compared to the condition number, both in theory and in practice, and explains the fast global linear convergence of the proposed methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.02014v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zachary Frangella, Pratik Rathore, Shipu Zhao, Madeleine Udell</dc:creator>
    </item>
    <item>
      <title>The Price of Adaptivity in Stochastic Convex Optimization</title>
      <link>https://arxiv.org/abs/2402.10898</link>
      <description>arXiv:2402.10898v2 Announce Type: replace 
Abstract: We prove impossibility results for adaptivity in non-smooth stochastic convex optimization. Given a set of problem parameters we wish to adapt to, we define a "price of adaptivity" (PoA) that, roughly speaking, measures the multiplicative increase in suboptimality due to uncertainty in these parameters. When the initial distance to the optimum is unknown but a gradient norm bound is known, we show that the PoA is at least logarithmic for expected suboptimality, and double-logarithmic for median suboptimality. When there is uncertainty in both distance and gradient norm, we show that the PoA must be polynomial in the level of uncertainty. Our lower bounds nearly match existing upper bounds, and establish that there is no parameter-free lunch.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.10898v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yair Carmon, Oliver Hinder</dc:creator>
    </item>
    <item>
      <title>Remarks on "Successive Convexification: A Superlinearly Convergent Algorithm for Non-convex Optimal Control Problems"</title>
      <link>https://arxiv.org/abs/2403.00733</link>
      <description>arXiv:2403.00733v2 Announce Type: replace 
Abstract: The purpose of this note is to highlight and address inaccuracies in the convergence guarantees of SCvx, a nonconvex trajectory optimization algorithm proposed by Mao et al. (arXiv:1804.06539), and make connections to relevant prior work. Specifically, we identify errors in the convergence proof within Mao et al. (arXiv:1804.06539) and reestablish the proof of convergence by employing a new method under stricter assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.00733v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dayou Luo, Purnanand Elango, Behcet Acikmese</dc:creator>
    </item>
    <item>
      <title>Large-Scale Minimization of the Pseudospectral Abscissa</title>
      <link>https://arxiv.org/abs/2208.07540</link>
      <description>arXiv:2208.07540v3 Announce Type: replace-cross 
Abstract: This work concerns the minimization of the pseudospectral abscissa of a matrix-valued function dependent on parameters analytically. The problem is motivated by robust stability and transient behavior considerations for a linear control system that has optimization parameters. We describe a subspace procedure to cope with the setting when the matrix-valued function is of large size. The proposed subspace procedure solves a sequence of reduced problems obtained by restricting the matrix-valued function to small subspaces, whose dimensions increase gradually. It possesses desirable features such as the global convergence of the minimal values of the reduced problems to the minimal value of the original problem, and a superlinear convergence exhibited by the decay in the errors of the minimizers of the reduced problems. In mathematical terms, the problem we consider is a large-scale nonconvex minimax eigenvalue optimization problem such that the eigenvalue function appears in the constraint of the inner maximization problem. Devising and analyzing a subspace framework for the minimax eigenvalue optimization problem at hand with the eigenvalue function in the constraint require special treatment that makes use of a Lagrangian and dual variables. There are notable advantages in minimizing the pseudospectral abscissa over maximizing the distance to instability or minimizing the $\mathcal{H}_\infty$ norm; the optimized pseudospectral abscissa provides quantitative information about the worst-case transient growth, and the initial guesses for the parameter values to optimize the pseudospectral abscissa can be arbitrary, unlike the case to optimize the distance to instability and $\mathcal{H}_\infty$ norm that would normally require initial guesses yielding asymptotically stable systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.07540v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicat Aliyev, Emre Mengi</dc:creator>
    </item>
    <item>
      <title>Geometric structure of Deep Learning networks and construction of global ${\mathcal L}^2$ minimizers</title>
      <link>https://arxiv.org/abs/2309.10639</link>
      <description>arXiv:2309.10639v4 Announce Type: replace-cross 
Abstract: In this paper, we explicitly determine local and global minimizers of the $\mathcal{L}^2$ cost function in underparametrized Deep Learning (DL) networks; our main goal is to shed light on their geometric structure and properties. We accomplish this by a direct construction, without invoking the gradient descent flow at any point of this work. We specifically consider $L$ hidden layers, a ReLU ramp activation function, an $\mathcal{L}^2$ Schatten class (or Hilbert-Schmidt) cost function, input and output spaces $\mathbb{R}^Q$ with equal dimension $Q\geq1$, and hidden layers also defined on $\mathbb{R}^{Q}$; the training inputs are assumed to be sufficiently clustered. The training input size $N$ can be arbitrarily large - thus, we are considering the underparametrized regime. More general settings are left to future work. We construct an explicit family of minimizers for the global minimum of the cost function in the case $L\geq Q$, which we show to be degenerate. Moreover, we determine a set of $2^Q-1$ distinct degenerate local minima of the cost function. In the context presented here, the concatenation of hidden layers of the DL network is reinterpreted as a recursive application of a {\em truncation map} which "curates" the training inputs by minimizing their noise to signal ratio.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.10639v4</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Chen, Patricia Mu\~noz Ewald</dc:creator>
    </item>
    <item>
      <title>Stable Nonconvex-Nonconcave Training via Linear Interpolation</title>
      <link>https://arxiv.org/abs/2310.13459</link>
      <description>arXiv:2310.13459v4 Announce Type: replace-cross 
Abstract: This paper presents a theoretical analysis of linear interpolation as a principled method for stabilizing (large-scale) neural network training. We argue that instabilities in the optimization process are often caused by the nonmonotonicity of the loss landscape and show how linear interpolation can help by leveraging the theory of nonexpansive operators. We construct a new optimization scheme called relaxed approximate proximal point (RAPP), which is the first explicit method without anchoring to achieve last iterate convergence rates for $\rho$-comonotone problems while only requiring $\rho &gt; -\tfrac{1}{2L}$. The construction extends to constrained and regularized settings. By replacing the inner optimizer in RAPP we rediscover the family of Lookahead algorithms for which we establish convergence in cohypomonotone problems even when the base optimizer is taken to be gradient descent ascent. The range of cohypomonotone problems in which Lookahead converges is further expanded by exploiting that Lookahead inherits the properties of the base optimizer. We corroborate the results with experiments on generative adversarial networks which demonstrates the benefits of the linear interpolation present in both RAPP and Lookahead.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.13459v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thomas Pethick, Wanyun Xie, Volkan Cevher</dc:creator>
    </item>
    <item>
      <title>Smooth Tchebycheff Scalarization for Multi-Objective Optimization</title>
      <link>https://arxiv.org/abs/2402.19078</link>
      <description>arXiv:2402.19078v2 Announce Type: replace-cross 
Abstract: Multi-objective optimization problems can be found in many real-world applications, where the objectives often conflict each other and cannot be optimized by a single solution. In the past few decades, numerous methods have been proposed to find Pareto solutions that represent different optimal trade-offs among the objectives for a given problem. However, these existing methods could have high computational complexity or may not have good theoretical properties for solving a general differentiable multi-objective optimization problem. In this work, by leveraging the smooth optimization technique, we propose a novel and lightweight smooth Tchebycheff scalarization approach for gradient-based multi-objective optimization. It has good theoretical properties for finding all Pareto solutions with valid trade-off preferences, while enjoying significantly lower computational complexity compared to other methods. Experimental results on various real-world application problems fully demonstrate the effectiveness of our proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.19078v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xi Lin, Xiaoyuan Zhang, Zhiyuan Yang, Fei Liu, Zhenkun Wang, Qingfu Zhang</dc:creator>
    </item>
  </channel>
</rss>
