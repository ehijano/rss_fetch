<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 15 Jul 2025 04:01:06 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Precomputed Dominant Resource Fairness</title>
      <link>https://arxiv.org/abs/2507.08846</link>
      <description>arXiv:2507.08846v1 Announce Type: new 
Abstract: Although resource allocation is a well studied problem in computer science, until the prevalence of distributed systems, such as computing clouds and data centres, the question had been addressed predominantly for single resource type scenarios. At the beginning of the last decade, with the introuction of Dominant Resource Fairness, the studies of the resource allocation problem has finally extended to the multiple resource type scenarios. Dominant Resource Fairness is a solution, addressing the problem of fair allocation of multiple resource types, among users with heterogeneous demands. Based on Max-min Fairness, which is a well established algorithm in the literature for allocating resources in the single resource type scenarios, Dominant Resource Fairness generalises the scheme to the multiple resource case. It has a number of desirable properties that makes it preferable over alternatives, such as Sharing Incentive, Envy-Freeness, Pareto Efficiency, and Strategy Proofness, and as such, it is widely adopted in distributed systems. In the present study, we revisit the original study, and analyse the structure of the algorithm in closer view, to come up with an alternative algorithm, which approximates the Dominant Resource Fairness allocation in fewer steps. We name the new algorithm Precomputed Dominant Resource Fairness, after its main working principle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.08846v1</guid>
      <category>cs.GT</category>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Serdar Metin</dc:creator>
    </item>
    <item>
      <title>A Survey on Bilateral Multi-Round Cloud-SLA Negotiation Strategies</title>
      <link>https://arxiv.org/abs/2507.08868</link>
      <description>arXiv:2507.08868v1 Announce Type: new 
Abstract: Today, static cloud markets where consumers purchase services directly from providers are dominating. Thus, consumers neither negotiate the price nor the characteristics of the service. In recent years, providers have adopted more dynamic trading mechanisms, as e.g. Amazon's EC2 platform shows: In addition to the reservation marketspace and the on-demand marketspace, Amazon offers a spot marketspace where consumers can bid for virtual machines. This spot marketspace was extended with spot blocks, and recently Amazon reworked the bidding options. In addition, other cloud providers, such as Virtustream, adopt dynamic trading mechanisms. The scientific community envisions autonomous multi-round negotiations for realizing future cloud marketspaces. Consequently, consumers and providers exchange offers and counteroffers to reach an agreement. This helps providers increase the utilization of their datacenters, while consumers can purchase highly customized cloud services.
  In the paper at hand, we present a survey on multi-round bilateral negotiation strategies for trading cloud resources. Thus, we analyzed peer-reviewed articles in order to identify trends, gaps, similarities, and the scope of such negotiation strategies. In addition, we surveyed the formalism that the scientific community uses to describe such strategies. Based on these findings, we derived recommendations for creating and documenting bilateral multi-round negotiation strategies to foster their implementation in the industry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.08868v1</guid>
      <category>cs.GT</category>
      <category>cs.DC</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Benedikt Pittl, Werner Mach, Erich Schikuta</dc:creator>
    </item>
    <item>
      <title>Learning from Synthetic Labs: Language Models as Auction Participants</title>
      <link>https://arxiv.org/abs/2507.09083</link>
      <description>arXiv:2507.09083v1 Announce Type: new 
Abstract: This paper investigates the behavior of simulated AI agents (large language models, or LLMs) in auctions, introducing a novel synthetic data-generating process to help facilitate the study and design of auctions. We find that LLMs -- when endowed with chain of thought reasoning capacity -- agree with the experimental literature in auctions across a variety of classic auction formats. In particular, we find that LLM bidders produce results consistent with risk-averse human bidders; that they perform closer to theoretical predictions in obviously strategy-proof auctions; and, that they succumb to the winner's curse in common value settings. On prompting, we find that LLMs are not very sensitive to naive changes in prompts (e.g., language, currency) but can improve dramatically towards theoretical predictions with the right mental model (i.e., the language of Nash deviations). We run 1,000$+$ auctions for less than $\$$400 with GPT-4 models (three orders of magnitude cheaper than modern auction experiments) and develop a framework flexible enough to run auction experiments with any LLM model and a wide range of auction design specifications, facilitating further experimental study by decreasing costs and serving as a proof-of-concept for the use of LLM proxies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09083v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anand Shah, Kehang Zhu, Yanchen Jiang, Jeffrey G. Wang, Arif K. Dayi, John J. Horton, David C. Parkes</dc:creator>
    </item>
    <item>
      <title>Nash Equilibria with Irradical Probabilities</title>
      <link>https://arxiv.org/abs/2507.09422</link>
      <description>arXiv:2507.09422v1 Announce Type: new 
Abstract: We present for every $n\ge4$ an $n$-player game in normal form with payoffs in $\{0,1,2\}$ that has a unique, fully mixed, Nash equilibrium in which all the probability weights are irradical (i.e., algebraic but not closed form expressible even with $m$-th roots for any integer $m$).</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09422v1</guid>
      <category>cs.GT</category>
      <category>math.NT</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Edan Orzech, Martin Rinard</dc:creator>
    </item>
    <item>
      <title>Incentive-Aware Dynamic Resource Allocation under Long-Term Cost Constraints</title>
      <link>https://arxiv.org/abs/2507.09473</link>
      <description>arXiv:2507.09473v1 Announce Type: new 
Abstract: Motivated by applications such as cloud platforms allocating GPUs to users or governments deploying mobile health units across competing regions, we study the dynamic allocation of a reusable resource to strategic agents with private valuations. Our objective is to simultaneously (i) maximize social welfare, (ii) satisfy multi-dimensional long-term cost constraints, and (iii) incentivize truthful reporting. We begin by numerically evaluating primal-dual methods widely used in constrained online optimization and find them to be highly fragile in strategic settings -- agents can easily manipulate their reports to distort future dual updates for future gain.
  To address this vulnerability, we develop an incentive-aware framework that makes primal-dual methods robust to strategic behavior. Our design combines epoch-based lazy updates -- where dual variables remain fixed within each epoch -- with randomized exploration rounds that extract approximately truthful signals for learning. Leveraging carefully designed online learning subroutines that can be of independent interest for dual updates, our mechanism achieves $\tilde{\mathcal{O}}(\sqrt{T})$ social welfare regret, satisfies all cost constraints, and ensures incentive alignment. This matches the performance of non-strategic allocation approaches while being robust to strategic agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09473v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yan Dai, Negin Golrezaei, Patrick Jaillet</dc:creator>
    </item>
    <item>
      <title>Existence of Fair and Efficient Allocation of Indivisible Chores</title>
      <link>https://arxiv.org/abs/2507.09544</link>
      <description>arXiv:2507.09544v1 Announce Type: new 
Abstract: We study the problem of allocating indivisible chores among agents with additive cost functions in a fair and efficient manner. A major open question in this area is whether there always exists an allocation that is envy-free up to one chore (EF1) and Pareto optimal (PO). Our main contribution is to provide a positive answer to this question by proving the existence of such an allocation for indivisible chores under additive cost functions. This is achieved by a novel combination of a fixed point argument and a discrete algorithm, providing a significant methodological advance in this area.
  Our additional key contributions are as follows. We show that there always exists an allocation that is EF1 and fractional Pareto optimal (fPO), where fPO is a stronger efficiency concept than PO. We also show that an EF1 and PO allocation can be computed in polynomial time when the number of agents is constant. Finally, we extend all of these results to the more general setting of weighted EF1 (wEF1), which accounts for the entitlements of agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09544v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ryoga Mahara</dc:creator>
    </item>
    <item>
      <title>Tie-breaking Agnostic Lower Bound for Fictitious Play</title>
      <link>https://arxiv.org/abs/2507.09902</link>
      <description>arXiv:2507.09902v1 Announce Type: new 
Abstract: Fictitious play (FP) is a natural learning dynamic in two-player zero-sum games. Samuel Karlin conjectured in 1959 that FP converges at a rate of $O(t^{-1/2})$ to Nash equilibrium, where $t$ is the number of steps played. However, Daskalakis and Pan disproved the stronger form of this conjecture in 2014, where \emph{adversarial} tie-breaking is allowed.
  This paper disproves Karlin's conjecture in its weaker form. In particular, there exists a 10-by-10 zero-sum matrix game, in which FP converges at a rate of $\Omega(t^{-1/3})$, and no ties occur except for the first step.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09902v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuanhao Wang</dc:creator>
    </item>
    <item>
      <title>Generalized Quantal Response Equilibrium: Existence and Efficient Learning</title>
      <link>https://arxiv.org/abs/2507.09928</link>
      <description>arXiv:2507.09928v1 Announce Type: new 
Abstract: We introduce a new solution concept for bounded rational agents in finite normal-form general-sum games called Generalized Quantal Response Equilibrium (GQRE) which generalizes Quantal Response Equilibrium~\citep{mckelvey1995quantal}. In our setup, each player maximizes a smooth, regularized expected utility of the mixed profiles used, reflecting bounded rationality that subsumes stochastic choice. After establishing existence under mild conditions, we present computationally efficient no-regret independent learning via smoothened versions of the Frank-Wolfe algorithm. Our algorithm uses noisy but correlated gradient estimates generated via a simulation oracle that reports on repeated plays of the game. We analyze convergence properties of our algorithm under assumptions that ensure uniqueness of equilibrium, using a class of gap functions that generalize the Nash gap. We end by demonstrating the effectiveness of our method on a set of complex general-sum games such as high-rank two-player games, large action two-player games, and known examples of difficult multi-player games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09928v1</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Apurv Shukla, Vijay Subramanian, Andy Zhao, Rahul Jain</dc:creator>
    </item>
    <item>
      <title>A New Incentive Model For Content Trust</title>
      <link>https://arxiv.org/abs/2507.09972</link>
      <description>arXiv:2507.09972v1 Announce Type: new 
Abstract: This paper outlines an incentive-driven and decentralized approach to verifying the veracity of digital content at scale. Widespread misinformation, an explosion in AI-generated content and reduced reliance on traditional news sources demands a new approach for content authenticity and truth-seeking that is fit for a modern, digital world. By using smart contracts and digital identity to incorporate 'trust' into the reward function for published content, not just engagement, we believe that it could be possible to foster a self-propelling paradigm shift to combat misinformation through a community-based governance model. The approach described in this paper requires that content creators stake financial collateral on factual claims for an impartial jury to vet with a financial reward for contribution. We hypothesize that with the right financial and social incentive model users will be motivated to participate in crowdsourced fact-checking and content creators will place more care in their attestations. This is an exploratory paper and there are a number of open issues and questions that warrant further analysis and exploration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09972v1</guid>
      <category>cs.GT</category>
      <category>cs.CY</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lucas Barbosa, Sam Kirshner, Rob Kopel, Eric Tze Kuan Lim, Tom Pagram</dc:creator>
    </item>
    <item>
      <title>A Coincidence of Wants Mechanism for Swap Trade Execution in Decentralized Exchanges</title>
      <link>https://arxiv.org/abs/2507.10149</link>
      <description>arXiv:2507.10149v1 Announce Type: new 
Abstract: We propose a mathematically rigorous framework for identifying and completing Coincidence of Wants (CoW) cycles in decentralized exchange (DEX) aggregators. Unlike existing auction based systems such as CoWSwap, our approach introduces an asset matrix formulation that not only verifies feasibility using oracle prices and formal conservation laws but also completes partial CoW cycles of swap orders that are discovered using graph traversal and are settled using imbalance correction. We define bridging orders and show that the resulting execution is slippage free and capital preserving for LPs. Applied to real world Arbitrum swap data, our algorithm demonstrates efficient discovery of CoW cycles and supports the insertion of synthetic orders for atomic cycle closure. This work can be thought of as the detailing of a potential delta-neutral strategy by liquidity providing market makers: a structured CoW cycle execution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.10149v1</guid>
      <category>cs.GT</category>
      <category>cs.CE</category>
      <category>q-fin.TR</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Abhimanyu Nag, Madhur Prabhakar, Tanuj Behl</dc:creator>
    </item>
    <item>
      <title>The Value Problem for Weighted Timed Games with Two Clocks is Undecidable</title>
      <link>https://arxiv.org/abs/2507.10550</link>
      <description>arXiv:2507.10550v1 Announce Type: new 
Abstract: The Value Problem for weighted timed games (WTGs) consists in determining, given a two-player weighted timed game with a reachability objective and a rational threshold, whether or not the value of the game exceeds the threshold. This problem was shown to be undecidable some ten years ago for WTGs making use of at least three clocks, and is known to be decidable for single-clock WTGs. In this paper, we establish undecidability for two-clock WTGs making use of non-negative weights, even in a time-bounded setting, closing the last remaining major gap in our algorithmic understanding of WTGs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.10550v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Quentin Guilmant, Jo\"el Ouaknine, Isa Vialard</dc:creator>
    </item>
    <item>
      <title>LLM-Stackelberg Games: Conjectural Reasoning Equilibria and Their Applications to Spearphishing</title>
      <link>https://arxiv.org/abs/2507.09407</link>
      <description>arXiv:2507.09407v1 Announce Type: cross 
Abstract: We introduce the framework of LLM-Stackelberg games, a class of sequential decision-making models that integrate large language models (LLMs) into strategic interactions between a leader and a follower. Departing from classical Stackelberg assumptions of complete information and rational agents, our formulation allows each agent to reason through structured prompts, generate probabilistic behaviors via LLMs, and adapt their strategies through internal cognition and belief updates. We define two equilibrium concepts: reasoning and behavioral equilibrium, which aligns an agent's internal prompt-based reasoning with observable behavior, and conjectural reasoning equilibrium, which accounts for epistemic uncertainty through parameterized models over an opponent's response. These layered constructs capture bounded rationality, asymmetric information, and meta-cognitive adaptation. We illustrate the framework through a spearphishing case study, where a sender and a recipient engage in a deception game using structured reasoning prompts. This example highlights the cognitive richness and adversarial potential of LLM-mediated interactions. Our results show that LLM-Stackelberg games provide a powerful paradigm for modeling decision-making in domains such as cybersecurity, misinformation, and recommendation systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09407v1</guid>
      <category>cs.AI</category>
      <category>cs.CR</category>
      <category>cs.GT</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Quanyan Zhu</dc:creator>
    </item>
    <item>
      <title>Nearly Tight Sample Complexity for Matroid Online Contention Resolution</title>
      <link>https://arxiv.org/abs/2507.09507</link>
      <description>arXiv:2507.09507v1 Announce Type: cross 
Abstract: Due to their numerous applications, in particular in Mechanism Design, Prophet Inequalities have experienced a surge of interest. They describe competitive ratios for basic stopping time problems where random variables get revealed sequentially. A key drawback in the classical setting is the assumption of full distributional knowledge of the involved random variables, which is often unrealistic. A natural way to address this is via sample-based approaches, where only a limited number of samples from the distribution of each random variable is available. Recently, Fu, Lu, Gavin Tang, Wu, Wu, and Zhang (2024) showed that sample-based Online Contention Resolution Schemes (OCRS) are a powerful tool to obtain sample-based Prophet Inequalities. They presented the first sample-based OCRS for matroid constraints, which is a heavily studied constraint family in this context, as it captures many interesting settings. This allowed them to get the first sample-based Matroid Prophet Inequality, using $O(\log^4 n)$ many samples (per random variable), where $n$ is the number of random variables, while obtaining a constant competitiveness of $\frac{1}{4}-\varepsilon$.
  We present a nearly optimal sample-based OCRS for matroid constraints, which uses only $O(\log \rho \cdot \log^2\log\rho)$ many samples, almost matching a known lower bound of $\Omega(\log \rho)$, where $\rho \leq n$ is the rank of the matroid. Through the above-mentioned connection to Prophet Inequalities, this yields a sample-based Matroid Prophet Inequality using only $O(\log n + \log\rho \cdot \log^2\log\rho)$ many samples, and matching the competitiveness of $\frac{1}{4}-\varepsilon$, which is the best known competitiveness for the considered almighty adversary setting even when the distributions are fully known.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09507v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>cs.GT</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Moran Feldman, Ola Svensson, Rico Zenklusen</dc:creator>
    </item>
    <item>
      <title>Ranked Pairs minimizes the $p$-norm as $p \to \infty$</title>
      <link>https://arxiv.org/abs/2507.09654</link>
      <description>arXiv:2507.09654v1 Announce Type: cross 
Abstract: We prove that Ranked Pairs orders candidates in such a way as to minimize the $p$-norm, in the limit as $p \to \infty$, of those head-to-head margins of victory which go against its ordering.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09654v1</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amir Babak Aazami, Hubert L. Bray</dc:creator>
    </item>
    <item>
      <title>Networked Information Aggregation via Machine Learning</title>
      <link>https://arxiv.org/abs/2507.09683</link>
      <description>arXiv:2507.09683v1 Announce Type: cross 
Abstract: We study a distributed learning problem in which learning agents are embedded in a directed acyclic graph (DAG). There is a fixed and arbitrary distribution over feature/label pairs, and each agent or vertex in the graph is able to directly observe only a subset of the features -- potentially a different subset for every agent. The agents learn sequentially in some order consistent with a topological sort of the DAG, committing to a model mapping observations to predictions of the real-valued label. Each agent observes the predictions of their parents in the DAG, and trains their model using both the features of the instance that they directly observe, and the predictions of their parents as additional features. We ask when this process is sufficient to achieve \emph{information aggregation}, in the sense that some agent in the DAG is able to learn a model whose error is competitive with the best model that could have been learned (in some hypothesis class) with direct access to \emph{all} features, despite the fact that no single agent in the network has such access. We give upper and lower bounds for this problem for both linear and general hypothesis classes. Our results identify the \emph{depth} of the DAG as the key parameter: information aggregation can occur over sufficiently long paths in the DAG, assuming that all of the relevant features are well represented along the path, and there are distributions over which information aggregation cannot occur even in the linear case, and even in arbitrarily large DAGs that do not have sufficient depth (such as a hub-and-spokes topology in which the spoke vertices collectively see all the features). We complement our theoretical results with a comprehensive set of experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09683v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Kearns, Aaron Roth, Emily Ryu</dc:creator>
    </item>
    <item>
      <title>Covering a Few Submodular Constraints and Applications</title>
      <link>https://arxiv.org/abs/2507.09879</link>
      <description>arXiv:2507.09879v1 Announce Type: cross 
Abstract: We consider the problem of covering multiple submodular constraints. Given a finite ground set $N$, a cost function $c: N \rightarrow \mathbb{R}_+$, $r$ monotone submodular functions $f_1,f_2,\ldots,f_r$ over $N$ and requirements $b_1,b_2,\ldots,b_r$ the goal is to find a minimum cost subset $S \subseteq N$ such that $f_i(S) \ge b_i$ for $1 \le i \le r$. When $r=1$ this is the well-known Submodular Set Cover problem. Previous work \cite{chekuri2022covering} considered the setting when $r$ is large and developed bi-criteria approximation algorithms, and approximation algorithms for the important special case when each $f_i$ is a weighted coverage function. These are fairly general models and capture several concrete and interesting problems as special cases. The approximation ratios for these problem are at least $\Omega(\log r)$ which is unavoidable when $r$ is part of the input. In this paper, motivated by some recent applications, we consider the problem when $r$ is a \emph{fixed constant} and obtain two main results. For covering multiple submodular constraints we obtain a randomized bi-criteria approximation algorithm that for any given integer $\alpha \ge 1$ outputs a set $S$ such that $f_i(S) \ge$ $(1-1/e^\alpha -\epsilon)b_i$ for each $i \in [r]$ and $\mathbb{E}[c(S)] \le (1+\epsilon)\alpha \cdot \sf{OPT}$. Second, when the $f_i$ are weighted coverage functions from a deletion-closed set system we obtain a $(1+\epsilon)$ $(\frac{e}{e-1})$ $(1+\beta)$-approximation where $\beta$ is the approximation ratio for the underlying set cover instances via the natural LP. These results show that one can obtain nearly as good an approximation for any fixed $r$ as what one would achieve for $r=1$. We mention some applications that follow easily from these general results and anticipate more in the future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09879v1</guid>
      <category>cs.DS</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tanvi Bajpai, Chandra Chekuri, Pooja Kulkarni</dc:creator>
    </item>
    <item>
      <title>Multi-Player Zero-Sum Markov Games with Networked Separable Interactions</title>
      <link>https://arxiv.org/abs/2307.09470</link>
      <description>arXiv:2307.09470v3 Announce Type: replace 
Abstract: We study a new class of Markov games, \emph(multi-player) zero-sum Markov Games} with \emph{Networked separable interactions} (zero-sum NMGs), to model the local interaction structure in non-cooperative multi-agent sequential decision-making. We define a zero-sum NMG as a model where {the payoffs of the auxiliary games associated with each state are zero-sum and} have some separable (i.e., polymatrix) structure across the neighbors over some interaction network. We first identify the necessary and sufficient conditions under which an MG can be presented as a zero-sum NMG, and show that the set of Markov coarse correlated equilibrium (CCE) collapses to the set of Markov Nash equilibrium (NE) in these games, in that the product of per-state marginalization of the former for all players yields the latter. Furthermore, we show that finding approximate Markov \emph{stationary} CCE in infinite-horizon discounted zero-sum NMGs is \texttt{PPAD}-hard, unless the underlying network has a ``star topology''. Then, we propose fictitious-play-type dynamics, the classical learning dynamics in normal-form games, for zero-sum NMGs, and establish convergence guarantees to Markov stationary NE under a star-shaped network structure. Finally, in light of the hardness result, we focus on computing a Markov \emph{non-stationary} NE and provide finite-iteration guarantees for a series of value-iteration-based algorithms. We also provide numerical experiments to corroborate our theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.09470v3</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chanwoo Park, Kaiqing Zhang, Asuman Ozdaglar</dc:creator>
    </item>
    <item>
      <title>Equilibria in multiagent online problems with predictions</title>
      <link>https://arxiv.org/abs/2405.11873</link>
      <description>arXiv:2405.11873v3 Announce Type: replace 
Abstract: We study the power of (competitive) algorithms with predictions in a multiagent setting. To this goal, we introduce a multiagent version of the ski-rental problem. In this problem agents can collaborate by pooling resources to get a group license for some asset. If the license price is not met then agents have to rent the asset individually for the day at a unit price. Otherwise the license becomes available forever to everyone at no extra cost.
  We investigate the effect of using predictors for self and others' behavior in such a setting, as well as the new equilibria formed in this way.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11873v3</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <category>cs.MA</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gabriel Istrate, Cosmin Bonchi\c{s}, Victor Bogdan</dc:creator>
    </item>
    <item>
      <title>Incentivizing Truthful Data Contributions in a Marketplace for Mean Estimation</title>
      <link>https://arxiv.org/abs/2502.16052</link>
      <description>arXiv:2502.16052v3 Announce Type: replace 
Abstract: We study a data marketplace where a broker intermediates between buyers, who seek to estimate the mean \(\mu\) of an unknown normal distribution \(\Ncal(\mu, \sigma^2)\), and contributors, who can collect data from this distribution at a cost. The broker delegates data collection work to contributors, aggregates reported datasets, sells it to buyers, and redistributes revenue as payments to contributors. We aim to maximize welfare or profit under key constraints: individual rationality for buyers and contributors, incentive compatibility (contributors are incentivized to comply with data collection instructions and truthfully report the collected data), and budget balance (total contributor payments equals total revenue). We first compute welfare/profit-optimal prices under truthful reporting; however, to incentivize data collection and truthful data reporting, we adjust them based on discrepancies in contributors' reported data. This yields a Nash equilibrium (NE) where the two lowest-cost contributors collect all data. We complement this with two hardness results: \emph{(i)} no nontrivial dominant-strategy incentive-compatible mechanism exists in this problem, and \emph{(ii)} no mechanism outperforms ours in a NE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16052v3</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Keran Chen, Alex Clinton, Kirthevasan Kandasamy</dc:creator>
    </item>
    <item>
      <title>It's Not All Black and White: Degree of Truthfulness for Risk-Avoiding Agents</title>
      <link>https://arxiv.org/abs/2502.18805</link>
      <description>arXiv:2502.18805v2 Announce Type: replace 
Abstract: The classic notion of \emph{truthfulness} requires that no agent has a profitable manipulation -- an untruthful report that, for \emph{some} combination of reports of the other agents, increases her utility. This strong notion implicitly assumes that the manipulating agent either knows what all other agents are going to report, or is willing to take the risk and act as-if she knows their reports.
  Without knowledge of the others' reports, most manipulations are \emph{risky} -- they might decrease the manipulator's utility for some other combinations of reports by the other agents. Accordingly, a recent paper (Bu, Song and Tao, ``On the existence of truthful fair cake cutting mechanisms'', Artificial Intelligence 319 (2023), 103904) suggests a relaxed notion, which we refer to as \emph{risk-avoiding truthfulness (RAT)}, which requires only that no agent can gain from a \emph{safe} manipulation -- one that is sometimes beneficial and never harmful.
  Truthfulness and RAT are two extremes: the former considers manipulators with complete knowledge of others, whereas the latter considers manipulators with no knowledge at all. In reality, agents often know about some -- but not all -- of the other agents. This paper introduces the \emph{RAT-degree} of a mechanism, defined as the smallest number of agents whose reports, if known, may allow another agent to safely manipulate, or $n$ if there is no such number. This notion interpolates between classic truthfulness (degree $n$) and RAT (degree at least $1$): a mechanism with a higher RAT-degree is harder to manipulate safely.
  To illustrate the generality and applicability of this concept, we analyze the RAT-degree of prominent mechanisms across various social choice settings, including auctions, indivisible goods allocations, cake-cutting, voting, and two-sided matching.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.18805v2</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>econ.TH</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3736252.374265</arxiv:DOI>
      <dc:creator>Eden Hartman, Erel Segal-Halevi, Biaoshuai Tao</dc:creator>
    </item>
    <item>
      <title>Vector Cost Bimatrix Games with Applications to Autonomous Racing</title>
      <link>https://arxiv.org/abs/2507.05171</link>
      <description>arXiv:2507.05171v2 Announce Type: replace 
Abstract: We formulate a vector cost alternative to the scalarization method for weighting and combining multi-objective costs. The algorithm produces solutions to bimatrix games that are simultaneously pure, unique Nash equilibria and Pareto optimal with guarantees for avoiding worst case outcomes. We achieve this by enforcing exact potential game constraints to guide cost adjustments towards equilibrium, while minimizing the deviation from the original cost structure. The magnitude of this adjustment serves as a metric for differentiating between Pareto optimal solutions. We implement this approach in a racing competition between agents with heterogeneous cost structures, resulting in fewer collision incidents with a minimal decrease in performance. Code is available at https://github.com/toazbenj/race_simulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.05171v2</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Benjamin R. Toaz, Shaunak D. Bopardikar</dc:creator>
    </item>
    <item>
      <title>Tarski Lower Bounds from Multi-Dimensional Herringbones</title>
      <link>https://arxiv.org/abs/2502.16679</link>
      <description>arXiv:2502.16679v2 Announce Type: replace-cross 
Abstract: Tarski's theorem states that every monotone function from a complete lattice to itself has a fixed point. We analyze the query complexity of finding such a fixed point on the $k$-dimensional grid of side length $n$ under the $\leq$ relation. In this setting, there is an unknown monotone function $f: \{0,1,\ldots, n-1\}^k \to \{0,1,\ldots, n-1\}^k$ and an algorithm must query a vertex $v$ to learn $f(v)$. The goal is to find a fixed point of $f$ using as few oracle queries as possible.
  We show that the randomized query complexity of this problem is $\Omega\left( \frac{k \cdot \log^2{n}}{\log{k}} \right)$ for all $n,k \geq 2$. This unifies and improves upon two prior results: a lower bound of $\Omega(\log^2{n})$ from [EPRY 2019] and a lower bound of $\Omega\left( \frac{k \cdot \log{n}}{\log{k}}\right)$ from [BPR 2024], respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16679v2</guid>
      <category>cs.CC</category>
      <category>cs.GT</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Simina Br\^anzei, Reed Phillips, Nicholas Recker</dc:creator>
    </item>
    <item>
      <title>Prediction-Augmented Mechanism Design for Weighted Facility Location</title>
      <link>https://arxiv.org/abs/2507.06509</link>
      <description>arXiv:2507.06509v3 Announce Type: replace-cross 
Abstract: Facility location is fundamental in operations research, mechanism design, and algorithmic game theory, with applications ranging from urban infrastructure planning to distributed systems. Recent research in this area has focused on augmenting classic strategyproof mechanisms with predictions to achieve an improved performance guarantee against the uncertainty under the strategic environment. Previous work has been devoted to address the trade-off obstacle of balancing the consistency (near-optimality under accurate predictions) and robustness (bounded inefficiency under poor predictions) primarily in the unweighted setting, assuming that all agents have the same importance. However, this assumption may not be true in some practical scenarios, leading to research of weighted facility location problems.
  The major contribution of the current work is to provide a prediction augmented algorithmic framework for balancing the consistency and robustness over strategic agents with non-uniform weights. In particular, through a reduction technique that identifies a subset of representative instances and maps the other given locations to the representative ones, we prove that there exists a strategyproof mechanism achieving a bounded consistency guarantee of $\frac{\sqrt{(1+c)^2W^2_{\min}+(1-c)^2W^2_{\max}}}{(1+c)W_{\min}}$ and a bounded robustness guarantee of $\frac{\sqrt{(1-c)^2W^2_{\min}+(1+c)^2W^2_{\max}}}{(1-c)W_{\min}}$ in weighted settings, where $c$ can be viewed as a parameter to make a trade-off between the consistency and robustness and $W_{\min}$ and $W_{\max}$ denote the minimum and maximum agents' weight. We also prove that there is no strategyproof deterministic mechanism that reach $1$-consistency and $O\left( n \cdot \frac{W_{\max}}{W_{\min}} \right)$-robustness in weighted FLP, even with fully predictions of all agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06509v3</guid>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yangguang Shi, Zhenyu Xue</dc:creator>
    </item>
  </channel>
</rss>
