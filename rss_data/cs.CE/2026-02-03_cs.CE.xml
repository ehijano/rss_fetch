<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 03 Feb 2026 16:06:16 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>An Impulse-formed Navier-Stokes Solver based on Long-range Particle Flow Maps</title>
      <link>https://arxiv.org/abs/2602.00499</link>
      <description>arXiv:2602.00499v1 Announce Type: new 
Abstract: We present a particle-grid characteristic-mapping framework that extends long-range characteristic mapping from inviscid flows to general Navier-Stokes dynamics with viscosity, body forces, and complex boundaries. Unlike traditional grid-based and vorticity-centered characteristic methods, our method is built on the observation that particle trajectories naturally provide the long-range flow map, enabling geometric quantities and their gradients to be transported in a direct and effective manner. We identify the impulse, the gauge variable of the velocity field, as the primary quantity mapped along characteristics while remaining compatible with standard velocity-based incompressible solvers. Using the 1-form representation of the impulse equation, we derive an integral formulation that decomposes the impulse evolution into a component transported geometrically along the particle flow map and a complementary component generated by viscosity and body forces evaluated through path integrals accumulated along particle trajectories. These components together yield a unified characteristic-mapping solver capable of handling incompressible Navier-Stokes flows with viscosity and body forces while maintaining the accuracy and geometric fidelity of characteristic transport.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00499v1</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhiqi Li, Duowen Chen, Junwei Zhou, Sinan Wang, Yuchen Sun, Bo Zhu</dc:creator>
    </item>
    <item>
      <title>The Enhanced Physics-Informed Kolmogorov-Arnold Networks: Applications of Newton's Laws in Financial Deep Reinforcement Learning (RL) Algorithms</title>
      <link>https://arxiv.org/abs/2602.01388</link>
      <description>arXiv:2602.01388v1 Announce Type: new 
Abstract: Deep Reinforcement Learning (DRL), a subset of machine learning focused on sequential decision-making, has emerged as a powerful approach for tackling financial trading problems. In finance, DRL is commonly used either to generate discrete trade signals or to determine continuous portfolio allocations. In this work, we propose a novel reinforcement learning framework for portfolio optimization that incorporates Physics-Informed Kolmogorov-Arnold Networks (PIKANs) into several DRL algorithms. The approach replaces conventional multilayer perceptrons with Kolmogorov-Arnold Networks (KANs) in both actor and critic components-utilizing learnable B-spline univariate functions to achieve parameter-efficient and more interpretable function approximation. During actor updates, we introduce a physics-informed regularization loss that promotes second-order temporal consistency between observed return dynamics and the action-induced portfolio adjustments. The proposed framework is evaluated across three equity markets-China, Vietnam, and the United States, covering both emerging and developed economies. Across all three markets, PIKAN-based agents consistently deliver higher cumulative and annualized returns, superior Sharpe and Calmar ratios, and more favorable drawdown characteristics compared to both standard DRL baselines and classical online portfolio-selection methods. This yields more stable training, higher Sharpe ratios, and superior performance compared to traditional DRL counterparts. The approach is particularly valuable in highly dynamic and noisy financial markets, where conventional DRL often suffers from instability and poor generalization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01388v1</guid>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Trang Thoi, Hung Tran, Tram Thoi, Huaiyang Zhong</dc:creator>
    </item>
    <item>
      <title>Mutual-Guided Expert Collaboration for Cross-Subject EEG Classification</title>
      <link>https://arxiv.org/abs/2602.01728</link>
      <description>arXiv:2602.01728v1 Announce Type: new 
Abstract: Decoding the human brain from electroencephalography (EEG) signals holds promise for understanding neurological activities. However, EEG data exhibit heterogeneity across subjects and sessions, limiting the generalization of existing methods. Representation learning approaches sacrifice subject-specific information for domain invariance, while ensemble learning methods risk error accumulation for unseen subjects. From a theoretical perspective, we reveal that the applicability of these paradigms depends on the reducibility cost of domain-specific functions to domain-invariant ones. Building on this insight, we propose a Mutual-Guided Expert Collaboration (MGEC) framework that employs distinct network structures aligned with domain-specific and domain-invariant functions. Shared expert-guided learning captures reducible domain-invariant functions. Routed expert-guided learning employs a mixture-of-experts architecture to model irreducible domain-specific functions. Mutual-guided learning enables collaborative regularization to prevent over-reduction and under-reduction. We validate our theoretical findings on synthetic datasets, and experiments on seven benchmarks demonstrate that MGEC outperforms state-of-the-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01728v1</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhi Zhang, Yan Liu, Zhejing Hu, Gong Chen, Jiannong Cao, Shenghua Zhong, Sean Fontaine, Changhong Jing, Shuqiang Wang</dc:creator>
    </item>
    <item>
      <title>Cell-JEPA: Latent Representation Learning for Single-Cell Transcriptomics</title>
      <link>https://arxiv.org/abs/2602.02093</link>
      <description>arXiv:2602.02093v1 Announce Type: new 
Abstract: Single-cell foundation models learn by reconstructing masked gene expression, implicitly treating technical noise as signal. With dropout rates exceeding 90%, reconstruction objectives encourage models to encode measurement artifacts rather than stable cellular programs. We introduce Cell-JEPA, a joint-embedding predictive architecture that shifts learning from reconstructing sparse counts to predicting in latent space. The key insight is that cell identity is redundantly encoded across genes. We show predicting cell-level embeddings from partial observations forces the model to learn dropout-robust features. On cell-type clustering, Cell-JEPA achieves 0.72 AvgBIO in zero-shot transfer versus 0.53 for scGPT, a 36% relative improvement. On perturbation prediction within a single cell line, Cell-JEPA improves absolute-state reconstruction but not effect-size estimation, suggesting that representation learning and perturbation modeling address complementary aspects of cellular prediction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02093v1</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ali ElSheikh, Rui-Xi Wang, Weimin Wu, Yibo Wen, Payam Dibaeinia, Jennifer Yuntong Zhang, Jerry Yao-Chieh Hu, Mei Knudson, Sudarshan Babu, Shao-Hua Sun, Aly A. Khan, Han Liu</dc:creator>
    </item>
    <item>
      <title>Neural Geometry for PDEs: Regularity, Stability, and Convergence Guarantees</title>
      <link>https://arxiv.org/abs/2602.02271</link>
      <description>arXiv:2602.02271v1 Announce Type: new 
Abstract: Implicit Neural Representations (INRs) have emerged as a powerful tool for geometric representation, yet their suitability for physics-based simulation remains underexplored. While metrics like Hausdorff distance quantify surface reconstruction quality, they fail to capture the geometric regularity required for provable numerical performance. This work establishes a unified theoretical framework connecting INR training errors to Partial Differential Equation (PDE) (specifically, linear elliptic equation) solution accuracy. We define the minimal geometric regularity required for INRs to support well-posed boundary value problems and derive \emph{a priori} error estimates linking the neural network's function approximation error to the finite element discretization error. Our analysis reveals that to match the convergence rate of linear finite elements, the INR training loss must scale quadratically relative to the mesh size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02271v1</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Samundra Karki, Adarsh Krishnamurthy, Baskar Ganapathysubramanian</dc:creator>
    </item>
    <item>
      <title>Modelling Socio-Psychological Drivers of Land Management Intensity</title>
      <link>https://arxiv.org/abs/2602.02347</link>
      <description>arXiv:2602.02347v1 Announce Type: new 
Abstract: Land management intensity shapes ecosystem service provision, socio-ecological resilience and is central to sustainable transformation. Yet most land use models emphasise economic and biophysical drivers, while socio-psychological factors influencing land managers' decisions remain underrepresented despite increasing evidence that they shape land management choices. To address this gap, we develop a generic behavioural extension for agent-based land use models, guided by the Theory of Planned Behaviour as an overarching conceptual framework. The extension integrates environmental attitudes, descriptive social norms and behavioural inertia into land managers' decisions on land management intensity. To demonstrate applicability, the extension is coupled to an existing land use modelling framework and explored in stylised settings to isolate behavioural mechanisms. Results show that socio-psychological drivers can significantly alter land management intensity shares, landscape configuration, and ecosystem service provision. Nonlinear feedbacks between these drivers, spatial resource heterogeneity, and ecosystem service demand lead to emergent dynamics that are sometimes counter-intuitive and can diverge from the agent-level decision rules. Increasing the influence of social norms generates spatial clustering and higher landscape connectivity, while feedbacks between behavioural factors can lead to path dependence, lock-in effects, and the emergence of multiple stable regimes with sharp transitions. The proposed framework demonstrates how even low levels of behavioural diversity and social interactions can reshape system-level land use outcomes and provides a reusable modelling component for incorporating socio-psychological processes into land use simulations. The approach can be integrated into other agent-based land use models and parameterised empirically in future work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02347v1</guid>
      <category>cs.CE</category>
      <category>cs.MA</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ronja Hotz, Calum Brown, Yongchao Zeng, Thomas Schmitt, Mark Rounsevell</dc:creator>
    </item>
    <item>
      <title>Bitcoin Price Prediction using Machine Learning and Combinatorial Fusion Analysis</title>
      <link>https://arxiv.org/abs/2602.00037</link>
      <description>arXiv:2602.00037v1 Announce Type: cross 
Abstract: In this work, we propose to apply a new model fusion and learning paradigm, known as Combinatorial Fusion Analysis (CFA), to the field of Bitcoin price prediction. Price prediction of financial product has always been a big topic in finance, as the successful prediction of the price can yield significant profit. Every machine learning model has its own strength and weakness, which hinders progress toward robustness. CFA has been used to enhance models by leveraging rank-score characteristic (RSC) function and cognitive diversity in the combination of a moderate set of diverse and relatively well-performed models. Our method utilizes both score and rank combinations as well as other weighted combination techniques. Key metrics such as RMSE and MAPE are used to evaluate our methodology performance. Our proposal presents a notable MAPE performance of 0.19\%. The proposed method greatly improves upon individual model performance, as well as outperforms other Bitcoin price prediction models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00037v1</guid>
      <category>q-fin.ST</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuanhong Wu, Wei Ye, Jingyan Xu, D. Frank Hsu</dc:creator>
    </item>
    <item>
      <title>Impact of LLMs news Sentiment Analysis on Stock Price Movement Prediction</title>
      <link>https://arxiv.org/abs/2602.00086</link>
      <description>arXiv:2602.00086v1 Announce Type: cross 
Abstract: This paper addresses stock price movement prediction by leveraging LLM-based news sentiment analysis. Earlier works have largely focused on proposing and assessing sentiment analysis models and stock movement prediction methods, however, separately. Although promising results have been achieved, a clear and in-depth understanding of the benefit of the news sentiment to this task, as well as a comprehensive assessment of different architecture types in this context, is still lacking. Herein, we conduct an evaluation study that compares 3 different LLMs, namely, DeBERTa, RoBERTa and FinBERT, for sentiment-driven stock prediction. Our results suggest that DeBERTa outperforms the other two models with an accuracy of 75% and that an ensemble model that combines the three models can increase the accuracy to about 80%. Also, we see that sentiment news features can benefit (slightly) some stock market prediction models, i.e., LSTM-, PatchTST- and tPatchGNN-based classifiers and PatchTST- and TimesNet-based regression tasks models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00086v1</guid>
      <category>q-fin.ST</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Walid Siala (SnT, University of Luxembourg, Luxembourg), Ahmed Khanfir (RIADI, ENSI, University of Manouba, Tunisia, SnT, University of Luxembourg, Luxembourg), Mike Papadakis (SnT, University of Luxembourg, Luxembourg)</dc:creator>
    </item>
    <item>
      <title>A Formal Approach to AMM Fee Mechanisms with Lean 4</title>
      <link>https://arxiv.org/abs/2602.00101</link>
      <description>arXiv:2602.00101v1 Announce Type: cross 
Abstract: Decentralized Finance (DeFi) has revolutionized financial markets by enabling complex asset-exchange protocols without trusted intermediaries. Automated Market Makers (AMMs) are a central component of DeFi, providing the core functionality of swapping assets of different types at algorithmically computed exchange rates. Several mainstream AMM implementations are based on the constant-product model, which ensures that swaps preserve the product of the token reserves in the AMM -- up to a \emph{trading fee} used to incentivize liquidity provision. Trading fees substantially complicate the economic properties of AMMs, and for this reason some AMM models abstract them away in order to simplify the analysis. However, trading fees have a non-trivial impact on users' trading strategies, making it crucial to develop refined AMM models that precisely account for their effects. We extend a foundational model of AMMs by introducing a new parameter, the trading fee $\phi\in(0,1]$, into the swap rate function. Fee amounts increase inversely proportional to $\phi$. When $\phi = 1$, no fee is applied and the original model is recovered. We analyze the resulting fee-adjusted model from an economic perspective. We show that several key properties of the swap rate function, including output-boundedness and monotonicity, are preserved. At the same time, other properties - most notably additivity - no longer hold. We precisely characterize this deviation by deriving a generalized form of additivity that captures the effect of swaps in the presence of trading fees. We prove that when $\phi &lt; 1$, executing a single large swap yields strictly greater profit than splitting the trade into smaller ones. Finally, we derive a closed-form solution to the arbitrage problem in the presence of trading fees and prove its uniqueness. All results are formalized and machine-checked in the Lean 4 proof assistant.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00101v1</guid>
      <category>q-fin.MF</category>
      <category>cs.CE</category>
      <category>cs.CR</category>
      <category>q-fin.TR</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marco Dessalvi, Massimo Bartoletti, Alberto Lluch-Lafuente</dc:creator>
    </item>
    <item>
      <title>Multimodal Scientific Learning Beyond Diffusions and Flows</title>
      <link>https://arxiv.org/abs/2602.00960</link>
      <description>arXiv:2602.00960v1 Announce Type: cross 
Abstract: Scientific machine learning (SciML) increasingly requires models that capture multimodal conditional uncertainty arising from ill-posed inverse problems, multistability, and chaotic dynamics. While recent work has favored highly expressive implicit generative models such as diffusion and flow-based methods, these approaches are often data-hungry, computationally costly, and misaligned with the structured solution spaces frequently found in scientific problems. We demonstrate that Mixture Density Networks (MDNs) provide a principled yet largely overlooked alternative for multimodal uncertainty quantification in SciML. As explicit parametric density estimators, MDNs impose an inductive bias tailored to low-dimensional, multimodal physics, enabling direct global allocation of probability mass across distinct solution branches. This structure delivers strong data efficiency, allowing reliable recovery of separated modes in regimes where scientific data is scarce. We formalize these insights through a unified probabilistic framework contrasting explicit and implicit distribution networks, and demonstrate empirically that MDNs achieve superior generalization, interpretability, and sample efficiency across a range of inverse, multistable, and chaotic scientific regression tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00960v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Leonardo Ferreira Guilhoto, Akshat Kaushal, Paris Perdikaris</dc:creator>
    </item>
    <item>
      <title>Harnessing Flexible Spatial and Temporal Data Center Workloads for Grid Regulation Services</title>
      <link>https://arxiv.org/abs/2602.01508</link>
      <description>arXiv:2602.01508v1 Announce Type: cross 
Abstract: Data centers (DCs) are increasingly recognized as flexible loads that can support grid frequency regulation. Yet, most existing methods treat workload scheduling and regulation capacity bidding separately, overlooking how queueing dynamics and spatial-temporal dispatch decisions affect the ability to sustain real-time regulation. As a result, the committed regulation may become infeasible or short-lived. To address this issue, we propose a unified day-ahead co-optimization framework that jointly decides workload distribution across geographically distributed DCs and regulation capacity commitments. We construct a space-time network model to capture workload migration costs, latency requirements, and heterogeneous resource limits. To ensure that the committed regulation remains deliverable, we introduce chance constraints on instantaneous power flexibility based on interactive load forecasts, and apply Value-at-Risk queue-state constraints to maintain sustainable response under cumulative regulation signals. Case studies on a modified IEEE 68-bus system using real data center traces show that the proposed framework lowers system operating costs, enables more viable regulation capacity, and achieves better revenue-risk trade-offs compared to strategies that optimize scheduling and regulation independently.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01508v1</guid>
      <category>eess.SY</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.SY</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yingrui Fan, Junbo Zhao</dc:creator>
    </item>
    <item>
      <title>FluxNet: Learning Capacity-Constrained Local Transport Operators for Conservative and Bounded PDE Surrogates</title>
      <link>https://arxiv.org/abs/2602.01941</link>
      <description>arXiv:2602.01941v1 Announce Type: cross 
Abstract: Autoregressive learning of time-stepping operators offers an effective approach to data-driven PDE simulation on grids. For conservation laws, however, long-horizon rollouts are often destabilized when learned updates violate global conservation and, in many applications, additional state bounds such as nonnegative mass and densities or concentrations constrained to [0,1]. Enforcing these coupled constraints via direct next-state regression remains difficult. We introduce a framework for learning conservative transport operators on regular grids, inspired by lattice Boltzmann-style discrete-velocity transport representations. Instead of predicting the next state, the model outputs local transport operators that update cells through neighborhood exchanges, guaranteeing discrete conservation by construction. For bounded quantities, we parameterize transport within a capacity-constrained feasible set, enforcing bounds structurally rather than by post-hoc clipping. We validate FluxNet on 1D convection-diffusion, 2D shallow water equations, 1D traffic flow, and 2D spinodal decomposition. Experiments on shallow-water equations and traffic flow show improved rollout stability and physical consistency over strong baselines. On phase-field spinodal decomposition, the method enables large time-steps with long-range transport, accelerating simulation while preserving microstructure evolution in both pointwise and statistical measures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01941v1</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zishuo Lan, Junjie Li, Lei Wang, Jincheng Wang</dc:creator>
    </item>
    <item>
      <title>Structure-Guided Memory Consolidation for Mitigating Compounding Errors in Literature Review Generation</title>
      <link>https://arxiv.org/abs/2508.04306</link>
      <description>arXiv:2508.04306v3 Announce Type: replace 
Abstract: Compounding errors pose a significant challenge in automatic literature review generation, as inaccuracies can cascade across multi-stage retrieval and generation workflows. Existing self-correction strategies often lack mechanisms to effectively track and consolidate verified information throughout the process, making it difficult to prevent error accumulation and propagation. In this paper, we propose Structure-Guided Memory Consolidation (SGMC), a novel framework that incrementally consolidates and verifies information using structured representations at each stage of the literature review pipeline. SGMC consists of three key modules: Tree-Guided Memory for hierarchical literature retrieval and outline generation, Hub-Guided Memory for evidence extraction and iterative content refinement, and Self-Loop Memory for proactive error correction via historical feedback. Extensive experiments on public benchmarks and a newly constructed large-scale dataset demonstrate that SGMC achieves state-of-the-art performance in citation accuracy and content quality, significantly mitigating compounding errors in long-form literature review generation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04306v3</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhi Zhang, Yan Liu, Zhejing Hu, Gong Chen, Shenghua Zhong, Sean Fontaine, Jiannong Cao</dc:creator>
    </item>
    <item>
      <title>A Survey of AI Methods for Geometry Preparation and Mesh Generation in Engineering Simulation</title>
      <link>https://arxiv.org/abs/2512.23719</link>
      <description>arXiv:2512.23719v2 Announce Type: replace 
Abstract: Artificial intelligence is beginning to reduce the manual effort in the CAD-to-mesh pipeline. Written for meshing and geometry practitioners with limited AI background, this survey organizes recent work by workflow step. We cover part classification and segmentation, mesh quality prediction, and defeaturing. We review AI guidance for unstructured meshing, block-structured meshing in 2D and 3D, and volumetric parameterization, including reconstruction from implicit or sampled geometry. We also discuss parallel mesh generation and scripting automation via reinforcement learning and large language models. Across these topics, AI complements established geometry and meshing algorithms rather than replacing them. We conclude with practical lessons and open challenges in data, benchmarks, and trustworthy integration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23719v2</guid>
      <category>cs.CE</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Steven Owen, Nathan Brown, Nikos Chrisochoides, Rao Garimella, Xianfeng Gu, Franck Ledoux, Na Lei, Roshan Quadros, Navamita Ray, Nicolas Winovich, Yongjie Jessica Zhang</dc:creator>
    </item>
    <item>
      <title>LEAD: An EEG Foundation Model for Alzheimer's Disease Detection</title>
      <link>https://arxiv.org/abs/2502.01678</link>
      <description>arXiv:2502.01678v4 Announce Type: replace-cross 
Abstract: Electroencephalography (EEG) provides a non-invasive, highly accessible, and cost-effective approach for detecting Alzheimer's disease (AD). However, existing methods, whether based on handcrafted feature engineering or standard deep learning, face three major challenges: 1) the lack of large-scale EEG-based AD datasets for robust representation learning; 2) limited generalizability across subjects; and 3) difficulty in adapting to highly heterogeneous data. To address these challenges, we curate the world's largest EEG-AD corpus to date, comprising 2,238 subjects. Leveraging this unique resource, we propose LEAD, the first large-scale foundation model for EEG-based AD detection. Specifically, we design a gated temporal-spatial Transformer that can adapt to EEG recordings with arbitrary lengths, channel configurations, and sampling rates. In addition, we introduce a subject-regularized training strategy to enhance subject-level feature learning. We further employ medical contrastive learning for pre-training on 13 datasets, including 4 AD datasets and 9 non-AD neurological disorder datasets, and fine-tune/test the model on the other 5 AD datasets. LEAD achieves the best average ranking across all 20 evaluations on 5 downstream datasets, substantially outperforming existing approaches, including state-of-the-art (SOTA) EEG foundation models. These results strongly demonstrate the effectiveness and practical potential of the proposed method for real-world EEG-based AD detection. Source code: https://github.com/DL4mHealth/LEAD</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01678v4</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>eess.SP</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yihe Wang, Nan Huang, Nadia Mammone, Marco Cecchi, Xiang Zhang</dc:creator>
    </item>
    <item>
      <title>Sparse Latent Factor Forecaster (SLFF) with Iterative Inference for Transparent Multi-Horizon Commodity Futures Prediction</title>
      <link>https://arxiv.org/abs/2505.06795</link>
      <description>arXiv:2505.06795v4 Announce Type: replace-cross 
Abstract: Commodity futures are volatile. Forecasting across horizons with interpretable drivers remains challenging. We propose the Sparse Latent Factor Forecaster with Iterative Inference (SLFF), a structured prediction latent variable model that combines sparse coding, unrolled optimization, and amortized inference. SLFF explicitly optimizes a sparse latent code to explain multi-horizon futures trajectories and trains an encoder whose outputs are validated against the optimization-based solution before deployment. The method is paired with an information set aware pipeline (vintage macro releases, lag aware fills, leakage checks) and evaluated under rolling origin folds against representative statistical and neural baselines. We provide quantitative criteria for factor labeling and directional diagnostics that account for no change regimes. On Copper and WTI futures (2005-2023), SLFF achieves competitive RMSE and MAE, improves directional skill beyond persistence, and yields factors that are stable across seeds and linked to measurable fundamentals. Code, diagnostics, and information set specifications are released for reproducibility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06795v4</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Abhijit Gupta</dc:creator>
    </item>
    <item>
      <title>Fast prediction of plasma instabilities with sparse-grid-accelerated optimized dynamic mode decomposition</title>
      <link>https://arxiv.org/abs/2507.03245</link>
      <description>arXiv:2507.03245v3 Announce Type: replace-cross 
Abstract: Parametric data-driven reduced-order models (ROMs) that embed dependencies in a large number of input parameters are crucial for enabling many-query tasks in large-scale problems. These tasks, including design optimization, control, and uncertainty quantification, are essential for developing digital twins in real-world applications. However, standard grid-based data generation methods are computationally prohibitive due to the curse of dimensionality. This paper investigates efficient training of parametric data-driven ROMs using sparse grid interpolation with (L)-Leja points, specifically targeting scenarios with higher-dimensional input parameter spaces. (L)-Leja points are nested and exhibit slow growth, resulting in sparse grids with low cardinality in low-to-medium dimensional settings, making them ideal for large-scale, computationally expensive problems. Focusing on gyrokinetic simulations of plasma micro-instabilities in fusion experiments as a representative real-world application, we construct parametric ROMs for the full 5D gyrokinetic distribution function via optimized dynamic mode decomposition (optDMD) and sparse grids based on (L)-Leja points. We perform detailed experiments in two scenarios: First, the Cyclone Base Case benchmark assesses optDMD ROM prediction capabilities beyond training time horizons and across variations in the binormal wave number. Second, for a real-world electron-temperature-gradient-driven micro-instability simulation with six input parameters, we demonstrate that a predictive parametric optDMD ROM that is up to three orders of magnitude cheaper to evaluate can be constructed using only 28 high-fidelity gyrokinetic simulations, enabled by the use of sparse grids. In the broader context of fusion research, these results demonstrate the potential of sparse grid-based parametric ROMs to enable otherwise intractable many-query tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.03245v3</guid>
      <category>physics.comp-ph</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.plasm-ph</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.jcp.2026.114718</arxiv:DOI>
      <arxiv:journal_reference>Journal of Computational Physics 553, 114718 (2026)</arxiv:journal_reference>
      <dc:creator>Kevin Gill, Ionut-Gabriel Farcas, Silke Glas, Benjamin J. Faber</dc:creator>
    </item>
    <item>
      <title>CostNav: A Navigation Benchmark for Real-World Economic-Cost Evaluation of Physical AI Agents</title>
      <link>https://arxiv.org/abs/2511.20216</link>
      <description>arXiv:2511.20216v2 Announce Type: replace-cross 
Abstract: While current navigation benchmarks prioritize task success in simplified settings, they neglect the multidimensional economic constraints essential for the real-world commercialization of autonomous delivery systems. We introduce CostNav, an Economic Navigation Benchmark that evaluates physical AI agents through comprehensive economic cost-revenue analysis aligned with real-world business operations. By integrating industry-standard data - such as SEC filings and AIS injury reports - with Isaac Sim's detailed collision and cargo dynamics, CostNav transcends simple task completion to accurately evaluate business value in complex, real-world scenarios. To our knowledge, CostNav is the first work to quantitatively expose the gap between navigation research metrics and commercial viability, revealing that optimizing for task success on a simplified task fundamentally differs from optimizing for real-world economic deployment. Our evaluation of rule-based Nav2 navigation shows that current approaches are not economically viable: the contribution margin is -22.81/run (AMCL) and -12.87/run (GPS), resulting in no break-even point. We challenge the community to develop navigation policies that achieve economic viability on CostNav. We remain method-agnostic, evaluating success solely on the metric of cost rather than the underlying architecture. All resources are available at https://github.com/worv-ai/CostNav.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.20216v2</guid>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>cs.RO</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haebin Seong, Sungmin Kim, Yongjun Cho, Myunchul Joe, Geunwoo Kim, Yubeen Park, Sunhoo Kim, Yoonshik Kim, Suhwan Choi, Jaeyoon Jung, Jiyong Youn, Jinmyung Kwak, Sunghee Ahn, Jaemin Lee, Younggil Do, Seungyeop Yi, Woojin Cheong, Minhyeok Oh, Minchan Kim, Yoonseok Kang, Seongjae Kang, Samwoo Seong, Youngjae Yu, Yunsung Lee</dc:creator>
    </item>
    <item>
      <title>Calibrated Probabilistic Interpolation for GEDI Biomass</title>
      <link>https://arxiv.org/abs/2601.16834</link>
      <description>arXiv:2601.16834v2 Announce Type: replace-cross 
Abstract: Reliable wall-to-wall biomass mapping from NASA's GEDI mission requires interpolating sparse LiDAR observations across heterogeneous landscapes. While machine learning approaches like Random Forest and XGBoost are standard for this task, they treat spatial predictions of GEDI observations from multispectral or SAR remote sensing data as independent without adapting to the varying difficulty of heterogeneous landscapes. We demonstrate these approaches generally fail to produce calibrated prediction intervals. We identify that this stems from conflating ensemble variance with aleatoric uncertainty and ignoring local spatial context.
  To resolve this, we introduce Attentive Neural Processes (ANPs), a probabilistic meta-learning framework that explicitly conditions predictions on local observation sets and geospatial foundation model embeddings. Unlike static ensembles, ANPs learn a flexible spatial covariance function, allowing uncertainty estimates to expand in complex landscapes and contract in homogeneous areas. We validate this approach across five distinct biomes ranging from Tropical Amazonian forests to Boreal and Alpine ecosystems, demonstrating that ANPs achieve competitive accuracy while maintaining near-ideal uncertainty calibration. We demonstrate the operational utility of the method through few-shot adaptation, where the model recovers most of the performance gap in cross-region transfer using minimal local data. This work provides a scalable, theoretically rigorous alternative to ensemble variance for continental scale earth observation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16834v2</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <category>cs.CV</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Robin Young, Srinivasan Keshav</dc:creator>
    </item>
    <item>
      <title>Investigating the Interplay of Parameterization and Optimizer in Gradient-Free Topology Optimization: A Cantilever Beam Case Study</title>
      <link>https://arxiv.org/abs/2601.22241</link>
      <description>arXiv:2601.22241v2 Announce Type: replace-cross 
Abstract: Gradient-free black-box optimization (BBO) is widely used in engineering design and provides a flexible framework for topology optimization (TO), enabling the discovery of high-performing structural designs without requiring gradient information from simulations. Yet, its success depends on two key choices: the geometric parameterization defining the search space and the optimizer exploring it.
  This study investigates this interplay through a compliance minimization problem for a cantilever beam subject to a connectivity constraint. We benchmark three geometric parameterizations, each combined with three representative BBO algorithms: differential evolution, covariance matrix adaptation evolution strategy, and heteroscedastic evolutionary Bayesian optimization, across 10D, 20D, and 50D design spaces.
  Results reveal that parameterization quality has a stronger influence on optimization performance than optimizer choice: a well-structured parameterization enables robust and competitive performance across algorithms, whereas weaker representations increase optimizer dependency. Overall, this study highlights the dominant role of geometric parameterization in practical BBO-based TO and shows that algorithm performance and selection cannot be fairly assessed without accounting for the induced design space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22241v2</guid>
      <category>cs.NE</category>
      <category>cs.CE</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jelle Westra, Iv\'an Olarte Rodr\'iguez, Niki van Stein, Thomas B\"ack, Elena Raponi</dc:creator>
    </item>
  </channel>
</rss>
