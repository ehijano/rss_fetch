<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 20 Aug 2024 02:33:32 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 19 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Kernelization for Orthogonality Dimension</title>
      <link>https://arxiv.org/abs/2408.08380</link>
      <description>arXiv:2408.08380v1 Announce Type: new 
Abstract: The orthogonality dimension of a graph over $\mathbb{R}$ is the smallest integer $d$ for which one can assign to every vertex a nonzero vector in $\mathbb{R}^d$ such that every two adjacent vertices receive orthogonal vectors. For an integer $d$, the $d$-Ortho-Dim$_\mathbb{R}$ problem asks to decide whether the orthogonality dimension of a given graph over $\mathbb{R}$ is at most $d$. We prove that for every integer $d \geq 3$, the $d$-Ortho-Dim$_\mathbb{R}$ problem parameterized by the vertex cover number $k$ admits a kernel with $O(k^{d-1})$ vertices and bit-size $O(k^{d-1} \cdot \log k)$. We complement this result by a nearly matching lower bound, showing that for any $\varepsilon &gt; 0$, the problem admits no kernel of bit-size $O(k^{d-1-\varepsilon})$ unless $\mathsf{NP} \subseteq \mathsf{coNP/poly}$. We further study the kernelizability of orthogonality dimension problems in additional settings, including over general fields and under various structural parameterizations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08380v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ishay Haviv, Dror Rabinovich</dc:creator>
    </item>
    <item>
      <title>Improved Approximation Algorithms for Index Coding</title>
      <link>https://arxiv.org/abs/2408.08382</link>
      <description>arXiv:2408.08382v1 Announce Type: new 
Abstract: The index coding problem is concerned with broadcasting encoded information to a collection of receivers in a way that enables each receiver to discover its required data based on its side information, which comprises the data required by some of the others. Given the side information map, represented by a graph in the symmetric case and by a digraph otherwise, the goal is to devise a coding scheme of minimum broadcast length.
  We present a general method for developing efficient algorithms for approximating the index coding rate for prescribed families of instances. As applications, we obtain polynomial-time algorithms that approximate the index coding rate of graphs and digraphs on $n$ vertices to within factors of $O(n/\log^2 n)$ and $O(n/\log n)$ respectively. This improves on the approximation factors of $O(n/\log n)$ for graphs and $O(n \cdot \log \log n/\log n)$ for digraphs achieved by Blasiak, Kleinberg, and Lubetzky (IEEE Trans. Inform. Theory, 2013). For the family of quasi-line graphs, we exhibit a polynomial-time algorithm that approximates the index coding rate to within a factor of $2$. This improves on the approximation factor of $O(n^{2/3})$ achieved by Arbabjolfaei and Kim (ISIT, 2016) for graphs on $n$ vertices taken from certain sub-families of quasi-line graphs.
  Our approach is applicable for approximating a variety of additional graph and digraph quantities to within the same approximation factors. Specifically, it captures every graph quantity sandwiched between the independence number and the clique cover number and every digraph quantity sandwiched between the maximum size of an acyclic induced sub-digraph and the directed clique cover number.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08382v1</guid>
      <category>cs.DS</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dror Chawin, Ishay Haviv</dc:creator>
    </item>
    <item>
      <title>Algebraic Vertex Ordering of a Sparse Graph for Adjacency Access Locality and Graph Compression</title>
      <link>https://arxiv.org/abs/2408.08439</link>
      <description>arXiv:2408.08439v1 Announce Type: new 
Abstract: In this work, we establish theoretical and practical connections between vertex indexing for sparse graph/network compression and matrix ordering for sparse matrix-vector multiplication and variable elimination. We present a fundamental analysis of adjacency access locality in vertex ordering from the perspective of graph composition of, or decomposition into, elementary compact graphs. We introduce an algebraic indexing approach that maintains the advantageous features of existing methods, mitigates their shortcomings, and adapts to the degree distribution. The new method demonstrates superior and versatile performance in graph compression across diverse types of graphs. It also renders proportional improvement in the efficiency of matrix-vector multiplications for subspace iterations in response to random walk queries on a large network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08439v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dimitris Floros, Nikos Pitsianis, Xiaobai Sun</dc:creator>
    </item>
    <item>
      <title>Accelerating Spectral Clustering on Quantum and Analog Platforms</title>
      <link>https://arxiv.org/abs/2408.08486</link>
      <description>arXiv:2408.08486v1 Announce Type: new 
Abstract: We introduce a novel hybrid quantum-analog algorithm to perform graph clustering that exploits connections between the evolution of dynamical systems on graphs and the underlying graph spectra. This approach constitutes a new class of algorithms that combine emerging quantum and analog platforms to accelerate computations. Our hybrid algorithm is equivalent to spectral clustering and has a computational complexity of $O(N)$, where $N$ is the number of nodes in the graph, compared to $O(N^3)$ scaling on classical computing platforms. The proposed method employs the dynamic mode decomposition (DMD) framework on data generated by Schr\"{o}dinger dynamics embedded into the manifold generated by the graph Laplacian. We prove and demonstrate that one can extract the eigenvalues and scaled eigenvectors of the normalized graph Laplacian from quantum evolution on the graph by using DMD computations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08486v1</guid>
      <category>cs.DS</category>
      <category>math.DS</category>
      <category>math.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xingzi Xu, Tuhin Sahai</dc:creator>
    </item>
    <item>
      <title>Optimal Sketching for Residual Error Estimation for Matrix and Vector Norms</title>
      <link>https://arxiv.org/abs/2408.08494</link>
      <description>arXiv:2408.08494v1 Announce Type: new 
Abstract: We study the problem of residual error estimation for matrix and vector norms using a linear sketch. Such estimates can be used, for example, to quickly assess how useful a more expensive low-rank approximation computation will be. The matrix case concerns the Frobenius norm and the task is to approximate the $k$-residual $\|A - A_k\|_F$ of the input matrix $A$ within a $(1+\epsilon)$-factor, where $A_k$ is the optimal rank-$k$ approximation. We provide a tight bound of $\Theta(k^2/\epsilon^4)$ on the size of bilinear sketches, which have the form of a matrix product $SAT$. This improves the previous $O(k^2/\epsilon^6)$ upper bound in (Andoni et al. SODA 2013) and gives the first non-trivial lower bound, to the best of our knowledge. In our algorithm, our sketching matrices $S$ and $T$ can both be sparse matrices, allowing for a very fast update time. We demonstrate that this gives a substantial advantage empirically, for roughly the same sketch size and accuracy as in previous work.
  For the vector case, we consider the $\ell_p$-norm for $p&gt;2$, where the task is to approximate the $k$-residual $\|x - x_k\|_p$ up to a constant factor, where $x_k$ is the optimal $k$-sparse approximation to $x$. Such vector norms are frequently studied in the data stream literature and are useful for finding frequent items or so-called heavy hitters. We establish an upper bound of $O(k^{2/p}n^{1-2/p}\operatorname{poly}(\log n))$ for constant $\epsilon$ on the dimension of a linear sketch for this problem. Our algorithm can be extended to the $\ell_p$ sparse recovery problem with the same sketching dimension, which seems to be the first such bound for $p &gt; 2$. We also show an $\Omega(k^{2/p}n^{1-2/p})$ lower bound for the sparse recovery problem, which is tight up to a $\mathrm{poly}(\log n)$ factor.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08494v1</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yi Li, Honghao Lin, David P. Woodruff</dc:creator>
    </item>
    <item>
      <title>More basis reduction for linear codes: backward reduction, BKZ, slide reduction, and more</title>
      <link>https://arxiv.org/abs/2408.08507</link>
      <description>arXiv:2408.08507v1 Announce Type: new 
Abstract: We expand on recent exciting work of Debris-Alazard, Ducas, and van Woerden [Transactions on Information Theory, 2022], which introduced the notion of basis reduction for codes, in analogy with the extremely successful paradigm of basis reduction for lattices. We generalize DDvW's LLL algorithm and size-reduction algorithm from codes over $\mathbb{F}_2$ to codes over $\mathbb{F}_q$, and we further develop the theory of proper bases. We then show how to instantiate for codes the BKZ and slide-reduction algorithms, which are the two most important generalizations of the LLL algorithm for lattices.
  Perhaps most importantly, we show a new and very efficient basis-reduction algorithm for codes, called full backward reduction. This algorithm is quite specific to codes and seems to have no analogue in the lattice setting. We prove that this algorithm finds vectors as short as LLL does in the worst case (i.e., within the Griesmer bound) and does so in less time. We also provide both heuristic and empirical evidence that it outperforms LLL in practice, and we give a variant of the algorithm that provably outperforms LLL (in some sense) for random codes.
  Finally, we explore the promise and limitations of basis reduction for codes. In particular, we show upper and lower bounds on how ``good'' of a basis a code can have, and we show two additional illustrative algorithms that demonstrate some of the promise and the limitations of basis reduction for codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08507v1</guid>
      <category>cs.DS</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Surendra Ghentiyala, Noah Stephens-Davidowitz</dc:creator>
    </item>
    <item>
      <title>A Tight ($3/2 + \varepsilon$)-Approximation Algorithm for Demand Strip Packing</title>
      <link>https://arxiv.org/abs/2408.08627</link>
      <description>arXiv:2408.08627v1 Announce Type: new 
Abstract: We consider the Demand Strip Packing problem (DSP), in which we are given a set of jobs, each specified by a processing time and a demand. The task is to schedule all jobs such that they are finished before some deadline $D$ while minimizing the peak demand, i.e., the maximum total demand of tasks executed at any point in time. DSP is closely related to the Strip Packing problem (SP), in which we are given a set of axis-aligned rectangles that must be packed into a strip of fixed width while minimizing the maximum height. DSP and SP are known to be NP-hard to approximate to within a factor below $\frac{3}{2}$.
  To achieve the essentially best possible approximation guarantee, we prove a structural result. Any instance admits a solution with peak demand at most $\big(\frac32+\varepsilon\big)OPT$ satisfying one of two properties. Either (i) the solution leaves a gap for a job with demand $OPT$ and processing time $\mathcal O(\varepsilon D)$ or (ii) all jobs with demand greater than $\frac{OPT}2$ appear sorted by demand in immediate succession. We then provide two efficient algorithms that find a solution with maximum demand at most $\big(\frac32+\varepsilon\big)OPT$ in the respective case. A central observation, which sets our approach apart from previous ones for DSP, is that the properties (i) and (ii) need not be efficiently decidable: We can simply run both algorithms and use whichever solution is the better one.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08627v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Franziska Eberle, Felix Hommelsheim, Malin Rau, Stefan Walzer</dc:creator>
    </item>
    <item>
      <title>Online Matching with Delays and Size-based Costs</title>
      <link>https://arxiv.org/abs/2408.08658</link>
      <description>arXiv:2408.08658v1 Announce Type: new 
Abstract: In this paper, we introduce the problem of Online Matching with Delays and Size-based Costs (OMDSC). The OMDSC problem involves $m$ requests arriving online. At any time, a group can be formed by matching any number of these requests that have been received but are still unmatched. The cost associated with each group is determined by the waiting time for each request within the group and a size-dependent cost. Our goal is to partition all incoming requests into multiple groups while minimizing the total associated cost. The problem extends the TCP acknowledgment problem proposed by Dooly et al. (JACM 2001). It generalizes the cost model for sending acknowledgments. This paper reveals the competitive ratios for a fundamental case where the range of the penalty function is limited to $0$ and $1$. We classify such penalty functions into three distinct cases: (i) a fixed penalty of $1$ regardless of group size, (ii) a penalty of $0$ if and only if the group size is a multiple of a specific integer $k$, and (iii) other situations. The problem of case (i) is equivalent to the TCP acknowledgment problem, for which Dooly et al. proposed a $2$-competitive algorithm. For case (ii), we first show that natural algorithms that match all the remaining requests are $\Omega(\sqrt{k})$-competitive. We then propose an $O(\log k / \log \log k)$-competitive deterministic algorithm by carefully managing match size and timing, and we also prove its optimality. For case (iii), we demonstrate the non-existence of a competitive online algorithm. Additionally, we discuss competitive ratios for other typical penalty functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08658v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yasushi Kawase, Tomohiro Nakayoshi</dc:creator>
    </item>
    <item>
      <title>A Novel Quantum Algorithm for Efficient Attractor Search in Gene Regulatory Networks</title>
      <link>https://arxiv.org/abs/2408.08814</link>
      <description>arXiv:2408.08814v1 Announce Type: cross 
Abstract: The description of gene interactions that constantly occur in the cellular environment is an extremely challenging task due to an immense number of degrees of freedom and incomplete knowledge about microscopic details. Hence, a coarse-grained and rather powerful modeling of such dynamics is provided by Boolean Networks (BNs). BNs are dynamical systems composed of Boolean agents and a record of their possible interactions over time. Stable states in these systems are called attractors which are closely related to the cellular expression of biological phenotypes. Identifying the full set of attractors is, therefore, of substantial biological interest. However, for conventional high-performance computing, this problem is plagued by an exponential growth of the dynamic state space. Here, we demonstrate a novel quantum search algorithm inspired by Grover's algorithm to be implemented on quantum computing platforms. The algorithm performs an iterative suppression of states belonging to basins of previously discovered attractors from a uniform superposition, thus increasing the amplitudes of states in basins of yet unknown attractors. This approach guarantees that a new attractor state is measured with each iteration of the algorithm, an optimization not currently achieved by any other algorithm in the literature. Tests of its resistance to noise have also shown promising performance on devices from the current Noise Intermediate Scale Quantum Computing (NISQ) era.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08814v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>q-bio.MN</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mirko Rossini, Felix M. Weidner, Joachim Ankerhold, Hans A. Kestler</dc:creator>
    </item>
    <item>
      <title>Entropy Coding of Unordered Data Structures</title>
      <link>https://arxiv.org/abs/2408.08837</link>
      <description>arXiv:2408.08837v1 Announce Type: cross 
Abstract: We present shuffle coding, a general method for optimal compression of sequences of unordered objects using bits-back coding. Data structures that can be compressed using shuffle coding include multisets, graphs, hypergraphs, and others. We release an implementation that can easily be adapted to different data types and statistical models, and demonstrate that our implementation achieves state-of-the-art compression rates on a range of graph datasets including molecular data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08837v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julius Kunze, Daniel Severo, Giulio Zani, Jan-Willem van de Meent, James Townsend</dc:creator>
    </item>
    <item>
      <title>On modeling NP-Complete problems as polynomial-sized linear programs: Escaping/Side-stepping the "barriers"</title>
      <link>https://arxiv.org/abs/2304.07716</link>
      <description>arXiv:2304.07716v5 Announce Type: replace-cross 
Abstract: In view of the extended formulations (EFs) developments (e.g. "Fiorini, S., S. Massar, S. Pokutta, H.R. Tiwary, and R. de Wolf [2015]. Exponential Lower Bounds for Polytopes in Combinatorial Optimization. Journal of the ACM 62:2"), we focus in this paper on the question of whether it is possible to model an NP-Complete problem as a polynomial-sized linear program. For the sake of simplicity of exposition, the discussions are focused on the TSP. We show that a finding that there exists no polynomial-sized extended formulation of "the TSP polytope" does not (necessarily) imply that it is "impossible" for a polynomial-sized linear program to solve the TSP optimization problem. We show that under appropriate conditions the TSP optimization problem can be solved without recourse to the traditional city-to-city ("travel leg") variables, thereby side-stepping/"escaping from" "the TSP polytope" and hence, the barriers. Some illustrative examples are discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.07716v5</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Moustapha Diaby, Mark Karwan, Lei Sun</dc:creator>
    </item>
  </channel>
</rss>
