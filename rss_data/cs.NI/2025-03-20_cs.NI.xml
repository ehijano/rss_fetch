<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 21 Mar 2025 04:00:16 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Towards Agentic AI Networking in 6G: A Generative Foundation Model-as-Agent Approach</title>
      <link>https://arxiv.org/abs/2503.15764</link>
      <description>arXiv:2503.15764v1 Announce Type: new 
Abstract: The promising potential of AI and network convergence in improving networking performance and enabling new service capabilities has recently attracted significant interest. Existing network AI solutions, while powerful, are mainly built based on the close-loop and passive learning framework, resulting in major limitations in autonomous solution finding and dynamic environmental adaptation. Agentic AI has recently been introduced as a promising solution to address the above limitations and pave the way for true generally intelligent and beneficial AI systems. The key idea is to create a networking ecosystem to support a diverse range of autonomous and embodied AI agents in fulfilling their goals. In this paper, we focus on the novel challenges and requirements of agentic AI networking. We propose AgentNet, a novel framework for supporting interaction, collaborative learning, and knowledge transfer among AI agents. We introduce a general architectural framework of AgentNet and then propose a generative foundation model (GFM)-based implementation in which multiple GFM-as-agents have been created as an interactive knowledge-base to bootstrap the development of embodied AI agents according to different task requirements and environmental features. We consider two application scenarios, digital-twin-based industrial automation and metaverse-based infotainment system, to describe how to apply AgentNet for supporting efficient task-driven collaboration and interaction among AI agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15764v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yong Xiao, Guangming Shi, Ping Zhang</dc:creator>
    </item>
    <item>
      <title>Energy-Efficient Federated Learning and Migration in Digital Twin Edge Networks</title>
      <link>https://arxiv.org/abs/2503.15822</link>
      <description>arXiv:2503.15822v1 Announce Type: new 
Abstract: The digital twin edge network (DITEN) is a significant paradigm in the sixth-generation wireless system (6G) that aims to organize well-developed infrastructures to meet the requirements of evolving application scenarios. However, the impact of the interaction between the long-term DITEN maintenance and detailed digital twin tasks, which often entail privacy considerations, is commonly overlooked in current research. This paper addresses this issue by introducing a problem of digital twin association and historical data allocation for a federated learning (FL) task within DITEN. To achieve this goal, we start by introducing a closed-form function to predict the training accuracy of the FL task, referring to it as the data utility. Subsequently, we carry out comprehensive convergence analyses on the proposed FL methodology. Our objective is to jointly optimize the data utility of the digital twin-empowered FL task and the energy costs incurred by the long-term DITEN maintenance, encompassing FL model training, data synchronization, and twin migration. To tackle the aforementioned challenge, we present an optimization-driven learning algorithm that effectively identifies optimized solutions for the formulated problem. Numerical results demonstrate that our proposed algorithm outperforms various baseline approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15822v1</guid>
      <category>cs.NI</category>
      <category>cs.LG</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuzhi Zhou, Yaru Fu, Zheng Shi, Howard H. Yang, Kevin Hung, Yan Zhang</dc:creator>
    </item>
    <item>
      <title>PromptMobile: Efficient Promptus for Low Bandwidth Mobile Video Streaming</title>
      <link>https://arxiv.org/abs/2503.16112</link>
      <description>arXiv:2503.16112v1 Announce Type: new 
Abstract: Traditional video compression algorithms exhibit significant quality degradation at extremely low bitrates. Promptus emerges as a new paradigm for video streaming, substantially cutting down the bandwidth essential for video streaming. However, Promptus is computationally intensive and can not run in real-time on mobile devices. This paper presents PromptMobile, an efficient acceleration framework tailored for on-device Promptus. Specifically, we propose (1) a two-stage efficient generation framework to reduce computational cost by 8.1x, (2) a fine-grained inter-frame caching to reduce redundant computations by 16.6\%, (3) system-level optimizations to further enhance efficiency. The evaluations demonstrate that compared with the original Promptus, PromptMobile achieves a 13.6x increase in image generation speed. Compared with other streaming methods, PromptMobile achives an average LPIPS improvement of 0.016 (compared with H.265), reducing 60\% of severely distorted frames (compared to VQGAN).</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16112v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.MM</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liming Liu, Jiangkai Wu, Haoyang Wang, Peiheng Wang, Xinggong Zhang, Zongming Guo</dc:creator>
    </item>
    <item>
      <title>Distributed Split Computing Using Diffusive Metrics for UAV Swarms</title>
      <link>https://arxiv.org/abs/2503.16146</link>
      <description>arXiv:2503.16146v1 Announce Type: new 
Abstract: In large-scale UAV swarms, dynamically executing machine learning tasks can pose significant challenges due to network volatility and the heterogeneous resource constraints of each UAV. Traditional approaches often rely on centralized orchestration to partition tasks among nodes. However, these methods struggle with communication bottlenecks, latency, and reliability when the swarm grows or the topology shifts rapidly. To overcome these limitations, we propose a fully distributed, diffusive metric-based approach for split computing in UAV swarms. Our solution introduces a new iterative measure, termed the aggregated gigaflops, capturing each node's own computing capacity along with that of its neighbors without requiring global network knowledge. By forwarding partial inferences intelligently to underutilized nodes, we achieve improved task throughput, lower latency, and enhanced energy efficiency. Further, to handle sudden workload surges and rapidly changing node conditions, we incorporate an early-exit mechanism that can adapt the inference pathway on-the-fly. Extensive simulations demonstrate that our approach significantly outperforms baseline strategies across multiple performance indices, including latency, fairness, and energy consumption. These results highlight the feasibility of large-scale distributed intelligence in UAV swarms and provide a blueprint for deploying robust, scalable ML services in diverse aerial networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16146v1</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Talip Tolga Sar{\i}, G\"okhan Se\c{c}inti, Angelo Trotta</dc:creator>
    </item>
    <item>
      <title>Omnichain Web: The Universal Framework for Streamlined Chain Abstraction and Cross-Layer Interaction</title>
      <link>https://arxiv.org/abs/2411.10132</link>
      <description>arXiv:2411.10132v2 Announce Type: cross 
Abstract: The Web3 ecosystem is highly fragmented, making seamless integration difficult for over a billion Web2 businesses, enterprises, and AI protocols. As blockchains, rollups, and app-specific chains expand, cross-chain interactions remain inefficient, and liquidity is deeply fragmented. AI systems lack standardized blockchain access, limiting autonomous functionality. Intent-based interactions, crucial for AI-driven automation, face scalability issues due to the absence of robust execution platforms. Meanwhile, the current solver ecosystem is centralized, as liquidity rebalancing remains a challenge due to a lack of developer-friendly tools. Dojima's Omnichain Web introduces a universal framework that abstracts blockchain complexity, bridging Web2, Web3, and AI. At its core, OmniRollups facilitate scalable execution across chains, while the Omni Sequencer ensures atomic, secure intent processing. Linera microchains enable AI-driven transaction automation, seamlessly integrating with Web3 data streams. Ragno Network decentralizes L1 infrastructure, optimizing cross-chain liquidity flows, while the Proof Network enhances cryptographic security for omnichain transactions. Finally, the Builder Marketplace introduces a solver-driven execution layer, allowing developers to build and monetize intent-based applications without liquidity constraints. By fostering a composable marketplace at the intersection of Web2 and Web3, Omnichain Web enables the seamless flow of data, value, and computation. This framework mirrors the internet, bridging Web3 decentralization with Web2 scale to drive the next wave of adoption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10132v2</guid>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Hardik Gajera, Akhil Reddy, Bhagath Reddy</dc:creator>
    </item>
    <item>
      <title>Enhancing Physical Layer Security in Cognitive Radio-Enabled NTNs with Beyond Diagonal RIS</title>
      <link>https://arxiv.org/abs/2503.15787</link>
      <description>arXiv:2503.15787v1 Announce Type: cross 
Abstract: Beyond diagonal reconfigurable intelligent surfaces (BD-RIS) have emerged as a transformative technology for enhancing wireless communication by intelligently manipulating the propagation environment. This paper explores the potential of BD-RIS in improving cognitive radio enabled multilayer non-terrestrial networks (NTNs). It is assumed that a high-altitude platform station (HAPS) has set up the primary network, while an uncrewed aerial vehicle (UAV) establishes the secondary network in the HAPS footprint. We formulate a joint optimization problem to maximize the secrecy rate by optimizing BD-RIS phase shifts and the secondary transmitter power allocation while controlling the interference temperature from the secondary network to the primary network. To solve this problem efficiently, we decouple the original problem into two sub-problems, which are solved iteratively by relying on alternating optimization. Simulation results demonstrate the effectiveness of BD-RIS in cognitive radio-enabled multilayer NTNs to accommodate the secondary network while satisfying the constraints imposed from the primary network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15787v1</guid>
      <category>eess.SP</category>
      <category>cs.ET</category>
      <category>cs.NI</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wali Ullah Khan, Chandan Kumar Sheemar, Eva Lagunas, Symeon Chatzinotas</dc:creator>
    </item>
    <item>
      <title>Integrating Atmospheric Sensing and Communications for Resource Allocation in NTNs</title>
      <link>https://arxiv.org/abs/2407.06705</link>
      <description>arXiv:2407.06705v2 Announce Type: replace 
Abstract: The integration of Non-Terrestrial Networks (NTNs) with Low Earth Orbit (LEO) satellite constellations into 5G and Beyond is essential to achieve truly global connectivity. A distinctive characteristic of LEO mega constellations is that they constitute a global infrastructure with predictable dynamics, which enables the pre-planned allocation of radio resources. However, the different bands that can be used for ground-to-satellite communication are affected differently by atmospheric conditions such as precipitation, which introduces uncertainty on the attenuation of the communication links at high frequencies. Based on this, we present a compelling case for applying integrated sensing and communications (ISAC) in heterogeneous and multi-layer LEO satellite constellations over wide areas. Specifically, we propose a sensing-assisted communications framework and frame structure that not only enables the accurate estimation of the atmospheric attenuation in the communication links through sensing but also leverages this information to determine the optimal serving satellites and allocate resources efficiently for downlink communication with users on the ground. The results show that, by dedicating an adequate amount of resources for sensing and solving the association and resource allocation problems jointly, it is feasible to increase the average throughput by 59% and the fairness by 700% when compared to solving these problems separately.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06705v2</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Israel Leyva-Mayorga, Fabio Saggese, Lintao Li, Petar Popovski</dc:creator>
    </item>
    <item>
      <title>Mobile Edge Intelligence for Large Language Models: A Contemporary Survey</title>
      <link>https://arxiv.org/abs/2407.18921</link>
      <description>arXiv:2407.18921v2 Announce Type: replace 
Abstract: On-device large language models (LLMs), referring to running LLMs on edge devices, have raised considerable interest since they are more cost-effective, latency-efficient, and privacy-preserving compared with the cloud paradigm. Nonetheless, the performance of on-device LLMs is intrinsically constrained by resource limitations on edge devices. Sitting between cloud and on-device AI, mobile edge intelligence (MEI) presents a viable solution by provisioning AI capabilities at the edge of mobile networks, enabling end users to offload heavy AI computation to capable edge servers nearby. This article provides a contemporary survey on harnessing MEI for LLMs. We begin by illustrating several killer applications to demonstrate the urgent need for deploying LLMs at the network edge. Next, we present the preliminaries of LLMs and MEI, followed by resource-efficient LLM techniques. We then present an architectural overview of MEI for LLMs (MEI4LLM), outlining its core components and how it supports the deployment of LLMs. Subsequently, we delve into various aspects of MEI4LLM, extensively covering edge LLM caching and delivery, edge LLM training, and edge LLM inference. Finally, we identify future research opportunities. We hope this article inspires researchers in the field to leverage mobile edge computing to facilitate LLM deployment, thereby unleashing the potential of LLMs across various privacy- and delay-sensitive applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18921v2</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guanqiao Qu, Qiyuan Chen, Wei Wei, Zheng Lin, Xianhao Chen, Kaibin Huang</dc:creator>
    </item>
    <item>
      <title>LumosCore: Highly Scalable LLM Clusters with Optical Interconnect</title>
      <link>https://arxiv.org/abs/2411.01503</link>
      <description>arXiv:2411.01503v2 Announce Type: replace 
Abstract: We propose \emph{LumosCore} to build high-bandwidth and large-scale data center networks for LLM jobs. By replacing the core-layer electrical packet switches by optical circuit switches, \emph{LumosCore} could achieves $2\times$ increase in bandwidth or $8\times$ increase in network size. We offer the detailed design of \emph{LumosCore} at both deployment stage and running stage. At deployment stage, we propose Interleaved Wiring, which is compatible with all possible logical topologies. At running stage, we design polynomial-time algorithms for GPU placement, logical topology generating and OCS reconfiguration to minimize network contention and reduce impact to scheduled jobs. We evaluate \emph{LumosCore} using both testbed experiments and large-scale simulation. Compared to traditional hybrid optical/electrical architectures, \emph{LumosCore} increases the end-to-end training throughput by up to 39.5\% on a 128-node testbed. Compared to the state-of-art Clos architectures, \emph{LumosCore} reduces the average job completion time by up to 34.1\% in a 16k simulation platform.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01503v2</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinchi Han, Yongxi Lv, Shizhen Zhao, Zhuotao Liu, Ximeng Liu, Xinbing Wang</dc:creator>
    </item>
    <item>
      <title>Privacy-preserving Blockchain-enabled Parametric Insurance via Remote Sensing and IoT</title>
      <link>https://arxiv.org/abs/2305.08384</link>
      <description>arXiv:2305.08384v2 Announce Type: replace-cross 
Abstract: Traditional Insurance, a popular approach of financial risk management, has suffered from the issues of high operational costs, opaqueness, inefficiency and a lack of trust. Recently, blockchain-enabled "parametric insurance" through authorized data sources (e.g., remote sensing and IoT) aims to overcome these issues by automating the underwriting and claim processes of insurance policies on a blockchain. However, the openness of blockchain platforms raises a concern of user privacy, as the private user data in insurance claims on a blockchain may be exposed to outsiders. In this paper, we propose a privacy-preserving parametric insurance framework based on succinct zero-knowledge proofs (zk-SNARKs), whereby an insuree submits a zero-knowledge proof (without revealing any private data) for the validity of an insurance claim and the authenticity of its data sources to a blockchain for transparent verification. Moreover, we extend the recent zk-SNARKs to support robust privacy protection for multiple heterogeneous data sources and improve its efficiency to cut the incurred gas cost by 80%. As a proof-of-concept, we implemented a working prototype of bushfire parametric insurance on real-world blockchain platform Ethereum, and present extensive empirical evaluations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.08384v2</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mingyu Hao, Keyang Qian, Sid Chi-Kin Chau</dc:creator>
    </item>
  </channel>
</rss>
