<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DL</link>
    <description>cs.DL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 10 Dec 2024 03:50:58 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>The Impact of Artificial Intelligence on Art Research: An Analysis of Academic Productivity and Multidisciplinary Integration</title>
      <link>https://arxiv.org/abs/2412.04850</link>
      <description>arXiv:2412.04850v1 Announce Type: new 
Abstract: This study investigates the transformative impact of artificial intelligence on art research by analysing data from 749 art research projects and 555,982 non art research projects, as well as 23,999 journal articles. We utilized the SciBERT model for text analysis on research funding proposals and the econometric model to evaluate AI impact on the academic productivity and impact. Our findings reveal that AI has significantly reshaped the role of art across various disciplines. The integration of AI has led to a notable expansion in keyword networks, highlighting advancements in visual art creation, data driven methodologies, and interactive educational tools. AI has also facilitated the integration of art knowledge into nearly all research disciplines, contrasting with the traditionally confined distribution of art knowledge. Despite the substantial increase in publication impact and citation counts facilitated by AI, it has not markedly improved the likelihood of publishing in high-prestige journals. These insights illustrate the complex nature of AI's impact enhancing research impact while presenting challenges in publication efficiency and multidisciplinary integration. The study offers a nuanced understanding of AI's role in art research and suggests directions for addressing the ongoing challenges of integrating art and AI across disciplines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.04850v1</guid>
      <category>cs.DL</category>
      <pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yang Ding</dc:creator>
    </item>
    <item>
      <title>ORKG ASK: a Neuro-symbolic Scholarly Search and Exploration System</title>
      <link>https://arxiv.org/abs/2412.04977</link>
      <description>arXiv:2412.04977v1 Announce Type: new 
Abstract: Purpose: Finding scholarly articles is a time-consuming and cumbersome activity, yet crucial for conducting science. Due to the growing number of scholarly articles, new scholarly search systems are needed to effectively assist researchers in finding relevant literature.
  Methodology: We take a neuro-symbolic approach to scholarly search and exploration by leveraging state-of-the-art components, including semantic search, Large Language Models (LLMs), and Knowledge Graphs (KGs). The semantic search component composes a set of relevant articles. From this set of articles, information is extracted and presented to the user.
  Findings: The presented system, called ORKG ASK (Assistant for Scientific Knowledge), provides a production-ready search and exploration system. Our preliminary evaluation indicates that our proposed approach is indeed suitable for the task of scholarly information retrieval.
  Value: With ORKG ASK, we present a next-generation scholarly search and exploration system and make it available online. Additionally, the system components are open source with a permissive license.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.04977v1</guid>
      <category>cs.DL</category>
      <pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Allard Oelen, Mohamad Yaser Jaradeh, S\"oren Auer</dc:creator>
    </item>
    <item>
      <title>How permanent are metadata for research data? Understanding changes in DataCite DOI metadata</title>
      <link>https://arxiv.org/abs/2412.05128</link>
      <description>arXiv:2412.05128v1 Announce Type: new 
Abstract: With the move towards open research information, the DOI registration agency DataCite is increasingly used as a source for metadata describing research data, for example to perform scientometric analyses. However, there is a lack of research on how DOI metadata describing research data are created and maintained. This paper adresses this gap by using DataCite metadata provenance information to analyze the overall prevalence and patterns of change to DataCite DOI metadata records. The results show that change of DataCite DOI metadata records is common, but it tends to be incremental and not extensive. DataCite DOI metadata records offer reliable descriptions of datasets and are stable enough to be used in scientometric research. The findings mirror insights from previous studies of metadata change in other contexts, suggesting that there are similarities in metadata practices between research data repositories and more traditional cataloging environments. However, the observed changes don't seem to fully align with idealized conceptualizations of metadata creation and maintenance for research data. In particular, the data does not show that metadata records are maintained continuously, and metadata change has a limited effect on metadata completeness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05128v1</guid>
      <category>cs.DL</category>
      <pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dorothea Strecker</dc:creator>
    </item>
    <item>
      <title>Journal Quality Factors from ChatGPT: More meaningful than Impact Factors?</title>
      <link>https://arxiv.org/abs/2411.09984</link>
      <description>arXiv:2411.09984v2 Announce Type: replace 
Abstract: Purpose: Journal Impact Factors and other citation-based indicators are widely used and abused to help select journals to publish in or to estimate the value of a published article. Nevertheless, citation rates primarily reflect scholarly impact rather than other quality dimensions, including societal impact, originality, and rigour. In contrast, Journal Quality Factors (JQFs) are average quality score estimates given to a journal's articles by ChatGPT. Design: JQFs were compared with Polish, Norwegian and Finnish journal ranks and with journal citation rates for 1,300 journals with 130,000 articles from 2021 in large monodisciplinary journals in the 25 out of 27 Scopus broad fields of research for which it was possible. Outliers were also examined. Findings: JQFs correlated positively and mostly strongly (median correlation: 0.641) with journal ranks in 24 out of the 25 broad fields examined, indicating a nearly science-wide ability for ChatGPT to estimate journal quality. Journal citation rates had similarly high correlations with national journal ranks, however, so JQFs are not a universally better indicator. An examination of journals with JQFs not matching their journal ranks suggested that abstract styles may affect the result, such as whether the societal contexts of research are mentioned. Limitations: Different journal rankings may have given different findings because there is no agreed meaning for journal quality. Implications: The results suggest that JQFs are plausible as journal quality indicators in all fields and may be useful for the (few) research and evaluation contexts where journal quality is an acceptable proxy for article quality, and especially for fields like mathematics for which citations are not strong indicators of quality. Originality: This is the first attempt to estimate academic journal value with a Large Language Model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.09984v2</guid>
      <category>cs.DL</category>
      <pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mike Thelwall, Kayvan Kousha</dc:creator>
    </item>
  </channel>
</rss>
