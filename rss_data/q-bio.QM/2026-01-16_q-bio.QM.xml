<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.QM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.QM</link>
    <description>q-bio.QM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.QM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 16 Jan 2026 05:00:29 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Robust and Generalizable Atrial Fibrillation Detection from ECG Using Time-Frequency Fusion and Supervised Contrastive Learning</title>
      <link>https://arxiv.org/abs/2601.10202</link>
      <description>arXiv:2601.10202v1 Announce Type: new 
Abstract: Atrial fibrillation (AF) is a common cardiac arrhythmia that significantly increases the risk of stroke and heart failure, necessitating reliable and generalizable detection methods from electrocardiogram (ECG) recordings. Although deep learning has advanced automated AF diagnosis, existing approaches often struggle to exploit complementary time-frequency information effectively, limiting both robustness under intra-dataset and generalization across diverse clinical datasets. To address these challenges, we propose a cross-modal deep learning framework comprising two key components: a Bidirectional Gating Module (BGM) and a Cross-modal Supervised Contrastive Learning (CSCL) strategy. The BGM facilitates dynamic, reciprocal refinement between time and frequency domain features, enhancing model robustness to signal variations within a dataset. Meanwhile, CSCL explicitly structures the joint embedding space by pulling together label-consistent samples and pushing apart different ones, thereby improving inter-class separability and enabling strong cross-dataset generalization. We evaluate our method through five-fold cross-validation on the AFDB and the CPSC2021 dataset, as well as bidirectional cross-dataset experiments (training on one and testing on the other). Results show consistent improvements over state-of-the-art methods across multiple metrics, demonstrating that our approach achieves both high intra-dataset robustness and excellent cross-dataset generalization. We further demonstrate that our method achieves high computational efficiency and anti-interference capability, making it suitable for edge deployment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10202v1</guid>
      <category>q-bio.QM</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hongtao Li, Jia Wei, Jia Xiao, Yuanjun Lai, Mingyang Liu, Shuzhen Lv, Xueqiang Ouyang</dc:creator>
    </item>
    <item>
      <title>A Predictive Model for Synergistic Oncolytic Virotherapy: Unveiling the Ping-Pong Mechanism and Optimal Timing of Combined Vesicular Stomatitis and Vaccinia Viruses</title>
      <link>https://arxiv.org/abs/2601.10405</link>
      <description>arXiv:2601.10405v1 Announce Type: new 
Abstract: We present a mathematical model that describes the synergistic mechanism of combined Vesicular Stomatitis Virus (VSV) and Vaccinia Virus (VV). The model captures the dynamic interplay between tumor cells, viral replication, and the interferon-mediated immune response, revealing a `ping-pong' synergy where VV-infected cells produce B18R protein that neutralizes interferon-$\alpha$, thereby enhancing VSV replication within the tumor. Numerical simulations demonstrate that this combination achieves complete tumor clearance in approximately 50 days, representing an 11\% acceleration compared to VV monotherapy (56 days), while VSV alone fails to eradicate tumors. Through bifurcation analysis, we identify critical thresholds for viral burst size and B18R inhibition, while sensitivity analysis highlights infection rates and burst sizes as the most influential parameters for treatment efficacy. Temporal optimization reveals that therapeutic outcomes are maximized through immediate VSV administration followed by delayed VV injection within a 1-19 day window, offering a strategic approach to overcome the timing and dosing challenges inherent in OVT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10405v1</guid>
      <category>q-bio.QM</category>
      <category>math.DS</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joseph Malinzi, Amina Eladdadi, Rachid Ouifki, Raluca Eftimie, Anotida Madzvamuse, Helen M. Byrne</dc:creator>
    </item>
    <item>
      <title>Comparative Evaluation of Deep Learning-Based and WHO-Informed Approaches for Sperm Morphology Assessment</title>
      <link>https://arxiv.org/abs/2601.10070</link>
      <description>arXiv:2601.10070v1 Announce Type: cross 
Abstract: Assessment of sperm morphological quality remains a critical yet subjective component of male fertility evaluation, often limited by inter-observer variability and resource constraints. This study presents a comparative biomedical artificial intelligence framework evaluating an image-based deep learning model (HuSHeM) alongside a clinically grounded baseline derived from World Health Organization criteria augmented with the Systemic Inflammation Response Index (WHO(+SIRI)).
  The HuSHeM model was trained on high-resolution sperm morphology images and evaluated using an independent clinical cohort. Model performance was assessed using discrimination, calibration, and clinical utility analyses. The HuSHeM model demonstrated higher discriminative performance, as reflected by an increased area under the receiver operating characteristic curve with relatively narrow confidence intervals compared to WHO(+SIRI). Precision-recall analysis further indicated improved performance under class imbalance, with higher precision-recall area values across evaluated thresholds. Calibration analysis indicated closer agreement between predicted probabilities and observed outcomes for HuSHeM, while decision curve analysis suggested greater net clinical benefit across clinically relevant threshold probabilities.
  These findings suggest that image-based deep learning may offer improved predictive reliability and clinical utility compared with traditional rule-based and inflammation-augmented criteria. The proposed framework supports objective and reproducible assessment of sperm morphology and may serve as a decision-support tool within fertility screening and referral workflows. The proposed models are intended as decision-support or referral tools and are not designed to replace clinical judgment or laboratory assessment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10070v1</guid>
      <category>cs.LG</category>
      <category>cs.CV</category>
      <category>eess.IV</category>
      <category>q-bio.QM</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammad Abbadi</dc:creator>
    </item>
    <item>
      <title>Cell Behavior Video Classification Challenge, a benchmark for computer vision methods in time-lapse microscopy</title>
      <link>https://arxiv.org/abs/2601.10250</link>
      <description>arXiv:2601.10250v1 Announce Type: cross 
Abstract: The classification of microscopy videos capturing complex cellular behaviors is crucial for understanding and quantifying the dynamics of biological processes over time. However, it remains a frontier in computer vision, requiring approaches that effectively model the shape and motion of objects without rigid boundaries, extract hierarchical spatiotemporal features from entire image sequences rather than static frames, and account for multiple objects within the field of view.
  To this end, we organized the Cell Behavior Video Classification Challenge (CBVCC), benchmarking 35 methods based on three approaches: classification of tracking-derived features, end-to-end deep learning architectures to directly learn spatiotemporal features from the entire video sequence without explicit cell tracking, or ensembling tracking-derived with image-derived features.
  We discuss the results achieved by the participants and compare the potential and limitations of each approach, serving as a basis to foster the development of computer vision methods for studying cellular dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10250v1</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>q-bio.QM</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Raffaella Fiamma Cabini, Deborah Barkauskas, Guangyu Chen, Zhi-Qi Cheng, David E Cicchetti, Judith Drazba, Rodrigo Fernandez-Gonzalez, Raymond Hawkins, Yujia Hu, Jyoti Kini, Charles LeWarne, Xufeng Lin, Sai Preethi Nakkina, John W Peterson, Koert Schreurs, Ayushi Singh, Kumaran Bala Kandan Viswanathan, Inge MN Wortel, Sanjian Zhang, Rolf Krause, Santiago Fernandez Gonzalez, Diego Ulisse Pizzagalli</dc:creator>
    </item>
    <item>
      <title>Global dynamical structures from infinitesimal data</title>
      <link>https://arxiv.org/abs/2410.02111</link>
      <description>arXiv:2410.02111v2 Announce Type: replace 
Abstract: Scientists and engineers alike target modeling of complex, high dimensional, and nonlinear dynamical systems as a central goal. Machine learning breakthroughs alongside mounting computation and data advance the efficacy of learning from trajectory measurements. However scientifically interpreting data-driven models, e.g., localizing attracting sets and their basins, remains elusive. Such limitations particularly afflict identification of system-level regulatory mechanisms characteristic of living systems, e.g., stabilizing control for whole-body locomotion, where discontinuous, transient, and multiscale phenomena are common and prior models are rare. As a next step towards theory-grounded discovery of behavioral mechanisms in biology and beyond, we introduce VERT, a framework for discovering attracting sets from trajectories without recourse to any global model. Our infinitesimal-local-global (ILG) pipeline estimates the proximity of any sampled state to an attracting set, if one exists, with formal accuracy guarantees. We demonstrate our approach on phenomenological and physical oscillators with hierarchical and impulsive dynamics, finding sensitivity to both global and intermediate attractors composed in sequence and parallel. Application of VERT to human running kinematics data reveals insight into control modules that stabilize task-level dynamics, supporting a longstanding neuromechanical control hypothesis. The VERT framework promotes rigorous inference of underlying dynamical structure even for systems where learning a global dynamics model is impractical or impossible.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02111v2</guid>
      <category>q-bio.QM</category>
      <category>math.DS</category>
      <category>nlin.CD</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Benjamin McInroe, Robert J. Full, Daniel E. Koditschek, Yuliy Baryshnikov</dc:creator>
    </item>
    <item>
      <title>High-fidelity robotic PCR amplification</title>
      <link>https://arxiv.org/abs/2512.23877</link>
      <description>arXiv:2512.23877v2 Announce Type: replace 
Abstract: Polymerase chain reaction (PCR) underpins modern molecular biology, yet its deployment in emerging domains such as DNA data storage and distributed diagnostics remains constrained by bulky thermocyclers, complex thermal hardware, and contamination-prone workflows. Here, we present an autonomous robotic PCR platform that redefines thermocycling as a motion-controlled process rather than a temperature-controlled device. The system employs a programmable robotic liquid handler to execute PCR entirely within sealed pipette tips, repeatedly immersing and withdrawing reaction volumes in a single temperature-stabilized oil bath to realize denaturation, annealing, and extension steps through precise spatiotemporal control. This architecture eliminates conventional thermocyclers and enables fully enclosed reactions with complete sample recovery. We demonstrate that the robotic system achieves amplification efficiency and sequencing fidelity comparable to high-performance commercial thermocyclers when applied to DNA-encoded datasets. Beyond performance parity, the platform minimizes reagent consumption, suppresses cross-contamination through physical isolation, and supports parallelization through robotic scheduling rather than hardware duplication. By abstracting PCR thermocycling into a robotically orchestrated manipulation task, this work establishes a generalizable framework for automated biochemical processing and positions robotic control as a central design axis for scalable, low-cost molecular workflows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23877v2</guid>
      <category>q-bio.QM</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Vincent Beguin, Jean Gr\'etillat, Kornelija Kaminskait\.e, Simonas Juzenas, Dainius Kirsnauskas, Pierre-Yves Burgi, Samuel Wenger, Valentin Remonnay, Silvia Angeloni, Bart van der Schoot, Augustin Cerveaux, Thomas Heinis, Renaldas Raisutis, Martin Jost, Lukas Zemaitis, Ignas Galminas, J\'er\^ome Charmet</dc:creator>
    </item>
    <item>
      <title>Markovian Promoter Models: A Mechanistic Alternative to Hill Functions in Gene Regulatory Networks</title>
      <link>https://arxiv.org/abs/2512.18442</link>
      <description>arXiv:2512.18442v4 Announce Type: replace-cross 
Abstract: Gene regulatory networks are typically modeled using ordinary differential equations (ODEs) with phenomenological Hill functions to represent transcriptional regulation. While computationally efficient, Hill functions lack mechanistic grounding and cannot capture stochastic promoter dynamics. We present a hybrid Markovian-ODE framework that explicitly models discrete promoter states while maintaining computational tractability. Uniquely, we parameterize this model using fractional dwell times derived from ChEC-seq data, enabling the inference of in vivo kinetic rates from steady-state chromatin profiling. Our approach tracks individual transcription factor binding events as a continuous-time Markov chain, linked to deterministic molecular dynamics. We validate this framework on seven gene regulatory systems spanning basic to advanced complexity: the GAL system, repressilator, Goodwin oscillator, toggle switch, incoherent feed-forward loop, p53-Mdm2 oscillator, and NF-$\kappa$B pathway. Comparison with stochastic simulation algorithm (SSA) ground truth demonstrates that Markovian promoter models achieve similar accuracy to full stochastic simulations while being 10-100$\times$ faster. Our framework provides a mechanistic foundation for gene regulation modeling and enables investigation of promoter-level stochasticity in complex regulatory networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.18442v4</guid>
      <category>q-bio.MN</category>
      <category>q-bio.QM</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Tianyu Wu</dc:creator>
    </item>
  </channel>
</rss>
