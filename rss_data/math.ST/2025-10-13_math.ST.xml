<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.ST updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.ST</link>
    <description>math.ST updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.ST" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 14 Oct 2025 03:09:55 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Theoretical guarantees for change localization using conformal p-values</title>
      <link>https://arxiv.org/abs/2510.08749</link>
      <description>arXiv:2510.08749v1 Announce Type: new 
Abstract: Changepoint localization aims to provide confidence sets for a changepoint (if one exists). Existing methods either relying on strong parametric assumptions or providing only asymptotic guarantees or focusing on a particular kind of change(e.g., change in the mean) rather than the entire distributional change. A method (possibly the first) to achieve distribution-free changepoint localization with finite-sample validity was recently introduced by \cite{dandapanthula2025conformal}. However, while they proved finite sample coverage, there was no analysis of set size. In this work, we provide rigorous theoretical guarantees for their algorithm. We also show the consistency of a point estimator for change, and derive its convergence rate without distributional assumptions. Along that line, we also construct a distribution-free consistent test to assess whether a particular time point is a changepoint or not. Thus, our work provides unified distribution-free guarantees for changepoint detection, localization, and testing. In addition, we present various finite sample and asymptotic properties of the conformal $p$-value in the distribution change setup, which provides a theoretical foundation for many applications of the conformal $p$-value. As an application of these properties, we construct distribution-free consistent tests for exchangeability against distribution-change alternatives and a new, computationally tractable method of optimizing the powers of conformal tests. We run detailed simulation studies to corroborate the performance of our methods and theoretical results. Together, our contributions offer a comprehensive and theoretically principled approach to distribution-free changepoint inference, broadening both the scope and credibility of conformal methods in modern changepoint analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08749v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Swapnaneel Bhattacharyya, Aaditya Ramdas</dc:creator>
    </item>
    <item>
      <title>Drift estimation for rough processes under small noise asymptotic : QMLE approach</title>
      <link>https://arxiv.org/abs/2510.09028</link>
      <description>arXiv:2510.09028v1 Announce Type: new 
Abstract: We consider a process X^$\epsilon$ solution of a stochastic Volterra equation with an unknown parameter $\theta$ in the drift function. The Volterra kernel is singular and given by K(u) = cu $\alpha$-1 __u&gt;0 with $\alpha$ $\in$ (1/2, 1) and it is assumed that the diffusion coefficient is proportional to $\epsilon$ $\rightarrow$ 0 Based on the observation of a discrete sampling with mesh h $\rightarrow$ 0 of the Volterra process, we build a Quasi Maximum Likelihood Estimator. The main step is to assess the error arising in the reconstruction of the path of a semi-martingale from the inversion of the Volterra kernel. We show that this error decreases as h^{1/2} whatever is the value of $\alpha$. Then, we can introduce an explicit contrast function, which yields an efficient estimator when $\epsilon$ $\rightarrow$ 0.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.09028v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arnaud Gloter (LaMME), Nakahiro Yoshida</dc:creator>
    </item>
    <item>
      <title>Fast Wasserstein rates for estimating probability distributions of probabilistic graphical models</title>
      <link>https://arxiv.org/abs/2510.09270</link>
      <description>arXiv:2510.09270v1 Announce Type: new 
Abstract: Using i.i.d. data to estimate a high-dimensional distribution in Wasserstein distance is a fundamental instance of the curse of dimensionality. We explore how structural knowledge about the data-generating process which gives rise to the distribution can be used to overcome this curse. More precisely, we work with the set of distributions of probabilistic graphical models for a known directed acyclic graph. It turns out that this knowledge is only helpful if it can be quantified, which we formalize via smoothness conditions on the transition kernels in the disintegration corresponding to the graph. In this case, we prove that the rate of estimation is governed by the local structure of the graph, more precisely by dimensions corresponding to single nodes together with their parent nodes. The precise rate depends on the exact notion of smoothness assumed for the kernels, where either weak (Wasserstein-Lipschitz) or strong (bidirectional Total-Variation-Lipschitz) conditions lead to different results. We prove sharpness under the strong condition and show that this condition is satisfied for example for distributions having a positive Lipschitz density.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.09270v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Bartl, Stephan Eckstein</dc:creator>
    </item>
    <item>
      <title>Generalized Taylor's Law for Dependent and Heterogeneous Heavy-Tailed Data</title>
      <link>https://arxiv.org/abs/2510.09562</link>
      <description>arXiv:2510.09562v1 Announce Type: new 
Abstract: Taylor's law, also known as fluctuation scaling in physics and the power-law variance function in statistics, is an empirical pattern widely observed across fields including ecology, physics, finance, and epidemiology. It states that the variance of a sample scales as a power function of the mean of the sample. We study generalizations of Taylor's law in the context of heavy-tailed distributions with infinite mean and variance. We establish the probabilistic limit and analyze the associated convergence rates. Our results extend the existing literature by relaxing the i.i.d. assumption to accommodate dependence and heterogeneity among the random variables. This generalization enables application to dependent data such as time series and network-structured data. We support the theoretical developments by extensive simulations, and the practical relevance through applications to real network data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.09562v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Pok Him Cheng, Joel E. Cohen, Hok Kan Ling, Sheung Chi Phillip Yam</dc:creator>
    </item>
    <item>
      <title>Multiplexons: Limits of Multiplex Networks</title>
      <link>https://arxiv.org/abs/2510.08639</link>
      <description>arXiv:2510.08639v1 Announce Type: cross 
Abstract: In a multiplex network, a set of nodes is connected by different types of interactions, each represented as a separate layer within the network. Multiplexes have emerged as a key instrument for modeling large-scale complex systems, due to the widespread coexistence of diverse interactions in social, industrial, and biological domains. This motivates the development of a rigorous and readily applicable framework for studying properties of large multiplex networks. In this article, we provide a self-contained introduction to the limit theory of dense multiplex networks, analogous to the theory of graphons (limit theory of dense graphs). As applications, we derive limiting analogues of commonly used multiplex features, such as degree distributions and clustering coefficients. We also present a range of illustrative examples, including correlated versions of Erd\H{o}s-R\'enyi and inhomogeneous random graph models and dynamic networks. Finally, we discuss how multiplex networks fit within the broader framework of decorated graphs, and how the convergence results can be recovered from the limit theory of decorated graphs. Several future directions are outlined for further developing the multiplex limit theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08639v1</guid>
      <category>math.PR</category>
      <category>cs.SI</category>
      <category>math.CO</category>
      <category>math.ST</category>
      <category>physics.soc-ph</category>
      <category>stat.TH</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ankan Ganguly, Bhaswar B. Bhattacharya</dc:creator>
    </item>
    <item>
      <title>PAC Reasoning: Controlling the Performance Loss for Efficient Reasoning</title>
      <link>https://arxiv.org/abs/2510.09133</link>
      <description>arXiv:2510.09133v1 Announce Type: cross 
Abstract: Large reasoning models (LRMs) have achieved remarkable progress in complex problem-solving tasks. Despite this success, LRMs typically suffer from high computational costs during deployment, highlighting a need for efficient inference. A popular direction of efficiency improvement is to switch the LRM between thinking and nonthinking modes dynamically. However, such approaches often introduce additional reasoning errors and lack statistical guarantees for the performance loss, which are critical for high-stakes applications. In this work, we propose Probably Approximately Correct (PAC) reasoning that controls the performance loss under the user-specified performance loss tolerance. In particular, we construct an upper confidence bound on the performance loss, formulated as a monotone function of the uncertainty score, and subsequently determine a threshold for switching to the nonthinking model. Theoretically, using the threshold to switch between the thinking and nonthinking modes ensures bounded performance loss in a distribution-free manner. Our comprehensive experiments on reasoning benchmarks show that the proposed method can save computational budgets and control the user-specified performance loss.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.09133v1</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Zeng, Jianguo Huang, Bingyi Jing, Hongxin Wei, Bo An</dc:creator>
    </item>
    <item>
      <title>Hypothesis testing on invariant subspaces of non-diagonalizable matrices with applications to network statistics</title>
      <link>https://arxiv.org/abs/2303.18233</link>
      <description>arXiv:2303.18233v5 Announce Type: replace 
Abstract: We generalise the inference procedure for eigenvectors of symmetrizable matrices of Tyler (1981) to that of invariant and singular subspaces of non-diagonalizable matrices. Wald tests for invariant vectors and $t$-tests for their individual coefficients perform well in simulations, despite the matrix being not symmetric. Using these results, it is now possible to perform inference on network statistics that depend on eigenvectors of non-symmetric adjacency matrices as they arise in empirical applications from directed networks. Further, we find that statisticians only need control over the first-order Davis-Kahan bound to control convergence rates of invariant subspace estimators to higher-orders. For general invariant subspaces, the minimal eigenvalue separation dominates the first-order bound potentially slowing convergence rates considerably. In an example, we find that accounting for uncertainty in network estimates changes empirical conclusions about the ranking of nodes' popularity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.18233v5</guid>
      <category>math.ST</category>
      <category>econ.EM</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>J\'er\^ome R. Simons</dc:creator>
    </item>
    <item>
      <title>Online and Offline Robust Multivariate Linear Regression</title>
      <link>https://arxiv.org/abs/2404.19496</link>
      <description>arXiv:2404.19496v2 Announce Type: replace 
Abstract: We consider the robust estimation of the parameters of multivariate Gaussian linear regression models. To this aim we consider robust version of the usual (Mahalanobis) least-square criterion, with or without Ridge regularization. We introduce two methods each considered contrast: (i) online stochastic gradient descent algorithms and their averaged versions and (ii) offline fix-point algorithms. Under weak assumptions, we prove the asymptotic normality of the resulting estimates. Because the variance matrix of the noise is usually unknown, we propose to plug a robust estimate of it in the Mahalanobis-based stochastic gradient descent algorithms. We show, on synthetic data, the dramatic gain in terms of robustness of the proposed estimates as compared to the classical least-square ones. Well also show the computational efficiency of the online versions of the proposed algorithms. All the proposed algorithms are implemented in the R package RobRegression available on CRAN.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.19496v2</guid>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Antoine Godichon-Baggioni (LPSM), Stephane S. Robin (LPSM), Laure Sansonnet (MIA Paris-Saclay, LPSM)</dc:creator>
    </item>
    <item>
      <title>Positive Semidefinite Matrix Supermartingales</title>
      <link>https://arxiv.org/abs/2401.15567</link>
      <description>arXiv:2401.15567v5 Announce Type: replace-cross 
Abstract: We explore the asymptotic convergence and nonasymptotic maximal inequalities of supermartingales and backward submartingales in the space of positive semidefinite matrices. These are natural matrix analogs of scalar nonnegative supermartingales and backward nonnegative submartingales, whose convergence and maximal inequalities are the theoretical foundations for a wide and ever-growing body of results in statistics, econometrics, and theoretical computer science.
  Our results lead to new concentration inequalities for either martingale dependent or exchangeable random symmetric matrices under a variety of tail conditions, encompassing now-standard Chernoff bounds to self-normalized heavy-tailed settings. Further, these inequalities are usually expressed in the Loewner order, are sometimes valid simultaneously for all sample sizes or at an arbitrary data-dependent stopping time, and can often be tightened via an external randomization factor.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.15567v5</guid>
      <category>math.PR</category>
      <category>math.FA</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongjian Wang, Aaditya Ramdas</dc:creator>
    </item>
    <item>
      <title>Multiparameter regularization and aggregation in the context of polynomial functional regression</title>
      <link>https://arxiv.org/abs/2405.04147</link>
      <description>arXiv:2405.04147v2 Announce Type: replace-cross 
Abstract: Most of the recent results in polynomial functional regression have been focused on an in-depth exploration of single-parameter regularization schemes. In contrast, in this study we go beyond that framework by introducing an algorithm for multiple parameter regularization and presenting a theoretically grounded method for dealing with the associated parameters. This method facilitates the aggregation of models with varying regularization parameters. The efficacy of the proposed approach is assessed through evaluations on both synthetic and some real-world medical data, revealing promising results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04147v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1142/S0219530526500065</arxiv:DOI>
      <dc:creator>Elke R. Gizewski, Markus Holzleitner, Lukas Mayer-Suess, Sergiy Pereverzyev Jr., Sergei V. Pereverzyev</dc:creator>
    </item>
    <item>
      <title>Statistical methods: Basic concepts, interpretations, and cautions</title>
      <link>https://arxiv.org/abs/2508.10168</link>
      <description>arXiv:2508.10168v3 Announce Type: replace-cross 
Abstract: The study of associations and their causal explanations is a central research activity whose methodology varies tremendously across fields. Even within specialized subfields, comparisons across textbooks and journals reveals that the basics are subject to considerable variation and controversy. This variation is often obscured by the singular viewpoints presented within textbooks and journal guidelines, which may be deceptively written as if the norms they adopt are unchallenged. Furthermore, human limitations and the vastness within fields imply that no one can have expertise across all subfields and that interpretations will be severely constrained by the limitations of studies of human populations.
  The present chapter outlines an approach to statistical methods that attempts to recognize these problems from the start, rather than assume they are absent as in the claims of 'statistical significance' and 'confidence' ordinarily attached to statistical tests and interval estimates. It does so by grounding models and statistics in data description, and treating inferences from them as speculations based on assumptions that cannot be fully validated or checked using the analysis data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10168v3</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sander Greenland</dc:creator>
    </item>
  </channel>
</rss>
