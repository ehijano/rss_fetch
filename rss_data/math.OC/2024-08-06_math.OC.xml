<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 06 Aug 2024 04:01:23 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 06 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Deep Reinforcement Learning for Dynamic Order Picking in Warehouse Operations</title>
      <link>https://arxiv.org/abs/2408.01656</link>
      <description>arXiv:2408.01656v1 Announce Type: new 
Abstract: Order picking is a crucial operation in warehouses that significantly impacts overall efficiency and profitability. This study addresses the dynamic order picking problem, a significant concern in modern warehouse management where real-time adaptation to fluctuating order arrivals and efficient picker routing are crucial. Traditional methods, often assuming fixed order sets, fall short in this dynamic environment. We utilize Deep Reinforcement Learning (DRL) as a solution methodology to handle the inherent uncertainties in customer demands. We focus on a single-block warehouse with an autonomous picking device, eliminating human behavioral factors. Our DRL framework enables the dynamic optimization of picker routes, significantly reducing order throughput times, especially under high order arrival rates. Experiments demonstrate a substantial decrease in order throughput time and unfulfilled orders compared to benchmark algorithms. We further investigate integrating a hyperparameter in the reward function that allows for flexible balancing between distance traveled and order completion time. Finally, we demonstrate the robustness of our DRL model for out-of-sample test instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01656v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sasan Mahmoudinazlou, Abhay Sobhanan, Hadi Charkhgard, Ali Eshragh, George Dunn</dc:creator>
    </item>
    <item>
      <title>A Robust Compressed Push-Pull Method for Decentralized Nonconvex Optimization</title>
      <link>https://arxiv.org/abs/2408.01727</link>
      <description>arXiv:2408.01727v1 Announce Type: new 
Abstract: In the modern paradigm of multi-agent networks, communication has become one of the main bottlenecks for decentralized optimization, where a large number of agents are involved in minimizing the average of the local cost functions. In this paper, we propose a robust compressed push-pull algorithm (RCPP) that combines gradient tracking with communication compression. In particular, RCPP is robust under a much more general class of compression operators that allow both relative and absolute compression errors, in contrast to the existing works which can handle either one of them or assume convex problems. We show that RCPP enjoys sublinear convergence rate for smooth and possibly nonconvex objective functions over general directed networks. Moreover, under the additional Polyak-{\L}ojasiewicz condition, linear convergence rate can be achieved for RCPP. Numerical examples verify the theoretical findings and demonstrate the efficiency, flexibility, and robustness of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01727v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiwei Liao, Zhuorui Li, Shi Pu, Tsung-Hui Chang</dc:creator>
    </item>
    <item>
      <title>Boundary null controllability of the heat equation with Wentzell boundary condition and Dirichlet control</title>
      <link>https://arxiv.org/abs/2408.01740</link>
      <description>arXiv:2408.01740v1 Announce Type: new 
Abstract: We consider the linear heat equation with a Wentzell-type boundary condition and a Dirichlet control. Such a boundary condition can be reformulated as one of dynamic type. First, we formulate the boundary controllability problem of the system within the framework of boundary control systems, proving its well-posedness. Then we reduce the question to a moment problem. Using the spectral analysis of the associated Sturm-Liouville problem and the moment method, we establish the null controllability of the system at any positive time $T$. Finally, we approximate minimum energy controls by a penalized HUM approach. This allows us to validate the theoretical controllability results obtained by the moment method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01740v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>S. E. Chorfi, M. I. Ismailov, L. Maniar, I. \"Oner</dc:creator>
    </item>
    <item>
      <title>Complexity of Minimizing Projected-Gradient-Dominated Functions with Stochastic First-order Oracles</title>
      <link>https://arxiv.org/abs/2408.01839</link>
      <description>arXiv:2408.01839v1 Announce Type: new 
Abstract: This work investigates the performance limits of projected stochastic first-order methods for minimizing functions under the $(\alpha,\tau,\mathcal{X})$-projected-gradient-dominance property, that asserts the sub-optimality gap $F(\mathbf{x})-\min_{\mathbf{x}'\in \mathcal{X}}F(\mathbf{x}')$ is upper-bounded by $\tau\cdot\|\mathcal{G}_{\eta,\mathcal{X}}(\mathbf{x})\|^{\alpha}$ for some $\alpha\in[1,2)$ and $\tau&gt;0$ and $\mathcal{G}_{\eta,\mathcal{X}}(\mathbf{x})$ is the projected-gradient mapping with $\eta&gt;0$ as a parameter. For non-convex functions, we show that the complexity lower bound of querying a batch smooth first-order stochastic oracle to obtain an $\epsilon$-global-optimum point is $\Omega(\epsilon^{-{2}/{\alpha}})$. Furthermore, we show that a projected variance-reduced first-order algorithm can obtain the upper complexity bound of $\mathcal{O}(\epsilon^{-{2}/{\alpha}})$, matching the lower bound. For convex functions, we establish a complexity lower bound of $\Omega(\log(1/\epsilon)\cdot\epsilon^{-{2}/{\alpha}})$ for minimizing functions under a local version of gradient-dominance property, which also matches the upper complexity bound of accelerated stochastic subgradient methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01839v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Saeed Masiha, Saber Salehkaleybar, Niao He, Negar Kiyavash, Patrick Thiran</dc:creator>
    </item>
    <item>
      <title>Methods for Optimization Problems with Markovian Stochasticity and Non-Euclidean Geometry</title>
      <link>https://arxiv.org/abs/2408.01848</link>
      <description>arXiv:2408.01848v1 Announce Type: new 
Abstract: This paper examines a variety of classical optimization problems, including well-known minimization tasks and more general variational inequalities. We consider a stochastic formulation of these problems, and unlike most previous work, we take into account the complex Markov nature of the noise. We also consider the geometry of the problem in an arbitrary non-Euclidean setting, and propose four methods based on the Mirror Descent iteration technique. Theoretical analysis is provided for smooth and convex minimization problems and variational inequalities with Lipschitz and monotone operators. The convergence guarantees obtained are optimal for first-order stochastic methods, as evidenced by the lower bound estimates provided in this paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01848v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vladimir Solodkin, Andrew Veprikov, Aleksandr Beznosikov</dc:creator>
    </item>
    <item>
      <title>A consistently adaptive trust-region method</title>
      <link>https://arxiv.org/abs/2408.01874</link>
      <description>arXiv:2408.01874v1 Announce Type: new 
Abstract: Adaptive trust-region methods attempt to maintain strong convergence guarantees without depending on conservative estimates of problem properties such as Lipschitz constants. However, on close inspection, one can show existing adaptive trust-region methods have theoretical guarantees with severely suboptimal dependence on problem properties such as the Lipschitz constant of the Hessian. For example, TRACE developed by Curtis et al. obtains a $O(\Delta_f L^{3/2} \epsilon^{-3/2}) + \tilde{O}(1)$ iteration bound where $L$ is the Lipschitz constant of the Hessian. Compared with the optimal $O(\Delta_f L^{1/2} \epsilon^{-3/2})$ bound this is suboptimal with respect to $L$. We present the first adaptive trust-region method which circumvents this issue and requires at most $O( \Delta_f L^{1/2} \epsilon^{-3/2}) + \tilde{O}(1)$ iterations to find an $\epsilon$-approximate stationary point, matching the optimal iteration bound up to an additive logarithmic term. Our method is a simple variant of a classic trust-region method and in our experiments performs competitively with both ARC and a classical trust-region method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01874v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fadi Hamad, Oliver Hinder</dc:creator>
    </item>
    <item>
      <title>Diagonally forced systems and the spectral signature of matrix cycles</title>
      <link>https://arxiv.org/abs/2408.01987</link>
      <description>arXiv:2408.01987v1 Announce Type: new 
Abstract: Given any square matrix, $\mathbf{M}$, whose diagonal elements are negative, and which is multiplied by a variable, $\sigma$, we wish to find the minimal $\sigma$ such that the eigenvalue of $\mathbf{M}_{\sigma}$ is exactly zero. By Gershgorin, we know that $\mathbf{M}_{\sigma}$ can be made stable by making $\sigma$ large enough. We prove a relation which analytically determines when and how we are able to find the value of $\sigma$ such that the maximal eigenvalue is exactly zero. In so doing, we prove the equivalence of the roots of the characteristic polynomial of $\mathbf{M}_{\sigma}$ and the eigenvalues that arise from a scaling operation on $\mathbf{M}$. Further, through the characteristic polynomial, we are able to isolate the dominant feedback cycles comprising the elements of the matrix which, under the action of $\sigma$, ensures the stability of the system. We then explore, using the stabilising and destabilising cycles within the coefficients of the characteristic polynomial, an intrinsic spectral signature associated with any matrix based on the size and sign (or zero) of its respective elements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01987v1</guid>
      <category>math.OC</category>
      <category>math.CA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Thorne</dc:creator>
    </item>
    <item>
      <title>A Bregman-Sinkhorn Algorithm for the Maximum Weight Independent Set Problem</title>
      <link>https://arxiv.org/abs/2408.02086</link>
      <description>arXiv:2408.02086v1 Announce Type: new 
Abstract: We propose a scalable approximate algorithm for the NP-hard maximum-weight independent set problem. The core of our algorithm is a dual coordinate descent applied to a smoothed LP relaxation of the problem. This technique is referred to as Bregman method or Sinkhorn algorithm in the literature. Our algorithm addresses a family of clique cover LP relaxations, where the constraints are determined by the set of cliques covering the underlying graph. The objective function of the relaxation is smoothed with an entropy term.
  An important question determining efficiency of our algorithm is the control of the smoothing level over the course of optimization. While several dedicated techniques have been considered in the literature to this end, we propose a new one based on estimation of the relaxed duality gap. To make this estimation possible, we developed a new projection method to the feasible set of the considered LP relaxation. We experimentally show that our technique notably outperforms the standard one based on feasibility estimation.
  Additionally to solving the relaxed dual, we utilize a simple and very efficient primal heuristic to obtain feasible integer solutions of the initial non-relaxed problem. Our heuristic is a combination of the greedy generation and optimal recombination applied to the reduced costs computed by the dual optimization.
  Our experimental validation considers two datasets based on real-life applications, where our method shows competitive results being able to find high quality approximate solutions within 10 seconds for graphs with hundreds of thousands of nodes and dozens of millions of edges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02086v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefan Haller, Bogdan Savchynskyy</dc:creator>
    </item>
    <item>
      <title>Optimal policy for control of epidemics with constrained time intervals and region-based interactions</title>
      <link>https://arxiv.org/abs/2408.02097</link>
      <description>arXiv:2408.02097v1 Announce Type: new 
Abstract: We introduce a policy model coupled with the susceptible-infected-recovered (SIR) epidemic model to study interactions between policy-making and the dynamics of epidemics. We consider both single-region policies, as well as game-theoretic models involving interactions among several regions, and hierarchical interactions among policy-makers modeled as multi-layer games. We assume that the policy functions are piece-wise constant with a minimum time interval for each policy stage, considering policies cannot change frequently in time or they cannot be easily followed. The optimal policy is obtained by minimizing a cost function which consists of an implementation cost, an impact cost, and, in the case of multi-layer games, a non-compliance cost. We show in a case study of COVID-19 in France that when the cost function is reduced to the impact cost and is parameterized as the final epidemic size, the solution approximates that of the optimal control in Bliman et al, J. Optim. Theory Appl., 189, 2021, for sufficiently small minimum policy time interval. For a larger time interval however the optimal policy is a step down function, quite different from the step up structure typically deployed during the COVID-19 pandemic. In addition, we present a counterfactual study of how the pandemic would have evolved if herd immunity was reached during the second wave in the county of Los Angeles, California. Lastly, we study a case of three interacting counties with and without a governing state.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02097v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <category>physics.soc-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xia Li, Andrea L. Bertozzi, P. Jeffrey Brantingham, Yevgeniy Vorobeychik</dc:creator>
    </item>
    <item>
      <title>Sensitivity analysis of multiobjective linear programming from a geometric perspective</title>
      <link>https://arxiv.org/abs/2408.02101</link>
      <description>arXiv:2408.02101v1 Announce Type: new 
Abstract: Sensitivity analysis plays a crucial role in multiobjective linear programming (MOLP), where understanding the impact of parameter changes on efficient solutions is essential. This work builds upon and extends previous investigations. In this paper, we introduce a novel approach to sensitivity analysis in MOLP, designed to be computationally feasible for decision-makers studying the behavior of efficient solutions under perturbations of objective function coefficients in a two-dimensional variable space. This approach classifies all MOLP problems in $S \subset \mathbb{R}^{2}$ by defining an equivalence relation that partitions the space of linear maps$-$comprising all sequences of linear forms on $\mathbb{R}^2$ of length $K \geq 2-$into a finite number of equivalence classes. Each equivalence class is associated with a unique subset of the boundary of $S$. For any MOLP with $K$ objective functions belonging to the same equivalence class, its set of efficient solutions corresponds to the associated subset of the boundary of $S$. This approach is detailed and illustrated with a numerical example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02101v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mustapha Kaci</dc:creator>
    </item>
    <item>
      <title>Embedding generalization within the learning dynamics: An approach based-on sample path large deviation theory</title>
      <link>https://arxiv.org/abs/2408.02167</link>
      <description>arXiv:2408.02167v1 Announce Type: new 
Abstract: We consider a typical learning problem of point estimations for modeling of nonlinear functions or dynamical systems in which generalization, i.e., verifying a given learned model, can be embedded as an integral part of the learning process or dynamics. In particular, we consider an empirical risk minimization based learning problem that exploits gradient methods from continuous-time perspective with small random perturbations, which is guided by the training dataset loss. Here, we provide an asymptotic probability estimate in the small noise limit based-on the Freidlin-Wentzell theory of large deviations, when the sample path of the random process corresponding to the randomly perturbed gradient dynamical system hits a certain target set, i.e., a rare event, when the latter is specified by the testing dataset loss landscape. Interestingly, the proposed framework can be viewed as one way of improving generalization and robustness in learning problems that provides new insights leading to optimal point estimates which is guided by training data loss, while, at the same time, the learning dynamics has an access to the testing dataset loss landscape in some form of future achievable or anticipated target goal. Moreover, as a by-product, we establish a connection with optimal control problem, where the target set, i.e., the rare event, is considered as the desired outcome or achievable target goal for a certain optimal control problem, for which we also provide a verification result reinforcing the rationale behind the proposed framework. Finally, we present a computational algorithm that solves the corresponding variational problem leading to an optimal point estimates and, as part of this work, we also present some numerical results for a typical case of nonlinear regression problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02167v1</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Getachew K. Befekadu</dc:creator>
    </item>
    <item>
      <title>Discrete Shortest Paths in Optimal Power Flow Feasible Regions</title>
      <link>https://arxiv.org/abs/2408.02172</link>
      <description>arXiv:2408.02172v1 Announce Type: new 
Abstract: Optimal power flow (OPF) is a critical optimization problem for power systems to operate at points where cost or operational objectives are optimized. Due to the non-convexity of the set of feasible OPF operating points, it is non-trivial to transition the power system from its current operating point to the optimal one without violating constraints. On top of that, practical considerations dictate that the transition should be achieved using a small number of small-magnitude control actions. To solve this problem, this paper proposes an algorithm for computing a transition path by framing it as a shortest path problem. This problem is formulated in terms of a discretized piece-wise linear path, where the number of pieces is fixed a priori in order to limit the number of control actions. This formulation yields a nonlinear optimization problem (NLP) with a block tridiagonal structure, which we leverage by utilizing a specialized interior point method. An initial feasible path for our method is generated by solving a sequence of relaxations which are then tightened in a homotopy-like procedure. Numerical experiments illustrate the effectiveness of the algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02172v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Turizo, Diego Cifuentes, Anton Leykin, Daniel K. Molzahn</dc:creator>
    </item>
    <item>
      <title>On the Equilibrium of a Class of Leader-Follower Games with Decision-Dependent Chance Constraints</title>
      <link>https://arxiv.org/abs/2408.02174</link>
      <description>arXiv:2408.02174v1 Announce Type: new 
Abstract: In this paper, we study the existence of equilibrium in a single-leader-multiple-follower game with decision-dependent chance constraints (DDCCs), where decision-dependent uncertainties (DDUs) exist in the constraints of followers. DDUs refer to the uncertainties impacted by the leader's strategy, while the leader cannot capture their exact probability distributions. To address such problems, we first use decision-dependent ambiguity sets under moment information and Cantelli's inequality to transform DDCCs into second-order cone constraints. This simplifies the game model by eliminating the probability distributions. We further prove that there exists at least one equilibrium point for this game by applying Kakutani's fixed-point theorem. Finally, a numerical example is provided to show the impact of DDUs on the equilibrium of such game models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02174v1</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jingxiang Wang, Zhaojian Wang, Bo Yang, Feng Liu, Xinping Guan</dc:creator>
    </item>
    <item>
      <title>Competitive optimal portfolio selection in a non-Markovian financial market: A backward stochastic differential equation study</title>
      <link>https://arxiv.org/abs/2408.02286</link>
      <description>arXiv:2408.02286v1 Announce Type: new 
Abstract: This paper studies a competitive optimal portfolio selection problem in a model where the interest rate, the appreciation rate and volatility rate of the risky asset are all stochastic processes, thus forming a non-Markovian financial market. In our model, all investors (or agents) aim to obtain an above-average wealth at the end of the common investment horizon. This competitive optimal portfolio problem is indeed a non-zero stochastic differential game problem. The quadratic BSDE theory is applied to tackle the problem and Nash equilibria in suitable spaces are found. We discuss both the CARA and CRRA utility cases. For the CARA utility case, there are three possible scenarios depending on market and competition parameters: a unique Nash equilibrium, no Nash equilibrium, and infinite Nash equilibria. The Nash equilibrium is given by the solutions of a quadratic BSDE and a linear BSDE with unbounded coefficient when it is unique. Different from the wealth-independent Nash equilibria in the existing literature, the equilibrium in our paper is of feedback form of wealth. For the CRRA utility case, the issue is a bit more complicated than the CARA utility case. We prove the solvability of a new kind of quadratic BSDEs with unbounded coefficients. A decoupling technology is used to relate the Nash equilibrium to a series of 1-dimensional quadratic BSDEs. With the help of this decoupling technology, we can even give the limiting strategies for both cases when the number of agent tends to be infinite.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02286v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guangchen Wang, Zuo Quan Xu, Panpan Zhang</dc:creator>
    </item>
    <item>
      <title>Fairness in Multi-Proposer-Multi-Responder Ultimatum Game</title>
      <link>https://arxiv.org/abs/2408.02410</link>
      <description>arXiv:2408.02410v1 Announce Type: new 
Abstract: The Ultimatum Game is conventionally formulated in the context of two players. Nonetheless, real-life scenarios often entail community interactions among numerous individuals. To address this, we introduce an extended version of the Ultimatum Game, called the Multi-Proposer-Multi-Responder Ultimatum Game. In this model, multiple responders and proposers simultaneously interact in a one-shot game, introducing competition both within proposers and within responders. We derive subgame-perfect Nash equilibria for all scenarios and explore how these non-trivial values might provide insight into proposal and rejection behavior experimentally observed in the context of one vs. one Ultimatum Game scenarios. Additionally, by considering the asymptotic numbers of players, we propose two potential estimates for a "fair" threshold: either 31.8% or 36.8% of the pie (share) for the responder.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02410v1</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hana Krakovsk\'a, Rudolf Hanel, Mark Broom</dc:creator>
    </item>
    <item>
      <title>On the influence of dependent features in classification problems: a game-theoretic perspective</title>
      <link>https://arxiv.org/abs/2408.02481</link>
      <description>arXiv:2408.02481v1 Announce Type: new 
Abstract: This paper deals with a new measure of the influence of each feature on the response variable in classification problems, accounting for potential dependencies among certain feature subsets. Within this framework, we consider a sample of individuals characterized by specific features, each feature encompassing a finite range of values, and classified based on a binary response variable. This measure turns out to be an influence measure explored in existing literature and related to cooperative game theory. We provide an axiomatic characterization of our proposed influence measure by tailoring properties from the cooperative game theory to our specific context. Furthermore, we demonstrate that our influence measure becomes a general characterization of the well-known Banzhaf-Owen value for games with a priori unions, from the perspective of classification problems. The definitions and results presented herein are illustrated through numerical examples and various applications, offering practical insights into our methodologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02481v1</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Laura Davila-Pena, Alejandro Saavedra-Nieves, Balbina Casas-M\'endez</dc:creator>
    </item>
    <item>
      <title>Full error analysis of policy gradient learning algorithms for exploratory linear quadratic mean-field control problem in continuous time with common noise</title>
      <link>https://arxiv.org/abs/2408.02489</link>
      <description>arXiv:2408.02489v1 Announce Type: new 
Abstract: We consider reinforcement learning (RL) methods for finding optimal policies in linear quadratic (LQ) mean field control (MFC) problems over an infinite horizon in continuous time, with common noise and entropy regularization. We study policy gradient (PG) learning and first demonstrate convergence in a model-based setting by establishing a suitable gradient domination condition.Next, our main contribution is a comprehensive error analysis, where we prove the global linear convergence and sample complexity of the PG algorithm with two-point gradient estimates in a model-free setting with unknown parameters. In this setting, the parameterized optimal policies are learned from samples of the states and population distribution.Finally, we provide numerical evidence supporting the convergence of our implemented algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02489v1</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Noufel Frikha (CES), Huy\^en Pham (LPSM), Xuanye Song (LPSM)</dc:creator>
    </item>
    <item>
      <title>Gradient flow in parameter space is equivalent to linear interpolation in output space</title>
      <link>https://arxiv.org/abs/2408.01517</link>
      <description>arXiv:2408.01517v1 Announce Type: cross 
Abstract: We prove that the usual gradient flow in parameter space that underlies many training algorithms for neural networks in deep learning can be continuously deformed into an adapted gradient flow which yields (constrained) Euclidean gradient flow in output space. Moreover, if the Jacobian of the outputs with respect to the parameters is full rank (for fixed training data), then the time variable can be reparametrized so that the resulting flow is simply linear interpolation, and a global minimum can be achieved.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01517v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Chen, Patr\'icia Mu\~noz Ewald</dc:creator>
    </item>
    <item>
      <title>Opinion Dynamics with Set-Based Confidence: Convergence Criteria and Periodic Solutions</title>
      <link>https://arxiv.org/abs/2408.01753</link>
      <description>arXiv:2408.01753v1 Announce Type: cross 
Abstract: This paper introduces a new multidimensional extension of the Hegselmann-Krause (HK) opinion dynamics model, where opinion proximity is not determined by a norm or metric. Instead, each agent trusts opinions within the Minkowski sum $\xi+\mathcal{O}$, where $\xi$ is the agent's current opinion and $\mathcal{O}$ is the confidence set defining acceptable deviations. During each iteration, agents update their opinions by simultaneously averaging the trusted opinions. Unlike traditional HK systems, where $\mathcal{O}$ is a ball in some norm, our model allows the confidence set to be non-convex and even unbounded.
  We demonstrate that the new model, referred to as SCOD (Set-based Confidence Opinion Dynamics), can exhibit properties absent in the conventional HK model. Some solutions may converge to non-equilibrium points in the state space, while others oscillate periodically. These ``pathologies'' disappear if the set $\mathcal{O}$ is symmetric and contains zero in its interior: similar to the usual HK model, SCOD then converges in a finite number of iterations to one of the equilibrium points. The latter property is also preserved if one agent is "stubborn" and resists changing their opinion, yet still influences the others; however, two stubborn agents can lead to oscillations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01753v1</guid>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <category>nlin.AO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Iryna Zabarianska, Anton V. Proskurnikov</dc:creator>
    </item>
    <item>
      <title>Using Linearized Optimal Transport to Predict the Evolution of Stochastic Particle Systems</title>
      <link>https://arxiv.org/abs/2408.01857</link>
      <description>arXiv:2408.01857v1 Announce Type: cross 
Abstract: We develop an algorithm to approximate the time evolution of a probability measure without explicitly learning an operator that governs the evolution. A particular application of interest is discrete measures $\mu_t^N$ that arise from particle systems. In many such situations, the individual particles move chaotically on short time scales, making it difficult to learn the dynamics of a governing operator, but the bulk distribution $\mu_t^N$ approximates an absolutely continuous measure $\mu_t$ that evolves ``smoothly.'' If $\mu_t$ is known on some time interval, then linearized optimal transport theory provides an Euler-like scheme for approximating the evolution of $\mu_t$ using its ``tangent vector field'' (represented as a time-dependent vector field on $\mathbb R^d$), which can be computed as a limit of optimal transport maps. We propose an analog of this Euler approximation to predict the evolution of the discrete measure $\mu_t^N$ (without knowing $\mu_t$). To approximate the analogous tangent vector field, we use a finite difference over a time step that sits between the two time scales of the system -- long enough for the large-$N$ evolution ($\mu_t$) to emerge but short enough to satisfactorily approximate the derivative object used in the Euler scheme. By allowing the limiting behavior to emerge, the optimal transport maps closely approximate the vector field describing the bulk distribution's smooth evolution instead of the individual particles' more chaotic movements. We demonstrate the efficacy of this approach with two illustrative examples, Gaussian diffusion and a cell chemotaxis model, and show that our method succeeds in predicting the bulk behavior over relatively large steps.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01857v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicholas Karris, Evangelos A. Nikitopoulos, Ioannis Kevrekidis, Seungjoon Lee, Alexander Cloninger</dc:creator>
    </item>
    <item>
      <title>Isolating Signatures of Cyberattacks under Stressed Grid Conditions</title>
      <link>https://arxiv.org/abs/2408.02011</link>
      <description>arXiv:2408.02011v1 Announce Type: cross 
Abstract: In a controlled cyber-physical network, such as a power grid, any malicious data injection in the sensor measurements can lead to widespread impact due to the actions of the closed-loop controllers. While fast identification of the attack signatures is imperative for reliable operations, it is challenging to do so in a large dynamical network with tightly coupled nodes. A particularly challenging scenario arises when the cyberattacks are strategically launched during a grid stress condition, caused by non-malicious physical disturbances. In this work, we propose an algorithmic framework -- based on Koopman mode (KM) decomposition -- for online identification and visualization of the cyberattack signatures in streaming time-series measurements from a power network. The KMs are capable of capturing the spatial embedding of both natural and anomalous modes of oscillations in the sensor measurements and thus revealing the specific influences of cyberattacks, even under existing non-malicious grid stress events. Most importantly, it enables us to quantitatively compare the outcomes of different potential cyberattacks injected by an attacker. The performance of the proposed algorithmic framework is illustrated on the IEEE 68-bus test system using synthetic attack scenarios. Such knowledge regarding the detection of various cyberattacks will enable us to devise appropriate diagnostic scheme while considering varied constraints arising from different attacks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02011v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sanchita Ghosh, Syed Ahsan Raza Naqvi, Sai Pushpak Nandanoori, Soumya Kundu</dc:creator>
    </item>
    <item>
      <title>Clearing-out of dipoles for minimisers of 2-dimensional discrete energies with topological singularities</title>
      <link>https://arxiv.org/abs/2408.02136</link>
      <description>arXiv:2408.02136v1 Announce Type: cross 
Abstract: A key question in the analysis of discrete models for material defects, such as vortices in spin systems and superconductors or isolated dislocations in metals, is whether information on boundary energy for a domain can be sufficient for controlling the number of defects in the interior. We present a general combinatorial dipole-removal argument for a large class of discrete models including XY systems and screw dislocation models, allowing to prove sharp conditions under which controlled flux and boundary energy guarantee to have minimizers with zero or one charges in the interior. The argument uses the max-flow min-cut theorem in combination with an ad-hoc duality for planar graphs, and is robust with respect to changes of the function defining the interaction energies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02136v1</guid>
      <category>math.AP</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adriana Garroni, Mircea Petrache, Emanuele Spadaro</dc:creator>
    </item>
    <item>
      <title>Path-dependent Hamilton-Jacobi equations with u-dependence and time-measurable Hamiltonians</title>
      <link>https://arxiv.org/abs/2408.02145</link>
      <description>arXiv:2408.02145v1 Announce Type: cross 
Abstract: We establish existence and uniqueness of minimax solutions for a fairly general class of path-dependent Hamilton-Jacobi equations. In particular, the relevant Hamiltonians can contain the solution and they only need to be measurable with respect to time. We apply our results to optimal control problems of (delay) functional differential equations with cost functionals that have discount factors and with time-measurable data. Our main results are also crucial for our companion paper Bandini and Keller (2024), where non-local path-dependent Hamilton-Jacobi-Bellman equations associated to the stochastic optimal control of non-Markovian piecewise deterministic processes are studied.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02145v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Elena Bandini, Christian Keller</dc:creator>
    </item>
    <item>
      <title>Non-local Hamilton-Jacobi-Bellman equations for the stochastic optimal control of path-dependent piecewise deterministic processes</title>
      <link>https://arxiv.org/abs/2408.02147</link>
      <description>arXiv:2408.02147v1 Announce Type: cross 
Abstract: We study the optimal control of path-dependent piecewise deterministic processes. An appropriate dynamic programming principle is established. We prove that the associated value function is the unique minimax solution of the corresponding non-local path-dependent Hamilton-Jacobi-Bellman equation. This is the first well-posedness result for nonsmooth solutions of fully nonlinear non-local path-dependent partial differential equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02147v1</guid>
      <category>math.PR</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Elena Bandini, Christian Keller</dc:creator>
    </item>
    <item>
      <title>Existence, Stability and Optimal Drug Dosage for a Reaction-Diffusion System Arising in a Cancer Treatment</title>
      <link>https://arxiv.org/abs/2408.02227</link>
      <description>arXiv:2408.02227v1 Announce Type: cross 
Abstract: In this paper, a reaction-diffusion system modeling injection of a chemotherapeutic drug on the surface of a living tissue during a treatment for cancer patients is studied. The system describes the interaction of the chemotherapeutic drug and the normal, tumor and immune cells. We first establish well-posedness for the nonlinear reaction-diffusion system, then investigate the long-time behavior of solutions. Particularly, it is shown that the cancer cells will be eliminated assuming that its reproduction rate is sufficiently small in a short time period in each treatment interval. The analysis is then essentially exploited to study an optimal drug injection rate problem during a chemotherapeutic drug treatment for tumor cells, which is formulated as an optimal boundary control problem with constraints. For this, we show that the existence of an optimal drug injection rate through the boundary, and derive the first-order optimality condition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02227v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Jeff Morgan, Bao Quoc Tang, Hong-Ming Yin</dc:creator>
    </item>
    <item>
      <title>Nonlinear Perturbation-based Non-Convex Optimization over Time-Varying Networks</title>
      <link>https://arxiv.org/abs/2408.02269</link>
      <description>arXiv:2408.02269v1 Announce Type: cross 
Abstract: Decentralized optimization strategies are helpful for various applications, from networked estimation to distributed machine learning. This paper studies finite-sum minimization problems described over a network of nodes and proposes a computationally efficient algorithm that solves distributed convex problems and optimally finds the solution to locally non-convex objective functions. In contrast to batch gradient optimization in some literature, our algorithm is on a single-time scale with no extra inner consensus loop. It evaluates one gradient entry per node per time. Further, the algorithm addresses link-level nonlinearity representing, for example, logarithmic quantization of the exchanged data or clipping of the exchanged data bits. Leveraging perturbation-based theory and algebraic Laplacian network analysis proves optimal convergence and dynamics stability over time-varying and switching networks. The time-varying network setup might be due to packet drops or link failures. Despite the nonlinear nature of the dynamics, we prove exact convergence in the face of odd sign-preserving sector-bound nonlinear data transmission over the links. Illustrative numerical simulations further highlight our contributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02269v1</guid>
      <category>eess.SY</category>
      <category>cs.DC</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammadreza Doostmohammadian, Zulfiya R. Gabidullina, Hamid R. Rabiee</dc:creator>
    </item>
    <item>
      <title>On the consistent reasoning paradox of intelligence and optimal trust in AI: The power of 'I don't know'</title>
      <link>https://arxiv.org/abs/2408.02357</link>
      <description>arXiv:2408.02357v1 Announce Type: cross 
Abstract: We introduce the Consistent Reasoning Paradox (CRP). Consistent reasoning, which lies at the core of human intelligence, is the ability to handle tasks that are equivalent, yet described by different sentences ('Tell me the time!' and 'What is the time?'). The CRP asserts that consistent reasoning implies fallibility -- in particular, human-like intelligence in AI necessarily comes with human-like fallibility. Specifically, it states that there are problems, e.g. in basic arithmetic, where any AI that always answers and strives to mimic human intelligence by reasoning consistently will hallucinate (produce wrong, yet plausible answers) infinitely often. The paradox is that there exists a non-consistently reasoning AI (which therefore cannot be on the level of human intelligence) that will be correct on the same set of problems. The CRP also shows that detecting these hallucinations, even in a probabilistic sense, is strictly harder than solving the original problems, and that there are problems that an AI may answer correctly, but it cannot provide a correct logical explanation for how it arrived at the answer. Therefore, the CRP implies that any trustworthy AI (i.e., an AI that never answers incorrectly) that also reasons consistently must be able to say 'I don't know'. Moreover, this can only be done by implicitly computing a new concept that we introduce, termed the 'I don't know' function -- something currently lacking in modern AI. In view of these insights, the CRP also provides a glimpse into the behaviour of Artificial General Intelligence (AGI). An AGI cannot be 'almost sure', nor can it always explain itself, and therefore to be trustworthy it must be able to say 'I don't know'.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02357v1</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Bastounis, Paolo Campodonico, Mihaela van der Schaar, Ben Adcock, Anders C. Hansen</dc:creator>
    </item>
    <item>
      <title>Online Fair Allocation with Best-of-Many-Worlds Guarantees</title>
      <link>https://arxiv.org/abs/2408.02403</link>
      <description>arXiv:2408.02403v1 Announce Type: cross 
Abstract: We investigate the online fair allocation problem with sequentially arriving items under various input models, with the goal of balancing fairness and efficiency. We propose the unconstrained PACE (Pacing According to Current Estimated utility) algorithm, a parameter-free allocation dynamic that requires no prior knowledge of the input while using only integral allocations. PACE attains near-optimal convergence or approximation guarantees under stationary, stochastic-but-nonstationary, and adversarial input types, thereby achieving the first best-of-many-worlds guarantee in online fair allocation. Beyond theoretical bounds, PACE is highly simple, efficient, and decentralized, and is thus likely to perform well on a broad range of real-world inputs. Numerical results support the conclusion that PACE works well under a variety of input models. We find that PACE performs very well on two real-world datasets even under the true temporal arrivals in the data, which are highly nonstationary.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02403v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zongjun Yang, Luofeng Liao, Yuan Gao, Christian Kroer</dc:creator>
    </item>
    <item>
      <title>Non-commutative optimization problems with differential constraints</title>
      <link>https://arxiv.org/abs/2408.02572</link>
      <description>arXiv:2408.02572v1 Announce Type: cross 
Abstract: Non-commutative polynomial optimization (NPO) problems seek to minimize the state average of a polynomial of some operator variables, subject to polynomial constraints, over all states and operators, as well as the Hilbert spaces where those might be defined. Many of these problems are known to admit a complete hierarchy of semidefinite programming (SDP) relaxations. NPO theory has found application in quantum information theory, quantum chemistry and statistical physics. In this work, we consider a variant of NPO problems where a subset of the operator variables satisfies a system of ordinary differential equations. We find that, under mild conditions of operator boundedness, for every such problem one can construct a standard NPO problem with the same solution. This allows us to define a complete hierarchy of SDPs to tackle the original differential problem. We apply this method to extrapolate quantum time series in a semi-device-independent way and sketch how one can use it to model Hamiltonian time evolution in many-body quantum systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02572v1</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mateus Ara\'ujo, Andrew J. P. Garner, Miguel Navascues</dc:creator>
    </item>
    <item>
      <title>Learning rheological parameters of non-Newtonian fluids from velocimetry data</title>
      <link>https://arxiv.org/abs/2408.02604</link>
      <description>arXiv:2408.02604v1 Announce Type: cross 
Abstract: We solve a Bayesian inverse Navier-Stokes (N-S) problem that assimilates velocimetry data in order to jointly reconstruct the flow field and learn the unknown N-S parameters. By incorporating a Carreau shear-thinning viscosity model into the N-S problem, we devise an algorithm that learns the most likely Carreau parameters of a shear-thinning fluid, and estimates their uncertainties, from velocimetry data alone. We then conduct a flow-MRI experiment to obtain velocimetry data of an axisymmetric laminar jet through an idealised medical device (FDA nozzle) for a blood analogue fluid. We show that the algorithm can successfully reconstruct the flow field by learning the most likely Carreau parameters, and that the learned parameters are in very good agreement with rheometry measurements. The algorithm accepts any algebraic effective viscosity model, as long as the model is differentiable, and it can be extended to more complicated non-Newtonian fluids (e.g. Oldroyd-B fluid) if a viscoelastic model is incorporated into the N-S problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02604v1</guid>
      <category>physics.flu-dyn</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexandros Kontogiannis, Richard Hodgkinson, Emily L. Manchester</dc:creator>
    </item>
    <item>
      <title>On the Infinite-Nudging Limit of the Nudging Filter for Continuous Data Assimilation</title>
      <link>https://arxiv.org/abs/2408.02646</link>
      <description>arXiv:2408.02646v1 Announce Type: cross 
Abstract: This article studies the intimate relationship between two filtering algorithms for continuous data assimilation, the synchronization filter and the nudging filter, in the paradigmatic context of the two-dimensional (2D) Navier-Stokes equations (NSE) for incompressible fluids. In this setting, the nudging filter can formally be viewed as an affine perturbation of the 2D NSE. Thus, in the degenerate limit of zero nudging parameter, the nudging filter converges to the solution of the 2D NSE. However, when the nudging parameter of the nudging filter is large, the perturbation becomes singular. It is shown that in the singular limit of infinite nudging parameter, the nudging filter converges to the synchronization filter. In establishing this result, the article fills a notable gap in the literature surrounding these algorithms. Numerical experiments are then presented that confirm the theoretical results and probes the issue of selecting a nudging strategy in the presence of observational noise. In this direction, an adaptive nudging strategy is proposed that leverages the insight gained from the relationship between the synchronization filter and the nudging filter that produces measurable improvement over the constant nudging strategy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02646v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Elizabeth Carlson, Aseel Farhat, Vincent R. Martinez, Collin Victor</dc:creator>
    </item>
    <item>
      <title>Adaptive Two-stage Stochastic Programming with an Analysis on Capacity Expansion Planning Problem</title>
      <link>https://arxiv.org/abs/1906.03513</link>
      <description>arXiv:1906.03513v5 Announce Type: replace 
Abstract: Multi-stage stochastic programming is a well-established framework for sequential decision making under uncertainty by seeking policies that are fully adapted to the uncertainty. Often such flexible policies are not desirable, and the decision maker may need to commit to a set of actions for a number of planning periods. Two-stage stochastic programming might be better suited to such settings, where the decisions for all periods are made here-and-now and do not adapt to the uncertainty realized. In this paper, we propose a novel alternative approach, where the stages are not predetermined but part of the optimization problem. Each component of the decision policy has an associated revision point, a period prior to which the decision is predetermined and after which it is revised to adjust to the uncertainty realized thus far. We motivate this setting using the multi-period newsvendor problem by deriving an optimal adaptive policy. We label the proposed approach as adaptive two-stage stochastic programming and provide a generic mixed-integer programming formulation for finite stochastic processes. We show that adaptive two-stage stochastic programming is NP-hard in general. Next, we derive bounds on the value of adaptive two-stage programming in comparison to the two-stage and multi-stage approaches for a specific problem structure inspired by the capacity expansion planning problem. Since directly solving the mixed-integer linear program associated with the adaptive two-stage approach might be very costly for large instances, we propose several heuristic solution algorithms based on the bound analysis. We provide approximation guarantees for these heuristics. Finally, we present an extensive computational study on an electricity generation capacity expansion planning problem and demonstrate the computational and practical impacts of the proposed approach from various perspectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:1906.03513v5</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Beste Basciftci, Shabbir Ahmed, Nagi Gebraeel</dc:creator>
    </item>
    <item>
      <title>Sparse decompositions of nonlinear dynamical systems and applications to moment-sum-of-squares relaxations</title>
      <link>https://arxiv.org/abs/2012.05572</link>
      <description>arXiv:2012.05572v3 Announce Type: replace 
Abstract: In this paper, we propose a general sparse decomposition of dynamical systems provided that the vector field and constraint set possess certain sparse structures, which we call subsystems. This notion is based on causal dependence in the dynamics between the different states. This results in sparse descriptions for fundamental problems from nonlinear dynamical systems: region of attraction, maximum positively invariant set, and global attractor. The decompositions can be paired with any method for computing (outer) approximations of these sets to reduce the computation to lower dimensional systems. This is illustrated by methods from previous work based on infinite-dimensional linear programming. This exhibits one example where the curse of dimensionality is present and hence dimension reduction is crucial. In this context, for polynomial dynamics, we show that these problems admit a sparse sum-of-squares (SOS) approximation with guaranteed convergence such that the number of variables in the largest SOS multiplier is given by the dimension of the largest subsystem appearing in the decomposition. The dimension of such subsystems depends on the sparse structure of the vector field and the constraint set; if the dimension of the largest subsystem is small compared to the ambient dimension, this allows for a significant reduction in the computation time of the SOS approximations. Numerical examples accompany the approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2012.05572v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Corbinian Schlosser, Milan Korda</dc:creator>
    </item>
    <item>
      <title>The Service Rate Region Polytope</title>
      <link>https://arxiv.org/abs/2303.04021</link>
      <description>arXiv:2303.04021v2 Announce Type: replace 
Abstract: We investigate the properties of a family of polytopes that naturally arise in connection with a problem in distributed data storage, namely service rate region polytopes. The service rate region of a distributed coded system describes the data access requests that the underlying system can support. In this paper, we study the polytope structure of the service rate region with the primary goal of describing its geometric shape and properties. We achieve so by introducing various structural parameters of the service rate region and establishing upper and lower bounds for them. The techniques we apply in this paper range from coding theory to optimization. One of our main results shows that every rational point of the service rate region has a so-called rational allocation, answering an open question in the research area.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.04021v2</guid>
      <category>math.OC</category>
      <category>cs.IT</category>
      <category>math.CO</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gianira N. Alfarano, Altan B. Kilic, Alberto Ravagnani, Emina Soljanin</dc:creator>
    </item>
    <item>
      <title>Galerkin-like Method for Integro-Differential Inclusions with applications to Volterra Sweeping processes</title>
      <link>https://arxiv.org/abs/2306.07821</link>
      <description>arXiv:2306.07821v2 Announce Type: replace 
Abstract: In this paper, we develop the Galerkin-like method to address first-order integro-differential inclusions. Under compactness or monotonicity conditions, we obtain new results for the existence of solutions for this class of problems, which generalize existing results in the literature and provide new insights for differential inclusions with an unbounded right-hand side. The effectiveness of the proposed approach is illustrated by presenting new existence results for nonconvex state-dependent Volterra sweeping processes, where the right-hand side is unbounded, and the classical theory of differential inclusions is not applicable. This is the first result of its kind.
  The paper concludes with an application to the existence of an optimal control problem governed by nonconvex state-dependent Volterra sweeping processes in finite dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.07821v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pedro P\'erez-Aros, Manuel Torres-Valdebenito, Emilio Vilches</dc:creator>
    </item>
    <item>
      <title>Optimality Conditions for Interval-Valued Optimization Problems on Riemannian Manifolds Under a Total Order Relation</title>
      <link>https://arxiv.org/abs/2309.09396</link>
      <description>arXiv:2309.09396v2 Announce Type: replace 
Abstract: This article explores fundamental properties of convex interval-valued functions defined on Riemannian manifolds. The study employs generalized Hukuhara directional differentiability to derive KKT-type optimality conditions for an interval-valued optimization problem on Riemannian manifolds. Based on type of functions involved in optimization problems, we consider the following cases:
  1. objective function as well as constraints are real-valued;
  2. objective function is interval-valued, and constraints are real-valued;
  3. objective function as well as constraints are interval-valued.
  The whole theory is justified with the help of examples. The order relation that we use throughout the paper is a total order relation defined on the collection of all closed and bounded intervals in $\mathbb{R}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.09396v2</guid>
      <category>math.OC</category>
      <category>math.DG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hilal Ahmad Bhat, Akhlad Iqbal, Mahwash Aftab</dc:creator>
    </item>
    <item>
      <title>Fidelity and interruption control for expensive constrained multi-fidelity blackbox optimization</title>
      <link>https://arxiv.org/abs/2312.13128</link>
      <description>arXiv:2312.13128v2 Announce Type: replace 
Abstract: This work introduces a novel blackbox optimization algorithm for computationally expensive constrained multi-fidelity problems. When applying a direct search method to such problems, the scarcity of feasible points may lead to numerous costly evaluations spent on infeasible points. Our proposed fidelity and interruption controlled optimization algorithm addresses this issue by leveraging multi-fidelity information, allowing for premature interruption of an evaluation when a point is estimated to be infeasible. These estimations are controlled by a biadjacency matrix, for which we propose a construction. The proposed method acts as an intermediary component bridging any non multi-fidelity direct search solver and a multi-fidelity blackbox problem, giving the user freedom of choice for the solver. A series of computational tests are conducted to validate the approach. The results show a significant improvement in solution quality when an initial feasible starting point is provided. When this condition is not met, the outcomes are contingent upon specific properties of the blackbox.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.13128v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>St\'ephane Alarie, Charles Audet, Miguel Diago, S\'ebastien Le Digabel, Xavier Lebeuf</dc:creator>
    </item>
    <item>
      <title>The computation of approximate feedback Stackelberg equilibria in multi-player nonlinear constrained dynamic games</title>
      <link>https://arxiv.org/abs/2401.15745</link>
      <description>arXiv:2401.15745v5 Announce Type: replace 
Abstract: Solving feedback Stackelberg games with nonlinear dynamics and coupled constraints, a common scenario in practice, presents significant challenges. This work introduces an efficient method for computing approximate local feedback Stackelberg equilibria in multi-player general-sum dynamic games, with continuous state and action spaces. Different from existing (approximate) dynamic programming solutions that are primarily designed for unconstrained problems, our approach involves reformulating a feedback Stackelberg dynamic game into a sequence of nested optimization problems, enabling the derivation of Karush-Kuhn-Tucker (KKT) conditions and the establishment of a second-order sufficient condition for local feedback Stackelberg equilibria. We propose a Newton-style primal-dual interior point method for solving constrained linear quadratic (LQ) feedback Stackelberg games, offering provable convergence guarantees. Our method is further extended to compute local feedback Stackelberg equilibria for more general nonlinear games by iteratively approximating them using LQ games, ensuring that their KKT conditions are locally aligned with those of the original nonlinear games. We prove the exponential convergence of our algorithm in constrained nonlinear games. In a feedback Stackelberg game with nonlinear dynamics and (nonconvex) coupled costs and constraints, our experimental results reveal the algorithm's ability to handle infeasible initial conditions and achieve exponential convergence towards an approximate local feedback Stackelberg equilibrium.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.15745v5</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jingqi Li, Somayeh Sojoudi, Claire Tomlin, David Fridovich-Keil</dc:creator>
    </item>
    <item>
      <title>Universal subgradient and proximal bundle methods for convex and strongly convex hybrid composite optimization</title>
      <link>https://arxiv.org/abs/2407.10073</link>
      <description>arXiv:2407.10073v2 Announce Type: replace 
Abstract: This paper develops two parameter-free methods for solving convex and strongly convex hybrid composite optimization problems, namely, a composite subgradient type method and a proximal bundle type method. Both functional and stationary complexity bounds for the two methods are established in terms of the unknown strong convexity parameter. To the best of our knowledge, the two proposed methods are the first universal methods for solving hybrid strongly convex composite optimization problems that do not rely on any restart scheme nor require the knowledge of the optimal value.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10073v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vincent Guigues, Jiaming Liang, Renato D. C. Monteiro</dc:creator>
    </item>
    <item>
      <title>Explicit solution to an optimal two-player switching game in infinite horizon</title>
      <link>https://arxiv.org/abs/2407.20913</link>
      <description>arXiv:2407.20913v2 Announce Type: replace 
Abstract: We consider a problem in which two decision makers have each, a set of possible decisions they can make at each time. Each decision implies a given random payoff. We choose the payoff to be a functional of a one-dimensional It\^o diffusion. At each time, they can switch from a decision to another, and switching incurs a cost. The first decision maker's objective is to select a sequence of switching times that maximizes the associated expected discounted payoff flow, while the second decision maker's objective is to select a sequence of switching times that minimizes the associated expected discounted payoff flow. The strategies of both decision makers are interconnected in the sense that the random payoff flow of one of the decision makers depends on the strategy of the other decision maker. We characterize the switching regions which reduce the switching problem into one of finding a finite number of threshold values in state process that would trigger switchings and then derive an explicit solution to this problem in the case where the functional of the diffusion process is identical for each regime, while the diffusion operators are different together with the assumption of possibly negative costs. We extend our work by giving a numerical procedure to compute threshold values in case we know their qualitative structure and finally we illustrate our results by numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.20913v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Brahim El Asri, Magnoud\'ewa Paka</dc:creator>
    </item>
    <item>
      <title>Morse inequalities for ordered eigenvalues of generic self-adjoint families</title>
      <link>https://arxiv.org/abs/2304.04331</link>
      <description>arXiv:2304.04331v3 Announce Type: replace-cross 
Abstract: In many applied problems one seeks to identify and count the critical points of a particular eigenvalue of a smooth parametric family of self-adjoint matrices, with the parameter space often being known and simple, such as a torus. Among particular settings where such a question arises are the Floquet--Bloch decomposition of periodic Schr\"odinger operators, topology of potential energy surfaces in quantum chemistry, spectral optimization problems such as minimal spectral partitions of manifolds, as well as nodal statistics of graph eigenfunctions. In contrast to the classical Morse theory dealing with smooth functions, the eigenvalues of families of self-adjoint matrices are not smooth at the points corresponding to repeated eigenvalues (called, depending on the application and on the dimension of the parameter space, the diabolical/Dirac/Weyl points or the conical intersections).
  This work develops a procedure for associating a Morse polynomial to a point of eigenvalue multiplicity; it utilizes the assumptions of smoothness and self-adjointness of the family to provide concrete answers. In particular, we define the notions of non-degenerate topologically critical point and generalized Morse family, establish that generalized Morse families are generic in an appropriate sense, establish a differential first-order conditions for criticality, as well as compute the local contribution of a topologically critical point to the Morse polynomial. Remarkably, the non-smooth contribution to the Morse polynomial turns out to depend only on the size of the eigenvalue multiplicity and the relative position of the eigenvalue of interest and not on the particulars of the operator family; it is expressed in terms of the homologies of Grassmannians.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.04331v3</guid>
      <category>math.SP</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gregory Berkolaiko, Igor Zelenko</dc:creator>
    </item>
    <item>
      <title>Fun with Flags: Robust Principal Directions via Flag Manifolds</title>
      <link>https://arxiv.org/abs/2401.04071</link>
      <description>arXiv:2401.04071v4 Announce Type: replace-cross 
Abstract: Principal component analysis (PCA), along with its extensions to manifolds and outlier contaminated data, have been indispensable in computer vision and machine learning. In this work, we present a unifying formalism for PCA and its variants, and introduce a framework based on the flags of linear subspaces, ie a hierarchy of nested linear subspaces of increasing dimension, which not only allows for a common implementation but also yields novel variants, not explored previously. We begin by generalizing traditional PCA methods that either maximize variance or minimize reconstruction error. We expand these interpretations to develop a wide array of new dimensionality reduction algorithms by accounting for outliers and the data manifold. To devise a common computational approach, we recast robust and dual forms of PCA as optimization problems on flag manifolds. We then integrate tangent space approximations of principal geodesic analysis (tangent-PCA) into this flag-based framework, creating novel robust and dual geodesic PCA variations. The remarkable flexibility offered by the 'flagification' introduced here enables even more algorithmic variants identified by specific flag types. Last but not least, we propose an effective convergent solver for these flag-formulations employing the Stiefel manifold. Our empirical results on both real-world and synthetic scenarios, demonstrate the superiority of our novel algorithms, especially in terms of robustness to outliers on manifolds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.04071v4</guid>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>math.DG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nathan Mankovich, Gustau Camps-Valls, Tolga Birdal</dc:creator>
    </item>
    <item>
      <title>Optimal Control of Underdamped Systems: An Analytic Approach</title>
      <link>https://arxiv.org/abs/2403.00679</link>
      <description>arXiv:2403.00679v2 Announce Type: replace-cross 
Abstract: Optimal control theory deals with finding protocols to steer a system between assigned initial and final states, such that a trajectory-dependent cost function is minimized. The application of optimal control to stochastic systems is an open and challenging research frontier, with a spectrum of applications ranging from stochastic thermodynamics to biophysics and data science. Among these, the design of nanoscale electronic components motivates the study of underdamped dynamics.
  In this work, we develop analytic techniques to determine protocols steering finite time transitions at a minimum thermodynamic cost for stochastic underdamped dynamics. As cost functions, we consider two paradigmatic thermodynamic indicators. The first is the Kullback-Leibler divergence between the probability measure of the controlled process and that of a reference process. The corresponding optimization problem is the underdamped version of the Schr\"odinger diffusion problem that has been widely studied in the overdamped regime. The second is the mean entropy production during the transition, corresponding to the second law of modern stochastic thermodynamics. For transitions between Gaussian states, we show that optimal protocols satisfy a Lyapunov equation, a central tool in stability analysis of dynamical systems. For transitions between states described by general Maxwell-Boltzmann distributions, we introduce an infinite-dimensional version of the Poincar\'e-Linstedt multiscale perturbation theory around the overdamped limit. This technique fundamentally improves the standard multiscale expansion. Indeed, it enables the explicit computation of momentum cumulants, whose variation in time is a distinctive trait of underdamped dynamics and is directly accessible to experimental observation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.00679v2</guid>
      <category>cond-mat.stat-mech</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julia Sanders, Marco Baldovin, Paolo Muratore-Ginanneschi</dc:creator>
    </item>
    <item>
      <title>Distributionally Robust Policy and Lyapunov-Certificate Learning</title>
      <link>https://arxiv.org/abs/2404.03017</link>
      <description>arXiv:2404.03017v2 Announce Type: replace-cross 
Abstract: This article presents novel methods for synthesizing distributionally robust stabilizing neural controllers and certificates for control systems under model uncertainty. A key challenge in designing controllers with stability guarantees for uncertain systems is the accurate determination of and adaptation to shifts in model parametric uncertainty during online deployment. We tackle this with a novel distributionally robust formulation of the Lyapunov derivative chance constraint ensuring a monotonic decrease of the Lyapunov certificate. To avoid the computational complexity involved in dealing with the space of probability measures, we identify a sufficient condition in the form of deterministic convex constraints that ensures the Lyapunov derivative constraint is satisfied. We integrate this condition into a loss function for training a neural network-based controller and show that, for the resulting closed-loop system, the global asymptotic stability of its equilibrium can be certified with high confidence, even with Out-of-Distribution (OoD) model uncertainties. To demonstrate the efficacy and efficiency of the proposed methodology, we compare it with an uncertainty-agnostic baseline approach and several reinforcement learning approaches in two control problems in simulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03017v2</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Kehan Long, Jorge Cortes, Nikolay Atanasov</dc:creator>
    </item>
    <item>
      <title>cDVAE: Multimodal Generative Conditional Diffusion Guided by Variational Autoencoder Latent Embedding for Virtual 6D Phase Space Diagnostics</title>
      <link>https://arxiv.org/abs/2407.20218</link>
      <description>arXiv:2407.20218v5 Announce Type: replace-cross 
Abstract: Imaging the 6D phase space of a beam in a particle accelerator in a single shot is currently impossible. Single shot beam measurements only exist for certain 2D beam projections and these methods are destructive. A virtual diagnostic that can generate an accurate prediction of a beam's 6D phase space would be incredibly useful for precisely controlling the beam. In this work, a generative conditional diffusion-based approach to creating a virtual diagnostic of all 15 unique 2D projections of a beam's 6D phase space is developed. The diffusion process is guided by a combination of scalar parameters and images that are converted to low-dimensional latent vector representation by a variational autoencoder (VAE). We demonstrate that conditional diffusion guided by VAE (cDVAE) can accurately reconstruct all 15 of the unique 2D projections of a charge particle beam's 6 phase space for the HiRES compact accelerator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.20218v5</guid>
      <category>physics.acc-ph</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Scheinker</dc:creator>
    </item>
    <item>
      <title>Distributed Adaptive Time-Varying Optimization with Global Asymptotic Convergence</title>
      <link>https://arxiv.org/abs/2407.20897</link>
      <description>arXiv:2407.20897v2 Announce Type: replace-cross 
Abstract: In this note, we study distributed time-varying optimization for a multi-agent system. We first focus on a class of time-varying quadratic cost functions, and develop a new distributed algorithm that integrates an average estimator and an adaptive optimizer, with both bridged by a Dead Zone Algorithm. Based on a composite Lyapunov function and finite escape-time analysis, we prove the closed-loop global asymptotic convergence to the optimal solution under mild assumptions. Particularly, the introduction of the estimator relaxes the requirement for the Hessians of cost functions, and the integrated design eliminates the waiting time required in the relevant literature for estimating global parameter during algorithm implementation. We then extend this result to a more general class of time-varying cost functions. Two examples are used to verify the proposed designs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.20897v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liangze Jiang, Zheng-Guang Wu, Lei Wang</dc:creator>
    </item>
    <item>
      <title>Randomized Controlled Trials of Service Interventions: The Impact of Capacity Constraints</title>
      <link>https://arxiv.org/abs/2407.21322</link>
      <description>arXiv:2407.21322v2 Announce Type: replace-cross 
Abstract: Randomized controlled trials (RCTs), or experiments, are the gold standard for intervention evaluation. However, the main appeal of RCTs, the clean identification of causal effects, can be compromised by interference, when one subject's treatment assignment can influence another subject's behavior or outcomes. In this paper, we formalise and study a type of interference stemming from the operational implementation of a subclass of interventions we term Service Interventions (SIs): interventions that include an on-demand service component provided by a costly and limited resource (e.g., healthcare providers or teachers).
  We show that in such a system, the capacity constraints induce dependencies across experiment subjects, where an individual may need to wait before receiving the intervention. By modeling these dependencies using a queueing system, we show how increasing the number of subjects without increasing the capacity of the system can lead to a nonlinear decrease in the treatment effect size. This has implications for conventional power analysis and recruitment strategies: increasing the sample size of an RCT without appropriately expanding capacity can decrease the study's power. To address this issue, we propose a method to jointly select the system capacity and number of users using the square root staffing rule from queueing theory. We show how incorporating knowledge of the queueing structure can help an experimenter reduce the amount of capacity and number of subjects required while still maintaining high power. In addition, our analysis of congestion-driven interference provides one concrete mechanism to explain why similar protocols can result in different RCT outcomes and why promising interventions at the RCT stage may not perform well at scale.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.21322v2</guid>
      <category>stat.ME</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Justin Boutilier, Jonas Oddur Jonasson, Hannah Li, Erez Yoeli</dc:creator>
    </item>
  </channel>
</rss>
