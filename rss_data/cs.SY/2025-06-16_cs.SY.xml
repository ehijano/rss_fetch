<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SY updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SY</link>
    <description>cs.SY updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SY" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 16 Jun 2025 04:00:12 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Smart Predict-Then-Control: Integrating identification and control via decision regret</title>
      <link>https://arxiv.org/abs/2506.11279</link>
      <description>arXiv:2506.11279v1 Announce Type: new 
Abstract: This paper presents Smart Predict-Then-Control (SPC) framework for integrating system identification and control. This novel SPC framework addresses the limitations of traditional methods, the unaligned modeling error and control cost. It leverages decision regret to prioritize control-relevant dynamics, optimizing prediction errors based on their impact on control performance. Furthermore, the existence of guarantees on regret bounds are theoretically proved. The proposed SPC is validated on both linear and nonlinear systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11279v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiachen Li, Shihao Li, Dongmei Chen</dc:creator>
    </item>
    <item>
      <title>Influence Functions for Data Attribution in Linear System Identification and LQR Control</title>
      <link>https://arxiv.org/abs/2506.11293</link>
      <description>arXiv:2506.11293v1 Announce Type: new 
Abstract: Understanding the influence of individual training data points is crucial for developing reliable machine learning-based control systems. However, conventional methods like leave-one-out retraining are computationally infeasible for large datasets. This paper introduces a framework using influence functions to efficiently approximate the impact of removing specific training trajectories on both learned system dynamics and downstream control performance. We formulate two influence functions(IF): IF1, which estimates the effect on the predictive accuracy of a learned linear dynamics model, and IF2, which quantifies the subsequent impact on the cost of a Linear Quadratic Regulator (LQR) controller designed using these learned dynamics. These involve tracing sensitivities through the Discrete Algebraic Riccati Equation (DARE) solution. We empirically validate our approach on simulated linear systems analogous to robotic manipulators. Results show strong positive correlations between influence predictions and ground truth changes obtained via retraining. Our framework provides a computationally tractable method for data attribution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11293v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiachen Li, Shihao Li, Jiamin Xu, Soovadeep Bakshi, Dongmei Chen</dc:creator>
    </item>
    <item>
      <title>A Hybrid Adaptive Nash Equilibrium Solver for Distributed Multi-Agent Systems with Game-Theoretic Jump Triggering</title>
      <link>https://arxiv.org/abs/2506.11304</link>
      <description>arXiv:2506.11304v1 Announce Type: new 
Abstract: This paper presents a hybrid adaptive Nash equilibrium solver for distributed multi-agent systems incorporating game-theoretic jump triggering mechanisms. The approach addresses fundamental scalability and computational challenges in multi-agent hybrid systems by integrating distributed game-theoretic optimization with systematic hybrid system design. A novel game-theoretic jump triggering mechanism coordinates discrete mode transitions across multiple agents while maintaining distributed autonomy. The Hybrid Adaptive Nash Equilibrium Solver (HANES) algorithm integrates these methodologies. Sufficient conditions establish exponential convergence to consensus under distributed information constraints. The framework provides rigorous stability guarantees through coupled Hamilton-Jacobi-Bellman equations while enabling rapid emergency response capabilities through coordinated jump dynamics. Simulation studies in pursuit-evasion and leader-follower consensus scenarios demonstrate significant improvements in convergence time, computational efficiency, and scalability compared to existing centralized and distributed approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11304v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiuyu Miao, Zhigang Wu</dc:creator>
    </item>
    <item>
      <title>Deception Against Data-Driven Linear-Quadratic Control</title>
      <link>https://arxiv.org/abs/2506.11373</link>
      <description>arXiv:2506.11373v1 Announce Type: new 
Abstract: Deception is a common defense mechanism against adversaries with an information disadvantage. It can force such adversaries to select suboptimal policies for a defender's benefit. We consider a setting where an adversary tries to learn the optimal linear-quadratic attack against a system, the dynamics of which it does not know. On the other end, a defender who knows its dynamics exploits its information advantage and injects a deceptive input into the system to mislead the adversary. The defender's aim is to then strategically design this deceptive input: it should force the adversary to learn, as closely as possible, a pre-selected attack that is different from the optimal one. We show that this deception design problem boils down to the solution of a coupled algebraic Riccati and a Lyapunov equation which, however, are challenging to tackle analytically. Nevertheless, we use a block successive over-relaxation algorithm to extract their solution numerically and prove the algorithm's convergence under certain conditions. We perform simulations on a benchmark aircraft, where we showcase how the proposed algorithm can mislead adversaries into learning attacks that are less performance-degrading.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11373v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Filippos Fotiadis, Aris Kanellopoulos, Kyriakos G. Vamvoudakis, Ufuk Topcu</dc:creator>
    </item>
    <item>
      <title>Design and Simulation of Vehicle Motion Tracking System using a Youla Controller Output Observation System</title>
      <link>https://arxiv.org/abs/2506.11386</link>
      <description>arXiv:2506.11386v1 Announce Type: new 
Abstract: This paper presents a novel linear robust Youla controller output observation system for tracking vehicle motion trajectories using a simple nonlinear kinematic vehicle model, supplemented with positional data from a radar sensor. The proposed system operates across the full vehicle trajectory range with only three linear observers, improving upon previous methods that required four nonlinear observers. To ensure smooth transitions between Youla controllers and observers, a switching technique is introduced, preventing bumps during controller changes. The proposed observer system is evaluated through simulations, demonstrating accurate and robust estimation of longitudinal and lateral positions, vehicle orientation, and velocity from sensor measurements during various standard driving maneuvers. Results are provided for different driving scenarios, including lane changes and intersection crossings, where significant changes in vehicle orientation occur. The novelty of this work lies in the first application of a Youla controller output observer for vehicle tracking estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11386v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rongfei Li, Francis Assadian. Iman Soltani</dc:creator>
    </item>
    <item>
      <title>Compositional and Equilibrium-Free Conditions for Power System Stability -- Part I: Theory</title>
      <link>https://arxiv.org/abs/2506.11406</link>
      <description>arXiv:2506.11406v1 Announce Type: new 
Abstract: Traditional centralized stability analysis struggles with scalability in large complex modern power grids. This two-part paper proposes a compositional and equilibrium-free approach to analyzing power system stability. In Part I, we prove that using equilibrium-free local conditions we can certificate system-wide stability of power systems with heterogeneous nonlinear devices and structure-preserving lossy networks. This is built on a recently developed notion of delta dissipativity, which yields local stability conditions without knowing the system-wide equilibrium. As a consequence, our proposed theory can certificate stability of equilibria set rather than single equilibrium. In Part I, we verify our theory and demonstrate promising implications by the single machine single load benchmark, which helps to better explain the compositional and equilibrium-set-oriented stability analysis. Part II of this paper will provide methods for applying our theory to complex power grids, together with case studies across a wide range of system scales. Our results enable a more scalable and adaptable approach to stability analysis. It also sheds light on how to regulate grid-connected devices to guarantee system-wide stability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11406v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peng Yang, Xiaoyu Peng, Xi Ru, Hua Geng, Feng Liu</dc:creator>
    </item>
    <item>
      <title>Compositional and Equilibrium-Free Conditions for Power System Stability -- Part II: Method and Application</title>
      <link>https://arxiv.org/abs/2506.11411</link>
      <description>arXiv:2506.11411v1 Announce Type: new 
Abstract: This two-part paper proposes a compositional and equilibrium-free approach to analyzing power system stability. In Part I, we have established the stability theory and proposed stability conditions based on the delta dissipativity. In Part II, we focus on methods for applying our theory to complex power grids. We first propose a method to verify the local condition, i.e., delta dissipativity, for heterogeneous devices in power systems. Then, we propose a method to verify the coupling condition based on Alternating Direction Method of Multipliers (ADMM). Finally, we investigate three applications of our theory including stability assessment toward multiple equilibria, stability assessment under varying operating conditions, and a distributed computing framework. Case studies on modified IEEE 9-bus, 39-bus, and 118-bus benchmarks well verified our theory and methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11411v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peng Yang, Yifan Su, Xiaoyu Peng, Hua Geng, Feng Liu</dc:creator>
    </item>
    <item>
      <title>Symmetric Sliding-Mode Control of Grid-Forming Inverters With Controllable Region Under AC and DC Sides Varying</title>
      <link>https://arxiv.org/abs/2506.11504</link>
      <description>arXiv:2506.11504v1 Announce Type: new 
Abstract: Conventional grid-forming (GFM) controls often entangle voltage formation with power flow and dc-source dynamics, which can degrade voltage tracking performance and stability under grid disturbances, load transients, and dc-side perturbations. To address this issue, a symmetric sliding-mode control (SSMC) method is developed and its explicit voltage controllable region is derived. It illustrates how much ac-side power dynamics and dc-link voltage varying can be decoupled from the voltage regulation task, which helps predict when the entangling appears. While conventional sliding-mode controls address voltage-tracking error through complex sliding surface designs, repetitive correction techniques or special reaching laws, this work identifies that the error at power-line frequency primarily stem from the asymmetry property of inverters with the delay effect and the computational inaccuracy. Guided by this insight, a symmetric compensation structure is proposed, which avoids added design complexity and directly mitigates low-frequency voltage tracking errors. Furthermore, the control design is supported by a physical and quantitative explanation, aiding in parameter tuning. Simulation and experimental results demonstrate that the proposed method achieves faster tracking responses-on the order of hundreds of microseconds-while maintaining robust and more accurate tracking under both dc-link voltage and ac-side current variations. Conventional grid-forming and classical sliding-mode controllers, which handle these disturbances separately, cannot match this combined speed and robustness. Furthermore, the voltage controllability analysis is explicitly verified.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11504v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Qianxi Tang, Li Peng</dc:creator>
    </item>
    <item>
      <title>Vectorized Sparse Second-Order Forward Automatic Differentiation for Optimal Control Direct Methods</title>
      <link>https://arxiv.org/abs/2506.11537</link>
      <description>arXiv:2506.11537v1 Announce Type: new 
Abstract: Direct collocation methods are widely used numerical techniques for solving optimal control problems. The discretization of continuous-time optimal control problems transforms them into large-scale nonlinear programming problems, which require efficient computation of first- and second-order derivatives. To achieve computational efficiency, these derivatives must be computed in sparse and vectorized form, exploiting the problem's inherent sparsity structure. This paper presents a vectorized sparse second-order forward automatic differentiation framework designed for direct collocation methods in optimal control. The method exploits the problem's sparse structure to efficiently compute derivatives across multiple mesh points. By incorporating both scalar and vector nodes within the expression graph, the approach enables effective parallelization and optimized memory access patterns while maintaining flexibility for complex problems. The methodology is demonstrated through application to a prototype optimal control problem. A complete implementation for multi-phase optimal control problems is available as an open-source package, supporting both theoretical research and practical applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11537v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yilin Zou, Fanghua Jiang</dc:creator>
    </item>
    <item>
      <title>Harvest and Jam: Optimal Self-Sustainable Jamming Attacks against Remote State Estimation</title>
      <link>https://arxiv.org/abs/2506.11606</link>
      <description>arXiv:2506.11606v1 Announce Type: new 
Abstract: This paper considers the optimal power allocation of a jamming attacker against remote state estimation. The attacker is self-sustainable and can harvest energy from the environment to launch attacks. The objective is to carefully allocate its attack power to maximize the estimation error at the fusion center. Regarding the attacker's knowledge of the system, two cases are discussed: (i) perfect channel knowledge and (ii) unknown channel model. For both cases, we formulate the problem as a Markov decision process (MDP) and prove the existence of an optimal deterministic and stationary policy. Moreover, for both cases, we develop algorithms to compute the allocation policy and demonstrate that the proposed algorithms for both cases converge to the optimal policy as time goes to infinity. Additionally, the optimal policy exhibits certain structural properties that can be leveraged to accelerate both algorithms. Numerical examples are given to illustrate the main results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11606v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuxing Zhong, Yuzhe Li, Daniel E. Quevedo, Ling Shi</dc:creator>
    </item>
    <item>
      <title>5G-Enabled Smart Prosthetic Hand: Connectivity Analysis and Assessment</title>
      <link>https://arxiv.org/abs/2506.11729</link>
      <description>arXiv:2506.11729v1 Announce Type: new 
Abstract: In this paper, we demonstrate a proof-of-concept implementation of a framework for the development of edge-connected prosthetic systems. The framework is composed of a bionic hand equipped with a camera and connected to a Jetson device that establishes a wireless connection to the edge server, processing the received video stream and feeding back the inferred information about the environment. The hand-edge server connection is obtained either through a direct 5G link, where the edge server also functions as a 5G base station, or through a WiFi link. We evaluate the latency of closing the control loop in the system, showing that, in a realistic usage scenario, the connectivity and computation delays combined are well below 125 ms, which falls into the natural control range. To the best of our knowledge, this is the first analysis showcasing the feasibility of a 5G-enabled prosthetic system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11729v1</guid>
      <category>eess.SY</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ozan Karaali, Hossam Farag, Strahinja Dosen, Cedomir Stefanovic</dc:creator>
    </item>
    <item>
      <title>A Theory-driven Interpretation and Elaboration of Verification and Validation</title>
      <link>https://arxiv.org/abs/2506.10997</link>
      <description>arXiv:2506.10997v1 Announce Type: cross 
Abstract: This paper presents a formal theory of verification and validation (V&amp;V) within systems engineering, grounded in the axiom that V&amp;V are fundamentally knowledge-building activities. Using dynamic epistemic modal logic, we develop precise definitions of verification and validation, articulating their roles in confirming and contextualizing knowledge about systems. The theory formalizes the interplay between epistemic states, evidence, and reasoning processes, allowing for the derivation of theorems that clarify the conceptual underpinnings of V&amp;V. By providing a formal foundation, this work addresses ambiguities in traditional V&amp;V practices, offering a structured framework to enhance precision and consistency in systems engineering methodologies. The insights gained have implications for both academic research and practical applications, fostering a deeper understanding of V&amp;V as critical components of engineering knowledge generation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10997v1</guid>
      <category>cs.SE</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hanumanthrao Kannan, Alejandro Salado</dc:creator>
    </item>
    <item>
      <title>Enabling On-Device Medical AI Assistants via Input-Driven Saliency Adaptation</title>
      <link>https://arxiv.org/abs/2506.11105</link>
      <description>arXiv:2506.11105v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) have significant impact on the healthcare scenarios but remain prohibitively large for deployment in real-time, resource-constrained environments such as edge devices. In this work, we introduce a novel medical assistant system, optimized through our general-purpose compression framework, which tailors Large Language Models (LLMs) for deployment in specialized domains. By measuring neuron saliency on domain-specific data, our method can aggressively prune irrelevant neurons, reducing model size while preserving performance. Following pruning, we apply post-training quantization to further reduce the memory footprint, and evaluate the compressed model across medical benchmarks including MedMCQA, MedQA, and PubMedQA. We also deploy the 50\% compressed Gemma and the 67\% compressed LLaMA3 models on Jetson Orin Nano (18.7W peak) and Raspberry Pi 5 (6.3W peak), achieving real-time, energy-efficient inference under hardware constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11105v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.AR</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Uttej Kallakurik, Edward Humes, Rithvik Jonna, Xiaomin Lin, Tinoosh Mohsenin</dc:creator>
    </item>
    <item>
      <title>Beyond Formal Semantics for Capabilities and Skills: Model Context Protocol in Manufacturing</title>
      <link>https://arxiv.org/abs/2506.11180</link>
      <description>arXiv:2506.11180v1 Announce Type: cross 
Abstract: Explicit modeling of capabilities and skills -- whether based on ontologies, Asset Administration Shells, or other technologies -- requires considerable manual effort and often results in representations that are not easily accessible to Large Language Models (LLMs). In this work-in-progress paper, we present an alternative approach based on the recently introduced Model Context Protocol (MCP). MCP allows systems to expose functionality through a standardized interface that is directly consumable by LLM-based agents. We conduct a prototypical evaluation on a laboratory-scale manufacturing system, where resource functions are made available via MCP. A general-purpose LLM is then tasked with planning and executing a multi-step process, including constraint handling and the invocation of resource functions via MCP. The results indicate that such an approach can enable flexible industrial automation without relying on explicit semantic models. This work lays the basis for further exploration of external tool integration in LLM-driven production systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11180v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luis Miguel Vieira da Silva, Aljosha K\"ocher, Felix Gehlhoff</dc:creator>
    </item>
    <item>
      <title>Can Time-Series Foundation Models Perform Building Energy Management Tasks?</title>
      <link>https://arxiv.org/abs/2506.11250</link>
      <description>arXiv:2506.11250v1 Announce Type: cross 
Abstract: Building energy management (BEM) tasks require processing and learning from a variety of time-series data. Existing solutions rely on bespoke task- and data-specific models to perform these tasks, limiting their broader applicability. Inspired by the transformative success of Large Language Models (LLMs), Time-Series Foundation Models (TSFMs), trained on diverse datasets, have the potential to change this. Were TSFMs to achieve a level of generalizability across tasks and contexts akin to LLMs, they could fundamentally address the scalability challenges pervasive in BEM. To understand where they stand today, we evaluate TSFMs across four dimensions: (1) generalizability in zero-shot univariate forecasting, (2) forecasting with covariates for thermal behavior modeling, (3) zero-shot representation learning for classification tasks, and (4) robustness to performance metrics and varying operational conditions. Our results reveal that TSFMs exhibit \emph{limited} generalizability, performing only marginally better than statistical models on unseen datasets and modalities for univariate forecasting. Similarly, inclusion of covariates in TSFMs does not yield performance improvements, and their performance remains inferior to conventional models that utilize covariates. While TSFMs generate effective zero-shot representations for downstream classification tasks, they may remain inferior to statistical models in forecasting when statistical models perform test-time fitting. Moreover, TSFMs forecasting performance is sensitive to evaluation metrics, and they struggle in more complex building environments compared to statistical models. These findings underscore the need for targeted advancements in TSFM design, particularly their handling of covariates and incorporating context and temporal dynamics into prediction mechanisms, to develop more adaptable and scalable solutions for BEM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11250v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ozan Baris Mulayim, Pengrui Quan, Liying Han, Xiaomin Ouyang, Dezhi Hong, Mario Berg\'es, Mani Srivastava</dc:creator>
    </item>
    <item>
      <title>Sensor Model Identification via Simultaneous Model Selection and State Variable Determination</title>
      <link>https://arxiv.org/abs/2506.11263</link>
      <description>arXiv:2506.11263v1 Announce Type: cross 
Abstract: We present a method for the unattended gray-box identification of sensor models commonly used by localization algorithms in the field of robotics. The objective is to determine the most likely sensor model for a time series of unknown measurement data, given an extendable catalog of predefined sensor models. Sensor model definitions may require states for rigid-body calibrations and dedicated reference frames to replicate a measurement based on the robot's localization state. A health metric is introduced, which verifies the outcome of the selection process in order to detect false positives and facilitate reliable decision-making. In a second stage, an initial guess for identified calibration states is generated, and the necessity of sensor world reference frames is evaluated. The identified sensor model with its parameter information is then used to parameterize and initialize a state estimation application, thus ensuring a more accurate and robust integration of new sensor elements. This method is helpful for inexperienced users who want to identify the source and type of a measurement, sensor calibrations, or sensor reference frames. It will also be important in the field of modular multi-agent scenarios and modularized robotic platforms that are augmented by sensor modalities during runtime. Overall, this work aims to provide a simplified integration of sensor modalities to downstream applications and circumvent common pitfalls in the usage and development of localization approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11263v1</guid>
      <category>cs.RO</category>
      <category>cs.IT</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <category>math.NA</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christian Brommer, Alessandro Fornasier, Jan Steinbrener, Stephan Weiss</dc:creator>
    </item>
    <item>
      <title>Robust Optimal Task Planning to Maximize Battery Life</title>
      <link>https://arxiv.org/abs/2506.11264</link>
      <description>arXiv:2506.11264v1 Announce Type: cross 
Abstract: This paper proposes a control-oriented optimization platform for autonomous mobile robots (AMRs), focusing on extending battery life while ensuring task completion. The requirement of fast AMR task planning while maintaining minimum battery state of charge, thus maximizing the battery life, renders a bilinear optimization problem. McCormick envelop technique is proposed to linearize the bilinear term. A novel planning algorithm with relaxed constraints is also developed to handle parameter uncertainties robustly with high efficiency ensured. Simulation results are provided to demonstrate the utility of the proposed methods in reducing battery degradation while satisfying task completion requirements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11264v1</guid>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiachen Li, Chu Jian, Feiyang Zhao, Shihao Li, Wei Li, Dongmei Chen</dc:creator>
    </item>
    <item>
      <title>Domain-Constrained Diffusion Models to Synthesize Tabular Data: A Case Study in Power Systems</title>
      <link>https://arxiv.org/abs/2506.11281</link>
      <description>arXiv:2506.11281v1 Announce Type: cross 
Abstract: Growing concerns over privacy, security, and legal barriers are driving the rising demand for synthetic data across domains such as healthcare, finance, and energy. While generative models offer a promising solution to overcome these barriers, their utility depends on the incorporation of domain-specific knowledge. We propose to synthesize data using a guided diffusion model that integrates domain constraints directly into the generative process. We develop the model in the context of power systems, with potential applicability to other domains that involve tabular data. Specifically, we synthesize statistically representative and high-fidelity power flow datasets. To satisfy domain constraints, e.g., Kirchhoff laws, we introduce a gradient-based guidance to steer the sampling trajectory in a feasible direction. Numerical results demonstrate the effectiveness of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11281v1</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Milad Hoseinpour, Vladimir Dvorkin</dc:creator>
    </item>
    <item>
      <title>Decentralized Uplink Adaptive Compression for Cell-Free MIMO with Limited Fronthaul</title>
      <link>https://arxiv.org/abs/2506.11284</link>
      <description>arXiv:2506.11284v1 Announce Type: cross 
Abstract: We study the problem of uplink compression for cell-free multi-input multi-output networks with limited fronthaul capacity. In compress-forward mode, remote radio heads (RRHs) compress the received signal and forward it to a central unit for joint processing. While previous work has focused on a transform-based approach, which optimizes the transform matrix that reduces signals of high dimension to a static pre-determined lower dimension, we propose a rate-based approach that simultaneously finds both dimension and compression adaptively. Our approach accommodates for changes to network traffic and fronthaul limits. Using mutual information as the objective, we obtain the theoretical network capacity for adaptive compression and decouple the expression to enable decentralization. Furthermore, using channel statistics and user traffic density, we show different approaches to compute an efficient representation of side information that summarizes global channel state information and is shared with RRHs to assist compression. While keeping the information exchange overhead low, our decentralized implementation of adaptive compression shows competitive overall network performance compared to a centralized approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11284v1</guid>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zehua Li, Jingjie Wei, Raviraj Adve</dc:creator>
    </item>
    <item>
      <title>WIP: Exploring the Value of a Debugging Cheat Sheet and Mini Lecture in Improving Undergraduate Debugging Skills and Mindset</title>
      <link>https://arxiv.org/abs/2506.11339</link>
      <description>arXiv:2506.11339v1 Announce Type: cross 
Abstract: This work-in-progress research paper explores the efficacy of a small-scale microelectronics debugging education intervention utilizing quasi-experimental design in an introductory microelectronics course for third-year electrical and computer engineering (ECE) students. In the first semester of research, the experimental group attended a debugging "mini lecture" covering two common sources of circuit error and received a debugging cheat sheet with recommendations for testing and hypothesis formation. Across three debugging problems, students in the experimental group were faster by an average of 1:43 and had a 7 percent higher success rate than the control group. Both groups demonstrated a strong general growth mindset while the experimental group also displayed a shift in their debugging mindset by perceiving a greater value towards debugging. Though these differences are not yet statistically significant, the pilot results indicate that a mini-lecture and debugging cheat sheet are steps in the right direction toward improving students' readiness for debugging in the workplace.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11339v1</guid>
      <category>cs.CY</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrew Ash, John Hu</dc:creator>
    </item>
    <item>
      <title>Control Architecture and Design for a Multi-robotic Visual Servoing System in Automated Manufacturing Environment</title>
      <link>https://arxiv.org/abs/2506.11387</link>
      <description>arXiv:2506.11387v1 Announce Type: cross 
Abstract: The use of robotic technology has drastically increased in manufacturing in the 21st century. But by utilizing their sensory cues, humans still outperform machines, especially in micro scale manufacturing, which requires high-precision robot manipulators. These sensory cues naturally compensate for high levels of uncertainties that exist in the manufacturing environment. Uncertainties in performing manufacturing tasks may come from measurement noise, model inaccuracy, joint compliance (e.g., elasticity), etc. Although advanced metrology sensors and high precision microprocessors, which are utilized in modern robots, have compensated for many structural and dynamic errors in robot positioning, a well-designed control algorithm still works as a comparable and cheaper alternative to reduce uncertainties in automated manufacturing. Our work illustrates that a multi-robot control system that simulates the positioning process for fastening and unfastening applications can reduce various uncertainties, which may occur in this process, to a great extent. In addition, most research papers in visual servoing mainly focus on developing control and observation architectures in various scenarios, but few have discussed the importance of the camera's location in the configuration. In a manufacturing environment, the quality of camera estimations may vary significantly from one observation location to another, as the combined effects of environmental conditions result in different noise levels of a single image shot at different locations. Therefore, in this paper, we also propose a novel algorithm for the camera's moving policy so that it explores the camera workspace and searches for the optimal location where the image noise level is minimized.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11387v1</guid>
      <category>cs.RO</category>
      <category>cs.CV</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rongfei Li</dc:creator>
    </item>
    <item>
      <title>Linearly Solving Robust Rotation Estimation</title>
      <link>https://arxiv.org/abs/2506.11547</link>
      <description>arXiv:2506.11547v1 Announce Type: cross 
Abstract: Rotation estimation plays a fundamental role in computer vision and robot tasks, and extremely robust rotation estimation is significantly useful for safety-critical applications. Typically, estimating a rotation is considered a non-linear and non-convex optimization problem that requires careful design. However, in this paper, we provide some new perspectives that solving a rotation estimation problem can be reformulated as solving a linear model fitting problem without dropping any constraints and without introducing any singularities. In addition, we explore the dual structure of a rotation motion, revealing that it can be represented as a great circle on a quaternion sphere surface. Accordingly, we propose an easily understandable voting-based method to solve rotation estimation. The proposed method exhibits exceptional robustness to noise and outliers and can be computed in parallel with graphics processing units (GPUs) effortlessly. Particularly, leveraging the power of GPUs, the proposed method can obtain a satisfactory rotation solution for large-scale($10^6$) and severely corrupted (99$\%$ outlier ratio) rotation estimation problems under 0.5 seconds. Furthermore, to validate our theoretical framework and demonstrate the superiority of our proposed method, we conduct controlled experiments and real-world dataset experiments. These experiments provide compelling evidence supporting the effectiveness and robustness of our approach in solving rotation estimation problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11547v1</guid>
      <category>cs.CV</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yinlong Liu, Tianyu Huang, Zhi-Xin Yang</dc:creator>
    </item>
    <item>
      <title>Development of a Smart Autonomous Irrigation System Using Iot and AI</title>
      <link>https://arxiv.org/abs/2506.11835</link>
      <description>arXiv:2506.11835v1 Announce Type: cross 
Abstract: Agricultural irrigation ensures that the water required for plant growth is delivered to the soil in a controlled manner. However, uncontrolled management can lead to water waste while reducing agricultural productivity. Drip irrigation systems, which have been one of the most efficient methods since the 1970s, are modernised with IoT and artificial intelligence in this study, aiming to both increase efficiency and prevent water waste. The developed system is designed to be applicable to different agricultural production areas and tested with a prototype consisting of 3 rows and 3 columns. The project will commence with the transmission of environmental data from the ESP32 microcontroller to a computer via USB connection, where it will be processed using an LSTM model to perform learning and prediction. The user will be able to control the system manually or delegate it to artificial intelligence through the Blynk application. The system includes ESP32 microcontroller, rain and soil moisture sensors, DHT11 temperature and humidity sensor, relays, solenoid valves and 12V power supply. The system aims to increase labour productivity and contribute to the conservation of water resources by enabling agricultural and greenhouse workers to focus on processes other than irrigation. In addition, the developed autonomous irrigation system will support the spread of sustainable agricultural practices and increase agricultural productivity. Keywords: Autonomous Irrigation, IoT, Artificial Intelligence, Agriculture, Water Management</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11835v1</guid>
      <category>cs.CY</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yunus Emre Kunt</dc:creator>
    </item>
    <item>
      <title>Stochastic Data-Driven Predictive Control with Equivalence to Stochastic MPC</title>
      <link>https://arxiv.org/abs/2312.15177</link>
      <description>arXiv:2312.15177v3 Announce Type: replace 
Abstract: We propose a data-driven receding-horizon control method dealing with the chance-constrained output-tracking problem of unknown stochastic linear time-invariant (LTI) systems with partial state observation. The proposed method takes into account the statistics of the process noise, the measurement noise and the uncertain initial condition, following an analogous framework to Stochastic Model Predictive Control (SMPC), but does not rely on the use of a parametric system model. As such, our receding-horizon algorithm produces a sequence of closed-loop control policies for predicted time steps, as opposed to a sequence of open-loop control actions. Under certain conditions, we establish that our proposed data-driven control method produces identical control inputs as that produced by the associated model-based SMPC. Simulation results on a grid-connected power converter are provided to illustrate the performance benefits of our methodology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.15177v3</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ruiqi Li, John W. Simpson-Porco, Stephen L. Smith</dc:creator>
    </item>
    <item>
      <title>Dynamic Virtual Power Plants with Robust Frequency Regulation Capability</title>
      <link>https://arxiv.org/abs/2406.05976</link>
      <description>arXiv:2406.05976v2 Announce Type: replace 
Abstract: The rapid integration of inverter-based resources (IBRs) into power systems has identified frequency security challenges due to reduced inertia and increased load volatility. This paper proposes a robust power reserve decision-making approach for dynamic virtual power plants (DVPPs) to address these challenges, especially under temporally sequential and uncertain disturbances. An analytical model is developed to characterize the system's frequency response dynamics, enabling the quantification of virtual inertia and virtual damping requirements to meet rate-of-change-of-frequency (RoCoF), frequency nadir, and steady-state deviation constraints. By analytically deriving the regulation power dynamics, the required virtual inertia and damping parameters for the DVPP are determined in a robust way. Then, the total power reserve decision is made by optimally allocating the parameters and calculating the actual power reserves for IBRs, fully considering their economic diversity. Finally, case studies conducted on an IEEE nine-bus system demonstrate the effectiveness of the proposed approach. The results indicate the high reliability of the proposed approach in ensuring frequency security.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05976v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiang Zhu (Grant), Hua Geng (Grant), Hongyang Qing (Grant),  Guangchun (Grant),  Ruan, Xiuqiang He</dc:creator>
    </item>
    <item>
      <title>Control Industrial Automation System with Large Language Model Agents</title>
      <link>https://arxiv.org/abs/2409.18009</link>
      <description>arXiv:2409.18009v2 Announce Type: replace 
Abstract: Traditional industrial automation systems require specialized expertise to operate and complex reprogramming to adapt to new processes. Large language models offer the intelligence to make them more flexible and easier to use. However, LLMs' application in industrial settings is underexplored. This paper introduces a framework for integrating LLMs to achieve end-to-end control of industrial automation systems. At the core of the framework are an agent system designed for industrial tasks, a structured prompting method, and an event-driven information modeling mechanism that provides real-time data for LLM inference. The framework supplies LLMs with real-time events on different context semantic levels, allowing them to interpret the information, generate production plans, and control operations on the automation system. It also supports structured dataset creation for fine-tuning on this downstream application of LLMs. Our contribution includes a formal system design, proof-of-concept implementation, and a method for generating task-specific datasets for LLM fine-tuning and testing. This approach enables a more adaptive automation system that can respond to spontaneous events, while allowing easier operation and configuration through natural language for more intuitive human-machine interaction. We provide demo videos and detailed data on GitHub: https://github.com/YuchenXia/LLM4IAS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.18009v2</guid>
      <category>eess.SY</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.MA</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Yuchen Xia, Nasser Jazdi, Jize Zhang, Chaitanya Shah, Michael Weyrich</dc:creator>
    </item>
    <item>
      <title>Assessing the Optimistic Bias in the Natural Inflow Forecasts: A Call for Model Monitoring in Brazil</title>
      <link>https://arxiv.org/abs/2410.13763</link>
      <description>arXiv:2410.13763v3 Announce Type: replace 
Abstract: Hydroelectricity accounted for roughly 61.4% of Brazil's total generation in 2024 and addressed most of the intermittency of wind and solar generation. Thus, inflow forecasting plays a critical role in the operation, planning, and market in this country, as well as in any other hydro-dependent power system. These forecasts influence generation schedules, reservoir management, and market pricing, shaping the dynamics of the entire electricity sector. The objective of this paper is to measure and present empirical evidence of a systematic optimistic bias in the official inflow forecast methodology, which is based on the PAR(p)-A model. Additionally, we discuss possible sources of this bias and recommend ways to mitigate it. By analyzing 14 years of historical data from the Brazilian system through rolling-window multistep (out-of-sample) forecasts, results indicate that the official forecast model exhibits statistically significant biases of 6%, 14%, 20%, and 24% for 1-, 6-, 12-, and 24-step-ahead forecasts in the Southeast subsystem, and 19%, 57%, 81%, and 109% in the Northeast subsystem. These findings uncover the limitations of current inflow forecasting methodologies used in Brazil and call for new governance and monitoring policies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13763v3</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>stat.AP</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arthur Brigatto, Alexandre Street, Cristiano Fernandes, Davi Valladao, Guilherme Bodin, Joaquim Dias Garcia</dc:creator>
    </item>
    <item>
      <title>Parametrizations of All Stable Closed-loop Responses: From Theory to Neural Network Control Design</title>
      <link>https://arxiv.org/abs/2412.19280</link>
      <description>arXiv:2412.19280v2 Announce Type: replace 
Abstract: The complexity of modern control systems necessitates architectures that achieve high performance while ensuring robust stability, particularly for nonlinear systems. In this work, we tackle the challenge of designing output-feedback controllers to boost the performance of $\ell_p$-stable discrete-time nonlinear systems while preserving closed-loop stability from external disturbances to input and output channels. Leveraging operator theory and neural network representations, we parametrize the achievable closed-loop maps for a given system and propose novel parametrizations of all $\ell_p$-stabilizing controllers, unifying frameworks such as nonlinear Youla parametrization and internal model control. Contributing to a rapidly growing research line, our approach enables unconstrained optimization exclusively over stabilizing controllers and provides sufficient conditions to ensure robustness against model mismatch. Additionally, our methods reveal that stronger notions of stability can be imposed on the closed-loop maps if disturbance realizations are available after one time step. Last, our approaches are compatible with the design of nonlinear distributed controllers. Numerical experiments on cooperative robotics demonstrate the flexibility of the proposed framework, allowing cost functions to be freely designed for achieving complex behaviors while preserving stability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.19280v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Clara Luc\'ia Galimberti, Luca Furieri, Giancarlo Ferrari-Trecate</dc:creator>
    </item>
    <item>
      <title>Lessons learned from field demonstrations of model predictive control and reinforcement learning for residential and commercial HVAC: A review</title>
      <link>https://arxiv.org/abs/2503.05022</link>
      <description>arXiv:2503.05022v5 Announce Type: replace 
Abstract: A large body of simulation research suggests that model predictive control (MPC) and reinforcement learning (RL) for heating, ventilation, and air-conditioning (HVAC) in residential and commercial buildings could reduce energy costs, pollutant emissions, and strain on power grids. Despite this potential, neither MPC nor RL has seen widespread industry adoption. Field demonstrations could accelerate MPC and RL adoption by providing real-world data that support the business case for deployment. Here we review 24 papers that document field demonstrations of MPC and RL in residential buildings and 80 in commercial buildings. After presenting demographic information -- such as experiment scopes, locations, and durations -- this paper analyzes experiment protocols and their influence on performance estimates. We find that 71% of the reviewed field demonstrations use experiment protocols that may lead to unreliable performance estimates. Over the remaining 29% that we view as reliable, the weighted-average cost savings, weighted by experiment duration, are 16% in residential buildings and 13% in commercial buildings. While these savings are potentially attractive, making the business case for MPC and RL also requires characterizing the costs of deployment, operation, and maintenance. Only 13 of the 104 reviewed papers report these costs or discuss related challenges. Based on these observations, we recommend directions for future field research, including: Improving experiment protocols; reporting deployment, operation, and maintenance costs; designing algorithms and instrumentation to reduce these costs; controlling HVAC equipment alongside other distributed energy resources; and pursuing emerging objectives such as peak shaving, arbitraging wholesale energy prices, and providing power grid reliability services.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05022v5</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Arash J. Khabbazi, Elias N. Pergantis, Levi D. Reyes Premer, Panagiotis Papageorgiou, Alex H. Lee, James E. Braun, Gregor P. Henze, Kevin J. Kircher</dc:creator>
    </item>
    <item>
      <title>Finite Sample Analysis of System Poles for Ho-Kalman Algorithm</title>
      <link>https://arxiv.org/abs/2503.16331</link>
      <description>arXiv:2503.16331v4 Announce Type: replace 
Abstract: The Ho-Kalman algorithm has been widely employed for the identification of discrete-time linear time-invariant (LTI) systems. In this paper, we investigate the pole estimation error for the Ho-Kalman algorithm based on finite input/output sample data. Building upon prior works, we derive finite sample error bounds for system pole estimation in both single-trajectory and multiple-trajectory scenarios. Specifically, we prove that, with high probability, the estimation error for an $n$-dimensional system decreases at a rate of at least $\mathcal{O}(T^{-1/2n})$ in the single-trajectory setting with trajectory length $T$, and at a rate of at least $\mathcal{O}(N^{-1/2n})$ in the multiple-trajectory setting with $N$ independent trajectories. Furthermore, we reveal that in both settings, achieving a constant estimation error requires a super-polynomial sample size in $ \max\{n/m, n/p\} $, where $n/m$ and $n/p$ denote the state-to-output and state-to-input dimension ratios, respectively. Finally, numerical experiments are conducted to validate the non-asymptotic results of system pole estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16331v4</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuai Sun, Xu Wang</dc:creator>
    </item>
    <item>
      <title>Safe Physics-Informed Machine Learning for Dynamics and Control</title>
      <link>https://arxiv.org/abs/2504.12952</link>
      <description>arXiv:2504.12952v2 Announce Type: replace 
Abstract: This tutorial paper focuses on safe physics-informed machine learning in the context of dynamics and control, providing a comprehensive overview of how to integrate physical models and safety guarantees. As machine learning techniques enhance the modeling and control of complex dynamical systems, ensuring safety and stability remains a critical challenge, especially in safety-critical applications like autonomous vehicles, robotics, medical decision-making, and energy systems. We explore various approaches for embedding and ensuring safety constraints, including structural priors, Lyapunov and Control Barrier Functions, predictive control, projections, and robust optimization techniques. Additionally, we delve into methods for uncertainty quantification and safety verification, including reachability analysis and neural network verification tools, which help validate that control policies remain within safe operating bounds even in uncertain environments. The paper includes illustrative examples demonstrating the implementation aspects of safe learning frameworks that combine the strengths of data-driven approaches with the rigor of physical principles, offering a path toward the safe control of complex dynamical systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.12952v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jan Drgona, Truong X. Nghiem, Thomas Beckers, Mahyar Fazlyab, Enrique Mallada, Colin Jones, Draguna Vrabie, Steven L. Brunton, Rolf Findeisen</dc:creator>
    </item>
    <item>
      <title>IAE Optimized PID Tuning with Phase Margin and Crossover Frequency Constraints</title>
      <link>https://arxiv.org/abs/2506.00923</link>
      <description>arXiv:2506.00923v2 Announce Type: replace 
Abstract: This paper presents PMwc-Tune, a novel PID tuning method that uniquely combines frequency-domain robustness constraints with time-domain performance optimization through constrained nonlinear programming. The key contribution is a unified formulation that simultaneously enforces phase margin and crossover frequency requirements (via nonlinear equality constraints) while minimizing the Integral Absolute Error (IAE) of the closed-loop response. The algorithm employs Sequential Quadratic Programming (SQP) to solve this constrained optimization problem, guaranteeing specification attainment within numerical tolerances while optimizing transient performance. Numerical validation on benchmark systems demonstrates precise convergence to design targets (phase margin and crossover frequency errors &lt;1%) with a 4.6% IAE reduction compared to MATLAB's pidtune. The open-source implementation provides both methodological transparency and practical design flexibility, enabling PID controllers that rigorously balance frequency-domain robustness and time-domain performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00923v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Senol Gulgonul</dc:creator>
    </item>
    <item>
      <title>Joint Beamforming with Extremely Large Scale RIS: A Sequential Multi-Agent A2C Approach</title>
      <link>https://arxiv.org/abs/2506.10815</link>
      <description>arXiv:2506.10815v2 Announce Type: replace 
Abstract: It is a challenging problem to jointly optimize the base station (BS) precoding matrix and the reconfigurable intelligent surface (RIS) phases simultaneously in a RIS-assisted multiple-user multiple-input-multiple-output (MU-MIMO) scenario when the size of the RIS becomes extremely large. In this paper, we propose a deep reinforcement learning algorithm called sequential multi-agent advantage actor-critic (A2C) to solve this problem. In addition, the discrete phase of RISs, imperfect channel state information (CSI), and channel correlations between users are taken into consideration. The computational complexity is also analyzed, and the performance of the proposed algorithm is compared with the zero-forcing (ZF) beamformer in terms of the sum spectral efficiency (SE). It is noted that the computational complexity of the proposed algorithm is lower than the benchmark, while the performance is better than the benchmark. Throughout simulations, it is also found that the proposed algorithm is robust to medium channel estimation error.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10815v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhi Chai, Jiajie Xu, Justin P Coon, Mohamed-Slim Alouini</dc:creator>
    </item>
    <item>
      <title>Robust Cooperative Multi-Agent Reinforcement Learning:A Mean-Field Type Game Perspective</title>
      <link>https://arxiv.org/abs/2406.13992</link>
      <description>arXiv:2406.13992v2 Announce Type: replace-cross 
Abstract: In this paper, we study the problem of robust cooperative multi-agent reinforcement learning (RL) where a large number of cooperative agents with distributed information aim to learn policies in the presence of \emph{stochastic} and \emph{non-stochastic} uncertainties whose distributions are respectively known and unknown. Focusing on policy optimization that accounts for both types of uncertainties, we formulate the problem in a worst-case (minimax) framework, which is is intractable in general. Thus, we focus on the Linear Quadratic setting to derive benchmark solutions. First, since no standard theory exists for this problem due to the distributed information structure, we utilize the Mean-Field Type Game (MFTG) paradigm to establish guarantees on the solution quality in the sense of achieved Nash equilibrium of the MFTG. This in turn allows us to compare the performance against the corresponding original robust multi-agent control problem. Then, we propose a Receding-horizon Gradient Descent Ascent RL algorithm to find the MFTG Nash equilibrium and we prove a non-asymptotic rate of convergence. Finally, we provide numerical experiments to demonstrate the efficacy of our approach relative to a baseline algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13992v2</guid>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Muhammad Aneeq uz Zaman, Mathieu Lauri\`ere, Alec Koppel, Tamer Ba\c{s}ar</dc:creator>
    </item>
    <item>
      <title>On the reproducibility of discrete-event simulation studies in health research: an empirical study using open models</title>
      <link>https://arxiv.org/abs/2501.13137</link>
      <description>arXiv:2501.13137v2 Announce Type: replace-cross 
Abstract: Reproducibility of computational research is critical for ensuring transparency, reliability and reusability. Challenges with computational reproducibility have been documented in several fields, but healthcare discrete-event simulation (DES) models have not been thoroughly examined in this context. This study assessed the computational reproducibility of eight published healthcare DES models (Python or R), selected to represent diverse contexts, complexities, and years of publication. Repositories and articles were also assessed against guidelines and reporting standards, offering insights into their relationship with reproducibility success. Reproducing results required up to 28 hours of troubleshooting per model, with 50% fully reproduced and 50% partially reproduced (12.5% to 94.1% of reported outcomes). Key barriers included the absence of open licences, discrepancies between reported and coded parameters, and missing code to produce model outputs, run scenarios, and generate tables and figures. Addressing these issues would often require relatively little effort from authors: adding an open licence and sharing all materials used to produce the article. Actionable recommendations are proposed to enhance reproducibility practices for simulation modellers and reviewers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13137v2</guid>
      <category>q-bio.OT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amy Heather, Thomas Monks, Alison Harper, Navonil Mustafee, Andrew Mayne</dc:creator>
    </item>
    <item>
      <title>Extended Hybrid Zero Dynamics for Bipedal Walking of the Knee-less Robot SLIDER</title>
      <link>https://arxiv.org/abs/2504.01165</link>
      <description>arXiv:2504.01165v2 Announce Type: replace-cross 
Abstract: Knee-less bipedal robots like SLIDER have the advantage of ultra-lightweight legs and improved walking energy efficiency compared to traditional humanoid robots. In this paper, we firstly introduce an improved hardware design of the SLIDER bipedal robot with new line-feet and more optimized mass distribution that enables higher locomotion speeds. Secondly, we propose an extended Hybrid Zero Dynamics (eHZD) method, which can be applied to prismatic joint robots like SLIDER. The eHZD method is then used to generate a library of gaits with varying reference velocities in an offline way. Thirdly, a Guided Deep Reinforcement Learning (DRL) algorithm is proposed to use the pre-generated library to create walking control policies in real-time. This approach allows us to combine the advantages of both HZD (for generating stable gaits with a full-dynamics model) and DRL (for real-time adaptive gait generation). The experimental results show that this approach achieves 150% higher walking velocity than the previous MPC-based approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01165v2</guid>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rui Zong, Martin Liang, Yuntian Fang, Ke Wang, Xiaoshuai Chen, Wei Chen, Petar Kormushev</dc:creator>
    </item>
    <item>
      <title>Interior Point Differential Dynamic Programming, Redux</title>
      <link>https://arxiv.org/abs/2504.08278</link>
      <description>arXiv:2504.08278v3 Announce Type: replace-cross 
Abstract: We present IPDDP2, a structure-exploiting algorithm for solving discrete-time, finite-horizon optimal control problems (OCPs) with nonlinear constraints. Inequality constraints are handled using a primal-dual interior point formulation and step acceptance for equality constraints follows a line-search filter approach. The iterates of the algorithm are derived under the Differential Dynamic Programming (DDP) framework. A proof of local quadratic convergence of the IPDDP2 iterates is provided. Our numerical experiments evaluate IPDDP2 on over 500 OCPs derived from five different classes of robotic motion planning problems, three of which are contact-implicit trajectory optimisation problems. IPDDP2 demonstrates improvements in robustness against existing constrained DDP algorithms for contact-implicit planning, while being significantly faster than general-purpose solver IPOPT. We provide a full implementation of IPDDP2 in the Julia programming language.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.08278v3</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Ming Xu, Stephen Gould, Iman Shames</dc:creator>
    </item>
    <item>
      <title>Expressivity of Quadratic Neural ODEs</title>
      <link>https://arxiv.org/abs/2504.09385</link>
      <description>arXiv:2504.09385v2 Announce Type: replace-cross 
Abstract: This work focuses on deriving quantitative approximation error bounds for neural ordinary differential equations having at most quadratic nonlinearities in the dynamics. The simple dynamics of this model form demonstrates how expressivity can be derived primarily from iteratively composing many basic elementary operations, versus from the complexity of those elementary operations themselves. Like the analog differential analyzer and universal polynomial DAEs, the expressivity is derived instead primarily from the "depth" of the model. These results contribute to our understanding of what depth specifically imparts to the capabilities of deep learning architectures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.09385v2</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joshua Hanson, Maxim Raginsky</dc:creator>
    </item>
    <item>
      <title>Policy Gradient Adaptive Control for the LQR: Indirect and Direct Approaches</title>
      <link>https://arxiv.org/abs/2505.03706</link>
      <description>arXiv:2505.03706v2 Announce Type: replace-cross 
Abstract: Motivated by recent advances of reinforcement learning and direct data-driven control, we propose policy gradient adaptive control (PGAC) for the linear quadratic regulator (LQR), which uses online closed-loop data to improve the control policy while maintaining stability. Our method adaptively updates the policy in feedback by descending the gradient of the LQR cost and is categorized as indirect, when gradients are computed via an estimated model, versus direct, when gradients are derived from data using sample covariance parameterization. Beyond the vanilla gradient, we also showcase the merits of the natural gradient and Gauss-Newton methods for the policy update. Notably, natural gradient descent bridges the indirect and direct PGAC, and the Gauss-Newton method of the indirect PGAC leads to an adaptive version of the celebrated Hewer's algorithm. To account for the uncertainty from noise, we propose a regularization method for both indirect and direct PGAC. For all the considered PGAC approaches, we show closed-loop stability and convergence of the policy to the optimal LQR gain. Simulations validate our theoretical findings and demonstrate the robustness and computational efficiency of PGAC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03706v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Feiran Zhao, Alessandro Chiuso, Florian D\"orfler</dc:creator>
    </item>
  </channel>
</rss>
