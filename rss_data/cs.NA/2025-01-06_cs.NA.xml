<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NA</link>
    <description>cs.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 07 Jan 2025 03:19:46 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Optimal error bounds on an exponential wave integrator Fourier spectral method for fractional nonlinear Schr\"{o}dinger equations with low regularity potential and nonlinearity</title>
      <link>https://arxiv.org/abs/2501.01445</link>
      <description>arXiv:2501.01445v1 Announce Type: new 
Abstract: We establish optimal error bounds on an exponential wave integrator (EWI) for the space fractional nonlinear Schr\"{o}dinger equation (SFNLSE) with low regularity potential and/or nonlinearity. For the semi-discretization in time, under the assumption of $L^\infty$-potential, $C^1$-nonlinearity, and $H^\alpha$-solution with $1&lt;\alpha \leq 2$ being the fractional index of $(-\Delta)^\frac{\alpha}{2}$, we prove an optimal first-order $L^2$-norm error bound $O(\tau)$ and a uniform $H^\alpha$-norm bound of the semi-discrete numerical solution, where $\tau$ is the time step size. We further discretize the EWI in space by the Fourier spectral method and obtain an optimal error bound without introducing any CFL-type time step size restrictions. In particular, the spatial convergence is optimal with respect to the regularity of the exact solution. Moreover, under slightly stronger regularity assumptions, we obtain optimal error bounds in $H^\frac{\alpha}{2}$-norm, which is the norm associated to the energy. Extensive numerical examples are provided to validate the optimal error bounds and show their sharpness. We also find distinct evolving patterns between the SFNLSE and the classical nonlinear Schr\"{o}dinger equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01445v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junqing Jia, Xiaoyun Jiang</dc:creator>
    </item>
    <item>
      <title>High order interpolation of magnetic fields with vector potential reconstruction for particle simulations</title>
      <link>https://arxiv.org/abs/2501.01523</link>
      <description>arXiv:2501.01523v1 Announce Type: new 
Abstract: We propose a method for interpolating divergence-free continuous magnetic fields via vector potential reconstruction using Hermite interpolation, which ensures high-order continuity for applications requiring adaptive, high-order ordinary differential equation (ODE) integrators, such as the Dormand-Prince method. The method provides C(m) continuity and achieves high-order accuracy, making it particularly suited for particle trajectory integration and Poincar\'e section analysis under optimal integration order and timestep adjustments. Through numerical experiments, we demonstrate that the Hermite interpolation method preserves volume and continuity, which are critical for conserving toroidal canonical momentum and magnetic moment in guiding center simulations, especially over long-term trajectory integration. Furthermore, we analyze the impact of insufficient derivative continuity on Runge-Kutta schemes and show how it degrades accuracy at low error tolerances, introducing discontinuity-induced truncation errors. Finally, we demonstrate performant Poincar\'e section analysis in two relevant settings of field data collocated from finite element meshes</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01523v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.plasm-ph</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Oleksii Beznosov, Jesus Bonilla, Xianzhu Tang, Golo Wimmer</dc:creator>
    </item>
    <item>
      <title>Enriched $C^1$ finite elements for crack problems in simplified strain gradient elasticity</title>
      <link>https://arxiv.org/abs/2501.01536</link>
      <description>arXiv:2501.01536v1 Announce Type: new 
Abstract: We present a new type of triangular $C^1$ finite elements developed for the plane strain crack problems within the simplified strain gradient elasticity (SGE). The finite element space contains a conventional fifth-degree polynomial interpolation that was originally developed for the plate bending problems and subsequently adopted for SGE. The enrichment is performed by adding the near-field analytic SGE solutions for crack problems preserving $C^1$ continuity of interpolation. This allows us an accurate representation of strain and stress fields near the crack tip and also results in the direct calculation of the amplitude factors of SGE asymptotic solution and related value of J-integral (energy release rate). The improved convergence of presented formulation is demonstrated within mode I and mode II problems. Size effects on amplitude factors and J-integral are also evaluated. It is found that amplitude factors of SGE asymptotic solution exhibit a linear dependence on crack size for relatively large cracks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01536v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.class-ph</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yury Solyaev, Vasiliy Dobryanskiy</dc:creator>
    </item>
    <item>
      <title>VGPT-PINN: Viscosity-enhanced Generative Pre-Trained Physics Informed Neural Networks for parameterized nonlinear conservation laws</title>
      <link>https://arxiv.org/abs/2501.01587</link>
      <description>arXiv:2501.01587v1 Announce Type: new 
Abstract: We propose a Viscosity-enhanced Generative Pre-Trained Physics-Informed Neural Network with a transform layer (VGPT-PINN) for solving parameterized nonlinear conservation laws. The VGPT-PINN extends the traditional physics-informed neural networks and its recently proposed generative pre-trained strategy for linear model reduction to nonlinear model reduction and shock-capturing domains. By utilizing an adaptive meta-network, a simultaneously trained transform layer, viscosity enhancement strategies, implementable shock interaction analysis, and a separable training process, the VGPT-PINN efficiently captures complex parameter-dependent shock formations and interactions. Numerical results of VGPT-PINN applied to the families of inviscid Burgers' equation and the Euler equations, parameterized by their initial conditions, demonstrate the robustness and accuracy of the proposed technique. It accurately solves for the viscosity solution via very few neurons without leveraging any {\it a priori} knowledge of the equations or its initial condition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01587v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yajie Ji, Yanlai Chen, Zhenli Xu</dc:creator>
    </item>
    <item>
      <title>A hyperreduced reduced basis element method for reduced-order modeling of component-based nonlinear systems</title>
      <link>https://arxiv.org/abs/2501.01621</link>
      <description>arXiv:2501.01621v1 Announce Type: new 
Abstract: We introduce a hyperreduced reduced basis element method for model reduction of parameterized, component-based systems in continuum mechanics governed by nonlinear partial differential equations. In the offline phase, the method constructs, through a component-wise empirical training, a library of archetype components defined by a component-wise reduced basis and hyperreduced quadrature rules with varying hyperreduction fidelities. In the online phase, the method applies an online adaptive scheme informed by the Brezzi-Rappaz-Raviart theorem to select an appropriate hyperreduction fidelity for each component to meet the user-prescribed error tolerance at the system level. The method accommodates the rapid construction of hyperreduced models for large-scale component-based nonlinear systems and enables model reduction of problems with many continuous and topology-varying parameters. The efficacy of the method is demonstrated on a two-dimensional nonlinear thermal fin system that comprises up to 225 components and 68 independent parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01621v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.cma.2024.117254</arxiv:DOI>
      <arxiv:journal_reference>Computer Methods in Applied Mechanics and Engineering 431 (2024): 117254</arxiv:journal_reference>
      <dc:creator>Mehran Ebrahimi, Masayuki Yano</dc:creator>
    </item>
    <item>
      <title>Enhanced Error Bounds For The Masked Projection Techniques via Cosine-Sine Decomposition</title>
      <link>https://arxiv.org/abs/2501.01651</link>
      <description>arXiv:2501.01651v1 Announce Type: new 
Abstract: The masked projection techniques are popular in the area of non-linear model reduction. Quantifying and minimizing the error in model reduction, particularly from masked projections, is important. The exact error expressions are often infeasible. This leads to the use of error-bound expressions in the literature. In this paper, we derive two generalized error bounds using cosine-sine decomposition for uniquely determined masked projection techniques. Generally, the masked projection technique is employed to efficiently approximate non-linear functions in the model reduction of dynamical systems. The discrete empirical interpolation method (DEIM) is also a masked projection technique; therefore, the proposed error bounds apply to DEIM projection errors. Furthermore, the proposed error bounds are shown tighter than those currently available in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01651v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Brij Nandan Tripathi, Hanumant Singh Shekhawat</dc:creator>
    </item>
    <item>
      <title>Krylov iterative methods for linear least squares problems with linear equality constraints</title>
      <link>https://arxiv.org/abs/2501.01655</link>
      <description>arXiv:2501.01655v1 Announce Type: new 
Abstract: We consider the linear least squares problem with linear equality constraints (LSE problem) formulated as $\min_{x\in\mathbb{R}^{n}}\|Ax-b\|_2 \ \mathrm{s.t.} \ Cx = d$. Although there are some classical methods available to solve this problem, most of them rely on matrix factorizations or require the null space of $C$, which limits their applicability to large-scale problems. To address this challenge, we present a novel analysis of the LSE problem from the perspective of operator-type least squares (LS) problems, where the linear operators are induced by $\{A,C\}$. We show that the solution of the LSE problem can be decomposed into two components, each corresponding to the solution of an operator-form LS problem. Building on this decomposed-form solution, we propose two Krylov subspace based iterative methods to approximate each component, thereby providing an approximate solution of the LSE problem. Several numerical examples are constructed to test the proposed iterative algorithm for solving the LSE problems, which demonstrate the effectiveness of the algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01655v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haibo Li</dc:creator>
    </item>
    <item>
      <title>A BDDC method for three-dimensional advection-diffusion problems with an adaptive coarse space</title>
      <link>https://arxiv.org/abs/2501.01676</link>
      <description>arXiv:2501.01676v1 Announce Type: new 
Abstract: The solution of nonsymmetric positive definite (NSPD) systems for advection-diffusion problems is an important research topic in science and engineering. The adaptive BDDC method is a significant class of non-overlapping domain decomposition methods, which is often used for solving symmetric positive definite problems. In this paper, we apply the adaptive BDDC method to solve the NSPD systems of te advection-diffusion problems. Moreover, by designing a class of edge generalized eigenvalue problems based on prior selected primal constraints, the number of primal unknowns is further reduced. Numerical experiments have verified the effectiveness of the proposed methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01676v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jie Peng, Shi Shu, Junxian Wang, Liuqiang Zhong</dc:creator>
    </item>
    <item>
      <title>Order-one explicit approximations of random periodic solutions of semi-linear SDEs with multiplicative noise</title>
      <link>https://arxiv.org/abs/2501.01474</link>
      <description>arXiv:2501.01474v1 Announce Type: cross 
Abstract: This paper is devoted to order-one explicit approximations of random periodic solutions to multiplicative noise driven stochastic differential equations (SDEs) with non-globally Lipschitz coefficients. The existence of the random periodic solution is demonstrated as the limit of the pull-back of the discretized SDE. A novel approach is introduced to analyze mean-square error bounds of the proposed scheme that does not depend on a prior high-order moment bounds of the numerical approximations. Under mild assumptions, the proposed scheme is proved to achieve an expected order-one mean square convergence in the infinite time horizon. Numerical examples are finally provided to verify the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01474v1</guid>
      <category>math.PR</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yujia Guo, Xiaojie Wang, Yue Wu</dc:creator>
    </item>
    <item>
      <title>Semialgebraic Neural Networks: From roots to representations</title>
      <link>https://arxiv.org/abs/2501.01564</link>
      <description>arXiv:2501.01564v1 Announce Type: cross 
Abstract: Many numerical algorithms in scientific computing -- particularly in areas like numerical linear algebra, PDE simulation, and inverse problems -- produce outputs that can be represented by semialgebraic functions; that is, the graph of the computed function can be described by finitely many polynomial equalities and inequalities. In this work, we introduce Semialgebraic Neural Networks (SANNs), a neural network architecture capable of representing any bounded semialgebraic function, and computing such functions up to the accuracy of a numerical ODE solver chosen by the programmer. Conceptually, we encode the graph of the learned function as the kernel of a piecewise polynomial selected from a class of functions whose roots can be evaluated using a particular homotopy continuation method. We show by construction that the SANN architecture is able to execute this continuation method, thus evaluating the learned semialgebraic function. Furthermore, the architecture can exactly represent even discontinuous semialgebraic functions by executing a continuation method on each connected component of the target function. Lastly, we provide example applications of these networks and show they can be trained with traditional deep-learning techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01564v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>cs.NE</category>
      <category>math.NA</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>S. David Mis, Matti Lassas, Maarten V. de Hoop</dc:creator>
    </item>
    <item>
      <title>Discontinuous Galerkin methods for the Laplace-Beltrami operator on point cloud</title>
      <link>https://arxiv.org/abs/2012.15433</link>
      <description>arXiv:2012.15433v3 Announce Type: replace 
Abstract: This paper is dedicated to the development of numerical analysis for high-order methods solving partial differential equations on scattered point clouds. We build a novel geometric error analysis framework by estimating the error in the approximation of the Riemann metric tensor. The innovative framework serves as a fundamental tool for analyzing discontinuous Galerkin methods applied to the Laplace-Beltrami operator on possibly discontinuous geometry. We provide numerical examples on patchy surfaces reconstructed from point clouds to support our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2012.15433v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guozhi Dong, Hailong Guo, Zuoqiang Shi</dc:creator>
    </item>
    <item>
      <title>Solving multiscale dynamical systems by deep learning</title>
      <link>https://arxiv.org/abs/2401.01220</link>
      <description>arXiv:2401.01220v2 Announce Type: replace 
Abstract: Multiscale dynamical systems, modeled by high-dimensional stiff ordinary differential equations (ODEs) with wide-ranging characteristic timescales, arise across diverse fields of science and engineering, but their numerical solvers often encounter severe efficiency bottlenecks. This paper introduces a novel DeePODE method, which consists of an Evolutionary Monte Carlo Sampling method (EMCS) and an efficient end-to-end deep neural network (DNN) to predict multiscale dynamical systems. We validate this finding across dynamical systems from ecological systems to reactive flows, including a predator-prey model, a power system oscillation, a battery electrolyte thermal runaway, and turbulent reaction-diffusion systems with complex chemical kinetics. The method demonstrates robust generalization capabilities, allowing pre-trained DNN models to accurately predict the behavior in previously unseen scenarios, largely due to the delicately constructed dataset. While theoretical guarantees remain to be established, empirical evidence shows that DeePODE achieves the accuracy of implicit numerical schemes while maintaining the computational efficiency of explicit schemes. This work underscores the crucial relationship between training data distribution and neural network generalization performance. This work demonstrates the potential of deep learning approaches in modeling complex dynamical systems across scientific and engineering domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.01220v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Junjie Yao, Yuxiao Yi, Liangkai Hang, Weinan E, Weizong Wang, Yaoyu Zhang, Tianhan Zhang, Zhi-Qin John Xu</dc:creator>
    </item>
    <item>
      <title>A number-theoretic method sampling neural network for solving partial differential equations</title>
      <link>https://arxiv.org/abs/2411.17039</link>
      <description>arXiv:2411.17039v5 Announce Type: replace 
Abstract: When dealing with a large number of points, the widely used uniform random sampling approach for approximating integrals using the Monte Carlo method becomes inefficient. In this work, we develop a deep learning framework established in a set of points generated from the number-theoretic method, which is a deterministic and robust sampling approach. This framework is designed to address low-regularity and high-dimensional partial differential equations, where Physics-Informed neural networks are incorporated. Furthermore, rigorous mathematical proofs are provided to validate the error bound of our method is less than that of uniform random sampling method. We employ numerical experiments involving the Poisson equation with low regularity, the two-dimensional inverse Helmholtz equation, and high-dimensional linear and nonlinear problems to illustrate the effectiveness of our algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.17039v5</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu Yang, Pingan He, Xiaoling Peng, Qiaolin He</dc:creator>
    </item>
    <item>
      <title>Quantum Channel Learning</title>
      <link>https://arxiv.org/abs/2407.04406</link>
      <description>arXiv:2407.04406v2 Announce Type: replace-cross 
Abstract: The problem of an optimal mapping between Hilbert spaces $IN$ and $OUT$, based on a series of density matrix mapping measurements $\rho^{(l)} \to \varrho^{(l)}$, $l=1\dots M$, is formulated as an optimization problem maximizing the total fidelity $\mathcal{F}=\sum_{l=1}^{M} \omega^{(l)} F\left(\varrho^{(l)},\sum_s B_s \rho^{(l)} B^{\dagger}_s\right)$ subject to probability preservation constraints on Kraus operators $B_s$. For $F(\varrho,\sigma)$ in the form that total fidelity can be represented as a quadratic form with superoperator $\mathcal{F}=\sum_s\left\langle B_s\middle|S\middle| B_s \right\rangle$ (either exactly or as an approximation) an iterative algorithm is developed. The work introduces two important generalizations of unitary learning: 1. $IN$/$OUT$ states are represented as density matrices. 2. The mapping itself is formulated as a mixed unitary quantum channel $A^{OUT}=\sum_s |w_s|^2 \mathcal{U}_s A^{IN} \mathcal{U}_s^{\dagger}$ (no general quantum channel yet). This marks a crucial advancement from the commonly studied unitary mapping of pure states $\phi_l=\mathcal{U} \psi_l$ to a quantum channel, what allows us to distinguish probabilistic mixture of states and their superposition. An application of the approach is demonstrated on unitary learning of density matrix mapping $\varrho^{(l)}=\mathcal{U} \rho^{(l)} \mathcal{U}^{\dagger}$, in this case a quadratic on $\mathcal{U}$ fidelity can be constructed by considering $\sqrt{\rho^{(l)}} \to \sqrt{\varrho^{(l)}}$ mapping, and on a quantum channel, where quadratic on $B_s$ fidelity is an approximation -- a quantum channel is then obtained as a hierarchy of unitary mappings, a mixed unitary channel. The approach can be applied to studying quantum inverse problems, variational quantum algorithms, quantum tomography, and more.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04406v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>quant-ph</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1103/PhysRevE.111.015302</arxiv:DOI>
      <arxiv:journal_reference>Phys. Rev. E 111, 015302, (2025)</arxiv:journal_reference>
      <dc:creator>Mikhail Gennadievich Belov, Victor Victorovich Dubov, Alexey Vladimirovich Filimonov, Vladislav Gennadievich Malyshkin</dc:creator>
    </item>
  </channel>
</rss>
