<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 26 Nov 2024 05:00:14 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Totally $\Delta$-modular IPs with two non-zeros in most rows</title>
      <link>https://arxiv.org/abs/2411.15282</link>
      <description>arXiv:2411.15282v1 Announce Type: new 
Abstract: Integer programs (IPs) on constraint matrices with bounded subdeterminants are conjectured to be solvable in polynomial time. We give a strongly polynomial time algorithm to solve IPs where the constraint matrix has bounded subdeterminants and at most two non-zeros per row after removing a constant number of rows and columns. This result extends the work by Fiorini, Joret, Weltge \&amp; Yuditsky (J. ACM 2024) by allowing for additional, unifying constraints and variables.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15282v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <category>math.OC</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefan Kober</dc:creator>
    </item>
    <item>
      <title>Tag arrays</title>
      <link>https://arxiv.org/abs/2411.15291</link>
      <description>arXiv:2411.15291v1 Announce Type: new 
Abstract: The Burrows-Wheeler Transform (BWT) moves characters with similar contexts in a text together, where a character's context consists of the characters immediately following it. We say that a property has contextual locality if characters with similar contexts tend to have the same or similar values (``tags'') of that property. We argue that if we consider a repetitive text and such a property and the tags in their characters' BWT order, then the resulting string -- the text and property's {\em tag array} -- will be run-length compressible either directly or after some minor manipulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15291v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Travis Gagie</dc:creator>
    </item>
    <item>
      <title>Exploring Facets of Language Generation in the Limit</title>
      <link>https://arxiv.org/abs/2411.15364</link>
      <description>arXiv:2411.15364v1 Announce Type: new 
Abstract: The recent work of Kleinberg and Mullainathan [KM24] provides a concrete model for language generation in the limit: given a sequence of examples from an unknown target language, the goal is to generate new examples from the target language such that no incorrect examples are generated beyond some point. In sharp contrast to strong negative results for the closely related problem of language identification, they establish positive results for language generation in the limit for all countable collections of languages. Follow-up work by Raman and Tewari [RT24] studies bounds on the number of distinct inputs required by an algorithm before correct language generation is achieved -- namely, whether this is a constant for all languages in the collection (uniform generation) or a language-dependent constant (non-uniform generation).
  We show that every countable language collection has a generator which has the stronger property of non-uniform generation in the limit. However, while the generation algorithm of [KM24] can be implemented using membership queries, we show that any algorithm cannot non-uniformly generate even for collections of just two languages, using only membership queries.
  We also formalize the tension between validity and breadth in the generation algorithm of [KM24] by introducing a definition of exhaustive generation, and show a strong negative result for exhaustive generation. Our result shows that a tradeoff between validity and breadth is inherent for generation in the limit. Finally, inspired by algorithms that can choose to obtain feedback, we consider a model of uniform generation with feedback, completely characterizing language collections for which such uniform generation with feedback is possible in terms of a complexity measure of the collection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15364v1</guid>
      <category>cs.DS</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Moses Charikar, Chirag Pabbaraju</dc:creator>
    </item>
    <item>
      <title>Implicit High-Order Moment Tensor Estimation and Learning Latent Variable Models</title>
      <link>https://arxiv.org/abs/2411.15669</link>
      <description>arXiv:2411.15669v1 Announce Type: new 
Abstract: We study the task of learning latent-variable models. An obstacle towards designing efficient algorithms for such models is the necessity of approximating moment tensors of super-constant degree. Motivated by such applications, we develop a general efficient algorithm for implicit moment tensor computation. Our algorithm computes in $\mathrm{poly}(d, k)$ time a succinct approximate description of tensors of the form $M_m=\sum_{i=1}^{k}w_iv_i^{\otimes m}$, for $w_i\in\mathbb{R}_+$--even for $m=\omega(1)$--assuming there exists a polynomial-size arithmetic circuit whose expected output on an appropriate samplable distribution is equal to $M_m$, and whose covariance on this input is bounded. Our framework broadly generalizes the work of~\cite{LL21-opt} which developed an efficient algorithm for the specific moment tensors that arise in clustering mixtures of spherical Gaussians.
  By leveraging our general algorithm, we obtain the first polynomial-time learners for the following models.
  * Mixtures of Linear Regressions. We give a $\mathrm{poly}(d, k, 1/\epsilon)$-time algorithm for this task. The previously best algorithm has super-polynomial complexity in $k$.
  * Learning Mixtures of Spherical Gaussians. We give a $\mathrm{poly}(d, k, 1/\epsilon)$-time density estimation algorithm, under the condition that the means lie in a ball of radius $O(\sqrt{\log k})$. Prior algorithms incur super-polynomial complexity in $k$. We also give a $\mathrm{poly}(d, k, 1/\epsilon)$-time parameter estimation algorithm, under the {\em optimal} mean separation of $\Omega(\log^{1/2}(k/\epsilon))$.
  * PAC Learning Sums of ReLUs. We give a learner with complexity $\mathrm{poly}(d, k) 2^{\mathrm{poly}(1/\epsilon)}$. This is the first algorithm for this task that runs in $\mathrm{poly}(d, k)$ time for subconstant values of $\epsilon = o_{k, d}(1)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15669v1</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ilias Diakonikolas, Daniel M. Kane</dc:creator>
    </item>
    <item>
      <title>Directed Token Sliding</title>
      <link>https://arxiv.org/abs/2411.16149</link>
      <description>arXiv:2411.16149v1 Announce Type: new 
Abstract: Reconfiguration problems involve determining whether two given configurations can be transformed into each other under specific rules. The Token Sliding problem asks whether, given two different set of tokens on vertices of a graph $G$, we can transform one into the other by sliding tokens step-by-step along edges of $G$ such that each resulting set of tokens forms an independent set in $G$. Recently, Ito et al. [MFCS 2022] introduced a directed variant of this problem. They showed that for general oriented graphs (i.e., graphs where no pair of vertices can have directed edges in both directions), the problem remains $\mathsf{PSPACE}$-complete, and is solvable in polynomial time on oriented trees.
  In this paper, we further investigate the Token Sliding problem on various oriented graph classes. We show that the problem remains $\mathsf{PSPACE}$-complete for oriented planar graphs, split graphs, bipartite graphs and bounded treewidth graphs. Additionally, we present polynomial-time algorithms for solving the problem on oriented cycles and cographs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16149v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Niranka Banerjee, Christian Engels, Duc A. Hoang</dc:creator>
    </item>
    <item>
      <title>Dynamic Range Minimum Queries on the Ultra-Wide Word RAM</title>
      <link>https://arxiv.org/abs/2411.16281</link>
      <description>arXiv:2411.16281v1 Announce Type: new 
Abstract: We consider the dynamic range minimum problem on the ultra-wide word RAM model of computation. This model extends the classic $w$-bit word RAM model with special ultrawords of length $w^2$ bits that support standard arithmetic and boolean operation and scattered memory access operations that can access $w$ (non-contiguous) locations in memory. The ultra-wide word RAM model captures (and idealizes) modern vector processor architectures.
  Our main result is a linear space data structure that supports range minimum queries and updates in $O(\log \log \log n)$ time. This exponentially improves the time of existing techniques. Our result is based on a simple reduction to prefix minimum computations on sequences $O(\log n)$ words combined with a new parallel, recursive implementation of these.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16281v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Philip Bille, Inge Li G{\o}rtz, Tord Stordalen, M\'aximo P\'erez L\'opez</dc:creator>
    </item>
    <item>
      <title>Forest Covers and Bounded Forest Covers</title>
      <link>https://arxiv.org/abs/2411.16578</link>
      <description>arXiv:2411.16578v1 Announce Type: new 
Abstract: We study approximation algorithms for the forest cover and bounded forest cover problems. A probabilistic $2+\epsilon$ approximation algorithm for the forest cover problem is given using the method of dual fitting. A deterministic algorithm with a 2-approximation ratio that rounds the optimal solution to a linear program is given next. The 2-approximation for the forest cover is then used to give a 6-approximation for the bounded forest cover problem. The use of the probabilistic method to develop the $2+\epsilon$ approximation algorithm may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16578v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>math.CO</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daya Ram Gaur, Barun Gorain, Shaswati Patra, Rishi Ranjan Singh</dc:creator>
    </item>
    <item>
      <title>Approximation Algorithms for Combinatorial Optimization with Predictions</title>
      <link>https://arxiv.org/abs/2411.16600</link>
      <description>arXiv:2411.16600v1 Announce Type: new 
Abstract: We initiate a systematic study of utilizing predictions to improve over approximation guarantees of classic algorithms, without increasing the running time. We propose a systematic method for a wide class of optimization problems that ask to select a feasible subset of input items of minimal (or maximal) total weight. This gives simple (near-)linear time algorithms for, e.g., Vertex Cover, Steiner Tree, Min-Weight Perfect Matching, Knapsack, and Clique. Our algorithms produce optimal solutions when provided with perfect predictions and their approximation ratios smoothly degrade with increasing prediction error. With small enough prediction error we achieve approximation guarantees that are beyond reach without predictions in the given time bounds, as exemplified by the NP-hardness and APX-hardness of many of the above problems. Although we show our approach to be optimal for this class of problems as a whole, there is a potential for exploiting specific structural properties of individual problems to obtain improved bounds; we demonstrate this on the Steiner Tree problem. We conclude with an empirical evaluation of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16600v1</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Antonios Antoniadis, Marek Eli\'a\v{s}, Adam Polak, Moritz Venzin</dc:creator>
    </item>
    <item>
      <title>Heavy-tailed Contamination is Easier than Adversarial Contamination</title>
      <link>https://arxiv.org/abs/2411.15306</link>
      <description>arXiv:2411.15306v1 Announce Type: cross 
Abstract: A large body of work in the statistics and computer science communities dating back to Huber (Huber, 1960) has led to statistically and computationally efficient outlier-robust estimators. Two particular outlier models have received significant attention: the adversarial and heavy-tailed models. While the former models outliers as the result of a malicious adversary manipulating the data, the latter relaxes distributional assumptions on the data allowing outliers to naturally occur as part of the data generating process. In the first setting, the goal is to develop estimators robust to the largest fraction of outliers while in the second, one seeks estimators to combat the loss of statistical efficiency, where the dependence on the failure probability is paramount.
  Despite these distinct motivations, the algorithmic approaches to both these settings have converged, prompting questions on the relationship between the models. In this paper, we investigate and provide a principled explanation for this phenomenon. First, we prove that any adversarially robust estimator is also resilient to heavy-tailed outliers for any statistical estimation problem with i.i.d data. As a corollary, optimal adversarially robust estimators for mean estimation, linear regression, and covariance estimation are also optimal heavy-tailed estimators. Conversely, for arguably the simplest high-dimensional estimation task of mean estimation, we construct heavy-tailed estimators whose application to the adversarial setting requires any black-box reduction to remove almost all the outliers in the data. Taken together, our results imply that heavy-tailed estimation is likely easier than adversarially robust estimation opening the door to novel algorithmic approaches for the heavy-tailed setting. Additionally, confidence intervals obtained for adversarially robust estimation also hold with high-probability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15306v1</guid>
      <category>math.ST</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yeshwanth Cherapanamjeri, Daniel Lee</dc:creator>
    </item>
    <item>
      <title>The Polymatroid Representation of a Greedoid, and Associated Galois Connections</title>
      <link>https://arxiv.org/abs/2411.15363</link>
      <description>arXiv:2411.15363v1 Announce Type: cross 
Abstract: The greedoid is a significant abstraction of the matroid allowing for a more flexible analysis of structures in which the greedy algorithm "works." However, their diverse structure imposes difficulties towards their application in combinatorial optimization [Sze21]. In response, we revisit the polymatroid greedoid [KL85a] to characterize it by properties approximating those of matroids, by using the submodularity of its polymatroid representation in particular. Towards doing so, our main contribution is a full description of this class. Specifically, we show that a greedoid is a polymatroid greedoid if and only if it is an optimistic interval greedoid whose kernels are closed under intersection. This constitutes the first necessary and sufficient characterization of the polymatroid greedoid in terms of its combinatorial attributes, thereby resolving a central open question of Korte and Lov\'asz [KL85a]. Here, we introduce the optimism property to approximate properties of a matroid's continuations which are implied by the closure axioms of its span, which no longer hold for greedoids. And, because the kernels of an interval greedoid are in many ways an extension of a matroid's closed sets, our direction of necessity is a direct generalization of Birkhoff and Edmond's characterization of the meet in the lattice of a matroid's closed sets [Bir35, Edm03]. Towards achieving this result, our main technical insights arise from relating the lattice of flats of a polymatroid greedoid to that of the closed sets of its representation through order preserving mappings. Specifically, we will show the novel insight that the notion of polymatroid representation considered in [KL85a] is equivalent to the existence of a certain Galois connection. As a consequence, the representation of a greedoid via a polymatroid is an order theoretic concept in disguise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15363v1</guid>
      <category>math.CO</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Robert Streit, Vijay K. Garg</dc:creator>
    </item>
    <item>
      <title>Revenue Maximization in Choice-Based Matching Markets</title>
      <link>https://arxiv.org/abs/2411.15727</link>
      <description>arXiv:2411.15727v1 Announce Type: cross 
Abstract: The primary contribution of this paper resides in devising constant-factor approximation guarantees for revenue maximization in two-sided matching markets, under general pairwise rewards. A major distinction between our work and state-of-the-art results in this context (Ashlagi et al., 2022; Torrico et al., 2023) is that, for the first time, we are able to address reward maximization, reflected by assigning each customer-supplier pair an arbitrarily-valued reward. The specific type of performance guarantees we attain depends on whether one considers the customized model or the inclusive model. The fundamental difference between these settings lies in whether the platform should display to each supplier all selecting customers, as in the inclusive model, or whether the platform can further personalize this set, as in the customized model. Technically speaking, our algorithmic approach and its analysis revolve around presenting novel linear relaxations, leveraging convex stochastic orders, employing approximate dynamic programming, and developing tailor-made analytical ideas. In both models considered, these ingredients allow us to overcome the lack of submodularity and subadditivity that stems from pairwise rewards, plaguing the applicability of existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15727v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Dan Nissim, Danny Segev, Alfredo Torrico</dc:creator>
    </item>
    <item>
      <title>Binary Search with Distributional Predictions</title>
      <link>https://arxiv.org/abs/2411.16030</link>
      <description>arXiv:2411.16030v1 Announce Type: cross 
Abstract: Algorithms with (machine-learned) predictions is a powerful framework for combining traditional worst-case algorithms with modern machine learning. However, the vast majority of work in this space assumes that the prediction itself is non-probabilistic, even if it is generated by some stochastic process (such as a machine learning system). This is a poor fit for modern ML, particularly modern neural networks, which naturally generate a distribution. We initiate the study of algorithms with distributional predictions, where the prediction itself is a distribution. We focus on one of the simplest yet fundamental settings: binary search (or searching a sorted array). This setting has one of the simplest algorithms with a point prediction, but what happens if the prediction is a distribution? We show that this is a richer setting: there are simple distributions where using the classical prediction-based algorithm with any single prediction does poorly. Motivated by this, as our main result, we give an algorithm with query complexity $O(H(p) + \log \eta)$, where $H(p)$ is the entropy of the true distribution $p$ and $\eta$ is the earth mover's distance between $p$ and the predicted distribution $\hat p$. This also yields the first distributionally-robust algorithm for the classical problem of computing an optimal binary search tree given a distribution over target keys. We complement this with a lower bound showing that this query complexity is essentially optimal (up to constants), and experiments validating the practical usefulness of our algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16030v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Dinitz, Sungjin Im, Thomas Lavastida, Benjamin Moseley, Aidin Niaparast, Sergei Vassilvitskii</dc:creator>
    </item>
    <item>
      <title>On the Robustness of the Successive Projection Algorithm</title>
      <link>https://arxiv.org/abs/2411.16195</link>
      <description>arXiv:2411.16195v1 Announce Type: cross 
Abstract: The successive projection algorithm (SPA) is a workhorse algorithm to learn the $r$ vertices of the convex hull of a set of $(r-1)$-dimensional data points, a.k.a. a latent simplex, which has numerous applications in data science. In this paper, we revisit the robustness to noise of SPA and several of its variants. In particular, when $r \geq 3$, we prove the tightness of the existing error bounds for SPA and for two more robust preconditioned variants of SPA. We also provide significantly improved error bounds for SPA, by a factor proportional to the conditioning of the $r$ vertices, in two special cases: for the first extracted vertex, and when $r \leq 2$. We then provide further improvements for the error bounds of a translated version of SPA proposed by Arora et al. (''A practical algorithm for topic modeling with provable guarantees'', ICML, 2013) in two special cases: for the first two extracted vertices, and when $r \leq 3$. Finally, we propose a new more robust variant of SPA that first shifts and lifts the data points in order to minimize the conditioning of the problem. We illustrate our results on synthetic data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16195v1</guid>
      <category>math.NA</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>stat.ML</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giovanni Barbarino, Nicolas Gillis</dc:creator>
    </item>
    <item>
      <title>Scalable Fault-Tolerant MapReduce</title>
      <link>https://arxiv.org/abs/2411.16255</link>
      <description>arXiv:2411.16255v1 Announce Type: cross 
Abstract: Supercomputers getting ever larger and energy-efficient is at odds with the reliability of the used hardware. Thus, the time intervals between component failures are decreasing. Contrarily, the latencies for individual operations of coarse-grained big-data tools grow with the number of processors. To overcome the resulting scalability limit, we need to go beyond the current practice of interoperation checkpointing. We give first results on how to achieve this for the popular MapReduce framework where huge multisets are processed by user-defined mapping and reducing functions. We observe that the full state of a MapReduce algorithm is described by its network communication. We present a low-overhead technique with no additional work during fault-free execution and the negligible expected relative communication overhead of $1/(p-1)$ on $p$ PEs. Recovery takes approximately the time of processing $1/p$ of the data on the surviving PEs. We achieve this by backing up self-messages and locally storing all messages sent through the network on the sending and receiving PEs until the next round of global communication. A prototypical implementation already indicates low overhead $&lt;4\,\%$ during fault-free execution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16255v1</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Demian Hespe, Lukas H\"ubner, Charel Mercatoris, Peter Sanders</dc:creator>
    </item>
    <item>
      <title>Bow Metrics and Hyperbolicity</title>
      <link>https://arxiv.org/abs/2411.16548</link>
      <description>arXiv:2411.16548v1 Announce Type: cross 
Abstract: A ($\lambda,\mu$)-bow metric was defined in (Dragan &amp; Ducoffe, 2023) as a far reaching generalization of an $\alpha_i$-metric (which is equivalent to a ($0,i$)-bow metric). A graph $G=(V,E)$ is said to satisfy ($\lambda,\mu$)-bow metric if for every four vertices $u,v,w,x$ of $G$ the following holds: if two shortest paths $P(u,w)$ and $P(v,x)$ share a common shortest subpath $P(v,w)$ of length more than $\lambda$ (that is, they overlap by more than $\lambda$), then the distance between $u$ and $x$ is at least $d_G(u,v)+d_G(v,w)+d_G(w,x)-\mu$. ($\lambda,\mu$)-Bow metric can also be considered for all geodesic metric spaces. It was shown by Dragan &amp; Ducoffe that every $\delta$-hyperbolic graph (in fact, every $\delta$-hyperbolic geodesic metric space) satisfies ($\delta, 2\delta$)-bow metric. Thus, ($\lambda,\mu$)-bow metric is a common generalization of hyperbolicity and of $\alpha_i$-metric. In this paper, we investigate an intriguing question whether ($\lambda,\mu$)-bow metric implies hyperbolicity in graphs. Note that, this is not the case for general geodesic metric spaces as Euclidean spaces satisfy ($0,0$)-bow metric whereas they have unbounded hyperbolicity. We conjecture that, in graphs, ($\lambda,\mu$)-bow metric indeed implies hyperbolicity and show that our conjecture is true for several large families of graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16548v1</guid>
      <category>math.CO</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Feodor F. Dragan, Guillaume Ducoffe, Michel Habib, Laurent Viennot</dc:creator>
    </item>
    <item>
      <title>Leakage-Robust Bayesian Persuasion</title>
      <link>https://arxiv.org/abs/2411.16624</link>
      <description>arXiv:2411.16624v1 Announce Type: cross 
Abstract: We introduce the concept of leakage-robust Bayesian persuasion. Situated between public persuasion [KG11, CCG23, Xu20] and private persuasion [AB19], leakage-robust persuasion considers a setting where one or more signals privately sent by a sender to the receivers may be leaked. We study the design of leakage-robust persuasion schemes and quantify the price of robustness using two formalisms:
  - The first notion, $k$-worst-case persuasiveness, requires a scheme to remain persuasive as long as each receiver observes at most $k$ leaked signals. We quantify the Price of Worst-case Robustness (PoWR$_k$) -- i.e., the gap in sender's utility as compared to the optimal private scheme -- as $\Theta(\min\{2^k,n\})$ for supermodular sender utilities and $\Theta(k)$ for submodular or XOS utilities, where $n$ is the number of receivers. This result also establishes that in some instances, $\Theta(\log k)$ leakages are sufficient for the utility of the optimal leakage-robust persuasion to degenerate to that of public persuasion.
  - The second notion, expected downstream utility robustness, relaxes the persuasiveness and considers the impact on sender's utility when receivers best respond to their observations. By quantifying the Price of Downstream Robustness (PoDR) as the gap between the sender's expected utility over random leakage patterns as compared to private persuasion, we show that over several natural and structured distributions of leakage patterns, PoDR improves PoWR to $\Theta(k)$ or even $\Theta(1)$, where $k$ is the maximum number of leaked signals observable to each receiver across leakage patterns in the distribution.
  En route to these results, we show that subsampling and masking are general-purpose algorithmic paradigms for transforming private persuasion signaling schemes to leakage-robust ones, with minmax optimal loss in the sender's utility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16624v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <category>cs.MA</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nika Haghtalab, Mingda Qiao, Kunhe Yang</dc:creator>
    </item>
    <item>
      <title>OPMOS: Ordered Parallel Multi-Objective Shortest-Path</title>
      <link>https://arxiv.org/abs/2411.16667</link>
      <description>arXiv:2411.16667v1 Announce Type: cross 
Abstract: The Multi-Objective Shortest-Path (MOS) problem finds a set of Pareto-optimal solutions from a start node to a destination node in a multi-attribute graph. To solve the NP-hard MOS problem, the literature explores heuristic multi-objective A*-style algorithmic approaches. A generalized MOS algorithm maintains a "frontier" of partial paths at each node and performs ordered processing to ensure that Pareto-optimal paths are generated to reach the goal node. The algorithm becomes computationally intractable as the number of objectives increases due to a rapid increase in the non-dominated paths, and the concomitantly large increase in Pareto-optimal solutions. While prior works have focused on algorithmic methods to reduce the complexity, we tackle this challenge by exploiting parallelism using an algorithm-architecture approach. The key insight is that MOS algorithms rely on the ordered execution of partial paths to maintain high work efficiency. The OPMOS framework, proposed herein, unlocks ordered parallelism and efficiently exploits the concurrent execution of multiple paths in MOS. Experimental evaluation using the NVIDIA GH200 Superchip shows the performance scaling potential of OPMOS on work efficiency and parallelism using a real-world application to ship routing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16667v1</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <category>cs.AR</category>
      <category>cs.DS</category>
      <category>cs.PF</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Leo Gold, Adam Bienkowski, David Sidoti, Krishna Pattipati, Omer Khan</dc:creator>
    </item>
    <item>
      <title>Fast Practical Compression of Deterministic Finite Automata</title>
      <link>https://arxiv.org/abs/2306.12771</link>
      <description>arXiv:2306.12771v4 Announce Type: replace 
Abstract: We revisit the popular \emph{delayed deterministic finite automaton} (\ddfa{}) compression algorithm introduced by Kumar~et~al.~[SIGCOMM 2006] for compressing deterministic finite automata (DFAs) used in intrusion detection systems. This compression scheme exploits similarities in the outgoing sets of transitions among states to achieve strong compression while maintaining high throughput for matching.
  The \ddfa{} algorithm and later variants of it, unfortunately, require at least quadratic compression time since they compare all pairs of states to compute an optimal compression. This is too slow and, in some cases, even infeasible for collections of regular expression in modern intrusion detection systems that produce DFAs of millions of states.
  Our main result is a simple, general framework for constructing \ddfa{} based on locality-sensitive hashing that constructs an approximation of the optimal \ddfa{} in near-linear time. We apply our approach to the original \ddfa{} compression algorithm and two important variants, and we experimentally evaluate our algorithms on DFAs from widely used modern intrusion detection systems. Overall, our new algorithms compress up to an order of magnitude faster than existing solutions with either no or little loss of compression size. Consequently, our algorithms are significantly more scalable and can handle larger collections of regular expressions than previous solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.12771v4</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Philip Bille, Inge Li G{\o}rtz, Max Rish{\o}j Pedersen</dc:creator>
    </item>
    <item>
      <title>Collision-Free Robot Scheduling</title>
      <link>https://arxiv.org/abs/2402.12019</link>
      <description>arXiv:2402.12019v2 Announce Type: replace 
Abstract: Robots are becoming an increasingly common part of scientific work within laboratory environments. In this paper, we investigate the problem of designing \emph{schedules} for completing a set of tasks at fixed locations with multiple robots in a laboratory. We represent the laboratory as a graph with tasks placed on fixed vertices and robots represented as agents, with the constraint that no two robots may occupy the same vertex at any given timestep. Each schedule is partitioned into a set of timesteps, corresponding to a walk through the graph (allowing for a robot to wait at a vertex to complete a task), with each timestep taking time equal to the time for a robot to move from one vertex to another and each task taking some given number of timesteps during the completion of which a robot must stay at the vertex containing the task. The goal is to determine a set of schedules, with one schedule for each robot, minimising the number of timesteps taken by the schedule taking the greatest number of timesteps within the set of schedules.
  We show that this problem is NP-complete for many simple classes of graphs, the problem of determining the fastest schedule, defined by the number of time steps required for a robot to visit every vertex in the schedule and complete every task assigned in its assigned schedule. Explicitly, we provide this result for complete graphs, bipartite graphs, star graphs, and planar graphs. Finally, we provide positive results for line graphs, showing that we can find an optimal set of schedules for $k$ robots completing $m$ tasks of equal length of a path of length $n$ in $O(kmn)$ time, and a $k$-approximation when the length of the tasks is unbounded.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.12019v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Duncan Adamson, Nathan Flaherty, Igor Potapov, Paul Spirakis</dc:creator>
    </item>
    <item>
      <title>Structural and Algorithmic Results for Stable Cycles and Partitions in the Roommates Problem</title>
      <link>https://arxiv.org/abs/2406.00437</link>
      <description>arXiv:2406.00437v3 Announce Type: replace 
Abstract: In the Stable Roommates problem, we seek a stable matching of the agents into pairs, in which no two agents have an incentive to deviate from their assignment. It is well known that a stable matching is unlikely to exist, but a stable partition always does and provides a succinct certificate for the unsolvability of an instance. Furthermore, apart from being a useful structural tool to study the problem, every stable partition corresponds to a stable half-matching, which has applications, for example, in sports scheduling and time-sharing.
  We establish new structural results for stable partitions and show how to enumerate all stable partitions and the cycles included in such structures efficiently. We also adapt optimality criteria from stable matchings to stable partitions and give complexity and approximability results for the problems of computing such "fair" and "optimal" stable partitions.
  Through this research, we contribute to a deeper understanding of stable partitions from a combinatorial point of view, as well as the computational complexity of computing "fair" or "optimal" stable half-matchings in practice, closing the gap between integral and fractional stable matchings and paving the way for further applications of stable partitions to unsolvable instances and computationally hard stable matching problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00437v3</guid>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Frederik Glitzner, David Manlove</dc:creator>
    </item>
    <item>
      <title>A Simple Algorithm for Dynamic Carpooling with Recourse</title>
      <link>https://arxiv.org/abs/2411.07553</link>
      <description>arXiv:2411.07553v2 Announce Type: replace 
Abstract: We give an algorithm for the fully-dynamic carpooling problem with recourse: Edges arrive and depart online from a graph $G$ with $n$ nodes according to an adaptive adversary. Our goal is to maintain an orientation $H$ of $G$ that keeps the discrepancy, defined as $\max_{v \in V} |\text{deg}_H^+(v) - \text{deg}_H^-(v)|$, small at all times. We present a simple algorithm and analysis for this problem with recourse based on cycles that simplifies and improves on a result of Gupta et al. [SODA '22].</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07553v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuval Efron, Shyamal Patel, Cliff Stein</dc:creator>
    </item>
    <item>
      <title>An Algorithm for the Longest Common Subsequence and Substring Problem for Multiple Strings</title>
      <link>https://arxiv.org/abs/2411.09472</link>
      <description>arXiv:2411.09472v2 Announce Type: replace 
Abstract: Let $X_1, X_2, ..., X_s$ and $Y_1, Y_2, ..., Y_t$ be strings over an alphabet $\Sigma$, where $s$ and $t$ are positive integers. The longest common subsequence and substring problem for multiple strings $X_1, X_2, ..., X_s$ and $Y_1, Y_2, ..., Y_t$ is to find the longest string which is a subsequence of $X_1, X_2, ..., X_s$ and a substring of $Y_1, Y_2, ..., Y_t$. In this paper, we propose an algorithm to solve the problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.09472v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rao Li</dc:creator>
    </item>
    <item>
      <title>Fault-Equivalent Lowest Common Ancestors</title>
      <link>https://arxiv.org/abs/2411.11049</link>
      <description>arXiv:2411.11049v2 Announce Type: replace 
Abstract: Let $T$ be a rooted tree in which a set $M$ of vertices are marked. The lowest common ancestor (LCA) of $M$ is the unique vertex $\ell$ with the following property: after failing (i.e., deleting) any single vertex $x$ from $T$, the root remains connected to $\ell$ if and only if it remains connected to some marked vertex. In this note, we introduce a generalized notion called $f$-fault-equivalent LCAs ($f$-FLCA), obtained by adapting the above view to $f$ failures for arbitrary $f \geq 1$. We show that there is a unique vertex set $M^* = \operatorname{FLCA}(M,f)$ of minimal size such after the failure of any $f$ vertices (or less), the root remains connected to some $v \in M$ iff it remains connected to some $u \in M^*$. Computing $M^*$ takes linear time. A bound of $|M^*| \leq 2^{f-1}$ always holds, regardless of $|M|$, and holds with equality for some choice of $T$ and $M$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11049v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Asaf Petruschka</dc:creator>
    </item>
    <item>
      <title>Massively Parallel Maximum Coverage Revisited</title>
      <link>https://arxiv.org/abs/2411.11277</link>
      <description>arXiv:2411.11277v2 Announce Type: replace 
Abstract: We study the maximum set coverage problem in the massively parallel model. In this setting, $m$ sets that are subsets of a universe of $n$ elements are distributed among $m$ machines. In each round, these machines can communicate with each other, subject to the memory constraint that no machine may use more than $\tilde{O}(n)$ memory. The objective is to find the $k$ sets whose coverage is maximized. We consider the regime where $k = \Omega(m)$, $m = O(n)$, and each machine has $\tilde{O}(n)$ memory. Maximum coverage is a special case of the submodular maximization problem subject to a cardinality constraint. This problem can be approximated to within a $1-1/e$ factor using the greedy algorithm, but this approach is not directly applicable to parallel and distributed models. When $k = \Omega(m)$, to obtain a $1-1/e-\epsilon$ approximation, previous work either requires $\tilde{O}(mn)$ memory per machine which is not interesting compared to the trivial algorithm that sends the entire input to a single machine, or requires $2^{O(1/\epsilon)} n$ memory per machine which is prohibitively expensive even for a moderately small value $\epsilon$. Our result is a randomized $(1-1/e-\epsilon)$-approximation algorithm that uses $O(1/\epsilon^3 \cdot \log m \cdot (\log (1/\epsilon) + \log m))$ rounds. Our algorithm involves solving a slightly transformed linear program of the maximum coverage problem using the multiplicative weights update method, classic techniques in parallel computing such as parallel prefix, and various combinatorial arguments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11277v2</guid>
      <category>cs.DS</category>
      <category>cs.DC</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thai Bui, Hoa T. Vu</dc:creator>
    </item>
    <item>
      <title>A refined graph container lemma and applications to the hard-core model on bipartite expanders</title>
      <link>https://arxiv.org/abs/2411.03393</link>
      <description>arXiv:2411.03393v2 Announce Type: replace-cross 
Abstract: We establish a refined version of a graph container lemma due to Galvin and discuss several applications related to the hard-core model on bipartite expander graphs. Given a graph $G$ and $\lambda&gt;0$, the hard-core model on $G$ at activity $\lambda$ is the probability distribution $\mu_{G,\lambda}$ on independent sets in $G$ given by $\mu_{G,\lambda}(I)\propto \lambda^{|I|}$. As one of our main applications, we show that the hard-core model at activity $\lambda$ on the hypercube $Q_d$ exhibits a `structured phase' for $\lambda= \Omega( \log^2 d/d^{1/2})$ in the following sense: in a typical sample from $\mu_{Q_d,\lambda}$, most vertices are contained in one side of the bipartition of $Q_d$. This improves upon a result of Galvin which establishes the same for $\lambda=\Omega(\log d/ d^{1/3})$. As another application, we establish a fully polynomial-time approximation scheme (FPTAS) for the hard-core model on a $d$-regular bipartite $\alpha$-expander, with $\alpha&gt;0$ fixed, when $\lambda= \Omega( \log^2 d/d^{1/2})$. This improves upon the bound $\lambda=\Omega(\log d/ d^{1/4})$ due to the first author, Perkins and Potukuchi. We discuss similar improvements to results of Galvin-Tetali, Balogh-Garcia-Li and Kronenberg-Spinka.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03393v2</guid>
      <category>math.CO</category>
      <category>cs.DS</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthew Jenssen, Alexandru Malekshahian, Jinyoung Park</dc:creator>
    </item>
  </channel>
</rss>
