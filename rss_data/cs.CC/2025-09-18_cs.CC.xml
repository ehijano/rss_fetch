<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 19 Sep 2025 04:01:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>An MDL-Style Cost Functional KC, Distribution-Preserving Reductions (A2^d), and an AC^0+log Lower Bound for 3SAT via Balanced 3XOR</title>
      <link>https://arxiv.org/abs/2509.14305</link>
      <description>arXiv:2509.14305v1 Announce Type: new 
Abstract: We introduce a model-agnostic MDL-style cost functional $K_C$ for resource-bounded classifiers and prove a Total-Variation stable reduction lemma ($A2^d$) for distribution-preserving many-to-one reductions. On a balanced distribution of random 3XOR instances (with co-rank $t'=\Theta(n)$) we obtain a size-aware lower bound against P-uniform AC^0+log models: $\Pr[M=\chi] \le \frac{1}{2} + s(N)\exp(-\alpha_d m^{c/d})$ with an absolute $c \in (0,1)$ (e.g., $c=1/3$ gives $\beta_d=1/(3d)$). A deterministic, injective 3XOR-&gt;3SAT translation (four 3-clauses per XOR, no auxiliaries) is $\delta=0$ measure-preserving on its image window; by $A2^d$ the bound transfers to 3SAT. This yields, to our knowledge, the first explicit $K_C$-reading of such size-aware bounds under a $\delta=0$ measure-preserving reduction in small-depth circuit lower bounds. We provide artifacts (generator -&gt; DIMACS -&gt; verification) with match-rate 1.0.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14305v1</guid>
      <category>cs.CC</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marko Lela</dc:creator>
    </item>
    <item>
      <title>The Complexity of Finding and Counting Subtournaments</title>
      <link>https://arxiv.org/abs/2509.14807</link>
      <description>arXiv:2509.14807v1 Announce Type: new 
Abstract: We study the complexity of counting and finding small tournament patterns inside large tournaments. Given a fixed tournament $T$ of order $k$, we write ${\#}\text{IndSub}_{\text{To}}(\{T\})$ for the problem whose input is a tournament $G$ and the task is to compute the number of subtournaments of $G$ that are isomorphic to $T$. Previously, Yuster [Yus25] obtained that ${\#}\text{IndSub}_{\text{To}}(\{T\})$ is hard to compute for random tournaments $T$. We consider a new approach that uses linear combinations of subgraph-counts [CDM17] to obtain a finer analysis of the complexity of ${\#}\text{IndSub}_{\text{To}}(\{T\})$.
  We show that for all tournaments $T$ of order $k$ the problem ${\#}\text{IndSub}_{\text{To}}(\{T\})$ is always at least as hard as counting $\lfloor 3k/4 \rfloor$-cliques. This immediately yields tight bounds under ETH. Further, we consider the parameterized version of ${\#}\text{IndSub}_{\text{To}}(\mathcal{T})$ where we only consider patterns $T \in \mathcal{T}$ and that is parameterized by the pattern size $|V(T)|$. We show that ${\#}\text{IndSub}_{\text{To}}(\mathcal{T})$ is ${\#}W[1]$-hard as long as $\mathcal{T}$ contains infinitely many tournaments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14807v1</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Simon D\"oring, Sarah Houdaigoui, Lucas Picasarri-Arrieta, Philip Wellnitz</dc:creator>
    </item>
    <item>
      <title>Freeze-Tag is NP-hard in 2D with $L_1$ distance</title>
      <link>https://arxiv.org/abs/2509.14357</link>
      <description>arXiv:2509.14357v1 Announce Type: cross 
Abstract: The Freeze-Tag Problem (FTP) is a scheduling problem with application in robot swarm activation and was introduced by Arkin et al. in 2002. This problem seeks an efficient way of activating a robot swarm starting with a single active robot. Activations occur through direct contact, and once a robot becomes active, it can move and help activate other robots.
  Although the problem has been shown to be NP-hard in the Euclidean plane $R^2$ under the $L_2$ distance, and in three-dimensional Euclidean space $R^3$ under any $L_p$ distance with $p \ge 1$, its complexity under the $L_1$ (Manhattan) distance in $R^2$ has remained an open question. In this paper, we settle this question by proving that FTP is strongly NP-hard in the Euclidean plane with $L_1$ distance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14357v1</guid>
      <category>cs.CG</category>
      <category>cs.CC</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Lucas de Oliveira Silva, Lehilton Lelis Chaves Pedrosa</dc:creator>
    </item>
    <item>
      <title>On the Complexity of Decoded Quantum Interferometry</title>
      <link>https://arxiv.org/abs/2509.14443</link>
      <description>arXiv:2509.14443v1 Announce Type: cross 
Abstract: We study the complexity of Decoded Quantum Interferometry (DQI), a recently proposed quantum algorithm for approximate optimization. We argue that DQI is hard to classically simulate, and that the hardness comes from locating an exponentially large hidden subset. This type of hardness is shared by Shor's algorithm, but the hidden subset here has no apparent group structure. We first prove that DQI can be simulated in a low level of the polynomial hierarchy, ruling out hardness arguments related to quantum supremacy. Instead, we show that DQI implements an existential coding theory bound based on the MacWilliams identity, and that it prepares a state within an obfuscated quantum harmonic oscillator. Both viewpoints require a coherent application of a discrete Hermite transform, which has no natural classical analog.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14443v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kunal Marwaha, Bill Fefferman, Alexandru Gheorghiu, Vojtech Havlicek</dc:creator>
    </item>
    <item>
      <title>Efficiently learning depth-3 circuits via quantum agnostic boosting</title>
      <link>https://arxiv.org/abs/2509.14461</link>
      <description>arXiv:2509.14461v1 Announce Type: cross 
Abstract: We initiate the study of quantum agnostic learning of phase states with respect to a function class $\mathsf{C}\subseteq \{c:\{0,1\}^n\rightarrow \{0,1\}\}$: given copies of an unknown $n$-qubit state $|\psi\rangle$ which has fidelity $\textsf{opt}$ with a phase state $|\phi_c\rangle=\frac{1}{\sqrt{2^n}}\sum_{x\in \{0,1\}^n}(-1)^{c(x)}|x\rangle$ for some $c\in \mathsf{C}$, output $|\phi\rangle$ which has fidelity $|\langle \phi | \psi \rangle|^2 \geq \textsf{opt}-\varepsilon$. To this end, we give agnostic learning protocols for the following classes: (i) Size-$t$ decision trees which runs in time $\textsf{poly}(n,t,1/\varepsilon)$. This also implies $k$-juntas can be agnostically learned in time $\textsf{poly}(n,2^k,1/\varepsilon)$. (ii) $s$-term DNF formulas in near-polynomial time $\textsf{poly}(n,(s/\varepsilon)^{\log \log s/\varepsilon})$.
  Our main technical contribution is a quantum agnostic boosting protocol which converts a weak agnostic learner, which outputs a parity state $|\phi\rangle$ such that $|\langle \phi|\psi\rangle|^2\geq \textsf{opt}/\textsf{poly}(n)$, into a strong learner which outputs a superposition of parity states $|\phi'\rangle$ such that $|\langle \phi'|\psi\rangle|^2\geq \textsf{opt} - \varepsilon$.
  Using quantum agnostic boosting, we obtain the first near-polynomial time $n^{O(\log \log n)}$ algorithm for learning $\textsf{poly}(n)$-sized depth-$3$ circuits (consisting of $\textsf{AND}$, $\textsf{OR}$, $\textsf{NOT}$ gates) in the uniform quantum $\textsf{PAC}$ model using quantum examples. Classically, the analogue of efficient learning depth-$3$ circuits (and even depth-$2$ circuits) in the uniform $\textsf{PAC}$ model has been a longstanding open question in computational learning theory. Our work nearly settles this question, when the learner is given quantum examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14461v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Srinivasan Arunachalam, Arkopal Dutt, Alexandru Gheorghiu, Michael de Oliveira</dc:creator>
    </item>
    <item>
      <title>Kronecker Powers, Orthogonal Vectors, and the Asymptotic Spectrum</title>
      <link>https://arxiv.org/abs/2509.14489</link>
      <description>arXiv:2509.14489v1 Announce Type: cross 
Abstract: We study circuits for computing depth-2 linear transforms defined by Kronecker power matrices. Recent works have improved on decades-old constructions in this area using a new ''rebalancing'' approach [Alman, Guan and Padaki, SODA'23; Sergeev'22], but it was unclear how to apply this approach optimally.
  We find that Strassen's theory of asymptotic spectra can be applied to capture the design of these circuits. In particular, in hindsight, we find that the techniques of recent work on rebalancing were proving special cases of the duality theorem, which is central to Strassen's theory. We carefully outline a collection of ''obstructions'' to designing small depth-2 circuits using a rebalancing approach, and apply Strassen's theory to show that our obstructions are complete.
  Using this connection, combined with other algorithmic techniques, we give new improved circuit constructions as well as other applications, including:
  - The $N \times N$ disjointness matrix has a depth-2 linear circuit of size $O(N^{1.2495})$ over any field. This also yield smaller circuits for many families of matrices using reductions to disjointness.
  - The Strong Exponential Time Hypothesis implies an $N^{1 + \Omega(1)}$ size lower bound for depth-2 linear circuits computing the Walsh--Hadamard transform (and the disjointness matrix with a technical caveat), and proving a $N^{1 + \Omega(1)}$ depth-2 size lower bound would also imply breakthrough threshold circuit lower bounds.
  - The Orthogonal Vectors (OV) problem in moderate dimension $d$ can be solved in deterministic time $\tilde{O}(n \cdot 1.155^d)$, derandomizing an algorithm of Nederlof and W\k{e}grzycki [STOC'21], and the counting problem can be solved in time $\tilde{O}(n \cdot 1.26^d)$, improving an algorithm of Williams [FOCS'24] which runs in time $\tilde{O}(n \cdot 1.35^d)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14489v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Josh Alman, Baitian Li</dc:creator>
    </item>
    <item>
      <title>Realizing Metric Spaces with Convex Obstacles</title>
      <link>https://arxiv.org/abs/2509.14709</link>
      <description>arXiv:2509.14709v1 Announce Type: cross 
Abstract: The presence of obstacles has a major impact on distance computation, motion planning, and visibility. While these problems are well studied in the plane, our understanding in three and higher dimensions is still limited. We investigate how different obstacle properties affect the induced geodesic metric in three-dimensional space. A finite metric space is said to be approximately realizable by a collection of obstacles if, for any $\varepsilon&gt;0$, it can be embedded into the free space around the obstacles with geodesic distance and worst-case distortion $1+\varepsilon$. We focus on three key properties-convexity, disjointness, and fatness-and analyze how omitting each of them influences realizability.
  Our main result shows that if fatness is dropped, then every finite metric space can be realized with distortion $1+\varepsilon$ using convex, pairwise disjoint obstacles in $\mathbb{R}^3$, even if all obstacles are congruent equilateral triangles. Moreover, if we enforce fatness but drop convexity or disjointness, the same realizability still holds.
  Our results have important implications on the approximability of TSP with Obstacles, a natural variant of TSP introduced recently by Alkema et al. (ESA 2022). Specifically, we use the recent results of Banerjee et al. on TSP in doubling spaces (FOCS 2024) and of Chew et al. on distances among obstacles (Information Processing Letters 2002) to show that TSP with Obstacles admits a PTAS if the obstacles are convex, fat, and pairwise disjoint. If any of these three properties is dropped, then our results, combined with the APX-hardness of Metric TSP, demonstrate that TSP with Obstacles is APX-hard.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14709v1</guid>
      <category>cs.CG</category>
      <category>cs.CC</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>S\'andor Kisfaludi-Bak, Leonidas Theocharous</dc:creator>
    </item>
    <item>
      <title>On the complexity of unique quantum witnesses and quantum approximate counting</title>
      <link>https://arxiv.org/abs/2410.23811</link>
      <description>arXiv:2410.23811v2 Announce Type: replace-cross 
Abstract: We study the long-standing open question on the power of unique witnesses in quantum protocols, which asks if $\textsf{UniqueQMA}$, a variant of $\textsf{QMA}$ whose accepting witness space is 1-dimensional, contains $\mathsf{QMA}$ under quantum reductions.
  This work rules out any black-box reduction from $\mathsf{QMA}$ to $\mathsf{UniqueQMA}$ by showing a quantum oracle separation between $\mathsf{BQP}^\mathsf{UniqueQMA}$ and $\mathsf{QMA}$. This provides a contrast to the classical case, where the Valiant-Vazirani theorem shows a black-box randomized reduction from $\mathsf{UniqueNP}$ to $\mathsf{NP}$, and suggests the need for studying the structure of the ground space of local Hamiltonians in distilling a potential unique witness. Via similar techniques, we show, relative to a quantum oracle, that $\mathsf{QMA}^\mathsf{QMA}$ cannot decide quantum approximate counting, ruling out a quantum analogue of Stockmeyer's algorithm in the black-box setting.
  We then ask a natural question; what structural properties of the local Hamiltonian problem can we exploit? We introduce a physically motivated candidate by showing that the ground energy of local Hamiltonians that satisfy a computational variant of the eigenstate thermalization hypothesis (ETH) can be estimated through a $\mathsf{UniqueQMA}$ protocol. Our protocol can be viewed as a quantum expander test in a low energy subspace of the Hamiltonian and verifies a unique entangled state across two copies of the subspace. This allows us to conclude that if $\mathsf{UniqueQMA}$ is not equivalent to $\mathsf{QMA}$, then $\mathsf{QMA}$-hard Hamiltonians must violate ETH under adversarial perturbations. This also serves as evidence that chaotic local Hamiltonians, such as the SYK model may be computationally simpler than general local Hamiltonians.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23811v2</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anurag Anshu, Jonas Haferkamp, Yeongwoo Hwang, Quynh T. Nguyen</dc:creator>
    </item>
    <item>
      <title>Benford's Law from Turing Ensembles and Integer Partitions</title>
      <link>https://arxiv.org/abs/2502.16314</link>
      <description>arXiv:2502.16314v4 Announce Type: replace-cross 
Abstract: We develop two complementary generative mechanisms that explain when and why Benford's first-digit law arises. First, a probabilistic Turing machine (PTM) ensemble induces a geometric law for code length. Maximizing its entropy under a constraint on halting length yields Benford statistics. This model shows a phase transition with respect to the halt probability. Second, a constrained partition model (Einstein-solid combinatorics) recovers the same logarithmic profile as the maximum-entropy solution under a coarse-grained entropy-rate constraint, clarifying the role of non-ergodicity (ensemble vs.\ trajectory averages). We also perform numerical experiments that corroborate our conclusions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16314v4</guid>
      <category>cs.IT</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>math-ph</category>
      <category>math.IT</category>
      <category>math.MP</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Kolpakov, Aidan Rocke</dc:creator>
    </item>
    <item>
      <title>Trainability of Quantum Models Beyond Known Classical Simulability</title>
      <link>https://arxiv.org/abs/2507.06344</link>
      <description>arXiv:2507.06344v2 Announce Type: replace-cross 
Abstract: Variational Quantum Algorithms (VQAs) are promising candidates for near-term quantum computing, yet they face scalability challenges due to barren plateaus, where gradients vanish exponentially in the system size. Recent conjectures suggest that avoiding barren plateaus might inherently lead to classical simulability, thus limiting the opportunities for quantum advantage. In this work, we advance the theoretical understanding of the relationship between the trainability and computational complexity of VQAs, thus directly addressing the conjecture. We introduce the Linear Clifford Encoder (LCE), a novel technique that ensures constant-scaling gradient statistics on optimization landscape regions that are close to Clifford circuits. Additionally, we leverage classical Taylor surrogates to reveal computational complexity phase transitions from polynomial to super-polynomial as the initialization region size increases. Combining these results, we reveal a deeper link between trainability and computational complexity, and analytically prove that barren plateaus can be avoided in regions for which no classical surrogate is known to exist. Furthermore, numerical experiments on LCE transformed landscapes confirm in practice the existence of a super-polynomially complex ``transition zone'' where gradients decay polynomially. These findings indicate a plausible path to practically relevant, barren plateau-free variational models with potential for quantum advantage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06344v2</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sabri Meyer, Francesco Scala, Francesco Tacchino, Aurelien Lucchi</dc:creator>
    </item>
    <item>
      <title>4-uniform Maker-Breaker and Maker-Maker games are PSPACE-complete</title>
      <link>https://arxiv.org/abs/2509.13819</link>
      <description>arXiv:2509.13819v2 Announce Type: replace-cross 
Abstract: We study two positional games where two players take turns picking a previously unpicked vertex of a hypergraph $H$. We say a player fills an edge of $H$ if that player has picked all the vertices of that edge. In the Maker-Maker game, whoever first fills an edge wins, or we get a draw if no edge is filled. In the Maker-Breaker game, the first player aims at filling an edge while the second player aims at preventing the first player from filling an edge. We show that, for both games, deciding whether the first player has a winning strategy is a PSPACE-complete problem even when restricted to 4-uniform hypergraphs. For the Maker-Maker game, this improves on a previous result for hypergraphs of rank 4. For the Maker-Breaker game, this improves on a previous result for 5-uniform hypergraphs, and closes the complexity gap as the problem for hypergraphs of rank 3 is known to be solvable in polynomial time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.13819v2</guid>
      <category>cs.DM</category>
      <category>cs.CC</category>
      <category>math.CO</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Florian Galliot</dc:creator>
    </item>
  </channel>
</rss>
