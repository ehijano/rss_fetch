<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 20 Oct 2025 04:00:12 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 20 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Targeted Attacks and Defenses for Distributed Federated Learning in Vehicular Networks</title>
      <link>https://arxiv.org/abs/2510.15109</link>
      <description>arXiv:2510.15109v1 Announce Type: new 
Abstract: In emerging networked systems, mobile edge devices such as ground vehicles and unmanned aerial system (UAS) swarms collectively aggregate vast amounts of data to make machine learning decisions such as threat detection in remote, dynamic, and infrastructure-constrained environments where power and bandwidth are scarce. Federated learning (FL) addresses these constraints and privacy concerns by enabling nodes to share local model weights for deep neural networks instead of raw data, facilitating more reliable decision-making than individual learning. However, conventional FL relies on a central server to coordinate model updates in each learning round, which imposes significant computational burdens on the central node and may not be feasible due to the connectivity constraints. By eliminating dependence on a central server, distributed federated learning (DFL) offers scalability, resilience to node failures, learning robustness, and more effective defense strategies. Despite these advantages, DFL remains vulnerable to increasingly advanced and stealthy cyberattacks. In this paper, we design sophisticated targeted training data poisoning and backdoor (Trojan) attacks, and characterize the emerging vulnerabilities in a vehicular network. We analyze how DFL provides resilience against such attacks compared to individual learning and present effective defense mechanisms to further strengthen DFL against the emerging cyber threats.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.15109v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Mon, 20 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Utku Demir, Tugba Erpek, Yalin E. Sagduyu, Sastry Kompella, Mengran Xue</dc:creator>
    </item>
    <item>
      <title>Structural Generalization for Microservice Routing Using Graph Neural Networks</title>
      <link>https://arxiv.org/abs/2510.15210</link>
      <description>arXiv:2510.15210v1 Announce Type: new 
Abstract: This paper focuses on intelligent routing in microservice systems and proposes an end-to-end optimization framework based on graph neural networks. The goal is to improve routing decision efficiency and overall system performance under complex topologies. The method models invocation relationships among microservices as a graph. In this graph, service nodes and communication links are treated as graph nodes and edges. Multi-dimensional features such as node states, link latency, and call frequency are used as input. A multi-layer graph neural network is employed to perform high-order information aggregation and structural modeling. The model outputs a score for each candidate service path. These scores are then used to guide dynamic routing decisions. To improve the model's ability to assess path quality, an edge-aware attention mechanism is introduced. This mechanism helps the model capture instability and bottleneck risks in service communications more accurately. The paper also conducts a systematic analysis of the model's performance under different network depths, topology densities, and service scales. It evaluates the effectiveness of the method in terms of routing accuracy, prediction error, and system stability. Experimental results show that the proposed method outperforms existing mainstream strategies across multiple key metrics. It handles highly dynamic and concurrent microservice environments effectively and demonstrates strong performance, robustness, and structural generalization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.15210v1</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 20 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chenrui Hu, Ziyu Cheng, Di Wu, Yuxiao Wang, Feng Liu, Zhimin Qiu</dc:creator>
    </item>
    <item>
      <title>Content and Access Networks Synergies: Tradeoffs in Public and Private Investments by Content Providers</title>
      <link>https://arxiv.org/abs/2510.15373</link>
      <description>arXiv:2510.15373v1 Announce Type: new 
Abstract: The ubiquity of smartphones has fueled content consumption worldwide, leading to an ever-increasing demand for a better Internet experience. This has necessitated an upgrade of the capacity of the access network. The Internet service providers (ISPs) have been demanding that the content providers (CPs) share the cost of upgrading access network infrastructure. A \emph{public investment} in the infrastructure of a neutral ISP will boost the profit of the CPs, and hence, seems a rational strategy. A CP can also make a \emph{private investment} in its infrastructure and boost its profits. In this paper, we study the trade-off between public and private investments by a CP when the decision is made under different types of interaction between them. Specifically, we consider four interaction models between CPs -- centralized allocation, cooperative game, non-cooperative game, and a bargaining game -- and determine the public and private investment for each model. Via numerical results, we evaluate the impact of different incentive structures on the utility of the CPs. We see that the bargaining game can result in higher public investment than the non-cooperative and centralized models. However, this benefit gets reduced if the CPs are incentivized to invest in private infrastructure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.15373v1</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 20 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pranay Agarwal, D. Manjunath</dc:creator>
    </item>
    <item>
      <title>Uno: A One-Stop Solution for Inter- and Intra-Datacenter Congestion Control and Reliable Connectivity</title>
      <link>https://arxiv.org/abs/2510.15802</link>
      <description>arXiv:2510.15802v1 Announce Type: new 
Abstract: Cloud computing and AI workloads are driving unprecedented demand for efficient communication within and across datacenters. However, the coexistence of intra- and inter-datacenter traffic within datacenters plus the disparity between the RTTs of intra- and inter-datacenter networks complicates congestion management and traffic routing. Particularly, faster congestion responses of intra-datacenter traffic causes rate unfairness when competing with slower inter-datacenter flows. Additionally, inter-datacenter messages suffer from slow loss recovery and, thus, require reliability. Existing solutions overlook these challenges and handle inter- and intra-datacenter congestion with separate control loops or at different granularities. We propose Uno, a unified system for both inter- and intra-DC environments that integrates a transport protocol for rapid congestion reaction and fair rate control with a load balancing scheme that combines erasure coding and adaptive routing. Our findings show that Uno significantly improves the completion times of both inter- and intra-DC flows compared to state-of-the-art methods such as Gemini.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.15802v1</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 20 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3712285.3759884</arxiv:DOI>
      <arxiv:journal_reference>Proceedings of The International Conference for High Performance Computing Networking, Storage, and Analysis (SC '25) (2025)</arxiv:journal_reference>
      <dc:creator>Tommaso Bonato, Sepehr Abdous, Abdul Kabbani, Ahmad Ghalayini, Nadeen Gebara, Terry Lam, Anup Agarwal, Tiancheng Chen, Zhuolong Yu, Konstantin Taranov, Mahmoud Elhaddad, Daniele De Sensi, Soudeh Ghorbani, Torsten Hoefler</dc:creator>
    </item>
    <item>
      <title>BeLLMan: Controlling LLM Congestion</title>
      <link>https://arxiv.org/abs/2510.15330</link>
      <description>arXiv:2510.15330v1 Announce Type: cross 
Abstract: Large language model (LLM) applications are blindfolded to the infrastructure underneath and generate tokens autoregressively, indifferent to the system load, thus risking inferencing latency inflation and poor user experience. Our first-cut controller, named beLLMan, enables the LLM infrastructure to actively and progressively signal the first-party LLM application to adjust the output length in response to changing system load. On a real testbed with H100 GPUs, beLLMan helps keep inferencing latency under control (upto 8X lower end-to-end latency) and reduces energy consumption by 25% (while serving 19% more requests) during periods of congestion for a summarization workload.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.15330v1</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.NI</category>
      <pubDate>Mon, 20 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Tella Rajashekhar Reddy, Atharva Deshmukh, Karan Tandon, Rohan Gandhi, Anjaly Parayil, Debopam Bhattacherjee</dc:creator>
    </item>
    <item>
      <title>Flexible Qubit Allocation of Network Resource States</title>
      <link>https://arxiv.org/abs/2510.15776</link>
      <description>arXiv:2510.15776v1 Announce Type: cross 
Abstract: The Quantum Internet is still in its infancy, yet identifying scalable and resilient quantum network resource states is an essential task for realizing it. We explore the use of graph states with flexible, non-trivial qubit-to-node assignments. This flexibility enables adaptable engineering of the entanglement topology of an arbitrary quantum network. In particular, we focus on cluster states with arbitrary allocation as network resource states and as a promising candidate for a network core-level entangled resource, due to its intrinsic flexible connectivity properties and resilience to particle losses. We introduce a modeling framework for overlaying entanglement topologies on physical networks and demonstrate how optimized and even random qubit assignment, creates shortcuts and improves robustness and memory savings, while substantially reducing the average hop distance between remote network nodes, when compared to conventional approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.15776v1</guid>
      <category>quant-ph</category>
      <category>cs.NI</category>
      <pubDate>Mon, 20 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Francesco Mazza, Jorge Miguel-Ramiro, Jessica Illiano, Alexander Pirker, Marcello Caleffi, Angela Sara Cacciapuoti, Wolfgang D\"ur</dc:creator>
    </item>
    <item>
      <title>Ambusher: Exploring the Security of Distributed SDN Controllers Through Protocol State Fuzzing</title>
      <link>https://arxiv.org/abs/2510.15798</link>
      <description>arXiv:2510.15798v1 Announce Type: cross 
Abstract: Distributed SDN (Software-Defined Networking) controllers have rapidly become an integral element of Wide Area Networks (WAN), particularly within SD-WAN, providing scalability and fault-tolerance for expansive network infrastructures. However, the architecture of these controllers introduces new potential attack surfaces that have thus far received inadequate attention. In response to these concerns, we introduce Ambusher, a testing tool designed to discover vulnerabilities within protocols used in distributed SDN controllers. Ambusher achieves this by leveraging protocol state fuzzing, which systematically finds attack scenarios based on an inferred state machine. Since learning states from a cluster is complicated, Ambusher proposes a novel methodology that extracts a single and relatively simple state machine, achieving efficient state-based fuzzing. Our evaluation of Ambusher, conducted on a real SD-WAN deployment spanning two campus networks and one enterprise network, illustrates its ability to uncover 6 potential vulnerabilities in the widely used distributed controller platform.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.15798v1</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Mon, 20 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TIFS.2024.3402967</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Information Forensics and Security, Vol. 19, pp. 6264-6279, May 2024</arxiv:journal_reference>
      <dc:creator>Jinwoo Kim, Minjae Seo, Eduard Marin, Seungsoo Lee, Jaehyun Nam, Seungwon Shin</dc:creator>
    </item>
  </channel>
</rss>
