<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 23 Dec 2025 03:30:29 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 22 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>From Priors to Predictions: Explaining and Visualizing Human Reasoning in a Graph Neural Network Framework</title>
      <link>https://arxiv.org/abs/2512.17255</link>
      <description>arXiv:2512.17255v1 Announce Type: new 
Abstract: Humans excel at solving novel reasoning problems from minimal exposure, guided by inductive biases, assumptions about which entities and relationships matter. Yet the computational form of these biases and their neural implementation remain poorly understood. We introduce a framework that combines Graph Theory and Graph Neural Networks (GNNs) to formalize inductive biases as explicit, manipulable priors over structure and abstraction. Using a human behavioral dataset adapted from the Abstraction and Reasoning Corpus (ARC), we show that differences in graph-based priors can explain individual differences in human solutions. Our method includes an optimization pipeline that searches over graph configurations, varying edge connectivity and node abstraction, and a visualization approach that identifies the computational graph, the subset of nodes and edges most critical to a model's prediction. Systematic ablation reveals how generalization depends on specific prior structures and internal processing, exposing why human like errors emerge from incorrect or incomplete priors. This work provides a principled, interpretable framework for modeling the representational assumptions and computational dynamics underlying generalization, offering new insights into human reasoning and a foundation for more human aligned AI systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.17255v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <pubDate>Mon, 22 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Quan Do, Caroline Ahn, Leah Bakst, Michael Pascale, Joseph T. McGuire, Chantal E. Stern, Michael E. Hasselmo</dc:creator>
    </item>
    <item>
      <title>Novel Kuramoto model with inhibition dynamics modeling scale-free avalanches and synchronization in neuronal cultures</title>
      <link>https://arxiv.org/abs/2512.17317</link>
      <description>arXiv:2512.17317v1 Announce Type: new 
Abstract: Neuronal cultures exhibit a complex activity, bursts, or avalanches, characterized by the coexistence of scale invariance and synchronization, quite stable with the percentage of inhibitory neurons. While this bistable behavior has been already observed in the past, the characterization of the statistical properties of avalanche activity and their temporal organization is still lacking, as well as a model able to reproduce these dynamics. Here, we analyze experimental data of human neuronal cultures with controlled percentage of inhibitory neurons and characterize their statistical properties and dynamical organization. In order to model the experimental data, we propose a novel version of the Kuramoto model for two populations of oscillators, excitatory and inhibitory, implementing successfully the inhibition dynamics. The model can fully reproduce the experimental results, confirming the existence of correlations in the temporal organization of avalanche activity and the presence of an amplification - attenuation regime, as found in the human brain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.17317v1</guid>
      <category>q-bio.NC</category>
      <category>cond-mat.dis-nn</category>
      <pubDate>Mon, 22 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dario Lucente, Letizia Cerutti, Martina Brofiga, Alessandro Sarracino, Giulia Parodi, Sergio Martinoia, Paolo Massobrio, Lucilla de Arcangelis</dc:creator>
    </item>
    <item>
      <title>Gravity Prior and Temporal Horizon Shape Interceptive Behavior under Active Inference</title>
      <link>https://arxiv.org/abs/2512.17735</link>
      <description>arXiv:2512.17735v1 Announce Type: new 
Abstract: Accurate interception of moving objects, such as catching a ball, requires the nervous system to overcome sensory delays, noise, and environmental dynamics. One key challenge is predicting future object motion in the presence of sensory uncertainty and inherent neural processing latencies. Theoretical frameworks such as internal models and optimal control have emphasized the role of predictive mechanisms in motor behavior. Active Inference extends these ideas by positing that perception and action arise from minimizing variational free energy under a generative model of the world. In this study, we investigate how different predictive strategies and the inclusion of environmental dynamics, specifically an internal model of gravity, influence interceptive control within an Active Inference agent. We simulate a simplified ball-catching task in which the agent moves a cursor horizontally to intercept a parabolically falling object. Four strategies are compared: short temporal horizon prediction of the next position or long horizon estimation of the interception point, each with or without a gravity prior. Performance is evaluated across diverse initial conditions using spatial and temporal error, action magnitude, and movement corrections. All strategies produce successful interception behavior, but those that incorporate gravity and longer temporal horizons outperform others. Including a gravity prior significantly improves spatial and temporal accuracy. Predicting the future interception point yields lower action values and smoother trajectories compared to short-horizon prediction. These findings suggest that internal models of physical dynamics and extended predictive horizons can enhance interceptive control, providing a unified computational account of how the brain may integrate sensory uncertainty, physical expectations, and motor planning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.17735v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Mon, 22 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Marta Russo, Antonella Maselli, Federico Maggiore, Giovanni Pezzulo</dc:creator>
    </item>
    <item>
      <title>How Light Shapes Memory: Beta Synchrony in the Temporal-Parietal Cortex Predicts Cognitive Ergonomics for BCI Applications</title>
      <link>https://arxiv.org/abs/2512.17775</link>
      <description>arXiv:2512.17775v1 Announce Type: new 
Abstract: Working memory is a promising paradigm for assessing cognitive ergonomics of brain states in brain-computer interfaces(BCIs). This study decodes these states with a focus on environmental illumination effects via two distinct working memory tasks(Recall and Sequence) for mixed-recognition analysis. Leveraging nonlinear patterns in brain connectivity, we propose an innovative framework: multi-regional dynamic interplay patterns based on beta phase synchrony dynamics, to identify low-dimensional EEG regions (prefrontal, temporal, parietal) for state recognition. Based on nonlinear phase map analysis of the above three brain regions using beta-phase connectivity, we found that: (1)Temporal-parietal phase clustering outperforms other regional combinations in distinguishing memory states; (2)Illumination-enhanced environments optimize temporoparietal balance;(3) Machine learning confirms temporal-parietal synchrony as the dominant cross-task classification feature. These results provide a precise prediction algorithm, facilitating a low-dimensional system using temporal and parietal EEG channels with practical value for real-time cognitive ergonomics assessment in BCIs and optimized human-machine interaction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.17775v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Mon, 22 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiajia Li, Tian Guo, Fan Li, Huichao Ding, Guozheng Xu, Jian Song</dc:creator>
    </item>
    <item>
      <title>Bitbox: Behavioral Imaging Toolbox for Computational Analysis of Behavior from Videos</title>
      <link>https://arxiv.org/abs/2512.17655</link>
      <description>arXiv:2512.17655v1 Announce Type: cross 
Abstract: Computational measurement of human behavior from video has recently become feasible due to major advances in AI. These advances now enable granular and precise quantification of facial expression, head movement, body action, and other behavioral modalities and are increasingly used in psychology, psychiatry, neuroscience, and mental health research. However, mainstream adoption remains slow. Most existing methods and software are developed for engineering audiences, require specialized software stacks, and fail to provide behavioral measurements at a level directly useful for hypothesis-driven research. As a result, there is a large barrier to entry for researchers who wish to use modern, AI-based tools in their work. We introduce Bitbox, an open-source toolkit designed to remove this barrier and make advanced computational analysis directly usable by behavioral scientists and clinical researchers. Bitbox is guided by principles of reproducibility, modularity, and interpretability. It provides a standardized interface for extracting high-level behavioral measurements from video, leveraging multiple face, head, and body processors. The core modules have been tested and validated on clinical samples and are designed so that new measures can be added with minimal effort. Bitbox is intended to serve both sides of the translational gap. It gives behavioral researchers access to robust, high-level behavioral metrics without requiring engineering expertise, and it provides computer scientists a practical mechanism for disseminating methods to domains where their impact is most needed. We expect that Bitbox will accelerate integration of computational behavioral measurement into behavioral, clinical, and mental health research. Bitbox has been designed from the beginning as a community-driven effort that will evolve through contributions from both method developers and domain scientists.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.17655v1</guid>
      <category>cs.CV</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 22 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Evangelos Sariyanidi, Gokul Nair, Lisa Yankowitz, Casey J. Zampella, Mohan Kashyap Pargi, Aashvi Manakiwala, Maya McNealis, John D. Herrington, Jeffrey Cohn, Robert T. Schultz, Birkan Tunc</dc:creator>
    </item>
  </channel>
</rss>
