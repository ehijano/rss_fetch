<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IT</link>
    <description>cs.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 29 Jul 2025 02:12:44 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>RIS Codebook Index Assignment under Imperfect Control Links Using TSP-Inspired Optimization</title>
      <link>https://arxiv.org/abs/2507.18727</link>
      <description>arXiv:2507.18727v1 Announce Type: new 
Abstract: Reconfigurable Intelligent Surfaces (RIS) promise transformative gains in wireless communications by enabling programmable control of the propagation environment through discrete phase configurations. In practical deployments, the control of RIS phase states is typically managed using finite codebooks, with configuration indices transmitted over low latency, yet imperfect, wireless feedback channels. Even rare feedback bit errors can lead to significant mismatches between intended and applied RIS states, degrading system performance. This paper addresses the challenge of robust RIS codebook index assignment by formulating it as a combinatorial optimization problem, equivalent to the Traveling Salesman Problem (TSP), where codewords are "cities" and edge weights reflect SNR degradation under codeword confusion. A novel three-phase heuristic algorithm is proposed to solve this, consisting of a provision phase, a shotgun phase, and a fuzzy concatenation phase. Simulation results show that the method outperforms conventional indexing strategies and achieves near-optimal robustness to index errors, while also being scalable and hardwareagnostic for real time deployment. Future work includes multiple bits error correction and online adaptive mapping for time varying channels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.18727v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Liangshun Wu, Wen Chen, Qingqing Wu, Xudong Bai, Kunlun Wang</dc:creator>
    </item>
    <item>
      <title>EDPC: Accelerating Lossless Compression via Lightweight Probability Models and Decoupled Parallel Dataflow</title>
      <link>https://arxiv.org/abs/2507.18969</link>
      <description>arXiv:2507.18969v1 Announce Type: new 
Abstract: The explosive growth of multi-source multimedia data has significantly increased the demands for transmission and storage, placing substantial pressure on bandwidth and storage infrastructures. While Autoregressive Compression Models (ACMs) have markedly improved compression efficiency through probabilistic prediction, current approaches remain constrained by two critical limitations: suboptimal compression ratios due to insufficient fine-grained feature extraction during probability modeling, and real-time processing bottlenecks caused by high resource consumption and low compression speeds. To address these challenges, we propose Efficient Dual-path Parallel Compression (EDPC), a hierarchically optimized compression framework that synergistically enhances modeling capability and execution efficiency via coordinated dual-path operations. At the modeling level, we introduce the Information Flow Refinement (IFR) metric grounded in mutual information theory, and design a Multi-path Byte Refinement Block (MBRB) to strengthen cross-byte dependency modeling via heterogeneous feature propagation. At the system level, we develop a Latent Transformation Engine (LTE) for compact high-dimensional feature representation and a Decoupled Pipeline Compression Architecture (DPCA) to eliminate encoding-decoding latency through pipelined parallelization. Experimental results demonstrate that EDPC achieves comprehensive improvements over state-of-the-art methods, including a 2.7x faster compression speed, and a 3.2% higher compression ratio. These advancements establish EDPC as an efficient solution for real-time processing of large-scale multimedia data in bandwidth-constrained scenarios. Our code is available at https://github.com/Magie0/EDPC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.18969v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zeyi Lu, Xiaoxiao Ma, Yujun Huang, Minxiao Chen, Bin Chen, Baoyi An, Shu-Tao Xia</dc:creator>
    </item>
    <item>
      <title>Dynamic Agile Reconfigurable Intelligent Surface Antenna (DARISA) MIMO: DoF Analysis and Effective DoF Optimization</title>
      <link>https://arxiv.org/abs/2507.19136</link>
      <description>arXiv:2507.19136v1 Announce Type: new 
Abstract: In this paper, we propose a dynamic agile reconfigurable intelligent surface antenna (DARISA) array integrated into multi-input multi-output (MIMO) transceivers. Each DARISA comprises a number of metasurface elements activated simultaneously via a parallel feed network. The proposed system enables rapid and intelligent phase response adjustments for each metasurface element within a single symbol duration, facilitating a dynamic agile adjustment of phase response (DAAPR) strategy. By analyzing the theoretical degrees of freedom (DoF) of the DARISA MIMO system under the DAAPR framework, we derive an explicit relationship between DoF and critical system parameters, including agility frequentness (i.e., the number of phase adjustments of metasurface elements during one symbol period), cluster angular spread of wireless channels, DARISA array size, and the number of transmit/receive DARISAs. The DoF result reveals a significant conclusion: when the number of receive DARISAs is smaller than that of transmit DARISAs, the DAAPR strategy of the DARISA MIMO enhances the overall system DoF. Furthermore, relying on DoF alone to measure channel capacity is insufficient, so we analyze the effective DoF (EDoF) that reflects the impacts of the DoF and channel matrix singular value distribution on capacity. We show channel capacity monotonically increases with EDoF, and optimize the agile phase responses of metasurface elements by using fractional programming (FP) and semidefinite relaxation (SDR) algorithms to maximize the EDoF. Simulations validate the theoretical DoF gains and reveal that increasing agility frequentness, metasurface element density, and phase quantization accuracy can enhance the EDoF. Additionally, densely deployed elements can compensate for the loss in communication performance caused by lower phase quantization accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19136v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiale Bai, Hui-Ming Wang, Liang Jin</dc:creator>
    </item>
    <item>
      <title>Achievable Rates for a Distributed Antenna System with No Channel State Information at the Central Processor</title>
      <link>https://arxiv.org/abs/2507.19177</link>
      <description>arXiv:2507.19177v1 Announce Type: new 
Abstract: A recent trend in wireless communications considers the migration of traditional monolithic base stations to the so-called disaggregated architecture, where radio units (RUs) implement only the low-level physical layer functionalities such as demodulation, and A/D conversion, while the high-level physical layer, such as channel decoding, is implemented as software-defined functions running on general-purpose hardware in some remote central processing unit (CP). The corresponding information theoretic model for the uplink (from the wireless users to the CP) is a multiaccess-relay channel with primitive oblivious relays. The relays (RUs) are oblivious, as they are agnostic of the users codebooks, and primitive, since the fronthaul links (from RUs to CP) are error-free with limited capacity. This class of networks has been intensely studied in the information theoretic literature, where several approximated or exact (under certain conditions) capacity results have been derived. In particular, in the Gaussian case, the model has been analyzed for fixed and known channel state. This paper is motivated by the fact that, in practice, the channel state is a random process, and it is estimated at the base station side through uplink pilot symbols sent by the users. The pilot dimension may take up a large portion of the channel coherence block, i.e., the number of symbols over which the channel state remains approximately constant. Hence, sending both pilot and data symbols from the relays to the CP may require a significant overhead, especially when the fronthaul capacity is small. As a prototypical problem, we consider the ergodic achievable rate for a diamond network formed by a single user and two relays where the channel state is known at the relays, but not known at the CP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19177v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yi Song (Shitz), Hao Xu (Shitz), Kai Wan (Shitz), Kai-Kit Wong (Shitz), Giuseppe Caire (Shitz), Shlomo Shamai (Shitz)</dc:creator>
    </item>
    <item>
      <title>Overview of 3GPP Release 19 Study on Channel Modeling Enhancements to TR 38.901 for 6G</title>
      <link>https://arxiv.org/abs/2507.19266</link>
      <description>arXiv:2507.19266v1 Announce Type: new 
Abstract: Channel models are a fundamental component of wireless communication systems, providing critical insights into the physics of radio wave propagation. As wireless systems evolve every decade, the development of accurate and standardized channel models becomes increasingly important for the development, evaluation and performance assessment of emerging technologies. An effort to develop a standardized channel model began around 2000 through the Third Generation Partnership Project (3GPP) and the International Telecommunication Union (ITU) with the aim of addressing a broad range of frequencies from sub-1 GHz to 100 GHz. Prior efforts focused heavily on sub-6 GHz bands and mmWave bands, and there exist some gaps in accurately modeling the 7-24 GHz frequency range, a promising candidate band for 6G. To address these gaps, 3GPP approved a Release (Rel) 19 channel modeling study. This study resulted in several enhancements to the channel models, including the ability to accurately model a Suburban Macrocell (SMa) scenario, realistic User Terminal (UT) antenna models, variability in the number of clusters, variability in the number of rays per cluster, a framework for capturing variability in power among all polarizations, near field (NF) propagation, and spatial non-stationarity (SNS) effects, all of which may be crucial for future 6G deployments. This paper presents the outcomes of this study and provides an overview of the underlying rationale, and key discussions that guided the validation, refinement, and enhancements of the 3GPP TR 38.901 channel models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19266v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hitesh Poddar, Dimitri Gold, Daewon Lee, Nan Zhang, Gokul Sridharan, Henrik Asplund, Mansoor Shaf</dc:creator>
    </item>
    <item>
      <title>Sparse Recovery from Group Orbits</title>
      <link>https://arxiv.org/abs/2507.19274</link>
      <description>arXiv:2507.19274v1 Announce Type: new 
Abstract: While most existing sparse recovery results allow only minimal structure within the measurement scheme, many practical problems possess significant structure. To address this gap, we present a framework for structured measurements that are generated by random orbits of a group representation associated with a finite group. We differentiate between two scenarios: one in which the sampling set is fixed and another in which the sampling set is randomized. For each case, we derive an estimate for the number of measurements required to ensure that the restricted isometry property holds with high probability. These estimates are contingent upon the specific representation employed. For this reason, we analyze and characterize various representations that yield favorable recovery outcomes, including the left regular representation. Our work not only establishes a comprehensive framework for sparse recovery of group-structured measurements but also generalizes established measurement schemes, such as those derived from partial random circulant matrices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19274v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Timm Gilles, Hartmut F\"uhr</dc:creator>
    </item>
    <item>
      <title>Low-Complexity 6DMA Rotation and Position Optimization Based on Statistical Channel Information</title>
      <link>https://arxiv.org/abs/2507.19309</link>
      <description>arXiv:2507.19309v1 Announce Type: new 
Abstract: The six-dimensional movable antenna (6DMA) is a promising technology to fully exploit spatial variation in wireless channels by allowing flexible adjustment of three-dimensional (3D) positions and rotations of antennas at the transceiver. In this paper, we consider a 6DMA-equipped base station (BS) and aim to maximize the average sum logarithmic rate of all users served by the BS by jointly designing 6DMA surface positions and rotations based on statistical channel information (SCI). Different from prior works on 6DMA design which use alternating optimization to iteratively update surface positions and rotations, we propose a new sequential optimization method that first determines the optimal rotations and then identifies feasible positions to realize these rotations under practical antenna placement constraints. Simulation results show that our proposed optimization scheme significantly reduces the computational complexity of conventional alternating optimization (AO), while achieving communication performance comparable to the AO-based approach and superior to existing fixed-position/rotation antenna arrays.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19309v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qijun Jiang, Xiaodan Shao, Rui Zhang</dc:creator>
    </item>
    <item>
      <title>On Anti-collusion Codes for Averaging Attack in Multimedia Fingerprinting</title>
      <link>https://arxiv.org/abs/2507.19384</link>
      <description>arXiv:2507.19384v1 Announce Type: new 
Abstract: Multimedia fingerprinting is a technique to protect the copyrighted contents against being illegally redistributed under various collusion attack models. Averaging attack is the most fair choice for each colluder to avoid detection, and also makes the pirate copy have better perceptional quality. This makes such an attack one of the most feasible approaches to carrying out collusion. In order to trace all the colluders, several types of multimedia fingerprinting codes were introduced to construct fingerprints resistant to averaging attacks on multimedia contents, such as AND anti-collusion codes (AND-ACCs), binary separable codes (SCs), logical anti-collusion codes (LACCs), binary frameproof codes (FPCs), binary strongly-separable codes (SSCs) and binary secure code with list decoding (SCLDs). Then codes with the rate as high as possible are desired. However, the existing fingerprinting codes have low code rate due to the strong combinatorial structure. The reason is that the previous research methods adopted simple tracing algorithms. In this paper, we first propose novel tracing algorithms and then find appropriate fingerprinting codes with weaker combinatorial structure, i.e., the binary strongly identifiable parent property code for multimedia fingerprinting (SMIPPC) and its concatenated code. Theoretical comparisons and numerical comparisons show that SMIPPCs have higher code rates than those of the existing codes due to their weaker combinatorial structures. It is worth noting that SMIPPCs can only trace a part of colluders by using the previous tracing algorithm and the concatenated SMIPPC may be not an SMIPPC. This implies that our tracing algorithms have strong traceability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19384v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jing Jiang, Cailin Wen, Minquan Cheng</dc:creator>
    </item>
    <item>
      <title>Sample Abundance for Signal Processing: A Brief Introduction</title>
      <link>https://arxiv.org/abs/2507.19415</link>
      <description>arXiv:2507.19415v1 Announce Type: new 
Abstract: This paper reports, by way of introduction, on the advances made by our group and the broader signal processing community on the concept of sample abundance; a phenomenon that naturally arises in one-bit and few-bit signal processing frameworks. By leveraging large volumes of low-precision measurements, we show how traditionally costly constraints, such as matrix semi-definiteness and rank conditions, become redundant, yielding simple overdetermined linear feasibility problems. We illustrate key algorithms, theoretical guarantees via the Finite Volume Property, and the sample abundance singularity phenomenon, where computational complexity sharply drops.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19415v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arian Eamaz, Farhang Yeganegi, Mojtaba Soltanalian</dc:creator>
    </item>
    <item>
      <title>Bespoke multiresolution analysis of graph signals</title>
      <link>https://arxiv.org/abs/2507.19181</link>
      <description>arXiv:2507.19181v1 Announce Type: cross 
Abstract: We present a novel framework for discrete multiresolution analysis of graph signals. The main analytical tool is the samplet transform, originally defined in the Euclidean framework as a discrete wavelet-like construction, tailored to the analysis of scattered data. The first contribution of this work is defining samplets on graphs. To this end, we subdivide the graph into a fixed number of patches, embed each patch into a Euclidean space, where we construct samplets, and eventually pull the construction back to the graph. This ensures orthogonality, locality, and the vanishing moments property with respect to properly defined polynomial spaces on graphs. Compared to classical Haar wavelets, this framework broadens the class of graph signals that can efficiently be compressed and analyzed. Along this line, we provide a definition of a class of signals that can be compressed using our construction. We support our findings with different examples of signals defined on graphs whose vertices lie on smooth manifolds. For efficient numerical implementation, we combine heavy edge clustering, to partition the graph into meaningful patches, with landmark \texttt{Isomap}, which provides low-dimensional embeddings for each patch. Our results demonstrate the method's robustness, scalability, and ability to yield sparse representations with controllable approximation error, significantly outperforming traditional Haar wavelet approaches in terms of compression efficiency and multiresolution fidelity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19181v1</guid>
      <category>eess.SP</category>
      <category>cs.DM</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giacomo Elefante, Gianluca Giacchi, Michael Multerer, Jacopo Quizi</dc:creator>
    </item>
    <item>
      <title>Branch-and-bound method for calculating Viterbi path in triplet Markov models</title>
      <link>https://arxiv.org/abs/2507.19338</link>
      <description>arXiv:2507.19338v1 Announce Type: cross 
Abstract: We consider a bivariate, possibly non-homogeneous, finite-state Markov chain $(X,U)=\{(X_t,U_t)\}_{t=1}^n$. We are interested in the marginal process $X$, which typically is not a Markov chain. The goal is to find a realization (path) $x=(x_1,\ldots,x_n)$ with maximal probability $P(X=x)$. If $X$ is Markov chain, then such path can be efficiently found using the celebrated Viterbi algorithm. However, when $X$ is not Markovian, identifying the most probable path -- hereafter referred to as the Viterbi path -- becomes computationally expensive. In this paper, we explore the branch-and-bound method for finding Viterbi paths. The method is based on the lower and upper bounds on maximum probability $\max_x P(X=x)$, and the objective of the paper is to exploit the joint Markov property of $(X,Y)$ to calculate possibly good bounds in possibly cheap way.
  This research is motivated by decoding or segmentation problem in triplet Markov models. A triplet Markov model is trivariate homogeneous Markov process $(X,U,Y)$. In decoding, a realization of one marginal process $Y$ is observed (representing the data), while $X$ and $U$ are latent processes. The process $U$ serves as a nuisance variable, whereas $X$ is the process of primary interest. Decoding refers to estimating the hidden sequence $X$ based solely on the observation $Y$. Conditional on $Y$, the latent processes $(X, U)$ form a non-homogeneous Markov chain. In this context, the Viterbi path corresponds to the maximum a posteriori (MAP) estimate of $X$, making it a natural choice for signal reconstruction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19338v1</guid>
      <category>stat.CO</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Oskar Soop, J\"uri Lember</dc:creator>
    </item>
    <item>
      <title>Sequence of Numbers of Linear Codes with Increasing Hull Dimensions</title>
      <link>https://arxiv.org/abs/2402.01255</link>
      <description>arXiv:2402.01255v2 Announce Type: replace 
Abstract: The hull of a linear code $C$ is the intersection of $C$ with its dual code. We present and analyze the number of linear $q$-ary codes of the same length and dimension but with different dimensions for their hulls. We prove that for given dimension $k$ and length $n\ge 2k$ the number of all $[n,k]_q$ linear codes with hull dimension $l$ decreases as $l$ increases. We also present classification results for binary and ternary linear codes with trivial hulls (LCD and self-orthogonal) for some values of the length $n$ and dimension $k$, comparing the obtained numbers with the number of all linear codes for the given $n$ and $k$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.01255v2</guid>
      <category>cs.IT</category>
      <category>cs.DM</category>
      <category>math.IT</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stefka Bouyuklieva, Iliya Bouyukliev, Ferruh \"Ozbudak</dc:creator>
    </item>
    <item>
      <title>Towards Quantum Universal Hypothesis Testing</title>
      <link>https://arxiv.org/abs/2504.16299</link>
      <description>arXiv:2504.16299v2 Announce Type: replace 
Abstract: Hoeffding's formulation and solution to the universal hypothesis testing (UHT) problem had a profound impact on many subsequent works dealing with asymmetric hypotheses. In this work, we introduce a quantum universal hypothesis testing framework that serves as a quantum analog to Hoeffding's UHT. Motivated by Hoeffding's approach, which estimates the empirical distribution and uses it to construct the test statistic, we employ quantum state tomography to reconstruct the unknown state prior to forming the test statistic. Leveraging the concentration properties of quantum state tomography, we establish the exponential consistency of the proposed test: the type II error probability decays exponentially quickly, with the exponent determined by the trace distance between the true state and the nominal state.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16299v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>quant-ph</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arick Grootveld, Haodong Yang, Biao Chen, Venkata Gandikota, Jason Pollack</dc:creator>
    </item>
    <item>
      <title>On Lattice Isomorphism Problems for Lattices from LCD Codes over Finite Rings</title>
      <link>https://arxiv.org/abs/2507.09257</link>
      <description>arXiv:2507.09257v2 Announce Type: replace 
Abstract: These days, post-quantum cryptography based on the lattice isomorphism problem has been proposed. Ducas-Gibbons introduced the hull attack, which solves the lattice isomorphism problem for lattices obtained by Construction A from an LCD code over a finite field. Using this attack, they showed that the lattice isomorphism problem for such lattices can be reduced to the lattice isomorphism problem with the trivial lattice $\mathbb{Z}^n$ and the graph isomorphism problem. While the previous work by Ducas-Gibbons only considered lattices constructed by a code over a \textit{finite field}, this paper considers lattices constructed by a code over a \textit{finite ring} $\mathbb{Z}/k\mathbb{Z}$, which is a more general case. In particular, when $k$ is odd, an odd prime power, or not divisible by $4$, we show that the lattice isomorphism problem can be reduced to the lattice isomorphism problem for $\mathbb{Z}^n$ and the graph isomorphism problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09257v2</guid>
      <category>cs.IT</category>
      <category>math.CO</category>
      <category>math.IT</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yusaku Nishimura, Katsuyuki Takashima, Tsuyoshi Miezaki</dc:creator>
    </item>
    <item>
      <title>A Framework of Distributed Source Encryption using Mutual Information Security Criterion and the Strong Converse Theorem</title>
      <link>https://arxiv.org/abs/2507.13294</link>
      <description>arXiv:2507.13294v2 Announce Type: replace 
Abstract: We reinvestigate the general distributed secure source coding based on the common key cryptosystem proposed by Oohama and Santoso (ITW 2021). They proposed a framework of distributed source encryption and derived the necessary and sufficient conditions to have reliable and secure transmission. However, the bounds of the rate region, which specifies both necessary and sufficient conditions to have reliable and secure transmission under the proposed cryptosystem, were derived based on a self-tailored non-standard} security criterion. In this paper we adopt the standard security criterion, i.e., standard mutual information. We successfully establish the bounds of the rate region based on this security criterion. Information spectrum method and a variant of Birkhoff-von Neumann theorem play an important role in deriving the result.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13294v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yasutada Oohama, Bagus Santoso</dc:creator>
    </item>
    <item>
      <title>Estimating Rate-Distortion Functions Using the Energy-Based Model</title>
      <link>https://arxiv.org/abs/2507.15700</link>
      <description>arXiv:2507.15700v2 Announce Type: replace 
Abstract: The rate-distortion (RD) theory is one of the key concepts in information theory, providing theoretical limits for compression performance and guiding the source coding design, with both theoretical and practical significance. The Blahut-Arimoto (BA) algorithm, as a classical algorithm to compute RD functions, encounters computational challenges when applied to high-dimensional scenarios. In recent years, many neural methods have attempted to compute high-dimensional RD problems from the perspective of implicit generative models. Nevertheless, these approaches often neglect the reconstruction of the optimal conditional distribution or rely on unreasonable prior assumptions. In face of these issues, we propose an innovative energy-based modeling framework that leverages the connection between the RD dual form and the free energy in statistical physics, achieving effective reconstruction of the optimal conditional distribution.The proposed algorithm requires training only a single neural network and circumvents the challenge of computing the normalization factor in energy-based models using the Markov chain Monte Carlo (MCMC) sampling. Experimental results demonstrate the significant effectiveness of the proposed algorithm in estimating high-dimensional RD functions and reconstructing the optimal conditional distribution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.15700v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shitong Wu, Sicheng Xu, Lingyi Chen, Huihui Wu, Wenyi Zhang</dc:creator>
    </item>
    <item>
      <title>On entropic and almost multilinear representability of matroids</title>
      <link>https://arxiv.org/abs/2206.03465</link>
      <description>arXiv:2206.03465v3 Announce Type: replace-cross 
Abstract: This article studies two notions of generalized matroid representations motivated by algorithmic information theory and cryptographic secret sharing. The first (entropic representability) involves discrete random variables, while the second (almost-multilinear representability) deals with approximate subspace arrangements. In both cases, we prove that determining whether an input matroid has such a representation is undecidable. Consequently, the conditional independence implication problem is also undecidable, providing an independent answer to a question posed by Geiger and Pearl, recently resolved by Cheuk Ting Li. These problems are also closely related to characterizing achievable rates in network coding and constructing secret sharing schemes. For example, another corollary of our work is that deciding whether an access structure admits an ideal secret sharing scheme is undecidable. Our approach reduces undecidable problems from group theory to matroid representation problems. Specifically, we reduce the uniform word problem for finite groups to entropic representability and the word problem for sofic groups to almost-multilinear representability. A key part of this reduction involves modifying group presentations into forms where linear representations are generic in an appropriate sense when restricted to the generating set.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.03465v3</guid>
      <category>math.CO</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lukas K\"uhne, Geva Yashfe</dc:creator>
    </item>
    <item>
      <title>Difficulties Constructing Lattices with Exponential Kissing Number from Codes</title>
      <link>https://arxiv.org/abs/2410.16660</link>
      <description>arXiv:2410.16660v2 Announce Type: replace-cross 
Abstract: In this note, we present examples showing that several natural ways of constructing lattices from error-correcting codes do not in general yield a correspondence between minimum-weight non-zero codewords and shortest non-zero lattice vectors. From these examples, we conclude that the main results in two works of Vl\u{a}du\c{t} (Moscow J. Comb. Number Th., 2019 and Discrete Comput. Geom., 2021) on constructing lattices with exponential kissing number from error-correcting codes are invalid. A more recent preprint (arXiv, 2024) that Vl\u{a}du\c{t} posted after an initial version of this work was made public is also invalid.
  Exhibiting a family of lattices with exponential kissing number therefore remains an open problem (as of July 2025).</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16660v2</guid>
      <category>math.MG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.NT</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huck Bennett, Alexander Golovnev, Noah Stephens-Davidowitz</dc:creator>
    </item>
    <item>
      <title>Quantifying interdisciplinary synergy in higher STEM education</title>
      <link>https://arxiv.org/abs/2502.17841</link>
      <description>arXiv:2502.17841v3 Announce Type: replace-cross 
Abstract: We propose a framework to quantify and utilize interdisciplinarity in science and engineering curricula at the university-level higher education. We analyze interdisciplinary relations by standardizing large-scale official educational data in Korea using a cutting-edge large language model and constructing knowledge maps for disciplines of scientific education. We design and evaluate single-field and integrated dual-field curricula by adapting pedagogical theory and utilizing information theory-based metrics. We develop standard curricula for individual disciplines and integrated curricula combining two fields, with their interdisciplinarity quantified by the curriculum synergy score. The results indicate higher interdisciplinarity for combinations within or across closely related fields, especially in engineering fields. Based on the analysis, engineering fields constitute the core structure of our design for curriculum interdisciplinarity, while basic natural science fields are located at peripheral stems to provide fundamental concepts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.17841v3</guid>
      <category>physics.soc-ph</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>physics.ed-ph</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1140/epjds/s13688-025-00566-6</arxiv:DOI>
      <arxiv:journal_reference>EPJ Data Sci. 14, 56 (2025)</arxiv:journal_reference>
      <dc:creator>Gahyoun Gim, Jinhyuk Yun, Sang Hoon Lee</dc:creator>
    </item>
    <item>
      <title>Plan for Speed: Dilated Scheduling for Masked Diffusion Language Models</title>
      <link>https://arxiv.org/abs/2506.19037</link>
      <description>arXiv:2506.19037v3 Announce Type: replace-cross 
Abstract: Masked diffusion language models (MDLMs) promise fast, non-autoregressive text generation, yet existing samplers, which pick tokens to unmask based on model confidence, ignore interactions when unmasking multiple positions in parallel and effectively reduce to slow, autoregressive behavior. We propose the Dilated Unmasking Scheduler (DUS), an inference-only, planner-model-free method that partitions sequence positions into non-adjacent dilated groups and unmasked them in parallel so as to minimize an upper bound on joint entropy gain at each denoising step. By explicitly trading off the number of network calls against generation quality, DUS recovers most of the performance lost under traditional parallel unmasking strategies. Across math (GSM8K, MATH500), code (HumanEval, MBPP) and general-knowledge benchmarks (BBH, MMLU-Pro), DUS outperforms confidence-based planners, without modifying the underlying denoiser, and reveals the true speed-quality frontier of MDLMs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19037v3</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <category>math.IT</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Omer Luxembourg, Haim Permuter, Eliya Nachmani</dc:creator>
    </item>
    <item>
      <title>Tight Bound for Quantum Unitary Time-Reversal</title>
      <link>https://arxiv.org/abs/2507.05736</link>
      <description>arXiv:2507.05736v3 Announce Type: replace-cross 
Abstract: Time-reversal of unitary evolution is fundamental in quantum information processing. Many scenarios, particularly those in quantum learning and metrology, assume free access to the time-reverse of an unknown unitary. In this paper, we settle the query complexity of the unitary time-reversal task: approximately implementing $U^{-1}$ given only black-box access to an unknown $d$-dimensional unitary $U$. We provide a tight query lower bound $\Omega((1-\epsilon)d^2)$ for the unitary time-reversal to within diamond norm error $\epsilon$. Notably, our lower bound applies to general coherent protocols with unbounded ancillas, and holds even when $\epsilon$ is an average-case distance error and access to control-$U$ is available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.05736v3</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kean Chen, Nengkun Yu, Zhicheng Zhang</dc:creator>
    </item>
  </channel>
</rss>
