<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.GN updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.GN</link>
    <description>q-bio.GN updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.GN" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 07 Nov 2025 02:35:44 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>NABench: Large-Scale Benchmarks of Nucleotide Foundation Models for Fitness Prediction</title>
      <link>https://arxiv.org/abs/2511.02888</link>
      <description>arXiv:2511.02888v1 Announce Type: new 
Abstract: Nucleotide sequence variation can induce significant shifts in functional fitness. Recent nucleotide foundation models promise to predict such fitness effects directly from sequence, yet heterogeneous datasets and inconsistent preprocessing make it difficult to compare methods fairly across DNA and RNA families. Here we introduce NABench, a large-scale, systematic benchmark for nucleic acid fitness prediction. NABench aggregates 162 high-throughput assays and curates 2.6 million mutated sequences spanning diverse DNA and RNA families, with standardized splits and rich metadata. We show that NABench surpasses prior nucleotide fitness benchmarks in scale, diversity, and data quality. Under a unified evaluation suite, we rigorously assess 29 representative foundation models across zero-shot, few-shot prediction, transfer learning, and supervised settings. The results quantify performance heterogeneity across tasks and nucleic-acid types, demonstrating clear strengths and failure modes for different modeling choices and establishing strong, reproducible baselines. We release NABench to advance nucleic acid modeling, supporting downstream applications in RNA/DNA design, synthetic biology, and biochemistry. Our code is available at https://github.com/mrzzmrzz/NABench.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.02888v1</guid>
      <category>q-bio.GN</category>
      <category>cs.AI</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhongmin Li, Runze Ma, Jiahao Tan, Chengzi Tan, Shuangjia Zheng</dc:creator>
    </item>
    <item>
      <title>Phospho-Proteomics Method Optimization and Application to Stimulated Jurkat Cells</title>
      <link>https://arxiv.org/abs/2511.02932</link>
      <description>arXiv:2511.02932v1 Announce Type: cross 
Abstract: In clinical proteomics, available input is often limited. In addition, phospho-proteomics is of particular interest since the dysregulation of these post-translational modifications (PTMs) has been implicated in various diseases such as cancer. We therefore assessed the feasibility of low input phospho-proteomics via phospho-bulk titration and low-input starting material. We found that there was identification of more phospho-peptides through phospho-bulk titration because of sample loss during preparation of low input starting material. Additionally, we explored various lysis buffers and boiling times for efficiency of decrosslinking formalin-fixed cells since cells and tissues are often fixed for preservation and sorting via FACS. We found that boiling in 0.05M Tris pH 7.6 with 5% SDS for 60 min yielded the highest number of phospho-peptides. Lastly, we applied Evotips Pure and phospho-bulk titration to treated Jurkat cells and identified 7 phospho-sites involved in T-cell stimulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.02932v1</guid>
      <category>q-bio.QM</category>
      <category>q-bio.GN</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Teresia Ndungu, Jana Zecha, Lisa Cazares, Sonja Hess</dc:creator>
    </item>
    <item>
      <title>Scalable Single-Cell Gene Expression Generation with Latent Diffusion Models</title>
      <link>https://arxiv.org/abs/2511.02986</link>
      <description>arXiv:2511.02986v1 Announce Type: cross 
Abstract: Computational modeling of single-cell gene expression is crucial for understanding cellular processes, but generating realistic expression profiles remains a major challenge. This difficulty arises from the count nature of gene expression data and complex latent dependencies among genes. Existing generative models often impose artificial gene orderings or rely on shallow neural network architectures. We introduce a scalable latent diffusion model for single-cell gene expression data, which we refer to as scLDM, that respects the fundamental exchangeability property of the data. Our VAE uses fixed-size latent variables leveraging a unified Multi-head Cross-Attention Block (MCAB) architecture, which serves dual roles: permutation-invariant pooling in the encoder and permutation-equivariant unpooling in the decoder. We enhance this framework by replacing the Gaussian prior with a latent diffusion model using Diffusion Transformers and linear interpolants, enabling high-quality generation with multi-conditional classifier-free guidance. We show its superior performance in a variety of experiments for both observational and perturbational single-cell data, as well as downstream tasks like cell-level classification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.02986v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>q-bio.GN</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giovanni Palla, Sudarshan Babu, Payam Dibaeinia, James D. Pearce, Donghui Li, Aly A. Khan, Theofanis Karaletsos, Jakub M. Tomczak</dc:creator>
    </item>
    <item>
      <title>LA-MARRVEL: A Knowledge-Grounded and Language-Aware LLM Reranker for AI-MARRVEL in Rare Disease Diagnosis</title>
      <link>https://arxiv.org/abs/2511.02263</link>
      <description>arXiv:2511.02263v3 Announce Type: replace 
Abstract: Diagnosing rare diseases requires linking gene findings with often unstructured reference text. Current pipelines collect many candidate genes, but clinicians still spend a lot of time filtering false positives and combining evidence from papers and databases. A key challenge is language: phenotype descriptions and inheritance patterns are written in prose, not fully captured by tables. Large language models (LLMs) can read such text, but clinical use needs grounding in citable knowledge and stable, repeatable behavior. We explore a knowledge-grounded and language-aware reranking layer on top of a high-recall first-stage pipeline. The goal is to improve precision and explainability, not to replace standard bioinformatics steps. We use expert-built context and a consensus method to reduce LLM variability, producing shorter, better-justified gene lists for expert review. LA-MARRVEL achieves the highest accuracy, outperforming other methods -- including traditional bioinformatics diagnostic tools (AI-MARRVEL, Exomiser, LIRICAL) and naive large language models (e.g., Anthropic Claude) -- with an average Recall@5 of 94.10%, a +3.65 percentage-point improvement over AI-MARRVEL. The LLM-generated reasoning provides clear prose on phenotype matching and inheritance patterns, making clinical review faster and easier. LA-MARRVEL has three parts: expert-engineered context that enriches phenotype and disease information; a ranked voting algorithm that combines multiple LLM runs to choose a consensus ranked gene list; and the AI-MARRVEL pipeline that provides first-stage ranks and gene annotations, already known as a state-of-the-art method in Rare Disease Diagnosis on BG, DDD, and UDN cohorts. The online AI-MARRVEL includes LA-MARRVEL as an LLM feature at https://ai.marrvel.org . We evaluate LA-MARRVEL on three datasets from independent cohorts of real-world diagnosed patients.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.02263v3</guid>
      <category>q-bio.GN</category>
      <category>cs.AI</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jaeyeon Lee, Hyun-Hwan Jeong, Zhandong Liu</dc:creator>
    </item>
  </channel>
</rss>
