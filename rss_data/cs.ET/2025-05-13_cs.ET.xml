<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 13 May 2025 10:38:52 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>QSeer: A Quantum-Inspired Graph Neural Network for Parameter Initialization in Quantum Approximate Optimization Algorithm Circuits</title>
      <link>https://arxiv.org/abs/2505.06810</link>
      <description>arXiv:2505.06810v1 Announce Type: new 
Abstract: To mitigate the barren plateau problem, effective parameter initialization is crucial for optimizing the Quantum Approximate Optimization Algorithm (QAOA) in the near-term Noisy Intermediate-Scale Quantum (NISQ) era. Prior physics-driven approaches leveraged the optimal parameter concentration phenomenon, utilizing medium values of previously optimized QAOA parameters stored in databases as initialization for new graphs. However, this medium-value-based strategy lacks generalization capability. Conversely, prior computer-science-based approaches employed graph neural networks (GNNs) trained on previously optimized QAOA parameters to predict initialization values for new graphs. However, these approaches neglect key physics-informed QAOA principles, such as parameter concentration, symmetry, and adiabatic evolution, resulting in suboptimal parameter predictions and limited performance improvements. Furthermore, no existing GNN-based methods support parameter initialization for QAOA circuits with variable depths or for solving weighted Max-Cut problems. This paper introduces QSeer, a quantum-inspired GNN designed for accurate QAOA parameter prediction. Compared to prior physics- and computer-science-driven methods, QSeer improves the initial approximation ratio and convergence speed of QAOA circuits across diverse graphs by 6%-68% and 5x-10x, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06810v1</guid>
      <category>cs.ET</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lei Jiang, Chi Zhang, Fan Chen</dc:creator>
    </item>
    <item>
      <title>AI-Driven Optimization of Wave-Controlled Reconfigurable Intelligent Surfaces</title>
      <link>https://arxiv.org/abs/2505.07126</link>
      <description>arXiv:2505.07126v1 Announce Type: new 
Abstract: A promising type of Reconfigurable Intelligent Surface (RIS) employs tunable control of its varactors using biasing transmission lines below the RIS reflecting elements. Biasing standing waves (BSWs) are excited by a time-periodic signal and sampled at each RIS element to create a desired biasing voltage and control the reflection coefficients of the elements. A simple rectifier can be used to sample the voltages and capture the peaks of the BSWs over time. Like other types of RIS, attempting to model and accurately configure a wave-controlled RIS is extremely challenging due to factors such as device non-linearities, frequency dependence, element coupling, etc., and thus significant differences will arise between the actual and assumed performance. An alternative approach to solving this problem is data-driven: Using training data obtained by sampling the reflected radiation pattern of the RIS for a set of BSWs, a neural network (NN) is designed to create an input-output map between the BSW amplitudes and the resulting sampled radiation pattern. This is the approach discussed in this paper. In the proposed approach, the NN is optimized using a genetic algorithm (GA) to minimize the error between the predicted and measured radiation patterns. The BSW amplitudes are then designed via Simulated Annealing (SA) to optimize a signal-to-leakage-plus-noise ratio measure by iteratively forward-propagating the BSW amplitudes through the NN and using its output as feedback to determine convergence. The resulting optimal solutions are stored in a lookup table to be used both as settings to instantly configure the RIS and as a basis for determining more complex radiation patterns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07126v1</guid>
      <category>cs.ET</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gal Ben Itzhak, Miguel Saavedra-Melo, Ender Ayanoglu, Filippo Capolino, A. Lee Swindlehurst</dc:creator>
    </item>
    <item>
      <title>Empowering the Grid: Collaborative Edge Artificial Intelligence for Decentralized Energy Systems</title>
      <link>https://arxiv.org/abs/2505.07170</link>
      <description>arXiv:2505.07170v1 Announce Type: new 
Abstract: This paper examines how decentralized energy systems can be enhanced using collaborative Edge Artificial Intelligence. Decentralized grids use local renewable sources to reduce transmission losses and improve energy security. Edge AI enables real-time, privacy-preserving data processing at the network edge. Techniques such as federated learning and distributed control improve demand response, equipment maintenance, and energy optimization. The paper discusses key challenges including data privacy, scalability, and interoperability, and suggests solutions such as blockchain integration and adaptive architectures. Examples from virtual power plants and smart grids highlight the potential of these technologies. The paper calls for increased investment, policy support, and collaboration to advance sustainable energy systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07170v1</guid>
      <category>cs.ET</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eddie de Paula Jr, Niel Bunda, Hezerul Abdul Karim, Nouar AlDahoul, Myles Joshua Toledo Tan</dc:creator>
    </item>
    <item>
      <title>Lagrange Oscillatory Neural Networks for Constraint Satisfaction and Optimization</title>
      <link>https://arxiv.org/abs/2505.07179</link>
      <description>arXiv:2505.07179v1 Announce Type: new 
Abstract: Physics-inspired computing paradigms are receiving renewed attention to enhance efficiency in compute-intensive tasks such as artificial intelligence and optimization. Similar to Hopfield neural networks, oscillatory neural networks (ONNs) minimize an Ising energy function that embeds the solutions of hard combinatorial optimization problems. Despite their success in solving unconstrained optimization problems, Ising machines still face challenges with constrained problems as they can get stuck at infeasible local minima. In this paper, we introduce a Lagrange ONN (LagONN) designed to escape infeasible states based on the theory of Lagrange multipliers. Unlike existing oscillatory Ising machines, LagONN employs additional Lagrange oscillators to guide the system towards feasible states in an augmented energy landscape and settles only when constraints are met. Taking the maximum satisfiability problem with three literals as a use case (Max-3-SAT), we harness LagONN's constraint satisfaction mechanism to find optimal solutions for random SATlib instances with up to 200 variables and 860 clauses, which provides a deterministic alternative to simulated annealing for coupled oscillators. We further discuss the potential of Lagrange oscillators to address other constraints, such as phase copying, which is useful in oscillatory Ising machines with limited connectivity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07179v1</guid>
      <category>cs.ET</category>
      <category>cs.NE</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Corentin Delacour, Bram Haverkort, Filip Sabo, Nadine Azemard, Aida Todri-Sanial</dc:creator>
    </item>
    <item>
      <title>Circuit Partitioning Using Large Language Models for Quantum Compilation and Simulations</title>
      <link>https://arxiv.org/abs/2505.07711</link>
      <description>arXiv:2505.07711v1 Announce Type: new 
Abstract: We are in the midst of the noisy intermediate-scale quantum (NISQ) era, where quantum computers are limited by noisy gates, some of which are more error-prone than others and can render the final computation incomprehensible. Quantum circuit compilation algorithms attempt to minimize these noisy gates when mapping quantum algorithms onto quantum hardware but face computational challenges that restrict their application to circuits with no more than 5-6 qubits, necessitating the need to partition large circuits before the application of noisy quantum gate minimization algorithms. The existing generation of these algorithms is heuristic in nature and does not account for downstream gate minimization tasks. Large language models (LLMs) have the potential to change this and help improve quantum circuit partitions. This paper investigates the use of LLMs, such as Llama and Mistral, for partitioning quantum circuits by capitalizing on their abilities to understand and generate code, including QASM. Specifically, we teach LLMs to partition circuits using the quick partition approach of the Berkeley Quantum Synthesis Toolkit. Through experimental evaluations, we show that careful fine-tuning of open source LLMs enables us to obtain an accuracy of 53.4% for the partition task while over-the-shelf LLMs are unable to correctly partition circuits, using standard 1-shot and few-shot training approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07711v1</guid>
      <category>cs.ET</category>
      <category>cs.AI</category>
      <category>quant-ph</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pranav Sinha, Sumit Kumar Jha, Sunny Raj</dc:creator>
    </item>
    <item>
      <title>BedreFlyt: Improving Patient Flows through Hospital Wards with Digital Twins</title>
      <link>https://arxiv.org/abs/2505.06287</link>
      <description>arXiv:2505.06287v1 Announce Type: cross 
Abstract: Digital twins are emerging as a valuable tool for short-term decision-making as well as for long-term strategic planning across numerous domains, including process industry, energy, space, transport, and healthcare. This paper reports on our ongoing work on designing a digital twin to enhance resource planning, e.g., for the in-patient ward needs in hospitals. By leveraging executable formal models for system exploration, ontologies for knowledge representation and an SMT solver for constraint satisfiability, our approach aims to explore hypothetical "what-if" scenarios to improve strategic planning processes, as well as to solve concrete, short-term decision-making tasks. Our proposed solution uses the executable formal model to turn a stream of arriving patients, that need to be hospitalized, into a stream of optimization problems, e.g., capturing daily inpatient ward needs, that can be solved by SMT techniques. The knowledge base, which formalizes domain knowledge, is used to model the needed configuration in the digital twin, allowing the twin to support both short-term decision-making and long-term strategic planning by generating scenarios spanning average-case as well as worst-case resource needs, depending on the expected treatment of patients, as well as ranging over variations in available resources, e.g., bed distribution in different rooms. We illustrate our digital twin architecture by considering the problem of bed bay allocation in a hospital ward.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06287v1</guid>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.LO</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.418.1</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 418, 2025, pp. 1-15</arxiv:journal_reference>
      <dc:creator>Riccardo Sieve (Dept. of Informatics, University of Oslo), Paul Kobialka (Dept. of Informatics, University of Oslo), Laura Slaughter (dScience Center, University of Oslo), Rudolf Schlatte (Dept. of Informatics, University of Oslo), Einar Broch Johnsen (Dept. of Informatics, University of Oslo), Silvia Lizeth Tapia Tarifa (Dept. of Informatics, University of Oslo)</dc:creator>
    </item>
    <item>
      <title>The Quantum Approximate Optimization Algorithm Can Require Exponential Time to Optimize Linear Functions</title>
      <link>https://arxiv.org/abs/2505.06404</link>
      <description>arXiv:2505.06404v1 Announce Type: cross 
Abstract: QAOA is a hybrid quantum-classical algorithm to solve optimization problems in gate-based quantum computers. It is based on a variational quantum circuit that can be interpreted as a discretization of the annealing process that quantum annealers follow to find a minimum energy state of a given Hamiltonian. This ensures that QAOA must find an optimal solution for any given optimization problem when the number of layers, $p$, used in the variational quantum circuit tends to infinity. In practice, the number of layers is usually bounded by a small number. This is a must in current quantum computers of the NISQ era, due to the depth limit of the circuits they can run to avoid problems with decoherence and noise. In this paper, we show mathematical evidence that QAOA requires exponential time to solve linear functions when the number of layers is less than the number of different coefficients of the linear function $n$. We conjecture that QAOA needs exponential time to find the global optimum of linear functions for any constant value of $p$, and that the runtime is linear only if $p \geq n$. We conclude that we need new quantum algorithms to reach quantum supremacy in quantum optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06404v1</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3712255.3734319</arxiv:DOI>
      <dc:creator>Francisco Chicano, Zakaria Abdelmoiz Dahi, Gabiel Luque</dc:creator>
    </item>
    <item>
      <title>Engineering Risk-Aware, Security-by-Design Frameworks for Assurance of Large-Scale Autonomous AI Models</title>
      <link>https://arxiv.org/abs/2505.06409</link>
      <description>arXiv:2505.06409v1 Announce Type: cross 
Abstract: As AI models scale to billions of parameters and operate with increasing autonomy, ensuring their safe, reliable operation demands engineering-grade security and assurance frameworks. This paper presents an enterprise-level, risk-aware, security-by-design approach for large-scale autonomous AI systems, integrating standardized threat metrics, adversarial hardening techniques, and real-time anomaly detection into every phase of the development lifecycle. We detail a unified pipeline - from design-time risk assessments and secure training protocols to continuous monitoring and automated audit logging - that delivers provable guarantees of model behavior under adversarial and operational stress. Case studies in national security, open-source model governance, and industrial automation demonstrate measurable reductions in vulnerability and compliance overhead. Finally, we advocate cross-sector collaboration - uniting engineering teams, standards bodies, and regulatory agencies - to institutionalize these technical safeguards within a resilient, end-to-end assurance ecosystem for the next generation of AI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06409v1</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Krti Tallam</dc:creator>
    </item>
    <item>
      <title>ThreatLens: LLM-guided Threat Modeling and Test Plan Generation for Hardware Security Verification</title>
      <link>https://arxiv.org/abs/2505.06821</link>
      <description>arXiv:2505.06821v1 Announce Type: cross 
Abstract: Current hardware security verification processes predominantly rely on manual threat modeling and test plan generation, which are labor-intensive, error-prone, and struggle to scale with increasing design complexity and evolving attack methodologies. To address these challenges, we propose ThreatLens, an LLM-driven multi-agent framework that automates security threat modeling and test plan generation for hardware security verification. ThreatLens integrates retrieval-augmented generation (RAG) to extract relevant security knowledge, LLM-powered reasoning for threat assessment, and interactive user feedback to ensure the generation of practical test plans. By automating these processes, the framework reduces the manual verification effort, enhances coverage, and ensures a structured, adaptable approach to security verification. We evaluated our framework on the NEORV32 SoC, demonstrating its capability to automate security verification through structured test plans and validating its effectiveness in real-world scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06821v1</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dipayan Saha, Hasan Al Shaikh, Shams Tarek, Farimah Farahmandi</dc:creator>
    </item>
    <item>
      <title>Fast and low energy approximate full adder based on FELIX logic</title>
      <link>https://arxiv.org/abs/2505.06888</link>
      <description>arXiv:2505.06888v1 Announce Type: cross 
Abstract: In the "Big Data" era, a lot of data must be processed and moved between processing and memory units. New technologies and architectures have emerged to improve system performance and overcome the memory bottleneck. The memristor is a technology with both computing and memory capabilities. In-Memory Computing (IMC) can be performed by applying memristors to stateful design methods. The Fast and Energy-Efficient Logic in Memory (FELIX) logic is one of the stateful implementation logics compatible with memristive crossbar arrays. The way computations are performed can be changed to improve performance. Approximate design methods can be applied in error-resilient applications. In error-resilient applications, an acceptable amount of precision is lost while features such as hardware complexity, latency, and energy are improved. In this paper, using these two concepts, an approximate full adder circuit with exact Cout and approximate Sum outputs has been proposed using the FELIX design method for IMC in two different implementation approaches. The applied memristor count in the proposed FELIX-based Approximate Full Adder (FAFA) in the two proposed implementation approaches (FAFA1 and FAFA2) is improved by 14.28% and 28.57%, energy consumption is improved by 73.735% and 81.754%, respectively. The number of computational steps in both approaches is improved by 66.66% compared to the exact FELIX-based full adder. In this paper, two different scenarios are considered for evaluating the FAFA. In the 1st and 2nd scenarios, respectively, for the three and four Most Significant Bits (MSBs), the exact full adder is used, and for the five and four Least Significant Bits (LSBs), the FAFA is used. The results of error analysis and evaluations of the FAFA in three different image processing applications confirmed that FAFA has high accuracy and acceptable performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06888v1</guid>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Seyed Erfan Fatemieh, Samane Asgari, Mohammad Reza Reshadinezhad</dc:creator>
    </item>
    <item>
      <title>Energy-Efficient Ternary Encoding for High-Speed Data Transmission in 3D-Integrated Circuits Using Inductive Coupling Links</title>
      <link>https://arxiv.org/abs/2505.06908</link>
      <description>arXiv:2505.06908v1 Announce Type: cross 
Abstract: This paper proposes a ternary signalling scheme for inductive coupling links (ICLs) in 3D-integrated circuits (3D-ICs) to reduce crosstalk and electromagnetic interference in multi-stacked chip communications. By converting binary data into ternary sequences with three voltage levels (-V, 0V, +V), the approach enhances signal separation, reduces crosstalk, and improves signal integrity. Unlike traditional Non-Return to Zero (NRZ) systems, the ternary scheme increases bandwidth efficiency and reduces power consumption through fewer signal transitions. A modified H-Bridge transmitter generates ternary symbols by controlling current flow based on binary-to-ternary mapping. Preliminary simulations validate the efficiency of the scheme, showing reduced power consumption and higher data rates compared to NRZ. This approach shows promise for high-performance computing and IoT devices in 3D-IC environments, offering enhanced noise resilience, lower power usage, and improved communication efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06908v1</guid>
      <category>cs.CE</category>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abdullah Saeed Alghotmi</dc:creator>
    </item>
    <item>
      <title>Privacy of Groups in Dense Street Imagery</title>
      <link>https://arxiv.org/abs/2505.07085</link>
      <description>arXiv:2505.07085v1 Announce Type: cross 
Abstract: Spatially and temporally dense street imagery (DSI) datasets have grown unbounded. In 2024, individual companies possessed around 3 trillion unique images of public streets. DSI data streams are only set to grow as companies like Lyft and Waymo use DSI to train autonomous vehicle algorithms and analyze collisions. Academic researchers leverage DSI to explore novel approaches to urban analysis. Despite good-faith efforts by DSI providers to protect individual privacy through blurring faces and license plates, these measures fail to address broader privacy concerns. In this work, we find that increased data density and advancements in artificial intelligence enable harmful group membership inferences from supposedly anonymized data. We perform a penetration test to demonstrate how easily sensitive group affiliations can be inferred from obfuscated pedestrians in 25,232,608 dashcam images taken in New York City. We develop a typology of identifiable groups within DSI and analyze privacy implications through the lens of contextual integrity. Finally, we discuss actionable recommendations for researchers working with data from DSI providers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07085v1</guid>
      <category>cs.CY</category>
      <category>cs.CV</category>
      <category>cs.ET</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Matt Franchi, Hauke Sandhaus, Madiha Zahrah Choksi, Severin Engelmann, Wendy Ju, Helen Nissenbaum</dc:creator>
    </item>
    <item>
      <title>Exact Spin Elimination in Ising Hamiltonians and Energy-Based Machine Learning</title>
      <link>https://arxiv.org/abs/2505.07163</link>
      <description>arXiv:2505.07163v1 Announce Type: cross 
Abstract: We present an exact spin-elimination technique that reduces the dimensionality of both quadratic and k-local Ising Hamiltonians while preserving their original ground-state configurations. By systematically replacing each removed spin with an effective interaction among its neighbors, our method lowers the total spin count without invoking approximations or iterative recalculations. This capability is especially beneficial for hardware-constrained platforms, classical or quantum, that can directly implement multi-body interactions but have limited qubit or spin resources. We demonstrate three key advances enabled by this technique. First, we handle larger instances of benchmark problems such as Max-Cut on cubic graphs without exceeding a 2-local interaction limit. Second, we reduce qubit requirements in QAOA-based integer factorization on near-term quantum devices, thus extending the feasible range of integers to be factorized. Third, we improve memory capacity in Hopfield associative memories and enhance memory retrieval by suppressing spurious attractors, enhancing retrieval performance. Our spin-elimination procedure trades local spin complexity for higher-order couplings or higher node degrees in a single pass, opening new avenues for scaling up combinatorial optimization and energy-based machine learning on near-term hardware. Finally, these results underscore that the next-generation physical spin machines will likely capitalize on k-local spin Hamiltonians to offer an alternative to classical computations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07163v1</guid>
      <category>quant-ph</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Natalia G. Berloff</dc:creator>
    </item>
    <item>
      <title>SmartUT: Receive Beamforming for Spectral Coexistence of NGSO Satellite Systems</title>
      <link>https://arxiv.org/abs/2505.07714</link>
      <description>arXiv:2505.07714v1 Announce Type: cross 
Abstract: In this paper, we investigate downlink co-frequency interference (CFI) mitigation in non-geostationary satellites orbits (NGSOs) co-existing systems. Traditional mitigation techniques, such as Zero-forcing (ZF), produce a null towards the direction of arrivals (DOAs) of the interfering signals, but they suffer from high computational complexity due to matrix inversions and required knowledge of the channel state information (CSI). Furthermore, adaptive beamformers, such as sample matrix inversion (SMI)-based minimum variance, provide poor performance when the available snapshots are limited. We propose a Mamba-based beamformer (MambaBF) that leverages an unsupervised deep learning (DL) approach and can be deployed on the user terminal (UT) antenna array, for assisting downlink beamforming and CFI mitigation using only a limited number of available array snapshots as input, and without CSI knowledge. Simulation results demonstrate that MambaBF consistently outperforms conventional beamforming techniques in mitigating interference and maximizing the signal-to-interference-plus-noise ratio (SINR), particularly under challenging conditions characterized by low SINR, limited snapshots, and imperfect CSI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07714v1</guid>
      <category>eess.SP</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Almoatssimbillah Saifaldawla, Eva Lagunas, Flor Ortiz, Abuzar B. M. Adam, Symeon Chatzinotas</dc:creator>
    </item>
    <item>
      <title>The Energy Cost of Artificial Intelligence Lifecycle in Communication Networks</title>
      <link>https://arxiv.org/abs/2408.00540</link>
      <description>arXiv:2408.00540v3 Announce Type: replace 
Abstract: Artificial Intelligence (AI) is being incorporated in several optimization, scheduling, orchestration as well as in native communication network functions. While this paradigm shift results in increased energy consumption, quantifying the end-toend energy consumption of adding intelligence to such systems is particularly challenging. Conventional metrics focus on either communication, computation infrastructure, or model development. To address this, we propose a new metric, the Energy Cost of AI Lifecycle (eCAL) of one AI model in a system. eCAL captures the energy consumption throughout the development and deployment of an AI-model providing intelligence in a wireless communication network by analyzing the complexity of data collection and manipulation in individual components and deriving overall and per-bit energy consumption. We show that the better a model is and the more it is used, the more energy efficient an inference is. For a simple case study, eCAL for making 100 inferences is 2.73 times higher than for 1000 inferences. Additionally, we have developed a modular and extendable opensource simulation tool to enable researchers, practitioners, and engineers to calculate the end-to-end energy cost with various configurations and across various systems, ensuring adaptability to diverse use cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.00540v3</guid>
      <category>cs.ET</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shih-Kai Chou, Jernej Hribar, Vid Han\v{z}el, Mihael Mohor\v{c}i\v{c}, Carolina Fortuna</dc:creator>
    </item>
    <item>
      <title>Semantic Communication for Efficient Point Cloud Transmission</title>
      <link>https://arxiv.org/abs/2409.03319</link>
      <description>arXiv:2409.03319v2 Announce Type: replace 
Abstract: As three-dimensional acquisition technologies like LiDAR cameras advance, the need for efficient transmission of 3D point clouds is becoming increasingly important. In this paper, we present a novel semantic communication (SemCom) approach for efficient 3D point cloud transmission. Different from existing methods that rely on downsampling and feature extraction for compression, our approach utilizes a parallel structure to separately extract both global and local information from point clouds. This system is composed of five key components: local semantic encoder, global semantic encoder, channel encoder, channel decoder, and semantic decoder. Our numerical results indicate that this approach surpasses both the traditional Octree compression methodology and alternative deep learning-based strategies in terms of reconstruction quality. Moreover, our system is capable of achieving high-quality point cloud reconstruction under adverse channel conditions, specifically maintaining a reconstruction quality of over 37dB even with severe channel noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03319v2</guid>
      <category>cs.ET</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/GLOBECOM52923.2024.10901573</arxiv:DOI>
      <dc:creator>Shangzhuo Xie, Qianqian Yang, Yuyi Sun, Tianxiao Han, Zhaohui Yang, Zhiguo Shi</dc:creator>
    </item>
  </channel>
</rss>
