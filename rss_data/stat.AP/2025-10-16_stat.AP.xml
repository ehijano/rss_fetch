<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 17 Oct 2025 01:51:26 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Trajectory-based real-time pedestrian crash prediction at intersections: A novel non-linear link function for block maxima led Bayesian GEV framework addressing heterogeneous traffic condition</title>
      <link>https://arxiv.org/abs/2510.12963</link>
      <description>arXiv:2510.12963v1 Announce Type: new 
Abstract: This study develops a real-time framework for estimating pedestrian crash risk at signalized intersections under heterogeneous, non-lane-based traffic. Existing approaches often assume linear relationships between covariates and parameters, oversimplifying the complex, non-monotonic interactions among different road users. To overcome this, the framework introduces a non-linear link function within a Bayesian generalized extreme value (GEV) structure to capture traffic variability more accurately. The framework applies extreme value theory through the block maxima approach using post-encroachment time as a surrogate safety measure. A hierarchical Bayesian model incorporating both linear and non-linear link functions into GEV parameters is estimated using Markov Chain Monte Carlo simulation. It also introduces a behavior-normalized Modified Crash Risk (MRC) formula to account for pedestrians' habitual risk-taking behavior. Seven Bayesian hierarchical models were developed and compared using deviance information criterion. Models employing non-linear link functions for the location and scale parameters significantly outperformed their linear counterparts. The results revealed that pedestrian speed has a negative relationship with crash risk, while flow and speed of motorized vehicles, pedestrian flow, and non-motorized vehicles conflicting speed contribute positively. The MRC formulation reduced overestimation and provided crash predictions with 93% confidence. The integration of non-linear link functions enhances model flexibility, capturing the non-linear nature of traffic extremes. The proposed MRC metric aligns crash risk estimates with real-world pedestrian behavior in mixed-traffic environments. This framework offers a practical analytical tool for traffic engineers and planners to design adaptive signal control and pedestrian safety interventions before crashes occur.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.12963v1</guid>
      <category>stat.AP</category>
      <category>physics.soc-ph</category>
      <category>stat.ME</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Parvez Anowar, Nazmul Haque, Md Asif Raihan, Md Hadiuzzaman</dc:creator>
    </item>
    <item>
      <title>Surrogate Models to Predict Wave Hydrodynamics on Evolving Landscapes</title>
      <link>https://arxiv.org/abs/2510.12986</link>
      <description>arXiv:2510.12986v1 Announce Type: new 
Abstract: Coastal planners using probabilistic risk assessments to evaluate structural flood risk reduction projects may wish to simulate the hydrodynamics associated with large suites of tropical cyclones in large ensembles of landscapes: with and without projects' implementation; over decades of their useful lifetimes; and under multiple scenarios reflecting uncertainty about sea level rise, land subsidence, and other factors. Wave action can be a substantial contributor to flood losses and overtopping of structural features like levees and floodwalls, but numerical methods solving for wave dynamics are computationally expensive, potentially limiting budget-constrained planning efforts. In this study, we present and evaluate the performance of deep learning-based surrogate models for predicting peak significant wave heights under a variety of relevant use cases: predicting waves with or without modeled peak storm surge as a feature, predicting wave heights while simultaneously predicting peak storm surge, or using storm surge predicted by another surrogate model as an input feature. All models incorporate landscape morphological elements (e.g., elevation, roughness, canopy) and global boundary conditions (e.g., sea level) in addition to tropical cyclone characteristics as predictive features to improve accuracy as landscapes evolve over time. Using simulations from Louisiana's 2023 Coastal Master Plan as a case study, we demonstrate suitable accuracy of surrogate models for planning-level studies, with a two-sided Kolmogorov-Smirnov test indicating no significant difference between significant wave heights generated by the Simulating Waves Nearshore model and those predicted by our surrogate models in approximately 89% of grid cells and landscapes evaluated in the study, with performance varying by landscape and model. On average, the models produced a root mean squared error of 0.05-0.06 m.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.12986v1</guid>
      <category>stat.AP</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammad Ahmadi Gharehtoragh, David R Johnson</dc:creator>
    </item>
    <item>
      <title>The Impact of Renewable Energy Communities in the Italian Day-Ahead Electricity Market: A Scenario Analysis</title>
      <link>https://arxiv.org/abs/2510.13517</link>
      <description>arXiv:2510.13517v1 Announce Type: new 
Abstract: This paper evaluates the economic impact of Renewable Energy Communities (RECs) on the Italian wholesale power market. Combining a bottom-up engineering approach with a short-run economic impact assessment, the study begins by mapping existing and emerging RECs in Italy. We identify key characteristics of RECs, such as average installed capacity, institutional profiles of members, types of renewable systems used, and distribution across Italy's electricity market zones. This mapping yields representative REC configurations, which are employed within a bottom-up engineering model to generate energy injection and self-consumption profiles for different REC prosumer and producer categories (residential, public, small and medium enterprise, non-profit organization, and standalone installation), considering the different levels of solar irradiance in Italy based on latitude. These zonal results, aggregated on an hourly basis, inform the implementation of the synthetic counterfactual approach, which develops alternative scenarios (e.g., 5 GW target for REC-driven capacity set by Italian policy for 2027) to assess the impact of REC-driven injection and self-consumption on the Italian day-ahead power market. The findings suggest that REC deployment can increase equilibrium quantities during daylight in most of the time, while decreasing equilibrium quantities mostly during the cold months, as electrified heating drives greater self-consumption and offsets lower grid injections. Both positive and negative effects on equilibrium quantities suggest that REC deployment also has a potential to reduce wholesale electricity prices. Moreover, by reducing grid exchanges through higher self-consumption, REC proliferation can alleviate pressure on the distribution system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13517v1</guid>
      <category>stat.AP</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maksym Koltunov, Filippo Beltrami, Luigi Grossi, Nicola Blasuttigh</dc:creator>
    </item>
    <item>
      <title>Model-assisted estimation for MRV: How to boost the economics of SOC sequestration projects without compromising on scientific integrity</title>
      <link>https://arxiv.org/abs/2510.13609</link>
      <description>arXiv:2510.13609v1 Announce Type: new 
Abstract: Soil organic carbon (SOC) sequestration projects require unbiased, precise and cost-effective Monitoring, Reporting, and Verification (MRV) systems that balance sampling costs against uncertainty deductions imposed by regulatory frameworks. Design-based estimators guarantee unbiasedness but cannot exploit auxiliary data. Model-based approaches (VCS Methodology VT0014 v1.0 (2025)) can improve precision but require independent validation for each project. Model-assisted estimation offers a robust compromise, combining model predictions with probability sampling to retain design-based guarantees while improving precision. We evaluate the scientific integrity and efficiency of the simple regression estimator (SRE), a well-known model-assisted estimator, via an extensive simulation study. Our simulations span diverse SOC stock variances, sample sizes, and model performances. We assess three core properties: empirical bias, empirical confidence interval coverage, and precision gain relative to the design-based Horvitz-Thompson estimator (HTE). Results show negligible bias and valid coverage probabilities for n &gt; 40, regardless of SOC stock variance. Below this threshold, variance approximations and normality assumptions yield unreliable uncertainty estimates. With correlated ancillary variables (r^2 = 0.3), SRE achieves 30% precision gains over HTE. With uncorrelated variables, no gains are observed, but performance converges to HTE for n &gt;= 40. Model-assisted estimation can enhance project economics without compromising scientific rigor. Regulators should permit such estimators while mandating minimum sample size thresholds. Project proponents should routinely employ such estimators when correlated ancillary variables exist. The industry should prioritize the retrieval of high-quality, project-specific covariates to maximize precision gains and thereby the project economics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13609v1</guid>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ahmad Awad, Erik Scharw\"achter</dc:creator>
    </item>
    <item>
      <title>Hierarchical Bayesian Modeling of Dengue in Recife, Brazil (2015-2024): The Role of Spatial Granularity and Data Quality for Epidemiological Risk Mapping</title>
      <link>https://arxiv.org/abs/2510.13672</link>
      <description>arXiv:2510.13672v1 Announce Type: new 
Abstract: Dengue remains one of Brazil's major epidemiological challenges, marked by strong intra-urban inequalities and the influence of climatic and socio-environmental factors. This study analyzed confirmed dengue cases in Recife from 2015 to 2024 using a Bayesian hierarchical spatio-temporal model implemented in R-INLA, combining a BYM2 spatial structure with an RW1 temporal component. Covariates included population density, household size, income, drainage channels, lagged precipitation, and mean temperature. Population density and household size had positive effects on dengue risk, while income and channel presence were protective. Lagged precipitation increased risk, and higher temperatures showed an inverse association, suggesting thermal thresholds for vector activity. The model achieved good fit (DIC=65817; WAIC=64506) and stable convergence, with moderate residual spatial autocorrelation (phi=0.06) and a smooth temporal trend between 2016 and 2019. Spatio-temporal estimates revealed persistent high-risk clusters in northern and western Recife, overlapping with areas of higher density and social vulnerability. Beyond reproducing historical patterns, the Bayesian model supports probabilistic forecasting and early warning systems. Compared with classical models (GLM, SAR, GWR, GTWR), INLA explicitly integrates uncertainty and spatial-temporal dependence, offering credible interval inference for decision-making in urban health management.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13672v1</guid>
      <category>stat.AP</category>
      <category>q-bio.QM</category>
      <category>stat.ME</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marc\'ilio Ferreira dos Santos, Andreza dos Santos Rodrigues de Melo</dc:creator>
    </item>
    <item>
      <title>Macro-Level Correlational Analysis of Mental Disorders: Economy, Education, Society, and Technology Development</title>
      <link>https://arxiv.org/abs/2510.13780</link>
      <description>arXiv:2510.13780v1 Announce Type: new 
Abstract: This paper quantifies the age-stratified global burden of four mental disorders in 27 regions from 1990 to 2021 using GBD 2021. To put it in detail, it links the age-standardized years of disability adjustment with 18 world development indicators across economic, educational, social and information technology sectors. Then, by means of Pearson correlation, mutual information, Granger causality and maximum information coefficient and other methods, the linear, nonlinear and lagged dependency relationships were evaluated. After research, it was found that there is a very prominent spatio-temporal heterogeneity among young people aged 20 to 39, and the coupling relationship is stronger. From the overall situation, education corresponds to a low burden. Unemployment corresponds to a high burden. Through lag analysis, it can be known that the influence time of economic and technological factors is relatively short, while that of educational factors is relatively long. These results highlight the macro determinants that play a role at different time scales and also provide population-level references for verifying computational mental health models and for intervention measures in specific regions and for specific ages.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13780v1</guid>
      <category>stat.AP</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yingzhi Tao, Chang Yang</dc:creator>
    </item>
    <item>
      <title>The Price-Pareto growth model of networks with community structure</title>
      <link>https://arxiv.org/abs/2510.13392</link>
      <description>arXiv:2510.13392v1 Announce Type: cross 
Abstract: We introduce a new analytical framework for modelling degree sequences in individual communities of real-world networks, e.g., citations to papers in different fields. Our work is inspired by Price's model and its recent generalisation called 3DSI (three dimensions of scientific impact), which assumes that citations are gained partly accidentally, and to some extent preferentially. Our generalisation is motivated by existing research indicating significant differences between how various scientific disciplines grow, namely, minding different growth ratios, average reference list lengths, and preferential citing tendencies. Extending the 3DSI model to heterogeneous networks with a community structure allows us to devise new analytical formulas for, e.g., citation number inequality and preferentiality measures. We show that the distribution of citations in a community tends to a Pareto type II distribution. We also present analytical formulas for estimating its parameters and Gini's index. The new model is validated on real citation networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13392v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.SI</category>
      <category>stat.AP</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>{\L}ukasz Brzozowski, Marek Gagolewski, Grzegorz Siudem, Barbara \.Zoga{\l}a-Siudem</dc:creator>
    </item>
    <item>
      <title>Mobile Coverage Analysis using Crowdsourced Data</title>
      <link>https://arxiv.org/abs/2510.13459</link>
      <description>arXiv:2510.13459v1 Announce Type: cross 
Abstract: Effective assessment of mobile network coverage and the precise identification of service weak spots are paramount for network operators striving to enhance user Quality of Experience (QoE). This paper presents a novel framework for mobile coverage and weak spot analysis utilising crowdsourced QoE data. The core of our methodology involves coverage analysis at the individual cell (antenna) level, subsequently aggregated to the site level, using empirical geolocation data. A key contribution of this research is the application of One-Class Support Vector Machine (OC-SVM) algorithm for calculating mobile network coverage. This approach models the decision hyperplane as the effective coverage contour, facilitating robust calculation of coverage areas for individual cells and entire sites. The same methodology is extended to analyse crowdsourced service loss reports, thereby identifying and quantifying geographically localised weak spots. Our findings demonstrate the efficacy of this novel framework in accurately mapping mobile coverage and, crucially, in highlighting granular areas of signal deficiency, particularly within complex urban environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13459v1</guid>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.NI</category>
      <category>stat.AP</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Timothy Wong, Tom Freeman, Joseph Feehily</dc:creator>
    </item>
    <item>
      <title>Multifractality and its sources in the digital currency market</title>
      <link>https://arxiv.org/abs/2510.13785</link>
      <description>arXiv:2510.13785v1 Announce Type: cross 
Abstract: Multifractality in time series analysis characterizes the presence of multiple scaling exponents, indicating heterogeneous temporal structures and complex dynamical behaviors beyond simple monofractal models. In the context of digital currency markets, multifractal properties arise due to the interplay of long-range temporal correlations and heavy-tailed distributions of returns, reflecting intricate market microstructure and trader interactions. Incorporating multifractal analysis into the modeling of cryptocurrency price dynamics enhances the understanding of market inefficiencies, may improve volatility forecasting and facilitate the detection of critical transitions or regime shifts. Based on the multifractal cross-correlation analysis (MFCCA) whose spacial case is the multifractal detrended fluctuation analysis (MFDFA), as the most commonly used practical tools for quantifying multifractality, in the present contribution a recently proposed method of disentangling sources of multifractality in time series was applied to the most representative instruments from the digital market. They include Bitcoin (BTC), Ethereum (ETH), decentralized exchanges (DEX) and non-fungible tokens (NFT). The results indicate the significant role of heavy tails in generating a broad multifractal spectrum. However, they also clearly demonstrate that the primary source of multifractality are temporal correlations in the series, and without them, multifractality fades out. It appears characteristic that these temporal correlations, to a large extent, do not depend on the thickness of the tails of the fluctuation distribution. These observations, made here in the context of the digital currency market, provide a further strong argument for the validity of the proposed methodology of disentangling sources of multifractality in time series.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13785v1</guid>
      <category>q-fin.ST</category>
      <category>cs.CE</category>
      <category>physics.data-an</category>
      <category>stat.AP</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.3390/fi17100470</arxiv:DOI>
      <arxiv:journal_reference>Future Internet 2025, 17(10)</arxiv:journal_reference>
      <dc:creator>Stanis{\l}aw Dro\.zd\.z, Robert Kluszczy\'nski, Jaros{\l}aw Kwapie\'n, Marcin W\k{a}torek</dc:creator>
    </item>
    <item>
      <title>Accounting for Missing Data in Public Health Research Using a Synthesis of Statistical and Mathematical Models</title>
      <link>https://arxiv.org/abs/2503.02789</link>
      <description>arXiv:2503.02789v3 Announce Type: replace 
Abstract: Introduction: Accounting for missing data by imputing or weighting conditional on covariates relies on the variable with missingness being observed at least some of the time for all unique covariate values. This requirement is referred to as positivity and positivity violations can result in bias. Here, we review a novel approach to addressing positivity violations in the context of systolic blood pressure. Methods: To illustrate the proposed approach, we estimate the mean systolic blood pressure among children and adolescents aged 2-17 years old in the United States using data from the 2017-2018 National Health and Nutrition Examination Survey (NHANES). As blood pressure was not measured for those aged 2-7, there exists a positivity violation by design. Using a recently proposed synthesis of statistical and mathematical models, we integrate external information with NHANES to address our motivating question. Results: With the synthesis model, the estimated mean systolic blood pressure was 100.5 (95% confidence interval: 99.9, 101.0), which is notably lower than either a complete-case analysis or extrapolation from a statistical model. The synthesis results were supported by a diagnostic comparing the performance of the mathematical model in the positive region. Discussion: Positivity violations pose a threat to quantitative medical research, and standard approaches to addressing nonpositivity rely on restrictive untestable assumptions. Using a synthesis model, like the one detailed here, offers a viable alternative.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02789v3</guid>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paul N Zivich, Bonnie E Shook-Sa, Stephen R Cole, Eric T Lofgren, Jessie K Edwards</dc:creator>
    </item>
    <item>
      <title>Autoregressive models for panel data causal inference with application to state-level opioid policies</title>
      <link>https://arxiv.org/abs/2408.09012</link>
      <description>arXiv:2408.09012v2 Announce Type: replace-cross 
Abstract: Motivated by the study of state opioid policies, we propose a novel approach that uses autoregressive models for causal effect estimation in settings with panel data and staggered treatment adoption. Specifically, we seek to estimate the impact of key opioid-related policies by quantifying the effects of must access prescription drug monitoring programs (PDMPs), naloxone access laws (NALs), and medical marijuana laws on opioid prescribing. Existing methods, such as differences-in-differences and synthetic controls, are challenging to apply in these types of dynamic policy landscapes where multiple policies are implemented over time and sample sizes are small. Autoregressive models are an alternative strategy that have been used to estimate policy effects in similar settings, but until this paper have lacked formal justification. We outline a set of assumptions that tie these models to causal effects, and we study biases of estimates based on this approach when key causal assumptions are violated. In a set of simulation studies that mirror the structure of our application, we show that our proposed estimators frequently outperform existing estimators. In short, we justify the use of autoregressive models to evaluate the effectiveness of four state policies in combating the opioid crisis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09012v2</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joseph Antonelli, Max Rubinstein, Denis Agniel, Rosanna Smart, Elizabeth Stuart, Matthew Cefalu, Terry Schell, Joshua Eagan, Elizabeth Stone, Max Griswold, Beth Ann Griffin</dc:creator>
    </item>
    <item>
      <title>Discretion in the Loop: Human Expertise in Algorithm-Assisted College Advising</title>
      <link>https://arxiv.org/abs/2505.13325</link>
      <description>arXiv:2505.13325v3 Announce Type: replace-cross 
Abstract: In higher education, many institutions use algorithmic alerts to flag at-risk students and deliver advising at scale. While much research has focused on evaluating algorithmic predictions, relatively little is known about how discretionary interventions by human experts shape outcomes in algorithm-assisted settings. We study this question using rich quantitative and qualitative data from a randomized controlled trial of an algorithm-assisted advising program at Georgia State University. Taking a mixed-methods approach, we examine whether and how advisors use context unavailable to an algorithm to guide interventions and influence student success. We develop a causal graphical framework for human expertise in the interventional setting, extending prior work on discretion in purely predictive settings. We then test a necessary condition for discretionary expertise using structured advisor logs and student outcomes data, identifying several interventions that meet the criterion for statistical significance. Accordingly, we estimate that 2 out of 3 interventions taken by advisors in the treatment arm were plausibly ``expertly targeted'' to students using non-algorithmic context. Systematic qualitative analysis of advisor notes corroborates these findings, showing a pattern of advisors incorporating diverse forms of contextual information--such as personal circumstances, financial issues, and student engagement--into their decisions. Finally, we document heterogeneity in advising styles, finding that one style elicits more holistic information about students and is associated with improved graduation rates. Our results offer theoretical and practical insight into the real-world effectiveness of algorithm-supported college advising, and underscore the importance of accounting for human expertise in the design, evaluation, and implementation of algorithmic decision systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13325v3</guid>
      <category>cs.CY</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kara Schechtman, Benjamin Brandon, Jenise Stafford, Hannah Li, Lydia T. Liu</dc:creator>
    </item>
  </channel>
</rss>
