<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 15 Apr 2024 04:00:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 15 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Viscosity solutions for mean field optimal switching with a two-time-scale Markov chain</title>
      <link>https://arxiv.org/abs/2404.07998</link>
      <description>arXiv:2404.07998v1 Announce Type: new 
Abstract: In this paper, we consider the mean field optimal switching problem with a Markov chain under viscosity solution notion. Based on the conditional distribution of the Markov chain, the value function and corresponding dynamic programming principle (DPP) are established. The switching problem is characterized by an obstacle equation on the Wasserstein space, and the existence, stability, and comparison principle are obtained in the sense of viscosity solution. In particular, we consider a two-time-scale structure and obtain the convergence of the limit system. As an application of our theoretical results, an innovative example concerning the stock trading problem in a regime switching market is solved.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07998v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tian Chen, Guanxu Li, Zhen Wu</dc:creator>
    </item>
    <item>
      <title>Spurious Stationarity and Hardness Results for Mirror Descent</title>
      <link>https://arxiv.org/abs/2404.08073</link>
      <description>arXiv:2404.08073v1 Announce Type: new 
Abstract: Despite the considerable success of Bregman proximal-type algorithms, such as mirror descent, in machine learning, a critical question remains: Can existing stationarity measures, often based on Bregman divergence, reliably distinguish between stationary and non-stationary points? In this paper, we present a groundbreaking finding: All existing stationarity measures necessarily imply the existence of spurious stationary points. We further establish an algorithmic independent hardness result: Bregman proximal-type algorithms are unable to escape from a spurious stationary point in finite steps when the initial point is unfavorable, even for convex problems. Our hardness result points out the inherent distinction between Euclidean and Bregman geometries, and introduces both fundamental theoretical and numerical challenges to both machine learning and optimization communities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08073v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>He Chen, Jiajin Li, Anthony Man-Cho So</dc:creator>
    </item>
    <item>
      <title>A least-square method for non-asymptotic identification in linear switching control</title>
      <link>https://arxiv.org/abs/2404.08120</link>
      <description>arXiv:2404.08120v1 Announce Type: new 
Abstract: The focus of this paper is on linear system identification in the setting where it is known that the underlying partially-observed linear dynamical system lies within a finite collection of known candidate models. We first consider the problem of identification from a given trajectory, which in this setting reduces to identifying the index of the true model with high probability. We characterize the finite-time sample complexity of this problem by leveraging recent advances in the non-asymptotic analysis of linear least-square methods in the literature. In comparison to the earlier results that assume no prior knowledge of the system, our approach takes advantage of the smaller hypothesis class and leads to the design of a learner with a dimension-free sample complexity bound. Next, we consider the switching control of linear systems, where there is a candidate controller for each of the candidate models and data is collected through interaction of the system with a collection of potentially destabilizing controllers. We develop a dimension-dependent criterion that can detect those destabilizing controllers in finite time. By leveraging these results, we propose a data-driven switching strategy that identifies the unknown parameters of the underlying system. We then provide a non-asymptotic analysis of its performance and discuss its implications on the classical method of estimator-based supervisory control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08120v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haoyuan Sun, Ali Jadbabaie</dc:creator>
    </item>
    <item>
      <title>Equitable Routing -- Rethinking the Multiple Traveling Salesman Problem</title>
      <link>https://arxiv.org/abs/2404.08157</link>
      <description>arXiv:2404.08157v1 Announce Type: new 
Abstract: The Multiple Traveling Salesman Problem (MTSP) with a single depot is a generalization of the well-known Traveling Salesman Problem (TSP) that involves an additional parameter, namely, the number of salesmen. In the MTSP, several salesmen at the depot need to visit a set of interconnected targets, such that each target is visited precisely once by at most one salesman while minimizing the total length of their tours. An equally important variant of the MTSP, the min-max MTSP, aims to distribute the workload (length of the individual tours) among salesmen by requiring the longest tour of all the salesmen to be as short as possible, i.e., minimizing the maximum tour length among all salesmen. The min-max MTSP appears in real-life applications to ensure a good balance of workloads for the salesmen. It is known in the literature that the min-max MTSP is notoriously difficult to solve to optimality due to the poor lower bounds its linear relaxations provide. In this paper, we formulate two novel parametric variants of the MTSP called the "fair-MTSP". One variant is formulated as a Mixed-Integer Second Order Cone Program (MISOCP), and the other as a Mixed Integer Linear Program (MILP). Both focus on enforcing the workloads for the salesmen to be equitable, i.e., the distribution of tour lengths for the salesmen to be fair while minimizing the total cost of their tours. We present algorithms to solve the two variants of the fair-MTSP to global optimality and computational results on benchmark and real-world test instances that make a case for fair-MTSP as a viable alternative to the min-max MTSP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08157v1</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abhay Singh Bhadoriya, Deepjyoti Deka, Kaarthik Sundar</dc:creator>
    </item>
    <item>
      <title>The Rank-1 Completion Problem for Cubic Tensors</title>
      <link>https://arxiv.org/abs/2404.08171</link>
      <description>arXiv:2404.08171v1 Announce Type: new 
Abstract: This paper studies the rank-$1$ tensor completion problem for cubic order tensors. First of all, we show that this problem is equivalent to a special rank-$1$ matrix recovery problem. We propose both nuclear norm relaxation and moment relaxation methods for solving the resulting rank-$1$ matrix recovery problem. The nuclear norm relaxation sometimes get a rank-$1$ tensor completion, while sometimes it does not. When it fails, we apply the moment hierarchy of semidefinite programming relaxations to solve the rank-$1$ matrix recovery problem. The moment hierarchy can always get a rank-$1$ tensor completion, or detect its nonexistence. In particular, when the tensor is strongly rank-$1$ completable, we show that the problem is equivalent to a rank-$1$ matrix completion problem and it can be solved by an iterative formula. Therefore, much larger size problems can be solved efficiently for strongly rank-$1$ completable tensors. Numerical experiments are shown to demonstrate the efficiency of these proposed methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08171v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jinling Zhou, Jiawang Nie, Zheng Peng, Guangming Zhou</dc:creator>
    </item>
    <item>
      <title>A Parametric Approach for Solving Convex Quadratic Optimization with Indicators Over Trees</title>
      <link>https://arxiv.org/abs/2404.08178</link>
      <description>arXiv:2404.08178v1 Announce Type: new 
Abstract: This paper investigates convex quadratic optimization problems involving $n$ indicator variables, each associated with a continuous variable, particularly focusing on scenarios where the matrix $Q$ defining the quadratic term is positive definite and its sparsity pattern corresponds to the adjacency matrix of a tree graph. We introduce a graph-based dynamic programming algorithm that solves this problem in time and memory complexity of $\mathcal{O}(n^2)$. Central to our algorithm is a precise parametric characterization of the cost function across various nodes of the graph corresponding to distinct variables. Our computational experiments conducted on both synthetic and real-world datasets demonstrate the superior performance of our proposed algorithm compared to existing algorithms and state-of-the-art mixed-integer optimization solvers. An important application of our algorithm is in the real-time inference of Gaussian hidden Markov models from data affected by outlier noise. Using a real on-body accelerometer dataset, we solve instances of this problem with over 30,000 variables in under a minute, and its online variant within milliseconds on a standard computer. A Python implementation of our algorithm is available at https://github.com/aareshfb/Tree-Parametric-Algorithm.git.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08178v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aaresh Bhathena, Salar Fattahi, Andr\'es G\'omez, Simge K\"u\c{c}\"ukyavuz</dc:creator>
    </item>
    <item>
      <title>The Inverse Carson's Equations Problem: Definition, Implementation and Experiments</title>
      <link>https://arxiv.org/abs/2404.08210</link>
      <description>arXiv:2404.08210v1 Announce Type: new 
Abstract: In recent years, with the increase in renewable energy and storage penetration, power flow studies in low-voltage networks have become of interest in both industry and academia. Many studies use impedance represented by sequence components due to the lack of datasets with fully parameterized impedance matrices. This assumes that the network impedance is balanced, which is typically not the case in the low voltage network and therefore risks the accuracy of the study. This paper proposes a methodology for the recovery of more detailed impedance data from sequence components as an inverse problem, i.e. the inverse Carson's equations problem, for both overhead lines and cables. We consider discrete properties like material and configuration of conductors common in the distribution network and investigate what data can be reliably recovered from only sequence components using nonlinear optimisation models. Presented results include uniqueness of recovered variables and the likelihood of mismatch.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08210v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ching Hong Tam, Frederik Geth, Nadarajah Mithulananthan</dc:creator>
    </item>
    <item>
      <title>On the controllability in projections for linear quantum systems</title>
      <link>https://arxiv.org/abs/2404.08290</link>
      <description>arXiv:2404.08290v1 Announce Type: new 
Abstract: We present sufficient conditions for the exact controllability in projection of the linear Schr{\"o}dinger equations in the case where the spectrum of the free Hamiltonian is pure point. We consider the general case in which the Hamiltonian may be nonlinear with respect to the control. The controllability result applies, in particular, to Schr{\"o}dinger equations with a polarizability term.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08290v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Chambrion (IMB), Nabile Boussaid (LMB), Marco Caponigro</dc:creator>
    </item>
    <item>
      <title>Towards a representer theorem for identification of passive systems</title>
      <link>https://arxiv.org/abs/2404.08297</link>
      <description>arXiv:2404.08297v1 Announce Type: new 
Abstract: A major problem in system identification is the incorporation of prior knowledge about the physical properties of the given system, such as stability, positivity and passivity. In this paper, we present first steps towards tackling this problem for passive systems. In particular, using ideas from the theory of reproducing kernel Hilbert spaces, we solve the problem of identifying a nonnegative input-output operator from data consisting of input-output trajectories of the system. We prove a representer theorem for this problem in the case where the input space is finite-dimensional. This provides a computationally tractable solution, which we show can be obtained by solving an associated semidefinite program.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08297v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Brayan M. Shali, Henk J. van Waarde</dc:creator>
    </item>
    <item>
      <title>Finite State Mean Field Games with Common Shocks</title>
      <link>https://arxiv.org/abs/2404.08316</link>
      <description>arXiv:2404.08316v1 Announce Type: new 
Abstract: We present a novel framework for mean field games with finite state space and common noise, where the common noise is given through shocks that occur at random times. We first analyze the game for up to $n$ shocks, in which case we are able to characterize mean field equilibria through a system of parameterized and coupled forward-backward equations. We establish existence and uniqueness of solutions to this system for small time horizons. In addition, we show that mean field equilibria for the $n$-shock setting constitute approximate equilibria for the corresponding mean field game with infinitely many common shocks. Our results are illustrated in a corruption detection model with random audits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08316v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Berenice Anne Neumann, Frank T. Seifried</dc:creator>
    </item>
    <item>
      <title>An Iterative Refinement Approach for the Rolling Stock Rotation Problem with Predictive Maintenance</title>
      <link>https://arxiv.org/abs/2404.08367</link>
      <description>arXiv:2404.08367v1 Announce Type: new 
Abstract: The rolling stock rotation problem with predictive maintenance (RSRP-PdM) involves the assignment of trips to a fleet of vehicles with integrated maintenance scheduling based on the predicted failure probability of the vehicles. These probabilities are determined by the health states of the vehicles, which are considered to be random variables distributed by a parameterized family of probability distribution functions. During the operation of the trips, the corresponding parameters get updated. In this article, we present a dual solution approach for RSRP-PdM and generalize a linear programming based lower bound for this problem to families of probability distribution functions with more than one parameter. For this purpose, we define a rounding function that allows for a consistent underestimation of the parameters and model the problem by a state-expanded event-graph in which the possible states are restricted to a discrete set. This induces a flow problem that is solved by an integer linear program. We show that the iterative refinement of the underlying discretization leads to solutions that converge from below to an optimal solution of the original instance. Thus, the linear relaxation of the considered integer linear program results in a lower bound for RSRP-PdM. Finally, we report on the results of computational experiments conducted on a library of test instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08367v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Felix Prause, Ralf Bornd\"orfer</dc:creator>
    </item>
    <item>
      <title>Optimal Transport for Mixtures of Radial Functions</title>
      <link>https://arxiv.org/abs/2404.08383</link>
      <description>arXiv:2404.08383v1 Announce Type: new 
Abstract: Recently, a relaxed formulation of optimal transport for Gaussian mixtures has been proposed, which is based on the explicit formulation between Gaussians. The Gaussian distributions can be viewed as special elliptical contoured distributions generated from exponential function. In literature, there are few research about optimal transport between elliptical contoured distributions generated from different functions. In this paper, we first study optimal transport between radial contoured distributions generated from different functions and show theirWasserstein barycenter is still radial. Then we introduce a relaxed Wasserstein-type distance for mixtures with radial contoured components. We also consider the corresponding barycenter problem and connect it with a multimarginal problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08383v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Keyu Chen, Yunxin Zhang</dc:creator>
    </item>
    <item>
      <title>A modified Polak-Ribiere-Polyak type conjugate gradient method with two stepsize strategies for vector optimization</title>
      <link>https://arxiv.org/abs/2404.08503</link>
      <description>arXiv:2404.08503v1 Announce Type: new 
Abstract: In this paper, in order to find critical points of vector-valued functions with respect to the partial order induced by a closed, convex, and pointed cone with nonempty interior, we propose a nonlinear modified Polak-Ribiere-Polyak type conjugate gradient method with a nonnegative conjugate parameter. We show that the search direction in our method satisfies the sufficient descent condition independent of any line search. Furthermore, under mild assumptions, we obtain the results of global convergence with the standard Wolfe line search conditions as well as the standard Armijo line search strategy without convexity assumption of the objective functions. Computational experiments are given to show the effectiveness of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08503v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yushan Bai, Jiawei Chen, Kaiping Liu</dc:creator>
    </item>
    <item>
      <title>Convexity in Optimal Control Problems</title>
      <link>https://arxiv.org/abs/2404.08621</link>
      <description>arXiv:2404.08621v1 Announce Type: new 
Abstract: This paper investigates the central role played by the Hamiltonian in continuous-time nonlinear optimal control problems. We show that the strict convexity of the Hamiltonian in the control variable is a sufficient condition for the existence of a unique optimal trajectory, and the nonlinearity/non-convexity of the dynamics and the cost are immaterial. The analysis is extended to discrete-time problems, revealing that discretization destroys the convex Hamiltonian structure, leading to multiple spurious optima, unless the time discretization is sufficiently small. We present simulated results comparing the "indirect" Iterative Linear Quadratic Regulator (iLQR) and the "direct" Sequential Quadratic Programming (SQP) approach for solving the optimal control problem for the cartpole and pendulum models to validate the theoretical analysis. Results show that the ILQR always converges to the "globally" optimum solution while the SQP approach gets stuck in spurious minima given multiple random initial guesses for a time discretization that is insufficiently small, while both converge to the same unique solution if the discretization is sufficiently small.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08621v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator> Abhijeet, Mohamed Naveed Gul Mohamed, Aayushman Sharma, Suman Chakravorty</dc:creator>
    </item>
    <item>
      <title>Actionable forecasting as a determinant of function in noisy biological systems</title>
      <link>https://arxiv.org/abs/2404.07895</link>
      <description>arXiv:2404.07895v1 Announce Type: cross 
Abstract: Continuous adaptation to variable environments is crucial for the survival of living organisms. Here, we analyze how adaptation, forecasting, and resource mobilization towards a target state, termed actionability, interact to determine biological function. We develop a general theory and show that it is possible for organisms to continuously track their optimal state in a dynamic environment by adapting towards an actionable target that incorporates just current information on the optimal state and its rate of change. If the environmental information is precise and readily actionable, it is possible to implement perfect tracking without anticipatory mechanisms, irrespective of the adaptation rate. In contrast, predictive functions, like those of circadian rhythms, are beneficial if sensing the environment is slow or unreliable, as they allow better adaptation with fewer resources. To explore potential actionable forecasting mechanisms, we develop a general approach that implements the adaptation dynamics with forecasting through a dynamics-informed neural network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07895v1</guid>
      <category>q-bio.CB</category>
      <category>cond-mat.stat-mech</category>
      <category>math.OC</category>
      <category>nlin.AO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jose M. G. Vilar, Leonor Saiz</dc:creator>
    </item>
    <item>
      <title>Learning Efficient and Fair Policies for Uncertainty-Aware Collaborative Human-Robot Order Picking</title>
      <link>https://arxiv.org/abs/2404.08006</link>
      <description>arXiv:2404.08006v1 Announce Type: cross 
Abstract: In collaborative human-robot order picking systems, human pickers and Autonomous Mobile Robots (AMRs) travel independently through a warehouse and meet at pick locations where pickers load items onto the AMRs. In this paper, we consider an optimization problem in such systems where we allocate pickers to AMRs in a stochastic environment. We propose a novel multi-objective Deep Reinforcement Learning (DRL) approach to learn effective allocation policies to maximize pick efficiency while also aiming to improve workload fairness amongst human pickers. In our approach, we model the warehouse states using a graph, and define a neural network architecture that captures regional information and effectively extracts representations related to efficiency and workload. We develop a discrete-event simulation model, which we use to train and evaluate the proposed DRL approach. In the experiments, we demonstrate that our approach can find non-dominated policy sets that outline good trade-offs between fairness and efficiency objectives. The trained policies outperform the benchmarks in terms of both efficiency and fairness. Moreover, they show good transferability properties when tested on scenarios with different warehouse sizes. The implementation of the simulation model, proposed approach, and experiments are published.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08006v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Igor G. Smit, Zaharah Bukhsh, Mykola Pechenizkiy, Kostas Alogariastos, Kasper Hendriks, Yingqian Zhang</dc:creator>
    </item>
    <item>
      <title>DIMAT: Decentralized Iterative Merging-And-Training for Deep Learning Models</title>
      <link>https://arxiv.org/abs/2404.08079</link>
      <description>arXiv:2404.08079v1 Announce Type: cross 
Abstract: Recent advances in decentralized deep learning algorithms have demonstrated cutting-edge performance on various tasks with large pre-trained models. However, a pivotal prerequisite for achieving this level of competitiveness is the significant communication and computation overheads when updating these models, which prohibits the applications of them to real-world scenarios. To address this issue, drawing inspiration from advanced model merging techniques without requiring additional training, we introduce the Decentralized Iterative Merging-And-Training (DIMAT) paradigm--a novel decentralized deep learning framework. Within DIMAT, each agent is trained on their local data and periodically merged with their neighboring agents using advanced model merging techniques like activation matching until convergence is achieved. DIMAT provably converges with the best available rate for nonconvex functions with various first-order methods, while yielding tighter error bounds compared to the popular existing approaches. We conduct a comprehensive empirical analysis to validate DIMAT's superiority over baselines across diverse computer vision tasks sourced from multiple datasets. Empirical results validate our theoretical claims by showing that DIMAT attains faster and higher initial gain in accuracy with independent and identically distributed (IID) and non-IID data, incurring lower communication overhead. This DIMAT paradigm presents a new opportunity for the future decentralized learning, enhancing its adaptability to real-world with sparse and light-weight communication and computation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08079v1</guid>
      <category>cs.LG</category>
      <category>cs.CV</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nastaran Saadati, Minh Pham, Nasla Saleem, Joshua R. Waite, Aditya Balu, Zhanhong Jiang, Chinmay Hegde, Soumik Sarkar</dc:creator>
    </item>
    <item>
      <title>Variance-reduced Zeroth-Order Methods for Fine-Tuning Language Models</title>
      <link>https://arxiv.org/abs/2404.08080</link>
      <description>arXiv:2404.08080v1 Announce Type: cross 
Abstract: Fine-tuning language models (LMs) has demonstrated success in a wide array of downstream tasks. However, as LMs are scaled up, the memory requirements for backpropagation become prohibitively high. Zeroth-order (ZO) optimization methods can leverage memory-efficient forward passes to estimate gradients. More recently, MeZO, an adaptation of ZO-SGD, has been shown to consistently outperform zero-shot and in-context learning when combined with suitable task prompts. In this work, we couple ZO methods with variance reduction techniques to enhance stability and convergence for inference-based LM fine-tuning. We introduce Memory-Efficient Zeroth-Order Stochastic Variance-Reduced Gradient (MeZO-SVRG) and demonstrate its efficacy across multiple LM fine-tuning tasks, eliminating the reliance on task-specific prompts. Evaluated across a range of both masked and autoregressive LMs on benchmark GLUE tasks, MeZO-SVRG outperforms MeZO with up to 20% increase in test accuracies in both full- and partial-parameter fine-tuning settings. MeZO-SVRG benefits from reduced computation time as it often surpasses MeZO's peak test accuracy with a $2\times$ reduction in GPU-hours. MeZO-SVRG significantly reduces the required memory footprint compared to first-order SGD, i.e. by $2\times$ for autoregressive models. Our experiments highlight that MeZO-SVRG's memory savings progressively improve compared to SGD with larger batch sizes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08080v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tanmay Gautam, Youngsuk Park, Hao Zhou, Parameswaran Raman, Wooseok Ha</dc:creator>
    </item>
    <item>
      <title>Efficient Duple Perturbation Robustness in Low-rank MDPs</title>
      <link>https://arxiv.org/abs/2404.08089</link>
      <description>arXiv:2404.08089v1 Announce Type: cross 
Abstract: The pursuit of robustness has recently been a popular topic in reinforcement learning (RL) research, yet the existing methods generally suffer from efficiency issues that obstruct their real-world implementation. In this paper, we introduce duple perturbation robustness, i.e. perturbation on both the feature and factor vectors for low-rank Markov decision processes (MDPs), via a novel characterization of $(\xi,\eta)$-ambiguity sets. The novel robust MDP formulation is compatible with the function representation view, and therefore, is naturally applicable to practical RL problems with large or even continuous state-action spaces. Meanwhile, it also gives rise to a provably efficient and practical algorithm with theoretical convergence rate guarantee. Examples are designed to justify the new robustness concept, and algorithmic efficiency is supported by both theoretical bounds and numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08089v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yang Hu, Haitong Ma, Bo Dai, Na Li</dc:creator>
    </item>
    <item>
      <title>Exponentially Weighted Moving Models</title>
      <link>https://arxiv.org/abs/2404.08136</link>
      <description>arXiv:2404.08136v1 Announce Type: cross 
Abstract: An exponentially weighted moving model (EWMM) for a vector time series fits a new data model each time period, based on an exponentially fading loss function on past observed data. The well known and widely used exponentially weighted moving average (EWMA) is a special case that estimates the mean using a square loss function. For quadratic loss functions EWMMs can be fit using a simple recursion that updates the parameters of a quadratic function. For other loss functions, the entire past history must be stored, and the fitting problem grows in size as time increases. We propose a general method for computing an approximation of EWMM, which requires storing only a window of a fixed number of past samples, and uses an additional quadratic term to approximate the loss associated with the data before the window. This approximate EWMM relies on convex optimization, and solves problems that do not grow with time. We compare the estimates produced by our approximation with the estimates from the exact EWMM method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08136v1</guid>
      <category>stat.CO</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <category>q-fin.CP</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eric Luxenberg, Stephen Boyd</dc:creator>
    </item>
    <item>
      <title>Generic controllability of equivariant systems and applications to particle systems and neural networks</title>
      <link>https://arxiv.org/abs/2404.08289</link>
      <description>arXiv:2404.08289v1 Announce Type: cross 
Abstract: There exist many examples of systems which have some symmetries, and which one may monitor with symmetry preserving controls. Since symmetries are preserved along the evolution, full controllability is not possible, and controllability has to be considered inside sets of states with same symmetries. We prove that generic systems with symmetries are controllable in this sense. This result has several applications, for instance:  (i) generic controllability of particle systems when the kernel of interaction between particles plays the role of a mean-field control;  (ii)  generic controllability for families of vector fields on manifolds with boundary; (iii) universal interpolation for neural networks architectures with "generic" self attention-type layers - a type of layers ubiquitous in recent neural networks architectures, e.g., in the Transformers architecture. The tools we develop could help address various other questions of control of equivariant systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08289v1</guid>
      <category>math.DS</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrei Agrachev (SISSA / ISAS), Cyril Letrouit (LMO, INSMI-CNRS)</dc:creator>
    </item>
    <item>
      <title>Federated Optimization with Doubly Regularized Drift Correction</title>
      <link>https://arxiv.org/abs/2404.08447</link>
      <description>arXiv:2404.08447v1 Announce Type: cross 
Abstract: Federated learning is a distributed optimization paradigm that allows training machine learning models across decentralized devices while keeping the data localized. The standard method, FedAvg, suffers from client drift which can hamper performance and increase communication costs over centralized methods. Previous works proposed various strategies to mitigate drift, yet none have shown uniformly improved communication-computation trade-offs over vanilla gradient descent.
  In this work, we revisit DANE, an established method in distributed optimization. We show that (i) DANE can achieve the desired communication reduction under Hessian similarity constraints. Furthermore, (ii) we present an extension, DANE+, which supports arbitrary inexact local solvers and has more freedom to choose how to aggregate the local updates. We propose (iii) a novel method, FedRed, which has improved local computational complexity and retains the same communication complexity compared to DANE/DANE+. This is achieved by using doubly regularized drift correction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08447v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaowen Jiang, Anton Rodomanov, Sebastian U. Stich</dc:creator>
    </item>
    <item>
      <title>Regularized Gradient Clipping Provably Trains Wide and Deep Neural Networks</title>
      <link>https://arxiv.org/abs/2404.08624</link>
      <description>arXiv:2404.08624v1 Announce Type: cross 
Abstract: In this work, we instantiate a regularized form of the gradient clipping algorithm and prove that it can converge to the global minima of deep neural network loss functions provided that the net is of sufficient width. We present empirical evidence that our theoretically founded regularized gradient clipping algorithm is also competitive with the state-of-the-art deep-learning heuristics. Hence the algorithm presented here constitutes a new approach to rigorous deep learning.
  The modification we do to standard gradient clipping is designed to leverage the PL* condition, a variant of the Polyak-Lojasiewicz inequality which was recently proven to be true for various neural networks for any depth within a neighborhood of the initialisation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08624v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matteo Tucat, Anirbit Mukherjee</dc:creator>
    </item>
    <item>
      <title>A Dynamic Principal Agent Problem with One-sided Commitment</title>
      <link>https://arxiv.org/abs/2208.06473</link>
      <description>arXiv:2208.06473v3 Announce Type: replace 
Abstract: In this paper we consider a principal agent problem where the agent is allowed to quit, by incurring a cost. When the current agent quits the job, the principal will hire a new one, possibly with a different type. We characterize the principal's dynamic value function, which could be discontinuous at the boundary, as the (unique) minimal solution of an infinite dimensional system of HJB equations, parametrized by the agent's type. This dynamic problem is time consistent in certain sense.
  Some interesting findings are worth mentioning. First, self-enforcing contracts are typically suboptimal. The principal would rather let the agent quit and hire a new one. Next, the standard contract for a committed agent may also be suboptimal, due to the presence of different types of agents in our model. The principal may prefer no commitment from the agent, then she can hire a cheaper one from the market at a later time by designing the contract to induce the current agent to quit. Moreover, due to the cost incurring to the agent, the principal will see only finitely many quittings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.06473v3</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianfeng Zhang, Zimu Zhu</dc:creator>
    </item>
    <item>
      <title>A novel dual-decomposition method for non-convex mixed integer quadratically constrained quadratic problems</title>
      <link>https://arxiv.org/abs/2302.09872</link>
      <description>arXiv:2302.09872v4 Announce Type: replace 
Abstract: We propose the novel p-branch-and-bound method for solving two-stage stochastic programming problems whose deterministic equivalents are represented by non-convex mixed-integer quadratically constrained quadratic programming (MIQCQP) models. The precision of the solution generated by the p-branch-and-bound method can be arbitrarily adjusted by altering the value of the precision factor p. The proposed method combines two key techniques. The first one, named p-Lagrangian decomposition, generates a mixed-integer relaxation of a dual problem with a separable structure for a primal non-convex MIQCQP problem. The second one is a version of the classical dual decomposition approach that is applied to solve the Lagrangian dual problem and ensures that integrality and non-anticipativity conditions are met once the optimal solution is obtained. This paper also presents a comparative analysis of the p-branch-and-bound method efficiency considering two alternative solution methods for the dual problems as a subroutine. These are the proximal bundle method and Frank-Wolfe progressive hedging. The latter algorithm relies on the interpolation of linearisation steps similar to those taken in the Frank-Wolfe method as an inner loop in the classic progressive hedging. The p-branch-and-bound method's efficiency was tested on randomly generated instances and demonstrated superior performance over commercial solver Gurobi.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.09872v4</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nikita Belyak, Fabricio Oliveira</dc:creator>
    </item>
    <item>
      <title>Null controllability for stochastic coupled systems of fourth order parabolic equations</title>
      <link>https://arxiv.org/abs/2311.18556</link>
      <description>arXiv:2311.18556v2 Announce Type: replace 
Abstract: This paper aims to establish null controllability for systems coupled by two backward fourth order stochastic parabolic equations. The main goal is to control both equations with only one control act on the drift term. To achieve this, we develop a new global Carleman estimate for fourth order stochastic parabolic equations, which allows us to deduce a suitable observability inequality for the adjoint systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.18556v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yu Wang</dc:creator>
    </item>
    <item>
      <title>Accelerated Objective Gap and Gradient Norm Convergence for Gradient Descent via Long Steps</title>
      <link>https://arxiv.org/abs/2403.14045</link>
      <description>arXiv:2403.14045v4 Announce Type: replace 
Abstract: This work considers gradient descent for L-smooth convex optimization with stepsizes larger than the classic regime where descent can be ensured. The stepsize schedules considered are similar to but differ slightly from the recent silver stepsizes of Altschuler and Parrilo. For one of our stepsize sequences, we prove a $O\left(N^{- 1.2716\dots}\right)$ convergence rate in terms of objective gap decrease and for the other, we show the same rate of decrease for squared-gradient-norm decrease. This first result improves on the recent result of Altschuler and Parrilo by a constant factor, while the second results improve on the exponent of the prior best squared-gradient-norm convergence guarantee of $O\left(N^{-1}\right)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.14045v4</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Benjamin Grimmer, Kevin Shu, Alex L. Wang</dc:creator>
    </item>
    <item>
      <title>Minimal hyperbolic polynomials and ranks of homogeneous cones</title>
      <link>https://arxiv.org/abs/2404.03860</link>
      <description>arXiv:2404.03860v2 Announce Type: replace 
Abstract: The starting point of this paper is the computation of minimal hyperbolic polynomials of duals of cones arising from chordal sparsity patterns. From that, we investigate the relation between ranks of homogeneous cones and their minimal polynomials. Along the way, we answer in the negative a question posed in an earlier paper and show examples of homogeneous cones that cannot be realized as rank-one generated (ROG) hyperbolicity cones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03860v2</guid>
      <category>math.OC</category>
      <category>math.AG</category>
      <category>math.MG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jo\~ao Gouveia, Masaru Ito, Bruno F. Louren\c{c}o</dc:creator>
    </item>
    <item>
      <title>Hardness of circuit and monotone diameters of polytopes</title>
      <link>https://arxiv.org/abs/2404.04158</link>
      <description>arXiv:2404.04158v2 Announce Type: replace 
Abstract: The Circuit diameter of polytopes was introduced by Borgwardt, Finhold and Hemmecke as a fundamental tool for the study of circuit augmentation schemes for linear programming and for estimating combinatorial diameters. Determining the complexity of computing the circuit diameter of polytopes was posed as an open problem by Sanit\`a as well as by Kafer, and was recently reiterated by Borgwardt, Grewe, Kafer, Lee and Sanit\`a.
  In this paper, we solve this problem by showing that computing the circuit diameter of a polytope given in halfspace-description is strongly NP-hard. To prove this result, we show that computing the combinatorial diameter of the perfect matching polytope of a bipartite graph is NP-hard. This complements a result by Sanit\`a (FOCS 2018) on the NP-hardness of computing the diameter of fractional matching polytopes and implies the new result that computing the diameter of a $\{0,1\}$-polytope is strongly NP-hard, which may be of independent interest. In our second main result, we give a precise graph-theoretic description of the monotone diameter of perfect matching polytopes and use this description to prove that computing the monotone (circuit) diameter of a given input polytope is strongly NP-hard as well.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04158v2</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christian N\"obel, Raphael Steiner</dc:creator>
    </item>
    <item>
      <title>Efficient Graph Laplacian Estimation by Proximal Newton</title>
      <link>https://arxiv.org/abs/2302.06434</link>
      <description>arXiv:2302.06434v3 Announce Type: replace-cross 
Abstract: The Laplacian-constrained Gaussian Markov Random Field (LGMRF) is a common multivariate statistical model for learning a weighted sparse dependency graph from given data. This graph learning problem can be formulated as a maximum likelihood estimation (MLE) of the precision matrix, subject to Laplacian structural constraints, with a sparsity-inducing penalty term. This paper aims to solve this learning problem accurately and efficiently. First, since the commonly used $\ell_1$-norm penalty is inappropriate in this setting and may lead to a complete graph, we employ the nonconvex minimax concave penalty (MCP), which promotes sparse solutions with lower estimation bias. Second, as opposed to existing first-order methods for this problem, we develop a second-order proximal Newton approach to obtain an efficient solver, utilizing several algorithmic features, such as using Conjugate Gradients, preconditioning, and splitting to active/free sets. Numerical experiments demonstrate the advantages of the proposed method in terms of both computational complexity and graph learning accuracy compared to existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.06434v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yakov Medvedovsky, Eran Treister, Tirza Routtenberg</dc:creator>
    </item>
    <item>
      <title>Reinforcement Learning with Non-Cumulative Objective</title>
      <link>https://arxiv.org/abs/2307.04957</link>
      <description>arXiv:2307.04957v2 Announce Type: replace-cross 
Abstract: In reinforcement learning, the objective is almost always defined as a \emph{cumulative} function over the rewards along the process. However, there are many optimal control and reinforcement learning problems in various application fields, especially in communications and networking, where the objectives are not naturally expressed as summations of the rewards. In this paper, we recognize the prevalence of non-cumulative objectives in various problems, and propose a modification to existing algorithms for optimizing such objectives. Specifically, we dive into the fundamental building block for many optimal control and reinforcement learning algorithms: the Bellman optimality equation. To optimize a non-cumulative objective, we replace the original summation operation in the Bellman update rule with a generalized operation corresponding to the objective. Furthermore, we provide sufficient conditions on the form of the generalized operation as well as assumptions on the Markov decision process under which the globally optimal convergence of the generalized Bellman updates can be guaranteed. We demonstrate the idea experimentally with the bottleneck objective, i.e., the objectives determined by the minimum reward along the process, on classical optimal control and reinforcement learning tasks, as well as on two network routing problems on maximizing the flow rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.04957v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TMLCN.2023.3285543</arxiv:DOI>
      <arxiv:journal_reference>IEEE Trans. Mach. Learn. Commun. Netw. 1 (2023) 124-137</arxiv:journal_reference>
      <dc:creator>Wei Cui, Wei Yu</dc:creator>
    </item>
    <item>
      <title>Properties of Discrete Sliced Wasserstein Losses</title>
      <link>https://arxiv.org/abs/2307.10352</link>
      <description>arXiv:2307.10352v4 Announce Type: replace-cross 
Abstract: The Sliced Wasserstein (SW) distance has become a popular alternative to the Wasserstein distance for comparing probability measures. Widespread applications include image processing, domain adaptation and generative modelling, where it is common to optimise some parameters in order to minimise SW, which serves as a loss function between discrete probability measures (since measures admitting densities are numerically unattainable). All these optimisation problems bear the same sub-problem, which is minimising the Sliced Wasserstein energy. In this paper we study the properties of $\mathcal{E}: Y \longmapsto \mathrm{SW}_2^2(\gamma_Y, \gamma_Z)$, i.e. the SW distance between two uniform discrete measures with the same amount of points as a function of the support $Y \in \mathbb{R}^{n \times d}$ of one of the measures. We investigate the regularity and optimisation properties of this energy, as well as its Monte-Carlo approximation $\mathcal{E}_p$ (estimating the expectation in SW using only $p$ samples) and show convergence results on the critical points of $\mathcal{E}_p$ to those of $\mathcal{E}$, as well as an almost-sure uniform convergence and a uniform Central Limit result on the process $\mathcal{E}_p(Y)$. Finally, we show that in a certain sense, Stochastic Gradient Descent methods minimising $\mathcal{E}$ and $\mathcal{E}_p$ converge towards (Clarke) critical points of these energies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.10352v4</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eloi Tanguy, R\'emi Flamary, Julie Delon</dc:creator>
    </item>
    <item>
      <title>Production optimization by agents of differing work rates</title>
      <link>https://arxiv.org/abs/2310.09208</link>
      <description>arXiv:2310.09208v4 Announce Type: replace-cross 
Abstract: We devise a scheme for producing, in the least possible time, $n$ identical objects with $p$ agents that work at differing speeds. This involves halting the process in order to transfer production across agent types. For the case of two types of agent, we construct a scheme based on the Euclidean algorithm that seeks to minimise the number of pauses in production.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.09208v4</guid>
      <category>math.CO</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Peter M. Higgins</dc:creator>
    </item>
  </channel>
</rss>
