<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 31 Oct 2024 04:00:15 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 31 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Neuromorphic Programming: Emerging Directions for Brain-Inspired Hardware</title>
      <link>https://arxiv.org/abs/2410.22352</link>
      <description>arXiv:2410.22352v1 Announce Type: cross 
Abstract: The value of brain-inspired neuromorphic computers critically depends on our ability to program them for relevant tasks. Currently, neuromorphic hardware often relies on machine learning methods adapted from deep learning. However, neuromorphic computers have potential far beyond deep learning if we can only harness their energy efficiency and full computational power. Neuromorphic programming will necessarily be different from conventional programming, requiring a paradigm shift in how we think about programming. This paper presents a conceptual analysis of programming within the context of neuromorphic computing, challenging conventional paradigms and proposing a framework that aligns more closely with the physical intricacies of these systems. Our analysis revolves around five characteristics that are fundamental to neuromorphic programming and provides a basis for comparison to contemporary programming methods and languages. By studying past approaches, we contribute a framework that advocates for underutilized techniques and calls for richer abstractions to effectively instrument the new hardware class.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.22352v1</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <category>cs.PL</category>
      <pubDate>Thu, 31 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Steven Abreu, Jens E. Pedersen</dc:creator>
    </item>
    <item>
      <title>Universality of the $\pi^2/6$ Pathway in Avoiding Model Collapse</title>
      <link>https://arxiv.org/abs/2410.22812</link>
      <description>arXiv:2410.22812v1 Announce Type: cross 
Abstract: Researchers in empirical machine learning recently spotlighted their fears of so-called Model Collapse. They imagined a discard workflow, where an initial generative model is trained with real data, after which the real data are discarded, and subsequently, the model generates synthetic data on which a new model is trained. They came to the conclusion that models degenerate as model-fitting generations proceed. However, other researchers considered an augment workflow, where the original real data continue to be used in each generation of training, augmented by synthetic data from models fit in all earlier generations. Empirical results on canonical datasets and learning procedures confirmed the occurrence of model collapse under the discard workflow and avoidance of model collapse under the augment workflow. Under the augment workflow, theoretical evidence also confirmed avoidance in particular instances; specifically, Gerstgrasser et al. (2024) found that for classical Linear Regression, test risk at any later generation is bounded by a moderate multiple, viz. pi-squared-over-6 of the test risk of training with the original real data alone. Some commentators questioned the generality of theoretical conclusions based on the generative model assumed in Gerstgrasser et al. (2024): could similar conclusions be reached for other task/model pairings? In this work, we demonstrate the universality of the pi-squared-over-6 augment risk bound across a large family of canonical statistical models, offering key insights into exactly why collapse happens under the discard workflow and is avoided under the augment workflow. In the process, we provide a framework that is able to accommodate a large variety of workflows (beyond discard and augment), thereby enabling an experimenter to judge the comparative merits of multiple different workflows by simulating a simple Gaussian process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.22812v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Thu, 31 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Apratim Dey, David Donoho</dc:creator>
    </item>
    <item>
      <title>KALAM: toolKit for Automating high-Level synthesis of Analog computing systeMs</title>
      <link>https://arxiv.org/abs/2410.22946</link>
      <description>arXiv:2410.22946v1 Announce Type: cross 
Abstract: Diverse computing paradigms have emerged to meet the growing needs for intelligent energy-efficient systems. The Margin Propagation (MP) framework, being one such initiative in the analog computing domain, stands out due to its scalability across biasing conditions, temperatures, and diminishing process technology nodes. However, the lack of digital-like automation tools for designing analog systems (including that of MP analog) hinders their adoption for designing large systems. The inherent scalability and modularity of MP systems present a unique opportunity in this regard. This paper introduces KALAM (toolKit for Automating high-Level synthesis of Analog computing systeMs), which leverages factor graphs as the foundational paradigm for synthesizing MP-based analog computing systems. Factor graphs are the basis of various signal processing tasks and, when coupled with MP, can be used to design scalable and energy-efficient analog signal processors. Using Python scripting language, the KALAM automation flow translates an input factor graph to its equivalent SPICE-compatible circuit netlist that can be used to validate the intended functionality. KALAM also allows the integration of design optimization strategies such as precision tuning, variable elimination, and mathematical simplification. We demonstrate KALAM's versatility for tasks such as Bayesian inference, Low-Density Parity Check (LDPC) decoding, and Artificial Neural Networks (ANN). Simulation results of the netlists align closely with software implementations, affirming the efficacy of our proposed automation tool.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.22946v1</guid>
      <category>eess.SY</category>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <pubDate>Thu, 31 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ankita Nandi, Krishil Gandhi, Mahendra Pratap Singh, Shantanu Chakrabartty, Chetan Singh Thakur</dc:creator>
    </item>
    <item>
      <title>Resilient-By-Design: A Resiliency Framework for Future Wireless Networks</title>
      <link>https://arxiv.org/abs/2410.23203</link>
      <description>arXiv:2410.23203v1 Announce Type: cross 
Abstract: Our future society will be increasingly digitalised, hyper-connected and globally data driven. The sixth generation (6G) and beyond 6G wireless networks are expected to bridge the digital and physical worlds by providing wireless connectivity as a service to different vertical sectors, including industries, smart cities, eHealth and autonomous transportation. Such far reaching integration will render the society increasingly reliant on wireless networks. While this has the potential to greatly enhance our quality and ease of life, any disruption to these networks would also have significant impact with overreaching consequences. Disruptions can happen due to a variety of reasons, including planned outages, failures due to the nature of wireless propagation, natural disasters, and deliberate cybersecurity attacks. Hence, 6G and beyond 6G networks should not only provide near instant and virtually unlimited connectivity, but also be resilient against internal and external disruptions. This paper proposes a resilient-by-design framework towards this end. First, we provide an overview of the disruption landscape. Thereafter, we comprehensively outline the main features of the proposed concept. Finally, we detail the four key steps of the framework, namely predict, preempt, protect and progress. A simple but illustrative preliminary simulation result is also presented to highlight the potential advantages and efficiency of the proposed approach in addressing outages.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23203v1</guid>
      <category>cs.NI</category>
      <category>cs.ET</category>
      <pubDate>Thu, 31 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nurul Huda Mahmood, Sumudu Samarakoon, Pawani Porambage, Mehdi Bennis, Matti Latva-aho</dc:creator>
    </item>
    <item>
      <title>Late Breaking Results: Fast System Technology Co-Optimization Framework for Emerging Technology Based on Graph Neural Networks</title>
      <link>https://arxiv.org/abs/2404.06939</link>
      <description>arXiv:2404.06939v4 Announce Type: replace 
Abstract: This paper proposes a fast system technology co-optimization (STCO) framework that optimizes power, performance, and area (PPA) for next-generation IC design, addressing the challenges and opportunities presented by novel materials and device architectures. We focus on accelerating the technology level of STCO using AI techniques, by employing graph neural network (GNN)-based approaches for both TCAD simulation and cell library characterization, which are interconnected through a unified compact model, collectively achieving over a 100X speedup over traditional methods. These advancements enable comprehensive STCO iterations with runtime speedups ranging from 1.9X to 14.1X and supports both emerging and traditional technologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06939v4</guid>
      <category>cs.ET</category>
      <category>cs.AI</category>
      <pubDate>Thu, 31 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianliang Ma, Guangxi Fan, Xuguang Sun, Zhihui Deng, Kainlu Low, Leilai Shao</dc:creator>
    </item>
    <item>
      <title>Noise-augmented Chaotic Ising Machines for Combinatorial Optimization and Sampling</title>
      <link>https://arxiv.org/abs/2408.04744</link>
      <description>arXiv:2408.04744v2 Announce Type: replace-cross 
Abstract: Ising machines, hardware accelerators for combinatorial optimization and probabilistic sampling problems, have gained significant interest recently. A key element is stochasticity, which enables a wide exploration of configurations, thereby helping avoid local minima. Here, we refine the previously proposed concept of coupled chaotic bits (c-bits) that operate without explicit stochasticity. We show that augmenting chaotic bits with stochasticity enhances performance in combinatorial optimization, achieving algorithmic scaling comparable to probabilistic bits (p-bits). We first demonstrate that c-bits follow the quantum Boltzmann law in a 1D transverse field Ising model. We then show that c-bits exhibit critical dynamics similar to stochastic p-bits in 2D Ising and 3D spin glass models, with promising potential to solve challenging optimization problems. Finally, we propose a noise-augmented version of coupled c-bits via the adaptive parallel tempering algorithm (APT). Our noise-augmented c-bit algorithm outperforms fully deterministic c-bits running versions of the simulated annealing algorithm. Other analog Ising machines with coupled oscillators could draw inspiration from the proposed algorithm. Running replicas at constant temperature eliminates the need for global modulation of coupling strengths. Mixing stochasticity with deterministic c-bits creates a powerful hybrid computing scheme that can bring benefits in scaled, asynchronous, and massively parallel hardware implementations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04744v2</guid>
      <category>cond-mat.dis-nn</category>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <pubDate>Thu, 31 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kyle Lee, Shuvro Chowdhury, Kerem Y. Camsari</dc:creator>
    </item>
    <item>
      <title>DFabric: Scaling Out Data Parallel Applications with CXL-Ethernet Hybrid Interconnects</title>
      <link>https://arxiv.org/abs/2409.05404</link>
      <description>arXiv:2409.05404v2 Announce Type: replace-cross 
Abstract: Emerging interconnects, such as CXL and NVLink, have been integrated into the intra-host topology to scale more accelerators and facilitate efficient communication between them, such as GPUs. To keep pace with the accelerator's growing computing throughput, the interconnect has seen substantial enhancement in link bandwidth, e.g., 256GBps for CXL 3.0 links, which surpasses Ethernet and InfiniBand network links by an order of magnitude or more. Consequently, when data-intensive jobs, such as LLM training, scale across multiple hosts beyond the reach limit of the interconnect, the performance is significantly hindered by the limiting bandwidth of the network infrastructure. We address the problem by proposing DFabric, a two-tier interconnect architecture. We address the problem by proposing DFabric, a two-tier interconnect architecture. First, DFabric disaggregates rack's computing units with an interconnect fabric, i.e., CXL fabric, which scales at rack-level, so that they can enjoy intra-rack efficient interconnecting. Second, DFabric disaggregates NICs from hosts, and consolidates them to form a NIC pool with CXL fabric. By providing sufficient aggregated capacity comparable to interconnect bandwidth, the NIC pool bridges efficient communication across racks or beyond the reach limit of interconnect fabric. However, the local memory accessing becomes the bottleneck when enabling each host to utilize the NIC pool efficiently. To the end, DFabric builds a memory pool with sufficient bandwidth by disaggregating host local memory and adding more memory devices. We have implemented a prototype of DFabric that can run applications transparently. We validated its performance gain by running various microbenchmarks and compute-intensive applications such as DNN and graph.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.05404v2</guid>
      <category>cs.DC</category>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <pubDate>Thu, 31 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xu Zhang, Ke Liu, Yisong Chang, Ke Zhang, Mingyu Chen</dc:creator>
    </item>
  </channel>
</rss>
