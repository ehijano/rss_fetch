<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.AR updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.AR</link>
    <description>cs.AR updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.AR" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 14 May 2025 01:37:40 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>FlexNeRFer: A Multi-Dataflow, Adaptive Sparsity-Aware Accelerator for On-Device NeRF Rendering</title>
      <link>https://arxiv.org/abs/2505.06504</link>
      <description>arXiv:2505.06504v1 Announce Type: new 
Abstract: Neural Radiance Fields (NeRF), an AI-driven approach for 3D view reconstruction, has demonstrated impressive performance, sparking active research across fields. As a result, a range of advanced NeRF models has emerged, leading on-device applications to increasingly adopt NeRF for highly realistic scene reconstructions. With the advent of diverse NeRF models, NeRF-based applications leverage a variety of NeRF frameworks, creating the need for hardware capable of efficiently supporting these models. However, GPUs fail to meet the performance, power, and area (PPA) cost demanded by these on-device applications, or are specialized for specific NeRF algorithms, resulting in lower efficiency when applied to other NeRF models. To address this limitation, in this work, we introduce FlexNeRFer, an energy-efficient versatile NeRF accelerator. The key components enabling the enhancement of FlexNeRFer include: i) a flexible network-on-chip (NoC) supporting multi-dataflow and sparsity on precision-scalable MAC array, and ii) efficient data storage using an optimal sparsity format based on the sparsity ratio and precision modes. To evaluate the effectiveness of FlexNeRFer, we performed a layout implementation using 28nm CMOS technology. Our evaluation shows that FlexNeRFer achieves 8.2~243.3x speedup and 24.1~520.3x improvement in energy efficiency over a GPU (i.e., NVIDIA RTX 2080 Ti), while demonstrating 4.2~86.9x speedup and 2.3~47.5x improvement in energy efficiency compared to a state-of-the-art NeRF accelerator (i.e., NeuRex).</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06504v1</guid>
      <category>cs.AR</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Seock-Hwan Noh (DGIST), Banseok Shin (DGIST), Jeik Choi (DGIST), Seungpyo Lee (DGIST), Jaeha Kung (DGIST), Yeseong Kim (DGIST)</dc:creator>
    </item>
    <item>
      <title>CaMDN: Enhancing Cache Efficiency for Multi-tenant DNNs on Integrated NPUs</title>
      <link>https://arxiv.org/abs/2505.06625</link>
      <description>arXiv:2505.06625v1 Announce Type: new 
Abstract: With the rapid development of DNN applications, multi-tenant execution, where multiple DNNs are co-located on a single SoC, is becoming a prevailing trend. Although many methods are proposed in prior works to improve multi-tenant performance, the impact of shared cache is not well studied. This paper proposes CaMDN, an architecture-scheduling co-design to enhance cache efficiency for multi-tenant DNNs on integrated NPUs. Specifically, a lightweight architecture is proposed to support model-exclusive, NPU-controlled regions inside shared cache to eliminate unexpected cache contention. Moreover, a cache scheduling method is proposed to improve shared cache utilization. In particular, it includes a cache-aware mapping method for adaptability to the varying available cache capacity and a dynamic allocation algorithm to adjust the usage among co-located DNNs at runtime. Compared to prior works, CaMDN reduces the memory access by 33.4% on average and achieves a model speedup of up to 2.56$\times$ (1.88$\times$ on average).</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06625v1</guid>
      <category>cs.AR</category>
      <category>cs.AI</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianhao Cai, Liang Wang, Limin Xiao, Meng Han, Zeyu Wang, Lin Sun, Xiaojian Liao</dc:creator>
    </item>
    <item>
      <title>Extend IVerilog to Support Batch RTL Fault Simulation</title>
      <link>https://arxiv.org/abs/2505.06687</link>
      <description>arXiv:2505.06687v1 Announce Type: new 
Abstract: The advancement of functional safety has made RTL-level fault simulation increasingly important to achieve iterative efficiency in the early stages of design and to ensure compliance with functional safety standards. In this paper, we extend IVerilog to support batch RTL fault simulation and integrate the event-driven algorithm and the concurrent fault simulation algorithm. Comparative experiments with a state-of-the-art commercial simulator and an open-source RTL fault simulator demonstrate that our simulator achieves a performance improvement of 2.2$\times$ and 3.4$\times$, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06687v1</guid>
      <category>cs.AR</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiaping Tang, Jianan Mu, Zizhen Liu, Zhiteng Chao, Jing Ye, Huawei Li</dc:creator>
    </item>
    <item>
      <title>Modeling PFAS in Semiconductor Manufacturing to Quantify Trade-offs in Energy Efficiency and Environmental Impact of Computing Systems</title>
      <link>https://arxiv.org/abs/2505.06727</link>
      <description>arXiv:2505.06727v1 Announce Type: new 
Abstract: The electronics and semiconductor industry is a prominent consumer of per- and poly-fluoroalkyl substances (PFAS), also known as forever chemicals. PFAS are persistent in the environment and can bioaccumulate to ecological and human toxic levels. Computer designers have an opportunity to reduce the use of PFAS in semiconductors and electronics manufacturing, including integrated circuits (IC), batteries, displays, etc., which currently account for a staggering 10% of the total PFAS fluoropolymers usage in Europe alone. In this paper, we present a framework where we (1) quantify the environmental impact of PFAS in computing systems manufacturing with granular consideration of the metal layer stack and patterning complexities in IC manufacturing at the design phase, (2) identify contending trends between embodied carbon (carbon footprint due to hardware manufacturing) versus PFAS. For example, manufacturing an IC at a 7 nm technology node using EUV lithography uses 18% less PFAS-containing layers, compared to manufacturing the same IC at a 7 nm technology node using DUV immersion lithography (instead of EUV) unlike embodied carbon trends, and (3) conduct case studies to illustrate how to optimize and trade-off designs with lower PFAS, while meeting power-performance-area constraints. We show that optimizing designs to use less back-end-of-line (BEOL) metal stack layers can save 1.7$\times$ PFAS-containing layers in systolic arrays.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06727v1</guid>
      <category>cs.AR</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mariam Elgamal, Abdulrahman Mahmoud, Gu-Yeon Wei, David Brooks, Gage Hills</dc:creator>
    </item>
    <item>
      <title>Regular mixed-radix DFT matrix factorization for in-place FFT accelerators</title>
      <link>https://arxiv.org/abs/2505.06728</link>
      <description>arXiv:2505.06728v1 Announce Type: new 
Abstract: The generic vector memory based accelerator is considered which supports DIT and DIF FFT with fixed datapath. The regular mixed-radix factorization of the DFT matrix coherent with the accelerator architecture is proposed and the correction proof is presented. It allows better understanding of architecture requirements and simplifies the developing and proving correctness of more complicated algorithms and conflict-free addressing schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06728v1</guid>
      <category>cs.AR</category>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sergey Salishev</dc:creator>
    </item>
    <item>
      <title>Image processing Application Development on Software Configurable Processor Array</title>
      <link>https://arxiv.org/abs/2505.06847</link>
      <description>arXiv:2505.06847v1 Announce Type: new 
Abstract: The software configurable processor finds best use in the embedded systems. These processors have onchip logic like FPGA (Field Programmable Gate Array) and thus can be configured to implement custom hardware functionality. The digital computing tasks that need to accelerate in hardware can be compiled down to a configuration file or bit stream that contains the information on how the logic components are configured and wired together. Video and image processing applications perform repeated pixel transformation and thus consume more power and the processing time. Software configurable processor best accelerates such compute intensive applications. This paper mainly focuses on the implementation of an image processing application called median filtering on a single processor and colour conversion algorithm on array of SCPs(Software Configurable Processors). Median filtering result on Digital Video Recorder (DVR) is discussed as a realtime application of SCP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06847v1</guid>
      <category>cs.AR</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ganesh Prabhu, Steevan Rodrigues, Niranjan Chiplunkar, Niranjan U. C</dc:creator>
    </item>
    <item>
      <title>Fast and low energy approximate full adder based on FELIX logic</title>
      <link>https://arxiv.org/abs/2505.06888</link>
      <description>arXiv:2505.06888v1 Announce Type: new 
Abstract: In the "Big Data" era, a lot of data must be processed and moved between processing and memory units. New technologies and architectures have emerged to improve system performance and overcome the memory bottleneck. The memristor is a technology with both computing and memory capabilities. In-Memory Computing (IMC) can be performed by applying memristors to stateful design methods. The Fast and Energy-Efficient Logic in Memory (FELIX) logic is one of the stateful implementation logics compatible with memristive crossbar arrays. The way computations are performed can be changed to improve performance. Approximate design methods can be applied in error-resilient applications. In error-resilient applications, an acceptable amount of precision is lost while features such as hardware complexity, latency, and energy are improved. In this paper, using these two concepts, an approximate full adder circuit with exact Cout and approximate Sum outputs has been proposed using the FELIX design method for IMC in two different implementation approaches. The applied memristor count in the proposed FELIX-based Approximate Full Adder (FAFA) in the two proposed implementation approaches (FAFA1 and FAFA2) is improved by 14.28% and 28.57%, energy consumption is improved by 73.735% and 81.754%, respectively. The number of computational steps in both approaches is improved by 66.66% compared to the exact FELIX-based full adder. In this paper, two different scenarios are considered for evaluating the FAFA. In the 1st and 2nd scenarios, respectively, for the three and four Most Significant Bits (MSBs), the exact full adder is used, and for the five and four Least Significant Bits (LSBs), the FAFA is used. The results of error analysis and evaluations of the FAFA in three different image processing applications confirmed that FAFA has high accuracy and acceptable performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06888v1</guid>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Seyed Erfan Fatemieh, Samane Asgari, Mohammad Reza Reshadinezhad</dc:creator>
    </item>
    <item>
      <title>Ecco: Improving Memory Bandwidth and Capacity for LLMs via Entropy-aware Cache Compression</title>
      <link>https://arxiv.org/abs/2505.06901</link>
      <description>arXiv:2505.06901v1 Announce Type: new 
Abstract: Large language models (LLMs) have demonstrated transformative capabilities across diverse artificial intelligence applications, yet their deployment is hindered by substantial memory and computational demands, especially in resource-constrained environments. Quantization techniques have emerged as a critical solution, reducing data precision to enhance memory and computational efficiency. However, existing methods often suffer from high runtime overheads and potential accuracy degradation. To address these challenges, we propose Ecco, an entropy-based cache compression technique tailored for LLMs. Ecco combines group-wise and non-uniform quantization with pre-defined shared k-means patterns and Huffman coding to exploit the inherent entropy characteristics of LLM cache data. Recognizing the inefficiencies of traditional Huffman coding in terms of parallelism and latency, we introduce a novel parallel Huffman-based decoding process with a multi-stage pipeline design, reducing latency by two orders of magnitude and achieving throughput comparable to GPU L2 caches. Comprehensive evaluations demonstrate that Ecco achieves an up to 2.9$\times$ and 1.9$\times$ speedup over the state-of-the-art AWQ and SmoothQuant framework, 2.4$\times$ over the Olive accelerator, all while increasing memory capacity by nearly 4$\times$ and maintaining state-of-the-art LLM accuracy. These results underscore the effectiveness of our entropy-based cache compression in enhancing LLM performance and efficiency, paving the way for more deployable large-scale AI models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06901v1</guid>
      <category>cs.AR</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Feng Cheng, Cong Guo, Chiyue Wei, Junyao Zhang, Changchun Zhou, Edward Hanson, Jiaqi Zhang, Xiaoxiao Liu, Hai "Helen" Li, Yiran Chen</dc:creator>
    </item>
    <item>
      <title>Efficient Implementation of RISC-V Vector Permutation Instructions</title>
      <link>https://arxiv.org/abs/2505.07112</link>
      <description>arXiv:2505.07112v1 Announce Type: new 
Abstract: RISC-V CPUs leverage the RVV (RISC-V Vector) extension to accelerate data-parallel workloads. In addition to arithmetic operations, RVV includes powerful permutation instructions that enable flexible element rearrangement within vector registers --critical for optimizing performance in tasks such as matrix operations and cryptographic computations. However, the diverse control mechanisms of these instructions complicate their execution within a unified datapath while maintaining the fixed-latency requirement of cryptographic accelerators. To address this, we propose a unified microarchitecture capable of executing all RVV permutation instructions efficiently, regardless of their control information structure. This approach minimizes area and hardware costs while ensuring single-cycle execution for short vector machines (up to 256 bits) and enabling efficient pipelining for longer vectors. The proposed design is integrated into an open-source RISC-V vector processor and implemented at 7 nm using the OpenRoad physical synthesis flow. Experimental results validate the efficiency of our unified vector permutation unit, demonstrating that it only incurs 1.5% area overhead to the total vector processor. Furthermore, this area overhead decreases to near-0% as the minimum supported element width for vector permutations increases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07112v1</guid>
      <category>cs.AR</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vasileios Titopoulos, George Alexakis, Chrysostomos Nicopoulos, Giorgos Dimitrakopoulos</dc:creator>
    </item>
    <item>
      <title>A Comprehensive Data Description for LoRaWAN Path Loss Measurements in an Indoor Office Setting: Effects of Environmental Factors</title>
      <link>https://arxiv.org/abs/2505.06375</link>
      <description>arXiv:2505.06375v1 Announce Type: cross 
Abstract: This paper presents a comprehensive dataset of LoRaWAN technology path loss measurements collected in an indoor office environment, focusing on quantifying the effects of environmental factors on signal propagation. Utilizing a network of six strategically placed LoRaWAN end devices (EDs) and a single indoor gateway (GW) at the University of Siegen, City of Siegen, Germany, we systematically measured signal strength indicators such as the Received Signal Strength Indicator (RSSI) and the Signal-to-Noise Ratio (SNR) under various environmental conditions, including temperature, relative humidity, carbon dioxide (CO$_2$) concentration, barometric pressure, and particulate matter levels (PM$_{2.5}$). Our empirical analysis confirms that transient phenomena such as reflections, scattering, interference, occupancy patterns (induced by environmental parameter variations), and furniture rearrangements can alter signal attenuation by as much as 10.58 dB, highlighting the dynamic nature of indoor propagation. As an example of how this dataset can be utilized, we tested and evaluated a refined Log-Distance Path Loss and Shadowing Model that integrates both structural obstructions (Multiple Walls) and Environmental Parameters (LDPLSM-MW-EP). Compared to a baseline model that considers only Multiple Walls (LDPLSM-MW), the enhanced approach reduced the root mean square error (RMSE) from 10.58 dB to 8.04 dB and increased the coefficient of determination (R$^2$) from 0.6917 to 0.8222. By capturing the extra effects of environmental conditions and occupancy dynamics, this improved model provides valuable insights for optimizing power usage and prolonging device battery life, enhancing network reliability in indoor Internet of Things (IoT) deployments, among other applications. This dataset offers a solid foundation for future research and development in indoor wireless communication.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06375v1</guid>
      <category>cs.NI</category>
      <category>cs.AR</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nahshon Mokua Obiri, Kristof Van Laerhoven</dc:creator>
    </item>
    <item>
      <title>"vcd2df" -- Leveraging Data Science Insights for Hardware Security Research</title>
      <link>https://arxiv.org/abs/2505.06470</link>
      <description>arXiv:2505.06470v1 Announce Type: cross 
Abstract: In this work, we hope to expand the universe of security practitioners of open-source hardware by creating a bridge from hardware design languages (HDLs) to data science languages like Python and R through libraries that converge VCD (value change dump) files into data frames, the expected input type of the modern data science tools. We show how insights can be derived in high-level languages from register transfer level (RTL) trace data. Additional, we show a promising future direction in hardware security research leveraging the parallelism of the Spark DataFrame.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06470v1</guid>
      <category>cs.CR</category>
      <category>cs.AR</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Calvin Deutschbein, Jimmy Ostler</dc:creator>
    </item>
    <item>
      <title>Energy-Efficient Ternary Encoding for High-Speed Data Transmission in 3D-Integrated Circuits Using Inductive Coupling Links</title>
      <link>https://arxiv.org/abs/2505.06908</link>
      <description>arXiv:2505.06908v1 Announce Type: cross 
Abstract: This paper proposes a ternary signalling scheme for inductive coupling links (ICLs) in 3D-integrated circuits (3D-ICs) to reduce crosstalk and electromagnetic interference in multi-stacked chip communications. By converting binary data into ternary sequences with three voltage levels (-V, 0V, +V), the approach enhances signal separation, reduces crosstalk, and improves signal integrity. Unlike traditional Non-Return to Zero (NRZ) systems, the ternary scheme increases bandwidth efficiency and reduces power consumption through fewer signal transitions. A modified H-Bridge transmitter generates ternary symbols by controlling current flow based on binary-to-ternary mapping. Preliminary simulations validate the efficiency of the scheme, showing reduced power consumption and higher data rates compared to NRZ. This approach shows promise for high-performance computing and IoT devices in 3D-IC environments, offering enhanced noise resilience, lower power usage, and improved communication efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06908v1</guid>
      <category>cs.CE</category>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abdullah Saeed Alghotmi</dc:creator>
    </item>
    <item>
      <title>LUT Tensor Core: A Software-Hardware Co-Design for LUT-Based Low-Bit LLM Inference</title>
      <link>https://arxiv.org/abs/2408.06003</link>
      <description>arXiv:2408.06003v2 Announce Type: replace 
Abstract: As large language model (LLM) inference continues to demand increasing computational resources, there is a rapidly growing trend toward using low-bit weights to reduce memory footprint and improve inference efficiency. However, low-bit LLMs introduce the need for mixed-precision general matrix multiplication (mpGEMM), which involves multiplying low-precision weights with higher-precision activations - a critical yet under-explored operation. Current hardware lacks native support for mpGEMM, leading to inefficient dequantization-based implementations.
  To address this, we explore a lookup table (LUT)-based approach to accelerate mpGEMM. While conventional LUT implementations fall short in performance and flexibility, we propose LUT Tensor Core, a software-hardware co-designed solution optimized for low-bit LLM inference. On the software side, we introduce operator fusion and table symmetrization techniques to optimize LUT generation and storage. On the hardware side, LUT Tensor Core adopts an elongated tiling shape to maximize table reuse and employs a bit-serial architecture to flexibly support a variety of precision combinations. Additionally, we design an end-to-end compilation stack with custom instructions to enable efficient code generation and optimization for LUT-based mpGEMM. Experimental results on low-bit LLMs such as BitNet and LLaMA demonstrate that LUT Tensor Core delivers over an order-of-magnitude improvement in both compute density and energy efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06003v2</guid>
      <category>cs.AR</category>
      <category>cs.LG</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3695053.3731057</arxiv:DOI>
      <dc:creator>Zhiwen Mo, Lei Wang, Jianyu Wei, Zhichen Zeng, Shijie Cao, Lingxiao Ma, Naifeng Jing, Ting Cao, Jilong Xue, Fan Yang, Mao Yang</dc:creator>
    </item>
    <item>
      <title>MFIT: Multi-Fidelity Thermal Modeling for 2.5D and 3D Multi-Chiplet Architectures</title>
      <link>https://arxiv.org/abs/2410.09188</link>
      <description>arXiv:2410.09188v4 Announce Type: replace 
Abstract: Rapidly evolving artificial intelligence and machine learning applications require ever-increasing computational capabilities, while monolithic 2D design technologies approach their limits. Heterogeneous integration of smaller chiplets using a 2.5D silicon interposer and 3D packaging has emerged as a promising paradigm to address this limit and meet performance demands. These approaches offer a significant cost reduction and higher manufacturing yield than monolithic 2D integrated circuits. However, the compact arrangement and high compute density exacerbate the thermal management challenges, potentially compromising performance. Addressing these thermal modeling challenges is critical, especially as system sizes grow and different design stages require varying levels of accuracy and speed. Since no single thermal modeling technique meets all these needs, this paper introduces MFIT, a range of multi-fidelity thermal models that effectively balance accuracy and speed. These multi-fidelity models can enable efficient design space exploration and runtime thermal management. Our extensive testing on systems with 16, 36, and 64 2.5D integrated chiplets and 16x3 3D integrated chiplets demonstrates that these models can reduce execution times from days to mere seconds and milliseconds with negligible loss in accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09188v4</guid>
      <category>cs.AR</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lukas Pfromm, Alish Kanani, Harsh Sharma, Parth Solanki, Eric Tervo, Jaehyun Park, Janardhan Rao Doppa, Partha Pratim Pande, Umit Y. Ogras</dc:creator>
    </item>
    <item>
      <title>Systolic Arrays and Structured Pruning Co-design for Efficient Transformers in Edge Systems</title>
      <link>https://arxiv.org/abs/2411.10285</link>
      <description>arXiv:2411.10285v2 Announce Type: replace 
Abstract: Efficient deployment of resource-intensive transformers on edge devices necessitates cross-stack optimization. We thus study the interrelation between structured pruning and systolic acceleration, matching the size of pruned blocks with the systolic array dimensions. In this setting, computations of pruned weight blocks can be skipped, reducing run-time and energy consumption, but potentially impacting quality of service (QoS). To evaluate the trade-offs between systolic array size and sparsity opportunities, we present a novel co-design framework that integrates algorithmic optimization, system simulation, and hardware design. Targeting speech recognition and machine translation using transformers as case study, we analyze how configuration choices across the stack affect performance metrics. Results demonstrate that structured pruning on systems featuring systolic array acceleration can effectively increase performance, while maintaining high QoS levels. Up to 44% system-wide speedups due to structured pruning and quantization were measured, with only 1.4% word error rate degradation on the standard LibriSpeech dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10285v2</guid>
      <category>cs.AR</category>
      <category>cs.AI</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3716368.3735158</arxiv:DOI>
      <dc:creator>Pedro Palacios, Rafael Medina, Jean-Luc Rouas, Giovanni Ansaloni, David Atienza</dc:creator>
    </item>
    <item>
      <title>ATiM: Autotuning Tensor Programs for Processing-in-DRAM</title>
      <link>https://arxiv.org/abs/2412.19630</link>
      <description>arXiv:2412.19630v2 Announce Type: replace 
Abstract: Processing-in-DRAM (DRAM-PIM) has emerged as a promising technology for accelerating memory-intensive operations in modern applications, such as Large Language Models (LLMs). Despite its potential, current software stacks for DRAM-PIM face significant challenges, including reliance on hand-tuned libraries that hinder programmability, limited support for high-level abstractions, and the lack of systematic optimization frameworks. To address these limitations, we present ATiM, a search-based optimizing tensor compiler for UPMEM. Key features of ATiM include: (1) automated searches of the joint search space for host and kernel tensor programs, (2) PIM-aware optimizations for efficiently handling boundary conditions, and (3) improved search algorithms for the expanded search space of UPMEM systems. Our experimental results on UPMEM hardware demonstrate performance gains of up to 6.18$\times$ for various UPMEM benchmark kernels and 8.21$\times$ for GPT-J layers. To the best of our knowledge, ATiM is the first tensor compiler to provide fully automated, autotuning-integrated code generation support for a DRAM-PIM system. By bridging the gap between high-level tensor computation abstractions and low-level hardware-specific requirements, ATiM establishes a foundation for advancing DRAM-PIM programmability and enabling streamlined optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.19630v2</guid>
      <category>cs.AR</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Yongwon Shin, Dookyung Kang, Hyojin Sung</dc:creator>
    </item>
    <item>
      <title>PHOENIX: Pauli-Based High-Level Optimization Engine for Instruction Execution on NISQ Devices</title>
      <link>https://arxiv.org/abs/2504.03529</link>
      <description>arXiv:2504.03529v3 Announce Type: replace-cross 
Abstract: Variational quantum algorithms (VQA) based on Hamiltonian simulation represent a specialized class of quantum programs well-suited for near-term quantum computing applications due to its modest resource requirements in terms of qubits and circuit depth. Unlike the conventional single-qubit (1Q) and two-qubit (2Q) gate sequence representation, Hamiltonian simulation programs are essentially composed of disciplined subroutines known as Pauli exponentiations (Pauli strings with coefficients) that are variably arranged. To capitalize on these distinct program features, this study introduces PHOENIX, a highly effective compilation framework that primarily operates at the high-level Pauli-based intermediate representation (IR) for generic Hamiltonian simulation programs. PHOENIX exploits global program optimization opportunities to the greatest extent, compared to existing SOTA methods despite some of them also utilizing similar IRs. PHOENIX employs the binary symplectic form (BSF) to formally describe Pauli strings and reformulates IR synthesis as reducing the column weights of BSF by appropriate Clifford transformations. It comes with a heuristic BSF simplification algorithm that searches for the most appropriate 2Q Clifford operators in sequence to maximally simplify the BSF at each step, until the BSF can be directly synthesized by basic 1Q and 2Q gates. PHOENIX further performs a global ordering strategy in a Tetris-like fashion for these simplified IR groups, carefully balancing optimization opportunities for gate cancellation, minimizing circuit depth, and managing qubit routing overhead. Experimental results demonstrate that PHOENIX outperforms SOTA VQA compilers across diverse program categories, backend ISAs, and hardware topologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03529v3</guid>
      <category>quant-ph</category>
      <category>cs.AR</category>
      <category>cs.PL</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaohui Yang, Dawei Ding, Chenghong Zhu, Jianxin Chen, Yuan Xie</dc:creator>
    </item>
    <item>
      <title>ApproXAI: Energy-Efficient Hardware Acceleration of Explainable AI using Approximate Computing</title>
      <link>https://arxiv.org/abs/2504.17929</link>
      <description>arXiv:2504.17929v2 Announce Type: replace-cross 
Abstract: Explainable artificial intelligence (XAI) enhances AI system transparency by framing interpretability as an optimization problem. However, this approach often necessitates numerous iterations of computationally intensive operations, limiting its applicability in real-time scenarios. While recent research has focused on XAI hardware acceleration on FPGAs and TPU, these methods do not fully address energy efficiency in real-time settings. To address this limitation, we propose XAIedge, a novel framework that leverages approximate computing techniques into XAI algorithms, including integrated gradients, model distillation, and Shapley analysis. XAIedge translates these algorithms into approximate matrix computations and exploits the synergy between convolution, Fourier transform, and approximate computing paradigms. This approach enables efficient hardware acceleration on TPU-based edge devices, facilitating faster real-time outcome interpretations. Our comprehensive evaluation demonstrates that XAIedge achieves a $2\times$ improvement in energy efficiency compared to existing accurate XAI hardware acceleration techniques while maintaining comparable accuracy. These results highlight the potential of XAIedge to significantly advance the deployment of explainable AI in energy-constrained real-time applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17929v2</guid>
      <category>cs.AI</category>
      <category>cs.AR</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ayesha Siddique, Khurram Khalil, Khaza Anuarul Hoque</dc:creator>
    </item>
  </channel>
</rss>
