<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 25 Dec 2024 05:00:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Strategy to control biases in prior event rate ratio method, with application to palliative care in patients with advanced cancer</title>
      <link>https://arxiv.org/abs/2412.17879</link>
      <description>arXiv:2412.17879v1 Announce Type: new 
Abstract: Objectives: Prior event rate ratio (PERR) is a method shown to perform well in mitigating confounding in real-world evidence research but it depends on several model assumptions. We propose an analytic strategy to correct biases arising from violation of two model assumptions, namely, population homogeneity and event-independent treatment. Study Design and Setting: We reformulate PERR estimation by embedding a treatment-by-period interaction term in an analytic model for recurrent event data, which is robust to bias arising from unobserved heterogeneity. Based on this model, we propose a set of methods to examine the presence of event-dependent treatment and to correct the resultant bias. We evaluate the proposed methods by simulation and apply it to a de-identified dataset on palliative care and emergency department visits in patients with advanced cancer. Results: Simulation results showed that the proposed method could mitigate the two sources of bias in PERR. In the palliative care study, analysis by the Cox model showed that patients who had started receiving palliative care had higher incidence of emergency department visits than their match controls (hazard ratio 3.31; 95% confidence interval 2.78 to 3.94). Using PERR without the proposed bias control strategy indicated a 19% reduction of the incidence (0.81; 0.64 to 1.02). However, there was evidence of event-dependent treatment. The proposed correction method showed no effect of palliative care on ED visits (1.00; 0.79 to 1.26). Conclusions: The proposed analytic strategy can control two sources of biases in the PERR approach. It enriches the armamentarium for real-world evidence research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17879v1</guid>
      <category>stat.AP</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiangmei Ma, Grace Meijuan Yang, Qingyuan Zhuang, Yin Bun Cheung</dc:creator>
    </item>
    <item>
      <title>Compact Neural Network Algorithm for Electrocardiogram Classification</title>
      <link>https://arxiv.org/abs/2412.17852</link>
      <description>arXiv:2412.17852v1 Announce Type: cross 
Abstract: In this paper, we present a high-performance, compact electrocardiogram (ECG)-based system for automatic classification of arrhythmias, integrating machine learning approaches to achieve robust cardiac diagnostics. Our method combines a compact artificial neural network with feature enhancement techniques, including mathematical transformations, signal analysis and data extraction algorithms, to capture both morphological and time-frequency features from ECG signals. A novel aspect of this work is the addition of 17 newly engineered features, which complement the algorithm's capability to extract significant data and physiological patterns from the ECG signal. This combination enables the classifier to detect multiple arrhythmia types, such as atrial fibrillation, sinus tachycardia, ventricular flutter, and other common arrhythmic disorders. The system achieves an accuracy of 97.36% on the MIT-BIH arrhythmia database, using a lower complexity compared to state-of-the-art models. This compact tool shows potential for clinical deployment, as well as adaptation for portable devices in long-term cardiac health monitoring applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17852v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mateo Frausto-Avila, Jose Pablo Manriquez-Amavizca, Alfred U'Ren, Mario A. Quiroz-Juarez</dc:creator>
    </item>
    <item>
      <title>Methods for differential network estimation: an empirical comparison</title>
      <link>https://arxiv.org/abs/2412.17922</link>
      <description>arXiv:2412.17922v1 Announce Type: cross 
Abstract: We provide a review and a comparison of methods for differential network estimation in Gaussian graphical models with focus on structure learning. We consider the case of two datasets from distributions associated with two graphical models. In our simulations, we use five different methods to estimate differential networks. We vary graph structure and sparsity to explore their influence on performance in terms of power and false discovery rate. We demonstrate empirically that presence of hubs proves to be a challenge for all the methods, as well as increased density. We suggest local and global properties that are associated with this challenge. Direct estimation with lasso penalized D-trace loss is shown to perform the best across all combinations of network structure and sparsity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17922v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anna Plaksienko, Magne Thoresen, Vera Djordjilovi\'c</dc:creator>
    </item>
    <item>
      <title>Network Models of Expertise in the Complex Task of Operating Particle Accelerators</title>
      <link>https://arxiv.org/abs/2412.17988</link>
      <description>arXiv:2412.17988v1 Announce Type: cross 
Abstract: We implement a network-based approach to study expertise in a complex real-world task: operating particle accelerators. Most real-world tasks we learn and perform (e.g., driving cars, operating complex machines, solving mathematical problems) are difficult to learn because they are complex, and the best strategies are difficult to find from many possibilities. However, how we learn such complex tasks remains a partially solved mystery, as we cannot explain how the strategies evolve with practice due to the difficulties of collecting and modeling complex behavioral data. As complex tasks are generally networks of many elementary subtasks, we model task performance as networks or graphs of subtasks and investigate how the networks change with expertise. We develop the networks by processing the text in a large archive of operator logs from 14 years of operations using natural language processing and machine learning. The network changes are examined using a set of measures at four levels of granularity - individual subtasks, interconnections among subtasks, groups of subtasks, and the whole complex task. We find that the operators consistently change with expertise at the subtask, the interconnection, and the whole-task levels, but they show remarkable similarity in how subtasks are grouped. These results indicate that the operators of all stages of expertise adopt a common divide-and-conquer approach by breaking the complex task into parts of manageable complexity, but they differ in the frequency and structure of nested subtasks. Operational logs are common data sources from real-world settings where people collaborate with hardware and software environments to execute complex tasks, and the network models investigated in this study can be expanded to accommodate multi-modal data. Therefore, our network-based approach provides a practical way to investigate expertise in the real world.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17988v1</guid>
      <category>cs.SI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>stat.AP</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roussel Rahman, Jane Shtalenkova, Aashwin Ananda Mishra, Wan-Lin Hu</dc:creator>
    </item>
    <item>
      <title>A Comparative Study of Imputation Methods for Multivariate Ordinal Data</title>
      <link>https://arxiv.org/abs/2010.10471</link>
      <description>arXiv:2010.10471v5 Announce Type: replace-cross 
Abstract: Missing data remains a very common problem in large datasets, including survey and census data containing many ordinal responses, such as political polls and opinion surveys. Multiple imputation (MI) is usually the go-to approach for analyzing such incomplete datasets, and there are indeed several implementations of MI, including methods using generalized linear models, tree-based models, and Bayesian non-parametric models. However, there is limited research on the statistical performance of these methods for multivariate ordinal data. In this article, we perform an empirical evaluation of several MI methods, including MI by chained equations (MICE) using multinomial logistic regression models, MICE using proportional odds logistic regression models, MICE using classification and regression trees, MICE using random forest, MI using Dirichlet process (DP) mixtures of products of multinomial distributions, and MI using DP mixtures of multivariate normal distributions. We evaluate the methods using simulation studies based on ordinal variables selected from the 2018 American Community Survey (ACS). Under our simulation settings, the results suggest that MI using proportional odds logistic regression models, classification and regression trees and DP mixtures of multinomial distributions generally outperform the other methods. In certain settings, MI using multinomial logistic regression models is able to achieve comparable performance, depending on the missing data mechanism and amount of missing data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2010.10471v5</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1093/jssam/smab028</arxiv:DOI>
      <arxiv:journal_reference>Journal of Survey Statistics and Methodology, Volume 11, Issue 1, February 2023, Pages 189-212</arxiv:journal_reference>
      <dc:creator>Chayut Wongkamthong, Olanrewaju Akande</dc:creator>
    </item>
    <item>
      <title>An Empirical Study: Extensive Deep Temporal Point Process</title>
      <link>https://arxiv.org/abs/2110.09823</link>
      <description>arXiv:2110.09823v5 Announce Type: replace-cross 
Abstract: Temporal point process as the stochastic process on continuous domain of time is commonly used to model the asynchronous event sequence featuring with occurrence timestamps. Thanks to the strong expressivity of deep neural networks, they are emerging as a promising choice for capturing the patterns in asynchronous sequences, in the context of temporal point process. In this paper, we first review recent research emphasis and difficulties in modeling asynchronous event sequences with deep temporal point process, which can be concluded into four fields: encoding of history sequence, formulation of conditional intensity function, relational discovery of events and learning approaches for optimization. We introduce most of recently proposed models by dismantling them into the four parts, and conduct experiments by remodularizing the first three parts with the same learning strategy for a fair empirical evaluation. Besides, we extend the history encoders and conditional intensity function family, and propose a Granger causality discovery framework for exploiting the relations among multi-types of events. Because the Granger causality can be represented by the Granger causality graph, discrete graph structure learning in the framework of Variational Inference is employed to reveal latent structures of the graph. Further experiments show that the proposed framework with latent graph discovery can both capture the relations and achieve an improved fitting and predicting performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2110.09823v5</guid>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haitao Lin, Cheng Tan, Lirong Wu, Zhangyang Gao, Zicheng Liu, Stan. Z. Li</dc:creator>
    </item>
    <item>
      <title>Smoothing Variances Across Time: Adaptive Stochastic Volatility</title>
      <link>https://arxiv.org/abs/2408.11315</link>
      <description>arXiv:2408.11315v3 Announce Type: replace-cross 
Abstract: We introduce a novel Bayesian framework for estimating time-varying volatility by extending the Random Walk Stochastic Volatility (RWSV) model with a new Dynamic Shrinkage Process (DSP) in (log) variances. Unlike classical Stochastic Volatility or GARCH-type models with restrictive parametric stationarity assumptions, our proposed Adaptive Stochastic Volatility (ASV) model provides smooth yet dynamically adaptive estimates of evolving volatility and its uncertainty (vol of vol). We derive the theoretical properties of the proposed global-local shrinkage prior. Through simulation studies, we demonstrate that ASV exhibits remarkable misspecification resilience with low prediction error across various data generating scenarios in simulation. Furthermore, ASV's capacity to yield locally smooth and interpretable estimates facilitates a clearer understanding of underlying patterns and trends in volatility. Additionally, we propose and illustrate an extension for Bayesian Trend Filtering simultaneously in both mean and variance. Finally, we show that this attribute makes ASV a robust tool applicable across a wide range of disciplines, including in finance, environmental science, epidemiology, and medicine, among others.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.11315v3</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jason B. Cho, David S. Matteson</dc:creator>
    </item>
  </channel>
</rss>
