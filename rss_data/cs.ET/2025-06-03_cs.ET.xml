<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 03 Jun 2025 04:00:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>iVAMS 3.0: Hierarchical-Machine-Learning-Metamodel-Integrated Intelligent Verilog-AMS for Ultra-Fast, Accurate Mixed-Signal Design Optimization</title>
      <link>https://arxiv.org/abs/2506.01045</link>
      <description>arXiv:2506.01045v1 Announce Type: new 
Abstract: Analog/Mixed-Signal (AMS) circuits and systems continually present significant challenges to designers with the increase of design complexity and aggressive technology scaling. This is due to the large number of design factors and parameters that must be taken into account as well as the process variations which are prominent in nano-CMOS circuits. Design optimization techniques while presenting an accurate and fast design flow which can perform design optimization in reasonable time are still lacking. Even with techniques such as metamodeling that aid the design phase, there is still the need to improve them for accuracy and time cost. As a trade-off of the accuracy and speed, this paper presents a design flow for ultra-fast variability-aware optimization of nano-CMOS based physical design of analog circuits. It combines a Kriging bootstrapped Artificial Neural Network (ANN) metamodel with a Particle Swarm Optimization (PSO) based algorithm in the design optimization flow. The Kriging bootstrapped ANN metamodel provides a trade-off between analog-quality accuracy and scalability and can be effectively used for large and complex AMS circuits. The proposed technique uses Kriging to bootstrap target samples used for the ANN training. This introduces Kriging characteristics, which account for correlation effects between design parameters, to the ANN. The effectiveness of the design flow is demonstrated using a PLL as a case study with as many as 21 design parameters. It is observed that the bootstrapped Kriging metamodeling is 24X faster than simple ANN metamodeling. The layout optimization for such a complex circuit can be performed effectively in a short time using this approach. The optimization flow could achieve significant reductions in the mean and standard deviation of the PLL characteristics. Thus, the proposed research is a major contribution to design for cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01045v1</guid>
      <category>cs.ET</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Saraju P. Mohanty, Elias Kougianos</dc:creator>
    </item>
    <item>
      <title>Rapid yet accurate Tile-circuit and device modeling for Analog In-Memory Computing</title>
      <link>https://arxiv.org/abs/2506.00004</link>
      <description>arXiv:2506.00004v1 Announce Type: cross 
Abstract: Analog In-Memory Compute (AIMC) can improve the energy efficiency of Deep Learning by orders of magnitude. Yet analog-domain device and circuit non-idealities -- within the analog ``Tiles'' performing Matrix-Vector Multiply (MVM) operations -- can degrade neural-network task accuracy. We quantify the impact of low-level distortions and noise, and develop a mathematical model for Multiply-ACcumulate (MAC) operations mapped to analog tiles. Instantaneous-current IR-drop (the most significant circuit non-ideality), and ADC quantization effects are fully captured by this model, which can predict MVM tile-outputs both rapidly and accurately, as compared to much slower rigorous circuit simulations. A statistical model of PCM read noise at nanosecond timescales is derived from -- and matched against -- experimental measurements. We integrate these (statistical) device and (deterministic) circuit effects into a PyTorch-based framework to assess the accuracy impact on the BERT and ALBERT Transformer networks. We show that hardware-aware fine-tuning using simple Gaussian noise provides resilience against ADC quantization and PCM read noise effects, but is less effective against IR-drop. This is because IR-drop -- although deterministic -- is non-linear, is changing significantly during the time-integration window, and is ultimately dependent on all the excitations being introduced in parallel into the analog tile. The apparent inability of simple Gaussian noise applied during training to properly prepare a DNN network for IR-drop during inference implies that more complex training approaches -- incorporating advances such as the Tile-circuit model introduced here -- will be critical for resilient deployment of large neural networks onto AIMC hardware.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00004v1</guid>
      <category>cs.AR</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>J. Luquin, C. Mackin, S. Ambrogio, A. Chen, F. Baldi, G. Miralles, M. J. Rasch, J. B\"uchel, M. Lalwani, W. Ponghiran, P. Solomon, H. Tsai, G. W. Burr, P. Narayanan</dc:creator>
    </item>
    <item>
      <title>Performance Analysis of Convolutional Neural Network By Applying Unconstrained Binary Quadratic Programming</title>
      <link>https://arxiv.org/abs/2506.00247</link>
      <description>arXiv:2506.00247v1 Announce Type: cross 
Abstract: Convolutional Neural Networks (CNNs) are pivotal in computer vision and Big Data analytics but demand significant computational resources when trained on large-scale datasets. Conventional training via back-propagation (BP) with losses like Mean Squared Error or Cross-Entropy often requires extensive iterations and may converge sub-optimally. Quantum computing offers a promising alternative by leveraging superposition, tunneling, and entanglement to search complex optimization landscapes more efficiently. In this work, we propose a hybrid optimization method that combines an Unconstrained Binary Quadratic Programming (UBQP) formulation with Stochastic Gradient Descent (SGD) to accelerate CNN training. Evaluated on the MNIST dataset, our approach achieves a 10--15\% accuracy improvement over a standard BP-CNN baseline while maintaining similar execution times. These results illustrate the potential of hybrid quantum-classical techniques in High-Performance Computing (HPC) environments for Big Data and Deep Learning. Fully realizing these benefits, however, requires a careful alignment of algorithmic structures with underlying quantum mechanisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00247v1</guid>
      <category>cs.LG</category>
      <category>cs.ET</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Aasish Kumar Sharma, Sanjeeb Prashad Pandey, Julian M. Kunkel</dc:creator>
    </item>
    <item>
      <title>GrapheonRL: A Graph Neural Network and Reinforcement Learning Framework for Constraint and Data-Aware Workflow Mapping and Scheduling in Heterogeneous HPC Systems</title>
      <link>https://arxiv.org/abs/2506.00260</link>
      <description>arXiv:2506.00260v1 Announce Type: cross 
Abstract: Effective resource utilization and decreased makespan in heterogeneous High Performance Computing (HPC) environments are key benefits of workload mapping and scheduling. Tools such as Snakemake, a workflow management solution, employ Integer Linear Programming (ILP) and heuristic techniques to deploy workflows in various HPC environments like SLURM (Simple Linux Utility for Resource Management) or Kubernetes. Its scheduler factors in workflow task dependencies, resource requirements, and individual task data sizes before system deployment. ILP offers optimal solutions respecting constraints, but only for smaller workflows. Meanwhile, meta-heuristics and heuristics offer faster, though suboptimal, makespan. As problem sizes, system constraints, and complexities evolve, maintaining these schedulers becomes challenging. In this study, we propose a novel solution that integrates Graph Neural Network (GNN) and Reinforcement Learning (RL) to flexibly handle workflows, dynamic constraints, and heterogeneous resources while providing quick responses. GNN manages dependencies and resource requirements, and RL optimizes scheduling decision-making via a learned policy, overcoming the need for a comprehensive global search. Experimental results with different datasets demonstrate that this method effectively adapts to different workflows, adheres to HPC constraints, and offers optimal solutions akin to ILP but with drastically reduced execution times (76 percent faster), comparable to heuristic methods (only 3.85 times slower than OLB). Our contribution is to provide a robust yet scalable mapping and scheduling solution that can handle changing constraints, as well as workload sizes and complexities in a heterogeneous HPC Compute Continuum system landscape.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00260v1</guid>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Aasish Kumar Sharma, Julian Kunkel</dc:creator>
    </item>
    <item>
      <title>COGNATE: Acceleration of Sparse Tensor Programs on Emerging Hardware using Transfer Learning</title>
      <link>https://arxiv.org/abs/2506.00424</link>
      <description>arXiv:2506.00424v1 Announce Type: cross 
Abstract: Sparse tensor programs are essential in deep learning and graph analytics, driving the need for optimized processing. To meet this demand, specialized hardware accelerators are being developed. Optimizing these programs for accelerators is challenging for two reasons: program performance is highly sensitive to variations in sparse inputs, and early-stage accelerators rely on expensive simulators. Therefore, ML-based cost models used for optimizing such programs on general-purpose hardware are often ineffective for early-stage accelerators, as they require large datasets for proper training. To this end, we introduce COGNATE, a novel framework that leverages inexpensive data samples from general-purpose hardware (e.g., CPUs) to train cost models, followed by few-shot fine-tuning on emerging hardware. COGNATE exploits the homogeneity of input features across hardware platforms while effectively mitigating heterogeneity, enabling cost model training with just 5% of the data samples needed by accelerator-specific models to achieve comparable performance. We conduct extensive experiments to demonstrate that COGNATE outperforms existing techniques, achieving average speedups of 1.47x (up to 5.46x) for SpMM and 1.39x (up to 4.22x) for SDDMM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00424v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chamika Sudusinghe, Gerasimos Gerogiannis Damitha Lenadora, Charles Block, Josep Torrellas, Charith Mendis</dc:creator>
    </item>
    <item>
      <title>Federated learning framework for collaborative remaining useful life prognostics: an aircraft engine case study</title>
      <link>https://arxiv.org/abs/2506.00499</link>
      <description>arXiv:2506.00499v1 Announce Type: cross 
Abstract: Complex systems such as aircraft engines are continuously monitored by sensors. In predictive aircraft maintenance, the collected sensor measurements are used to estimate the health condition and the Remaining Useful Life (RUL) of such systems. However, a major challenge when developing prognostics is the limited number of run-to-failure data samples. This challenge could be overcome if multiple airlines would share their run-to-failure data samples such that sufficient learning can be achieved. Due to privacy concerns, however, airlines are reluctant to share their data in a centralized setting. In this paper, a collaborative federated learning framework is therefore developed instead. Here, several airlines cooperate to train a collective RUL prognostic machine learning model, without the need to centrally share their data. For this, a decentralized validation procedure is proposed to validate the prognostics model without sharing any data. Moreover, sensor data is often noisy and of low quality. This paper therefore proposes four novel methods to aggregate the parameters of the global prognostic model. These methods enhance the robustness of the FL framework against noisy data. The proposed framework is illustrated for training a collaborative RUL prognostic model for aircraft engines, using the N-CMAPSS dataset. Here, six airlines are considered, that collaborate in the FL framework to train a collective RUL prognostic model for their aircraft's engines. When comparing the proposed FL framework with the case where each airline independently develops their own prognostic model, the results show that FL leads to more accurate RUL prognostics for five out of the six airlines. Moreover, the novel robust aggregation methods render the FL framework robust to noisy data samples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00499v1</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>stat.ML</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Diogo Landau, Ingeborg de Pater, Mihaela Mitici, Nishant Saurabh</dc:creator>
    </item>
    <item>
      <title>Learning with Calibration: Exploring Test-Time Computing of Spatio-Temporal Forecasting</title>
      <link>https://arxiv.org/abs/2506.00635</link>
      <description>arXiv:2506.00635v1 Announce Type: cross 
Abstract: Spatio-temporal forecasting is crucial in many domains, such as transportation, meteorology, and energy. However, real-world scenarios frequently present challenges such as signal anomalies, noise, and distributional shifts. Existing solutions primarily enhance robustness by modifying network architectures or training procedures. Nevertheless, these approaches are computationally intensive and resource-demanding, especially for large-scale applications. In this paper, we explore a novel test-time computing paradigm, namely learning with calibration, ST-TTC, for spatio-temporal forecasting. Through learning with calibration, we aim to capture periodic structural biases arising from non-stationarity during the testing phase and perform real-time bias correction on predictions to improve accuracy. Specifically, we first introduce a spectral-domain calibrator with phase-amplitude modulation to mitigate periodic shift and then propose a flash updating mechanism with a streaming memory queue for efficient test-time computation. ST-TTC effectively bypasses complex training-stage techniques, offering an efficient and generalizable paradigm. Extensive experiments on real-world datasets demonstrate the effectiveness, universality, flexibility and efficiency of our proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00635v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>stat.ML</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wei Chen, Yuxuan Liang</dc:creator>
    </item>
    <item>
      <title>Review of Blockchain-Based Approaches to Spent Fuel Management in Nuclear Power Plants</title>
      <link>https://arxiv.org/abs/2506.00677</link>
      <description>arXiv:2506.00677v1 Announce Type: cross 
Abstract: This study addresses critical challenges in managing the transportation of spent nuclear fuel, including inadequate data transparency, stringent confidentiality requirements, and a lack of trust among collaborating parties, issues prevalent in traditional centralized management systems. Given the high risks involved, balancing data confidentiality with regulatory transparency is imperative. To overcome these limitations, a prototype system integrating blockchain technology and the Internet of Things (IoT) is proposed, featuring a multi-tiered consortium chain architecture. This system utilizes IoT sensors for real-time data collection, which is immutably recorded on the blockchain, while a hierarchical data structure (operational, supervisory, and public layers) manages access for diverse stakeholders. The results demonstrate that this approach significantly enhances data immutability, enables real-time multi-sensor data integration, improves decentralized transparency, and increases resilience compared to traditional systems. Ultimately, this blockchain-IoT framework improves the safety, transparency, and efficiency of spent fuel transportation, effectively resolving the conflict between confidentiality and transparency in nuclear data management and offering significant practical implications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00677v1</guid>
      <category>cs.CR</category>
      <category>cs.ET</category>
      <category>physics.app-ph</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuxiang Xu, Wenjuan Yu, Yuqian Wan, Zhongming Zhang</dc:creator>
    </item>
    <item>
      <title>Adaptive Traffic-Following Scheme for Orderly Distributed Control of Multi-Vehicle Systems</title>
      <link>https://arxiv.org/abs/2506.00703</link>
      <description>arXiv:2506.00703v1 Announce Type: cross 
Abstract: We present an adaptive control scheme to enable the emergence of order within distributed, autonomous multi-agent systems. Past studies showed that under high-density conditions, order generated from traffic-following behavior reduces travel times, while under low densities, choosing direct paths is more beneficial. In this paper, we leveraged those findings to allow aircraft to independently and dynamically adjust their degree of traffic-following behavior based on the current state of the airspace. This enables aircraft to follow other traffic only when beneficial. Quantitative analyses revealed that dynamic traffic-following behavior results in lower aircraft travel times at the cost of minimal levels of additional disorder to the airspace. The sensitivity of these benefits to temporal and spatial horizons was also investigated. Overall, this work highlights the benefits, and potential necessity, of incorporating self-organizing behavior in making distributed, autonomous multi-agent systems scalable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00703v1</guid>
      <category>cs.MA</category>
      <category>cs.ET</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anahita Jain, Husni Idris, John-Paul Clarke, Daniel Delahaye</dc:creator>
    </item>
    <item>
      <title>ETDI: Mitigating Tool Squatting and Rug Pull Attacks in Model Context Protocol (MCP) by using OAuth-Enhanced Tool Definitions and Policy-Based Access Control</title>
      <link>https://arxiv.org/abs/2506.01333</link>
      <description>arXiv:2506.01333v1 Announce Type: cross 
Abstract: The Model Context Protocol (MCP) plays a crucial role in extending the capabilities of Large Language Models (LLMs) by enabling integration with external tools and data sources. However, the standard MCP specification presents significant security vulnerabilities, notably Tool Poisoning and Rug Pull attacks. This paper introduces the Enhanced Tool Definition Interface (ETDI), a security extension designed to fortify MCP. ETDI incorporates cryptographic identity verification, immutable versioned tool definitions, and explicit permission management, often leveraging OAuth 2.0. We further propose extending MCP with fine-grained, policy-based access control, where tool capabilities are dynamically evaluated against explicit policies using a dedicated policy engine, considering runtime context beyond static OAuth scopes. This layered approach aims to establish a more secure, trustworthy, and controllable ecosystem for AI applications interacting with LLMs and external tools.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01333v1</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Manish Bhatt, Vineeth Sai Narajala, Idan Habler</dc:creator>
    </item>
    <item>
      <title>Nearest neighbor synthesis of CNOT circuits on general quantum architectures</title>
      <link>https://arxiv.org/abs/2310.00592</link>
      <description>arXiv:2310.00592v2 Announce Type: replace-cross 
Abstract: NISQ devices have inherent limitations in terms of connectivity and hardware noise. The synthesis of CNOT circuits considers the physical constraints and transforms quantum algorithms into low-level quantum circuits that can execute on physical chips correctly. In the current trend, quantum chip architectures without Hamiltonian paths are gradually replacing architectures with Hamiltonian paths due to their scalability and low-noise characteristics. To this end, this paper addresses the nearest neighbor synthesis of CNOT circuits in the architectures with and without Hamiltonian paths, aiming to enhance the fidelity of the circuits after execution. Firstly, a key-qubit priority mapping model for general quantum architectures is proposed. Secondly, the initial mapping is further improved by using tabu search to reduce the number of CNOT gates after circuit synthesis and enhance its fidelity. Finally, the noise-aware CNOT circuit nearest neighbor synthesis algorithm for the general architecture is proposed based on the key-qubit priority mapping model. The algorithm is demonstrated on several popular cloud quantum computing platforms and simulators, showing that it effectively optimizes the fidelity of CNOT circuits compared with mainstream methods. Moreover, the method can be extended to more general circuits, thereby improving the overall performance of quantum computing on NISQ devices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.00592v2</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinyu Chen, Mingqiang Zhu, Xueyun Cheng, Zhijin Guan, Shiguang Feng, Pengcheng Zhu</dc:creator>
    </item>
    <item>
      <title>Content Moderation by LLM: From Accuracy to Legitimacy</title>
      <link>https://arxiv.org/abs/2409.03219</link>
      <description>arXiv:2409.03219v2 Announce Type: replace-cross 
Abstract: One trending application of LLM (large language model) is to use it for content moderation in online platforms. Most current studies on this application have focused on the metric of accuracy -- the extent to which LLMs make correct decisions about content. This article argues that accuracy is insufficient and misleading because it fails to grasp the distinction between easy cases and hard cases, as well as the inevitable trade-offs in achieving higher accuracy. Closer examination reveals that content moderation is a constitutive part of platform governance, the key of which is to gain and enhance legitimacy. Instead of making moderation decisions correct, the chief goal of LLMs is to make them legitimate. In this regard, this article proposes a paradigm shift from the single benchmark of accuracy towards a legitimacy-based framework for evaluating the performance of LLM moderators. The framework suggests that for easy cases, the key is to ensure accuracy, speed, and transparency, while for hard cases, what matters is reasoned justification and user participation. Examined under this framework, LLMs' real potential in moderation is not accuracy improvement. Rather, LLMs can better contribute in four other aspects: to conduct screening of hard cases from easy cases, to provide quality explanations for moderation decisions, to assist human reviewers in getting more contextual information, and to facilitate user participation in a more interactive way. To realize these contributions, this article proposes a workflow for incorporating LLMs into the content moderation system. Using normative theories from law and social sciences to critically assess the new technological application, this article seeks to redefine LLMs' role in content moderation and redirect relevant research in this field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03219v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Tao Huang</dc:creator>
    </item>
  </channel>
</rss>
