<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 11 Feb 2025 04:04:28 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Hidden assumptions of integer ratio analyses in bioacoustics and music</title>
      <link>https://arxiv.org/abs/2502.04464</link>
      <description>arXiv:2502.04464v1 Announce Type: new 
Abstract: Rhythm is ubiquitous in human culture and in nature, but hard to capture in all its complexity. A key dimension of rhythm, integer ratio categories occur when the relationship between temporal intervals can be expressed as small-integer ratios. Recent work has found integer ratio categories in most human musical cultures and some animal species' vocalizations or behavioral displays. But biological systems are noisy, and empirically measured intervals rarely form an exact small-integer ratio. Here, we mathematically assess whether the leading integer ratio analysis method makes valid statistical and biological assumptions. In particular, we (1) make the temporal properties of empirical ratios explicit, both in general and for the typical use in the literature; (2) show how the choice of ratio formula affects the probability distribution of rhythm ratios and ensuing statistical results; (3) guide the reader to carefully consider the assumptions and null hypotheses of the statistical analysis; (4) present a comprehensive methodology to statistically test integer ratios for any null hypothesis of choice. Our observations have implications for both past and future research in music cognition and animal behavior: They suggest how to interpret past findings and provide tools to choose the correct null hypotheses in future empirical work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04464v1</guid>
      <category>stat.AP</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yannick Jadoul, Tommaso Tufarelli, Chlo\'e Coissac, Marco Gamba, Andrea Ravignani</dc:creator>
    </item>
    <item>
      <title>Invariant Image Reparameterisation: A Unified Approach to Structural and Practical Identifiability and Model Reduction</title>
      <link>https://arxiv.org/abs/2502.04867</link>
      <description>arXiv:2502.04867v1 Announce Type: new 
Abstract: Both structural and practical parameter non-identifiability present fundamental challenges when using mathematical models to interpret data. This issue is particularly acute in complex, applied areas such as the life sciences or engineering, where determining appropriate model complexity is challenging. While several approaches exist for diagnosing and resolving parameter non-identifiability, including symbolic methods, profile likelihood analysis, and sloppiness analysis, these approaches have distinct limitations and are rarely combined. We present an integrated approach called Invariant Image Reparameterisation (IIR) that incorporates key elements of these methods in a new way. Our approach replaces symbolic computations with numerical calculations at a single reference estimate and an invariance condition that determines when this local calculation holds globally. Parameter combinations determined by this method are naturally ordered by degree of identifiability, and this supports model reduction by replacing a practically non-identified model with a structurally non-identified approximate model. This approximate model can be further parameterised in terms of identified parameters only. By treating parameter combinations determined by our approach as interest parameters within our established likelihood-based Profile-Wise Analysis (PWA) framework, we incorporate uncertainty quantification in terms of likelihood profiles and confidence sets. We provide a Julia library on GitHub (https://github.com/omaclaren/reparam) demonstrating our methodology across a range of mathematical models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04867v1</guid>
      <category>stat.AP</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Oliver J. Maclaren, Ruanui Nicholson, Joel A. Trent, Joshua Rottenberry, Matthew Simpson</dc:creator>
    </item>
    <item>
      <title>Joint TITE-CRM for Dual Agent Dose Finding Studies</title>
      <link>https://arxiv.org/abs/2502.05072</link>
      <description>arXiv:2502.05072v1 Announce Type: new 
Abstract: Dual agent dose-finding trials study the effect of a combination of more than one agent, where the objective is to find the Maximum Tolerated Dose Combination (MTC), the combination of doses of the two agents that is associated with a pre-specified risk of being unsafe. In a Phase I/II setting, the objective is to find a dose combination that is both safe and active, the Optimal Biological Dose (OBD), that optimizes a criterion based on both safety and activity. Since Oncology treatments are typically given over multiple cycles, both the safety and activity outcome can be considered as late-onset, potentially occurring in the later cycles of treatment. This work proposes two model-based designs for dual-agent dose finding studies with late-onset activity and late-onset toxicity outcomes, the Joint TITE-POCRM and the Joint TITE-BLRM. Their performance is compared alongside a model-assisted comparator in a comprehensive simulation study motivated by a real trial example, with an extension to consider alternative sized dosing grids. It is found that both model-based methods outperform the model-assisted design. Whilst on average the two model-based designs are comparable, this comparability is not consistent across scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05072v1</guid>
      <category>stat.AP</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Helen Barnett, Oliver Boix, Dimitris Kontos, Thomas Jaki</dc:creator>
    </item>
    <item>
      <title>Estimated Roadway Segment Traffic Data by Vehicle Class for the United States: A Machine Learning Approach</title>
      <link>https://arxiv.org/abs/2502.05161</link>
      <description>arXiv:2502.05161v1 Announce Type: new 
Abstract: The Highway Performance Monitoring System, managed by the Federal Highway Administration, provides essential data on average annual daily traffic across U.S. roadways, but it has limited representation of medium- and heavy-duty vehicles on non-interstate roads. This gap limits research and policy analysis on the impacts of truck traffic, especially concerning air quality and public health. To address this, we use random forest regression to estimate medium- and heavy-duty vehicle traffic volumes in areas with sparse data. This results in a more comprehensive dataset, which enables the estimation of traffic density at the census block level as a proxy for traffic-related air pollution exposure. Our high-resolution spatial data products, rigorously validated, provide a more accurate representation of truck traffic and its environmental and health impacts. These datasets are valuable for transportation planning, public health research, and policy decisions aimed at mitigating the effects of truck traffic on vulnerable communities exposed to air pollution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05161v1</guid>
      <category>stat.AP</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Brittany Antonczak, Meg Fay, Aviral Chawla, Gregory Rowangould</dc:creator>
    </item>
    <item>
      <title>System Architecture Optimization Strategies: Dealing with Expensive Hierarchical Problems</title>
      <link>https://arxiv.org/abs/2502.00838</link>
      <description>arXiv:2502.00838v1 Announce Type: cross 
Abstract: Choosing the right system architecture for the problem at hand is challenging due to the large design space and high uncertainty in the early stage of the design process. Formulating the architecting process as an optimization problem may mitigate some of these challenges. This work investigates strategies for solving System Architecture Optimization (SAO) problems: expensive, black-box, hierarchical, mixed-discrete, constrained, multi-objective problems that may be subject to hidden constraints. Imputation ratio, correction ratio, correction fraction, and max rate diversity metrics are defined for characterizing hierar chical design spaces. This work considers two classes of optimization algorithms for SAO: Multi-Objective Evolutionary Algorithms (MOEA) such as NSGA-II, and Bayesian Optimization (BO) algorithms. A new Gaussian process kernel is presented that enables modeling hierarchical categorical variables, extending previous work on modeling continuous and integer hierarchical variables. Next, a hierarchical sampling algorithm that uses design space hierarchy to group design vectors by active design variables is developed. Then, it is demonstrated that integrating more hierarchy information in the optimization algorithms yields better optimization results for BO algorithms. Several realistic single-objective and multi-objective test problems are used for investigations. Finally, the BO algorithm is applied to a jet engine architecture optimization problem. This work shows that the developed BO algorithm can effectively solve the problem with one order of magnitude less function evaluations than NSGA-II. The algorithms and problems used in this work are implemented in the open-source Python library SBArchOpt.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00838v1</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <category>stat.AP</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s10898-024-01443-8</arxiv:DOI>
      <dc:creator>Jasper H. Bussemaker, Paul Saves, Nathalie Bartoli, Thierry Lefebvre, R\'emi Lafage</dc:creator>
    </item>
    <item>
      <title>Dark Brain Energy: Toward an Integrative Model of Spontaneous Slow Oscillations</title>
      <link>https://arxiv.org/abs/2502.04574</link>
      <description>arXiv:2502.04574v1 Announce Type: cross 
Abstract: Neural oscillations facilitate the functioning of the human brain in spatial and temporal dimensions at various frequencies. These oscillations feature a universal frequency architecture that is governed by brain anatomy, ensuring frequency specificity remains invariant across different measurement techniques. Initial magnetic resonance imaging (MRI) methodology constrained functional MRI (fMRI) investigations to a singular frequency range, thereby neglecting the frequency characteristics inherent in blood oxygen level-dependent oscillations. With advancements in MRI technology, it has become feasible to decode intricate brain activities via multi-band frequency analysis (MBFA). During the past decade, the utilization of MBFA in fMRI studies has surged, unveiling frequency-dependent characteristics of spontaneous slow oscillations (SSOs) believed to base dark energy in the brain. There remains a dearth of conclusive insights and hypotheses pertaining to the properties and functionalities of SSOs in distinct bands. We surveyed the SSO MBFA studies during the past 15 years to delineate the attributes of SSOs and enlighten their correlated functions. We further proposed a model to elucidate the hierarchical organization of multi-band SSOs by integrating their function, aimed at bridging theoretical gaps and guiding future MBFA research endeavors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04574v1</guid>
      <category>q-bio.NC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.AP</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>ZhuQing Gong, XiNian Zuo</dc:creator>
    </item>
    <item>
      <title>Capturing Extreme Events in Turbulence using an Extreme Variational Autoencoder (xVAE)</title>
      <link>https://arxiv.org/abs/2502.04685</link>
      <description>arXiv:2502.04685v1 Announce Type: cross 
Abstract: Turbulent flow fields are characterized by extreme events that are statistically intermittent and carry a significant amount of energy and physical importance. To emulate these flows, we introduce the extreme variational Autoencoder (xVAE), which embeds a max-infinitely divisible process with heavy-tailed distributions into a standard VAE framework, enabling accurate modeling of extreme events. xVAEs are neural network models that reduce system dimensionality by learning non-linear latent representations of data. We demonstrate the effectiveness of xVAE in large-eddy simulation data of wildland fire plumes, where intense heat release and complex plume-atmosphere interactions generate extreme turbulence. Comparisons with the commonly used Proper Orthogonal Decomposition (POD) modes show that xVAE is more robust in capturing extreme values and provides a powerful uncertainty quantification framework using variational Bayes. Additionally, xVAE enables analysis of the so-called copulas of fields to assess risks associated with rare events while rigorously accounting for uncertainty, such as simultaneous exceedances of high thresholds across multiple locations. The proposed approach provides a new direction for studying realistic turbulent flows, such as high-speed aerodynamics, space propulsion, and atmospheric and oceanic systems that are characterized by extreme events.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04685v1</guid>
      <category>physics.flu-dyn</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Likun Zhang, Kiran Bhaganagar, Christopher K. Wikle</dc:creator>
    </item>
    <item>
      <title>Estimating the duration of RT-PCR positivity for SARS-CoV-2 from doubly interval censored data with undetected infections</title>
      <link>https://arxiv.org/abs/2502.04824</link>
      <description>arXiv:2502.04824v1 Announce Type: cross 
Abstract: Monitoring the incidence of new infections during a pandemic is critical for an effective public health response. General population prevalence surveys for SARS-CoV-2 can provide high-quality data to estimate incidence. However, estimation relies on understanding the distribution of the duration that infections remain detectable. This study addresses this need using data from the Coronavirus Infection Survey (CIS), a long-term, longitudinal, general population survey conducted in the UK. Analyzing these data presents unique challenges, such as doubly interval censoring, undetected infections, and false negatives. We propose a Bayesian nonparametric survival analysis approach, estimating a discrete-time distribution of durations and integrating prior information derived from a complementary study. Our methodology is validated through a simulation study, including its resilience to model misspecification, and then applied to the CIS dataset. This results in the first estimate of the full duration distribution in a general population, as well as methodology that could be transferred to new contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04824v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joshua Blake, Paul Birrell, A. Sarah Walker, Koen B. Pouwels, Thomas House, Brian D. M. Tom, Theodore Kypraios, Daniela De Angelis</dc:creator>
    </item>
    <item>
      <title>Multi-study factor regression model: an application in nutritional epidemiology</title>
      <link>https://arxiv.org/abs/2304.13077</link>
      <description>arXiv:2304.13077v2 Announce Type: replace 
Abstract: Diet is a risk factor for many diseases. In nutritional epidemiology, studying reproducible dietary patterns is critical to reveal important associations with health. However, it is challenging: diverse cultural and ethnic backgrounds may critically impact eating patterns, showing heterogeneity, leading to incorrect dietary patterns and obscuring the components shared across different groups or populations. Moreover, covariate effects generated from observed variables, such as demographics and other confounders, can further bias these dietary patterns. Identifying the shared and group-specific dietary components and covariate effects is essential to drive accurate conclusions. To address these issues, we introduce a new modeling factor regression, the Multi-Study Factor Regression (MSFR) model. The MSFR model analyzes different populations simultaneously, achieving three goals: capturing shared component(s) across populations, identifying group-specific structures, and correcting for covariate effects. We use this novel method to derive common and ethnic-specific dietary patterns in a multi-center epidemiological study in Hispanic/Latinos community. Our model improves the accuracy of common and group dietary signals and yields better prediction than other techniques, revealing significant associations with health. In summary, we provide a tool to integrate different groups, giving accurate dietary signals crucial to inform public health policy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.13077v2</guid>
      <category>stat.AP</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roberta De Vito, Alejandra Avalos-Pacheco</dc:creator>
    </item>
    <item>
      <title>On the reconstruction limits of complex networks</title>
      <link>https://arxiv.org/abs/2501.01437</link>
      <description>arXiv:2501.01437v2 Announce Type: replace 
Abstract: Network reconstruction consists in retrieving the hidden interaction structure of a system from observations. Many reconstruction algorithms have been proposed, although less research has been devoted to describe their theoretical limitations. In this work, we adopt an information-theoretic perspective and define the reconstructability: The fraction of structural information recoverable from data. The reconstructability depends on the true data generating (TDG) model which is shown to set the reconstruction limit: any algorithm can perform, on average, at best like the TDG model. We show that the reconstructability is related to various performance measures, such as the probability of error and the Jaccard similarity. In an empirical context where the TDG model is unknown, we introduce the reconstruction index as an approximation of the reconstructability. We find that performing model selection is crucial for the validity of the reconstruction index as a proxy of the reconstructability of empirical time series and networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01437v2</guid>
      <category>stat.AP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>physics.data-an</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Charles Murphy, Simon Lizotte, Fran\c{c}ois Thibault, Vincent Thibeault, Patrick Desrosiers, Antoine Allard</dc:creator>
    </item>
    <item>
      <title>A Tutorial on Markov Renewal and Semi-Markov Proportional Hazards Model</title>
      <link>https://arxiv.org/abs/2502.03479</link>
      <description>arXiv:2502.03479v2 Announce Type: replace 
Abstract: Transition probability estimation plays a critical role in multi-state modeling, especially in clinical research. This paper investigates the application of semi-Markov and Markov renewal frameworks to the EBMT dataset, focusing on six clinical states encountered during hematopoietic stem cell transplantation. By comparing Aalen-Johansen (AJ) and Dabrowska-Sun-Horowitz (DSH) estimators, we demonstrate that semi-Markov models, which incorporate sojourn times, provide a more nuanced and temporally sensitive depiction of patient trajectories compared to memoryless Markov models. The DSH estimator consistently yields smoother probability curves, particularly for transitions involving prolonged states. We use empirical process theory and Burkholder-Davis-Gundy inequality to show weak convergence of the estimator. Future work includes extending the framework to accommodate advanced covariate structures and non-Markovian dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03479v2</guid>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eliuvish Cuicizion, Itsugo Ri, Elaine Holmes, Sho Lyeutsaon, Jawad Hassan Chern</dc:creator>
    </item>
  </channel>
</rss>
