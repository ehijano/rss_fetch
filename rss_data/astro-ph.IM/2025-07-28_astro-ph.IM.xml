<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>astro-ph.IM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/astro-ph.IM</link>
    <description>astro-ph.IM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/astro-ph.IM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 28 Jul 2025 04:02:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Experimental Validation for Serial Conjunction of Diffraction-limited Coronagraph and Fiber Nuller</title>
      <link>https://arxiv.org/abs/2507.18663</link>
      <description>arXiv:2507.18663v1 Announce Type: new 
Abstract: We report the experimental results of a serially conjoined nuller system, which combines a type of Lyot coronagraph with a fiber nuller. The utilized one-dimensional diffraction-limited coronagraph (1DDLC) has promising features (binary nuller, small inner working angles (IWAs)). Still, it has a performance that is highly sensitive to spectral bandwidth and tilt aberrations. Nevertheless, for the 1DDLC, wavelengths other than the design wavelength introduce leaks with a flat wavefront on the Lyot-stop plane, preserving the same complex amplitude profile as an on-axis point source. This property supports the concept of serially coupling additional nullers after the 1DDLC. The fiber-nulling unit employs a Lyot-plane mask, relay optics (1/100$\times$), and a single-mode fiber. The Lyot-plane mask splits the incoming beam -- comprising leakage from the 1DDLC and planetary light -- into four beams so that, in principle, the on-axis single-mode fiber does not couple with the on-axis leak from the 1DDLC. For the wavelength 6-\% less than the coronagraph's design-center wavelength, we confirmed the contrast mitigation ability of $3.5 \times 10^{-5}$, which is about 1/20 times the value of the case with only 1DDLC. The resultant value approximately reaches the 1DDLC's contrast mitigation ability at the design center wavelength demonstrated in the previous study, suggesting that the combined system works robustly against the broad spectral bandwidth. Future work needs to address the demonstration of the anticipated robustness for the contrast-mitigation level lower than about $10^{-5}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.18663v1</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.EP</category>
      <category>physics.optics</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Satoshi Itoh, Taro Matsuo, Reiki Kojima, Takahiro Sumi, Motohide Tamura</dc:creator>
    </item>
    <item>
      <title>NASA Exoplanet Exploration Program (ExEP) Science Gap List</title>
      <link>https://arxiv.org/abs/2507.18665</link>
      <description>arXiv:2507.18665v1 Announce Type: new 
Abstract: The Exoplanet Exploration Program (ExEP) is chartered by the NASA Astrophysics Division to carry out science, research, and technology tasks that advance NASA's science goals for exoplanets. The ExEP Science Gap List is a compilation of "science gaps", defined as either: 1) The difference between knowledge needed to define requirements for specified future NASA exoplanet missions and the current state of the art, or 2) Knowledge which is needed to enhance the exoplanet science return of current and future NASA exoplanet missions. It is annually updated and input is solicited from the exoplanet community via ExoPAG. Current gaps are: 1) Spectroscopic observations of the atmospheres of small exoplanets, 2) Modeling exoplanet atmospheres, 3) Spectral signature retrieval, 4) Planetary system architectures: occurrence rates for exoplanets of all sizes, 5) Occurrence rates and uncertainties for temperate rocky planets, 6) Yield estimation for exoplanet direct imaging missions, 7) Intrinsic properties of known exoplanet host stars, 8) Mitigating stellar jitter as a limitation to sensitivity of dynamical methods to detect small temperate exoplanets and measure their masses and orbits, 9) Dynamical confirmation of exoplanet candidates and determination of their masses and orbits, 10) Observations and analyses of direct imaging targets, 11) Understanding the abundance and distribution of exozodiacal dust, 12) Measurements of accurate transiting planet radii, 13) Properties of atoms, molecules and aerosols in exoplanet atmospheres, 14) Exoplanet interior structure and material properties, 15) Quantify and mitigate the impacts of stellar contamination on transmission spectroscopy for measuring the composition of exoplanet atmospheres, 16) Complete the inventory of remotely observable exoplanet biosignatures and their false positives, 17) Understanding planet formation and disk properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.18665v1</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.EP</category>
      <category>astro-ph.HE</category>
      <category>astro-ph.SR</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Karl Stapelfeldt, Eric Mamajek</dc:creator>
    </item>
    <item>
      <title>A Practical Framework for Weight Map Construction in CCD Photometry</title>
      <link>https://arxiv.org/abs/2507.18679</link>
      <description>arXiv:2507.18679v1 Announce Type: new 
Abstract: This note presents a practical formulation for constructing weight maps in CCD photometry, accounting for various noise contributions under the assumption of statistical independence. We provide complete equations for both electron-count and ADU-based imaging data, along with simplified expressions for different observational conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.18679v1</guid>
      <category>astro-ph.IM</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.3847/2515-5172/adf29b</arxiv:DOI>
      <arxiv:journal_reference>Res. Notes AAS 9 198 (2025)</arxiv:journal_reference>
      <dc:creator>Dezi Liu, Yuan Fang</dc:creator>
    </item>
    <item>
      <title>Recommendations to overcome language barriers in the Vera C. Rubin Observatory Research Ecosystem</title>
      <link>https://arxiv.org/abs/2507.18682</link>
      <description>arXiv:2507.18682v1 Announce Type: new 
Abstract: The report presents a comprehensive set of five recommendations to reduce language barriers within the Vera C. Rubin Observatory Research Ecosystem, promoting greater inclusion of researchers who are speakers of English as an additional language. Recognizing that English linguistic hegemony in science limits participation and productivity, the document proposes multilingual presentation formats, academic writing training, a Virtual Writing Center, language support programs, and writing retreats. Each recommendation is grounded in both pedagogical theory and empirical evidence, with an emphasis on collaborative, socially embedded approaches to scientific writing. The proposed academic writing training integrates constructivist and socio-cultural perspectives, emphasizing genre awareness, rhetorical competence, and reflective practices. The Virtual Writing Center would serve as a permanent infrastructure offering personalized tutoring and peer review support, while the language support programs address ongoing needs through workshops, consultations, and access to language tools. Writing retreats provide immersive environments for focused work and mentorship. The recommendations also encourage ethical use of AI tools for translation and writing assistance, fostering digital literacy alongside linguistic proficiency. Collectively, these initiatives aim to transform language from a barrier into a resource, recognizing multilingualism as an asset in global research collaboration. Rather than offering a one-size-fits-all solution, the document advocates for adaptable, community-driven strategies that can evolve within the diverse institutional and disciplinary contexts of the Rubin Research Ecosystem. By implementing these practices, the Ecosystem could lead efforts to democratize scientific communication and foster a more equitable, multilingual research culture.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.18682v1</guid>
      <category>astro-ph.IM</category>
      <category>cs.CY</category>
      <category>physics.soc-ph</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.3847/25c2cfeb.983bab04</arxiv:DOI>
      <dc:creator>Jos\'e Antonio Alonso Pav\'on, Andr\'es Alejandro Plazas Malag\'on</dc:creator>
    </item>
    <item>
      <title>ARVE: Analyzing Radial Velocity Elements. I. The Code</title>
      <link>https://arxiv.org/abs/2507.18869</link>
      <description>arXiv:2507.18869v1 Announce Type: new 
Abstract: Context. In order to overcome the radial velocity (RV) precision barrier imposed by stellar variability, there has been a surge of software aimed at simulating and modeling these activity patterns. Aims. We present Analyzing Radial Velocity Elements (ARVE), a Python-based software which enables RV extraction using various customizable techniques, and subsequent analysis of the stellar and planetary signals present in the RVs. One of ARVE's unique features is its library of pre-computed auxiliary data, which includes synthetic spectra and spectral line masks, allowing the code to efficiently perform certain routines with minimal input from the user. Methods. ARVE is a class-based and modular code in which its functionalities are divided between four subclasses: functions, which handles general functions utilized by the other subclasses; data, which reads the input data, loads the auxiliary data, and extracts RVs from input high-resolution spectra; star, which characterizes the stellar activity components present in the RV time series; and planets, which performs fits of Keplerian signals in the data and offers injection-recovery tests of fictitious planets to determine the detection limits. Results. Demonstrations of ARVE are performed on three years of HARPS-N solar data. We show the evolution of granulation and supergranulation characteristic timescales with activity level, and we investigate the differences in planetary period-mass detection limits when extracting RVs with different methods. Conclusions. As stellar activity mitigation techniques grow more diverse, we foresee that a tool like ARVE could greatly benefit the community by offering a user-friendly and multi-functional approach to extract and analyze RV time series. With its current code structure, expanded functionality and increased compatibility with more spectrographs should be easily addable to future versions of ARVE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.18869v1</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.EP</category>
      <category>astro-ph.SR</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>K. Al Moulla</dc:creator>
    </item>
    <item>
      <title>Wavefront super-resolution for Adaptive Optics systems on ground-based telescopes</title>
      <link>https://arxiv.org/abs/2507.19150</link>
      <description>arXiv:2507.19150v1 Announce Type: new 
Abstract: In ground-based astronomy, Adaptive Optics (AO) is a pivotal technique, engineered to correct wavefront phase distortions and thereby enhance the quality of the observed images. Integral to an AO system is the wavefront sensor (WFS), which is crucial for detecting wavefront aberrations from guide stars, essential for phase calculations. Many models based on a single-WFS model have been proposed to obtain the high-resolution phase of the incoming wavefront. In this paper, we delve into the realm of multiple WFSs within the framework of state-of-the-art telescope setups for high-resolution phase reconstruction. We propose a model for reconstructing a high-resolution wavefront from a sequence of wavefront gradient data from multiple WFSs. Our model is based on the turbulence statistics and the Taylor frozen flow hypothesis, incorporating knowledge of the wind velocities in atmospheric turbulence layers. We also introduce an $H_2$ regularization term, especially for atmospheric characteristics under von Karman statistics, and provide a theoretical analysis for $H^2$ space within $H^{11/6}$. Numerical simulations are conducted to demonstrate the robustness and effectiveness of our regularization term and multi-WFS reconstruction strategy under identical experimental conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19150v1</guid>
      <category>astro-ph.IM</category>
      <category>math.OC</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yutong Wu, Roland Wagner, Ronny Ramlau, Raymond H. Chan</dc:creator>
    </item>
    <item>
      <title>An RFSoC-based F-engine for ARGOS</title>
      <link>https://arxiv.org/abs/2507.19386</link>
      <description>arXiv:2507.19386v1 Announce Type: new 
Abstract: Radio interferometers provide the means to perform the wide-field-of-view (FoV), high-sensitivity observations required for modern radio surveys. As computing power per cost has decreased, there has been a move towards larger arrays of smaller dishes, such as DSA-2000, the upcoming HIRAX, CHORD and SKA radio telescopes. Such arrays can have simpler receiver designs with room-temperature low-noise amplifiers and direct sampling to achieve, greatly reducing the cost per antenna. The ARGOS project is currently developing an array of five 6-meter antennas that will be used to demonstrate the technology required for a next generation "small-D, big-N" radio interferometer in Europe. In this work, our objective was to implement a first-stage digital signal processing system for the ARGOS demonstrator array, providing digitization, channelization, delay correction and frequency-dependent complex gain correction. The system is intended to produce delay and phase corrected dual-polarization channelized voltages in the frequency range 1-3 GHz with a nominal channel bandwidth of 1 MHz. We use an RFSoC 4x2 evaluation board with four analog-to-digital converters (ADCs) that can simultaneously sample two 1 GHz, dual-polarization bands. We use Xilinx Vitis HLS C++ to develop the required firmware as a set of customizable modules suitable for rapid prototyping. We performed hardware verification of the channel response of the critically sampled PFB and of the delay correction, showing both to be consistent with theoretical expectations. Furthermore, the board was installed at the Effelsberg 100-meter radio telescope where we performed commensal pulsar observations with the Effelsberg Direct Digitization backend, showing comparable performance. This work demonstrates the utility of high-level synthesis (HLS) languages in the development of high performance radio astronomy processing backends.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19386v1</guid>
      <category>astro-ph.IM</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yunpeng Men, Ewan Barr, Amit Bansod, Weiwei Chen, Jason Wu, John Antoniadis, Jan Behrend, Niclas Esser, Oliver Polch, Gundolf Wieching, Tobias Winchen</dc:creator>
    </item>
    <item>
      <title>Bayesian Deep Gaussian Processes for Correlated Functional Data: A Case Study in Cosmological Matter Power Spectra</title>
      <link>https://arxiv.org/abs/2507.18683</link>
      <description>arXiv:2507.18683v1 Announce Type: cross 
Abstract: Understanding the structure of our universe and the distribution of matter is an area of active research. As cosmological surveys grow in complexity, the development of emulators to efficiently and effectively predict matter power spectra is essential. We are particularly motivated by the Mira-Titan Universe simulation suite that, for a specified cosmological parameterization (termed a "cosmology"), provides multiple response curves of various fidelities, including correlated functional realizations. Our objective is two-fold. First, we estimate the underlying true matter power spectra, with appropriate uncertainty quantification (UQ), from all of the provided curves. To this end, we propose a novel Bayesian deep Gaussian process (DGP) hierarchical model which synthesizes all the simulation information to estimate the underlying matter power spectra while providing effective UQ. Our model extends previous work on Bayesian DGPs from scalar responses to correlated functional outputs. Second, we leverage our predicted power spectra from various cosmologies in order to accurately predict the entire matter power spectra for an unobserved cosmology. For this task, we use basis function representations of the functional spectra to train a separate Gaussian process emulator. Our method performs well in synthetic exercises and against the benchmark cosmological emulator (Cosmic Emu).</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.18683v1</guid>
      <category>stat.AP</category>
      <category>astro-ph.CO</category>
      <category>astro-ph.IM</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stephen A. Walsh, Annie S. Booth, David Higdon, Jared Clark, Kelly R. Moran, Katrin Heitmann</dc:creator>
    </item>
    <item>
      <title>The GAPS Programme at TNG LXVIII. Characterization of the outer substellar companion around HD 72659 with a multi-technique approach</title>
      <link>https://arxiv.org/abs/2507.19063</link>
      <description>arXiv:2507.19063v1 Announce Type: cross 
Abstract: Before discovering the first exoplanets, the Radial Velocity (RV) method had been used for decades to discover binary stars. Despite significant advancements in this technique, it is limited by the intrinsic mass-inclination degeneracy that can be broken when combining RVs with astrometry, which allows us to determine the orbital inclination, or direct imaging, from which we can estimate the true mass of the target. HD 72659 is a solar analog known to host a gas giant on a $\sim 10$-yr orbit and a massive outer companion. This work aims to confirm HD 72659 c, which was recently announced using data from HIRES and HARPS spectrographs in combination with Gaia's astrometric data. We monitored HD 72659 with HARPS-N in the framework of the GAPS project since 2012. We now combined our 91 spectra with literature data and Gaia DR3 high-precision astrometry to constrain the mass and the orbit of this object ($M_{\rm c} \sim 19$ $M_{\rm J}$, $a \sim 21$ au) that falls in the Brown Dwarf desert. Moreover, we analyzed our high-resolution imaging observation taken with SPHERE, but since the target was not detected, we could only derive upper limits on its mass. We characterize the orbital parameters of HD 72659 c, confirming the literature mass of this object but finding a period twice as high as previously reported, and we also refine the parameters of planet b with reduced uncertainties compared to previous works. Finally, we analyze and discuss the dynamic configuration of this system, finding that the Kozai-Lidov mechanism may be at work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19063v1</guid>
      <category>astro-ph.EP</category>
      <category>astro-ph.IM</category>
      <category>astro-ph.SR</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>A. Ruggieri, A. Sozzetti, S. Desidera, D. Mesa, R. Gratton, F. Marzari, M. Bonavita, K. Biazzo, V. D'Orazi, C. Ginski, M. Meyer, L. Malavolta, M. Pinamonti, D. Barbato, C. Lazzoni, A. F. Lanza, L. Mancini, L. Naponiello, D. Nardiello, T. Zingales, M. Rainer, G. Scandariato, P. Giacobbe, R. Cosentino, A. Fiorenzano, R. Claudi</dc:creator>
    </item>
    <item>
      <title>Investigating the Influence of Asymmetric Errors on Retrievals of Exoplanet Transmission Spectra</title>
      <link>https://arxiv.org/abs/2507.19223</link>
      <description>arXiv:2507.19223v1 Announce Type: cross 
Abstract: In studies of exoplanet atmospheres using transmission spectroscopy, Bayesian retrievals are the most popular form of analysis. In these procedures it is common to adopt a Gaussian likelihood. However, this implicitly assumes that the upper and lower error bars on the spectral points are equal. With recent observations from the James Webb Space Telescope (JWST) offering higher quality of data, it is worth revisiting this assumption to understand the impact that an asymmetry between the error bars may have on retrieved parameters. In this study, we challenge the approximation by comparing retrievals using a symmetric, Gaussian likelihood, and an asymmetric, split normal likelihood. We find that the influence of this assumption is minimal at the scales of asymmetry observed in JWST observations of WASP-39 b (with a maximum asymmetry of 77%) but we show that it would become critical with greater levels of asymmetry (e.g. an average asymmetry of 80%). Furthermore, we stress the importance of the shape of the asymmetric distribution and the difficulty in fitting this distribution from three summary statistics (the median and an upper and lower bound on the transit depth). An asymmetric likelihood sampler will incorrectly predict parameters if the shape of the likelihood does not match that of the underlying noise distribution even when the levels of asymmetry are equal in both. Overall, we find that it is safe to use the Gaussian likelihood assumption for current datasets but it is worth considering the potential bias if greater asymmetries are observed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19223v1</guid>
      <category>astro-ph.EP</category>
      <category>astro-ph.IM</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jack J. Davey, Kai Hou Yip, Quentin Changeat, Ingo P. Waldmann</dc:creator>
    </item>
    <item>
      <title>A novel energy reconstruction method for the MAGIC stereoscopic observation</title>
      <link>https://arxiv.org/abs/2212.03592</link>
      <description>arXiv:2212.03592v3 Announce Type: replace 
Abstract: We present a new gamma ray energy reconstruction method based on Random Forest to be commonly used for the data analysis of the MAGIC Telescopes, a system of two Imaging Atmospheric Cherenkov Telescopes.
  The energy resolution with the new energy reconstruction improves compared to the one obtained with the LUTs method. For standard observations i.e. dark conditions with pointing zenith (Zd) less than 35 deg for a point-like source, the energy resolution goes from $\sim 20\%$ at 100 GeV to $\sim 10\%$ at a few TeV.
  In addition, the new method suppresses the outlier population in the energy error distribution, which is thus better described by a Gaussian distribution. The new energy reconstruction method enhances the reliability especially for the sources with steep spectra, in higher energies and/or in observations at higher Zd pointings.
  We validate the new method in different ways and demonstrate some cases of its remarkable benefit in spectral analysis with simulated observation data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.03592v3</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.HE</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.astropartphys.2024.102937</arxiv:DOI>
      <arxiv:journal_reference>Astroparticle Physics Volume 158, June 2024, 102937</arxiv:journal_reference>
      <dc:creator>Kazuma Ishio, David Paneque</dc:creator>
    </item>
    <item>
      <title>spike: A tool to drizzle HST, JWST, and Roman PSFs for improved analyses</title>
      <link>https://arxiv.org/abs/2503.02288</link>
      <description>arXiv:2503.02288v2 Announce Type: replace 
Abstract: A point spread function (PSF) describes the distribution of light for a pure point source in an astronomical image due to the optics of the instrument. An accurate PSF is key for deconvolution, point source photometry and source removal. Space-based telescopes can then pose a challenge because their PSFs are influenced by their complex construction, and the myriad of pointings and rotations used to capture deep images. These telescopes also capture the highest resolution images of astronomical sources, resolving stars in even relatively distant galaxies. Proper co-addition of PSFs at a specific source position for space-based imaging is then both critical and challenging. The library described in this work, spike, generates model PSFs and runs them through the same processing pipeline used to derive deep, co-added images, providing correctly co-added and resampled PSFs for images from the Hubble Space Telescope, the James Webb Space Telescope, and the Nancy Grace Roman Space Telescope.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02288v2</guid>
      <category>astro-ph.IM</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.21105/joss.08200</arxiv:DOI>
      <arxiv:journal_reference>Journal of Open Source Software, 10(111), 8200, July 2025</arxiv:journal_reference>
      <dc:creator>Ava Polzin</dc:creator>
    </item>
    <item>
      <title>Redshift Assessment Infrastructure Layers (RAIL): Rubin-era photometric redshift stress-testing and at-scale production</title>
      <link>https://arxiv.org/abs/2505.02928</link>
      <description>arXiv:2505.02928v2 Announce Type: replace 
Abstract: Virtually all extragalactic use cases of the Vera C. Rubin Observatory's Legacy Survey of Space and Time (LSST) require the use of galaxy redshift information, yet the vast majority of its sample of tens of billions of galaxies will lack high-fidelity spectroscopic measurements thereof, instead relying on photometric redshifts (photo-$z$) subject to systematic imprecision and inaccuracy best encapsulated by photo-$z$ probability density functions (PDFs). We present the version 1 release of Redshift Assessment Infrastructure Layers (RAIL), an open source Python library for at-scale probabilistic photo-$z$ estimation, initiated by the LSST Dark Energy Science Collaboration (DESC) with contributions from the LSST Interdisciplinary Network for Collaboration and Computing (LINCC) Frameworks team. RAIL's three subpackages provide modular tools for end-to-end stress-testing, including a forward modeling suite to generate realistically complex photometry, a unified API for estimating per-galaxy and ensemble redshift PDFs by an extensible set of algorithms, and built-in metrics of both photo-$z$ PDFs and point estimates. RAIL serves as a flexible toolkit enabling the derivation and optimization of photo-$z$ data products at scale for a variety of science goals and is not specific to LSST data. We thus describe to the extragalactic science community, including and beyond Rubin the design and functionality of the RAIL software library so that any researcher may have access to its wide array of photo-$z$ characterization and assessment tools.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02928v2</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.CO</category>
      <category>astro-ph.GA</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator> The RAIL Team, Jan Luca van den Busch, Eric Charles, Johann Cohen-Tanugi, Alice Crafford, John Franklin Crenshaw, Sylvie Dagoret, Josue De-Santiago, Juan De Vicente, Qianjun Hang, Benjamin Joachimi, Shahab Joudaki, J. Bryce Kalmbach, Arun Kannawadi, Shuang Liang, Olivia Lynn, Alex I. Malz, Rachel Mandelbaum, Grant Merz, Irene Moskowitz, Drew Oldag, Jaime Ruiz-Zapatero, Mubdi Rahman, Markus M. Rau, Samuel J. Schmidt, Jennifer Scora, Raphael Shirley, Benjamin St\"olzner, Laura Toribio San Cipriano, Luca Tortorelli, Ziang Yan, Tianqing Zhang, the Dark Energy Science Collaboration</dc:creator>
    </item>
    <item>
      <title>A pipeline for searching and fitting instrumental glitches in LISA data</title>
      <link>https://arxiv.org/abs/2505.19870</link>
      <description>arXiv:2505.19870v2 Announce Type: replace-cross 
Abstract: Instrumental artefacts, such as glitches, can significantly compromise the scientific output of LISA. Our methodology employs advanced Bayesian techniques, including Reversible Jump Markov Chain Monte Carlo and parallel tempering to find and characterize glitches and astrophysical signals. The robustness of the pipeline is demonstrated through its ability to simultaneously handle diverse glitch morphologies and it is validated with a 'Spritz'-type data set from the LISA Data Challenge. Our approach enables accurate inference on Massive Black Hole Binaries, while simultaneously characterizing both instrumental artefacts and noise. These results present a significant development in strategies for differentiating between instrumental noise and astrophysical signals, which will ultimately improve the accuracy and reliability of source population analyses with LISA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19870v2</guid>
      <category>gr-qc</category>
      <category>astro-ph.IM</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martina Muratore, Jonathan Gair, Olaf Hartwig, Michael L. Katz, Alexandre Toubiana</dc:creator>
    </item>
    <item>
      <title>CLASS_SZ II: Notes and Examples of Fast and Accurate Calculations of Halo Model, Large Scale Structure and Cosmic Microwave Background Observables</title>
      <link>https://arxiv.org/abs/2507.07346</link>
      <description>arXiv:2507.07346v3 Announce Type: replace-cross 
Abstract: These notes are very much work-in-progress and simply intended to showcase, in various degrees of details (and rigour), some of the cosmology calculations that class_sz can do. We describe the class_sz code in C, Python and Jax. Based on the Boltzmann code class, it can compute a wide range of observables relevant to current and forthcoming CMB and Large Scale Structure surveys. This includes galaxy shear and clustering, CMB lensing, thermal and kinetic Sunyaev and Zeldovich observables, Cosmic Infrared Background, cross-correlations and three-point statistics. Calculations can be done either within the halo model or the linear bias model. For standard $\Lambda$CDM cosmology and extensions, class_sz uses high-accuracy cosmopower emulators of the CMB and matter power spectrum to accelerate calculations. With this, along with efficient numerical integration routines, most class_sz output can be obtained in less than 500 ms (CMB $C_\ell$'s or matter $P(k)$ take $\mathcal{O}(1\mathrm{ms})$), allowing for fast or ultra-fast parameter inference analyses. Parts of the calculations are "jaxified", so the software can be integrated into differentiable pipelines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07346v3</guid>
      <category>astro-ph.CO</category>
      <category>astro-ph.IM</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Boris Bolliet, Aleksandra Kusiak, Fiona McCarthy, Alina Sabyr, Kristen Surrao, Jens Chluba, Carmen Embil Villagra, Simone Ferraro, Boryana Hadzhiyska, Dongwon Han, J. Colin Hill, Juan Francisco Mac\'ias-P\'erez, Abhishek Maniyar, Yogesh Mehta, Shivam Pandey, Emmanuel Schaan, Blake Sherwin, Alessio Spurio Mancini, \'I\~nigo Zubeldia</dc:creator>
    </item>
  </channel>
</rss>
