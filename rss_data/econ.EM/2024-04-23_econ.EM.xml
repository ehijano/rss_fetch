<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 23 Apr 2024 04:00:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 23 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>How do applied researchers use the Causal Forest? A methodological review of a method</title>
      <link>https://arxiv.org/abs/2404.13356</link>
      <description>arXiv:2404.13356v1 Announce Type: new 
Abstract: This paper conducts a methodological review of papers using the causal forest machine learning method for flexibly estimating heterogeneous treatment effects. It examines 133 peer-reviewed papers. It shows that the emerging best practice relies heavily on the approach and tools created by the original authors of the causal forest such as their grf package and the approaches given by them in examples. Generally researchers use the causal forest on a relatively low-dimensional dataset relying on randomisation or observed controls to identify effects. There are several common ways to then communicate results -- by mapping out the univariate distribution of individual-level treatment effect estimates, displaying variable importance results for the forest and graphing the distribution of treatment effects across covariates that are important either for theoretical reasons or because they have high variable importance. Some deviations from this common practice are interesting and deserve further development and use. Others are unnecessary or even harmful.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13356v1</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Patrick Rehill</dc:creator>
    </item>
    <item>
      <title>Identification and Estimation of Nonseparable Triangular Equations with Mismeasured Instruments</title>
      <link>https://arxiv.org/abs/2404.13735</link>
      <description>arXiv:2404.13735v1 Announce Type: new 
Abstract: In this paper, I study the nonparametric identification and estimation of the marginal effect of an endogenous variable $X$ on the outcome variable $Y$, given a potentially mismeasured instrument variable $W^*$, without assuming linearity or separability of the functions governing the relationship between observables and unobservables. To address the challenges arising from the co-existence of measurement error and nonseparability, I first employ the deconvolution technique from the measurement error literature to identify the joint distribution of $Y, X, W^*$ using two error-laden measurements of $W^*$. I then recover the structural derivative of the function of interest and the "Local Average Response" (LAR) from the joint distribution via the "unobserved instrument" approach in Matzkin (2016). I also propose nonparametric estimators for these parameters and derive their uniform rates of convergence. Monte Carlo exercises show evidence that the estimators I propose have good finite sample performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13735v1</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shaomin Wu</dc:creator>
    </item>
    <item>
      <title>Stochastic Volatility in Mean: Efficient Analysis by a Generalized Mixture Sampler</title>
      <link>https://arxiv.org/abs/2404.13986</link>
      <description>arXiv:2404.13986v1 Announce Type: new 
Abstract: In this paper we consider the simulation-based Bayesian analysis of stochastic volatility in mean (SVM) models. Extending the highly efficient Markov chain Monte Carlo mixture sampler for the SV model proposed in Kim et al. (1998) and Omori et al. (2007), we develop an accurate approximation of the non-central chi-squared distribution as a mixture of thirty normal distributions. Under this mixture representation, we sample the parameters and latent volatilities in one block. We also detail a correction of the small approximation error by using additional Metropolis-Hastings steps. The proposed method is extended to the SVM model with leverage. The methodology and models are applied to excess holding yields in empirical studies, and the SVM model with leverage is shown to outperform competing volatility models based on marginal likelihoods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13986v1</guid>
      <category>econ.EM</category>
      <category>q-fin.MF</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daichi Hiraki, Siddhartha Chib, Yasuhiro Omori</dc:creator>
    </item>
    <item>
      <title>An economically-consistent discrete choice model with flexible utility specification based on artificial neural networks</title>
      <link>https://arxiv.org/abs/2404.13198</link>
      <description>arXiv:2404.13198v1 Announce Type: cross 
Abstract: Random utility maximisation (RUM) models are one of the cornerstones of discrete choice modelling. However, specifying the utility function of RUM models is not straightforward and has a considerable impact on the resulting interpretable outcomes and welfare measures. In this paper, we propose a new discrete choice model based on artificial neural networks (ANNs) named "Alternative-Specific and Shared weights Neural Network (ASS-NN)", which provides a further balance between flexible utility approximation from the data and consistency with two assumptions: RUM theory and fungibility of money (i.e., "one euro is one euro"). Therefore, the ASS-NN can derive economically-consistent outcomes, such as marginal utilities or willingness to pay, without explicitly specifying the utility functional form. Using a Monte Carlo experiment and empirical data from the Swissmetro dataset, we show that ASS-NN outperforms (in terms of goodness of fit) conventional multinomial logit (MNL) models under different utility specifications. Furthermore, we show how the ASS-NN is used to derive marginal utilities and willingness to pay measures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13198v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>econ.EM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jose Ignacio Hernandez, Niek Mouter, Sander van Cranenburgh</dc:creator>
    </item>
    <item>
      <title>Efficient Integrated Volatility Estimation in the Presence of Infinite Variation Jumps via Debiased Truncated Realized Variations</title>
      <link>https://arxiv.org/abs/2209.10128</link>
      <description>arXiv:2209.10128v3 Announce Type: replace 
Abstract: Statistical inference for stochastic processes based on high-frequency observations has been an active research area for more than two decades. One of the most well-known and widely studied problems has been the estimation of the quadratic variation of the continuous component of an It\^o semimartingale with jumps. Several rate- and variance-efficient estimators have been proposed in the literature when the jump component is of bounded variation. However, to date, very few methods can deal with jumps of unbounded variation. By developing new high-order expansions of the truncated moments of a locally stable L\'evy process, we propose a new rate- and variance-efficient volatility estimator for a class of It\^o semimartingales whose jumps behave locally like those of a stable L\'evy process with Blumenthal-Getoor index $Y\in (1,8/5)$ (hence, of unbounded variation). The proposed method is based on a two-step debiasing procedure for the truncated realized quadratic variation of the process and can also cover the case $Y&lt;1$. Our Monte Carlo experiments indicate that the method outperforms other efficient alternatives in the literature in the setting covered by our theoretical framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.10128v3</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>q-fin.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>B. Cooper Boniece, Jos\'e E. Figueroa-L\'opez, Yuchen Han</dc:creator>
    </item>
    <item>
      <title>The Falsification Adaptive Set in Linear Models with Instrumental Variables that Violate the Exclusion or Conditional Exogeneity Restriction</title>
      <link>https://arxiv.org/abs/2212.04814</link>
      <description>arXiv:2212.04814v2 Announce Type: replace 
Abstract: Masten and Poirier (2021) introduced the falsification adaptive set (FAS) in linear models with a single endogenous variable estimated with multiple correlated instrumental variables (IVs). The FAS reflects the model uncertainty that arises from falsification of the baseline model. We show that it applies to cases where a conditional exogeneity assumption holds and invalid instruments violate the exclusion assumption only. We propose a generalized FAS that reflects the model uncertainty when some instruments violate the exclusion assumption and/or some instruments violate the conditional exogeneity assumption. Under the assumption that invalid instruments are not themselves endogenous explanatory variables, if there is at least one relevant instrument that satisfies both the exclusion and conditional exogeneity assumptions then this generalized FAS is guaranteed to contain the parameter of interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.04814v2</guid>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicolas Apfel, Frank Windmeijer</dc:creator>
    </item>
    <item>
      <title>One-step smoothing splines instrumental regression</title>
      <link>https://arxiv.org/abs/2307.14867</link>
      <description>arXiv:2307.14867v3 Announce Type: replace 
Abstract: We extend nonparametric regression smoothing splines to a context where there is endogeneity and instrumental variables are available. Unlike popular existing estimators, the resulting estimator is one-step and relies on a unique regularization parameter. We derive uniform rates of the convergence for the estimator and its first derivative. We also address the issue of imposing monotonicity in estimation and extend the approach to a partly linear model. Simulations confirm the good performances of our estimator compared to two-step procedures. Our method yields economically sensible results when used to estimate Engel curves.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.14867v3</guid>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jad Beyhum, Elia Lapenta, Pascal Lavergne</dc:creator>
    </item>
    <item>
      <title>Arellano-Bond LASSO Estimator for Dynamic Linear Panel Models</title>
      <link>https://arxiv.org/abs/2402.00584</link>
      <description>arXiv:2402.00584v2 Announce Type: replace 
Abstract: The Arellano-Bond estimator is a fundamental method for dynamic panel data models, which is widely used in practice. However, the estimator is severely biased when the data's time series dimension $T$ is long due to the large degree of overidentification. We propose a simple two-step approach to remove the bias. First, apply LASSO to the cross-section data at each time period to select the most informative moment conditions, using lagged values of suitable covariates. Second, apply a linear instrumental variable estimator using the instruments constructed from the selected moment conditions. Combine the two stages using cross-fitted generalized method of moments to avoid overfitting bias. Under weak dependence of time series we show the new estimator is consistent and asymptotically normal under much weaker conditions on the growth of $T$ than the Arellano-Bond estimator. Our theory covers models with high dimensional covariates, including multiple lags of the dependent variable, common in modern applications. We illustrate our approach by applying it to weekly county-level panel data from the United States to study the short and long-term effects of opening K-12 schools and other mitigation policies on COVID-19's spread.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.00584v2</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Victor Chernozhukov, Iv\'an Fern\'andez-Val, Chen Huang, Weining Wang</dc:creator>
    </item>
  </channel>
</rss>
