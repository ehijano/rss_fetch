<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 16 Dec 2024 05:00:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>On the Parameterized Complexity of Diverse SAT</title>
      <link>https://arxiv.org/abs/2412.09717</link>
      <description>arXiv:2412.09717v1 Announce Type: new 
Abstract: We study the Boolean Satisfiability problem (SAT) in the framework of diversity, where one asks for multiple solutions that are mutually far apart (i.e., sufficiently dissimilar from each other) for a suitable notion of distance/dissimilarity between solutions. Interpreting assignments as bit vectors, we take their Hamming distance to quantify dissimilarity, and we focus on problem of finding two solutions. Specifically, we define the problem MAX DIFFER SAT (resp. EXACT DIFFER SAT) as follows: Given a Boolean formula $\phi$ on $n$ variables, decide whether $\phi$ has two satisfying assignments that differ on at least (resp. exactly) $d$ variables. We study classical and parameterized (in parameters $d$ and $n-d$) complexities of MAX DIFFER SAT and EXACT DIFFER SAT, when restricted to some formula-classes on which SAT is known to be polynomial-time solvable. In particular, we consider affine formulas, $2$-CNF formulas and hitting formulas.
  For affine formulas, we show the following: Both problems are polynomial-time solvable when each equation has at most two variables. EXACT DIFFER SAT is NP-hard, even when each equation has at most three variables and each variable appears in at most four equations. Also, MAX DIFFER SAT is NP-hard, even when each equation has at most four variables. Both problems are W[1]-hard in the parameter $n-d$. In contrast, when parameterized by $d$, EXACT DIFFER SAT is W[1]-hard, but MAX DIFFER SAT admits a single-exponential FPT algorithm and a polynomial-kernel.
  For 2-CNF formulas, we show the following: Both problems are polynomial-time solvable when each variable appears in at most two clauses. Also, both problems are W[1]-hard in the parameter $d$ (and therefore, it turns out, also NP-hard), even on monotone inputs (i.e., formulas with no negative literals). Finally, for hitting formulas, we show that both problems are polynomial-time solvable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09717v1</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Neeldhara Misra, Harshil Mittal, Ashutosh Rai</dc:creator>
    </item>
    <item>
      <title>Learning-Augmented Streaming Algorithms for Approximating MAX-CUT</title>
      <link>https://arxiv.org/abs/2412.09773</link>
      <description>arXiv:2412.09773v1 Announce Type: new 
Abstract: We study learning-augmented streaming algorithms for estimating the value of MAX-CUT in a graph. In the classical streaming model, while a $1/2$-approximation for estimating the value of MAX-CUT can be trivially achieved with $O(1)$ words of space, Kapralov and Krachun [STOC'19] showed that this is essentially the best possible: for any $\epsilon &gt; 0$, any (randomized) single-pass streaming algorithm that achieves an approximation ratio of at least $1/2 + \epsilon$ requires $\Omega(n / 2^{\text{poly}(1/\epsilon)})$ space. We show that it is possible to surpass the $1/2$-approximation barrier using just $O(1)$ words of space by leveraging a (machine learned) oracle. Specifically, we consider streaming algorithms that are equipped with an $\epsilon$-accurate oracle that for each vertex in the graph, returns its correct label in $\{-1, +1\}$, corresponding to an optimal MAX-CUT solution in the graph, with some probability $1/2 + \epsilon$, and the incorrect label otherwise. Within this framework, we present a single-pass algorithm that approximates the value of MAX-CUT to within a factor of $1/2 + \Omega(\epsilon^2)$ with probability at least $2/3$ for insertion-only streams, using only $\text{poly}(1/\epsilon)$ words of space. We also extend our algorithm to fully dynamic streams while maintaining a space complexity of $\text{poly}(1/\epsilon,\log n)$ words.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09773v1</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yinhao Dong, Pan Peng, Ali Vakilian</dc:creator>
    </item>
    <item>
      <title>Fast FPT Algorithms for Grundy Number on Dense Graphs</title>
      <link>https://arxiv.org/abs/2412.10082</link>
      <description>arXiv:2412.10082v1 Announce Type: new 
Abstract: In this paper, we investigate the \textsc{Grundy Coloring} problem for graphs with a cluster modulator, a structure commonly found in dense graphs. The Grundy chromatic number, representing the maximum number of colors needed for the first-fit coloring of a graph in the worst-case vertex ordering, is known to be $W[1]$-hard when parameterized by the number of colors required by the most adversarial ordering. We focus on fixed-parameter tractable (FPT) algorithms for solving this problem on graph classes characterized by dense substructures, specifically those with a cluster modulator. A cluster modulator is a vertex subset whose removal results in a cluster graph (a disjoint union of cliques). We present FPT algorithms for graphs where the cluster graph consists of one, two, or $k$ cliques, leveraging the cluster modulator's properties to achieve the best-known FPT runtimes, parameterized by both the modulator's size and the number of cliques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10082v1</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sina Ghasemi Nezhad, Maryam Moghaddas, Fahad Panolan</dc:creator>
    </item>
    <item>
      <title>Optimal Bounds for Private Minimum Spanning Trees via Input Perturbation</title>
      <link>https://arxiv.org/abs/2412.10130</link>
      <description>arXiv:2412.10130v1 Announce Type: new 
Abstract: We study the problem of privately releasing an approximate minimum spanning tree (MST). Given a graph $G = (V, E, \vec{W})$ where $V$ is a set of $n$ vertices, $E$ is a set of $m$ undirected edges, and $ \vec{W} \in \mathbb{R}^{|E|} $ is an edge-weight vector, our goal is to publish an approximate MST under edge-weight differential privacy, as introduced by Sealfon in PODS 2016, where $V$ and $E$ are considered public and the weight vector is private. Our neighboring relation is $\ell_\infty$-distance on weights: for a sensitivity parameter $\Delta_\infty$, graphs $ G = (V, E, \vec{W}) $ and $ G' = (V, E, \vec{W}') $ are neighboring if $\|\vec{W}-\vec{W}'\|_\infty \leq \Delta_\infty$.
  Existing private MST algorithms face a trade-off, sacrificing either computational efficiency or accuracy. We show that it is possible to get the best of both worlds: With a suitable random perturbation of the input that does not suffice to make the weight vector private, the result of any non-private MST algorithm will be private and achieves a state-of-the-art error guarantee.
  Furthermore, by establishing a connection to Private Top-k Selection [Steinke and Ullman, FOCS '17], we give the first privacy-utility trade-off lower bound for MST under approximate differential privacy, demonstrating that the error magnitude, $\tilde{O}(n^{3/2})$, is optimal up to logarithmic factors. That is, our approach matches the time complexity of any non-private MST algorithm and at the same time achieves optimal error. We complement our theoretical treatment with experiments that confirm the practicality of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10130v1</guid>
      <category>cs.DS</category>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Rasmus Pagh, Lukas Retschmeier, Hao Wu, Hanwen Zhang</dc:creator>
    </item>
    <item>
      <title>Fast and Lightweight Distributed Suffix Array Construction -- First Results</title>
      <link>https://arxiv.org/abs/2412.10160</link>
      <description>arXiv:2412.10160v1 Announce Type: new 
Abstract: We present first algorithmic ideas for a practical and lightweight adaption of the DCX suffix array construction algorithm [Sanders et al., 2003] to the distributed-memory setting. Our approach relies on a bucketing technique which enables a lightweight implementation which uses less than half of the memory required by the currently fastest distributed-memory suffix array algorithm PSAC [Flick and Aluru, 2015] while being competitive or even faster in terms of running time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10160v1</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Manuel Haag, Florian Kurpicz, Peter Sanders, Matthias Schimek</dc:creator>
    </item>
    <item>
      <title>Single-Source Regular Path Querying in Terms of Linear Algebra</title>
      <link>https://arxiv.org/abs/2412.10287</link>
      <description>arXiv:2412.10287v1 Announce Type: new 
Abstract: A given edge-labelled graph two-way regular path queries (2-RPQs) allow one to use regular languages over labelled edges and inverted edges to constraint paths of interest. 2-RPQs are (partially) adopted in different real-world graph analysis systems and are a part of the GQL ISO standard. But the performance of 2-RPQs on real-world graphs is still a bottleneck for wider adoption. A new single-source 2-RPQ algorithm based on linear algebra is proposed. Utilization of high-performance sparse linear algebra libraries for the algorithm implementation allows one to achieve significant speedup over competitors on real-world data and queries. Our implementation demonstrates better performance on average on Wikidata and the respective query log in comparison with MillenniumDB, FalkorDB, and the algorithm of Diego Arroyuelo et al.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10287v1</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Georgiy Belyanin, Semyon Grigoriev</dc:creator>
    </item>
    <item>
      <title>The Correlated Gaussian Sparse Histogram Mechanism</title>
      <link>https://arxiv.org/abs/2412.10357</link>
      <description>arXiv:2412.10357v1 Announce Type: new 
Abstract: We consider the problem of releasing a sparse histogram under $(\varepsilon, \delta)$-differential privacy. The stability histogram independently adds noise from a Laplace or Gaussian distribution to the non-zero entries and removes those noisy counts below a threshold.
  Thereby, the introduction of new non-zero values between neighboring histograms is only revealed with probability at most $\delta$, and typically, the value of the threshold dominates the error of the mechanism. We consider the variant of the stability histogram with Gaussian noise.
  Recent works ([Joseph and Yu, COLT '24] and [Lebeda, SOSA '25]) reduced the error for private histograms using correlated Gaussian noise. However, these techniques can not be directly applied in the very sparse setting. Instead, we adopt Lebeda's technique and show that adding correlated noise to the non-zero counts only allows us to reduce the magnitude of noise when we have a sparsity bound. This, in turn, allows us to use a lower threshold by up to a factor of $1/2$ compared to the non-correlated noise mechanism. We then extend our mechanism to a setting without a known bound on sparsity. Additionally, we show that correlated noise can give a similar improvement for the more practical discrete Gaussian mechanism.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10357v1</guid>
      <category>cs.DS</category>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Christian Janos Lebeda, Lukas Retschmeier</dc:creator>
    </item>
    <item>
      <title>Computational Explorations of Total Variation Distance</title>
      <link>https://arxiv.org/abs/2412.10370</link>
      <description>arXiv:2412.10370v1 Announce Type: new 
Abstract: We investigate some previously unexplored (or underexplored) computational aspects of total variation (TV) distance. First, we give a simple deterministic polynomial-time algorithm for checking equivalence between mixtures of product distributions, over arbitrary alphabets. This corresponds to a special case, whereby the TV distance between the two distributions is zero. Second, we prove that unless $\mathsf{NP} \subseteq \mathsf{RP}$, it is impossible to efficiently estimate the TV distance between arbitrary Ising models, even in a bounded-error randomized setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10370v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arnab Bhattacharyya, Sutanu Gayen, Kuldeep S. Meel, Dimitrios Myrisiotis, A. Pavan, N. V. Vinodchandran</dc:creator>
    </item>
    <item>
      <title>Private Synthetic Data Generation in Small Memory</title>
      <link>https://arxiv.org/abs/2412.09756</link>
      <description>arXiv:2412.09756v1 Announce Type: cross 
Abstract: Protecting sensitive information on data streams is a critical challenge for modern systems. Current approaches to privacy in data streams follow two strategies. The first transforms the stream into a private sequence, enabling the use of non-private analyses but incurring high memory costs. The second uses compact data structures to create private summaries but restricts flexibility to predefined queries.
  To address these limitations, we propose $\textsf{PrivHP}$, a lightweight synthetic data generator that ensures differential privacy while being resource-efficient. $\textsf{PrivHP}$ generates private synthetic data that preserves the input stream's distribution, allowing flexible downstream analyses without additional privacy costs. It leverages a hierarchical decomposition of the domain, pruning low-frequency subdomains while preserving high-frequency ones in a privacy-preserving manner. To achieve memory efficiency in streaming contexts, $\textsf{PrivHP}$ uses private sketches to estimate subdomain frequencies without accessing the full dataset.
  $\textsf{PrivHP}$ is parameterized by a privacy budget $\varepsilon$, a pruning parameter $k$ and the sketch width $w$. It can process a dataset of size $n$ in $\mathcal{O}((w+k)\log (\varepsilon n))$ space, $\mathcal{O}(\log (\varepsilon n))$ update time, and outputs a private synthetic data generator in $\mathcal{O}(k\log k\log (\varepsilon n))$ time. Prior methods require $\Omega(n)$ space and construction time. Our evaluation uses the expected 1-Wasserstein distance between the sampler and the empirical distribution. Compared to state-of-the-art methods, we demonstrate that the additional cost in utility is inversely proportional to $k$ and $w$. This represents the first meaningful trade-off between performance and utility for private synthetic data generation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09756v1</guid>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rayne Holland, Seyit Camtepe, Chandra Thapa, Jason Xue</dc:creator>
    </item>
    <item>
      <title>Deep Learning Service for Efficient Data Distribution Aware Sorting</title>
      <link>https://arxiv.org/abs/1907.08817</link>
      <description>arXiv:1907.08817v4 Announce Type: replace 
Abstract: In this paper, we present a neural network-enabled data distribution aware sorting method, coined as NN-sort. Our approach explores the potential of developing deep learning techniques to speed up large-scale sort operations, enabling data distribution aware sorting as a deep learning service. Compared to traditional pairwise comparison-based sorting algorithms, which sort data elements by performing pairwise operations, NN-sort leverages the neural network model to learn the data distribution and uses it to map large-scale data elements into ordered ones. Our experiments demonstrate the significant advantage of using NN-sort. Measurements on both synthetic and real-world datasets show that NN-sort yields 2.18x to 10x performance improvement over traditional sorting algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:1907.08817v4</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaoke Zhu, Qi Zhang, Wei Zhou, Ling Liu</dc:creator>
    </item>
    <item>
      <title>Online Bipartite Matching in the Probe-Commit Model</title>
      <link>https://arxiv.org/abs/2303.08908</link>
      <description>arXiv:2303.08908v2 Announce Type: replace 
Abstract: We consider the classical online bipartite matching problem in the probe-commit model. In this problem, when an online vertex arrives, its edges must be probed to determine if they exist, based on known edge probabilities. A probing algorithm must respect commitment, meaning that if a probed edge exists, it must be used in the matching. Additionally, each online vertex has a patience constraint which limits the number of probes that can be made to an online vertex's adjacent edges. We introduce a new configuration linear program (LP) which we prove is a relaxation of an optimal offline probing algorithm. Using this LP, we establish the following competitive ratios which depend on the model used to generate the instance graph, and the arrival order of its online vertices:
  - In the worst-case instance model, an optimal $1/e$ ratio when the vertices arrive in uniformly at random (u.a.r.) order.
  - In the known independently distributed (i.d.) instance model, an optimal $1/2$ ratio when the vertices arrive in adversarial order, and a $1-1/e$ ratio when the vertices arrive in u.a.r. order.
  The latter two results improve upon the previous best competitive ratio of $0.46$ due to Brubach et al. (Algorithmica 2020), which only held in the more restricted known i.i.d. (independent and identically distributed) instance model. Our $1-1/e$-competitive algorithm matches the best known result for the prophet secretary matching problem due to Ehsani et al. (SODA 2018). Our algorithm is efficient and implies a $1-1/e$ approximation ratio for the special case when the graph is known. This is the offline stochastic matching problem, and we improve upon the $0.42$ approximation ratio for one-sided patience due to Pollner et al. (EC 2022), while also generalizing the $1-1/e$ approximation ratio for unbounded patience due to Gamlath et al. (SODA 2019).</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.08908v2</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Allan Borodin, Calum MacRury</dc:creator>
    </item>
    <item>
      <title>L'algorithme : pourquoi et comment le d{\'e}finir pour l'enseigner</title>
      <link>https://arxiv.org/abs/2406.04385</link>
      <description>arXiv:2406.04385v2 Announce Type: replace 
Abstract: The question of the definition of what is an algorithm is recurrent. It is found in teaching, at different levels and particularly in secondary education because of the recent evolutions in high school, with immediate consequences in higher education. It is found in mediation, with the different meanings that the word ``algorithm'' is charged with in the media space. It is also found in research, with issues in different branches of computer science, from foundations in computability and complexity to applications in big data. Beyond the issue of definition, it is the raison d'{\^e}tre of the notion of algorithm that should be questioned: what do we want to do with it and what is at stake? It is by trying to specify this that we can identify didactic elements that are likely to help teach the algorithm, in interaction with mathematics or not, and to different audiences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04385v2</guid>
      <category>cs.DS</category>
      <category>math.HO</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Emmanuel Beffara (MeTAH, LIG, IREM)</dc:creator>
    </item>
    <item>
      <title>Optimal Offline ORAM with Perfect Security via Simple Oblivious Priority Queues</title>
      <link>https://arxiv.org/abs/2409.12021</link>
      <description>arXiv:2409.12021v2 Announce Type: replace 
Abstract: Oblivious RAM (ORAM) is a well-researched primitive to hide the memory access pattern of a RAM computation; it has a variety of applications in trusted computing, outsourced storage, and multiparty computation. In this paper, we study the so-called offline ORAM in which the sequence of memory access locations to be hidden is known in advance. Apart from their theoretical significance, offline ORAMs can be used to construct efficient oblivious algorithms.
  We obtain the first optimal offline ORAM with perfect security from oblivious priority queues via time-forward processing. For this, we present a simple construction of an oblivious priority queue with perfect security. Our construction achieves an asymptotically optimal (amortized) runtime of $\Theta(\log N)$ per operation for a capacity of $N$ elements and is of independent interest.
  Building on our construction, we additionally present efficient external-memory instantiations of our oblivious, perfectly-secure construction: For the cache-aware setting, we match the optimal I/O complexity of $\Theta(\frac{1}{B} \log \frac{N}{M})$ per operation (amortized), and for the cache-oblivious setting we achieve a near-optimal I/O complexity of $O(\frac{1}{B} \log \frac{N}{M} \log\log_M N)$ per operation (amortized).</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.12021v2</guid>
      <category>cs.DS</category>
      <category>cs.CR</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4230/LIPIcs.ISAAC.2024.55</arxiv:DOI>
      <arxiv:journal_reference>Thore Thie{\ss}en and Jan Vahrenhold. Optimal offline ORAM with perfect security via simple oblivious priority queues. In 35th International Symposium on Algorithms and Computation (ISAAC 2024), 18 pages. 2024</arxiv:journal_reference>
      <dc:creator>Thore Thie{\ss}en, Jan Vahrenhold</dc:creator>
    </item>
    <item>
      <title>Listing 6-Cycles in Sparse Graphs</title>
      <link>https://arxiv.org/abs/2411.07499</link>
      <description>arXiv:2411.07499v2 Announce Type: replace 
Abstract: This work considers the problem of output-sensitive listing of occurrences of $2k$-cycles for fixed constant $k\geq 2$ in an undirected host graph with $m$ edges and $t$ $2k$-cycles. Recent work of Jin and Xu (and independently Abboud, Khoury, Leibowitz, and Safier) [STOC 2023] gives an $O(m^{4/3}+t)$ time algorithm for listing $4$-cycles, and recent work by Jin, Vassilevska Williams and Zhou [SOSA 2024] gives an $\widetilde{O}(n^2+t)$ time algorithm for listing $6$-cycles in $n$ node graphs. We focus on resolving the next natural question: obtaining listing algorithms for $6$-cycles in the sparse setting, i.e., in terms of $m$ rather than $n$. Previously, the best known result here is the better of Jin, Vassilevska Williams and Zhou's $\widetilde{O}(n^2+t)$ algorithm and Alon, Yuster and Zwick's $O(m^{5/3}+t)$ algorithm.
  We give an algorithm for listing $6$-cycles with running time $\widetilde{O}(m^{1.6}+t)$. Our algorithm is a natural extension of Dahlgaard, Knudsen and St\"ockel's [STOC 2017] algorithm for detecting a $2k$-cycle. Our main technical contribution is the analysis of the algorithm which involves a type of ``supersaturation'' lemma relating the number of $2k$-cycles in a bipartite graph to the sizes of the parts in the bipartition and the number of edges. We also give a simplified analysis of Dahlgaard, Knudsen and St\"ockel's $2k$-cycle detection algorithm (with a small polylogarithmic increase in the running time), which is helpful in analyzing our listing algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07499v2</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Virginia Vassilevska Williams, Alek Westover</dc:creator>
    </item>
    <item>
      <title>Robust Dequantization of the Quantum Singular value Transformation and Quantum Machine Learning Algorithms</title>
      <link>https://arxiv.org/abs/2304.04932</link>
      <description>arXiv:2304.04932v2 Announce Type: replace-cross 
Abstract: Several quantum algorithms for linear algebra problems, and in particular quantum machine learning problems, have been "dequantized" in the past few years. These dequantization results typically hold when classical algorithms can access the data via length-squared sampling. In this work we investigate how robust these dequantization results are. We introduce the notion of approximate length-squared sampling, where classical algorithms are only able to sample from a distribution close to the ideal distribution in total variation distance. While quantum algorithms are natively robust against small perturbations, current techniques in dequantization are not. Our main technical contribution is showing how many techniques from randomized linear algebra can be adapted to work under this weaker assumption as well. We then use these techniques to show that the recent low-rank dequantization framework by Chia, Gily\'en, Li, Lin, Tang and Wang (JACM 2022) and the dequantization framework for sparse matrices by Gharibian and Le Gall (STOC 2022), which are both based on the Quantum Singular Value Transformation, can be generalized to the case of approximate length-squared sampling access to the input. We also apply these results to obtain a robust dequantization of many quantum machine learning algorithms, including quantum algorithms for recommendation systems, supervised clustering and low-rank matrix inversion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.04932v2</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fran\c{c}ois Le Gall</dc:creator>
    </item>
  </channel>
</rss>
