<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.IT</link>
    <description>math.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 16 Aug 2024 04:01:57 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 16 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Simultaneous Information and Energy Transmission with Short Packets and Finite Constellations</title>
      <link>https://arxiv.org/abs/2408.07807</link>
      <description>arXiv:2408.07807v1 Announce Type: new 
Abstract: This paper characterizes the trade-offs between information and energy transmission over an additive white Gaussian noise channel in the finite block-length regime with finite channel input symbols. These trade-offs are characterized in the form of inequalities involving the information transmission rate, energy transmission rate, decoding error probability (DEP) and energy outage probability (EOP) for a given finite block-length code. The first set of results identify the set of necessary conditions that a given code must satisfy for simultaneous information and energy transmission. Following this, a novel method for constructing a family of codes that can satisfy a target information rate, energy rate, DEP and EOP is proposed. Finally, the achievability results identify the set of tuples of information rate, energy rate, DEP and EOP that can be simultaneously achieved by the constructed family of codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07807v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sadaf ul Zuhra, Samir M. Perlaza, H. Vincent Poor, Mikael Skoglund</dc:creator>
    </item>
    <item>
      <title>The Causal Complementation Algorithm for Lifting Factorization of Perfect Reconstruction Multirate Filter Banks</title>
      <link>https://arxiv.org/abs/2408.07970</link>
      <description>arXiv:2408.07970v1 Announce Type: new 
Abstract: An intrinsically causal approach to lifting factorization, called the Causal Complementation Algorithm, is developed for arbitrary two-channel perfect reconstruction FIR filter banks. This addresses an engineering shortcoming of the inherently noncausal strategy of Daubechies and Sweldens for factoring discrete wavelet transforms, which was based on the Extended Euclidean Algorithm for Laurent polynomials. The Causal Complementation Algorithm reproduces all lifting factorizations created by the causal version of the Euclidean Algorithm approach and generates additional causal factorizations, which are not obtainable via the causal Euclidean Algorithm, possessing degree-reducing properties that generalize those furnished by the Euclidean Algorithm. In lieu of the Euclidean Algorithm, the new approach employs Gaussian elimination in matrix polynomials using a slight generalization of polynomial long division. It is shown that certain polynomial degree-reducing conditions are both necessary and sufficient for a causal elementary matrix decomposition to be obtainable using the Causal Complementation Algorithm, yielding a formal definition of ``lifting factorization'' that was missing from the work of Daubechies and Sweldens.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07970v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Christopher M. Brislawn</dc:creator>
    </item>
    <item>
      <title>Joint Message Detection, Channel, and User Position Estimation for Unsourced Random Access in Cell-Free Networks</title>
      <link>https://arxiv.org/abs/2408.08045</link>
      <description>arXiv:2408.08045v1 Announce Type: new 
Abstract: We consider unsourced random access (uRA) in user-centric cell-free (CF) wireless networks, where random access users send codewords from a common codebook during specifically dedicated random access channel (RACH) slots. The system is conceptually similar to the so-called 2-step RACH currently discussed in 3GPP standardization. In order to cope with the distributed and CF nature of the network, we propose to partition the network coverage area into zones (referred to as ''locations'') and assign an uRA codebook to each location, such that users in a certain location make use of the associated codebook. The centralized uRA decoder makes use of the multisource AMP algorithm recently proposed by the authors. This yields at once the list of active uRA codewords, an estimate of the corresponding channel vectors, and an estimate of the active users' position. We show excellent performance of this approach and perfect agreement with the rigorous theoretical ''state evolution'' analysis. We also show that the proposed ''location-based'' partitioned codebook approach significantly outperforms a baseline system with a single non-partitioned uRA codebook.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08045v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eleni Gkiouzepi, Burak \c{C}akmak, Manfred Opper, Giuseppe Caire</dc:creator>
    </item>
    <item>
      <title>A Survey on Integrated Sensing, Communication, and Computation</title>
      <link>https://arxiv.org/abs/2408.08074</link>
      <description>arXiv:2408.08074v1 Announce Type: new 
Abstract: The forthcoming generation of wireless technology, 6G, promises a revolutionary leap beyond traditional data-centric services. It aims to usher in an era of ubiquitous intelligent services, where everything is interconnected and intelligent. This vision requires the seamless integration of three fundamental modules: Sensing for information acquisition, communication for information sharing, and computation for information processing and decision-making. These modules are intricately linked, especially in complex tasks such as edge learning and inference. However, the performance of these modules is interdependent, creating a resource competition for time, energy, and bandwidth. Existing techniques like integrated communication and computation (ICC), integrated sensing and computation (ISC), and integrated sensing and communication (ISAC) have made partial strides in addressing this challenge, but they fall short of meeting the extreme performance requirements. To overcome these limitations, it is essential to develop new techniques that comprehensively integrate sensing, communication, and computation. This integrated approach, known as Integrated Sensing, Communication, and Computation (ISCC), offers a systematic perspective for enhancing task performance. This paper begins with a comprehensive survey of historic and related techniques such as ICC, ISC, and ISAC, highlighting their strengths and limitations. It then explores the state-of-the-art signal designs for ISCC, along with network resource management strategies specifically tailored for ISCC. Furthermore, this paper discusses the exciting research opportunities that lie ahead for implementing ISCC in future advanced networks. By embracing ISCC, we can unlock the full potential of intelligent connectivity, paving the way for groundbreaking applications and services.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08074v1</guid>
      <category>cs.IT</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dingzhu Wen, Yong Zhou, Xiaoyang Li, Yuanming Shi, Kaibin Huang, Khaled B. Letaief</dc:creator>
    </item>
    <item>
      <title>UV-Plane Beam Mapping for Non-Terrestrial Networks in 3GPP System-Level Simulations</title>
      <link>https://arxiv.org/abs/2408.08090</link>
      <description>arXiv:2408.08090v1 Announce Type: new 
Abstract: Due to the high altitudes and large beam sizes of satellites, the curvature of the Earth's surface can impact system-level performance. To consider this, 3GPP introduces the UV-plane beam mapping for system-level simulations of non-terrestrial networks (NTNs). This paper aims to provide a comprehensive understanding of how beams and user equipments (UEs) are placed on the UV-plane and subsequently mapped to the Earth's surface. We present a general process of projecting UEs on the UV-plane onto the Earth's surface. This process could offer a useful guideline for beam and UE deployment when evaluating the system-level performance of NTNs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08090v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dong-Hyun Jung, Sucheol Kim, Miyeon Lee, Joon-Gyu Ryu, Junil Choi</dc:creator>
    </item>
    <item>
      <title>Heterogeneous System Design for Cell-Free Massive MIMO in Wideband Communications</title>
      <link>https://arxiv.org/abs/2408.08132</link>
      <description>arXiv:2408.08132v1 Announce Type: new 
Abstract: Cell-free massive multi-input multi-output (CFmMIMO) offers uniform service quality through distributed access points (APs), yet unresolved issues remain. This paper proposes a heterogeneous system design that goes beyond the original CFmMIMO architecture by exploiting the synergy of a base station (BS) and distributed APs. Users are categorized as near users (NUs) and far users (FUs) depending on their proximity to the BS. The BS serves the NUs, while the APs cater to the FUs. Through activating only the closest AP of each FU, the use of downlink pilots is enabled, thereby enhancing performance. This heterogeneous design outperforms other homogeneous massive MIMO configurations, demonstrating superior sum capacity while maintaining comparable user-experienced rates. Moreover, it lowers the costs associated with AP installations and reduces signaling overhead for the fronthaul network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08132v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Wei Jiang, Hans D. Schotten</dc:creator>
    </item>
    <item>
      <title>The Generating Idempotent Is a Minimum-Weight Codeword for Some Binary BCH Codes</title>
      <link>https://arxiv.org/abs/2408.08218</link>
      <description>arXiv:2408.08218v1 Announce Type: new 
Abstract: In a paper from 2015, Ding et al. (IEEE Trans. IT, May 2015) conjectured that for odd $m$, the minimum distance of the binary BCH code of length $2^m-1$ and designed distance $2^{m-2}+1$ is equal to the Bose distance calculated in the same paper.
  In this paper, we prove the conjecture. In fact, we prove a stronger result: the weight of the generating idempotent is equal to the Bose distance for both odd and even $m$. Our main tools are some new properties of the so-called fibbinary integers, in particular, the splitting field of related polynomials, and the relation of these polynomials to the idempotent of the BCH code.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08218v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yaron Shany, Amit Berman</dc:creator>
    </item>
    <item>
      <title>On the Asymptotic Rate of Optimal Codes that Correct Tandem Duplications for Nanopore Sequencing</title>
      <link>https://arxiv.org/abs/2408.08223</link>
      <description>arXiv:2408.08223v1 Announce Type: new 
Abstract: We study codes that can correct backtracking errors during nanopore sequencing. In this channel, a sequence of length $n$ over an alphabet of size $q$ is being read by a sliding window of length $\ell$, where from each window we obtain only its composition. Backtracking errors cause some windows to repeat, hence manifesting as tandem-duplication errors of length $k$ in the $\ell$-read vector of window compositions. While existing constructions for duplication-correcting codes can be straightforwardly adapted to this model, even resulting in optimal codes, their asymptotic rate is hard to find. In the regime of unbounded number of duplication errors, we either give the exact asymptotic rate of optimal codes, or bounds on it, depending on the values of $k$, $\ell$ and $q$. In the regime of a constant number of duplication errors, $t$, we find the redundancy of optimal codes to be $t\log_q n+O(1)$ when $\ell|k$, and only upper bounded by this quantity otherwise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08223v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenjun Yu, Zuo Ye, Moshe Schwartz</dc:creator>
    </item>
    <item>
      <title>Strong Data Processing Inequalities and their Applications to Reliable Computation</title>
      <link>https://arxiv.org/abs/2408.08239</link>
      <description>arXiv:2408.08239v1 Announce Type: new 
Abstract: In 1952, von Neumann gave a series of groundbreaking lectures that proved it was possible for circuits consisting of 3-input majority gates that have a sufficiently small independent probability $\delta &gt; 0$ of malfunctioning to reliably compute Boolean functions. In 1999, Evans and Schulman used a strong data-processing inequality (SDPI) to establish the tightest known necessary condition $\delta &lt; \frac{1}{2} - \frac{1}{2\sqrt{k}}$ for reliable computation when the circuit consists of components that have at most $k$ inputs. In 2017, Polyanskiy and Wu distilled Evans and Schulman's SDPI argument to establish a general result on the contraction of mutual information in Bayesian networks.
  In this essay, we will first introduce the problem of reliable computation from unreliable components and establish the existence of noise thresholds. We will then provide an exposition of von Neumann's result with 3-input majority gates and extend it to minority gates. We will then provide an introduction to SDPIs, which have many applications, including in statistical mechanics, portfolio theory, and lower bounds on statistical estimation under privacy constraints. We will then use the introduced material to provide an exposition of Polyanskiy and Wu's 2017 result on Bayesian networks, from which the 1999 result of Evans-Schulman follows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08239v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Andrew K. Yang</dc:creator>
    </item>
    <item>
      <title>Hybrid Semantic/Bit Communication Based Networking Problem Optimization</title>
      <link>https://arxiv.org/abs/2408.07820</link>
      <description>arXiv:2408.07820v1 Announce Type: cross 
Abstract: Semantic communication (SemCom) has recently shown great potential in significant resource savings and efficient information exchanges, thus naturally introducing a novel and practical next-generation cellular network paradigm where two modes of SemCom and conventional bit communication (BitCom) coexist, namely hybrid semantic/bit communication network (HSB-Net). Nevertheless, the pertinent wireless resource management issue becomes rather complicated and challenging, especially considering the unique background knowledge matching and time-consuming semantic coding requirements in SemCom. To this end, this paper jointly investigates user association (UA), mode selection (MS), and bandwidth allocation (BA) problems in the uplink of HSB-Net. Concretely, we first identify a unified performance metric of message throughput for both SemCom and BitCom links. Next, we comprehensively develop a knowledge matching-aware two-stage tandem packet queuing model and theoretically derive the average packet loss ratio and queuing latency. Combined with several practical constraints, we then formulate a joint optimization problem for UA, MS, and BA to maximize the overall message throughput of HSB-Net. Afterward, we propose an optimal resource management strategy by employing a Lagrange primal-dual method and devising a preference list-based heuristic algorithm. Finally, numerical results validate the performance superiority of our proposed strategy compared with different benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07820v1</guid>
      <category>cs.NI</category>
      <category>cs.IT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Le Xia, Yao Sun, Dusit Niyato, Lan Zhang, Lei Zhang, Muhammad Ali Imran</dc:creator>
    </item>
    <item>
      <title>Small error algorithms for tropical group testing</title>
      <link>https://arxiv.org/abs/2309.07264</link>
      <description>arXiv:2309.07264v2 Announce Type: replace 
Abstract: We consider a version of the classical group testing problem motivated by PCR testing for COVID-19. In the so-called tropical group testing model, the outcome of a test is the lowest cycle threshold (Ct) level of the individuals pooled within it, rather than a simple binary indicator variable. We introduce the tropical counterparts of three classical non-adaptive algorithms (COMP, DD and SCOMP), and analyse their behaviour through both simulations and bounds on error probabilities. By comparing the results of the tropical and classical algorithms, we gain insight into the extra information provided by learning the outcomes (Ct levels) of the tests. We show that in a limiting regime the tropical COMP algorithm requires as many tests as its classical counterpart, but that for sufficiently dense problems tropical DD can recover more information with fewer tests, and can be viewed as essentially optimal in certain regimes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.07264v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vivekanand Paligadu, Oliver Johnson, Matthew Aldridge</dc:creator>
    </item>
    <item>
      <title>On the Impact of Uncertainty and Calibration on Likelihood-Ratio Membership Inference Attacks</title>
      <link>https://arxiv.org/abs/2402.10686</link>
      <description>arXiv:2402.10686v2 Announce Type: replace 
Abstract: In a membership inference attack (MIA), an attacker exploits the overconfidence exhibited by typical machine learning models to determine whether a specific data point was used to train a target model. In this paper, we analyze the performance of the state-of-the-art likelihood ratio attack (LiRA) within an information-theoretical framework that allows the investigation of the impact of the aleatoric uncertainty in the true data generation process, of the epistemic uncertainty caused by a limited training data set, and of the calibration level of the target model. We compare three different settings, in which the attacker receives decreasingly informative feedback from the target model: confidence vector (CV) disclosure, in which the output probability vector is released; true label confidence (TLC) disclosure, in which only the probability assigned to the true label is made available by the model; and decision set (DS) disclosure, in which an adaptive prediction set is produced as in conformal prediction. We derive bounds on the advantage of an MIA adversary with the aim of offering insights into the impact of uncertainty and calibration on the effectiveness of MIAs. Simulation results demonstrate that the derived analytical bounds predict well the effectiveness of MIAs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.10686v2</guid>
      <category>cs.IT</category>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Meiyi Zhu, Caili Guo, Chunyan Feng, Osvaldo Simeone</dc:creator>
    </item>
    <item>
      <title>Josephson oscillations of two weakly coupled Bose-Einstein condensates</title>
      <link>https://arxiv.org/abs/2407.06208</link>
      <description>arXiv:2407.06208v2 Announce Type: replace-cross 
Abstract: A numerical experiment based on a particle number-conserving quantum field theory is performed for two initially independent Bose-Einstein condensates that are coherently coupled at two temperatures. The present model illustrates ab initio that the initial phase of each of the two condensates doesn't remain random at the Boltzmann equilibrium, but is distributed around integer multiple values of $2\pi$ from the interference and thermalization of forward and backward propagating matter waves. The thermalization inside the atomic vapors can be understood as an intrinsic measurement process that defines a temperature for the two condensates and projects the quantum states to an average wave field with zero (relative) phases. Following this approach, focus is put on the original thought experiment of Anderson on whether a Josephson current between two initially separated Bose-Einstein condensates occurs in a deterministic way or not, depending on the initial phase distribution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06208v2</guid>
      <category>cond-mat.quant-gas</category>
      <category>cond-mat.supr-con</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>quant-ph</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.12743/quanta.v13i1.266</arxiv:DOI>
      <arxiv:journal_reference>Quanta 13, 28-37 (2024)</arxiv:journal_reference>
      <dc:creator>Dr. Alexej Schelle</dc:creator>
    </item>
  </channel>
</rss>
