<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DB updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DB</link>
    <description>cs.DB updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DB" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 28 Feb 2025 05:00:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Fair and Actionable Causal Prescription Ruleset</title>
      <link>https://arxiv.org/abs/2502.19846</link>
      <description>arXiv:2502.19846v1 Announce Type: new 
Abstract: Prescriptions, or actionable recommendations, are commonly generated across various fields to influence key outcomes such as improving public health, enhancing economic policies, or increasing business efficiency. While traditional association-based methods may identify correlations, they often fail to reveal the underlying causal factors needed for informed decision-making. On the other hand, in decision-making for tasks with significant societal or economic impact, it is crucial to provide recommendations that are justifiable and equitable in terms of the outcome for both the protected and non-protected groups. Motivated by these two goals, this paper introduces a fairness-aware framework leveraging causal reasoning for generating a set of actionable prescription rules (ruleset) toward betterment of an outcome while preventing exacerbating inequalities for protected groups. By considering group and individual fairness metrics from the literature, we ensure that both protected and non-protected groups benefit from these recommendations, providing a balanced and equitable approach to decision-making. We employ efficient optimizations to explore the vast and complex search space considering both fairness and coverage of the ruleset. Empirical evaluation and case study on real-world datasets demonstrates the utility of our framework for different use cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.19846v1</guid>
      <category>cs.DB</category>
      <pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Benton Li, Nativ Levy, Brit Youngmann, Sainyam Galhotra, Sudeepa Roy</dc:creator>
    </item>
    <item>
      <title>Selective Use of Yannakakis' Algorithm to Improve Query Performance: Machine Learning to the Rescue</title>
      <link>https://arxiv.org/abs/2502.20233</link>
      <description>arXiv:2502.20233v1 Announce Type: new 
Abstract: Query optimization has played a central role in database research for decades. However, more often than not, the proposed optimization techniques lead to a performance improvement in some, but not in all, situations. Therefore, we urgently need a methodology for designing a decision procedure that decides for a given query whether the optimization technique should be applied or not.
  In this work, we propose such a methodology with a focus on Yannakakis-style query evaluation as our optimization technique of interest. More specifically, we formulate this decision problem as an algorithm selection problem and we present a Machine Learning based approach for its solution. Empirical results with several benchmarks on a variety of database systems show that our approach indeed leads to a statistically significant performance improvement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20233v1</guid>
      <category>cs.DB</category>
      <category>cs.AI</category>
      <pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Daniela B\"ohm, Georg Gottlob, Matthias Lanzinger, Davide Longo, Cem Okulmus, Reinhard Pichler, Alexander Selzer</dc:creator>
    </item>
    <item>
      <title>Mixtera: A Data Plane for Foundation Model Training</title>
      <link>https://arxiv.org/abs/2502.19790</link>
      <description>arXiv:2502.19790v1 Announce Type: cross 
Abstract: State-of-the-art large language and vision models are trained over trillions of tokens that are aggregated from a large variety of sources. As training data collections grow, manually managing the samples becomes time-consuming, tedious, and prone to errors. Yet recent research shows that the data mixture and the order in which samples are visited during training can significantly influence model accuracy. We build and present Mixtera, a data plane for foundation model training that enables users to declaratively express which data samples should be used in which proportion and in which order during training. Mixtera is a centralized, read-only layer that is deployed on top of existing training data collections and can be declaratively queried. It operates independently of the filesystem structure and supports mixtures across arbitrary properties (e.g., language, source dataset) as well as dynamic adjustment of the mixture based on model feedback. We experimentally evaluate Mixtera and show that our implementation does not bottleneck training and scales to 256 GH200 superchips. We demonstrate how Mixtera supports recent advancements in mixing strategies by implementing the proposed Adaptive Data Optimization (ADO) algorithm in the system and evaluating its performance impact. We also explore the role of mixtures for vision-language models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.19790v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DB</category>
      <pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maximilian B\"other, Xiaozhe Yao, Tolga Kerimoglu, Ana Klimovic</dc:creator>
    </item>
    <item>
      <title>A Universal Scheme for Dynamic Partitioned Shortest Path Index: Survey, Improvement, and Experiments</title>
      <link>https://arxiv.org/abs/2310.08213</link>
      <description>arXiv:2310.08213v3 Announce Type: replace 
Abstract: Shortest Path (SP) computation is a fundamental operation in many real-life applications such as navigation on road networks, link analysis on social networks, etc. These networks tend to be massive, and graph partitioning is commonly leveraged to scale up the SP algorithms. However, the Partitioned Shortest Path (PSP) index has never been systematically investigated. Moreover, few studies have explored its index maintenance in dynamic networks. In this paper, we survey the dynamic PSP index and propose a universal scheme for its design and analysis. Specifically, we first review the SP algorithms and put forward a novel structure-based partition method classification to facilitate the selection of partition methods. Furthermore, we summarize the existing Pre-boundary PSP strategy and propose two novel strategies (No-boundary and Post-boundary) to improve its index performance. Lastly, we propose a universal scheme with three dimensions (SP algorithm, partition method, and PSP strategy) to facilitate the analysis and design of the PSP index. Based on this scheme, we put forward five new PSP indexes with a prominent query or update efficiency performance. Extensive experiments are conducted to evaluate the performance of the PSP index and the effectiveness of the proposed techniques, with valuable guidance on the PSP index design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.08213v3</guid>
      <category>cs.DB</category>
      <pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Mengxuan Zhang, Xinjie Zhou, Lei Li, Ziyi Liu, Goce Trajcevski, Yan Huang, Xiaofang Zhou</dc:creator>
    </item>
    <item>
      <title>Distinctiveness Maximization in Datasets Assemblage</title>
      <link>https://arxiv.org/abs/2401.00659</link>
      <description>arXiv:2401.00659v4 Announce Type: replace 
Abstract: In this paper, given a user's query set and budget, we aim to use the limited budget to help users assemble a set of datasets that can enrich a base dataset by introducing the maximum number of distinct tuples (i.e., maximizing distinctiveness). We prove this problem to be NP-hard. A greedy algorithm using exact distinctiveness computation attains an approximation ratio of (1-1/e)/2, but it lacks efficiency and scalability due to its frequent computation of the exact distinctiveness marginal gain of any candidate dataset for selection. This requires scanning through every tuple in candidate datasets and thus is unaffordable in practice. To overcome this limitation, we propose an efficient machine learning (ML)-based method for estimating the distinctiveness marginal gain of any candidate dataset. This effectively eliminates the need to test each tuple individually. Estimating the distinctiveness marginal gain of a dataset involves estimating the number of distinct tuples in the tuple sets returned by each query in a query set across multiple datasets. This can be viewed as the cardinality estimation for a query set on a set of datasets, and the proposed method is the first to tackle this cardinality estimation problem. This is a significant advancement over prior methods that were limited to single-query cardinality estimation on a single dataset and struggled with identifying overlaps among tuple sets returned by each query in a query set across multiple datasets. Extensive experiments using five real-world data pools demonstrate that our algorithm, which utilizes ML-based distinctiveness estimation, outperforms all relevant baselines in effectiveness, efficiency, and scalability. A case study on two downstream ML tasks also highlights its potential to find datasets with more useful tuples to enhance the performance of ML tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.00659v4</guid>
      <category>cs.DB</category>
      <pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tingting Wang, Shixun Huang, Zhifeng Bao, J. Shane Culpepper, Volkan Dedeoglu, Reza Arablouei</dc:creator>
    </item>
    <item>
      <title>Computing Inconsistency Measures Under Differential Privacy</title>
      <link>https://arxiv.org/abs/2502.11009</link>
      <description>arXiv:2502.11009v2 Announce Type: replace 
Abstract: Assessing data quality is crucial to knowing whether and how to use the data for different purposes. Specifically, given a collection of integrity constraints, various ways have been proposed to quantify the inconsistency of a database. Inconsistency measures are particularly important when we wish to assess the quality of private data without revealing sensitive information. We study the estimation of inconsistency measures for a database protected under Differential Privacy (DP). Such estimation is nontrivial since some measures intrinsically query sensitive information, and the computation of others involves functions on underlying sensitive data. Among five inconsistency measures that have been proposed in recent work, we identify that two are intractable in the DP setting. The major challenge for the other three is high sensitivity: adding or removing one tuple from the dataset may significantly affect the outcome. To mitigate that, we model the dataset using a conflict graph and investigate private graph statistics to estimate these measures. The proposed machinery includes adapting graph-projection techniques with parameter selection optimizations on the conflict graph and a DP variant of approximate vertex cover size. We experimentally show that we can effectively compute DP estimates of the three measures on five real-world datasets with denial constraints, where the density of the conflict graphs highly varies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11009v2</guid>
      <category>cs.DB</category>
      <pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shubhankar Mohapatra, Amir Gilad, Xi He, Benny Kimelfeld</dc:creator>
    </item>
    <item>
      <title>ExaLogLog: Space-Efficient and Practical Approximate Distinct Counting up to the Exa-Scale</title>
      <link>https://arxiv.org/abs/2402.13726</link>
      <description>arXiv:2402.13726v2 Announce Type: replace-cross 
Abstract: This work introduces ExaLogLog, a new data structure for approximate distinct counting, which has the same practical properties as the popular HyperLogLog algorithm. It is commutative, idempotent, mergeable, reducible, has a constant-time insert operation, and supports distinct counts up to the exa-scale. At the same time, as theoretically derived and experimentally verified, it requires 43% less space to achieve the same estimation error.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.13726v2</guid>
      <category>cs.DS</category>
      <category>cs.DB</category>
      <pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Otmar Ertl</dc:creator>
    </item>
  </channel>
</rss>
