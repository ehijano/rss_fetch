<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.PE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.PE</link>
    <description>q-bio.PE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.PE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 30 Jul 2024 04:00:54 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 30 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A consistent least-squares criterion for calibrating edge lengths in phylogenetic networks</title>
      <link>https://arxiv.org/abs/2407.19343</link>
      <description>arXiv:2407.19343v1 Announce Type: new 
Abstract: In phylogenetic networks, it is desirable to estimate edge lengths in substitutions per site or calendar time. Yet, there is a lack of scalable methods that provide such estimates. Here we consider the problem of obtaining edge length estimates from genetic distances, in the presence of rate variation across genes and lineages, when the network topology is known. We propose a novel criterion based on least-squares that is both consistent and computationally tractable. The crux of our approach is to decompose the genetic distances into two parts, one of which is invariant across displayed trees of the network. The scaled genetic distances are then fitted to the invariant part, while the average scaled genetic distances are fitted to the non-invariant part. We show that this criterion is consistent provided that there exists a tree path between some pair of tips in the network, and that edge lengths in the network are identifiable from average distances. We also provide a constrained variant of this criterion assuming a molecular clock, which can be used to obtain relative edge lengths in calendar time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.19343v1</guid>
      <category>q-bio.PE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jingcheng Xu, C\'ecile An\'e</dc:creator>
    </item>
    <item>
      <title>The $B_2$ index of galled trees</title>
      <link>https://arxiv.org/abs/2407.19454</link>
      <description>arXiv:2407.19454v1 Announce Type: new 
Abstract: In recent years, there has been an effort to extend the classical notion of phylogenetic balance, originally defined in the context of trees, to networks. One of the most natural ways to do this is with the so-called $B_2$ index. In this paper, we study the $B_2$ index for a prominent class of phylogenetic networks: galled trees. We show that the $B_2$ index of a uniform leaf-labeled galled tree converges in distribution as the network becomes large. We characterize the corresponding limiting distribution, and show that its expected value is 2.707911858984... This is the first time that a balance index has been studied to this level of detail for a random phylogenetic network.
  One specificity of this work is that we use two different and independent approaches, each with its advantages: analytic combinatorics, and local limits. The analytic combinatorics approach is more direct, as it relies on standard tools; but it involves slightly more complex calculations. Because it has not previously been used to study such questions, the local limit approach requires developing an extensive framework beforehand; however, this framework is interesting in itself and can be used to tackle other similar problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.19454v1</guid>
      <category>q-bio.PE</category>
      <category>math.CO</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fran\c{c}ois Bienvenu, Jean-Jil Duchamps, Michael Fuchs, Tsan-Cheng Yu</dc:creator>
    </item>
    <item>
      <title>The evolution of cooperation with Q-learning: the impact of information perception</title>
      <link>https://arxiv.org/abs/2407.19634</link>
      <description>arXiv:2407.19634v1 Announce Type: new 
Abstract: The inherent huge complexities in human beings show a remarkable diversity in response to complex surroundings, enabling us to tackle problems from different perspectives. In the realm of cooperation studies, however, existing work assumes that individuals get access to the same kind of information to make their decisions, in contrast to the facts that individuals often perceive differently. Here, within the reinforcement learning framework, we investigate the impact of information perception on the evolution of cooperation in a 2-person scenario when playing the prisoner's dilemma game. We demonstrate that distinctly different evolution processes are observed in three information perception scenarios, revealing that the structure of information significantly affects the emergence of cooperation. Notably, the asymmetric information scenario exhibits a rich dynamical process, including the cooperation emergence, breakdown, and reconstruction, akin to psychological changes in humans. Our findings indicate that the information structure is vital to the emergence of cooperation, shedding new light on establishing mutually stable cooperative relationships and understanding human behavioral complexities in general.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.19634v1</guid>
      <category>q-bio.PE</category>
      <category>cond-mat.stat-mech</category>
      <category>nlin.AO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guozhong Zheng, Zhenwei Ding, Jiqiang Zhang, Shengfeng Deng, Weiran Cai, Li Chen</dc:creator>
    </item>
    <item>
      <title>Evolution of cooperation in the public goods game with Q-learning</title>
      <link>https://arxiv.org/abs/2407.19851</link>
      <description>arXiv:2407.19851v1 Announce Type: new 
Abstract: Recent paradigm shifts from imitation learning to reinforcement learning (RL) is shown to be productive in understanding human behaviors. In the RL paradigm, individuals search for optimal strategies through interaction with the environment to make decisions. This implies that gathering, processing, and utilizing information from their surroundings are crucial. However, existing studies typically study pairwise games such as the prisoners' dilemma and employ a self-regarding setup, where individuals play against one opponent based solely on their own strategies, neglecting the environmental information. In this work, we investigate the evolution of cooperation with the multiplayer game -- the public goods game using the Q-learning algorithm by leveraging the environmental information. Specifically, the decision-making of players is based upon the cooperation information in their neighborhood. Our results show that cooperation is more likely to emerge compared to the case of imitation learning by using Fermi rule. Of particular interest is the observation of an anomalous non-monotonic dependence which is revealed when voluntary participation is further introduced. The analysis of the Q-table explains the mechanisms behind the cooperation evolution. Our findings indicate the fundamental role of environment information in the RL paradigm to understand the evolution of cooperation, and human behaviors in general.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.19851v1</guid>
      <category>q-bio.PE</category>
      <category>cond-mat.stat-mech</category>
      <category>nlin.AO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guozhong Zheng, Jiqiang Zhang, Shengfeng Deng, Weiran Cai, Li Chen</dc:creator>
    </item>
    <item>
      <title>Flusion: Integrating multiple data sources for accurate influenza predictions</title>
      <link>https://arxiv.org/abs/2407.19054</link>
      <description>arXiv:2407.19054v1 Announce Type: cross 
Abstract: Over the last ten years, the US Centers for Disease Control and Prevention (CDC) has organized an annual influenza forecasting challenge with the motivation that accurate probabilistic forecasts could improve situational awareness and yield more effective public health actions. Starting with the 2021/22 influenza season, the forecasting targets for this challenge have been based on hospital admissions reported in the CDC's National Healthcare Safety Network (NHSN) surveillance system. Reporting of influenza hospital admissions through NHSN began within the last few years, and as such only a limited amount of historical data are available for this signal. To produce forecasts in the presence of limited data for the target surveillance system, we augmented these data with two signals that have a longer historical record: 1) ILI+, which estimates the proportion of outpatient doctor visits where the patient has influenza; and 2) rates of laboratory-confirmed influenza hospitalizations at a selected set of healthcare facilities. Our model, Flusion, is an ensemble that combines gradient boosting quantile regression models with a Bayesian autoregressive model. The gradient boosting models were trained on all three data signals, while the autoregressive model was trained on only the target signal; all models were trained jointly on data for multiple locations. Flusion was the top-performing model in the CDC's influenza prediction challenge for the 2023/24 season. In this article we investigate the factors contributing to Flusion's success, and we find that its strong performance was primarily driven by the use of a gradient boosting model that was trained jointly on data from multiple surveillance signals and locations. These results indicate the value of sharing information across locations and surveillance signals, especially when doing so adds to the pool of available training data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.19054v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>q-bio.PE</category>
      <category>stat.AP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Evan L. Ray, Yijin Wang, Russell D. Wolfinger, Nicholas G. Reich</dc:creator>
    </item>
    <item>
      <title>Does Gaia Play Dice? : Simple Models of non-Darwinian Selection</title>
      <link>https://arxiv.org/abs/2301.02623</link>
      <description>arXiv:2301.02623v2 Announce Type: replace 
Abstract: In this paper we introduce some simple models, based on rolling dice, to explore mechanisms proposed to explain planetary habitability. The idea is to study these selection mechanisms in an analytically tractable setting, isolating their consequences from other details which can confound or obscure their effect in more realistic models. We find that while the observable of interest, the face value shown on the die, `improves' over time in all models, for two of the more popular ideas, Selection by Survival and Sequential Selection, this is down to sampling effects. A modified version of Sequential Selection, Sequential Selection with Memory, implies a statistical tendency for systems to improve over time. We discuss the implications of this and its relationship to the ideas of the `Inhabitance Paradox' and the `Gaian bottleneck'.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.02623v2</guid>
      <category>q-bio.PE</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rudy Arthur, Arwen Nicholson</dc:creator>
    </item>
    <item>
      <title>Cost optimisation of individual-based institutional reward incentives for promoting cooperation in finite populations</title>
      <link>https://arxiv.org/abs/2402.07663</link>
      <description>arXiv:2402.07663v3 Announce Type: replace 
Abstract: In this paper, we study the problem of cost optimisation of individual-based institutional incentives (reward, punishment, and hybrid) for guaranteeing a certain minimal level of cooperative behaviour in a well-mixed, finite population. In this scheme, the individuals in the population interact via cooperation dilemmas (Donation Game or Public Goods Game) in which institutional reward is carried out only if cooperation is not abundant enough (i.e., the number of cooperators is below a threshold $1\leq t\leq N-1$, where $N$ is the population size); and similarly, institutional punishment is carried out only when defection is too abundant. We study analytically the cases $t=1$ for the reward incentive under the small mutation limit assumption and two different initial states, showing that the cost function is always non-decreasing. We derive the neutral drift and strong selection limits when the intensity of selection tends to zero and infinity, respectively. We numerically investigate the problem for other values of $t$ and for population dynamics with arbitrary mutation rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.07663v3</guid>
      <category>q-bio.PE</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>M. H. Duong, C. M. Durbac, T. A. Han</dc:creator>
    </item>
  </channel>
</rss>
