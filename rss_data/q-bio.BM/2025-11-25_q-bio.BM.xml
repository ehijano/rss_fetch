<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.BM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.BM</link>
    <description>q-bio.BM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.BM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 25 Nov 2025 05:08:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>EscalNet: Learn isotropic representation space for biomolecular dynamics based on effective energy</title>
      <link>https://arxiv.org/abs/2511.18010</link>
      <description>arXiv:2511.18010v1 Announce Type: new 
Abstract: Deep learning has emerged as a powerful framework for analyzing biomolecular dynamics trajectories, enabling efficient representations that capture essential system dynamics and facilitate mechanistic studies. We propose a neural network architecture incorporating Fourier Transform analysis to process trajectory data, achieving dual objectives: eliminating high-frequency noise while preserving biologically critical slow conformational dynamics, and establishing an isotropic representation space through the last hidden layer for enhanced dynamical quantification. Comparative protein simulations demonstrate our approach generates more uniform feature distributions than linear regression methods, evidenced by smoother state similarity matrices and clearer classification boundaries. Moreover, by using saliency score, we identified key structural determinants linked to effective energy landscapes governing system dynamics. We believe that the fusion of neural network features with physical order parameters creates a robust analytical framework for advancing biomolecular trajectory analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.18010v1</guid>
      <category>q-bio.BM</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Guanghong Zuo</dc:creator>
    </item>
    <item>
      <title>A universal phase-plane model for in vivo protein aggregation</title>
      <link>https://arxiv.org/abs/2511.18893</link>
      <description>arXiv:2511.18893v1 Announce Type: new 
Abstract: Neurodegenerative diseases are driven by the accumulation of protein aggregates in the brain of affected individuals. The aggregation behaviour in vitro is well understood and driven by the equilibration of a super-saturated protein solution to its aggregated equilibrium state. However, the situation is altered fundamentally in living systems where active processes consume energy to remove aggregates. It remains unclear how and why cells transition from a state with predominantly monomeric protein, which is stable over decades, to one dominated by aggregates. Here, we develop a simple but universal theoretical framework to describe cellular systems that include both aggregate formation and removal. Using a two-dimensional phase-plane representation, we show that the interplay of aggregate formation and removal generates cell-level bistability, with a bifurcation structure that explains both the emergence of disease and the effects of therapeutic interventions. We explore a wide range of aggregate formation and removal mechanisms and show that phenomena such as seeding arise robustly when a minimal set of requirements on the mechanism are satisfied. By connecting in vitro aggregation mechanisms to changes in cell state, our framework provides a general conceptual link between molecular-level therapeutic interventions and their impact on disease progression.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.18893v1</guid>
      <category>q-bio.BM</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matthew W. Cotton, Alain Goriely, David Klenerman, Georg Meisl</dc:creator>
    </item>
    <item>
      <title>Torsion-Space Diffusion for Protein Backbone Generation with Geometric Refinement</title>
      <link>https://arxiv.org/abs/2511.19184</link>
      <description>arXiv:2511.19184v1 Announce Type: new 
Abstract: Designing new protein structures is fundamental to computational biology, enabling advances in therapeutic molecule discovery and enzyme engineering. Existing diffusion-based generative models typically operate in Cartesian coordinate space, where adding noise disrupts strict geometric constraints such as fixed bond lengths and angles, often producing physically invalid structures. To address this limitation, we propose a Torsion-Space Diffusion Model that generates protein backbones by denoising torsion angles, ensuring perfect local geometry by construction. A differentiable forward-kinematics module reconstructs 3D coordinates with fixed 3.8 Angstrom backbone bond lengths while a constrained post-processing refinement optimizes global compactness via Radius of Gyration (Rg) correction, without violating bond constraints. Experiments on standard PDB proteins demonstrate 100% bond-length accuracy and significantly improved structural compactness, reducing Rg error from 70% to 18.6% compared to Cartesian diffusion baselines. Overall, this hybrid torsion-diffusion plus geometric-refinement framework generates physically valid and compact protein backbones, providing a promising path toward full-atom protein generation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.19184v1</guid>
      <category>q-bio.BM</category>
      <category>cs.AI</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lakshaditya Singh, Adwait Shelke, Divyansh Agrawal</dc:creator>
    </item>
    <item>
      <title>RTMol: Rethinking Molecule-text Alignment in a Round-trip View</title>
      <link>https://arxiv.org/abs/2511.12135</link>
      <description>arXiv:2511.12135v2 Announce Type: cross 
Abstract: Aligning molecular sequence representations (e.g., SMILES notations) with textual descriptions is critical for applications spanning drug discovery, materials design, and automated chemical literature analysis. Existing methodologies typically treat molecular captioning (molecule-to-text) and text-based molecular design (text-to-molecule) as separate tasks, relying on supervised fine-tuning or contrastive learning pipelines. These approaches face three key limitations: (i) conventional metrics like BLEU prioritize linguistic fluency over chemical accuracy, (ii) training datasets frequently contain chemically ambiguous narratives with incomplete specifications, and (iii) independent optimization of generation directions leads to bidirectional inconsistency. To address these issues, we propose RTMol, a bidirectional alignment framework that unifies molecular captioning and text-to-SMILES generation through self-supervised round-trip learning. The framework introduces novel round-trip evaluation metrics and enables unsupervised training for molecular captioning without requiring paired molecule-text corpora. Experiments demonstrate that RTMol enhances bidirectional alignment performance by up to 47% across various LLMs, establishing an effective paradigm for joint molecule-text understanding and generation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.12135v2</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>q-bio.BM</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Letian Chen, Runhan Shi, Gufeng Yu, Yang Yang</dc:creator>
    </item>
    <item>
      <title>Interpreting GFlowNets for Drug Discovery: Extracting Actionable Insights for Medicinal Chemistry</title>
      <link>https://arxiv.org/abs/2511.19264</link>
      <description>arXiv:2511.19264v1 Announce Type: cross 
Abstract: Generative Flow Networks, or GFlowNets, offer a promising framework for molecular design, but their internal decision policies remain opaque. This limits adoption in drug discovery, where chemists require clear and interpretable rationales for proposed structures. We present an interpretability framework for SynFlowNet, a GFlowNet trained on documented chemical reactions and purchasable starting materials that generates both molecules and the synthetic routes that produce them. Our approach integrates three complementary components. Gradient based saliency combined with counterfactual perturbations identifies which atomic environments influence reward and how structural edits change molecular outcomes. Sparse autoencoders reveal axis aligned latent factors that correspond to physicochemical properties such as polarity, lipophilicity, and molecular size. Motif probes show that functional groups including aromatic rings and halogens are explicitly encoded and linearly decodable from the internal embeddings. Together, these results expose the chemical logic inside SynFlowNet and provide actionable and mechanistic insight that supports transparent and controllable molecular design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.19264v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>q-bio.BM</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amirtha Varshini A S, Duminda S. Ranasinghe, Hok Hei Tam</dc:creator>
    </item>
    <item>
      <title>Mathematical Insights into Protein Architecture: Persistent Homology and Machine Learning Applied to the Flagellar Motor</title>
      <link>https://arxiv.org/abs/2504.16941</link>
      <description>arXiv:2504.16941v3 Announce Type: replace 
Abstract: We present a machine learning approach that leverages persistent homology to classify bacterial flagellar motors into two functional states: rotated and stalled. By embedding protein structural data into a topological framework, we extract multiscale features from filtered simplicial complexes constructed over atomic coordinates. These topological invariants, specifically persistence diagrams and barcodes, capture critical geometric and connectivity patterns that correlate with motor function. The extracted features are vectorized and integrated into a machine learning pipeline that includes dimensionality reduction and supervised classification. Applied to a curated dataset of experimentally characterized flagellar motors from diverse bacterial species, our model demonstrates high classification accuracy and robustness to structural variation. This approach highlights the power of topological data analysis in revealing functionally relevant patterns beyond the reach of traditional geometric descriptors, offering a novel computational tool for protein function prediction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16941v3</guid>
      <category>q-bio.BM</category>
      <category>cs.LG</category>
      <category>math.AT</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zakaria Lamine, Abdelatif Hafid, Mohamed Rahouti, My Ismail Mamouni</dc:creator>
    </item>
    <item>
      <title>Gradient Propagation in Retrosynthetic Space: An Efficient Framework for Synthesis Plan Generation</title>
      <link>https://arxiv.org/abs/2405.16123</link>
      <description>arXiv:2405.16123v2 Announce Type: replace-cross 
Abstract: Retrosynthesis, which aims to identify viable synthetic pathways for target molecules by decomposing them into simpler precursors, is often treated as a search problem. However, its complexity arises from multi-branched tree-structured pathways rather than linear paths. Some algorithms have been successfully applied in this task, but they either overlook the uncertainties inherent in chemical space or face limitations in practical application scenarios. To address these challenges, this paper introduces a novel gradient-propagation-based algorithmic framework for retrosynthetic route exploration. The proposed framework obtains the contributions of different nodes to the target molecule's success probability through gradient propagation and then guides the algorithm to greedily select the node with the highest contribution for expansion, thereby conducting efficient search in the chemical space. Experimental validations demonstrate that our algorithm achieves broad applicability across diverse molecular targets and exhibits superior computational efficiency compared to existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16123v2</guid>
      <category>cs.AI</category>
      <category>q-bio.BM</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chengyang Tian, Yuhang Chang, Yangpeng Zhang, Yang Liu</dc:creator>
    </item>
    <item>
      <title>Learning Potential Energy Surfaces of Hydrogen Atom Transfer Reactions in Peptides</title>
      <link>https://arxiv.org/abs/2508.00578</link>
      <description>arXiv:2508.00578v2 Announce Type: replace-cross 
Abstract: Hydrogen atom transfer (HAT) reactions are essential in many biological processes, such as radical migration in damaged proteins, but their mechanistic pathways remain incompletely understood. Simulating HAT is challenging due to the need for quantum chemical accuracy at biologically relevant scales; thus, neither classical force fields nor DFT-based molecular dynamics are applicable. Machine-learned potentials offer an alternative, able to learn potential energy surfaces (PESs) with near-quantum accuracy. However, training these models to generalize across diverse HAT configurations, especially at radical positions in proteins, requires tailored data generation and careful model selection. Here, we systematically generate HAT configurations in peptides to build large datasets using semiempirical methods and DFT. We benchmark three graph neural network architectures (SchNet, Allegro, and MACE) on their ability to learn HAT PESs and indirectly predict reaction barriers from energy predictions. MACE consistently outperforms the others in energy, force, and barrier prediction, achieving a mean absolute error of 1.13 kcal/mol on out-of-distribution DFT barrier predictions. Using molecular dynamics, we show our MACE potential is stable, reactive, and generalizes beyond training data to model HAT barriers in collagen I. This accuracy enables integration of ML potentials into large-scale collagen simulations to compute reaction rates from predicted barriers, advancing mechanistic understanding of HAT and radical migration in peptides. We analyze scaling laws, model transferability, and cost-performance trade-offs, and outline strategies for improvement by combining ML potentials with transition state search algorithms and active learning. Our approach is generalizable to other biomolecular systems, enabling quantum-accurate simulations of chemical reactivity in complex environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00578v2</guid>
      <category>cs.LG</category>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.chem-ph</category>
      <category>physics.comp-ph</category>
      <category>q-bio.BM</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marlen Neubert, Patrick Reiser, Frauke Gr\"ater, Pascal Friederich</dc:creator>
    </item>
    <item>
      <title>BadGraph: A Backdoor Attack Against Latent Diffusion Model for Text-Guided Graph Generation</title>
      <link>https://arxiv.org/abs/2510.20792</link>
      <description>arXiv:2510.20792v3 Announce Type: replace-cross 
Abstract: The rapid progress of graph generation has raised new security concerns, particularly regarding backdoor vulnerabilities. While prior work has explored backdoor attacks in image diffusion and unconditional graph generation, conditional, especially text-guided graph generation remains largely unexamined. This paper proposes BadGraph, a backdoor attack method against latent diffusion models for text-guided graph generation. BadGraph leverages textual triggers to poison training data, covertly implanting backdoors that induce attacker-specified subgraphs during inference when triggers appear, while preserving normal performance on clean inputs. Extensive experiments on four benchmark datasets (PubChem, ChEBI-20, PCDes, MoMu) demonstrate the effectiveness and stealth of the attack: less than 10% poisoning rate can achieves 50% attack success rate, while 24% suffices for over 80% success rate, with negligible performance degradation on benign samples. Ablation studies further reveal that the backdoor is implanted during VAE and diffusion training rather than pretraining. These findings reveal the security vulnerabilities in latent diffusion models of text-guided graph generation, highlight the serious risks in models' applications such as drug discovery and underscore the need for robust defenses against the backdoor attack in such diffusion models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20792v3</guid>
      <category>cs.LG</category>
      <category>cs.CL</category>
      <category>q-bio.BM</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liang Ye, Shengqin Chen, Jiazhu Dai</dc:creator>
    </item>
  </channel>
</rss>
