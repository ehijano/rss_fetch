<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 21 Aug 2025 01:27:37 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Graph-Based Deterministic Polynomial Algorithm for NP Problems</title>
      <link>https://arxiv.org/abs/2508.13166</link>
      <description>arXiv:2508.13166v2 Announce Type: new 
Abstract: The P = NP problem asks whether every problem whose solution can be verified in polynomial time (NP) can also be solved in polynomial time (P). In this paper, we present a proof that P = NP, demonstrating that every NP problem can be solved deterministically in polynomial time. We introduce a new Computation Model that enables the simulation of a Turing machine, and show that NP problems can be simulated efficiently within this framework. By introducing the concept of a Feasible Graph, we ensure that the simulation can be performed in polynomial time, providing a direct path to resolving the P = NP question. Our result has significant implications for fields such as cryptography, optimization, and artificial intelligence, where NP-complete problems play a central role.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13166v2</guid>
      <category>cs.CC</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Changryeol Lee (Department of Software, Yonsei University, Mirae Campus)</dc:creator>
    </item>
    <item>
      <title>An Intrinsic Barrier for Resolving P = NP (2-SAT as Flat, 3-SAT as High-Dimensional Void-Rich)</title>
      <link>https://arxiv.org/abs/2508.13200</link>
      <description>arXiv:2508.13200v1 Announce Type: new 
Abstract: We present a topological barrier to efficient computation, revealed by comparing the geometry of 2 SAT and 3 SAT solution spaces. Viewing the set of satisfying assignments as a cubical complex within the Boolean hypercube, we prove that every 2 SAT instance has a contractible solution space, topologically flat, with all higher Betti numbers bk equals 0 for k greater than or equal 1, while both random and explicit 3 SAT families can exhibit exponential second Betti numbers, corresponding to exponentially many independent voids. These voids are preserved under standard SAT reductions and cannot be collapsed without solving NP-hard subproblems, making them resistant to the three major complexity theoretic barriers, relativization, natural proofs, and algebrization. We establish exponential time lower bounds in restricted query models and extend these to broader algorithmic paradigms under mild information-theoretic or encoding assumptions. This topological contrast flat, connected landscapes in 2 SAT versus tangled, high-dimensional void-rich landscapes in 3 SAT, provides structural evidence toward P does not equal NP, identifying b2 as a paradigm-independent invariant of computational hardness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13200v1</guid>
      <category>cs.CC</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>M. Alasli</dc:creator>
    </item>
    <item>
      <title>Analog computation with transcriptional networks</title>
      <link>https://arxiv.org/abs/2508.14017</link>
      <description>arXiv:2508.14017v1 Announce Type: new 
Abstract: Transcriptional networks represent one of the most extensively studied types of systems in synthetic biology. Although the completeness of transcriptional networks for digital logic is well-established, *analog* computation plays a crucial role in biological systems and offers significant potential for synthetic biology applications. While transcriptional circuits typically rely on cooperativity and highly non-linear behavior of transcription factors to regulate *production* of proteins, they are often modeled with simple linear *degradation* terms. In contrast, general analog dynamics require both non-linear positive as well as negative terms, seemingly necessitating control over not just transcriptional (i.e., production) regulation but also the degradation rates of transcription factors.
  Surprisingly, we prove that controlling transcription factor production (i.e., transcription rate) without explicitly controlling degradation is mathematically complete for analog computation, achieving equivalent capabilities to systems where both production and degradation are programmable. We demonstrate our approach on several examples including oscillatory and chaotic dynamics, analog sorting, memory, PID controller, and analog extremum seeking. Our result provides a systematic methodology for engineering novel analog dynamics using synthetic transcriptional networks without the added complexity of degradation control and informs our understanding of the capabilities of natural transcriptional circuits.
  We provide a compiler, in the form of a Python package that can take any system of polynomial ODEs and convert it to an equivalent transcriptional network implementing the system *exactly*, under appropriate conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.14017v1</guid>
      <category>cs.CC</category>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Doty, Mina Latifi, David Soloveichick</dc:creator>
    </item>
    <item>
      <title>Multi-Metric Algorithmic Complexity: Beyond Asymptotic Analysis</title>
      <link>https://arxiv.org/abs/2508.13249</link>
      <description>arXiv:2508.13249v1 Announce Type: cross 
Abstract: Traditional algorithm analysis treats all basic operations as equally costly, which hides significant differences in time, energy consumption, and cost between different types of computations on modern processors. We propose a weighted-operation complexity model that assigns realistic cost values to different instruction types across multiple dimensions: computational effort, energy usage, carbon footprint, and monetary cost. The model computes overall efficiency scores based on user-defined priorities and can be applied through automated code analysis or integrated with performance measurement tools. This approach complements existing theoretical models by enabling practical, architecture-aware algorithm comparisons that account for performance, sustainability, and economic factors. We demonstrate an open-source implementation that analyzes code, estimates multi-dimensional costs, and provides efficiency recommendations across various algorithms. We address two research questions: (RQ1) Can a multi-metric model predict time/energy with high accuracy across architectures? (RQ2) How does it compare to baselines like Big-O, ICE, and EVM gas? Validation shows strong correlations (\r{ho}&gt;0.9) with measured data, outperforming baselines in multi-objective scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13249v1</guid>
      <category>cs.PF</category>
      <category>cs.AR</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sergii Kavun</dc:creator>
    </item>
    <item>
      <title>Adversarially robust quantum state learning and testing</title>
      <link>https://arxiv.org/abs/2508.13959</link>
      <description>arXiv:2508.13959v1 Announce Type: cross 
Abstract: Quantum state learning is a fundamental problem in physics and computer science. As near-term quantum devices are error-prone, it is important to design error-resistant algorithms. Apart from device errors, other unexpected factors could also affect the algorithm, such as careless human read-out error, or even a malicious hacker deliberately altering the measurement results. Thus, we want our algorithm to work even in the worst case when things go against our favor.
  We consider the practical setting of single-copy measurements and propose the $\gamma$-adversarial corruption model where an imaginary adversary can arbitrarily change $\gamma$-fraction of the measurement outcomes. This is stronger than the $\gamma$-bounded SPAM noise model, where the post-measurement state changes by at most $\gamma$ in trace distance. Under our stronger model of corruption, we design an algorithm using non-adaptive measurements that can learn an unknown rank-$r$ state up to $\tilde{O}(\gamma\sqrt{r})$ in trace distance, provided that the number of copies is sufficiently large. We further prove an information-theoretic lower bound of $\Omega(\gamma\sqrt{r})$ for non-adaptive measurements, demonstrating the optimality of our algorithm. Our upper and lower bounds also hold for quantum state testing, where the goal is to test whether an unknown state is equal to a given state or far from it.
  Our results are intriguingly optimistic and pessimistic at the same time. For general states, the error is dimension-dependent and $\gamma\sqrt{d}$ in the worst case, meaning that only corrupting a very small fraction ($1/\sqrt{d}$) of the outcomes could totally destroy any non-adaptive learning algorithm. However, for constant-rank states that are useful in many quantum algorithms, it is possible to achieve dimension-independent error, even in the worst-case adversarial setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13959v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maryam Aliakbarpour, Vladimir Braverman, Nai-Hui Chia, Yuhan Liu</dc:creator>
    </item>
    <item>
      <title>Certificate-Sensitive Subset Sum: Realizing Instance Complexity</title>
      <link>https://arxiv.org/abs/2507.15511</link>
      <description>arXiv:2507.15511v5 Announce Type: replace 
Abstract: We present, to our knowledge, the first deterministic, certificate-sensitive algorithm for a canonical NP-complete problem whose runtime provably adapts to the structure of each input. For a Subset-Sum instance $(S, t)$, let $\Sigma(S)$ denote the set of distinct subset sums and define $U = |\Sigma(S)|$. This set serves as an information-theoretically minimal witness, the instance-complexity (IC) certificate.
  Our solver, IC-SubsetSum, enumerates every element of $\Sigma(S)$ in deterministic time $O(U \cdot n^2)$ and space $O(U \cdot n)$. A randomized variant achieves expected runtime $O(U \cdot n)$. The algorithm's complexity is thus directly governed by the certificate size, and this structure-sensitive performance is paired with a guaranteed worst-case runtime of $O^*(2^{n/2 - \varepsilon})$ for some constant $\varepsilon &gt; 0$, the first such result to strictly outperform classical methods on every instance.
  We revisit fine-grained reductions that rely on the classical $2^{n/2}$ hardness of SubsetSum and show that these arguments hold only for collision-free instances where $U$ is maximal. IC-SubsetSum reframes this barrier structurally and introduces a new paradigm for certificate-sensitive algorithms across NP-complete problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.15511v5</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jesus Salas</dc:creator>
    </item>
    <item>
      <title>The PPP-completeness of the Ward-Szabo theorem</title>
      <link>https://arxiv.org/abs/2507.23345</link>
      <description>arXiv:2507.23345v2 Announce Type: replace 
Abstract: Ward and Szab\'o [WS94] have shown that a complete graph with $N^2$ nodes whose edges are colored by $N$ colors and that has at least two colors contains a bichromatic triangle. This fact leads us to a total search problem: Given an edge-coloring on a complete graph with $N^2$ nodes using at least two colors and at most $N$ colors, find a bichromatic triangle. Bourneuf, Folwarczn\'y, Hub\'acek, Rosen, and Schwartzbach [Bou+23] have proven that such a total search problem, called Ward-Szab\'o, is PWPP-hard and belongs to the class TFNP, a class for total search problems in which the correctness of every candidate solution is efficiently verifiable. However, it is open which TFNP subclass contains Ward-Szab\'o. This paper will improve the computational complexity of Ward-Szab\'o. We prove that Ward-Szab\'o is a complete problem for the complexity class PPP, a TFNP subclass of problems in which the existence of solutions is guaranteed by the pigeonhole principle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.23345v2</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Takashi Ishizuka</dc:creator>
    </item>
    <item>
      <title>NP-Hardness and ETH-Based Inapproximability of Communication Complexity via Relaxed Interlacing</title>
      <link>https://arxiv.org/abs/2508.05597</link>
      <description>arXiv:2508.05597v3 Announce Type: replace 
Abstract: We prove that computing the deterministic communication complexity D(f) of a Boolean function is NP-hard in the standard protocol-tree model, answering, independently and concurrently with Hirahara-Llango-Loff (arXiv:2507.10426), a question first posed by Yao (1979). Our reduction builds and expands on a suite of structural "interlacing" lemmas introduced by Mackenzie and Saffidine (arXiv:2411.19003); these lemmas can be reused as black boxes in future lower-bound constructions.
  The instances produced by our reduction admit optimal protocols for self-similar constructions with strong structural properties, giving a flexible framework for the design of reductions showing NP-hardness of deciding the communication complexity of a Boolean matrix. This complements the work by Hirahara, Ilango, and Loff, which establishes NP-hardness in the same model via a different route; our analysis additionally yields reusable structural guarantees and underpins further consequences concerning inapproximability.
  Because the gadgets in our construction are self-similar, they can be recursively embedded. We sketch how this yields, under the Exponential-Time Hypothesis, an additive inapproximability gap that grows without bound. Furthermore we outline a route toward NP-hardness of approximating D(f) within a fixed constant additive error. Full details of the ETH-based inapproximability results will appear in a future version.
  Beyond settling the complexity of deterministic communication complexity itself, the modular framework we develop opens the door to a wider class of reductions and, we believe, will prove useful in tackling other long-standing questions in communication complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05597v3</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Serge Gaspers, Tao Zixu He, Simon Mackenzie</dc:creator>
    </item>
    <item>
      <title>On the complexity of constrained reconfiguration and motion planning</title>
      <link>https://arxiv.org/abs/2508.13032</link>
      <description>arXiv:2508.13032v2 Announce Type: replace 
Abstract: Coordinating the motion of multiple agents in constrained environments is a fundamental challenge in robotics, motion planning, and scheduling. A motivating example involves $n$ robotic arms, each represented as a line segment. The objective is to rotate each arm to its vertical orientation, one at a time (clockwise or counterclockwise), without collisions nor rotating any arm more than once. This scenario is an example of the more general $k$-Compatible Ordering problem, where $n$ agents, each capable of $k$ state-changing actions, must transition to specific target states under constraints encoded as a set $\mathcal{G}$ of $k$ pairs of directed graphs.
  We show that $k$-Compatible Ordering is $\mathsf{NP}$-complete, even when $\mathcal{G}$ is planar, degenerate, or acyclic. On the positive side, we provide polynomial-time algorithms for cases such as when $k = 1$ or $\mathcal{G}$ has bounded treewidth. We also introduce generalized variants supporting multiple state-changing actions per agent, broadening the applicability of our framework. These results extend to a wide range of scheduling, reconfiguration, and motion planning applications in constrained environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13032v2</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>cs.RO</category>
      <category>math.CO</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicolas Bousquet, Remy El Sabeh, Amer E. Mouawad, Naomi Nishimura</dc:creator>
    </item>
    <item>
      <title>Superposition detection and QMA with non-collapsing measurements</title>
      <link>https://arxiv.org/abs/2403.02532</link>
      <description>arXiv:2403.02532v2 Announce Type: replace-cross 
Abstract: We prove that QMA where the verifier may also make a single non-collapsing measurement is equal to NEXP, resolving an open question of Aaronson. We show this is a corollary to a modified proof of QMA+ = NEXP [arXiv:2306.13247]. At the core of many results inspired by Blier and Tapp [arXiv:0709.0738] is an unphysical property testing problem deciding whether a quantum state is close to an element of a fixed basis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02532v2</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roozbeh Bassirian, Kunal Marwaha</dc:creator>
    </item>
    <item>
      <title>Minimum Selective Subset on Some Graph Classes</title>
      <link>https://arxiv.org/abs/2507.00235</link>
      <description>arXiv:2507.00235v3 Announce Type: replace-cross 
Abstract: In a connected simple graph G = (V(G),E(G)), each vertex is assigned a color from the set of colors C={1, 2,..., c}. The set of vertices V(G) is partitioned as V_1, V_2, ... ,V_c, where all vertices in V_j share the same color j. A subset S of V(G) is called Selective Subset if, for every vertex v in V(G), and if v is in V_j, at least one of its nearest neighbors in (S union (V(G)\ V_j)) has the same color as v. The Minimum Selective Subset (MSS) problem seeks to find a selective subset of minimum size. The problem was first introduced by Wilfong in 1991 for a set of points in the Euclidean plane, where two major problems, MCS (Minimum Consistent Subset) and MSS, were proposed.
  In graph algorithms, the only known result is that the MSS problem is NP-complete, as shown in 2018. Beyond this, no further progress has been made to date. In contrast, the MCS problem has been widely studied in various graph classes over the years. Therefore, in this work, we also extend the algorithmic study of MSS on various graph classes. We first present a log(n)-approximation algorithm for general graphs with n vertices and regardless of the number of colors. We also show that the problem remains NP-complete in planar graphs when restricted to just two colors.. Finally, we provide polynomial-time algorithms for computing optimal solutions in trees and unit interval graphs for any number of colors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.00235v3</guid>
      <category>cs.CG</category>
      <category>cs.CC</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bubai Manna</dc:creator>
    </item>
  </channel>
</rss>
