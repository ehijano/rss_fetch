<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 24 Nov 2025 05:00:06 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 24 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Optimal management of the vaccination process in SIRD epidemic models under constraints</title>
      <link>https://arxiv.org/abs/2511.16763</link>
      <description>arXiv:2511.16763v1 Announce Type: new 
Abstract: The paper considers the problems of optimal vaccination control in the classical SIR model under constraints on the resource capabilities of the insurance medical system, in particular under constraints on the possible absolute rate of vaccination of the population and the limitation on the available number of vaccines. The application of classical optimal control methods, the dynamic programming method and the Pontryagin maximum principle for such a model encounters difficulties associated with the possible non-smoothness of the Bellman function, and in the Pontryagin method the problem is to solve a boundary value problem with discontinuous control. Therefore, in the paper, optimal control is sought in the class of the so-called parametric strategies, which reduces the original problem to a finite-dimensional optimization problem with respect to unknown parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16763v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 24 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bogdan Norkin, Vladimir Norkin</dc:creator>
    </item>
    <item>
      <title>Efficient Penalty-Based Bilevel Methods: Improved Analysis, Novel Updates, and Flatness Condition</title>
      <link>https://arxiv.org/abs/2511.16796</link>
      <description>arXiv:2511.16796v1 Announce Type: new 
Abstract: Penalty-based methods have become popular for solving bilevel optimization (BLO) problems, thanks to their effective first-order nature. However, they often require inner-loop iterations to solve the lower-level (LL) problem and small outer-loop step sizes to handle the increased smoothness induced by large penalty terms, leading to suboptimal complexity. This work considers the general BLO problems with coupled constraints (CCs) and leverages a novel penalty reformulation that decouples the upper- and lower-level variables. This yields an improved analysis of the smoothness constant, enabling larger step sizes and reduced iteration complexity for Penalty-Based Gradient Descent algorithms in ALTernating fashion (ALT-PBGD). Building on the insight of reduced smoothness, we propose PBGD-Free, a novel fully single-loop algorithm that avoids inner loops for the uncoupled constraint BLO. For BLO with CCs, PBGD-Free employs an efficient inner-loop with substantially reduced iteration complexity. Furthermore, we propose a novel curvature condition describing the "flatness" of the upper-level objective with respect to the LL variable. This condition relaxes the traditional upper-level Lipschitz requirement, enables smaller penalty constant choices, and results in a negligible penalty gradient term during upper-level variable updates. We provide rigorous convergence analysis and validate the method's efficacy through hyperparameter optimization for support vector machines and fine-tuning of large language models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16796v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Mon, 24 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liuyuan Jiang, Quan Xiao, Lisha Chen, Tianyi Chen</dc:creator>
    </item>
    <item>
      <title>Phase Retrieval Based on DC and DnCNN</title>
      <link>https://arxiv.org/abs/2511.16913</link>
      <description>arXiv:2511.16913v1 Announce Type: new 
Abstract: This paper investigates noise-robust phase retrieval by enhancing the prDeep architecture with difference of convex functions (DC) and DnCNN-based denoising regularization. This research introduces two novel algorithms, prDeep-DC and prDeep-L2, which demonstrably achieve excellent quantitative and visual performance, as confirmed by extensive numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16913v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 24 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Xueming Li, Bing Guo</dc:creator>
    </item>
    <item>
      <title>On Solving Chance-Constrained Models with Gaussian Mixture Distribution</title>
      <link>https://arxiv.org/abs/2511.16960</link>
      <description>arXiv:2511.16960v1 Announce Type: new 
Abstract: We study linear chance-constrained problems where the coefficients follow a Gaussian mixture distribution. We provide mixed-binary quadratic programs that give inner and outer approximations of the chance constraint based on piecewise linear approximations of the standard normal cumulative density function. We show that $O\left(\sqrt{\ln(1/\tau)/\tau} \right)$ pieces are sufficient to attain $\tau$-accuracy in the chance constraint. We also show that any desired optimality gap can be achieved under a constraint qualification condition by controlling the approximation accuracy. Extensive computations using a commercial solver show that problems with up to one thousand random coefficients specified with up to fifteen Gaussian mixture components, generated under diverse settings, can be solved to near optimality within 18 hours, while satisfying chance constraint satisfaction probabilities of up to $0.999$. The solution times are significantly lower for problems with fewer random coefficients and mixture terms. For example, problems with one hundred random coefficients, ten mixture terms, and a constraint satisfaction probability of $0.999$ can be solved in a minute or less. Sample average approximations fail to provide meaningful solutions even for the smaller problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16960v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Mon, 24 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shibshankar Dey, Sanjay Mehrotra, Anirudh Subramanyam</dc:creator>
    </item>
    <item>
      <title>Contextual Quantile Minimization for Two-Stage Stochastic Programs</title>
      <link>https://arxiv.org/abs/2511.17020</link>
      <description>arXiv:2511.17020v1 Announce Type: new 
Abstract: Contextual stochastic optimization is an advanced methodology to model uncertainty in the presence of contextual information during decision planning processes. Although classical methodologies focus on minimizing the expectation of a random loss, in many applications, risk-averse decision-makers may be interested in minimizing a specific quantile as a more prudent alternative. In this paper, we propose a new risk-averse contextual stochastic optimization problem with a quantile objective for general two-stage problems. Given historical data on the model's random parameters and contextual information, we model the conditional quantile by replacing the conditional expectation in its variational characterization with a generic estimator. Under two sets of mild regularity conditions, we derive the asymptotic almost-sure convergence and convergence in probability of the optimal solution and the optimal value of the associated optimization problem to their true counterparts. Optimization problems with a quantile objective is usually non-convex, which are generally regarded as challenging to solve. To address the computational difficulties, we propose a new stochastic inexact constraint generation method with convergence guarantee. Finally, through numerical experiments on a single-server appointment scheduling problem, we study the computational performance of our proposed solution method as well as operational performance of our proposed methodology. Our results demonstrate the importance of incorporating useful contextual information and decision-maker's risk attitude into the optimization model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.17020v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 24 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Man Yiu Tsang, Tony Sit, Hoi Ying Wong</dc:creator>
    </item>
    <item>
      <title>Infinite Horizon Linear Quadratic Mean Field Problems with Common Noise and Regime Switching via Conditional McKean-Vlasov FBSDEs</title>
      <link>https://arxiv.org/abs/2511.17023</link>
      <description>arXiv:2511.17023v1 Announce Type: new 
Abstract: This paper studies infinite horizon linear quadratic (LQ) mean field problems with common noise and regime switching, covering both control and game formulations. To establish a theoretical foundation for the LQ framework, we first analyze fully coupled forward-backward stochastic differential equations (FBSDEs) of conditional McKean-Vlasov type with Markovian switching and establish its well-posedness under a generalized domination-monotonicity condition. Building upon this solvability result, we then derive necessary and sufficient conditions for both the open-loop optimal control in the control problem and the mean-field Nash equilibria in the game problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.17023v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 24 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qingmeng Wei, Yaqi Xu</dc:creator>
    </item>
    <item>
      <title>Carath\'eodory number of homogeneous convex cones</title>
      <link>https://arxiv.org/abs/2511.17051</link>
      <description>arXiv:2511.17051v1 Announce Type: new 
Abstract: We study the Carath\'eodory number of homogeneous convex cones via their spectrahedral representations. A characterization of homogeneous convex cones whose ranks match their Carath\'eodory numbers is given. This characterization is then used to show that a homogeneous convex cone is selfdual if and only if its rank matches the Carath\'eodory numbers of both its closure and its dual cone. It is further used to show that the only sparse spectrahedral cones that are homogeneous convex cones are those described by homogeneous chordal graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.17051v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 24 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chek Beng Chua</dc:creator>
    </item>
    <item>
      <title>Robustness of optimal control for controlled regime-switching diffusions with incorrect models</title>
      <link>https://arxiv.org/abs/2511.17121</link>
      <description>arXiv:2511.17121v1 Announce Type: new 
Abstract: This paper investigates the robustness of stochastic optimal control for controlled regime switching diffusions. We consider systems driven by both continuous fluctuations and discrete regime changes, allowing for model misspecification in both the diffusion and switching components. Within a unified framework, we study four classical cost formulations finite horizon, infinite-horizon discounted and ergodic costs, and the exit time cost, and establish continuity of value functions and robustness of optimal controls. Specifically, we show that as a sequence of approximating regime switching models converges to the true model, the associated value functions and optimal policies converge as well, ensuring vanishing performance loss. The analysis relies on the regularity of the solution to the associated weakly coupled HJB systems, and their stochastic representation. The results extend the robustness framework developed for diffusion processes to a significantly broader class of hybrid systems with interacting continuous and discrete dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.17121v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 24 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Somnath Pradhan, Dinesh Rathia</dc:creator>
    </item>
    <item>
      <title>An efficient branch-and-cut algorithm for the multiple probabilistic covering location problem</title>
      <link>https://arxiv.org/abs/2511.17128</link>
      <description>arXiv:2511.17128v1 Announce Type: new 
Abstract: In this paper, we consider the multiple probabilistic covering location problem (MPCLP), which attempts to open a fixed number of facilities to maximize the total covered customer demand under a joint probabilistic coverage setting. We present a new mixed integer nonlinear programming (MINLP) formulation, and develop an efficient linear programming (LP) based branch-and-cut (B&amp;C) algorithm where submodular and outer-approximation inequalities are used to replace the nonlinear constraints and are separated at the nodes of the search tree. One key advantage of the proposed B&amp;C algorithm is that the number of variables in the underlying formulation grows only linearly with the number of customers and facility locations and is one-order of magnitude smaller than that in the underlying formulation of a state-of-the-art B&amp;C algorithm in the literature. Moreover, we propose two new families of strong valid inequalities, called enhanced outer-approximation and lifted subadditive inequalities, to strengthen the LP relaxation and speed up the convergence of the proposed B&amp;C algorithm. In extensive computational experiments on a testbed of 240 benchmark MPCLP instances, we show that, thanks to the small problem size and the strong LP relaxation of the underlying formulation, the proposed B&amp;C algorithm significantly outperforms a state-of-the-art B&amp;C algorithm in terms of running time, number of nodes in the search tree, and number of solved instances. In particular, using the proposed B&amp;C algorithm, we are able to provide optimal solutions for 57 previously unsolved benchmark instances within a time limit of one hour.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.17128v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 24 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yan-Ru Wang, Wei-Kun Chen, Ivana Ljubi\'c</dc:creator>
    </item>
    <item>
      <title>The G\"uler-type acceleration for proximal gradient, linearized augmented Lagrangian and linearized alternating direction method of multipliers</title>
      <link>https://arxiv.org/abs/2511.17157</link>
      <description>arXiv:2511.17157v1 Announce Type: new 
Abstract: In this paper, we introduce the G\"uler-type acceleration technique and utilize it to propose three acceleration algorithms: the G\"uler-type accelerated proximal gradient method (GPGM), the G\"uler-type accelerated linearized augmented Lagrangian method (GLALM) and the G\"uler-type accelerated linearized alternating direction method of multipliers (GLADMM). The key idea behind these algorithms is to fully leverage the information of negative term \bm{$-\|x^k-\hat{x}^{k-1}\|^2$} in order to design the extrapolation step. This concept of using negative terms to improve acceleration can be extended to other algorithms as well. Moreover, the proposed GLALM and GLADMM enable simultaneous acceleration of both primal and dual variables. Additionally, GPGM and GLALM achieve the same convergence rate of $O(\frac{1}{k^2})$ with some existing results. Although GLADMM achieves the same total convergence rate of $O(\frac{1}{N})$ as in existing results, the partial convergence rate is improved from $O(\frac{1}{N^{3/2}})$ to $O(\frac{1}{N^2})$. To validate the effectiveness of our algorithms, we conduct numerical experiments on various problem instances, including the $\ell_1$ regularized logistic regression, quadratic programming, and compressive sensing. The experimental results indicate that our algorithms outperform existing methods in terms of efficiency. This also demonstrates the potential of the stochastic algorithmic versions of these algorithms in application areas such as statistics, machine learning, and data mining. Finally, it is worth noting that this paper aims to introduce how G\"uler's acceleration technique can be applied to gradient-based algorithms and to provide a unified and concise framework for their construction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.17157v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 24 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bin Zhou, Liusheng Hou, Xingju Cai, Hailin Sun</dc:creator>
    </item>
    <item>
      <title>Quadratic Mean-Field BSDEs and Exponential Utility Maximization</title>
      <link>https://arxiv.org/abs/2511.17214</link>
      <description>arXiv:2511.17214v1 Announce Type: new 
Abstract: We study real-valued mean-field backward stochastic differential equations (BSDEs) of the form \[ Y_t = \xi + \int_t^T \widetilde{\mathbb E}\, g(s, Z_s, \tilde Z_s)\, ds - \int_t^T Z_s \, dW_s, \] where $\tilde Z$ denotes an independent copy of $Z$ and $\widetilde{\mathbb E}$ the expectation with respect to $\tilde Z$. Under a \emph{separately quadratic} growth assumption (H\textsubscript{q}) on the generator $g$ in $(Z,\tilde Z)$, together with a bounded terminal condition, we prove existence and uniqueness of solutions in $\mathbb S^\infty \times \mathbb H^2_{\mathrm{BMO}}$. Our approach departs from classical fixed-point arguments and instead combines Malliavin calculus with refined BMO and stability estimates: we first obtain uniform $\mathbb S^\infty$-bounds for $Z$ in a Lipschitz setting with bounded Malliavin derivative, and then pass to the quadratic case by approximation, using a stability result in $\mathbb S^2\times\mathbb H^2$. This closes the gap between the quadratic BSDE results of Cheridito and Nam (2017) and Hao et al. (2025).
  In the second part of the paper, we extend the framework to generators of the form $g(t,z,\tilde z,\bar z)$ satisfying a \emph{fully coupled quadratic} condition (H\textsubscript{q}$'$). In this general regime we establish existence and uniqueness under a smallness condition on the centered terminal variable. As an application, we solve a mean-field exponential utility maximization problem with a collective liability, thereby generalizing the classical utility maximization framework of Hu et al. (2005) to a fully coupled quadratic mean-field setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.17214v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Mon, 24 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yining Ding, Kihun Nam, Jiaqiang Wen3</dc:creator>
    </item>
    <item>
      <title>Lyapunov and Riccati Equations from a Positive System Perspective</title>
      <link>https://arxiv.org/abs/2511.17243</link>
      <description>arXiv:2511.17243v1 Announce Type: new 
Abstract: This paper presents a new interpretation of the Lyapunov and Riccati equations from the perspective of positive system theory. We show it is possible to construct positive systems related to these equations, and then certain conclusions -- such as the existence and uniqueness of solutions -- can be drawn from positive systems theory. Specifically, under standard observability assumptions, a strictly positive linear system can be constructed for Lyapunov equations, leading to exponential convergence in Hilbert metric to the Perron-Frobenius vector -- closely related to the solution of the Lyapunov equation. For algebraic Riccati equations, homogeneous strictly positive systems can be constructed, which exhibit more complex dynamical behaviors. While the existence and uniqueness of the solution can still be proven, only asymptotic convergence can be obtained.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.17243v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 24 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Dongjun Wu, Yankai Lin</dc:creator>
    </item>
    <item>
      <title>Chance constrained optimization of energy intensive production as beneficial power units</title>
      <link>https://arxiv.org/abs/2511.17252</link>
      <description>arXiv:2511.17252v1 Announce Type: new 
Abstract: We study linear policy approximations for the risk-conscious operation of an industrial energy system with uncertain wind power, significant and variable electricity demand, and high thermal output, as found in a modern foundry. The system incorporates thermal storage and operates under rolling forecasts, leading to a sequential decision-making framework. To address uncertainty in key parameters, we formulate chance-constrained optimization problems that limit the probability of critical constraint violations, such as unmet demand requirements or the exceedance of system boundaries. To reduce computational effort, we replace direct uncertainty handling with a parameter-modified cost function that approximates the underlying risk structure. We validate our method through a numerical case study, demonstrating the trade-offs between operational efficiency and reliability in a stochastic environment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.17252v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 24 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Johannes Nicklaus, Lea Brass, Gunnar Schubert</dc:creator>
    </item>
    <item>
      <title>On the Convergence of Constrained Gradient Method</title>
      <link>https://arxiv.org/abs/2511.17430</link>
      <description>arXiv:2511.17430v1 Announce Type: new 
Abstract: The constrained gradient method (CGM) has recently been proposed to solve convex optimization and monotone variational inequality (VI) problems with general functional constraints. While existing literature has established convergence results for CGM, the assumptions employed therein are quite restrictive; in some cases, certain assumptions are mutually inconsistent, leading to gaps in the underlying analysis. This paper aims to derive rigorous and improved convergence guarantees for CGM under weaker and more reasonable assumptions, specifically in the context of strongly convex optimization and strongly monotone VI problems. Preliminary numerical experiments are provided to verify the validity of CGM and demonstrate its efficacy in addressing such problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.17430v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 24 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Danqing Zhou, Hongmei Chen, Shiqian Ma, Junfeng Yang</dc:creator>
    </item>
    <item>
      <title>Optimising pandemic response through vaccination strategies using neural networks</title>
      <link>https://arxiv.org/abs/2511.16932</link>
      <description>arXiv:2511.16932v1 Announce Type: cross 
Abstract: Epidemic risk assessment poses inherent challenges, with traditional approaches often failing to balance health outcomes and economic constraints. This paper presents a data-driven decision support tool that models epidemiological dynamics and optimises vaccination strategies to control disease spread whilst minimising economic losses. The proposed economic-epidemiological framework comprises three phases: modelling, optimising, and analysing. First, a stochastic compartmental model captures epidemic dynamics. Second, an optimal control problem is formulated to derive vaccination strategies that minimise pandemic-related expenditure. Given the analytical intractability of epidemiological models, neural networks are employed to calibrate parameters and solve the high-dimensional control problem. The framework is demonstrated using COVID-19 data from Victoria, Australia, empirically deriving optimal vaccination strategies that simultaneously minimise disease incidence and governmental expenditure. By employing this three-phase framework, policymakers can adjust input values to reflect evolving transmission dynamics and continuously update strategies, thereby minimising aggregate costs, aiding future pandemic preparedness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16932v1</guid>
      <category>stat.AP</category>
      <category>econ.EM</category>
      <category>math.OC</category>
      <pubDate>Mon, 24 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chang Zhai, Ping Chen, Zhuo Jin, David Pitt</dc:creator>
    </item>
    <item>
      <title>Asymptotics of motion planning complexity for control-affine systems</title>
      <link>https://arxiv.org/abs/2511.17130</link>
      <description>arXiv:2511.17130v1 Announce Type: cross 
Abstract: In this paper, we study the complexity of the approximation of nonadmissible curves for nonlinear control-affine systems satisfying the strong H{\"o}rmander condition. Focusing on tubular approximation complexities, we provide asymptotic equivalences, with explicit constants, for all generic situations where the distribution, i.e., the linear part of the control system, is of co-rank one. Namely, we consider curves in step 2 distributions and any dimension. In the 3 dimensional case, we also consider the case of distributions with Martinet-type singularities that are crossed by the curve at isolated points.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.17130v1</guid>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Mon, 24 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michele Motta (SISSA / ISAS), Dario Prandi (L2S, CNRS)</dc:creator>
    </item>
    <item>
      <title>Computing the Hard Scaled Relative Graph of LTI Systems</title>
      <link>https://arxiv.org/abs/2511.17297</link>
      <description>arXiv:2511.17297v1 Announce Type: cross 
Abstract: Scaled Relative Graphs (SRGs) provide a novel graphical frequency-domain method for the analysis of nonlinear systems, where Linear Time-Invariant (LTI) systems are the fundamental building block. To analyze feedback loops with unstable LTI components, the hard SRG is required, since it aptly captures the input/output behavior on the extended $L_2$ space. In this paper, we develop a systematic computational method to exactly compute the hard SRG of LTI systems, which may be unstable and contain integrators. We also study its connection to the Nyquist criterion, including the multivariable case, and demonstrate our method on several examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.17297v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 24 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julius P. J. Krebbekx, Eder Baron-Prada, Roland T\'oth, Amritam Das</dc:creator>
    </item>
    <item>
      <title>Convergence and stability of Q-learning in Hierarchical Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2511.17351</link>
      <description>arXiv:2511.17351v1 Announce Type: cross 
Abstract: Hierarchical Reinforcement Learning promises, among other benefits, to efficiently capture and utilize the temporal structure of a decision-making problem and to enhance continual learning capabilities, but theoretical guarantees lag behind practice. In this paper, we propose a Feudal Q-learning scheme and investigate under which conditions its coupled updates converge and are stable. By leveraging the theory of Stochastic Approximation and the ODE method, we present a theorem stating the convergence and stability properties of Feudal Q-learning. This provides a principled convergence and stability analysis tailored to Feudal RL. Moreover, we show that the updates converge to a point that can be interpreted as an equilibrium of a suitably defined game, opening the door to game-theoretic approaches to Hierarchical RL. Lastly, experiments based on the Feudal Q-learning algorithm support the outcomes anticipated by theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.17351v1</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 24 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Massimiliano Manenti, Andrea Iannelli</dc:creator>
    </item>
    <item>
      <title>Empirical universality and non-universality of local dynamics in the Sherrington-Kirkpatrick model</title>
      <link>https://arxiv.org/abs/2511.17428</link>
      <description>arXiv:2511.17428v1 Announce Type: cross 
Abstract: Several recent works have aimed to design algorithms for optimizing the Hamiltonians of spin glass models from statistical physics. While Montanari (2018) eventually gave a sophisticated message-passing algorithm to do this nearly optimally for the Sherrington-Kirkpatrick (SK) model, Parisi (2003) observed earlier that a simple yet unusual algorithm seems to perform just as well: perform local reluctant search, repeatedly making the local adjustment improving the objective function by the smallest possible amount. This is in contrast to the more intuitive local greedy search that repeatedly makes the local adjustment improving the objective by the largest possible amount. We study empirically how the performance of these algorithms depends on the distribution of entries of the coupling matrix in the SK model. We find evidence that, while the runtime of greedy search enjoys universality over a broad range of distributions, the runtime of reluctant search surprisingly is not universal, sometimes depending quite sensitively on the entry distribution. We propose that one mechanism leading to this non-universality is a change in the behavior of reluctant search when the couplings have discrete support on an evenly-spaced grid, and give experimental results supporting this proposal and investigating other properties of a distribution that might affect the performance of reluctant search.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.17428v1</guid>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Mon, 24 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Grace Liu, Dmitriy Kunisky</dc:creator>
    </item>
    <item>
      <title>A Framework for Adaptive Stabilisation of Nonlinear Stochastic Systems</title>
      <link>https://arxiv.org/abs/2511.17436</link>
      <description>arXiv:2511.17436v1 Announce Type: cross 
Abstract: We consider the adaptive control problem for discrete-time, nonlinear stochastic systems with linearly parameterised uncertainty. Assuming access to a parameterised family of controllers that can stabilise the system in a bounded set within an informative region of the state space when the parameter is well-chosen, we propose a certainty equivalence learning-based adaptive control strategy, and subsequently derive stability bounds on the closed-loop system that hold for some probabilities. We then show that if the entire state space is informative, and the family of controllers is globally stabilising with appropriately chosen parameters, high probability stability guarantees can be derived.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.17436v1</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 24 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Seth Siriya, Jingge Zhu, Dragan Ne\v{s}i\'c, Ye Pu</dc:creator>
    </item>
    <item>
      <title>Stabilization and control of the nonlinear plate equation</title>
      <link>https://arxiv.org/abs/2511.17468</link>
      <description>arXiv:2511.17468v1 Announce Type: cross 
Abstract: In this article we prove semiglobal stabilization and exact controllability results for nonlinear plate equations with hinged boundary conditions and analytic nonlinearity. These results hold when the damping or control is localized in a region where observability for the linear Schr\"odinger equation is known to hold. At the core of these results lies a new unique continuation property for the nonlinear plate equation, which significantly relaxes the geometric conditions required for such property to hold. This property is obtained by combining recent results on propagation of analyticity in time and unique continuation for linear plate operators. More broadly, our approach exploits the linear observability of the plate equation to establish both stabilization and control results. First, we prove exponential decay of the nonlinear energy under a defocusing assumption on the nonlinearity. Second, under a weaker asymptotic assumption on the nonlinearity, we prove semiglobal exact control by analyzing control properties inside the compact attractor provided by the dynamics of the damped equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.17468v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Mon, 24 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Crist\'obal Loyola</dc:creator>
    </item>
    <item>
      <title>Harnessing Data from Clustered LQR Systems: Personalized and Collaborative Policy Optimization</title>
      <link>https://arxiv.org/abs/2511.17489</link>
      <description>arXiv:2511.17489v1 Announce Type: cross 
Abstract: It is known that reinforcement learning (RL) is data-hungry. To improve sample-efficiency of RL, it has been proposed that the learning algorithm utilize data from 'approximately similar' processes. However, since the process models are unknown, identifying which other processes are similar poses a challenge. In this work, we study this problem in the context of the benchmark Linear Quadratic Regulator (LQR) setting. Specifically, we consider a setting with multiple agents, each corresponding to a copy of a linear process to be controlled. The agents' local processes can be partitioned into clusters based on similarities in dynamics and tasks. Combining ideas from sequential elimination and zeroth-order policy optimization, we propose a new algorithm that performs simultaneous clustering and learning to output a personalized policy (controller) for each cluster. Under a suitable notion of cluster separation that captures differences in closed-loop performance across systems, we prove that our approach guarantees correct clustering with high probability. Furthermore, we show that the sub-optimality gap of the policy learned for each cluster scales inversely with the size of the cluster, with no additional bias, unlike in prior works on collaborative learning-based control. Our work is the first to reveal how clustering can be used in data-driven control to learn personalized policies that enjoy statistical gains from collaboration but do not suffer sub-optimality due to inclusion of data from dissimilar processes. From a distributed implementation perspective, our method is attractive as it incurs only a mild logarithmic communication overhead.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.17489v1</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 24 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vinay Kanakeri, Shivam Bajaj, Ashwin Verma, Vijay Gupta, Aritra Mitra</dc:creator>
    </item>
    <item>
      <title>On Distributionally Robust Multistage Convex Optimization: Data-driven Models and Performance</title>
      <link>https://arxiv.org/abs/2210.08433</link>
      <description>arXiv:2210.08433v3 Announce Type: replace 
Abstract: This paper presents a novel algorithmic study with extensive numerical experiments of distributionally robust multistage convex optimization (DR-MCO). Following the previous work on dual dynamic programming (DDP) algorithmic framework for DR-MCO, we focus on data-driven DR-MCO models with Wasserstein ambiguity sets that allow probability measures with infinite supports. These data-driven Wasserstein DR-MCO models have out-of-sample performance guarantees and adjustable in-sample conservatism. Then by exploiting additional concavity or convexity in the uncertain cost functions, we design exact single stage subproblem oracle (SSSO) implementations that ensure the convergence of DDP algorithms. We test the data-driven Wasserstein DR-MCO models against multistage robust convex optimization (MRCO), risk-neutral and risk-averse multistage stochastic convex optimization (MSCO) models on multi-commodity inventory problems and hydro-thermal power planning problems. The results show that our DR-MCO models could outperform MRCO and MSCO models when the data size is small.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.08433v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 24 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shixuan Zhang, Xu Andy Sun</dc:creator>
    </item>
    <item>
      <title>Consensus-based algorithms for stochastic optimization problems</title>
      <link>https://arxiv.org/abs/2404.10372</link>
      <description>arXiv:2404.10372v4 Announce Type: replace 
Abstract: We address an optimization problem where the cost function is the expectation of a random mapping. To tackle the problem two approaches based on the approximation of the objective function by consensus-based particle optimization methods on the search space are developed. The resulting methods are mathematically analyzed using a mean-field approximation and their connection is established. Several numerical experiments show the validity of the proposed algorithms and investigate their rates of convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10372v4</guid>
      <category>math.OC</category>
      <pubDate>Mon, 24 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1137/24M1654531</arxiv:DOI>
      <arxiv:journal_reference>SIAM Journal on Optimization, 35(4): 2572-2598, 2025</arxiv:journal_reference>
      <dc:creator>Sabrina Bonandin, Michael Herty</dc:creator>
    </item>
    <item>
      <title>Uniform Value and Decidability in Ergodic Blind Stochastic Games</title>
      <link>https://arxiv.org/abs/2405.12583</link>
      <description>arXiv:2405.12583v2 Announce Type: replace 
Abstract: We study a class of two-player zero-sum stochastic games known as \textit{blind stochastic games}, where players neither observe the state nor receive any information about it during the game. A central concept for analyzing long-duration stochastic games is the \textit{uniform value}. A game has a uniform value $v$ if for every $\varepsilon&gt;0$, Player 1 (resp., Player 2) has a strategy such that, for all sufficiently large $n$, his average payoff over $n$ stages is at least $v-\varepsilon$ (resp., at most $v+\varepsilon$). Prior work has shown that the uniform value may not exist in general blind stochastic games. To address this, we introduce a subclass called \textit{ergodic blind stochastic games}, defined by imposing an ergodicity condition on the state transitions. For this subclass, we prove the existence of the uniform value and provide an algorithm to approximate it, establishing the \textit{decidability} of the approximation problem. Notably, this decidability result is novel even in the single-player setting of Partially Observable Markov Decision Processes (POMDPs). Furthermore, we show that no algorithm can compute the uniform value exactly, emphasizing the tightness of our result. Finally, we establish that the uniform value is independent of the initial belief.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12583v2</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <pubDate>Mon, 24 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Krishnendu Chatterjee, David Lurie, Raimundo Saona, Bruno Ziliotto</dc:creator>
    </item>
    <item>
      <title>Universal subgradient and proximal bundle methods for convex and strongly convex hybrid composite optimization</title>
      <link>https://arxiv.org/abs/2407.10073</link>
      <description>arXiv:2407.10073v4 Announce Type: replace 
Abstract: This paper develops two parameter-free methods for solving convex and strongly convex hybrid composite optimization problems, namely, a composite subgradient type method and a proximal bundle type method. Functional complexity bounds for the two methods are established in terms of the unknown strong convexity parameter. The two proposed methods are universal with respect to all problem parameters, including the strong convexity one, and require no knowledge of the optimal value. Moreover, in contrast to previous works, they do not restart nor use multiple threads.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10073v4</guid>
      <category>math.OC</category>
      <pubDate>Mon, 24 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vincent Guigues, Jiaming Liang, Renato D. C. Monteiro</dc:creator>
    </item>
    <item>
      <title>Asymptotic Linear Convergence of ADMM for Isotropic TV Norm Compressed Sensing</title>
      <link>https://arxiv.org/abs/2505.01240</link>
      <description>arXiv:2505.01240v2 Announce Type: replace 
Abstract: We prove an explicit local linear rate for ADMM solving the isotropic Total Variation (TV) norm compressed sensing problem in multiple dimensions, by analyzing the auxiliary variable in the equivalent Douglas-Rachford splitting on a dual problem. Numerical verification on large 3D problems and real MRI data will be shown. Though the proven rate is not sharp, it is close to the observed ones in numerical tests.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01240v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 24 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Emmanuel Gil Torres, Matt Jacobs, Xiangxiong Zhang</dc:creator>
    </item>
    <item>
      <title>Efficient Stochastic BFGS methods Inspired by Bayesian Principles</title>
      <link>https://arxiv.org/abs/2507.07729</link>
      <description>arXiv:2507.07729v3 Announce Type: replace 
Abstract: Quasi-Newton methods are ubiquitous in deterministic local search due to their efficiency and low computational cost. This class of methods uses the history of gradient evaluations to approximate second-order derivatives. However, only noisy gradient observations are accessible in stochastic optimization; thus, deriving quasi-Newton methods in this setting is challenging. Although most existing quasi-Newton methods for stochastic optimization rely on deterministic equations that are modified to circumvent noise, we propose a new approach inspired by Bayesian inference to assimilate noisy gradient information and derive the stochastic counterparts to standard quasi-Newton methods. We focus on the derivations of stochastic BFGS and L-BFGS, but our methodology can also be employed to derive stochastic analogs of other quasi-Newton methods. The resulting stochastic BFGS (S-BFGS) and stochastic L-BFGS (L-S-BFGS) can effectively learn an inverse Hessian approximation even with small batch sizes. For a problem of dimension $d$, the iteration cost of S-BFGS is $\mathcal{O}(d^2)$, and the cost of L-S-BFGS is $\mathcal{O}(d)$. Numerical experiments with a dimensionality of up to $30,720$ demonstrate the efficiency and robustness of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07729v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 24 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andr\'e Carlon, Luis Espath, Ra\'ul Tempone</dc:creator>
    </item>
    <item>
      <title>Dynamic access pricing control for fair and stable resource sharing</title>
      <link>https://arxiv.org/abs/2507.17939</link>
      <description>arXiv:2507.17939v2 Announce Type: replace 
Abstract: We consider the use of pricing as a regulatory mechanism when an unknown number of autonomous agents compete for access to a shared resource (possibly limited in volume or capacity). In standard dynamic pricing control systems, an increasing price is used to balance supply and demand for a resource in a constrained environment. A major drawback of dynamic pricing is that it is socially regressive, i.e., unfair, as such systems favour price-insensitive (unresponsive) traffic and control the demand at the expense of price-sensitive (responsive) traffic. We tackle this fundamental issue by proposing a new form of pricing that strikes a balance between using price as a control mechanism to manage demand for a resource and ensuring fair access to the resource for both price-sensitive and insensitive traffic. Our system gives rise to a switched non-linear ODE model, the stability of which is equivalent to ensuring the fairness properties of the pricing control system. Simulations illustrate this stability-fairness tradeoff and with the results demonstrating the effectiveness of the overall design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.17939v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 24 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Christopher King, Homayoun Hamedmoghadam, Christos G. Cassandras, Fabian R. Wirth, Robert N. Shorten</dc:creator>
    </item>
    <item>
      <title>Consensus-Based Optimization Beyond Finite-Time Analysis</title>
      <link>https://arxiv.org/abs/2509.12907</link>
      <description>arXiv:2509.12907v3 Announce Type: replace 
Abstract: We analyze a zeroth-order particle algorithm for the global optimization of a non-convex function, focusing on a variant of Consensus-Based Optimization (CBO) with small but fixed noise intensity. Unlike most previous studies restricted to finite horizons, we investigate its long-time behavior with fixed parameters. In the mean-field limit, a quantitative Laplace principle shows exponential convergence to a neighborhood of the minimizer x * . For finitely many particles, a block-wise analysis yields explicit error bounds: individual particles achieve long-time consistency near x * , and the global best particle converge to x * . The proof technique combines a quantitative Laplace principle with block-wise control of Wasserstein distances, avoiding the exponential blow-up typical of Gr{\"o}nwall-based estimates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.12907v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 24 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pascal Bianchi (S2A, IDS), Radu-Alexandru Dragomir (S2A, IDS), Victor Priser (S2A, IDS)</dc:creator>
    </item>
    <item>
      <title>Optimal Strategy in "Guess Who?": Beyond Binary Search</title>
      <link>https://arxiv.org/abs/1509.03327</link>
      <description>arXiv:1509.03327v3 Announce Type: replace-cross 
Abstract: "Guess Who?" is a popular two player game where players ask "Yes"/"No" questions to search for their opponent's secret identity from a pool of possible candidates. This is modeled as a simple stochastic game. Using this model, the optimal strategy is explicitly found. Contrary to popular belief, performing a binary search is \emph{not} always optimal. Instead, the optimal strategy for the player who trails is to make certain bold plays in an attempt catch up. This is discovered by first analyzing a continuous version of the game where players play indefinitely and the winner is never decided after finitely many rounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:1509.03327v3</guid>
      <category>math.PR</category>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Mon, 24 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1017/S026996481600022X</arxiv:DOI>
      <arxiv:journal_reference>Prob. Eng. Inf. Sci. 30 (2016) 576-592</arxiv:journal_reference>
      <dc:creator>Mihai Nica</dc:creator>
    </item>
    <item>
      <title>Relative Arbitrage Opportunities in an Extended Mean Field System</title>
      <link>https://arxiv.org/abs/2311.02690</link>
      <description>arXiv:2311.02690v3 Announce Type: replace-cross 
Abstract: This paper studies relative arbitrage opportunities in a market with competitive investors through stochastic differential games in the limit as the number of players tends to infinity. With common noises introduced by the stock capitalization processes, we establish a conditional McKean-Vlasov system to study the market dynamics coupled to the expected trading volume of investors. We show that optimal arbitrage can be characterized as a solution of a Cauchy PDE constructed by the volatility terms in the market model. The structure of the market dynamics can be relaxed, and we provide a theoretical framework to study a general mean-field system, where the interaction is characterized by a joint distribution of wealth and strategies. In this setting, the optimal relative arbitrage constitutes the strong equilibrium of an extended mean-field game. We provide conditions for the existence and uniqueness of the mean-field equilibrium. We further prove the propagation of chaos result for the finite-player game counterpart, and demonstrate that the Nash equilibrium converges to the mean field equilibrium when the population grows to infinity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.02690v3</guid>
      <category>q-fin.MF</category>
      <category>math.OC</category>
      <pubDate>Mon, 24 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicole Tianjiao Yang, Tomoyuki Ichiba</dc:creator>
    </item>
    <item>
      <title>Completeness in the Polynomial Hierarchy for many natural Problems in Bilevel and Robust Optimization</title>
      <link>https://arxiv.org/abs/2311.10540</link>
      <description>arXiv:2311.10540v4 Announce Type: replace-cross 
Abstract: In bilevel and robust optimization we are concerned with combinatorial min-max problems, for example from the areas of min-max regret robust optimization, network interdiction, most vital vertex problems, blocker problems, and two-stage adjustable robust optimization. Even though these areas are well-researched for over two decades and one would naturally expect many (if not most) of the problems occurring in these areas to be complete for the classes $\Sigma^p_2$ or $\Sigma^p_3$ from the polynomial hierarchy, almost no hardness results in this regime are currently known. However, such complexity insights are important, since they imply that no polynomial-sized integer program for these min-max problems exist, and hence conventional IP-based approaches fail. We address this lack of knowledge by introducing over 70 new $\Sigma^p_2$-complete and $\Sigma^p_3$-complete problems. The majority of all earlier publications on $\Sigma^p_2$- and $\Sigma^p_3$-completeness in said areas are special cases of our meta-theorem. Precisely, we introduce a large list of problems for which the meta-theorem is applicable (including clique, vertex cover, knapsack, TSP, facility location and many more). We show that for every single of these problems, the corresponding min-max (i.e. interdiction/regret) variant is $\Sigma^p_2$- and the min-max-min (i.e. two-stage) variant is $\Sigma^p_3$-complete.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.10540v4</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>math.OC</category>
      <pubDate>Mon, 24 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christoph Gr\"une, Lasse Wulf</dc:creator>
    </item>
    <item>
      <title>Optimal risk mitigation by deep reinsurance</title>
      <link>https://arxiv.org/abs/2408.06168</link>
      <description>arXiv:2408.06168v2 Announce Type: replace-cross 
Abstract: We consider an insurance company which faces financial risk in the form of insurance claims and market-dependent surplus fluctuations. The company aims to simultaneously control its terminal wealth (e.g. at the end of an accounting period) and the ruin probability in a finite time interval by purchasing reinsurance. The target functional is given by the expected utility of terminal wealth perturbed by a modified Gerber-Shiu penalty function. We solve the problem of finding the optimal reinsurance strategy and the corresponding maximal target functional via neural networks. The procedure is illustrated by a numerical example, where the surplus process is given by a Cram\'er-Lundberg model perturbed by a mean-reverting Ornstein-Uhlenbeck process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06168v2</guid>
      <category>q-fin.RM</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>q-fin.CP</category>
      <pubDate>Mon, 24 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aleksandar Arandjelovi\'c, Julia Eisenberg</dc:creator>
    </item>
    <item>
      <title>Can Nash inform capital requirements? Allocating systemic risk measures</title>
      <link>https://arxiv.org/abs/2504.20413</link>
      <description>arXiv:2504.20413v2 Announce Type: replace-cross 
Abstract: Systemic risk measures aggregate the risks from multiple financial institutions to find system-wide capital requirements. Though much attention has been given to assessing the level of systemic risk, less has been given to allocating that risk to the constituent institutions. Within this work, we propose a Nash allocation rule that is inspired by game theory. Intuitively, to construct these capital allocations, the banks compete in a game to reduce their own capital requirements while, simultaneously, maintaining system-level acceptability. We provide sufficient conditions for the existence and uniqueness of Nash allocation rules, and apply our results to the prominent structures used for systemic risk measures in the literature. We demonstrate the efficacy of Nash allocations with numerical case studies using the Eisenberg-Noe aggregation mechanism.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.20413v2</guid>
      <category>q-fin.RM</category>
      <category>math.OC</category>
      <pubDate>Mon, 24 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>\c{C}a\u{g}{\i}n Ararat, Zachary Feinstein</dc:creator>
    </item>
    <item>
      <title>Soft decision trees for survival analysis</title>
      <link>https://arxiv.org/abs/2506.16846</link>
      <description>arXiv:2506.16846v3 Announce Type: replace-cross 
Abstract: Decision trees are popular in survival analysis for their interpretability and ability to model complex relationships. Survival trees, which predict the timing of singular events using censored historical data, are typically built through heuristic approaches. Recently, there has been growing interest in globally optimized trees, where the overall tree is trained by minimizing the error function over all its parameters. We propose a new soft survival tree model (SST), with a soft splitting rule at each branch node, trained via a nonlinear optimization formulation amenable to decomposition. Since SSTs provide for every input vector a specific survival function associated to a single leaf node, they satisfy the conditional computation property and inherit the related benefits. SST and the training formulation combine flexibility with interpretability: any smooth survival function (parametric, semiparametric, or nonparametric) estimated through maximum likelihood can be used, and each leaf node of an SST yields a cluster of distinct survival functions which are associated to the data points routed to it. Numerical experiments on 15 well-known datasets show that SSTs, with parametric and spline-based semiparametric survival functions, trained using an adaptation of the node-based decomposition algorithm proposed by Consolo et al. (2024) for soft regression trees, outperform three benchmark survival trees in terms of four widely-used discrimination and calibration measures. SSTs can also be extended to consider group fairness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16846v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 24 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Antonio Consolo, Edoardo Amaldi, Emilio Carrizosa</dc:creator>
    </item>
  </channel>
</rss>
