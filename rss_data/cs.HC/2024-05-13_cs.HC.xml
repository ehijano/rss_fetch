<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.HC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.HC</link>
    <description>cs.HC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.HC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 13 May 2024 04:01:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 13 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Supporting Physical Activity Behavior Change with LLM-Based Conversational Agents</title>
      <link>https://arxiv.org/abs/2405.06061</link>
      <description>arXiv:2405.06061v1 Announce Type: new 
Abstract: Physical activity has significant benefits to health, yet large portions of the population remain physically inactive. Mobile health applications show promising potential for low-cost, scalable physical activity promotion, but existing approaches are often insufficiently personalized to a user's context and life circumstances. In this work, we explore the potential for large language model (LLM) based conversational agents to motivate physical activity behavior change. Through formative interviews with 12 health professionals and 10 non-experts, we identify design considerations and opportunities for LLM health coaching. We present GPTCoach, a chatbot that implements an evidence-based health coaching program, uses counseling strategies from motivational interviewing, and can query and visualize health data from a wearable through tool use. We evaluate GPTCoach as a technology probe in a user study with 16 participants. Through quantitive and qualitative analyses, we find promising evidence that GPTCoach can adhere to a health coaching program while adopting a facilitative, supportive, and non-judgmental tone. We find more variable support for GPTCoach's ability to proactively make use of data in ways that foster motivation and empowerment. We conclude with a discussion of our findings, implications for future research, as well as risks and limitations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06061v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matthew J\"orke, Shardul Sapkota, Lyndsea Warkenthien, Niklas Vainio, Paul Schmiedmayer, Emma Brunskill, James Landay</dc:creator>
    </item>
    <item>
      <title>Believing Anthropomorphism: Examining the Role of Anthropomorphic Cues on Trust in Large Language Models</title>
      <link>https://arxiv.org/abs/2405.06079</link>
      <description>arXiv:2405.06079v1 Announce Type: new 
Abstract: People now regularly interface with Large Language Models (LLMs) via speech and text (e.g., Bard) interfaces. However, little is known about the relationship between how users anthropomorphize an LLM system (i.e., ascribe human-like characteristics to a system) and how they trust the information the system provides. Participants (n=2,165; ranging in age from 18-90 from the United States) completed an online experiment, where they interacted with a pseudo-LLM that varied in modality (text only, speech + text) and grammatical person ("I" vs. "the system") in its responses. Results showed that the "speech + text" condition led to higher anthropomorphism of the system overall, as well as higher ratings of accuracy of the information the system provides. Additionally, the first-person pronoun ("I") led to higher information accuracy and reduced risk ratings, but only in one context. We discuss these findings for their implications for the design of responsible, human-generative AI experiences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06079v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Michelle Cohn, Mahima Pushkarna, Gbolahan O. Olanubi, Joseph M. Moran, Daniel Padgett, Zion Mengesha, Courtney Heldreth</dc:creator>
    </item>
    <item>
      <title>When Are Combinations of Humans and AI Useful?</title>
      <link>https://arxiv.org/abs/2405.06087</link>
      <description>arXiv:2405.06087v1 Announce Type: new 
Abstract: Inspired by the increasing use of AI to augment humans, researchers have studied human-AI systems involving different tasks, systems, and populations. Despite such a large body of work, we lack a broad conceptual understanding of when combinations of humans and AI are better than either alone. Here, we addressed this question by conducting a meta-analysis of over 100 recent experimental studies reporting over 300 effect sizes. First, we found that, on average, human-AI combinations performed significantly worse than the best of humans or AI alone. Second, we found performance losses in tasks that involved making decisions and significantly greater gains in tasks that involved creating content. Finally, when humans outperformed AI alone, we found performance gains in the combination, but when the AI outperformed humans alone we found losses. These findings highlight the heterogeneity of the effects of human-AI collaboration and point to promising avenues for improving human-AI systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06087v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michelle Vaccaro, Abdullah Almaatouq, Thomas Malone</dc:creator>
    </item>
    <item>
      <title>Estimating Speech Duration by Measuring the Abdominal Movement Using a Barometric Sensor</title>
      <link>https://arxiv.org/abs/2405.06252</link>
      <description>arXiv:2405.06252v1 Announce Type: new 
Abstract: Measuring the amount of speech production in daily life is important for understanding communication in organizations and identifying mental disorders. However, measuring the amount of speech production can be problematic in terms of privacy. We observed the whole body condition during speech and noted that the abdomen strains during speech production.Therefore, we developed a less uncomfortable, inflatable abdominal motion measurement device using a barometric sensor to measure speech production indirectly. We measured speech production in 10 subjects and created a speech discrimination model using machine learning. However, the estimated speech duration in an actual meeting using this model was much longer than the actual duration. We found that the wearer's posture significantly affects the accuracy of the speech discrimination model developed in this study. We plan to improve the abdominal motion measurement device to minimize the effect of posture and achieve more accurate speech production measurement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06252v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rintaro Katagiri, Yutaka Arakawa, Yugo Nakamura</dc:creator>
    </item>
    <item>
      <title>Storypark: Leveraging Large Language Models to Enhance Children Story Learning Through Child-AI collaboration Storytelling</title>
      <link>https://arxiv.org/abs/2405.06495</link>
      <description>arXiv:2405.06495v1 Announce Type: new 
Abstract: Interactive storytelling has been widely adopted by educators in teaching activities of young children. Such a teaching method combines storytelling with active child participation, benefiting their expressive abilities, creative thinking, and understanding of stories. Interactive storytelling requires facilitators to unidirectionally narrate the story content and encourage children's participation in story plot creation and interpretation of central themes through multi-sensory interactive methods such as questioning and drawing. However, providing tailored guidance based on diverse feedback from children during interactive storytelling poses challenges for most facilitators. These challenges include expanding story plot development based on children's ideas, using drawings to visualize children's thoughts, and interpreting the story's central themes based on children's thinking. This necessitates facilitators to possess strong imaginative, associative, domain knowledge, and drawing skills. Large language models have demonstrated their potential in facilitating responsive and participatory dialogues, offering new design possibilities to address the challenges faced by facilitators in interactive storytelling. In this study, our goal is to leverage large language models to design an interactive storytelling system that provides children with plot frameworks and interpretations of central themes during the interactive storytelling process. Through user experiments involving 20 child participants, we evaluate this interactive system's usability, learning effectiveness, and user experience. The user study shows that Storypark improves learning outcomes in understanding story key ideas, generalization, and transfer. And high engagement and willingness to use of participants demonstrate that StoryPark provides children with a positive learning experience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06495v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lyumanshan Ye, Jiandong Jiang, Danni Chang, Pengfei Liu</dc:creator>
    </item>
    <item>
      <title>"We are at the mercy of others' opinion": Supporting Blind People in Recreational Window Shopping with AI-infused Technology</title>
      <link>https://arxiv.org/abs/2405.06611</link>
      <description>arXiv:2405.06611v1 Announce Type: new 
Abstract: Engaging in recreational activities in public spaces poses challenges for blind people, often involving dependency on sighted help. Window shopping is a key recreational activity that remains inaccessible. In this paper, we investigate the information needs, challenges, and current approaches blind people have to recreational window shopping to inform the design of existing wayfinding and navigation technology for supporting blind shoppers in exploration and serendipitous discovery. We conduct a formative study with a total of 18 blind participants that include both focus groups (N=8) and interviews for requirements analysis (N=10). We find that there is a desire for push notifications of promotional information and pull notifications about shops of interest such as the targeted audience of a brand. Information about obstacles and points-of-interest required customization depending on one's mobility aid as well as presence of a crowd, children, and wheelchair users. We translate these findings into specific information modalities and rendering in the context of two existing AI-infused assistive applications: NavCog (a turn-by-turn navigation app) and Cabot (a navigation robot).</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06611v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rie Kamikubo, Hernisa Kacorri, Chieko Asakawa</dc:creator>
    </item>
    <item>
      <title>Large Language Models Show Human-like Social Desirability Biases in Survey Responses</title>
      <link>https://arxiv.org/abs/2405.06058</link>
      <description>arXiv:2405.06058v1 Announce Type: cross 
Abstract: As Large Language Models (LLMs) become widely used to model and simulate human behavior, understanding their biases becomes critical. We developed an experimental framework using Big Five personality surveys and uncovered a previously undetected social desirability bias in a wide range of LLMs. By systematically varying the number of questions LLMs were exposed to, we demonstrate their ability to infer when they are being evaluated. When personality evaluation is inferred, LLMs skew their scores towards the desirable ends of trait dimensions (i.e., increased extraversion, decreased neuroticism, etc). This bias exists in all tested models, including GPT-4/3.5, Claude 3, Llama 3, and PaLM-2. Bias levels appear to increase in more recent models, with GPT-4's survey responses changing by 1.20 (human) standard deviations and Llama 3's by 0.98 standard deviations-very large effects. This bias is robust to randomization of question order and paraphrasing. Reverse-coding all the questions decreases bias levels but does not eliminate them, suggesting that this effect cannot be attributed to acquiescence bias. Our findings reveal an emergent social desirability bias and suggest constraints on profiling LLMs with psychometric tests and on using LLMs as proxies for human participants.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06058v1</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aadesh Salecha, Molly E. Ireland, Shashanka Subrahmanya, Jo\~ao Sedoc, Lyle H. Ungar, Johannes C. Eichstaedt</dc:creator>
    </item>
    <item>
      <title>LLMs for XAI: Future Directions for Explaining Explanations</title>
      <link>https://arxiv.org/abs/2405.06064</link>
      <description>arXiv:2405.06064v1 Announce Type: cross 
Abstract: In response to the demand for Explainable Artificial Intelligence (XAI), we investigate the use of Large Language Models (LLMs) to transform ML explanations into natural, human-readable narratives. Rather than directly explaining ML models using LLMs, we focus on refining explanations computed using existing XAI algorithms. We outline several research directions, including defining evaluation metrics, prompt design, comparing LLM models, exploring further training methods, and integrating external data. Initial experiments and user study suggest that LLMs offer a promising way to enhance the interpretability and usability of XAI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06064v1</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexandra Zytek, Sara Pid\`o, Kalyan Veeramachaneni</dc:creator>
    </item>
    <item>
      <title>Collaborative Design for Job-Seekers with Autism: A Conceptual Framework for Future Research</title>
      <link>https://arxiv.org/abs/2405.06078</link>
      <description>arXiv:2405.06078v1 Announce Type: cross 
Abstract: The success of employment is highly related to a job seeker's capability of communicating and collaborating with others. While leveraging one's network during the job-seeking process is intuitive to the neurotypical, this can be challenging for people with autism. Recent empirical findings have started to show how facilitating collaboration between people with autism and their social surroundings through new design can improve their chances of employment. This work aims to provide actionable guidelines and conceptual frameworks that future researchers and practitioners can apply to improve collaborative design for job-seekers with autism. Built upon the literature on past technological interventions built for supporting job-seekers with autism, we define three major research challenges of (1) communication support, (2) employment stage-wise support, and (3) group work support. For each challenge, we review the current state-of-the-art practices and possible future solutions. We then suggest future designs that can provide breakthroughs from the interdisciplinary lens of human-AI collaboration, health services, group work, accessibility computing, and natural language processing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06078v1</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sungsoo Ray Hong, Marcos Zampieri, Brittany N. Hand, Vivian Motti, Dongjun Chung, Ozlem Uzuner</dc:creator>
    </item>
    <item>
      <title>Aligning Tutor Discourse Supporting Rigorous Thinking with Tutee Content Mastery for Predicting Math Achievement</title>
      <link>https://arxiv.org/abs/2405.06218</link>
      <description>arXiv:2405.06218v1 Announce Type: cross 
Abstract: This work investigates how tutoring discourse interacts with students' proximal knowledge to explain and predict students' learning outcomes. Our work is conducted in the context of high-dosage human tutoring where 9th-grade students (N= 1080) attended small group tutorials and individually practiced problems on an Intelligent Tutoring System (ITS). We analyzed whether tutors' talk moves and students' performance on the ITS predicted scores on math learning assessments. We trained Random Forest Classifiers (RFCs) to distinguish high and low assessment scores based on tutor talk moves, student's ITS performance metrics, and their combination. A decision tree was extracted from each RFC to yield an interpretable model. We found AUCs of 0.63 for talk moves, 0.66 for ITS, and 0.77 for their combination, suggesting interactivity among the two feature sources. Specifically, the best decision tree emerged from combining the tutor talk moves that encouraged rigorous thinking and students' ITS mastery. In essence, tutor talk that encouraged mathematical reasoning predicted achievement for students who demonstrated high mastery on the ITS, whereas tutors' revoicing of students' mathematical ideas and contributions was predictive for students with low ITS mastery. Implications for practice are discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06218v1</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mark Abdelshiheed, Jennifer K. Jacobs, Sidney K. D'Mello</dc:creator>
    </item>
    <item>
      <title>Code Compass: A Study on the Challenges of Navigating Unfamiliar Codebases</title>
      <link>https://arxiv.org/abs/2405.06271</link>
      <description>arXiv:2405.06271v1 Announce Type: cross 
Abstract: In our research, we investigate the challenges that software engineers face during program comprehension, particularly when debugging unfamiliar codebases. We propose a novel tool, CodeCompass, to address these issues. Our study highlights a significant gap in current tools and methodologies, especially the difficulty developers encounter in effectively utilizing documentation alongside code exploration. CodeCompass tackles these challenges by seamlessly integrating documentation within the IDE, offering context-aware suggestions and visualizations that streamline the debugging process. Our formative study demonstrates how effectively the tool reduces the time developers spend navigating documentation, thereby enhancing code comprehension and task completion rates. Future work will focus on automating the process of annotating codebases, creating sandbox tasks, and providing dynamic support. These innovations could potentially transform software development practices by improving the accessibility and efficiency of program comprehension tools.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06271v1</guid>
      <category>cs.SE</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ekansh Agrawal, Omair Alam, Chetan Goenka, Medha Iyer, Isabela Moise, Ashish Pandian, Bren Paul</dc:creator>
    </item>
    <item>
      <title>From Prompt Engineering to Prompt Science With Human in the Loop</title>
      <link>https://arxiv.org/abs/2401.04122</link>
      <description>arXiv:2401.04122v3 Announce Type: replace 
Abstract: As LLMs make their way into many aspects of our lives, one place that warrants increased scrutiny with LLM usage is scientific research. Using LLMs for generating or analyzing data for research purposes is gaining popularity. But when such application is marred with ad-hoc decisions and engineering solutions, we need to be concerned about how it may affect that research, its findings, or any future works based on that research. We need a more scientific approach to using LLMs in our research. While there are several active efforts to support more systematic construction of prompts, they are often focused more on achieving desirable outcomes rather than producing replicable and generalizable knowledge with sufficient transparency, objectivity, or rigor. This article presents a new methodology inspired by codebook construction through qualitative methods to address that. Using humans in the loop and a multi-phase verification processes, this methodology lays a foundation for more systematic, objective, and trustworthy way of applying LLMs for analyzing data. Specifically, we show how a set of researchers can work through a rigorous process of labeling, deliberating, and documenting to remove subjectivity and bring transparency and replicability to prompt generation process. A set of experiments are presented to show how this methodology can be put in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.04122v3</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Chirag Shah</dc:creator>
    </item>
    <item>
      <title>Practice-informed Patterns for Organising Large Groups in Distributed Mixed Reality Collaboration</title>
      <link>https://arxiv.org/abs/2405.04873</link>
      <description>arXiv:2405.04873v2 Announce Type: replace 
Abstract: Collaborating across dissimilar, distributed spaces presents numerous challenges for computer-aided spatial communication. Mixed reality (MR) can blend selected surfaces, allowing collaborators to work in blended f-formations (facing formations), even when their workstations are physically misaligned. Since collaboration often involves more than just participant pairs, this research examines how we might scale MR experiences for large-group collaboration. To do so, this study recruited collaboration designers (CDs) to evaluate and reimagine MR for large-scale collaboration. These CDs were engaged in a four-part user study that involved a technology probe, a semi-structured interview, a speculative low-fidelity prototyping activity and a validation session. The outcomes of this paper contribute (1) a set of collaboration design principles to inspire future computer-supported collaborative work, (2) eight collaboration patterns for blended f-formations and collaboration at scale and (3) theoretical implications for f-formations and space-place relationships. As a result, this work creates a blueprint for scaling collaboration across distributed spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04873v2</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3613904.3642502</arxiv:DOI>
      <arxiv:journal_reference>CHI '24, Proceedings of the CHI Conference on Human Factors in Computing Systems, May 11-16 2024, Honolulu, HI, USA</arxiv:journal_reference>
      <dc:creator>Emily Wong, Juan S\'anchez Esquivel, Jens Emil Gr{\o}nb{\ae}k, Germ\'an Leiva, Eduardo Velloso</dc:creator>
    </item>
  </channel>
</rss>
