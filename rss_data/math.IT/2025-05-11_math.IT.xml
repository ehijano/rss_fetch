<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.IT</link>
    <description>math.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 12 May 2025 04:02:18 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 12 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>An Efficient Transport-Based Dissimilarity Measure for Time Series Classification under Warping Distortions</title>
      <link>https://arxiv.org/abs/2505.05676</link>
      <description>arXiv:2505.05676v1 Announce Type: new 
Abstract: Time Series Classification (TSC) is an important problem with numerous applications in science and technology. Dissimilarity-based approaches, such as Dynamic Time Warping (DTW), are classical methods for distinguishing time series when time deformations are confounding information. In this paper, starting from a deformation-based model for signal classes we define a problem statement for time series classification problem. We show that, under theoretically ideal conditions, a continuous version of classic 1NN-DTW method can solve the stated problem, even when only one training sample is available. In addition, we propose an alternative dissimilarity measure based on Optimal Transport and show that it can also solve the aforementioned problem statement at a significantly reduced computational cost. Finally, we demonstrate the application of the newly proposed approach in simulated and real time series classification data, showing the efficacy of the method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.05676v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <pubDate>Mon, 12 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Akram Aldroubi, Roc\'io D\'iaz Mart\'in, Ivan Medri, Kristofor E. Pas, Gustavo K. Rohde, Abu Hasnat Mohammad Rubaiyat</dc:creator>
    </item>
    <item>
      <title>Towards Secure Semantic Transmission In the Era of GenAI: A Diffusion-based Framework</title>
      <link>https://arxiv.org/abs/2505.05724</link>
      <description>arXiv:2505.05724v1 Announce Type: new 
Abstract: Semantic communication, due to its focus on the transmitting meaning rather than the raw bit data, poses unique security challenges compared to the traditional communication systems. In particular, semantic communication systems are vulnerable to the malicious attacks that focus on the semantic layer, with the intention of understanding or distorting the intended meaning of the transmitted privacy data. Diffusion models, a class of generative artificial intelligence (GenAI), are well-suited for ensuring data security to attack. Through iteratively adding and then removing noise, diffusion models can generate meaningful information despite the presence of the unknown noise. This article proposes a diffusion-based framework to enhance the security of semantic transmission for the attacks including eavesdropping and jamming. Specifically, the proposed framework incorporates both the artificial noise and natural channel noise into the forward process of the diffusion models during the semantic transmission, with the reverse process used to remove noise at the legitimate receiver. In the eavesdropping scenarios, the artificial noise is the friendly noise designed to prevent semantic eavesdropping. In the jamming scenarios, the artificial noise is the malicious jamming generated by the jammer, which disrupts the semantic transmission. The case studies show that the proposed diffusion-based framework is promising in securing the semantic transmission. We also consolidate several broad research directions associated with the proposed framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.05724v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 12 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Boxiang He, Zihan Chen, Junshan Luo, Chuanhong Liu, Shilian Wang, Fanggang Wang, Tony Q. S. Quek</dc:creator>
    </item>
    <item>
      <title>Mechanical Power Modeling and Energy Efficiency Maximization for Movable Antenna Systems</title>
      <link>https://arxiv.org/abs/2505.05914</link>
      <description>arXiv:2505.05914v1 Announce Type: new 
Abstract: Movable antennas (MAs) have recently garnered significant attention in wireless communications due to their capability to reshape wireless channels via local antenna movement within a confined region. However, to achieve accurate antenna movement, MA drivers introduce non-negligible mechanical power consumption, rendering energy efficiency (EE) optimization more critical compared to conventional fixed-position antenna (FPA) systems. To address this problem, we develop in this paper a fundamental power consumption model for stepper motor-driven MA systems by resorting to basic electric motor theory. Based on this model, we formulate an EE maximization problem by jointly optimizing an MA's position, moving speed, and transmit power. However, this problem is difficult to solve optimally due to the intricate relationship between the mechanical power consumption and the design variables. To tackle this issue, we first uncover a hidden monotonicity of the EE performance with respect to the MA's moving speed. Then, we apply the Dinkelbach algorithm to obtain the optimal transmit power in a semi-closed form for any given MA position, followed by an enumeration to determine the optimal MA position. Numerical results demonstrate that despite the additional mechanical power consumption, the MA system can outperform the conventional FPA system in terms of EE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.05914v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Mon, 12 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xin Wei, Weidong Mei, Xuan Huang, Zhi Chen, Boyu Ning</dc:creator>
    </item>
    <item>
      <title>List-Recovery of Random Linear Codes over Small Fields</title>
      <link>https://arxiv.org/abs/2505.05935</link>
      <description>arXiv:2505.05935v1 Announce Type: new 
Abstract: We study list-recoverability of random linear codes over small fields, both from errors and from erasures. We consider codes of rate $\epsilon$-close to capacity, and aim to bound the dependence of the output list size $L$ on $\epsilon$, the input list size $\ell$, and the alphabet size $q$. Prior to our work, the best upper bound was $L = q^{O(\ell/\epsilon)}$ (Zyablov and Pinsker, Prob. Per. Inf. 1981).
  Previous work has identified cases in which linear codes provably perform worse than non-linear codes with respect to list-recovery. While there exist non-linear codes that achieve $L=O(\ell/\epsilon)$, we know that $L \ge \ell^{\Omega(1/\epsilon)}$ is necessary for list recovery from erasures over fields of small characteristic, and for list recovery from errors over large alphabets. We show that in other relevant regimes there is no significant price to pay for linearity, in the sense that we get the correct dependence on the gap-to-capacity $\epsilon$ and go beyond the Zyablov-Pinsker bound for the first time. Specifically, when $q$ is constant and $\epsilon$ approaches zero:
  - For list-recovery from erasures over prime fields, we show that $L \leq C_1/\epsilon$. By prior work, such a result cannot be obtained for low-characteristic fields.
  - For list-recovery from errors over arbitrary fields, we prove that $L \leq C_2/\epsilon$.
  Above, $C_1$ and $C_2$ depend on the decoding radius, input list size, and field size. We provide concrete bounds on the constants above, and the upper bounds on $L$ improve upon the Zyablov-Pinsker bound whenever $q\leq 2^{(1/\epsilon)^c}$ for some small universal constant $c&gt;0$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.05935v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 12 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dean Doron, Jonathan Mosheiff, Nicolas Resch, Jo\~ao Ribeiro</dc:creator>
    </item>
    <item>
      <title>Discretized Approximate Ancestral Sampling</title>
      <link>https://arxiv.org/abs/2505.06098</link>
      <description>arXiv:2505.06098v1 Announce Type: new 
Abstract: The Fourier Basis Density Model (FBM) was recently introduced as a flexible probability model for band-limited distributions, i.e. ones which are smooth in the sense of having a characteristic function with limited support around the origin. Its density and cumulative distribution functions can be efficiently evaluated and trained with stochastic optimization methods, which makes the model suitable for deep learning applications. However, the model lacked support for sampling. Here, we introduce a method inspired by discretization--interpolation methods common in Digital Signal Processing, which directly take advantage of the band-limited property. We review mathematical properties of the FBM, and prove quality bounds of the sampled distribution in terms of the total variation (TV) and Wasserstein--1 divergences from the model. These bounds can be used to inform the choice of hyperparameters to reach any desired sample quality. We discuss these results in comparison to a variety of other sampling techniques, highlighting tradeoffs between computational complexity and sampling quality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06098v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Mon, 12 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Alfredo De la Fuente, Saurabh Singh, Jona Ball\'e</dc:creator>
    </item>
    <item>
      <title>On Optimal Batch Size in Coded Computing</title>
      <link>https://arxiv.org/abs/2505.06199</link>
      <description>arXiv:2505.06199v1 Announce Type: new 
Abstract: We consider computing systems that partition jobs into tasks, add redundancy through coding, and assign the encoded tasks to different computing nodes for parallel execution. The expected execution time depends on the level of redundancy. The computing nodes execute large jobs in batches of tasks. We show that the expected execution time depends on the batch size as well. The optimal batch size that minimizes the execution time depends on the level of redundancy under a fixed number of parallel servers and other system parameters. Furthermore, we show how to (jointly) optimize the redundancy level and batch size to reduce the expected job completion time for two service-time distributions. The simulation presented helps us appreciate the claims.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06199v1</guid>
      <category>cs.IT</category>
      <category>cs.DC</category>
      <category>cs.PF</category>
      <category>math.IT</category>
      <pubDate>Mon, 12 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Swapnil Saha, Emina Soljanin, Philip Whiting</dc:creator>
    </item>
    <item>
      <title>Decoding Algorithms for Two-dimensional Constacyclic Codes over $\mathbb{F}_q$</title>
      <link>https://arxiv.org/abs/2505.06201</link>
      <description>arXiv:2505.06201v1 Announce Type: new 
Abstract: We derive the spectral domain properties of two-dimensional (2-D) $(\lambda_1, \lambda_2)$-constacyclic codes over $\mathbb{F}_q$ using the 2-D finite field Fourier transform (FFFT). Based on the spectral nulls of 2-D $(\lambda_1, \lambda_2)$-constacyclic codes, we characterize the structure of 2-D constacyclic coded arrays. The proposed 2-D construction has flexible code rates and works for any code areas, be it odd or even area. We present an algorithm to detect the location of 2-D errors. Further, we also propose decoding algorithms for extracting the error values using both time and frequency domain properties by exploiting the sparsity that arises due to duality in the time and frequency domains. Through several illustrative examples, we demonstrate the working of the proposed decoding algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06201v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 12 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vidya Sagar, Shikha Patel, Shayan Srinivasa Garani</dc:creator>
    </item>
    <item>
      <title>Optimal Regret of Bernoulli Bandits under Global Differential Privacy</title>
      <link>https://arxiv.org/abs/2505.05613</link>
      <description>arXiv:2505.05613v1 Announce Type: cross 
Abstract: As sequential learning algorithms are increasingly applied to real life, ensuring data privacy while maintaining their utilities emerges as a timely question. In this context, regret minimisation in stochastic bandits under $\epsilon$-global Differential Privacy (DP) has been widely studied. Unlike bandits without DP, there is a significant gap between the best-known regret lower and upper bound in this setting, though they "match" in order. Thus, we revisit the regret lower and upper bounds of $\epsilon$-global DP algorithms for Bernoulli bandits and improve both. First, we prove a tighter regret lower bound involving a novel information-theoretic quantity characterising the hardness of $\epsilon$-global DP in stochastic bandits. Our lower bound strictly improves on the existing ones across all $\epsilon$ values. Then, we choose two asymptotically optimal bandit algorithms, i.e. DP-KLUCB and DP-IMED, and propose their DP versions using a unified blueprint, i.e., (a) running in arm-dependent phases, and (b) adding Laplace noise to achieve privacy. For Bernoulli bandits, we analyse the regrets of these algorithms and show that their regrets asymptotically match our lower bound up to a constant arbitrary close to 1. This refutes the conjecture that forgetting past rewards is necessary to design optimal bandit algorithms under global DP. At the core of our algorithms lies a new concentration inequality for sums of Bernoulli variables under Laplace mechanism, which is a new DP version of the Chernoff bound. This result is universally useful as the DP literature commonly treats the concentrations of Laplace noise and random variables separately, while we couple them to yield a tighter bound.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.05613v1</guid>
      <category>stat.ML</category>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 12 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Achraf Azize, Yulian Wu, Junya Honda, Francesco Orabona, Shinji Ito, Debabrota Basu</dc:creator>
    </item>
    <item>
      <title>LLM-Text Watermarking based on Lagrange Interpolation</title>
      <link>https://arxiv.org/abs/2505.05712</link>
      <description>arXiv:2505.05712v1 Announce Type: cross 
Abstract: The rapid advancement of LLMs (Large Language Models) has established them as a foundational technology for many AI and ML powered human computer interactions. A critical challenge in this context is the attribution of LLM-generated text, either to the specific language model used or to the individual user who generated it. This is essential for combating misinformation, fake news, misinterpretation, and plagiarism. One of the key techniques for addressing this issue is watermarking.
  This work presents a watermarking scheme for LLM-generated text based on Lagrange interpolation, which enables the recovery of a secret author identity even when the text has been heavily redacted by an adversary. The core idea is to embed a continuous sequence of points (x, f(x)) that lie on a single straight line. The x-coordinates are generated pseudorandomly using either an LFSR (when security is not a priority) or a cryptographically secure NFSR for high-security applications. The scheme efficiency and resilience to adversarial modifications are analysed. Experimental results show that the proposed method is highly effective, allowing the recovery of the author identity when as few as three points survive adversarial manipulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.05712v1</guid>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 12 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jaros{\l}aw Janas, Pawe{\l} Morawiecki, Josef Pieprzyk</dc:creator>
    </item>
    <item>
      <title>Anti-concentration inequalities for log-concave variables on the real line</title>
      <link>https://arxiv.org/abs/2505.05793</link>
      <description>arXiv:2505.05793v1 Announce Type: cross 
Abstract: We prove sharp anti-concentration results for log-concave random variables on the real line in both the discrete and continuous setting. Our approach is elementary and uses majorization techniques to recover and extend some recent and not so recent results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.05793v1</guid>
      <category>math.PR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 12 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tulio Gaxiola, James Melbourne, Vincent Pigno, Emma Pollard</dc:creator>
    </item>
    <item>
      <title>On the Price of Differential Privacy for Spectral Clustering over Stochastic Block Models</title>
      <link>https://arxiv.org/abs/2505.05816</link>
      <description>arXiv:2505.05816v1 Announce Type: cross 
Abstract: We investigate privacy-preserving spectral clustering for community detection within stochastic block models (SBMs). Specifically, we focus on edge differential privacy (DP) and propose private algorithms for community recovery. Our work explores the fundamental trade-offs between the privacy budget and the accurate recovery of community labels. Furthermore, we establish information-theoretic conditions that guarantee the accuracy of our methods, providing theoretical assurances for successful community recovery under edge DP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.05816v1</guid>
      <category>cs.SI</category>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Mon, 12 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Antti Koskela, Mohamed Seif, Andrea J. Goldsmith</dc:creator>
    </item>
    <item>
      <title>Beyond Diagonal RIS Design for Parameter Estimation With and Without Eavesdropping</title>
      <link>https://arxiv.org/abs/2505.05971</link>
      <description>arXiv:2505.05971v1 Announce Type: cross 
Abstract: In this letter, we investigate the transmission of a complex-valued parameter vector from a transmitter to an intended receiver, considering both the presence and absence of an eavesdropper. The direct links from the transmitter to both the intended receiver and the eavesdropper are assumed to be blocked, and communications occur solely through cascaded channels facilitated by a beyond-diagonal reconfigurable intelligent surface (BD-RIS). While previous research has considered this system under conventional (diagonal) RIS assistance, we extend the setup to incorporate BD-RIS and quantify the resulting improvement in estimation performance at the intended receiver. This performance is measured by the trace of the Fisher information matrix (FIM), or equivalently, the average Fisher information, while simultaneously limiting the estimation capability of the eavesdropper. We propose solutions and algorithms for optimizing the BD-RIS response matrix and demonstrate their effectiveness. Numerical results reveal that the BD-RIS provides a significant enhancement in estimation quality compared to conventional diagonal RIS architectures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.05971v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 12 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>\"Ozlem Tu\u{g}fe Demir, Sinan Gezici</dc:creator>
    </item>
    <item>
      <title>Advancing Finite-Length Quantum Error Correction Using Generalized Bicycle Codes</title>
      <link>https://arxiv.org/abs/2505.06157</link>
      <description>arXiv:2505.06157v1 Announce Type: cross 
Abstract: Generalized bicycle (GB) codes have emerged as a promising class of quantum error-correcting codes with practical decoding capabilities. While numerous asymptotically good quantum codes and quantum low-density parity-check code constructions have been proposed, their finite block-length performance often remains unquantified. In this work, we demonstrate that GB codes exhibit comparable or superior error correction performance in finite-length settings, particularly when designed with higher or unrestricted row weights. Leveraging their flexible construction, GB codes can be tailored to achieve high rates while maintaining efficient decoding. We evaluate GB codes against other leading quantum code families, such as quantum Tanner codes and single-parity-check product codes, highlighting their versatility in practical finite-length applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06157v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 12 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Olai \AA. Mostad, Hsuan-Yin Lin, Eirik Rosnes, De-Shih Lee, Ching-Yi Lai</dc:creator>
    </item>
    <item>
      <title>Channel Capacity and Bounds In Mixed Gaussian-Impulsive Noise</title>
      <link>https://arxiv.org/abs/2311.08804</link>
      <description>arXiv:2311.08804v2 Announce Type: replace 
Abstract: Communication systems suffer from mixed noise consisting of both non-Gaussian impulsive noise (IN) and white Gaussian noise (WGN) in many practical applications. However, there is little literature about the channel capacity under mixed noise. In this paper, we first investigate statistical properties of the mixed noise model and demonstrate the existence and uniqueness of the capacity-achieving input distribution under the $p$-th moment constraint. Then, we derive lower and upper capacity bounds with closed expressions. It is shown that the lower bounds can degenerate to the well-known Shannon formula under special scenarios. More importantly, we obtain the convergence of the lower and upper bound and therefore, the asymptotic and analytical capacity expression is obtained. In addition, the capacity for specific modulations and the corresponding lower bounds are discussed. Numerical results reveal that the capacity decreases as the impulsiveness of the mixed noise becomes dominant and the proposed capacity bounds are very tight.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.08804v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Mon, 12 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianfu Qi, Jun Wang, Xiaoping Li</dc:creator>
    </item>
    <item>
      <title>Generalized Arlery-Tan-Rabaste-Levenshtein Lower Bounds on Ambiguity Function and Their Asymptotic Achievability</title>
      <link>https://arxiv.org/abs/2402.00455</link>
      <description>arXiv:2402.00455v3 Announce Type: replace 
Abstract: This paper presents generalized Arlery-Tan-Rabaste-Levenshtein lower bounds on the maximum aperiodic ambiguity function (AF) magnitude of unimodular sequences under certain delay-Doppler low ambiguity zones (LAZ). Our core idea is to explore the upper and lower bounds on the Frobenius norm of the weighted auto- and cross-AF matrices by introducing two weight vectors associated with the delay and Doppler shifts, respectively. As a second major contribution, we demonstrate that our derived lower bounds are asymptotically achievable with selected Chu sequence sets by analyzing their maximum auto- and cross- AF magnitudes within certain LAZ.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.00455v3</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Mon, 12 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lingsheng Meng, Yong Liang Guan, Yao Ge, Zilong Liu, Pingzhi Fan</dc:creator>
    </item>
    <item>
      <title>Let's Have Both! Optimal List-Recoverability via Alphabet Permutation Codes</title>
      <link>https://arxiv.org/abs/2502.05858</link>
      <description>arXiv:2502.05858v2 Announce Type: replace 
Abstract: We introduce alphabet-permutation (AP) codes, a new family of error-correcting codes defined by iteratively applying random coordinate-wise permutations to a fixed initial word. A special case recovers random additive codes and random binary linear codes, where each permutation corresponds to an additive shift over a finite field.
  We show that when these permutations are drawn from a suitably ``mixing'' distribution, the resulting code is almost surely list-recoverable with list size proportional to the inverse of the gap to capacity. Compared to any linear code, our construction achieves exponentially smaller list sizes at the same rate. Previously, only fully random codes were known to attain such parameters, requiring exponentially many random bits and offering no structure. In contrast, AP codes are structured and require only polynomially many random bits -- providing the first such construction to match the list-recovery guarantees of random codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05858v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 12 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sergey Komech, Jonathan Mosheiff</dc:creator>
    </item>
    <item>
      <title>Divisible minimal codes</title>
      <link>https://arxiv.org/abs/2312.00885</link>
      <description>arXiv:2312.00885v2 Announce Type: replace-cross 
Abstract: Minimal codes are linear codes where all non-zero codewords are minimal, i.e., whose support is not properly contained in the support of another codeword. The minimum possible length of such a $k$-dimensional linear code over $\mathbb{F}_q$ is denoted by $m(k,q)$. Here we determine $m(7,2)$, $m(8,2)$, and $m(9,2)$, as well as full classifications of all codes attaining $m(k,2)$ for $k\le 7$ and those attaining $m(9,2)$. We give improved upper bounds for $m(k,2)$ for all $10\le k\le 17$. It turns out that in many cases the attaining extremal codes have the property that the weights of all codewords are divisible by some constant $\Delta&gt;1$. So, here we study the minimum lengths of minimal codes where we additionally assume that the weights of the codewords are divisible by $\Delta$. As a byproduct we also give a few binary linear codes improving the best known lower bound for the minimum distance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.00885v2</guid>
      <category>math.CO</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 12 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vladimir Chubenko, Sascha Kurz</dc:creator>
    </item>
    <item>
      <title>Is speckle noise more challenging to mitigate than additive noise?</title>
      <link>https://arxiv.org/abs/2409.16585</link>
      <description>arXiv:2409.16585v2 Announce Type: replace-cross 
Abstract: We study the problem of estimating a function in the presence of both speckle and additive noises, commonly referred to as the de-speckling problem. Although additive noise has been thoroughly explored in nonparametric estimation, speckle noise, prevalent in applications such as synthetic aperture radar, ultrasound imaging, and digital holography, has not received as much attention. Consequently, there is a lack of theoretical investigations into the fundamental limits of mitigating the speckle noise.This paper is the first step in filling this gap.
  Our focus is on investigating the minimax estimation error for estimating a $\beta$-H\"older continuous function and determining the rate of the minimax risk. Specifically, if $n$ represents the number of data points, $f$ denotes the underlying function to be estimated, $\hat{\nu}_n$ is an estimate of $f$, and $\sigma_n$ is the standard deviation of the additive Gaussian noise, then $\inf_{\hat{\nu}_n} \sup_f \mathbb{E}_f\| \hat{\nu}_n - f \|^2_2$ decays at the rate $(\max(1,\sigma_n^4)/n)^{\frac{2\beta}{2\beta+1}}$. Note that the rate achieved under purely additive noise is $({\sigma_n^2/n})^{\frac{2\beta}{2\beta+1}}$. We will provide a detailed comparison of this rate with the one obtained in the presence of both noise types across different regimes of their relative magnitudes, and discuss the insights that emerge from these comparisons.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.16585v2</guid>
      <category>math.ST</category>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <category>stat.TH</category>
      <pubDate>Mon, 12 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Reihaneh Malekian, Hao Xing, Arian Maleki</dc:creator>
    </item>
    <item>
      <title>Variational Source-Channel Coding for Semantic Communication</title>
      <link>https://arxiv.org/abs/2410.08222</link>
      <description>arXiv:2410.08222v3 Announce Type: replace-cross 
Abstract: Semantic communication technology emerges as a pivotal bridge connecting AI with classical communication. The current semantic communication systems are generally modeled as an Auto-Encoder (AE). AE lacks a deep integration of AI principles with communication strategies due to its inability to effectively capture channel dynamics. This gap makes it difficult to justify the need for joint source-channel coding (JSCC) and to explain why performance improves. This paper begins by exploring lossless and lossy communication, highlighting that the inclusion of data distortion distinguishes semantic communication from classical communication. It breaks the conditions for the separation theorem to hold and explains why the amount of data transferred by semantic communication is less. Therefore, employing JSCC becomes imperative for achieving optimal semantic communication. Moreover, a Variational Source-Channel Coding (VSCC) method is proposed for constructing semantic communication systems based on data distortion theory, integrating variational inference and channel characteristics. Using a deep learning network, we develop a semantic communication system employing the VSCC method and demonstrate its capability for semantic transmission. We also establish semantic communication systems of equivalent complexity employing the AE method and the VAE method. Experimental results reveal that the VSCC model offers superior interpretability compared to AE model, as it clearly captures the semantic features of the transmitted data, represented as the variance of latent variables in our experiments. In addition, VSCC model exhibits superior semantic transmission capabilities compared to VAE model. At the same level of data distortion evaluated by PSNR, VSCC model exhibits stronger human interpretability, which can be partially assessed by SSIM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08222v3</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Mon, 12 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yulong Feng, Jing Xu, Liujun Hu, Guanghui Yu, Xiangyang Duan</dc:creator>
    </item>
    <item>
      <title>Multi-Draft Speculative Sampling: Canonical Decomposition and Theoretical Limits</title>
      <link>https://arxiv.org/abs/2410.18234</link>
      <description>arXiv:2410.18234v2 Announce Type: replace-cross 
Abstract: We consider multi-draft speculative sampling, where the proposal sequences are sampled independently from different draft models. At each step, a token-level draft selection scheme takes a list of valid tokens as input and produces an output token whose distribution matches that of the target model. Previous works have demonstrated that the optimal scheme (which maximizes the probability of accepting one of the input tokens) can be cast as a solution to a linear program. In this work we show that the optimal scheme can be decomposed into a two-step solution: in the first step an importance sampling (IS) type scheme is used to select one intermediate token; in the second step (single-draft) speculative sampling is applied to generate the output token. For the case of two identical draft models we further 1) establish a necessary and sufficient condition on the distributions of the target and draft models for the acceptance probability to equal one and 2) provide an explicit expression for the optimal acceptance probability. Our theoretical analysis also motives a new class of token-level selection schemes based on weighted importance sampling. Our experimental results demonstrate consistent improvements in the achievable block efficiency and token rates over baseline schemes in a number of scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18234v2</guid>
      <category>cs.CL</category>
      <category>cs.DC</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Mon, 12 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ashish Khisti, M. Reza Ebrahimi, Hassan Dbouk, Arash Behboodi, Roland Memisevic, Christos Louizos</dc:creator>
    </item>
  </channel>
</rss>
