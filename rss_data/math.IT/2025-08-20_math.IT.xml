<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.IT</link>
    <description>math.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 21 Aug 2025 04:01:58 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 21 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Multi-Source Peak Age of Information Optimization in Mobile Edge Computing Systems</title>
      <link>https://arxiv.org/abs/2508.14328</link>
      <description>arXiv:2508.14328v1 Announce Type: new 
Abstract: Age of Information (AoI) is emerging as a novel metric for measuring information freshness in real-time monitoring systems. For computation-intensive status data, the information is not revealed until being processed. We consider a status update problem in a multi-source single-server system where the sources are scheduled to generate and transmit status data which are received and processed at the edge server. Generate-at-will sources with both random transmission time and process time are considered, introducing the joint optimization of source scheduling and status sampling on the basis of transmission-computation balancing. We show that a random scheduler is optimal for both non-preemptive and preemptive server settings, and the optimal sampler depends on the scheduling result and its structure remains consistent with the single-source system, i.e., threshold-based sampler for non-preemptive case and transmission-aware deterministic sampler for preemptive case. Then, the problem can be transformed to jointly optimizing the scheduling frequencies and the sampling thresholds/functions, which is non-convex. We proposed an alternation optimization algorithm to solve it. Numerical experiments show that the proposed algorithm can achieve the optimal in a wide range of settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.14328v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 21 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jianhang Zhu, Jie Gong</dc:creator>
    </item>
    <item>
      <title>Reconstruction Codes for Deletions and Insertions: Connection, Distinction, and Construction</title>
      <link>https://arxiv.org/abs/2508.14386</link>
      <description>arXiv:2508.14386v1 Announce Type: new 
Abstract: Let $\mathcal{B}(\cdot)$ be an error ball function. A set of $q$-ary sequences of length $n$ is referred to as an \emph{$(n,q,N;\mathcal{B})$-reconstruction code} if each sequence $\boldsymbol{x}$ within this set can be uniquely reconstructed from any $N$ distinct elements within its error ball $\mathcal{B}(\boldsymbol{x})$. The main objective in this area is to determine or establish bounds for the minimum redundancy of $(n,q,N;\mathcal{B})$-reconstruction codes, denoted by $\rho(n,q,N;\mathcal{B})$. In this paper, we investigate reconstruction codes where the error ball is either the \emph{$t$-deletion ball} $\mathcal{D}_t(\cdot)$ or the \emph{$t$-insertion ball} $\mathcal{I}_t(\cdot)$. Firstly, we establish a fundamental connection between reconstruction codes for deletions and insertions. For any positive integers $n,t,q,N$, any $(n,q,N;\mathcal{I}_t)$-reconstruction code is also an $(n,q,N;\mathcal{D}_t)$-reconstruction code. This leads to the inequality $\rho(n,q,N;\mathcal{D}_t)\leq \rho(n,q,N;\mathcal{I}_t)$. Then, we identify a significant distinction between reconstruction codes for deletions and insertions when $N=O(n^{t-1})$ and $t\geq 2$. For deletions, we prove that $\rho(n,q,\tfrac{2(q-1)^{t-1}}{q^{t-1}(t-1)!}n^{t-1}+O(n^{t-2});\mathcal{D}_t)=O(1)$, which disproves a conjecture posed in \cite{Chrisnata-22-IT}. For insertions, we show that $\rho(n,q,\tfrac{(q-1)^{t-1}}{(t-1)!}n^{t-1}+O(n^{t-2});\mathcal{I}_t)=\log\log n + O(1)$, which extends a key result from \cite{Ye-23-IT}. Finally, we construct $(n,q,N;\mathcal{B})$-reconstruction codes, where $\mathcal{B}\in \{\mathcal{D}_2,\mathcal{I}_2\}$, for $N \in \{2,3, 4, 5\}$ and establish respective upper bounds of $3\log n+O(\log\log n)$, $3\log n+O(1)$, $2\log n+O(\log\log n)$ and $\log n+O(\log\log n)$ on the minimum redundancy $\rho(n,q,N;\mathcal{B})$. This generalizes results previously established in \cite{Sun-23-IT}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.14386v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 21 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yubo Sun, Gennian Ge</dc:creator>
    </item>
    <item>
      <title>DeepTelecom: A Digital-Twin Deep Learning Dataset for Channel and MIMO Applications</title>
      <link>https://arxiv.org/abs/2508.14507</link>
      <description>arXiv:2508.14507v1 Announce Type: new 
Abstract: Domain-specific datasets are the foundation for unleashing artificial intelligence (AI)-driven wireless innovation. Yet existing wireless AI corpora are slow to produce, offer limited modeling fidelity, and cover only narrow scenario types. To address the challenges, we create DeepTelecom, a three-dimension (3D) digital-twin channel dataset. Specifically, a large language model (LLM)-assisted pipeline first builds the third level of details (LoD3) outdoor and indoor scenes with segmentable material-parameterizable surfaces. Then, DeepTelecom simulates full radio-wave propagation effects based on Sionna's ray-tracing engine. Leveraging GPU acceleration, DeepTelecom streams ray-path trajectories and real-time signal-strength heat maps, compiles them into high-frame-rate videos, and simultaneously outputs synchronized multi-view images, channel tensors, and multi-scale fading traces. By efficiently streaming large-scale, high-fidelity, and multimodal channel data, DeepTelecom not only furnishes a unified benchmark for wireless AI research but also supplies the domain-rich training substrate that enables foundation models to tightly fuse large model intelligence with future communication systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.14507v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 21 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bohao Wang, Zehua Jiang, Zhenyu Yang, Chongwen Huang, Yongliang Shen, Siming Jiang, Chen Zhu, Zhaohui Yang, Richeng Jin, Zhaoyang Zhang, Sami Muhaidat, Merouane Debbah</dc:creator>
    </item>
    <item>
      <title>Minimizing Task-Oriented Age of Information for Remote Monitoring with Pre-Identification</title>
      <link>https://arxiv.org/abs/2508.14575</link>
      <description>arXiv:2508.14575v1 Announce Type: new 
Abstract: The emergence of new intelligent applications has fostered the development of a task-oriented communication paradigm, where a comprehensive, universal, and practical metric is crucial for unleashing the potential of this paradigm. To this end, we introduce an innovative metric, the Task-oriented Age of Information (TAoI), to measure whether the content of information is relevant to the system task, thereby assisting the system in efficiently completing designated tasks. We apply TAoI to a wireless monitoring system tasked with identifying targets and transmitting their images for subsequent analysis. To minimize TAoI and determine the optimal transmission policy, we formulate the dynamic transmission problem as a Semi-Markov Decision Process (SMDP) and transform it into an equivalent Markov Decision Process (MDP). Our analysis demonstrates that the optimal policy is threshold-based with respect to TAoI. Building on this, we propose a low-complexity relative value iteration algorithm tailored to this threshold structure to derive the optimal transmission policy. Additionally, we introduce a simpler single-threshold policy, which, despite a slight performance degradation, offers faster convergence. Comprehensive experiments and simulations validate the superior performance of our optimal transmission policy compared to two established baseline approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.14575v1</guid>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <pubDate>Thu, 21 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuying Gan, Xijun Wang, Chao Xu, Xiang Chen</dc:creator>
    </item>
    <item>
      <title>Context Steering: A New Paradigm for Compression-based Embeddings by Synthesizing Relevant Information Features</title>
      <link>https://arxiv.org/abs/2508.14780</link>
      <description>arXiv:2508.14780v1 Announce Type: cross 
Abstract: Compression-based distances (CD) offer a flexible and domain-agnostic means of measuring similarity by identifying implicit information through redundancies between data objects. However, as similarity features are derived from the data, rather than defined as an input, it often proves difficult to align with the task at hand, particularly in complex clustering or classification settings. To address this issue, we introduce "context steering," a novel methodology that actively guides the feature-shaping process. Instead of passively accepting the emergent data structure (typically a hierarchy derived from clustering CDs), our approach "steers" the process by systematically analyzing how each object influences the relational context within a clustering framework. This process generates a custom-tailored embedding that isolates and amplifies class-distinctive information. We validate the capabilities of this strategy using Normalized Compression Distance (NCD) and Relative Compression Distance (NRC) with common hierarchical clustering, providing an effective alternative to common transductive methods. Experimental results across heterogeneous datasets-from text to real-world audio-validate the robustness and generality of context steering, marking a fundamental shift in their application: from merely discovering inherent data structures to actively shaping a feature space tailored to a specific objective.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.14780v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 21 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guillermo Sarasa Dur\'an, Ana Granados Fontecha, Francisco de Borja Rodr\'iguez Ort\'iz</dc:creator>
    </item>
    <item>
      <title>Cell-Free Massive MIMO SWIPT with Beyond Diagonal Reconfigurable Intelligent Surfaces</title>
      <link>https://arxiv.org/abs/2402.00646</link>
      <description>arXiv:2402.00646v3 Announce Type: replace 
Abstract: This paper investigates the integration of beyond-diagonal reconfigurable intelligent surfaces (BD-RISs) into cell-free massive multiple-input multiple-output (CF-mMIMO) systems, focusing on applications involving simultaneous wireless information and power transfer (SWIPT). The system supports concurrently two user groups: information users (IUs) and energy users (EUs). A BD-RIS is employed to enhance the wireless power transfer (WPT) directed towards the EUs. To comprehensively evaluate the system's performance, we present an analytical framework for the spectral efficiency (SE) of IUs and the average harvested energy (HE) of EUs in the presence of spatial correlation among the BD-RIS elements and for a non-linear energy harvesting circuit. Our findings offer important insights into the transformative potential of BD-RIS, setting the stage for the development of more efficient and effective SWIPT networks. Finally, incorporating a heuristic scattering matrix design at the BD-RIS results in a substantial improvement compared to the scenario with random scattering matrix</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.00646v3</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Thu, 21 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/WCNC57260.2024.10571002</arxiv:DOI>
      <arxiv:journal_reference>2024 IEEE Wireless Communications and Networking Conference (WCNC)</arxiv:journal_reference>
      <dc:creator>Thien Duc Hua, Mohammadali Mohammadi, Hien Quoc Ngo, Michail Matthaiou</dc:creator>
    </item>
    <item>
      <title>Bounds on the privacy amplification of arbitrary channels via the contraction of $f_\alpha$-divergence</title>
      <link>https://arxiv.org/abs/2501.11473</link>
      <description>arXiv:2501.11473v3 Announce Type: replace 
Abstract: We examine the privacy amplification of channels that do not necessarily satisfy any LDP guarantee by analyzing their contraction behavior in terms of $f_\alpha$-divergence, an $f$-divergence related to R\'enyi-divergence via a monotonic transformation. We present bounds on contraction for restricted sets of prior distributions via $f$-divergence inequalities and present an improved Pinsker's inequality for $f_\alpha$-divergence based on the joint range technique by Harremo\"es and Vajda. The presented bound is tight whenever the value of the total variation distance is larger than $1/alpha$. By applying these inequalities in a cross-channel setting, we arrive at strong data processing inequalities for $f_\alpha$-divergence that can be adapted to use-case specific restrictions of input distributions and channel. The application of these results to privacy amplification shows that even very sparse channels can lead to significant privacy amplification when used as a post-processing step after local differentially private mechanisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11473v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 21 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Leonhard Grosse, Sara Saeidian, Tobias J. Oechtering, Mikael Skoglund</dc:creator>
    </item>
    <item>
      <title>On the Source Model Key Agreement Problem</title>
      <link>https://arxiv.org/abs/2502.00294</link>
      <description>arXiv:2502.00294v3 Announce Type: replace 
Abstract: We consider the source model key agreement problem involving two legitimate parties and an eavesdropper who observe n i.i.d. samples of X, Y, and Z, respectively. In this paper, we focus on one of the simplest instances where the key capacity remains open, specifically when X and Y are binary random variables and Z is a function of the pair (X, Y). The best-known upper bound on the key capacity is characterized by an inf-max optimization problem that generally lacks a closed-form solution. We provide general conditions under which the upper bound reduces to I(X;Y). As an example, we consider the XOR setting in which X and Y are binary, and Z is the XOR of X and Y. The upper bound reduces to I(X;Y) for this source. Next, we conjecture that the rate I(X;Y) is not achievable for the XOR source and provide some ideas that might be useful for developing a new upper bound on the source model problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00294v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 21 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hamidreza Abin, Amin Gohari</dc:creator>
    </item>
    <item>
      <title>Sum Capacity Characterization of Pinching Antennas-assisted Multiple Access Channels</title>
      <link>https://arxiv.org/abs/2508.05309</link>
      <description>arXiv:2508.05309v2 Announce Type: replace 
Abstract: Pinching antenna system (PASS) has recently shown its promising ability to flexibly reconfigure wireless channels via dynamically adjusting the positions of pinching antennas over a dielectric waveguide, termed as pinching beamforming. This paper studies the fundamental limit of the sum rate for a PASS-assisted multiple access channel, where multiple users transmit individual messages to a base station under the average power constraint. To this end, a dynamic pinching beamforming setup is conceived, where multiple pinching beamforming vectors are employed in a transmission period and the capacity-achieving non-orthogonal multiple access (NOMA) based scheme is considered. For the ideal case with an asymptotically large number of pinching beamforming vectors, the optimal transmission scheme is unveiled to carry out alternating transmission among each user whose channel power gain is maximized with the tailored pinching beamforming. This implies that NOMA is not needed for achieving the sum capacity and the required optimal number of pinching beamforming vectors is equal to the number of users. With this insight, the corresponding sum rate is derived in closed-form expression, which serves as the upper bound of the sum rate. Inspired by this result, a lower bound of the sum rate under an arbitrarily finite number of pinching beamforming vectors is obtained. Numerical results validate our theoretical findings and also illustrate the practical significance of using dynamic pinching beamforming to improve the sum rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05309v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 21 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guangji Chen, Qingqing Wu, Kangda Zhi, Xidong Mu, Yuanwei Liu</dc:creator>
    </item>
    <item>
      <title>Age of Semantic Information-Aware Wireless Transmission for Remote Monitoring Systems</title>
      <link>https://arxiv.org/abs/2508.12248</link>
      <description>arXiv:2508.12248v2 Announce Type: replace 
Abstract: Semantic communication is emerging as an effective means of facilitating intelligent and context-aware communication for next-generation communication systems. In this paper, we propose a novel metric called Age of Incorrect Semantics (AoIS) for the transmission of video frames over multiple-input multiple-output (MIMO) channels in a monitoring system. Different from the conventional age-based approaches, we jointly consider the information freshness and the semantic importance, and then formulate a time-averaged AoIS minimization problem by jointly optimizing the semantic actuation indicator, transceiver beamformer, and the semantic symbol design. We first transform the original problem into a low-complexity problem via the Lyapunov optimization. Then, we decompose the transformed problem into multiple subproblems and adopt the alternative optimization (AO) method to solve each subproblem. Specifically, we propose two efficient algorithms, i.e., the successive convex approximation (SCA) algorithm and the low-complexity zero-forcing (ZF) algorithm for optimizing transceiver beamformer. We adopt exhaustive search methods to solve the semantic actuation policy indicator optimization problem and the transmitted semantic symbol design problem. Experimental results demonstrate that our scheme can preserve more than 50\% of the original information under the same AoIS compared to the constrained baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.12248v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 21 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xue Han, Biqian Feng, Yongpeng Wu, Xiang-Gen Xia, Wenjun Zhang, Shengli Sun</dc:creator>
    </item>
    <item>
      <title>Cellular, Cell-less, and Everything in Between: A Unified Framework for Utility Region Analysis in Wireless Networks</title>
      <link>https://arxiv.org/abs/2507.23707</link>
      <description>arXiv:2507.23707v2 Announce Type: replace-cross 
Abstract: We introduce a unified framework for analyzing utility regions of wireless networks, with a focus on the signal-to-interference-noise-ratio (SINR) and achievable rate regions. The framework provides valuable insights into interference patterns of modern network architectures, such as cell-less and extremely large MIMO networks, and it generalizes existing characterizations of the weak Pareto boundary. A central contribution is the derivation of sufficient conditions that guarantee convexity of the utility regions. Convexity is an important property because it ensures that time sharing (or user grouping) cannot simultaneously increase the utility of all users when the network operates on the weak Pareto boundary. These sufficient conditions also have two key implications. First, they identify a family of (weighted) sum-rate maximization problems that are inherently convex without any variable transformations, thus paving the way for the development of efficient, provably optimal solvers for this family. Second, they provide a rigorous justification for formulating sum-rate maximization problems directly in terms of achievable rates, rather than SINR levels. Our theoretical insights also motivate an alternative to the concept of favorable propagation in the massive MIMO literature -- one that explicitly accounts for self-interference and the beamforming strategy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.23707v2</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 21 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Renato Luis Garrido Cavalcante, Tomasz Piotrowski, Slawomir Stanczak</dc:creator>
    </item>
    <item>
      <title>A Novel Image Similarity Metric for Scene Composition Structure</title>
      <link>https://arxiv.org/abs/2508.05037</link>
      <description>arXiv:2508.05037v2 Announce Type: replace-cross 
Abstract: The rapid advancement of generative AI models necessitates novel methods for evaluating image quality that extend beyond human perception. A critical concern for these models is the preservation of an image's underlying Scene Composition Structure (SCS), which defines the geometric relationships among objects and the background, their relative positions, sizes, orientations, etc. Maintaining SCS integrity is paramount for ensuring faithful and structurally accurate GenAI outputs. Traditional image similarity metrics often fall short in assessing SCS. Pixel-level approaches are overly sensitive to minor visual noise, while perception-based metrics prioritize human aesthetic appeal, neither adequately capturing structural fidelity. Furthermore, recent neural-network-based metrics introduce training overheads and potential generalization issues. We introduce the SCS Similarity Index Measure (SCSSIM), a novel, analytical, and training-free metric that quantifies SCS preservation by exploiting statistical measures derived from the Cuboidal hierarchical partitioning of images, robustly capturing non-object-based structural relationships. Our experiments demonstrate SCSSIM's high invariance to non-compositional distortions, accurately reflecting unchanged SCS. Conversely, it shows a strong monotonic decrease for compositional distortions, precisely indicating when SCS has been altered. Compared to existing metrics, SCSSIM exhibits superior properties for structural evaluation, making it an invaluable tool for developing and evaluating generative models, ensuring the integrity of scene composition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05037v2</guid>
      <category>cs.CV</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 21 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Md Redwanul Haque, Manzur Murshed, Manoranjan Paul, Tsz-Kwan Lee</dc:creator>
    </item>
  </channel>
</rss>
