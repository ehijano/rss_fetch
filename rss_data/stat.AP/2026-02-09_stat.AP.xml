<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 09 Feb 2026 05:01:17 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Early warning of Mpox outbreaks in U.S. jurisdictions using Lasso Vector Autoregression models with cross-jurisdictional lags</title>
      <link>https://arxiv.org/abs/2602.06135</link>
      <description>arXiv:2602.06135v1 Announce Type: new 
Abstract: Mpox is an orthopoxvirus that infects humans and animals and is transmitted primarily through close physical contact. The episodic and spatially heterogeneous dynamics of Mpox transmission underscores the need for timely, area-specific forecasts to support targeted public health responses in the U.S. We develop a Vector Autoregression model with Lasso regularization (VAR-Lasso) to generate rolling two-week-ahead forecasts of weekly Mpox cases for eight high-incidence U.S. jurisdictions using national surveillance data from the Centers for Disease Control and Prevention (CDC). The VAR-Lasso model identifies significant long-lag, cross-jurisdictional predictors. For a case study in San Diego County (SDC), these statistical predictors align with phylogenetic analysis that traces a 2023 cluster in SDC to an outbreak in Illinois six months earlier. As the need for public health action is often greatest when incidence is increasing, our performance evaluation focuses on positive-slope weighted error metrics. Forecast performance of the VAR-Lasso model is compared to a uni-variate Auto-Regressive (AR) Lasso model and a naive moving-average estimate. The models are compared using slope-weighted Root Mean Squared Error (RMSE), slope-weighted Mean Absolute Error (MAE), and slope-weighted bias. Across all observations, the VAR-Lasso model reduces slope-weighted RMSE, MAE, and bias by 12%, 7%, and 66% relative to the AR model, and by 16%, 13%, and 76% relative to the naive benchmark. Our findings highlight the value of sparse multivariate time-series models that leverage cross-jurisdictional case data for early forecasting of Mpox outbreaks. Such forecasting can aid health departments in proactively providing timely resources and messaging to mitigate the risks of a future outbreak.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.06135v1</guid>
      <category>stat.AP</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hannah Craddock, Joel O. Wertheim, Eliah Aronoff-Spencer, Mark Beatty, David Valentine, Rishi Graham, Jade C. Wang, Lior Rennert, Seema Shah, Ravi Goyal, Natasha K. Martin</dc:creator>
    </item>
    <item>
      <title>Non-Linear Drivers of Population Dynamics: a Nonparametric Coalescent Approach</title>
      <link>https://arxiv.org/abs/2602.06148</link>
      <description>arXiv:2602.06148v1 Announce Type: new 
Abstract: Effective population size (Ne(t)) is a fundamental parameter in population genetics and phylodynamics that quantifies genetic diversity and reveals demographic history. Coalescent-based methods enable the inference of Ne(t) trajectories through time from phylogenies reconstructed from molecular sequence data. Understanding the ecological and environmental drivers of population dynamics requires linking Ne(t) to external covariates. Existing approaches typically impose log-linear relationships between covariates and Ne(t), which may fail to capture complex biological processes and can introduce bias when the true relationship is nonlinear. We present a flexible Bayesian framework that integrates covariates into coalescent models with piecewise-constant Ne(t) through a Gaussian process (GP) prior. The GP, a distribution over functions, naturally accommodates nonlinear covariate effects without restrictive parametric assumptions. This formulation improves estimation of covariate-Ne(t) relationships, mitigates bias under nonlinear associations, and yields interpretable uncertainty quantification that varies across the covariate space. To balance global covariate-driven patterns with local temporal dynamics, we couple the GP prior with a Gaussian Markov random field that enforces smoothness in Ne(t) trajectories. Through simulation studies and three empirical applications - yellow fever virus dynamics in Brazil (2016-2018), late-Quaternary musk ox demography, and HIV-1 CRF02-AG evolution in Cameroon - we demonstrate that our method both confirms linear relationships where appropriate and reveals nonlinear covariate effects that would otherwise be missed or mischaracterized. This framework advances phylodynamic inference by enabling more accurate and biologically realistic modeling of how environmental and epidemiological factors shape population size through time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.06148v1</guid>
      <category>stat.AP</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Filippo Monti, Nuno R. Faria, Xiang Ji, Philippe Lemey, Moritz U. G. Kraemer, Marc A. Suchard</dc:creator>
    </item>
    <item>
      <title>Evaluating Predictive Modeling Strategies for Predicting Individual Treatment Effects in Precision Medicine</title>
      <link>https://arxiv.org/abs/2602.06210</link>
      <description>arXiv:2602.06210v1 Announce Type: new 
Abstract: Precision medicine seeks to match patients with treatments that produce the greatest benefit. The Predicted Individual Treatment Effect (PITE)-the difference between predicted outcomes under treatment and control-quantifies this benefit but is difficult to estimate due to unobserved counterfactuals, high dimensionality, and complex interactions. We compared 30+ modeling strategies, including penalized and projection-based methods, flexible learners, and tree-ensembles, using a structured simulation framework varying sample size, dimensionality, multicollinearity, and interaction complexity. Performance was measured using root mean squared error (RMSE) for prediction accuracy and directional accuracy (DIR) for correctly classifying benefit versus harm. Internal validation produced optimistic estimates, whereas external validation with distributional shifts and higher-order interactions more clearly revealed model weaknesses. Penalized and projection-based approaches-ridge, lasso, elastic net, partial least squares (PLS), and principal components regression (PCR)-consistently achieved strong RMSE and DIR performance. Flexible learners excelled only under strong signals and sufficient sample sizes. Results highlight robust linear/projection defaults and the necessity of rigorous external validation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.06210v1</guid>
      <category>stat.AP</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Pamela M. Chiroque-Solano, M Lee Van Horn, Thomas Jaki</dc:creator>
    </item>
    <item>
      <title>Modeling the Hazard Function with Non-linear Systems in Dynamical Survival Analysis</title>
      <link>https://arxiv.org/abs/2602.06322</link>
      <description>arXiv:2602.06322v1 Announce Type: new 
Abstract: Hazard functions play a central role in survival analysis, offering insight into the underlying risk dynamics of time to event data, with broad applications in medicine, epidemiology, and related fields. First order ordinary differential equation (ODE) formulations of the hazard function have been explored as extensions beyond classical parametric models. However, such approaches typically produce monotonic hazard patterns, limiting their ability to represent oscillatory behavior, nonlinear damping, or coupled growth decay dynamics. We propose a new statistical framework for modeling and simulating hazard functions governed by higher-order ODEs, allowing risk to depend on both its current level, its rate of change, and time. This class of models captures complex time dependent risk behaviors relevant to survival analysis and reliability studies. We develop a simulation procedure by reformulating the higher order ODE as a system of nonlinear first order equations solved numerically, with failure times generated via cumulative hazard inversion. Likelihood based inference under right censoring is also developed, and moment generating function analysis is used to characterize tail behavior. The proposed framework is evaluated through simulation studies and illustrated using real world survival data, where oscillatory hazard dynamics capture temporal risk patterns beyond standard monotone models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.06322v1</guid>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Dananjani Liyanage, Mahmudul Bari Hridoy, Fahad Mostafa</dc:creator>
    </item>
    <item>
      <title>Latent variation in pathogen strain-specific effects under multiple-versions-of-treatment theory</title>
      <link>https://arxiv.org/abs/2602.06262</link>
      <description>arXiv:2602.06262v1 Announce Type: cross 
Abstract: Evidence-informed policy on infections requires estimates of their effects on health. However, pathogenic variation, whereby occurrence of adverse outcomes depends on the infecting strain, might complicate the study of many infectious agents. Here, we consider the interpretation of epidemiologic studies on effects of infections on health when there is heterogeneity in strain-specific effects and information on strain composition is unavailable. We use potential outcomes and causal inference theory for analyses in the presence of multiple versions of treatment to argue that oft-reported quantities in these studies have a causal interpretation that depends on population frequencies of infecting strains. Moreover, as in other contexts where the treatment-variation-irrelevance assumption might be violated, transportability requires additional considerations, beyond those needed for non-compound exposures. This discussion, that considers potential heterogeneity in strain-specific effects, will facilitate interpretation of these studies, and for the reasons mentioned above, also highlights the value of pathogen subtype data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.06262v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bronner P. Gon\c{c}alves</dc:creator>
    </item>
    <item>
      <title>Design-Conditional Prior Elicitation for Dirichlet Process Mixtures: A Unified Framework for Cluster Counts and Weight Control</title>
      <link>https://arxiv.org/abs/2602.06301</link>
      <description>arXiv:2602.06301v1 Announce Type: cross 
Abstract: Dirichlet process mixture (DPM) models are widely used for semiparametric Bayesian analysis in educational and behavioral research, yet specifying the concentration parameter remains a critical barrier. Default hyperpriors often impose strong, unintended assumptions about clustering, while existing calibration methods based on cluster counts suffer from computational inefficiency and fail to control the distribution of mixture weights. This article introduces Design-Conditional Elicitation (DCE), a unified framework that translates practitioner beliefs about cluster structure into coherent Gamma hyperpriors for a fixed design size J. DCE makes three contributions. First, it solves the computational bottleneck using Two-Stage Moment Matching (TSMM), which couples a closed-form approximation with an exact Newton refinement to calibrate hyperparameters without grid search. Second, addressing the "unintended prior" phenomenon, DCE incorporates a Dual-Anchor protocol to diagnose and optionally constrain the risk of weight dominance while transparently reporting the resulting trade-off against cluster-count fidelity. Third, the complete workflow is implemented in the open-source DPprior R package with reproducible diagnostics and a reporting checklist. Simulation studies demonstrate that common defaults such as Gamma(1, 1) induce posterior collapse rates exceeding 60% regardless of the true cluster structure, while DCE-calibrated priors substantially reduce bias and improve recovery across varying levels of data informativeness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.06301v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>JoonHo Lee</dc:creator>
    </item>
    <item>
      <title>E-values for Adaptive Clinical Trials: Anytime-Valid Monitoring in Practice</title>
      <link>https://arxiv.org/abs/2602.06379</link>
      <description>arXiv:2602.06379v1 Announce Type: cross 
Abstract: Adaptive clinical trials rely on interim analyses, flexible stopping, and data-dependent design modifications that complicate statistical guarantees when fixed-horizon test statistics are repeatedly inspected or reused after adaptations. E-values and e-processes provide anytime-valid tests and confidence sequences that remain valid under optional stopping and optional continuation without requiring a prespecified monitoring schedule.
  This paper is a methodology guide for practitioners. We develop the betting-martingale construction of e-processes for two-arm randomized controlled trials, show how e-values naturally handle composite null hypotheses and support futility monitoring, and provide guidance on when e-values are appropriate, when established alternatives are preferable, and how to integrate e-value monitoring with group sequential and Bayesian adaptive workflows.
  A numerical study compares five monitoring rules -- naive and calibrated versions of frequentist, Bayesian, and e-value approaches -- in a two-arm binary-endpoint trial. Naive repeated testing and naive posterior thresholds inflate Type I error substantially under frequent interim looks. Among the valid methods, the calibrated group sequential rule achieves the highest power, the e-value rule provides robust anytime-valid control with moderate power, and the calibrated Bayesian rule is the most conservative.
  Extended simulations show that the power gap between group sequential and e-value methods depends on the monitoring schedule and reverses under continuous monitoring. The methodology, including futility monitoring, platform trial multiplicity control, and hybrid strategies combining e-values with established methods, is implemented in the open-source R package `evalinger` and situated within the regulatory framework of the January 2026 FDA draft guidance on Bayesian methodology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.06379v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexandra Sokolova, Vadim Sokolov</dc:creator>
    </item>
    <item>
      <title>Assessment of evidence against homogeneity in exhaustive subgroup treatment effect plots</title>
      <link>https://arxiv.org/abs/2602.06910</link>
      <description>arXiv:2602.06910v1 Announce Type: cross 
Abstract: Exhaustive subgroup treatment effect plots are constructed by displaying all subgroup treatment effects of interest against subgroup sample size, providing a useful overview of the observed treatment effect heterogeneity in a clinical trial. As in any exploratory subgroup analysis, however, the observed estimates suffer from small sample sizes and multiplicity issues. To facilitate more interpretable exploratory assessments, this paper introduces a computationally efficient method to generate homogeneity regions within exhaustive subgroup treatment effect plots. Using the Doubly Robust (DR) learner, pseudo-outcomes are used to estimate subgroup effects and derive reference distributions, quantifying how surprising observed heterogeneity is under a homogeneous effects model. Explicit formulas are derived for the homogeneity region and different methods for calculation of the critical values are compared. The method is illustrated with a cardiovascular trial and evaluated via simulation, showing well-calibrated inference and improved performance over standard approaches using simple differences of observed group means.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.06910v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bj\"orn Bornkamp, Jiarui Lu, Frank Bretz</dc:creator>
    </item>
    <item>
      <title>Scalable Bayesian Image-on-Scalar Regression for Population-Scale Neuroimaging Data Analysis</title>
      <link>https://arxiv.org/abs/2404.13204</link>
      <description>arXiv:2404.13204v3 Announce Type: replace 
Abstract: Bayesian Image-on-Scalar Regression (ISR) provides flexible, uncertainty-aware neuroimaging analysis. However, applying ISR to large-scale datasets such as the UK Biobank is challenging due to intensive computational demands and the need to handle subject-specific brain masks rather than a common mask. We propose a novel Bayesian ISR model that scales efficiently while accommodating these inconsistent masks. Our method leverages Gaussian process priors with salience area indicators and introduces a scalable posterior computation algorithm using stochastic gradient Langevin dynamics combined with memory mapping. This approach achieves linear scaling with subsample size and constrains memory usage to the batch size, facilitating direct spatial posterior inferences on brain activation regions. Simulation studies and analysis of UK Biobank task fMRI data (38,639 subjects; over 120,000 voxels per image) demonstrate a 4- to 11-fold speed increase and an 8-18% enhancement in statistical power compared to traditional Gibbs sampling with zero-imputation. Our analysis reveals a subregion of the amygdala where emotion-related brain activation decreases by approximately 58% between ages 50 and 60.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13204v3</guid>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yuliang Xu, Timothy D. Johnson, Thomas E. Nichols, Jian Kang</dc:creator>
    </item>
    <item>
      <title>The Hammock Plot: Where Categorical and Numerical Data Relax Together</title>
      <link>https://arxiv.org/abs/2506.13630</link>
      <description>arXiv:2506.13630v2 Announce Type: replace 
Abstract: Effective methods for visualizing data involving multiple variables, including categorical ones, are limited. The hammock plot (Schonlau 2003) visualizes both categorical and numerical variables using parallel coordinates. We introduce the Stata implementation hammock. We give numerous examples that explore highlighting, missing values, putting axes on the same scale, and tracing an observation across variables. Further, we discuss parallel univariate plots as an edge case of hammock plots. We also present and make publicly available a new dataset on the 2020 Tour de France. A graphical abstract is shown below.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.13630v2</guid>
      <category>stat.AP</category>
      <category>cs.HC</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matthias Schonlau, Tiancheng Yang</dc:creator>
    </item>
    <item>
      <title>What Quality Engineers Need to Know about Degradation Models</title>
      <link>https://arxiv.org/abs/2507.14666</link>
      <description>arXiv:2507.14666v3 Announce Type: replace 
Abstract: Degradation models play a critical role in quality engineering by enabling the assessment and prediction of system reliability based on data. The objective of this paper is to provide an accessible introduction to degradation models. We explore commonly used degradation data types, including repeated measures degradation data and accelerated destructive degradation test data, and review modeling approaches such as general path models and stochastic process models. Key inference problems, including reliability estimation and prediction, are addressed. Applications across diverse fields, including material science, renewable energy, civil engineering, aerospace, and pharmaceuticals, illustrate the broad impact of degradation models in industry. We also discuss best practices for quality engineers, software implementations, and challenges in applying these models. This paper aims to provide quality engineers with a foundational understanding of degradation models, equipping them with the knowledge necessary to apply these techniques effectively in real-world scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.14666v3</guid>
      <category>stat.AP</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jared M. Clark, Jie Min, Mingyang Li, Richard L. Warr, Stephanie P. DeHart, Caleb B. King, Lu Lu, Yili Hong</dc:creator>
    </item>
    <item>
      <title>Dynamic Conditional SKEPTIC</title>
      <link>https://arxiv.org/abs/2512.11648</link>
      <description>arXiv:2512.11648v2 Announce Type: replace 
Abstract: We introduce the Dynamic Conditional SKEPTIC (DCS), a semiparametric approach for efficiently and robustly estimating time-varying correlations in multivariate models. We exploit nonparametric rank-based statistics, namely Spearman's rho and Kendall's tau, to estimate the unknown correlation matrix and discuss the stationarity, beta- and rho- mixing conditions of the model. We illustrate the methodology by estimating the time-varying conditional correlation matrix of the stocks included in the S&amp;P100 and S&amp;P500 during the period from 02/01/2013 to 23/01/2025. The results show that DCS improves diagnostic checks compared to the classical Dynamic Conditional Correlation (DCC) models, providing uncorrelated and normally distributed residuals. A risk management application shows that global minimum variance portfolios estimated using the DCS model exhibit lower turnover than those based on the DCC and DCC-NL models, while also achieving higher Sharpe ratios for portfolios constructed from S&amp;P 100 constituents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11648v2</guid>
      <category>stat.AP</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gabriele Di Luzio, Giacomo Morelli</dc:creator>
    </item>
    <item>
      <title>Adventures in Demand Analysis Using AI</title>
      <link>https://arxiv.org/abs/2501.00382</link>
      <description>arXiv:2501.00382v3 Announce Type: replace-cross 
Abstract: This paper advances empirical demand analysis by integrating multimodal product representations derived from artificial intelligence (AI). Using a detailed dataset of toy cars on textit{Amazon.com}, we combine text descriptions, images, and tabular covariates to represent each product using transformer-based embedding models. These embeddings capture nuanced attributes, such as quality, branding, and visual characteristics, that traditional methods often struggle to summarize. Moreover, we fine-tune these embeddings for causal inference tasks. We show that the resulting embeddings substantially improve the predictive accuracy of sales ranks and prices and that they lead to more credible causal estimates of price elasticity. Notably, we uncover strong heterogeneity in price elasticity driven by these product-specific features. Our findings illustrate that AI-driven representations can enrich and modernize empirical demand analysis. The insights generated may also prove valuable for applied causal inference more broadly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.00382v3</guid>
      <category>econ.GN</category>
      <category>cs.AI</category>
      <category>q-fin.EC</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Philipp Bach, Victor Chernozhukov, Sven Klaassen, Martin Spindler, Jan Teichert-Kluge, Suhas Vijaykumar</dc:creator>
    </item>
    <item>
      <title>Credit Risk Estimation with Non-Financial Features: Evidence from a Synthetic Istanbul Dataset</title>
      <link>https://arxiv.org/abs/2512.12783</link>
      <description>arXiv:2512.12783v3 Announce Type: replace-cross 
Abstract: Financial exclusion constrains entrepreneurship, increases income volatility, and widens wealth gaps. Underbanked consumers in Istanbul often have no bureau file because their earnings and payments flow through informal channels. To study how such borrowers can be evaluated we create a synthetic dataset of one hundred thousand Istanbul residents that reproduces first quarter 2025 T\"U\.IK (TURKSTAT) census marginals and telecom usage patterns. Retrieval augmented generation feeds these public statistics into the OpenAI o3 model, which synthesises realistic yet private records. Each profile contains seven socio demographic variables and nine alternative attributes that describe phone specifications, online shopping rhythm, subscription spend, car ownership, monthly rent, and a credit card flag. To test the impact of the alternative financial data CatBoost, LightGBM, and XGBoost are each trained in two versions. Demo models use only the socio demographic variables; Full models include both socio demographic and alternative attributes. Across five fold stratified validation the alternative block raises area under the curve by about one point three percentage and lifts balanced F 1 from roughly 0.84 to 0.95, a fourteen percent gain. We contribute an open Istanbul 2025 Q1 synthetic dataset, a fully reproducible modeling pipeline, and empirical evidence that a concise set of behavioural attributes can approach bureau level discrimination power while serving borrowers who lack formal credit records. These findings give lenders and regulators a transparent blueprint for extending fair and safe credit access to the underbanked.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.12783v3</guid>
      <category>cs.LG</category>
      <category>q-fin.ST</category>
      <category>stat.AP</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Atalay Denknalbant, Emre Sezdi, Zeki Furkan Kutlu</dc:creator>
    </item>
    <item>
      <title>Collective Noise Filtering in Complex Networks</title>
      <link>https://arxiv.org/abs/2601.21299</link>
      <description>arXiv:2601.21299v2 Announce Type: replace-cross 
Abstract: Complex networks are powerful representations of complex systems across scales and domains, and the field is experiencing unprecedented growth in data availability. However, real-world network data often suffer from noise, biases, and missing data in edge weights, which undermine the reliability of downstream network analyses. Standard noise filtering approaches, whether treating individual edges one-by-one or assuming a uniform global noise level, are suboptimal, because in reality both signal and noise can be heterogeneous and correlated across multiple edges. As a solution, we introduce the Network Wiener Filter, a principled method for collective edge-level noise filtering that leverages both network structure and noise characteristics, to reduce error in the observed edge weights and to infer missing edge weights. We demonstrate the broad practical efficacy of the Network Wiener Filter in two distinct settings, the genetic interaction network of the budding yeast S. cerevisiae and the Enron Corpus email network, noting compelling evidence of successful noise suppression in both applications. With the Network Wiener Filter, we advocate for a shift toward error-aware network science, one that embraces data imperfection as an inherent feature and learns to navigate it effectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21299v2</guid>
      <category>cs.CE</category>
      <category>eess.SP</category>
      <category>stat.AP</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tingyu Zhao, Istv\'an A. Kov\'acs</dc:creator>
    </item>
  </channel>
</rss>
