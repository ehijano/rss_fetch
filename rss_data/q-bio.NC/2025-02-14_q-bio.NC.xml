<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 14 Feb 2025 05:01:39 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Neuronal Correlates of Semantic Event Classes during Presentation of Complex Naturalistic Stimuli: Anatomical Patterns, Context-Sensitivity, and Potential Impact on shared Human-Robot Ontologies</title>
      <link>https://arxiv.org/abs/2502.08694</link>
      <description>arXiv:2502.08694v1 Announce Type: new 
Abstract: The present study forms part of a research project that aims to develop cognition-enabled robotic agents with environmental interaction capabilities close to human proficiency. This approach is based on human-derived neuronal data in combination with a shared ontology to enable robots to learn from human experiences. To gain further insight into the relation between human neuronal activity patterns and ontological classes, we introduced General Linear Model (GLM) analyses on fMRI data of participants who were presented with complex naturalistic video stimuli comparable to the robot tasks. We modeled four event classes (pick, place, fetch and deliver) attached to different environmental and object-related context and employed a Representational Similarity Analysis (RSA) on associated brain activity patterns as a starting point for an automatic hierarchical clustering. Based on the default values for the Hemodynamic Response Function (HRF), the activity patterns were reliably grouped according to their parent classes of object interaction and navigation. Although fetch and deliver events were also distinguished by neuronal patterns, pick and place events demonstrated higher ambiguity with respect to neuronal activation patterns. Introducing a shorter HRF time-to-peak leads to a more reliable grouping of all four semantic classes, despite contextual factors. These data might give novel insights into the neuronal representation of complex stimuli and may enable further research in ontology validation in cognition-enabled robotics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08694v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Florian Ahrens, Mihai Pomarlan, Daniel Be{\ss}ler, Michael Beetz, Manfred Herrmann</dc:creator>
    </item>
    <item>
      <title>$^{18}$F-FDG brain PET hypometabolism in post-SARS-CoV-2 infection: substrate for persistent/delayed disorders?</title>
      <link>https://arxiv.org/abs/2502.09077</link>
      <description>arXiv:2502.09077v1 Announce Type: new 
Abstract: Purpose: Several brain complications of SARS-CoV-2 infection have been reported. It has been moreover speculated that this neurotropism could potentially cause a delayed outbreak of neuropsychiatric and neurodegenerative diseases of neuroinflammatory origin. A propagation mechanism has been proposed across the cribriform plate of the ethmoid bone, from the nose to the olfactory epithelium, and possibly afterward to other limbic structures, and deeper parts of the brain including the brainstem. Methods: Review of clinical examination, and whole-brain voxel-based analysis of $^{18}$F-FDG PET metabolism in comparison with healthy subjects (p voxel&lt;0.001, p-cluster&lt;0.05, uncorrected), of two patients with confirmed diagnosis of SARS-CoV-2 explored at the post-viral stage of the disease. Results: Hypometabolism of the olfactory/rectus gyrus was found on the two patients, especially one with 4-week prolonged anosmia. Additional hypometabolisms were found within amygdala, hippocampus, parahippocampus, cingulate cortex, pre-/post-central gyrus, thalamus/hypothalamus, cerebellum, pons, and medulla in the other patient who complained of delayed onset of a painful syndrome. Conclusion: These preliminary findings reinforce the hypotheses of SARS-CoV-2 neurotropism through the olfactory bulb and the possible extension of this impairment to other brain structures. $^{18}$F-FDG PET hypometabolism could constitute a cerebral quantitative biomarker of this involvement. Post-viral cohort studies are required to specify the exact relationship between such hypometabolisms and the possible persistent disorders, especially involving cognitive or emotion disturbances, residual respiratory symptoms, or painful complaints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09077v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s00259-020-04973-x</arxiv:DOI>
      <arxiv:journal_reference>European Journal of Nuclear Medicine and Molecular Imaging, 2020, 48 (2), pp.592-595</arxiv:journal_reference>
      <dc:creator>Eric Guedj (IMOTHEP, CERIMED), Matthieu Million (MEPHI, IHU Marseille), Pierre Dudouet (MEPHI, IHU Marseille), Herv\'e Tissot-Dupont (MEPHI, IHU Marseille), Fabienne Bregeon (MEPHI, IHU Marseille), Serge Cammilleri (IMOTHEP, CERIMED), Didier Raoult (MEPHI, IHU Marseille)</dc:creator>
    </item>
    <item>
      <title>Intrinsic motivation as constrained entropy maximization</title>
      <link>https://arxiv.org/abs/2502.02962</link>
      <description>arXiv:2502.02962v3 Announce Type: replace 
Abstract: "Intrinsic motivation" refers to the capacity for intelligent systems to be motivated endogenously, i.e. by features of agential architecture itself rather than by learned associations between action and reward. This paper views active inference, empowerment, and other formal accounts of intrinsic motivation as variations on the theme of constrained maximum entropy inference, providing a general perspective on intrinsic motivation complementary to existing frameworks. The connection between free energy and empowerment noted in previous literature is further explored, and it is argued that the maximum-occupancy approach in practice incorporates an implicit model-evidence constraint.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02962v3</guid>
      <category>q-bio.NC</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alex B. Kiefer</dc:creator>
    </item>
    <item>
      <title>Probing Mechanical Reasoning in Large Vision Language Models</title>
      <link>https://arxiv.org/abs/2410.00318</link>
      <description>arXiv:2410.00318v2 Announce Type: replace-cross 
Abstract: Mechanical reasoning is a hallmark of human intelligence, defined by its ubiquitous yet irreplaceable role in human activities ranging from routine tasks to civil engineering. Embedding machines with mechanical reasoning is therefore an important step towards building human-level artificial intelligence. Here, we leveraged 155 cognitive experiments to test the understanding of system stability, gears and pulley systems, leverage principle, inertia and motion, and fluid mechanics in 26 Vision Language Models (VLMs). Results indicate that VLMs consistently perform worse than humans on all domains, while demonstrate significant difficulty in reasoning about gear systems and fluid mechanics. Notably, their performance on these tasks do not improve as number of parameters increase, suggesting that current attention-based architecture may fail to grasp certain underlying mechanisms required for mechanical reasoning, particularly those pertaining to mental simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00318v2</guid>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haoran Sun, Qingying Gao, Haiyun Lyu, Dezhi Luo, Yijiang Li, Hokin Deng</dc:creator>
    </item>
    <item>
      <title>What if Eye...? Computationally Recreating Vision Evolution</title>
      <link>https://arxiv.org/abs/2501.15001</link>
      <description>arXiv:2501.15001v2 Announce Type: replace-cross 
Abstract: Vision systems in nature show remarkable diversity, from simple light-sensitive patches to complex camera eyes with lenses. While natural selection has produced these eyes through countless mutations over millions of years, they represent just one set of realized evolutionary paths. Testing hypotheses about how environmental pressures shaped eye evolution remains challenging since we cannot experimentally isolate individual factors. Computational evolution offers a way to systematically explore alternative trajectories. Here we show how environmental demands drive three fundamental aspects of visual evolution through an artificial evolution framework that co-evolves both physical eye structure and neural processing in embodied agents. First, we demonstrate computational evidence that task specific selection drives bifurcation in eye evolution - orientation tasks like navigation in a maze leads to distributed compound-type eyes while an object discrimination task leads to the emergence of high-acuity camera-type eyes. Second, we reveal how optical innovations like lenses naturally emerge to resolve fundamental tradeoffs between light collection and spatial precision. Third, we uncover systematic scaling laws between visual acuity and neural processing, showing how task complexity drives coordinated evolution of sensory and computational capabilities. Our work introduces a novel paradigm that illuminates evolutionary principles shaping vision by creating targeted single-player games where embodied agents must simultaneously evolve visual systems and learn complex behaviors. Through our unified genetic encoding framework, these embodied agents serve as next-generation hypothesis testing machines while providing a foundation for designing manufacturable bio-inspired vision systems. Website: http://eyes.mit.edu/</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.15001v2</guid>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.NE</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Kushagra Tiwary, Aaron Young, Zaid Tasneem, Tzofi Klinghoffer, Akshat Dave, Tomaso Poggio, Dan-Eric Nilsson, Brian Cheung, Ramesh Raskar</dc:creator>
    </item>
  </channel>
</rss>
