<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 14 Feb 2025 05:00:48 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Quantum Approaches for Dysphonia Assessment in Small Speech Datasets</title>
      <link>https://arxiv.org/abs/2502.08968</link>
      <description>arXiv:2502.08968v1 Announce Type: new 
Abstract: Dysphonia, a prevalent medical condition, leads to voice loss, hoarseness, or speech interruptions. To assess it, researchers have been investigating various machine learning techniques alongside traditional medical assessments. Convolutional Neural Networks (CNNs) have gained popularity for their success in audio classification and speech recognition. However, the limited availability of speech data, poses a challenge for CNNs. This study evaluates the performance of CNNs against a novel hybrid quantum-classical approach, Quanvolutional Neural Networks (QNNs), which are well-suited for small datasets. The audio data was preprocessed into Mel spectrograms, comprising 243 training samples and 61 testing samples in total, and used in ten experiments. Four models were developed (two QNNs and two CNNs) with the second models incorporating additional layers to boost performance. The results revealed that QNN models consistently outperformed CNN models in accuracy and stability across most experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08968v1</guid>
      <category>cs.ET</category>
      <category>cs.SD</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ha Tran, Bipasha Kashyap, Pubudu N. Pathirana</dc:creator>
    </item>
    <item>
      <title>Genetically programmable optical random neural networks</title>
      <link>https://arxiv.org/abs/2403.12490</link>
      <description>arXiv:2403.12490v2 Announce Type: replace 
Abstract: Today, machine learning tools, particularly artificial neural networks, have become crucial for diverse applications. However, current digital computing tools to train and deploy artificial neural networks often struggle with massive data sizes and high power consumptions. Optical computing provides inherent parallelism accommodating high-resolution input data and performs fundamental operations with passive optical components. However, most of the optical computing platforms suffer from relatively low accuracies for machine learning tasks due to fixed connections while avoiding complex and sensitive techniques. Here, we demonstrate a genetically programmable yet simple optical neural network to achieve high performances with optical random projection. By genetically programming the orientation of the scattering medium which acts as a random projection kernel and only using 1% of the search space, our novel technique finds an optimum kernel and improves initial test accuracies by 8-41% for various machine learning tasks. Through numerical simulations and experiments on a number of datasets, we validate the programmability and high-resolution sample processing capabilities of our design. Our optical computing method presents a promising approach to achieve high performance in optical neural networks with a simple and scalable design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12490v2</guid>
      <category>cs.ET</category>
      <category>cs.NE</category>
      <category>physics.optics</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Bora \c{C}arp{\i}nl{\i}o\u{g}lu, U\u{g}ur Te\u{g}in</dc:creator>
    </item>
    <item>
      <title>MPLS Network Actions: Technological Overview and P4-Based Implementation on a High-Speed Switching ASIC</title>
      <link>https://arxiv.org/abs/2410.20400</link>
      <description>arXiv:2410.20400v2 Announce Type: replace-cross 
Abstract: In MPLS, packets are encapsulated with labels that add domain-specific forwarding information. Special purpose labels were introduced to trigger special behavior in MPLS nodes but their number is limited. Therefore, the IETF proposed the MPLS Network Actions (MNA) framework. It extends MPLS with new features, some of which have already been defined to support relevant use cases. This paper provides a comprehensive technological overview of MNA concepts and use cases. It compares MNA to IPv6 extension headers (EHs) that serve a similar purpose, and argues that MNA can be better deployed than EHs. It then presents P4-MNA, a first hardware implementation running at 400 Gb/s per port. Scalability and performance of P4-MNA are evaluated, showing negligible impact on processing delay caused by network actions. Moreover, the applicability of MNA is demonstrated by implementing the use cases of link-specific packet loss measurement using the alternate-marking-method (AMM) and bandwidth reservation using network slicing. We identify header stacking constraints resulting from hardware resources and from the number of network actions that must be supported according to the MNA encoding. They make an implementation for hardware that can only parse a few MPLS headers infeasible. We propose to make the number of supported network actions a node parameter and signal this in the network. Then, an upgrade to MNA is also feasible for hardware with fewer available resources. We explain that for MNA with in-stack data (ISD), some header bits must remain unchanged during forwarding, and give an outlook on post-stack data (PSD).</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20400v2</guid>
      <category>cs.NI</category>
      <category>cs.ET</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fabian Ihle, Michael Menth</dc:creator>
    </item>
  </channel>
</rss>
