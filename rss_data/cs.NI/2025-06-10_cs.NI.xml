<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 10 Jun 2025 12:38:58 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Steps towards an Ecology for the Internet</title>
      <link>https://arxiv.org/abs/2506.06469</link>
      <description>arXiv:2506.06469v1 Announce Type: new 
Abstract: The Internet has grown from a humble set of protocols for end-to-end connectivity into a critical global system with no builtin "immune system". In the next decade the Internet will likely grow to a trillion nodes and need protection from threats ranging from floods of fake generative data to AI-driven malware. Unfortunately, growing centralisation has lead to the breakdown of mutualism across the network, with surveillance capitalism now the dominant business model. We take lessons from from biological systems towards evolving a more resilient Internet that can integrate adaptation mechanisms into its fabric. We also contribute ideas for how the Internet might incorporate digital immune systems, including how software stacks might mutate to encourage more architectural diversity. We strongly advocate for the Internet to "re-decentralise" towards incentivising more mutualistic forms of communication.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.06469v1</guid>
      <category>cs.NI</category>
      <category>cs.ET</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3744169.3744180</arxiv:DOI>
      <dc:creator>Anil Madhavapeddy, Sam Reynolds, Alec P. Christie, David A. Coomes, Michael W. Dales, Patrick Ferris, Ryan Gibb, Hamed Haddadi, Sadiq Jaffer, Josh Millar, Cyrus Omar, William J. Sutherland, Jon Crowcroft</dc:creator>
    </item>
    <item>
      <title>A Comparative Analyses Of Network Formation In Low-power Lossy Networks: ContikiMAC vs Orchestra-enabled TSCH</title>
      <link>https://arxiv.org/abs/2506.06688</link>
      <description>arXiv:2506.06688v1 Announce Type: new 
Abstract: Medium Access Control (MAC) layer protocols are the underlying paradigms which dictate the transmission &amp; reception of data in any network. Particularly for Low-powered Lossy Networks (LLNs), the design and selection of appropiate MAC-layer protocols is crucial inorder to satisfy several networking objectives such as joining time, network lifetime, energy consumption, end-to-end-delay, etc. In this report, we have presented a comparative analysis between Contiki-MAC and Orchestra-enabled TSCH protocol which provides insights towards the network joining &amp; convergence time as well as an estimate of the energy consumption required of build such LLNs. Our results indicates that Contiki-MAC outperforms Orchestra-enabled TSCH by a factor of 13 times in network formation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.06688v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Heerok Banerjee</dc:creator>
    </item>
    <item>
      <title>ARGOS: Anomaly Recognition and Guarding through O-RAN Sensing</title>
      <link>https://arxiv.org/abs/2506.06916</link>
      <description>arXiv:2506.06916v1 Announce Type: new 
Abstract: Rogue Base Station (RBS) attacks, particularly those exploiting downgrade vulnerabilities, remain a persistent threat as 5G Standalone (SA) deployments are still limited and User Equipment (UE) manufacturers continue to support legacy network connectivity. This work introduces ARGOS, a comprehensive O-RAN compliant Intrusion Detection System (IDS) deployed within the Near Real-Time RIC, designed to detect RBS downgrade attacks in real time, an area previously unexplored within the O-RAN context. The system enhances the 3GPP KPM Service Model to enable richer, UE-level telemetry and features a custom xApp that applies unsupervised Machine Learning models for anomaly detection. Distinctively, the updated KPM Service Model operates on cross-layer features extracted from Modem Layer 1 (ML1) logs and Measurement Reports collected directly from Commercial Off-The-Shelf (COTS) UEs. To evaluate system performance under realistic conditions, a dedicated testbed is implemented using Open5GS, srsRAN, and FlexRIC, and validated against an extensive real-world measurement dataset. Among the evaluated models, the Variational Autoencoder (VAE) achieves the best balance of detection performance and efficiency, reaching 99.5% Accuracy with only 0.6% False Positives and minimal system overhead.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.06916v1</guid>
      <category>cs.NI</category>
      <category>cs.CR</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Stavros Dimou, Guevara Noubir</dc:creator>
    </item>
    <item>
      <title>Delay Optimization in Remote ID-Based UAV Communication via BLE and Wi-Fi Switching</title>
      <link>https://arxiv.org/abs/2506.07715</link>
      <description>arXiv:2506.07715v1 Announce Type: new 
Abstract: The remote identification (Remote ID) broadcast capability allows unmanned aerial vehicles (UAVs) to exchange messages, which is a pivotal technology for inter-UAV communications. Although this capability enhances the operational visibility, low delay in Remote ID-based communications is critical for ensuring the efficiency and timeliness of multi-UAV operations in dynamic environments. To address this challenge, we first establish delay models for Remote ID communications by considering packet reception and collisions across both BLE 4 and Wi-Fi protocols. Building upon these models, we formulate an optimization problem to minimize the long-term communication delay through adaptive protocol selection. Since the delay performance varies with the UAV density, we propose an adaptive BLE/Wi-Fi switching algorithm based on the multi-agent deep Q-network approach. Experimental results demonstrate that in dynamic-density scenarios, our strategy achieves 32.1% and 37.7% lower latency compared to static BLE 4 and Wi-Fi modes respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.07715v1</guid>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yian Zhu, Ziye Jia, Lei Zhang, Yao Wu, Qiuming Zhu, Qihui Wu</dc:creator>
    </item>
    <item>
      <title>Diffusion-RL for Scalable Resource Allocation for 6G Networks</title>
      <link>https://arxiv.org/abs/2506.07880</link>
      <description>arXiv:2506.07880v1 Announce Type: new 
Abstract: This paper presents a novel approach to resource allocation in Open Radio Access Networks (O-RAN), leveraging a Generative AI technique with network slicing to address the diverse demands of 5G and 6G service types such as Enhanced Mobile Broadband (eMBB), Ultra-Reliable Low-Latency Communications (URLLC), and Massive Machine-Type Communications (mMTC). Additionally, we provide a comprehensive analysis and comparison of machine learning (ML) techniques for resource allocation within O-RAN, evaluating their effectiveness in optimizing network performance. We introduce a diffusion-based reinforcement learning (Diffusion-RL) algorithm designed to optimize the allocation of physical resource blocks (PRBs) and power consumption, thereby maximizing weighted throughput and minimizing the delay for user equipment (UE). The Diffusion-RL model incorporates controlled noise and perturbations to explore optimal resource distribution while meeting each service type's Quality of Service (QoS) requirements. We evaluate the performance of our proposed method against several benchmarks, including an exhaustive search algorithm, deep Q-networks (DQN), and the Semi-Supervised Variational Autoencoder (SS-VAE). Comprehensive metrics, such as throughput and latency, are presented for each service type. Experimental results demonstrate that the Diffusion-based RL approach outperforms existing methods in efficiency, scalability, and robustness, offering a promising solution for resource allocation in dynamic and heterogeneous O-RAN environments with significant implications for future 6G networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.07880v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Salar Nouri, Mojdeh Karbalaee Motalleb, Vahid Shah-Mansouri</dc:creator>
    </item>
    <item>
      <title>Edge-Enabled Collaborative Object Detection for Real-Time Multi-Vehicle Perception</title>
      <link>https://arxiv.org/abs/2506.06474</link>
      <description>arXiv:2506.06474v1 Announce Type: cross 
Abstract: Accurate and reliable object detection is critical for ensuring the safety and efficiency of Connected Autonomous Vehicles (CAVs). Traditional on-board perception systems have limited accuracy due to occlusions and blind spots, while cloud-based solutions introduce significant latency, making them unsuitable for real-time processing demands required for autonomous driving in dynamic environments. To address these challenges, we introduce an innovative framework, Edge-Enabled Collaborative Object Detection (ECOD) for CAVs, that leverages edge computing and multi-CAV collaboration for real-time, multi-perspective object detection. Our ECOD framework integrates two key algorithms: Perceptive Aggregation and Collaborative Estimation (PACE) and Variable Object Tally and Evaluation (VOTE). PACE aggregates detection data from multiple CAVs on an edge server to enhance perception in scenarios where individual CAVs have limited visibility. VOTE utilizes a consensus-based voting mechanism to improve the accuracy of object classification by integrating data from multiple CAVs. Both algorithms are designed at the edge to operate in real-time, ensuring low-latency and reliable decision-making for CAVs. We develop a hardware-based controlled testbed consisting of camera-equipped robotic CAVs and an edge server to evaluate the efficacy of our framework. Our experimental results demonstrate the significant benefits of ECOD in terms of improved object classification accuracy, outperforming traditional single-perspective onboard approaches by up to 75%, while ensuring low-latency, edge-driven real-time processing. This research highlights the potential of edge computing to enhance collaborative perception for latency-sensitive autonomous systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.06474v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.MA</category>
      <category>cs.NI</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Everett Richards, Bipul Thapa, Lena Mashayekhy</dc:creator>
    </item>
    <item>
      <title>Hierarchical and Collaborative LLM-Based Control for Multi-UAV Motion and Communication in Integrated Terrestrial and Non-Terrestrial Networks</title>
      <link>https://arxiv.org/abs/2506.06532</link>
      <description>arXiv:2506.06532v1 Announce Type: cross 
Abstract: Unmanned aerial vehicles (UAVs) have been widely adopted in various real-world applications. However, the control and optimization of multi-UAV systems remain a significant challenge, particularly in dynamic and constrained environments. This work explores the joint motion and communication control of multiple UAVs operating within integrated terrestrial and non-terrestrial networks that include high-altitude platform stations (HAPS). Specifically, we consider an aerial highway scenario in which UAVs must accelerate, decelerate, and change lanes to avoid collisions and maintain overall traffic flow. Different from existing studies, we propose a novel hierarchical and collaborative method based on large language models (LLMs). In our approach, an LLM deployed on the HAPS performs UAV access control, while another LLM onboard each UAV handles motion planning and control. This LLM-based framework leverages the rich knowledge embedded in pre-trained models to enable both high-level strategic planning and low-level tactical decisions. This knowledge-driven paradigm holds great potential for the development of next-generation 3D aerial highway systems. Experimental results demonstrate that our proposed collaborative LLM-based method achieves higher system rewards, lower operational costs, and significantly reduced UAV collision rates compared to baseline approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.06532v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zijiang Yan, Hao Zhou, Jianhua Pei, Hina Tabassum</dc:creator>
    </item>
    <item>
      <title>WiFi Pathologies Detection using LLMs</title>
      <link>https://arxiv.org/abs/2506.06943</link>
      <description>arXiv:2506.06943v1 Announce Type: cross 
Abstract: In this paper, we fine-tune encoder-only and decoder-only large language models (LLMs) to detect pathologies in IEEE 802.11 networks, commonly known as WiFi. Our approach involves manually crafting prompts followed by fine-tuning. Evaluations show that the sequential model achieves high detection accuracy using labeled data, while the causal model performs equally well for unlabeled data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.06943v1</guid>
      <category>eess.SP</category>
      <category>cs.NI</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Forough Shirin Abkenar</dc:creator>
    </item>
    <item>
      <title>SALT: A Lightweight Model Adaptation Method for Closed Split Computing Environments</title>
      <link>https://arxiv.org/abs/2506.07355</link>
      <description>arXiv:2506.07355v1 Announce Type: cross 
Abstract: We propose SALT (Split-Adaptive Lightweight Tuning), a lightweight model adaptation framework for Split Computing under closed constraints, where the head and tail networks are proprietary and inaccessible to users. In such closed environments, conventional adaptation methods are infeasible since they require access to model parameters or architectures. SALT addresses this challenge by introducing a compact, trainable adapter on the client side to refine latent features from the head network, enabling user-specific adaptation without modifying the original models or increasing communication overhead. We evaluate SALT on user-specific classification tasks with CIFAR-10 and CIFAR-100, demonstrating improved accuracy with lower training latency compared to fine-tuning methods. Furthermore, SALT facilitates model adaptation for robust inference over lossy networks, a common challenge in edge-cloud environments. With minimal deployment overhead, SALT offers a practical solution for personalized inference in edge AI systems under strict system constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.07355v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuya Okada, Takayuki Nishio</dc:creator>
    </item>
    <item>
      <title>Are Trees Really Green? A Detection Approach of IoT Malware Attacks</title>
      <link>https://arxiv.org/abs/2506.07836</link>
      <description>arXiv:2506.07836v1 Announce Type: cross 
Abstract: Nowadays, the Internet of Things (IoT) is widely employed, and its usage is growing exponentially because it facilitates remote monitoring, predictive maintenance, and data-driven decision making, especially in the healthcare and industrial sectors. However, IoT devices remain vulnerable due to their resource constraints and difficulty in applying security patches. Consequently, various cybersecurity attacks are reported daily, such as Denial of Service, particularly in IoT-driven solutions. Most attack detection methodologies are based on Machine Learning (ML) techniques, which can detect attack patterns. However, the focus is more on identification rather than considering the impact of ML algorithms on computational resources. This paper proposes a green methodology to identify IoT malware networking attacks based on flow privacy-preserving statistical features. In particular, the hyperparameters of three tree-based models -- Decision Trees, Random Forest and Extra-Trees -- are optimized based on energy consumption and test-time performance in terms of Matthew's Correlation Coefficient. Our results show that models maintain high performance and detection accuracy while consistently reducing power usage in terms of watt-hours (Wh). This suggests that on-premise ML-based Intrusion Detection Systems are suitable for IoT and other resource-constrained devices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.07836v1</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Silvia Lucia Sanna, Diego Soi, Davide Maiorca, Giorgio Giacinto</dc:creator>
    </item>
    <item>
      <title>Online SLA Decomposition: Enabling Real-Time Adaptation to Evolving Network Systems</title>
      <link>https://arxiv.org/abs/2408.08968</link>
      <description>arXiv:2408.08968v5 Announce Type: replace 
Abstract: When a network slice spans multiple technology domains, it is crucial for each domain to uphold the End-to-End (E2E) Service Level Agreement (SLA) associated with the slice. Consequently, the E2E SLA must be properly decomposed into partial SLAs that are assigned to each domain involved. In a network slice management system with a two-level architecture, comprising an E2E service orchestrator and local domain controllers, we consider that the orchestrator has access only to historical data regarding the responses of local controllers to previous requests, and this information is used to construct a risk model for each domain. In this study, we extend our previous work by investigating the dynamic nature of real-world systems and introducing an online learning-decomposition framework to tackle the dynamicity. We propose a framework that continuously updates the risk models based on the most recent feedback. This approach leverages key components such as online gradient descent and FIFO memory buffers, which enhance the stability and robustness of the overall process. Our empirical study on an analytic model-based simulator demonstrates that the proposed framework outperforms the state-of-the-art static approach, delivering more accurate and resilient SLA decomposition under varying conditions and data limitations. Furthermore, we provide a comprehensive complexity analysis of the proposed solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08968v5</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cyril Shih-Huan Hsu, Danny De Vleeschauwer, Chrysa Papagianni, Paola Grosso</dc:creator>
    </item>
    <item>
      <title>JingZhao: A Framework for Rapid NIC Prototyping in the Domain-Specific-Network Era</title>
      <link>https://arxiv.org/abs/2410.08476</link>
      <description>arXiv:2410.08476v3 Announce Type: replace 
Abstract: The network is becoming domain-specific, which requires on-demand design of the network protocols, as well as the microarchitecture of the NIC. However, to develop such a NIC is not that easy. Since the scissor gap between network speed and the growth of CPU frequency is expanding, most of the protocols need to be offloaded to hardware. The process of designing, verifying and optimizing a domain-specific NIC usually takes great effort, which hinders the rapid iteration of new protocols and algorithms. In this paper, we propose JingZhao, an open-sourced framework for NIC prototyping, which could be leveraged to rapidly implement and verify a domain-specific NIC. Using this framework, we implement a fully-functional RDMA NIC (RNIC). To the best of our knowledge, this represents the first open-source RDMA NIC solution with complete compatibility to the standard OFED communication library. The RNIC was also taped out using TSMC's 28nm process to validate our design. Our evaluation results show that new network functions can be easily integrated into the framework, and achieve nearly line-rate packet processing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08476v3</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fan Yang (Institute of Computing Technology, Chinese Academy of Sciences), Zhan Wang (Institute of Computing Technology, Chinese Academy of Sciences), Ning Kang (Institute of Computing Technology, Chinese Academy of Sciences), Zhenlong Ma (Institute of Computing Technology, Chinese Academy of Sciences), Jianxiong Li (Institute of Computing Technology, Chinese Academy of Sciences), Guojun Yuan (Institute of Computing Technology, Chinese Academy of Sciences), Guangming Tan (Institute of Computing Technology, Chinese Academy of Sciences)</dc:creator>
    </item>
    <item>
      <title>Energy-and Spectral-Efficiency Trade-off in Distributed Massive-MIMO Networks</title>
      <link>https://arxiv.org/abs/2501.01271</link>
      <description>arXiv:2501.01271v4 Announce Type: replace 
Abstract: This paper investigates a fundamental yet under-explored trade-off between energy efficiency (EE) and spectral efficiency (SE) in distributed massive MIMO (D-mMIMO) systems. Unlike conventional EE-SE trade-off studies that primarily focus on transmission power, D-mMIMO systems introduce new energy consumption factors including fronthaul signaling and distributed signal processing, which are heavily influenced by AP-UE association. This work highlights the critical need for a system-level EE-SE trade-off framework that accounts for these unique aspects of D-mMIMO. We formulate a joint optimization problem that maximizes EE while satisfying uplink sum-SE constraints, through the coordinated design of power allocation and AP-UE association strategies. By explicitly considering both transmission and infrastructure-related energy costs, our approach enables energy-aware network design without compromising throughput. Numerical simulations demonstrate the substantial impact of dynamic AP-UE association and power control on the EE-SE trade-off, providing actionable insights for an efficient deployment of large-scale distributed MIMO networks in next-generation wireless systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01271v4</guid>
      <category>cs.NI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohd Saif Ali Khan, Karthik RM, Samar Agnihotri</dc:creator>
    </item>
    <item>
      <title>LoRaConnect: Unlocking HTTP Potential on LoRa Backbones for Remote Areas and Ad-Hoc Networks</title>
      <link>https://arxiv.org/abs/2501.02469</link>
      <description>arXiv:2501.02469v2 Announce Type: replace 
Abstract: The minimal infrastructure requirements of LoRa make it suitable for deployments in remote and disaster-stricken areas. Concomitantly, the modern era is witnessing the proliferation of web applications in all aspects of human life, including IoT and other network services. Contemporary IoT and network solutions heavily rely on web applications to render services. However, despite the recent research and development pivoted around LoRa, there is still a lack of studies focusing on web application access over LoRa networks. Specifically, technical challenges like payload size limitation, low data rate, and contentions in multi-user setups limit the applicability of LoRa for web applications. Hence, we propose LoRaWeb, which enables web access over LoRa networks. The LoRaWeb hardware tethers a WiFi hotspot to which the client devices connect and access the web pages using a web browser. LoRa backbone of the network handles the web page transmission from the requester and receiver devices. LoRaWeb implements a synchronization procedure to address the aforementioned challenges for effective message exchange between requesters and responders. The system implements a caching mechanism to reduce latency and contention. Additionally, it implements a message-slicing mechanism in the application layer to overcome the hardware limitations on the message length. The actual hardware-based implementation results indicate seamless deployment, and the results indicate an average access time of ~$0.95 S$ for a $1.5 KB$ and ~$6 S$ for a $10 KB$ size web page.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.02469v2</guid>
      <category>cs.NI</category>
      <category>cs.CY</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Atonu Ghosh, Sudip Misra</dc:creator>
    </item>
    <item>
      <title>Extending Internet Access Over LoRa for Internet of Things and Critical Applications</title>
      <link>https://arxiv.org/abs/2501.03465</link>
      <description>arXiv:2501.03465v2 Announce Type: replace 
Abstract: LoRa bridges the gap between remote locations and mainstream networks, enabling large-scale Internet of Things (IoT) deployments. Despite the recent advancements around LoRa, Internet access over this technology is still largely unexplored. Most existing solutions only handle packets within the local LoRa network and do not interact with web applications. This limits the scalability and the ability to deliver essential web services in disconnected regions. This work proposes and implements ILoRa to extend the public Internet to disconnected areas for essential service delivery. ILoRa enables accessing Application Programming Interfaces (APIs) and web pages on the Internet over a LoRa backbone network. It comprises a ILoRa coordinator code (ICN) and access point nodes (APNs). The ICN interfaces the LoRa network with the public Internet and interprets content. The APN tethers a WiFi hotspot to which devices connect and access the web content. This work further proposes data handling methods for ICNs and APNs. An actual hardware-based implementation validates the proposed system. The implementation achieves a throughput of 1.06 kbps tested for an Internet-based API returning JSON data of 930 B. Furthermore, the APN consumed approximately $0.162$A current, and the resource utilization on the ICN was minimal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03465v2</guid>
      <category>cs.NI</category>
      <category>cs.CY</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Atonu Ghosh, Devadeep Misra, Hirdesh Mewada</dc:creator>
    </item>
    <item>
      <title>Space-O-RAN: Enabling Intelligent, Open, and Interoperable Non Terrestrial Networks in 6G</title>
      <link>https://arxiv.org/abs/2502.15936</link>
      <description>arXiv:2502.15936v2 Announce Type: replace 
Abstract: Satellite networks are rapidly evolving, yet most \glspl{ntn} remain isolated from terrestrial orchestration frameworks. Their control architectures are typically monolithic and static, limiting their adaptability to dynamic traffic, topology changes, and mission requirements. These constraints lead to inefficient spectrum use and underutilized network capacity. Although \gls{ai} promises automation, its deployment in orbit is limited by computing, energy, and connectivity limitations.
  This paper introduces Space-O-RAN, a distributed control architecture that extends Open RAN principles into satellite constellations through hierarchical, closed-loop control. Lightweight \glspl{dapp} operate onboard satellites, enabling real-time functions like scheduling and beam steering without relying on persistent ground access. Cluster-level coordination is managed via \glspl{spaceric}, which leverage low-latency \glspl{isl} for autonomous decisions in orbit. Strategic tasks, including AI training and policy updates, are transferred to terrestrial platforms \glspl{smo} using digital twins and feeder links.
  A key enabler is the dynamic mapping of the O-RAN interfaces to satellite links, supporting adaptive signaling under varying conditions. Simulations using the Starlink topology validate the latency bounds that inform this architectural split, demonstrating both feasibility and scalability for autonomous satellite RAN operations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.15936v2</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eduardo Baena, Paolo Testolina, Michele Polese, Dimitrios Koutsonikolas, Josep Jornet, Tommaso Melodia</dc:creator>
    </item>
    <item>
      <title>Open Wireless Digital Twin: End-to-End 5G Mobility Emulation in O-RAN Framework</title>
      <link>https://arxiv.org/abs/2503.12177</link>
      <description>arXiv:2503.12177v2 Announce Type: replace 
Abstract: This paper presents an end-to-end wireless digital twin platform constructed using open-source software and open data to enhance the evaluation of mobile communication systems. The proposed open wireless digital twin (OWDT) integrates OpenAirInterface (OAI) for 5G NR protocol stack emulation and NVIDIA Sionna RT for high-resolution ray tracing based radio propagation modeling. This integration enables realistic emulation of vehicular mobility scenarios, leveraging real-world geographic and building data to bridge the gap between theoretical simulations and real-world deployments. The platform utilizes O-RAN's Near-RT RIC via OAI FlexRIC to dynamically monitor key performance indicators (KPIs) such as RSRP, MCS, BLER, and throughput in real time. Through extensive evaluation in urban environments, this study demonstrates the validity of the emulation framework, revealing its capability to replicate real-world communication dynamics with high fidelity. The results underscore the potential of OWDT in accelerating wireless system development, reducing experimental costs, and optimizing network configurations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.12177v2</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tetsuya Iye, Masaya Sakamoto, Shohei Takaya, Eisaku Sato, Yuki Susukida, Yu Nagaoka, Kazuki Maruta, Jin Nakazato</dc:creator>
    </item>
    <item>
      <title>A Deep RL Approach on Task Placement and Scaling of Edge Resources for Cellular Vehicle-to-Network Service Provisioning</title>
      <link>https://arxiv.org/abs/2305.09832</link>
      <description>arXiv:2305.09832v4 Announce Type: replace-cross 
Abstract: Cellular Vehicle-to-Everything (C-V2X) is currently at the forefront of the digital transformation of our society. By enabling vehicles to communicate with each other and with the traffic environment using cellular networks, we redefine transportation, improving road safety and transportation services, increasing efficiency of vehicular traffic flows, and reducing environmental impact. To effectively facilitate the provisioning of Cellular Vehicular-to-Network (C-V2N) services, we tackle the interdependent problems of service task placement and scaling of edge resources. Specifically, we formulate the joint problem and prove that it is not computationally tractable. To address its complexity we propose Deep Hybrid Policy Gradient (DHPG), a new Deep Reinforcement Learning (DRL) approach that operates in hybrid action spaces, enabling holistic decision-making and enhancing overall performance. We evaluated the performance of DHPG using simulations with a real-world C-V2N traffic dataset, comparing it to several state-of-the-art (SoA) solutions. DHPG outperforms these solutions, guaranteeing the $99^{th}$ percentile of C-V2N service delay target, while simultaneously optimizing the utilization of computing resources. Finally, time complexity analysis is conducted to verify that the proposed approach can support real-time C-V2N services.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.09832v4</guid>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <category>cs.NI</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TNSM.2025.3570102</arxiv:DOI>
      <dc:creator>Cyril Shih-Huan Hsu, Jorge Mart\'in-P\'erez, Danny De Vleeschauwer, Luca Valcarenghi, Xi Li, Chrysa Papagianni</dc:creator>
    </item>
    <item>
      <title>Implementing LoRa MIMO System for Internet of Things</title>
      <link>https://arxiv.org/abs/2501.07148</link>
      <description>arXiv:2501.07148v2 Announce Type: replace-cross 
Abstract: Bandwidth constraints limit LoRa implementations. Contemporary IoT applications require higher throughput than that provided by LoRa. This work introduces a LoRa Multiple Input Multiple Output (MIMO) system and a spatial multiplexing algorithm to address LoRa's bandwidth limitation. The transceivers in the proposed approach modulate the signals on distinct frequencies of the same LoRa band. A Frequency Division Multiplexing (FDM) method is used at the transmitters to provide a wider MIMO channel. Unlike conventional Orthogonal Frequency Division Multiplexing (OFDM) techniques, this work exploits the orthogonality of the LoRa signals facilitated by its proprietary Chirp Spread Spectrum (CSS) modulation to perform an OFDM in the proposed LoRa MIMO system. By varying the Spreading Factor (SF) and bandwidth of LoRa signals, orthogonal signals can transmit on the same frequency irrespective of the FDM. Even though the channel correlation is minimal for different spreading factors and bandwidths, different Carrier Frequencies (CF) ensure the signals do not overlap and provide additional degrees of freedom. This work assesses the proposed model's performance and conducts an extensive analysis to provide an overview of resources consumed by the proposed system. Finally, this work provides the detailed results of a thorough evaluation of the model on test hardware.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.07148v2</guid>
      <category>cs.CY</category>
      <category>cs.AR</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Atonu Ghosh, Sharath Chandan, Sudip Misra</dc:creator>
    </item>
    <item>
      <title>Cost-driven prunings for iterative solving of constrained routing problem with SRLG-disjoint protection</title>
      <link>https://arxiv.org/abs/2503.08262</link>
      <description>arXiv:2503.08262v2 Announce Type: replace-cross 
Abstract: The search for the optimal pair of active and protection paths in a network with Shared Risk Link Groups (SRLG) is a challenging but high-value problem in the industry that is inevitable in ensuring reliable connections on the modern Internet. We propose a new approach to solving this problem, with a novel use of statistical analysis of the distribution of paths with respect to their cost, which is an integral part of our innovation. The key idea in our algorithm is to employ iterative updates of cost bounds, allowing efficient pruning of suboptimal paths. This idea drives an efficacious exploration of the search space. We benchmark our algorithms against the state-of-the-art algorithms that exploit the alternative strategy of conflicting links exclusion, showing that our approach has the advantage of finding more feasible connections within a set time limit.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08262v2</guid>
      <category>cs.DS</category>
      <category>cs.NI</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>P. A. Mosharev, Choon-Meng Lee, Xu Shu, Xiaoshan Zhang, Man-Hong Yung</dc:creator>
    </item>
  </channel>
</rss>
