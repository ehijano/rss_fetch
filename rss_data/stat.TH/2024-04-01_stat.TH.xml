<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.TH</link>
    <description>stat.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 01 Apr 2024 04:01:58 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 01 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Meta-Learning with Generalized Ridge Regression: High-dimensional Asymptotics, Optimality and Hyper-covariance Estimation</title>
      <link>https://arxiv.org/abs/2403.19720</link>
      <description>arXiv:2403.19720v1 Announce Type: new 
Abstract: Meta-learning involves training models on a variety of training tasks in a way that enables them to generalize well on new, unseen test tasks. In this work, we consider meta-learning within the framework of high-dimensional multivariate random-effects linear models and study generalized ridge-regression based predictions. The statistical intuition of using generalized ridge regression in this setting is that the covariance structure of the random regression coefficients could be leveraged to make better predictions on new tasks. Accordingly, we first characterize the precise asymptotic behavior of the predictive risk for a new test task when the data dimension grows proportionally to the number of samples per task. We next show that this predictive risk is optimal when the weight matrix in generalized ridge regression is chosen to be the inverse of the covariance matrix of random coefficients. Finally, we propose and analyze an estimator of the inverse covariance matrix of random regression coefficients based on data from the training tasks. As opposed to intractable MLE-type estimators, the proposed estimators could be computed efficiently as they could be obtained by solving (global) geodesically-convex optimization problems. Our analysis and methodology use tools from random matrix theory and Riemannian optimization. Simulation results demonstrate the improved generalization performance of the proposed method on new unseen test tasks within the considered framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.19720v1</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yanhao Jin, Krishnakumar Balasubramanian, Debashis Paul</dc:creator>
    </item>
    <item>
      <title>High-dimensional analysis of ridge regression for non-identically distributed data with a variance profile</title>
      <link>https://arxiv.org/abs/2403.20200</link>
      <description>arXiv:2403.20200v1 Announce Type: new 
Abstract: High-dimensional linear regression has been thoroughly studied in the context of independent and identically distributed data. We propose to investigate high-dimensional regression models for independent but non-identically distributed data. To this end, we suppose that the set of observed predictors (or features) is a random matrix with a variance profile and with dimensions growing at a proportional rate. Assuming a random effect model, we study the predictive risk of the ridge estimator for linear regression with such a variance profile. In this setting, we provide deterministic equivalents of this risk and of the degree of freedom of the ridge estimator. For certain class of variance profile, our work highlights the emergence of the well-known double descent phenomenon in high-dimensional regression for the minimum norm least-squares estimator when the ridge regularization parameter goes to zero. We also exhibit variance profiles for which the shape of this predictive risk differs from double descent. The proofs of our results are based on tools from random matrix theory in the presence of a variance profile that have not been considered so far to study regression models. Numerical experiments are provided to show the accuracy of the aforementioned deterministic equivalents on the computation of the predictive risk of ridge regression. We also investigate the similarities and differences that exist with the standard setting of independent and identically distributed data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.20200v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>J\'er\'emie Bigot, Issa-Mbenard Dabo, Camille Male</dc:creator>
    </item>
    <item>
      <title>Testing for common structures in high-dimensional factor models</title>
      <link>https://arxiv.org/abs/2403.19818</link>
      <description>arXiv:2403.19818v1 Announce Type: cross 
Abstract: This work proposes a novel procedure to test for common structures across two high-dimensional factor models. The introduced test allows to uncover whether two factor models are driven by the same loading matrix up to some linear transformation. The test can be used to discover inter individual relationships between two data sets. In addition, it can be applied to test for structural changes over time in the loading matrix of an individual factor model. The test aims to reduce the set of possible alternatives in a classical change-point setting. The theoretical results establish the asymptotic behavior of the introduced test statistic. The theory is supported by a simulation study showing promising results in empirical test size and power. A data application investigates changes in the loadings when modeling the celebrated US macroeconomic data set of Stock and Watson.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.19818v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marie-Christine D\"uker, Vladas Pipiras</dc:creator>
    </item>
    <item>
      <title>Interplay between Negation of a Probability Distribution and Jensen Inequality</title>
      <link>https://arxiv.org/abs/2403.20027</link>
      <description>arXiv:2403.20027v1 Announce Type: cross 
Abstract: Yager[5] proposed a transformation for opposing(negating) the occurence of an event that is not certain using the idea that one can oppose the occurence of any uncertain event by allocating its probability among the other outcomes in the sample space without preference to any particular outcome \textit{i.e.} the probability of every event in the sample space is redistributed equally among the other outcomes in the sample space. However this redistribution increases the uncertainty associated with the occurence of events. In the present work, we have established bounds on the uncertainty associated with negation of a probability distribution using well known Jensen inequality. The obtained results are validated with the help of various numerical examples. Finally a dissimilarity function between a probability distribution and its negation has been developed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.20027v1</guid>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amit Srivastava</dc:creator>
    </item>
    <item>
      <title>Incorporating Auxiliary Variables to Improve the Efficiency of Time-Varying Treatment Effect Estimation</title>
      <link>https://arxiv.org/abs/2306.17260</link>
      <description>arXiv:2306.17260v2 Announce Type: replace-cross 
Abstract: The use of smart devices (e.g., smartphones, smartwatches) and other wearables for context sensing and delivery of digital interventions to improve health outcomes has grown significantly in behavioral and psychiatric studies. Micro-randomized trials (MRTs) are a common experimental design for obtaining data-driven evidence on mobile health (mHealth) intervention effectiveness where each individual is repeatedly randomized to receive treatments over numerous time points. Individual characteristics and the contexts around randomizations are also collected throughout the study, some may be pre-specified as moderators when assessing time-varying causal effect moderation. Moreover, we have access to abundant measurements beyond just the moderators. Our study aims to leverage this auxiliary information to improve causal estimation and better understand the intervention effect. Similar problems have been raised in randomized control trials (RCTs), where extensive literature demonstrates that baseline covariate information can be incorporated to alleviate chance imbalances and increase asymptotic efficiency. However, covariate adjustment in the context of time-varying treatments and repeated measurements, as seen in MRTs, has not been studied. Recognizing the connection to Neyman Orthogonality, we address this gap by introducing an intuitive approach to incorporate auxiliary variables to improve the efficiency of moderated causal excursion effect estimation. The efficiency gain of our approach is proved theoretically and demonstrated through simulation studies and an analysis of data from the Intern Health Study (NeCamp et al., 2020).</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.17260v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jieru Shi, Zhenke Wu, Walter Dempsey</dc:creator>
    </item>
  </channel>
</rss>
