<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 29 Aug 2025 04:00:20 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 29 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A Unified Theory of Language</title>
      <link>https://arxiv.org/abs/2508.20109</link>
      <description>arXiv:2508.20109v1 Announce Type: new 
Abstract: A unified theory of language combines a Bayesian cognitive linguistic model of language processing, with the proposal that language evolved by sexual selection for the display of intelligence. The theory accounts for the major facts of language, including its speed and expressivity, and data on language diversity, pragmatics, syntax and semantics. The computational element of the theory is based on Construction Grammars. These give an account of the syntax and semantics of the worlds languages, using constructions and unification. Two novel elements are added to construction grammars: an account of language pragmatics, and an account of fast, precise language learning. Constructions are represented in the mind as graph like feature structures. People use slow general inference to understand the first few examples they hear of any construction. After that it is learned as a feature structure, and is rapidly applied by unification. All aspects of language (phonology, syntax, semantics, and pragmatics) are seamlessly computed by fast unification; there is no boundary between semantics and pragmatics. This accounts for the major puzzles of pragmatics, and for detailed pragmatic phenomena. Unification is Bayesian maximum likelihood pattern matching. This gives evolutionary continuity between language processing in the human brain, and Bayesian cognition in animal brains. Language is the basis of our mind reading abilities, our cooperation, self esteem and emotions; the foundations of human culture and society.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.20109v1</guid>
      <category>q-bio.NC</category>
      <category>cs.CL</category>
      <pubDate>Fri, 29 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Robert Worden</dc:creator>
    </item>
    <item>
      <title>On the possibility of deep alignment</title>
      <link>https://arxiv.org/abs/2508.20465</link>
      <description>arXiv:2508.20465v1 Announce Type: new 
Abstract: I consider motivation and value-alignment in AI systems from the perspective of (constrained) entropy maximization. Though the structures encoding knowledge in any physical system can be understood as energetic constraints, only living agents harness entropy in the endogenous generation of actions. I argue that this exploitation of "mortal" or thermodynamic computation, in which cognitive and physical dynamics are inseparable, is of the essence of desire, motivation, and value, while the lack of true endogenous motivation in simulated "agents" predicts pathologies like reward hacking.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.20465v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Fri, 29 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Alex B. Kiefer</dc:creator>
    </item>
    <item>
      <title>Improving Liver Disease Diagnosis with SNNDeep: A Custom Spiking Neural Network Using Diverse Learning Algorithms</title>
      <link>https://arxiv.org/abs/2508.20125</link>
      <description>arXiv:2508.20125v1 Announce Type: cross 
Abstract: Purpose: Spiking neural networks (SNNs) have recently gained attention as energy-efficient, biologically plausible alternatives to conventional deep learning models. Their application in high-stakes biomedical imaging remains almost entirely unexplored. Methods: This study introduces SNNDeep, the first tailored SNN specifically optimized for binary classification of liver health status from computed tomography (CT) features. To ensure clinical relevance and broad generalizability, the model was developed and evaluated using the Task03\Liver dataset from the Medical Segmentation Decathlon (MSD), a standardized benchmark widely used for assessing performance across diverse medical imaging tasks. We benchmark three fundamentally different learning algorithms, namely Surrogate Gradient Learning, the Tempotron rule, and Bio-Inspired Active Learning across three architectural variants: a fully customized low-level model built from scratch, and two implementations using leading SNN frameworks, i.e., snnTorch and SpikingJelly. Hyperparameter optimization was performed using Optuna. Results: Our results demonstrate that the custom-built SNNDeep consistently outperforms framework-based implementations, achieving a maximum validation accuracy of 98.35%, superior adaptability across learning rules, and significantly reduced training overhead. Conclusion:This study provides the first empirical evidence that low-level, highly tunable SNNs can surpass standard frameworks in medical imaging, especially in data-limited, temporally constrained diagnostic settings, thereby opening a new pathway for neuro-inspired AI in precision medicine.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.20125v1</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 29 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zofia Rudnicka, Janusz Szczepanski, Agnieszka Pregowska</dc:creator>
    </item>
    <item>
      <title>Adaptive Segmentation of EEG for Machine Learning Applications</title>
      <link>https://arxiv.org/abs/2508.20336</link>
      <description>arXiv:2508.20336v1 Announce Type: cross 
Abstract: Objective. Electroencephalography (EEG) data is derived by sampling continuous neurological time series signals. In order to prepare EEG signals for machine learning, the signal must be divided into manageable segments. The current naive approach uses arbitrary fixed time slices, which may have limited biological relevance because brain states are not confined to fixed intervals. We investigate whether adaptive segmentation methods are beneficial for machine learning EEG analysis.
  Approach. We introduce a novel adaptive segmentation method, CTXSEG, that creates variable-length segments based on statistical differences in the EEG data and propose ways to use them with modern machine learning approaches that typically require fixed-length input. We assess CTXSEG using controllable synthetic data generated by our novel signal generator CTXGEN. While our CTXSEG method has general utility, we validate it on a real-world use case by applying it to an EEG seizure detection problem. We compare the performance of CTXSEG with fixed-length segmentation in the preprocessing step of a typical EEG machine learning pipeline for seizure detection.
  Main results. We found that using CTXSEG to prepare EEG data improves seizure detection performance compared to fixed-length approaches when evaluated using a standardized framework, without modifying the machine learning method, and requires fewer segments.
  Significance. This work demonstrates that adaptive segmentation with CTXSEG can be readily applied to modern machine learning approaches, with potential to improve performance. It is a promising alternative to fixed-length segmentation for signal preprocessing and should be considered as part of the standard preprocessing repertoire in EEG machine learning applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.20336v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 29 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Johnson Zhou, Joseph West, Krista A. Ehinger, Zhenming Ren, Sam E. John, David B. Grayden</dc:creator>
    </item>
    <item>
      <title>Tumorigenesis as a trauma response: the fragmentation of morphogenetic memory drives neoplastic dissociation</title>
      <link>https://arxiv.org/abs/2508.20363</link>
      <description>arXiv:2508.20363v1 Announce Type: cross 
Abstract: The mitigation of stress is a key challenge for all biological systems. Conditions of unresolvable stress have been associated with a diverse array of pathologies, from cancer to post-traumatic stress disorder (PTSD). Here, I unify insights from evolutionary and developmental biology with trauma psychology to present a novel framework for tumorigenesis which synthesizes stress-perception, tissue dysfunction, and the hallmarks of neoplastic growth. This view carries therapeutic implications, suggesting a reintegrative approach that seeks to return cancer cells to the homeostatic control of the surrounding tissue.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.20363v1</guid>
      <category>q-bio.CB</category>
      <category>q-bio.NC</category>
      <category>q-bio.PE</category>
      <category>q-bio.TO</category>
      <pubDate>Fri, 29 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jordan Strasser</dc:creator>
    </item>
    <item>
      <title>Bridging Minds and Machines: Toward an Integration of AI and Cognitive Science</title>
      <link>https://arxiv.org/abs/2508.20674</link>
      <description>arXiv:2508.20674v1 Announce Type: cross 
Abstract: Cognitive Science has profoundly shaped disciplines such as Artificial Intelligence (AI), Philosophy, Psychology, Neuroscience, Linguistics, and Culture. Many breakthroughs in AI trace their roots to cognitive theories, while AI itself has become an indispensable tool for advancing cognitive research. This reciprocal relationship motivates a comprehensive review of the intersections between AI and Cognitive Science. By synthesizing key contributions from both perspectives, we observe that AI progress has largely emphasized practical task performance, whereas its cognitive foundations remain conceptually fragmented. We argue that the future of AI within Cognitive Science lies not only in improving performance but also in constructing systems that deepen our understanding of the human mind. Promising directions include aligning AI behaviors with cognitive frameworks, situating AI in embodiment and culture, developing personalized cognitive models, and rethinking AI ethics through cognitive co-evaluation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.20674v1</guid>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 29 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rui Mao, Qian Liu, Xiao Li, Erik Cambria, Amir Hussain</dc:creator>
    </item>
    <item>
      <title>Distinct weak asymmetric interactions shape human brain functions as probability fluxes</title>
      <link>https://arxiv.org/abs/2508.20961</link>
      <description>arXiv:2508.20961v1 Announce Type: cross 
Abstract: The functional computation of the human brain arises from the collective behaviour of the underlying neural network. The emerging technology enables the recording of population activity in neurons, and the theory of neural networks is expected to explain and extract functional computations from the data. Thermodynamically, a large proportion of the whole-body energy is consumed by the brain, and functional computation of the human brain seems to involve high energy consumption. The human brain, however, does not increase its energy consumption with its function, and most of its energy consumption is not involved in specific brain function: how can the human brain perform its wide repertoire of functional computations without drastically changing its energy consumption? Here, we present a mechanism to perform functional computation by subtle modification of the interaction network among the brain regions. We first show that, by analyzing the data of spontaneous and task-induced whole-cerebral-cortex activity, the probability fluxes, which are the microscopic irreversible measure of state transitions, exhibit unique patterns depending on the task being performed, indicating that the human brain function is a distinct sequence of the brain state transitions. We then fit the parameters of Ising spin systems with asymmetric interactions, where we reveal that the symmetric interactions among the brain regions are strong and task-independent, but the antisymmetric interactions are subtle and task-dependent, and the inferred model reproduces most of the observed probability flux patterns. Our results indicate that the human brain performs its functional computation by subtly modifying the antisymmetric interaction among the brain regions, which might be possible with a small amount of energy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.20961v1</guid>
      <category>physics.bio-ph</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>physics.data-an</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 29 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yoshiaki Horiike, Shin Fujishiro</dc:creator>
    </item>
    <item>
      <title>Possible Principles for Aligned Structure Learning Agents</title>
      <link>https://arxiv.org/abs/2410.00258</link>
      <description>arXiv:2410.00258v3 Announce Type: replace-cross 
Abstract: This paper offers a roadmap for the development of scalable aligned artificial intelligence (AI) from first principle descriptions of natural intelligence. In brief, a possible path toward scalable aligned AI rests upon enabling artificial agents to learn a good model of the world that includes a good model of our preferences. For this, the main objective is creating agents that learn to represent the world and other agents' world models; a problem that falls under structure learning (a.k.a. causal representation learning or model discovery). We expose the structure learning and alignment problems with this goal in mind, as well as principles to guide us forward, synthesizing various ideas across mathematics, statistics, and cognitive science. 1) We discuss the essential role of core knowledge, information geometry and model reduction in structure learning, and suggest core structural modules to learn a wide range of naturalistic worlds. 2) We outline a way toward aligned agents through structure learning and theory of mind. As an illustrative example, we mathematically sketch Asimov's Laws of Robotics, which prescribe agents to act cautiously to minimize the ill-being of other agents. We supplement this example by proposing refined approaches to alignment. These observations may guide the development of artificial intelligence in helping to scale existing -- or design new -- aligned structure learning systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00258v3</guid>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 29 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lancelot Da Costa, Tom\'a\v{s} Gaven\v{c}iak, David Hyland, Mandana Samiei, Cristian Dragos-Manta, Candice Pattisapu, Adeel Razi, Karl Friston</dc:creator>
    </item>
    <item>
      <title>Hyperbolic embedding of multilayer networks</title>
      <link>https://arxiv.org/abs/2505.20378</link>
      <description>arXiv:2505.20378v2 Announce Type: replace-cross 
Abstract: Multilayer networks offer a powerful framework for modeling complex systems across diverse domains, effectively capturing multiple types of connections and interdependent subsystems commonly found in real world scenarios. To analyze these networks, embedding techniques that project nodes into a lower-dimensional geometric space are essential. This paper introduces a novel hyperbolic embedding framework that advances the state of the art in multilayer network analysis. Our method, which supports heterogeneous node sets across networks and inter-layer connections, generates layer-specific hyperbolic embeddings, enabling detailed intra-layer analysis and inter-layer comparisons, while simultaneously preserving the global multilayer structure within hyperbolic space, a capability that sets it apart from existing approaches, which typically rely on independent embedding of layers. Through experiments on synthetic multilayer stochastic block models, we demonstrate that our approach effectively preserves community structure, even when layers consist of different node sets. When applied to real brain networks, the method successfully clusters disease-related brain regions from different patients, outperforming layer-independent approaches and highlighting its relevance for comparative analysis. Overall, this work provides a robust tool for multilayer network analysis, enhancing interpretability and offering new insights into the structure and function of complex systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20378v2</guid>
      <category>cs.SI</category>
      <category>physics.data-an</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 29 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martin Guillemaud, Vera Dinkelacker, Mario Chavez</dc:creator>
    </item>
  </channel>
</rss>
