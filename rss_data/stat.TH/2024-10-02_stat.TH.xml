<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.TH</link>
    <description>stat.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 03 Oct 2024 02:11:17 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Shuffled Linear Regression via Spectral Matching</title>
      <link>https://arxiv.org/abs/2410.00078</link>
      <description>arXiv:2410.00078v1 Announce Type: new 
Abstract: Shuffled linear regression (SLR) seeks to estimate latent features through a linear transformation, complicated by unknown permutations in the measurement dimensions. This problem extends traditional least-squares (LS) and Least Absolute Shrinkage and Selection Operator (LASSO) approaches by jointly estimating the permutation, resulting in shuffled LS and shuffled LASSO formulations. Existing methods, constrained by the combinatorial complexity of permutation recovery, often address small-scale cases with limited measurements. In contrast, we focus on large-scale SLR, particularly suited for environments with abundant measurement samples. We propose a spectral matching method that efficiently resolves permutations by aligning spectral components of the measurement and feature covariances. Rigorous theoretical analyses demonstrate that our method achieves accurate estimates in both shuffled LS and shuffled LASSO settings, given a sufficient number of samples. Furthermore, we extend our approach to address simultaneous pose and correspondence estimation in image registration tasks. Experiments on synthetic datasets and real-world image registration scenarios show that our method outperforms existing algorithms in both estimation accuracy and registration performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00078v1</guid>
      <category>math.ST</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <category>math.SP</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hang Liu, Anna Scaglione</dc:creator>
    </item>
    <item>
      <title>Improved performance guarantees for Tukey's median</title>
      <link>https://arxiv.org/abs/2410.00219</link>
      <description>arXiv:2410.00219v1 Announce Type: new 
Abstract: Is there a natural way to order data in dimension greater than one? The approach based on the notion of data depth, often associated with the name of John Tukey, is among the most popular. Tukey's depth has found applications in robust statistics, graph theory, and the study of elections and social choice. We present improved performance guarantees for empirical Tukey's median, a deepest point associated with the given sample, when the data-generating distribution is elliptically symmetric and possibly anisotropic. Some of our results remain valid in the class of affine equivariant estimators. As a corollary of our bounds, we show that the diameter of the set of all empirical Tukey's medians scales like $o(n^{-1/2})$ where $n$ is the sample size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00219v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stanislav Minsker, Yinan Shen</dc:creator>
    </item>
    <item>
      <title>Singularities in bivariate normal mixtures</title>
      <link>https://arxiv.org/abs/2410.00415</link>
      <description>arXiv:2410.00415v1 Announce Type: new 
Abstract: We investigate mappings $F = (f_1, f_2) \colon \mathbb{R}^2 \to \mathbb{R}^2 $ where $ f_1, f_2 $ are bivariate normal densities from the perspective of singularity theory of mappings, motivated by the need to understand properties of two-component bivariate normal mixtures. We show a classification of mappings $ F = (f_1, f_2) $ via $\mathcal{A}$-equivalence and characterize them using statistical notions. Our analysis reveals three distinct types, each with specific geometric properties. Furthermore, we determine the upper bounds for the number of modes in the mixture for each type.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00415v1</guid>
      <category>math.ST</category>
      <category>math.GT</category>
      <category>stat.TH</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yutaro Kabata, Hirotaka Matsumoto, Seiichi Uchida, Masao Ueki</dc:creator>
    </item>
    <item>
      <title>Optimal Designs for Regression on Lie Groups</title>
      <link>https://arxiv.org/abs/2410.00429</link>
      <description>arXiv:2410.00429v1 Announce Type: new 
Abstract: We consider a linear regression model with complex-valued response and predictors from a compact and connected Lie group. The regression model is formulated in terms of eigenfunctions of the Laplace-Beltrami operator on the Lie group. We show that the normalized Haar measure is an approximate optimal design with respect to all Kiefer's $\Phi_p$-criteria. Inspired by the concept of $t$-designs in the field of algebraic combinatorics, we then consider so-called $\lambda$-designs in order to construct exact $\Phi_p$-optimal designs for fixed sample sizes in the considered regression problem. In particular, we explicitly construct $\Phi_p$-optimal designs for regression models with predictors in the Lie groups $\mathrm{SU}(2)$ and $\mathrm{SO}(3)$, the groups of $2\times 2$ unitary matrices and $3\times 3$ orthogonal matrices with determinant equal to $1$, respectively. We also discuss the advantages of the derived theoretical results in a concrete biological application.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00429v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Somnath Chakraborty, Holger Dette, Martin Kroll</dc:creator>
    </item>
    <item>
      <title>Some notes on the $k$-means clustering for missing data</title>
      <link>https://arxiv.org/abs/2410.00546</link>
      <description>arXiv:2410.00546v1 Announce Type: new 
Abstract: The classical $k$-means clustering requires a complete data matrix without missing entries. As a natural extension of the $k$-means clustering for missing data, the $k$-POD clustering has been proposed, which ignores the missing entries in the $k$-means clustering. This paper shows the inconsistency of the $k$-POD clustering even under the missing completely at random mechanism. More specifically, the expected loss of the $k$-POD clustering can be represented as the weighted sum of the expected $k$-means losses with parts of variables. Thus, the $k$-POD clustering converges to the different clustering from the $k$-means clustering as the sample size goes to infinity. This result indicates that although the $k$-means clustering works well, the $k$-POD clustering may fail to capture the hidden cluster structure. On the other hand, for high-dimensional data, the $k$-POD clustering could be a suitable choice when the missing rate in each variable is low.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00546v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yoshikazu Terada, Xin Guan</dc:creator>
    </item>
    <item>
      <title>Nonparametric Diffusivity Estimation for the Stochastic Heat Equation from Noisy Observations</title>
      <link>https://arxiv.org/abs/2410.00677</link>
      <description>arXiv:2410.00677v1 Announce Type: new 
Abstract: We estimate nonparametrically the spatially varying diffusivity of a stochastic heat equation from observations perturbed by additional noise. To that end, we employ a two-step localization procedure, more precisely, we combine local state estimates into a locally linear regression approach. Our analysis relies on quantitative Trotter--Kato type approximation results for the heat semigroup that are of independent interest. The presence of observational noise leads to non-standard scaling behaviour of the model. Numerical simulations illustrate the results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00677v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gregor Pasemann, Markus Rei{\ss}</dc:creator>
    </item>
    <item>
      <title>How should we aggregate ratings? Accounting for personal rating scales via Wasserstein barycenters</title>
      <link>https://arxiv.org/abs/2410.00865</link>
      <description>arXiv:2410.00865v1 Announce Type: new 
Abstract: A common method of making quantitative conclusions in qualitative situations is to collect numerical ratings on a linear scale. We investigate the problem of calculating aggregate numerical ratings from individual numerical ratings and propose a new, non-parametric model for the problem. We show that, with minimal modeling assumptions, the equal-weights average is inconsistent for estimating the quality of items. Analyzing the problem from the perspective of optimal transport, we derive an alternative rating estimator, which we show is asymptotically consistent almost surely and in $L^p$ for estimating quality, with an optimal rate of convergence. Further, we generalize Kendall's W, a non-parametric coefficient of preference concordance between raters, from the special case of rankings to the more general case of arbitrary numerical ratings. Along the way, we prove Glivenko--Cantelli-type theorems for uniform convergence of the cumulative distribution functions and quantile functions for Wasserstein-2 Fr\'echet means on [0,1].</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00865v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Raban</dc:creator>
    </item>
    <item>
      <title>Bayesian Calibration in a multi-output transposition context</title>
      <link>https://arxiv.org/abs/2410.00116</link>
      <description>arXiv:2410.00116v1 Announce Type: cross 
Abstract: Bayesian calibration is an effective approach for ensuring that numerical simulations accurately reflect the behavior of physical systems. However, because numerical models are never perfect, a discrepancy known as model error exists between the model outputs and the observed data, and must be quantified. Conventional methods can not be implemented in transposition situations, such as when a model has multiple outputs but only one is experimentally observed. To account for the model error in this context, we propose augmenting the calibration process by introducing additional input numerical parameters through a hierarchical Bayesian model, which includes hyperparameters for the prior distribution of the calibration variables. Importance sampling estimators are used to avoid increasing computational costs. Performance metrics are introduced to assess the proposed probabilistic model and the accuracy of its predictions. The method is applied on a computer code with three outputs that models the Taylor cylinder impact test. The outputs are considered as the observed variables one at a time, to work with three different transposition situations. The proposed method is compared with other approaches that embed model errors to demonstrate the significance of the hierarchical formulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00116v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gilles Defaux, C\'edric Durantin, Josselin Garnier, Baptiste Kerleguer, Guillaume Perrin, Charlie Sire</dc:creator>
    </item>
    <item>
      <title>Research Frontiers in Ambit Stochastics: In memory of Ole E. Barndorff-Nielsen</title>
      <link>https://arxiv.org/abs/2410.00566</link>
      <description>arXiv:2410.00566v1 Announce Type: cross 
Abstract: This article surveys key aspects of ambit stochastics and remembers Ole E. Barndorff-Nielsen's important contributions to the foundation and advancement of this new research field over the last two decades. It also highlights some of the emerging trends in ambit stochastics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00566v1</guid>
      <category>stat.ME</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fred Espen Benth, Almut E. D. Veraart</dc:creator>
    </item>
    <item>
      <title>Distribution of a Unified $(k_1,k_2,\ldots,k_m)$-run</title>
      <link>https://arxiv.org/abs/2410.00571</link>
      <description>arXiv:2410.00571v1 Announce Type: cross 
Abstract: We explore a unified $(k_1,k_2,\ldots,k_m)$-run in multi-state trials, examining its distributional properties and waiting time distribution. Our study reveals that this particular run serves as a generalization encompassing various patterns. Additionally, we discuss various results pertaining to existing patterns as special cases. To illustrate our findings, we provide an application related to DNA frequent patterns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00571v1</guid>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Savita Chaturvedi, Amit N. Kumar</dc:creator>
    </item>
    <item>
      <title>Asymmetric GARCH modelling without moment conditions</title>
      <link>https://arxiv.org/abs/2410.00574</link>
      <description>arXiv:2410.00574v1 Announce Type: cross 
Abstract: There is a serious and long-standing restriction in the literature on heavy-tailed phenomena in that moment conditions, which are unrealistic, are almost always assumed in modelling such phenomena. Further, the issue of stability is often insufficiently addressed. To this end, we develop a comprehensive statistical inference for an asymmetric generalized autoregressive conditional heteroskedasticity model with standardized non-Gaussian symmetric stable innovation (sAGARCH) in a unified framework, covering both the stationary case and the explosive case. We consider first the maximum likelihood estimation of the model including the asymptotic properties of the estimator of the stable exponent parameter among others. We then propose a modified Kolmogorov-type test statistic for diagnostic checking, as well as those for strict stationarity and asymmetry testing. We conduct Monte Carlo simulation studies to examine the finite-sample performance of our entire statistical inference procedure. We include empirical examples of stock returns to highlight the usefulness and merits of our sAGARCH model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00574v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuxin Tao, Dong Li</dc:creator>
    </item>
    <item>
      <title>Entropy contraction of the Gibbs sampler under log-concavity</title>
      <link>https://arxiv.org/abs/2410.00858</link>
      <description>arXiv:2410.00858v1 Announce Type: cross 
Abstract: The Gibbs sampler (a.k.a. Glauber dynamics and heat-bath algorithm) is a popular Markov Chain Monte Carlo algorithm which iteratively samples from the conditional distributions of a probability measure $\pi$ of interest. Under the assumption that $\pi$ is strongly log-concave, we show that the random scan Gibbs sampler contracts in relative entropy and provide a sharp characterization of the associated contraction rate. Assuming that evaluating conditionals is cheap compared to evaluating the joint density, our results imply that the number of full evaluations of $\pi$ needed for the Gibbs sampler to mix grows linearly with the condition number and is independent of the dimension. If $\pi$ is non-strongly log-concave, the convergence rate in entropy degrades from exponential to polynomial. Our techniques are versatile and extend to Metropolis-within-Gibbs schemes and the Hit-and-Run algorithm. A comparison with gradient-based schemes and the connection with the optimization literature are also discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00858v1</guid>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Filippo Ascolani, Hugo Lavenant, Giacomo Zanella</dc:creator>
    </item>
    <item>
      <title>On the Gaussian product inequality conjecture for disjoint principal minors of Wishart random matrices</title>
      <link>https://arxiv.org/abs/2311.00202</link>
      <description>arXiv:2311.00202v3 Announce Type: replace 
Abstract: This paper extends various results related to the Gaussian product inequality (GPI) conjecture to the setting of disjoint principal minors of Wishart random matrices. This includes product-type inequalities for matrix-variate analogs of completely monotone functions and Bernstein functions of Wishart disjoint principal minors, respectively. In particular, the product-type inequalities apply to inverse determinant powers. Quantitative versions of the inequalities are also obtained when there is a mix of positive and negative exponents. Furthermore, an extended form of the GPI is shown to hold for the eigenvalues of Wishart random matrices by virtue of their law being multivariate totally positive of order 2 (MTP${}_2$). A new, unexplored avenue of research is presented to study the GPI from the point of view of elliptical distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.00202v3</guid>
      <category>math.ST</category>
      <category>math.FA</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christian Genest, Fr\'ed\'eric Ouimet, Donald Richards</dc:creator>
    </item>
    <item>
      <title>Matching prior pairs connecting Maximum A Posteriori estimation and posterior expectation</title>
      <link>https://arxiv.org/abs/2312.09586</link>
      <description>arXiv:2312.09586v2 Announce Type: replace 
Abstract: Bayesian statistics has two common measures of central tendency of a posterior distribution: posterior means and Maximum A Posteriori (MAP) estimates. In this paper, we discuss a connection between MAP estimates and posterior means. We derive an asymptotic condition for a pair of prior densities under which the posterior mean based on one prior coincides with the MAP estimate based on the other prior. A sufficient condition for the existence of this prior pair relates to $\alpha$-flatness of the statistical model in information geometry. We also construct a matching prior pair using $\alpha$-parallel priors. Our result elucidates an interesting connection between regularization in generalized linear regression models and posterior expectation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.09586v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michiko Okudo, Keisuke Yano</dc:creator>
    </item>
    <item>
      <title>The Extended UCB Policies for Frequentist Multi-armed Bandit Problems</title>
      <link>https://arxiv.org/abs/1112.1768</link>
      <description>arXiv:1112.1768v3 Announce Type: replace-cross 
Abstract: The multi-armed bandit (MAB) problem is a widely studied model in the field of operations research for sequential decision making and reinforcement learning. This paper mainly considers the classical MAB model with the heavy-tailed reward distributions. We introduce the extended robust UCB policy, which is an extension of the pioneering UCB policies proposed by Bubeck et al. [5] and Lattimore [21]. The previous UCB policies require the knowledge of an upper bound on specific moments of reward distributions or a particular moment to exist, which can be hard to acquire or guarantee in practical scenarios. Our extended robust UCB generalizes Lattimore's seminary work (for moments of orders $p=4$ and $q=2$) to arbitrarily chosen $p$ and $q$ as long as the two moments have a known controlled relationship, while still achieving the optimal regret growth order O(log T), thus providing a broadened application area of the UCB policies for the heavy-tailed reward distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:1112.1768v3</guid>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Keqin Liu, Tianshuo Zheng, Haoran Chen</dc:creator>
    </item>
    <item>
      <title>Identification enhanced generalised linear model estimation with nonignorable missing outcomes</title>
      <link>https://arxiv.org/abs/2204.10508</link>
      <description>arXiv:2204.10508v3 Announce Type: replace-cross 
Abstract: Missing data often result in undesirable bias and loss of efficiency. These become substantial problems when the response mechanism is nonignorable, such that the response model depends on unobserved variables. It is necessary to estimate the joint distribution of unobserved variables and response indicators to manage nonignorable nonresponse. However, model misspecification and identification issues prevent robust estimates despite careful estimation of the target joint distribution. In this study, we modelled the distribution of the observed parts and derived sufficient conditions for model identifiability, assuming a logistic regression model as the response mechanism and generalised linear models as the main outcome model of interest. More importantly, the derived sufficient conditions are testable with the observed data and do not require any instrumental variables, which are often assumed to guarantee model identifiability but cannot be practically determined beforehand. To analyse missing data, we propose a new imputation method which incorporates verifiable identifiability using only observed data. Furthermore, we present the performance of the proposed estimators in numerical studies and apply the proposed method to two sets of real data: exit polls for the 19th South Korean election data and public data collected from the Korean Survey of Household Finances and Living Conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2204.10508v3</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kenji Beppu, Jinung Choi, Kosuke Morikawa, Jongho Im</dc:creator>
    </item>
    <item>
      <title>Alternating minimization for generalized rank one matrix sensing: Sharp predictions from a random initialization</title>
      <link>https://arxiv.org/abs/2207.09660</link>
      <description>arXiv:2207.09660v2 Announce Type: replace-cross 
Abstract: We consider the problem of estimating the factors of a rank-$1$ matrix with i.i.d. Gaussian, rank-$1$ measurements that are nonlinearly transformed and corrupted by noise. Considering two prototypical choices for the nonlinearity, we study the convergence properties of a natural alternating update rule for this nonconvex optimization problem starting from a random initialization. We show sharp convergence guarantees for a sample-split version of the algorithm by deriving a deterministic recursion that is accurate even in high-dimensional problems. Notably, while the infinite-sample population update is uninformative and suggests exact recovery in a single step, the algorithm -- and our deterministic prediction -- converges geometrically fast from a random initialization. Our sharp, non-asymptotic analysis also exposes several other fine-grained properties of this problem, including how the nonlinearity and noise level affect convergence behavior.
  On a technical level, our results are enabled by showing that the empirical error recursion can be predicted by our deterministic sequence within fluctuations of the order $n^{-1/2}$ when each iteration is run with $n$ observations. Our technique leverages leave-one-out tools originating in the literature on high-dimensional $M$-estimation and provides an avenue for sharply analyzing higher-order iterative algorithms from a random initialization in other high-dimensional optimization problems with random data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.09660v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kabir Aladin Chandrasekher, Mengqi Lou, Ashwin Pananjady</dc:creator>
    </item>
    <item>
      <title>Stochastic Direct Search Method for Blind Resource Allocation</title>
      <link>https://arxiv.org/abs/2210.05222</link>
      <description>arXiv:2210.05222v2 Announce Type: replace-cross 
Abstract: Motivated by programmatic advertising optimization, we consider the task of sequentially allocating budget across a set of resources. At every time step, a feasible allocation is chosen and only a corresponding random return is observed. The goal is to maximize the cumulative expected sum of returns. This is a realistic model for budget allocation across subdivisions of marketing campaigns, with the objective of maximizing the number of conversions.  We study direct search (also known as pattern search) methods for linearly constrained and derivative-free optimization in the presence of noise, which apply in particular  to sequential budget allocation. These algorithms, which do not rely on hierarchical partitioning of the resource space, are easy to implement; they respect the operational constraints of resource allocation by avoiding evaluation outside of the feasible domain; and they are also compatible with warm start by being (approximate) descent algorithms. However, they have not yet been analyzed from the perspective of cumulative regret. We show that direct search methods achieves finite regret in the deterministic and unconstrained case. In the presence of evaluation noise and linear constraints, we propose a simple extension of direct search that achieves a regret upper-bound of the order of $T^{2/3}$. We also propose an accelerated version of the algorithm, relying on repeated sequential testing, that significantly improves the practical behavior of the approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.05222v2</guid>
      <category>cs.AI</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Transactions on Machine Learning Research Journal, 2024</arxiv:journal_reference>
      <dc:creator>Juliette Achddou (PSL, DI-ENS), Olivier Cappe (CNRS, DI-ENS, PSL), Aur\'elien Garivier (UMPA-ENSL, CNRS)</dc:creator>
    </item>
    <item>
      <title>To spike or not to spike: the whims of the Wonham filter in the strong noise regime</title>
      <link>https://arxiv.org/abs/2211.02032</link>
      <description>arXiv:2211.02032v3 Announce Type: replace-cross 
Abstract: We study the celebrated Shiryaev-Wonham filter (1964) in its historical setup where the hidden Markov jump process has two states. We are interested in the weak noise regime for the observation equation. Interestingly, this becomes a strong noise regime for the filtering equations.
  Earlier results of the authors show the appearance of spikes in the filtered process, akin to a metastability phenomenon. This paper is aimed at understanding the smoothed optimal filter, which is relevant for any system with feedback. In particular, we exhibit a sharp phase transition between a spiking regime and a regime with perfect smoothing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.02032v3</guid>
      <category>math.PR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>C\'edric Bernardin, Reda Chhaibi, Joseph Najnudel, Cl\'ement Pellegrini</dc:creator>
    </item>
    <item>
      <title>When can weak latent factors be statistically inferred?</title>
      <link>https://arxiv.org/abs/2407.03616</link>
      <description>arXiv:2407.03616v3 Announce Type: replace-cross 
Abstract: This article establishes a new and comprehensive estimation and inference theory for principal component analysis (PCA) under the weak factor model that allow for cross-sectional dependent idiosyncratic components under the nearly minimal factor strength relative to the noise level or signal-to-noise ratio. Our theory is applicable regardless of the relative growth rate between the cross-sectional dimension $N$ and temporal dimension $T$. This more realistic assumption and noticeable result require completely new technical device, as the commonly-used leave-one-out trick is no longer applicable to the case with cross-sectional dependence. Another notable advancement of our theory is on PCA inference $ - $ for example, under the regime where $N\asymp T$, we show that the asymptotic normality for the PCA-based estimator holds as long as the signal-to-noise ratio (SNR) grows faster than a polynomial rate of $\log N$. This finding significantly surpasses prior work that required a polynomial rate of $N$. Our theory is entirely non-asymptotic, offering finite-sample characterizations for both the estimation error and the uncertainty level of statistical inference. A notable technical innovation is our closed-form first-order approximation of PCA-based estimator, which paves the way for various statistical tests. Furthermore, we apply our theories to design easy-to-implement statistics for validating whether given factors fall in the linear spans of unknown latent factors, testing structural breaks in the factor loadings for an individual unit, checking whether two units have the same risk exposures, and constructing confidence intervals for systematic risks. Our empirical studies uncover insightful correlations between our test results and economic cycles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03616v3</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>q-fin.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianqing Fan, Yuling Yan, Yuheng Zheng</dc:creator>
    </item>
    <item>
      <title>Optimizing the Induced Correlation in Omnibus Joint Graph Embeddings</title>
      <link>https://arxiv.org/abs/2409.17544</link>
      <description>arXiv:2409.17544v2 Announce Type: replace-cross 
Abstract: Theoretical and empirical evidence suggests that joint graph embedding algorithms induce correlation across the networks in the embedding space. In the Omnibus joint graph embedding framework, previous results explicitly delineated the dual effects of the algorithm-induced and model-inherent correlations on the correlation across the embedded networks. Accounting for and mitigating the algorithm-induced correlation is key to subsequent inference, as sub-optimal Omnibus matrix constructions have been demonstrated to lead to loss in inference fidelity. This work presents the first efforts to automate the Omnibus construction in order to address two key questions in this joint embedding framework: the correlation-to-OMNI problem and the flat correlation problem. In the flat correlation problem, we seek to understand the minimum algorithm-induced flat correlation (i.e., the same across all graph pairs) produced by a generalized Omnibus embedding. Working in a subspace of the fully general Omnibus matrices, we prove both a lower bound for this flat correlation and that the classical Omnibus construction induces the maximal flat correlation. In the correlation-to-OMNI problem, we present an algorithm -- named corr2Omni -- that, from a given matrix of estimated pairwise graph correlations, estimates the matrix of generalized Omnibus weights that induces optimal correlation in the embedding space. Moreover, in both simulated and real data settings, we demonstrate the increased effectiveness of our corr2Omni algorithm versus the classical Omnibus construction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.17544v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Konstantinos Pantazis, Michael Trosset, William N. Frost, Carey E. Priebe, Vince Lyzinski</dc:creator>
    </item>
  </channel>
</rss>
