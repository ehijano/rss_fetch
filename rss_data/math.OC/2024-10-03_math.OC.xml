<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 04 Oct 2024 04:00:25 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Auto-conditioned primal-dual hybrid gradient method and alternating direction method of multipliers</title>
      <link>https://arxiv.org/abs/2410.01979</link>
      <description>arXiv:2410.01979v1 Announce Type: new 
Abstract: Line search procedures are often employed in primal-dual methods for bilinear saddle point problems, especially when the norm of the linear operator is large or difficult to compute. In this paper, we demonstrate that line search is unnecessary by introducing a novel primal-dual method, the auto-conditioned primal-dual hybrid gradient (AC-PDHG) method, which achieves optimal complexity for solving bilinear saddle point problems. AC-PDHG is fully adaptive to the linear operator, using only past iterates to estimate its norm. We further tailor AC-PDHG to solve linearly constrained problems, providing convergence guarantees for both the optimality gap and constraint violation. Moreover, we explore an important class of linearly constrained problems where both the objective and constraints decompose into two parts. By incorporating the design principles of AC-PDHG into the preconditioned alternating direction method of multipliers (ADMM), we propose the auto-conditioned alternating direction method of multipliers (AC-ADMM), which guarantees convergence based solely on one part of the constraint matrix and fully adapts to it, eliminating the need for line search. Finally, we extend both AC-PDHG and AC-ADMM to solve bilinear problems with an additional smooth term. By integrating these methods with a novel acceleration scheme, we attain optimal iteration complexities under the single-oracle setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01979v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guanghui Lan, Tianjiao Li</dc:creator>
    </item>
    <item>
      <title>Optimal Sensing Precision for Celestial Navigation Systems in Cislunar Space using LPV Framework</title>
      <link>https://arxiv.org/abs/2410.02013</link>
      <description>arXiv:2410.02013v1 Announce Type: new 
Abstract: This paper introduces two innovative convex optimization formulations to simultaneously optimize the H2/Hinf observer gain and sensing precision, and guarantee a specified estimation error bound for nonlinear systems in LPV form. Applied to the design of an onboard celestial navigation system for cislunar operations, these formulations demonstrate the ability to maintain accurate spacecraft positioning with minimal measurements and theoretical performance guarantees by design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02013v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eliot Nychka, Raktim Bhattacharya</dc:creator>
    </item>
    <item>
      <title>Approximating Multiple Robust Optimization Solutions in One Pass via Proximal Point Methods</title>
      <link>https://arxiv.org/abs/2410.02123</link>
      <description>arXiv:2410.02123v1 Announce Type: new 
Abstract: Robust optimization provides a principled and unified framework to model many problems in modern operations research and computer science applications, such as risk measures minimization and adversarially robust machine learning. To use a robust solution (e.g., to implement an investment portfolio or perform robust machine learning inference), the user has to a priori decide the trade-off between efficiency (nominal performance) and robustness (worst-case performance) of the solution by choosing the uncertainty level hyperparameters. In many applications, this amounts to solving the problem many times and comparing them, each from a different hyperparameter setting. This makes robust optimization practically cumbersome or even intractable. We present a novel procedure based on the proximal point method (PPM) to efficiently approximate many Pareto efficient robust solutions at once. This effectively reduces the total compute requirement from $N \times T$ to $2 \times T$, where $N$ is the number of robust solutions to be generated, and $T$ is the time to obtain one robust solution. We prove this procedure can produce exact Pareto efficient robust solutions for a class of robust linear optimization problems. For more general problems, we prove that with high probability, our procedure gives a good approximation of the efficiency-robustness trade-off in random robust linear optimization instances. We conduct numerical experiments to demonstrate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02123v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hao Hao, Peter Zhang</dc:creator>
    </item>
    <item>
      <title>A nonsmooth exact penalty method for equality-constrained optimization: complexity and implementation</title>
      <link>https://arxiv.org/abs/2410.02188</link>
      <description>arXiv:2410.02188v1 Announce Type: new 
Abstract: Penalty methods are a well known class of algorithms for constrained optimization. They transform a constrained problem into a sequence of unconstrained penalized problems in the hope that approximate solutions of the latter converge to a solution of the former. If Lagrange multipliers exist, exact penalty methods ensure that the penalty parameter only need increase a finite number of times, but are typically scorned in smooth optimization for the penalized problems are not smooth. This led researchers to consider the implementation of exact penalty methods inconvenient. Recently, advances in proximal methods have led to increasingly efficient solvers for nonsmooth optimization. We show that the exact $\ell_2$-penalty method for equality-constrained optimization can in fact be implemented efficiently by solving the penalized problem with a proximal-type algorithm. We study the convergence of our algorithm and establish a worst-case complexity bound of $O(\epsilon^{-2})$ to bring a stationarity measure below $\epsilon &gt; 0$ under the Mangarasian-Fromowitz constraint qualification and Lipschitz continuity of the objective gradient and constraint Jacobian. In a degenerate scenario where the penalty parameter grows unbounded, the complexity becomes $O(\epsilon^{-8})$, which is worse than another bound found in the literature. We justify the difference by arguing that our feasibility measure is properly scaled. Finally, we report numerical experience on small-scale problems from a standard collection and compare our solver with an augmented-Lagrangian and an SQP method. Our preliminary implementation is on par with the augmented Lagrangian in terms of robustness and efficiency. It is on par with the SQP method in terms of robustness, though the former remains ahead in terms of number of problem function evaluations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02188v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.13140/RG.2.2.16095.47527</arxiv:DOI>
      <dc:creator>Youssef Diouane, Maxence Gollier, Dominique Orban</dc:creator>
    </item>
    <item>
      <title>Exponential Convergence of Augmented Primal-dual Gradient Algorithms for Partially Strongly Convex Functions</title>
      <link>https://arxiv.org/abs/2410.02192</link>
      <description>arXiv:2410.02192v1 Announce Type: new 
Abstract: We show that global exponential convergence for the augmented primal-dual gradient algorithms can be achieved for partially strongly convex functions. In particular, the objective function only needs to be strongly convex in the subspace satisfying the equality constraint and can be generally convex elsewhere provided the global Lipschitz condition for the gradient is satisfied. This condition also implies that states outside the equality subspace will be driven towards it by the augmented primal-dual algorithm exponentially fast. The analysis is then applied to distributed optimization, where the partially strong convexity can be relaxed to the restricted secant inequality condition, which is not necessarily convex. This work unifies global exponential convergence results for some existing centralized and distributed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02192v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mengmou Li, Masaaki Nagahara</dc:creator>
    </item>
    <item>
      <title>Open-source shape optimization for isogeometric shells using FEniCS and OpenMDAO</title>
      <link>https://arxiv.org/abs/2410.02225</link>
      <description>arXiv:2410.02225v1 Announce Type: new 
Abstract: We present an open-source Python framework for the shape optimization of complex shell structures using isogeometric analysis (IGA). IGA seamlessly integrates computer-aided design (CAD) and analysis models by employing non-uniform rational B-splines (NURBS) as basis functions, enabling the natural implementation of the Kirchhoff--Love shell model due to their higher order of continuity. We leverage the recently developed FEniCS-based analysis framework, PENGoLINS, for the direct structural analysis of shell structures consisting of a collection of NURBS patches through a penalty-based formulation. This contribution introduces the open-source implementation of gradient-based shape optimization for isogeometric Kirchhoff--Love shells with a modular architecture. Complex shell structures with non-matching intersections are handled using a free-form deformation (FFD) approach and a moving intersections formulation. The symbolic differentiation and code generation capabilities in FEniCS are utilized to compute the analytical derivatives. By integrating FEniCS with OpenMDAO, we build modular components that facilitate gradient-based shape optimization of shell structures. The modular architecture in this work supports future extensions and integration with other disciplines and solvers, making it highly customizable and suitable for a wide range of applications. We validate the design-analysis-optimization workflow through several benchmark problems and demonstrate its application to aircraft wing design optimization. The framework is implemented in a Python library named GOLDFISH (Gradient-based Optimization and Large-scale Design Framework for Isogeometric SHells) and the source code will be maintained at https://github.com/hanzhao2020/GOLDFISH.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02225v1</guid>
      <category>math.OC</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Han Zhao, John T. Hwang, Jiun-Shyan Chen</dc:creator>
    </item>
    <item>
      <title>Optimal $H_{\infty}$ control based on stable manifold of discounted Hamilton-Jacobi-Isaacs equation</title>
      <link>https://arxiv.org/abs/2410.02272</link>
      <description>arXiv:2410.02272v1 Announce Type: new 
Abstract: The optimal \(H_{\infty}\) control problem over an infinite time horizon, which incorporates a performance function with a discount factor \(e^{-\alpha t}\) (\(\alpha &gt; 0\)), is important in various fields. Solving this optimal \(H_{\infty}\) control problem is equivalent to addressing a discounted Hamilton-Jacobi-Isaacs (HJI) partial differential equation. In this paper, we first provide a precise estimate for the discount factor \(\alpha\) that ensures the existence of a nonnegative stabilizing solution to the HJI equation. This stabilizing solution corresponds to the stable manifold of the characteristic system of the HJI equation, which is a contact Hamiltonian system due to the presence of the discount factor. Secondly, we demonstrate that approximating the optimal controller in a natural manner results in a closed-loop system with a finite \(L_2\)-gain that is nearly less than the gain of the original system. Thirdly, based on the theoretical results obtained, we propose a deep learning algorithm to approximate the optimal controller using the stable manifold of the contact Hamiltonian system associated with the HJI equation. Finally, we apply our method to the \(H_{\infty}\) control of the Allen-Cahn equation to illustrate its effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02272v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guoyuan Chen, Yi Wang, Qinglong Zhou</dc:creator>
    </item>
    <item>
      <title>Small-time controllability on the group of diffeomorphisms for Schr\"odinger equations</title>
      <link>https://arxiv.org/abs/2410.02383</link>
      <description>arXiv:2410.02383v1 Announce Type: new 
Abstract: In this work, we establish a link between the small-time approximate controllability of bilinear Schr\"odinger PDEs (posed on a boundaryless Riemannian manifold $M$) and the control in the group ${\rm Diff}_c^0(M)$ of the diffeomorphisms, isotopic to the identity and with compact support, of the underlying manifold $M$.
  More precisely, under a density assumption on the Lie algebra generated by the control potential and the Laplacian, we show that compositions $|J_P|^{1/2}(\psi_0\circ P)$ of the initial wavefunction $\psi_0\in L^2(M,\mathbb{C})$ with any diffeomorphism $P\in{\rm Diff}_c^0(M)$ can be approximately reached, in arbitrarily small times, by controlled solutions of the Schr\"odinger equation (here, $|J_P|$ denotes the determinant of the Jacobian of $P$). We illustrate this property on two examples, posed respectively on the torus $\mathbb{T}^d$ and on the euclidean space $\mathbb{R}^d$.
  As a physical application, we obtain in particular the small-time approximate control of the quantum particle's averaged positions. This yields also new small-time approximate controllability properties between families of eigenstates on $\mathbb{T}^d$.
  To prove the result, we first construct solutions of the Schr\"odinger equation that approximately evolve, arbitrarily fast, along any unitary transport flow on $L^2(M,\mathbb{C})$. In this way, we control the composition with any diffeomorphism that can be decomposed as a product of flows on $M$. We then combine this property with a result of Thurston on the simplicity of the group ${\rm Diff}_c^0(M)$ to conclude.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02383v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Karine Beauchard, Eugenio Pozzoli</dc:creator>
    </item>
    <item>
      <title>Where's Ben Nevis? A 2D optimisation benchmark with 957,174 local optima based on Great Britain terrain data</title>
      <link>https://arxiv.org/abs/2410.02422</link>
      <description>arXiv:2410.02422v1 Announce Type: new 
Abstract: We present a novel optimisation benchmark based on the real landscape of Great Britain (GB). The elevation data from the UK Ordnance Survey Terrain 50 dataset is slightly modified and linearly interpolated to produce a target function that simulates the GB terrain, packaged in a new Python module nevis. We introduce a discrete approach to classifying local optima and their corresponding basins of attraction, identifying 957,174 local optima of the target function. We then develop a benchmarking framework for optimisation methods based on this target function, where we propose a Generalised Expected Running Time performance measure to enable meaningful comparisons even when algorithms do not achieve successful runs (find Ben Nevis). Hyperparameter tuning is managed using the optuna framework, and plots and animations are produced to visualise algorithm performance. Using the proposed framework, we benchmark six optimisation algorithms implemented by common Python modules. Amongst those tested, the Differential Evolution algorithm implemented by scipy is the most effective for navigating the complex GB landscape and finding the summit of Ben Nevis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02422v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuhang Wei, Michael Clerx, Gary R. Mirams</dc:creator>
    </item>
    <item>
      <title>Connectivity via convexity: Bounds on the edge expansion in graphs</title>
      <link>https://arxiv.org/abs/2410.02526</link>
      <description>arXiv:2410.02526v1 Announce Type: new 
Abstract: Convexification techniques have gained increasing interest over the past decades. In this work, we apply a recently developed convexification technique for fractional programs by He, Liu and Tawarmalani (2024) to the problem of determining the edge expansion of a graph. Computing the edge expansion of a graph is a well-known, difficult combinatorial problem that seeks to partition the graph into two sets such that a fractional objective function is minimized.
  We give a formulation of the edge expansion as a completely positive program and propose a relaxation as a doubly non-negative program, further strengthened by cutting planes. Additionally, we develop an augmented Lagrangian algorithm to solve the doubly non-negative program, obtaining lower bounds on the edge expansion. Numerical results confirm that this relaxation yields strong bounds and is computationally efficient, even for graphs with several hundred vertices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02526v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Timotej Hrga, Melanie Siebenhofer, Angelika Wiegele</dc:creator>
    </item>
    <item>
      <title>Obtaining Lower Query Complexities through Lightweight Zeroth-Order Proximal Gradient Algorithms</title>
      <link>https://arxiv.org/abs/2410.02559</link>
      <description>arXiv:2410.02559v1 Announce Type: new 
Abstract: Zeroth-order (ZO) optimization is one key technique for machine learning problems where gradient calculation is expensive or impossible. Several variance reduced ZO proximal algorithms have been proposed to speed up ZO optimization for non-smooth problems, and all of them opted for the coordinated ZO estimator against the random ZO estimator when approximating the true gradient, since the former is more accurate. While the random ZO estimator introduces bigger error and makes convergence analysis more challenging compared to coordinated ZO estimator, it requires only $\mathcal{O}(1)$ computation, which is significantly less than $\mathcal{O}(d)$ computation of the coordinated ZO estimator, with $d$ being dimension of the problem space. To take advantage of the computationally efficient nature of the random ZO estimator, we first propose a ZO objective decrease (ZOOD) property which can incorporate two different types of errors in the upper bound of convergence rate. Next, we propose two generic reduction frameworks for ZO optimization which can automatically derive the convergence results for convex and non-convex problems respectively, as long as the convergence rate for the inner solver satisfies the ZOOD property. With the application of two reduction frameworks on our proposed ZOR-ProxSVRG and ZOR-ProxSAGA, two variance reduced ZO proximal algorithms with fully random ZO estimators, we improve the state-of-the-art function query complexities from $\mathcal{O}\left(\min\{\frac{dn^{1/2}}{\epsilon^2}, \frac{d}{\epsilon^3}\}\right)$ to $\tilde{\mathcal{O}}\left(\frac{n+d}{\epsilon^2}\right)$ under $d &gt; n^{\frac{1}{2}}$ for non-convex problems, and from $\mathcal{O}\left(\frac{d}{\epsilon^2}\right)$ to $\tilde{\mathcal{O}}\left(n\log\frac{1}{\epsilon}+\frac{d}{\epsilon}\right)$ for convex problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02559v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1162/neco_a_01636</arxiv:DOI>
      <arxiv:journal_reference>Neural Computation, 2024, 36(5): 897-935</arxiv:journal_reference>
      <dc:creator>Bin Gu, Xiyuan Wei, Hualin Zhang, Yi Chang, Heng Huang</dc:creator>
    </item>
    <item>
      <title>Online Learning Guided Quasi-Newton Methods with Global Non-Asymptotic Convergence</title>
      <link>https://arxiv.org/abs/2410.02626</link>
      <description>arXiv:2410.02626v1 Announce Type: new 
Abstract: In this paper, we propose a quasi-Newton method for solving smooth and monotone nonlinear equations, including unconstrained minimization and minimax optimization as special cases. For the strongly monotone setting, we establish two global convergence bounds: (i) a linear convergence rate that matches the rate of the celebrated extragradient method, and (ii) an explicit global superlinear convergence rate that provably surpasses the linear convergence rate after at most ${O}(d)$ iterations, where $d$ is the problem's dimension. In addition, for the case where the operator is only monotone, we prove a global convergence rate of ${O}(\min\{{1}/{k},{\sqrt{d}}/{k^{1.25}}\})$ in terms of the duality gap. This matches the rate of the extragradient method when $k = {O}(d^2)$ and is faster when $k = \Omega(d^2)$. These results are the first global convergence results to demonstrate a provable advantage of a quasi-Newton method over the extragradient method, without querying the Jacobian of the operator. Unlike classical quasi-Newton methods, we achieve this by using the hybrid proximal extragradient framework and a novel online learning approach for updating the Jacobian approximation matrices. Specifically, guided by the convergence analysis, we formulate the Jacobian approximation update as an online convex optimization problem over non-symmetric matrices, relating the regret of the online problem to the convergence rate of our method. To facilitate efficient implementation, we further develop a tailored online learning algorithm based on an approximate separation oracle, which preserves structures such as symmetry and sparsity in the Jacobian matrices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02626v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruichen Jiang, Aryan Mokhtari</dc:creator>
    </item>
    <item>
      <title>Convex Constrained Controller Synthesis for Evolution Equations</title>
      <link>https://arxiv.org/abs/2410.02658</link>
      <description>arXiv:2410.02658v1 Announce Type: new 
Abstract: We propose a convex controller synthesis framework for a large class of constrained linear systems, including those described by (deterministic and stochastic) partial differential equations and integral equations, commonly used in fluid dynamics, thermo-mechanical systems, quantum control, or transportation networks. Most existing control techniques rely on a (finite-dimensional) discrete description of the system, via ordinary differential equations. Here, we work instead with more general (infinite-dimensional) Hilbert spaces. This enables the discretization to be applied after the optimization (optimize-then-discretize). Using output-feedback SLS, we formulate the controller synthesis as a convex optimization problem. Structural constraints like sensor and communication delays, and locality constraints, are incorporated while preserving convexity, allowing parallel implementation and extending key SLS properties to infinite dimensions. The proposed approach and its benefits are demonstrated on a linear Boltzmann equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02658v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lauren Conger, Antoine P. Leeman, Franca Hoffmann</dc:creator>
    </item>
    <item>
      <title>Numerical optimal control for delay differential equations: A simultaneous approach based on linearization of the delayed state</title>
      <link>https://arxiv.org/abs/2410.02687</link>
      <description>arXiv:2410.02687v1 Announce Type: new 
Abstract: Time delays are ubiquitous in industry, and they must be accounted for when designing control strategies. However, numerical optimal control (NOC) of delay differential equations (DDEs) is challenging because it requires specialized discretization methods and the time delays may depend on the manipulated inputs or state variables. Therefore, in this work, we propose to linearize the delayed states around the current time. This results in a set of implicit differential equations, and we compare the steady states and the corresponding stability criteria of the DDEs and the approximate system. Furthermore, we propose a simultaneous approach for NOC of DDEs based on the linearization, and we discretize the approximate system using Euler's implicit method. Finally, we present a numerical example involving a molten salt nuclear fission reactor.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02687v1</guid>
      <category>math.OC</category>
      <category>cs.CE</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tobias K. S. Ritschel, S{\o}ren Stange</dc:creator>
    </item>
    <item>
      <title>Global Stabilization for the BBM-KP equations on R2</title>
      <link>https://arxiv.org/abs/2410.01998</link>
      <description>arXiv:2410.01998v1 Announce Type: cross 
Abstract: In this paper, we present results on the energy decay of the BBM KP equations (I and II) posed on R2 with localized damping. This model offers an alternative to the KP equations, analogous to how the regularized long-wave equation relates to the classical Korteweg de Vries (KdV) equation. We show that the energy associated with the Cauchy problem decays exponentially when a localized dissipative mechanism is present in a subdomain. Finally, we validate the theoretical results on the exponential stabilization of solutions to the BBM KP equations with damping through numerical experiments using a spectral finite difference scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01998v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>F. A. Gallego, V. H. Gonzalez Martinez, J. C. Mu\~noz Grajales</dc:creator>
    </item>
    <item>
      <title>Active Learning of Deep Neural Networks via Gradient-Free Cutting Planes</title>
      <link>https://arxiv.org/abs/2410.02145</link>
      <description>arXiv:2410.02145v1 Announce Type: cross 
Abstract: Active learning methods aim to improve sample complexity in machine learning. In this work, we investigate an active learning scheme via a novel gradient-free cutting-plane training method for ReLU networks of arbitrary depth. We demonstrate, for the first time, that cutting-plane algorithms, traditionally used in linear models, can be extended to deep neural networks despite their nonconvexity and nonlinear decision boundaries. Our results demonstrate that these methods provide a promising alternative to the commonly employed gradient-based optimization techniques in large-scale neural networks. Moreover, this training method induces the first deep active learning scheme known to achieve convergence guarantees. We exemplify the effectiveness of our proposed active learning method against popular deep active learning baselines via both synthetic data experiments and sentimental classification task on real datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02145v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erica Zhang, Fangzhao Zhang, Mert Pilanci</dc:creator>
    </item>
    <item>
      <title>An Efficient Scaled spectral preconditioner for sequences of symmetric positive definite linear systems</title>
      <link>https://arxiv.org/abs/2410.02204</link>
      <description>arXiv:2410.02204v1 Announce Type: cross 
Abstract: We explore a scaled spectral preconditioner for the efficient solution of sequences of symmetric and positive-definite linear systems. We design the scaled preconditioner not only as an approximation of the inverse of the linear system but also with consideration of its use within the conjugate gradient (CG) method. We propose three different strategies for selecting a scaling parameter, which aims to position the eigenvalues of the preconditioned matrix in a way that reduces the energy norm of the error, the quantity that CG monotonically decreases at each iteration. Our focus is on accelerating convergence especially in the early iterations, which is particularly important when CG is truncated due to computational cost constraints. Numerical experiments provide in data assimilation confirm that the scaled spectral preconditioner can significantly improve early CG convergence with negligible computational cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02204v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.13140/RG.2.2.28678.38725</arxiv:DOI>
      <dc:creator>Youssef Diouane, Selime G\"urol, Oussama Mouhtal, Dominique Orban</dc:creator>
    </item>
    <item>
      <title>Convex hulls of curves in $n$-space</title>
      <link>https://arxiv.org/abs/2410.02359</link>
      <description>arXiv:2410.02359v1 Announce Type: cross 
Abstract: Let $K\subseteq{\mathbb R}^n$ be a convex semialgebraic set. The semidefinite extension degree ${\mathrm{sxdeg}}(K)$ of $K$ is the smallest number $d$ such that $K$ is a linear image of an intersection of finitely many spectrahedra, each of which is described by a linear matrix inequality of size $\le d$. For an arbitrary semialgebraic set $S\subseteq{\mathbb R}^n$ of dimension one, the main result says that the closed convex hull $K$ of $S$ satisfies ${\mathrm{sxdeg}}(K)\le1+\lfloor\frac n2\rfloor$. Before, this was known for $n=2$, and also for general $n$ in the case where $S$ is a monomial curve. The bound is attained by the rational normal curve of degree $n$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02359v1</guid>
      <category>math.AG</category>
      <category>math.OC</category>
      <pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Claus Scheiderer</dc:creator>
    </item>
    <item>
      <title>Online Convex Optimization with a Separation Oracle</title>
      <link>https://arxiv.org/abs/2410.02476</link>
      <description>arXiv:2410.02476v1 Announce Type: cross 
Abstract: In this paper, we introduce a new projection-free algorithm for Online Convex Optimization (OCO) with a state-of-the-art regret guarantee among separation-based algorithms. Existing projection-free methods based on the classical Frank-Wolfe algorithm achieve a suboptimal regret bound of $O(T^{3/4})$, while more recent separation-based approaches guarantee a regret bound of $O(\kappa \sqrt{T})$, where $\kappa$ denotes the asphericity of the feasible set, defined as the ratio of the radii of the containing and contained balls. However, for ill-conditioned sets, $\kappa$ can be arbitrarily large, potentially leading to poor performance. Our algorithm achieves a regret bound of $\tilde{O}(\sqrt{dT} + \kappa d)$, while requiring only $\tilde{O}(1)$ calls to a separation oracle per round. Crucially, the main term in the bound, $\tilde{O}(\sqrt{d T})$, is independent of $\kappa$, addressing the limitations of previous methods. Additionally, as a by-product of our analysis, we recover the $O(\kappa \sqrt{T})$ regret bound of existing OCO algorithms with a more straightforward analysis and improve the regret bound for projection-free online exp-concave optimization. Finally, for constrained stochastic convex optimization, we achieve a state-of-the-art convergence rate of $\tilde{O}(\sigma/\sqrt{T} + \kappa d/T)$, where $\sigma$ represents the noise in the stochastic gradients, while requiring only $\tilde{O}(1)$ calls to a separation oracle per iteration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02476v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Zakaria Mhammedi</dc:creator>
    </item>
    <item>
      <title>Sample-Optimal Quantum State Tomography for Structured Quantum States in One Dimension</title>
      <link>https://arxiv.org/abs/2410.02583</link>
      <description>arXiv:2410.02583v1 Announce Type: cross 
Abstract: Quantum state tomography (QST) remains the gold standard for benchmarking and verifying quantum devices. A recent study has proved that, with Haar random projective measurements, only a $O(n^3)$ number of state copies is required to guarantee bounded recovery error of an matrix product operator (MPO) state of qubits $n$. While this result provides a formal evidence that quantum states with an efficient classical representation can be reconstructed with an efficient number of state copies, the number of state copies required is still significantly larger than the number of independent parameters in the classical representation.
  In this paper, we attempt to narrow this gap and study whether the number of state copies can saturate the information theoretic bound (i.e., $O(n)$, the number of parameters in the MPOs) using physical quantum measurements. We answer this question affirmatively by using a class of Informationally Complete Positive Operator-Valued Measures (IC-POVMs), including symmetric IC-POVMs (SIC-POVMs) and spherical $t$-designs. For SIC-POVMs and (approximate) spherical 2-designs, we show that the number of state copies to guarantee bounded recovery error of an MPO state with a constrained least-squares estimator depends on the probability distribution of the MPO under the POVM but scales only linearly with $n$ when the distribution is approximately uniform. For spherical $t$-designs with $t\ge3$, we prove that only a number of state copies proportional to the number of independent parameters in the MPO is needed for a guaranteed recovery of any state represented by an MPO. Moreover, we propose a projected gradient descent (PGD) algorithm to solve the constrained least-squares problem and show that it can efficiently find an estimate with bounded recovery error when appropriately initialized.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02583v1</guid>
      <category>quant-ph</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhen Qin, Casey Jameson, Alireza Goldar, Michael B. Wakin, Zhexuan Gong, Zhihui Zhu</dc:creator>
    </item>
    <item>
      <title>Expected Maximin Fairness in Max-Cut and other Combinatorial Optimization Problems</title>
      <link>https://arxiv.org/abs/2410.02589</link>
      <description>arXiv:2410.02589v1 Announce Type: cross 
Abstract: Maximin fairness is the ideal that the worst-off group (or individual) should be treated as well as possible. Literature on maximin fairness in various decision-making settings has grown in recent years, but theoretical results are sparse. In this paper, we explore the challenges inherent to maximin fairness in combinatorial optimization. We begin by showing that (1) optimal maximin-fair solutions are bounded by non-maximin-fair optimal solutions, and (2) stochastic maximin-fair solutions exceed their deterministic counterparts in expectation for a broad class of combinatorial optimization problems. In the remainder of the paper, we use the special case of Max-Cut to demonstrate challenges in defining and implementing maximin fairness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02589v1</guid>
      <category>cs.DS</category>
      <category>cs.CY</category>
      <category>math.OC</category>
      <pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jad Salem, Reuben Tate, Stephan Eidenbenz</dc:creator>
    </item>
    <item>
      <title>Convergence analysis of a primal-dual optimization-by-continuation algorithm</title>
      <link>https://arxiv.org/abs/2311.09123</link>
      <description>arXiv:2311.09123v2 Announce Type: replace 
Abstract: We present a numerical iterative optimization algorithm for the minimization of a cost function consisting of a linear combination of three convex terms, one of which is differentiable, a second one is prox-simple and the third one is the composition of a linear map and a prox-simple function. The algorithm's special feature lies in its ability to approximate, in a single iteration run, the minimizers of the cost function for many different values of the parameters determining the relative weight of the three terms in the cost function. A proof of convergence of the algorithm, based on an inexact variable metric approach, is also provided. As a special case, one recovers a generalization of the primal-dual algorithm of Chambolle and Pock, and also of the proximal-gradient algorithm. Finally, we show how it is related to a primal-dual iterative algorithm based on inexact proximal evaluations of the non-smooth terms of the cost function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.09123v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.cam.2024.116299</arxiv:DOI>
      <dc:creator>Ignace Loris, Simone Rebegoldi</dc:creator>
    </item>
    <item>
      <title>Solution of the Probabilistic Lambert Problem: Connections with Optimal Mass Transport, Schr\"odinger Bridge and Reaction-Diffusion PDEs</title>
      <link>https://arxiv.org/abs/2401.07961</link>
      <description>arXiv:2401.07961v4 Announce Type: replace 
Abstract: The Lambert problem originated in orbital mechanics. It concerns with determining the initial velocity for a boundary value problem involving the dynamical constraint due to gravitational potential with additional time horizon and endpoint position constraints. Its solution has application in transferring a spacecraft from a given initial to a given terminal position within prescribed flight time via velocity control. We consider a probabilistic variant of the Lambert problem where the knowledge of the endpoint constraints in position vectors are replaced by the knowledge of their respective joint probability density functions. We show that the Lambert problem with endpoint joint probability density constraints is a generalized optimal mass transport (OMT) problem, thereby connecting this classical astrodynamics problem with a burgeoning area of research in modern stochastic control and stochastic machine learning. This newfound connection allows us to rigorously establish the existence and uniqueness of solution for the probabilistic Lambert problem. The same connection also helps to numerically solve the probabilistic Lambert problem via diffusion regularization, i.e., by leveraging further connection of the OMT with the Schr\"odinger bridge problem (SBP). This also shows that the probabilistic Lambert problem with additive dynamic process noise is a generalized SBP, and can be solved numerically using the so-called Schr\"odinger factors, as we do in this work. Our analysis leads to solving a system of reaction-diffusion PDEs where the gravitational potential appears as the reaction rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.07961v4</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>stat.ML</category>
      <pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexis M. H. Teter, Iman Nodozi, Abhishek Halder</dc:creator>
    </item>
    <item>
      <title>Design Guidelines for Noise-Tolerant Optimization with Applications in Robust Design</title>
      <link>https://arxiv.org/abs/2401.15007</link>
      <description>arXiv:2401.15007v2 Announce Type: replace 
Abstract: The development of nonlinear optimization algorithms capable of performing reliably in the presence of noise has garnered considerable attention lately. This paper advocates for strategies to create noise-tolerant nonlinear optimization algorithms by adapting classical deterministic methods. These adaptations follow certain design guidelines described here, which make use of estimates of the noise level in the problem. The application of our methodology is illustrated by the development of a line search gradient projection method, which is tested on an engineering design problem. It is shown that a new self-calibrated line search and noise-aware finite-difference techniques are effective even in the high noise regime. Numerical experiments investigate the resiliency of key algorithmic components. A convergence analysis of the line search gradient projection method establishes convergence to a neighborhood of stationarity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.15007v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuchen Lou, Shigeng Sun, Jorge Nocedal</dc:creator>
    </item>
    <item>
      <title>Generalizing Space Logistics Network Optimization with Integrated Machine Learning and Mathematical Programming</title>
      <link>https://arxiv.org/abs/2404.18770</link>
      <description>arXiv:2404.18770v2 Announce Type: replace 
Abstract: Recent growing complexity in space missions has led to an active research field of space logistics and mission design. This research field leverages the key ideas and methods used to handle complex terrestrial logistics to tackle space logistics design problems. A typical goal in space logistics is to optimize the commodity flow to satisfy some mission objectives with the lowest cost. One of the successful space logistics approaches is network flow modeling and optimization using mixed-integer linear programming (MILP). A caveat of the conventional MILP-based network approach for space logistics is its incapability of handling nonlinearity. For example, in the MILP formulation, the spacecraft structure mass and fuel/payload capacity are approximated by a linear relationship. However, this oversimplified relationship cannot characterize a realistic spacecraft design. Other types of nonlinearity can appear when a nonlinear time-dependent trajectory model is considered in an event-driven network, where the time step of each event itself is a variable. In response to this challenge, this Note develops a new systematic general framework to handle nonlinearity in the MILP-based space logistics formulation using machine learning (ML). Specifically, we replace the nonlinear constraints in the space logistics formulation with trained ML models that are compatible with MILP. The MILP-compatible ML model includes linear regression, PWL approximations, neural networks (NN) with Rectified Linear Unit (ReLU) activations, decision tree regression, and random forest regression, among others; these models can be translated into MILP formulations with a definition of additional variables and constraints while maintaining the linearity. This Note provides the first demonstration of using such trained ML models directly in a MILP-based space logistics optimization formulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18770v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Koki Ho, Yuri Shimane, Masafumi Isaji</dc:creator>
    </item>
    <item>
      <title>Higher Degree Inexact Model for Optimization problems</title>
      <link>https://arxiv.org/abs/2405.16140</link>
      <description>arXiv:2405.16140v3 Announce Type: replace 
Abstract: In this paper, it was proposed a new concept of the inexact higher degree $(\delta, L, q)$-model of a function that is a generalization of the inexact $(\delta, L)$-model, $(\delta, L)$-oracle and $(\delta, L)$-oracle of degree $q \in [0,2)$. Some examples were provided to illustrate the proposed new model. Adaptive inexact gradient and fast gradient methods for convex and strongly convex functions were constructed and analyzed using the new proposed inexact model. A universal fast gradient method that allows solving optimization problems with a weaker level of smoothness, among them non-smooth problems was proposed. For convex optimization problems it was proved that the proposed gradient and fast gradient methods could be converged with rates $O\left(\frac{1}{k} + \frac{\delta}{k^{q/2}}\right)$ and $O\left(\frac{1}{k^2} + \frac{\delta}{k^{(3q-2)/2}}\right)$, respectively. For the gradient method, the coefficient of $\delta$ diminishes with $k$, and for the fast gradient method, there is no error accumulation for $q \geq 2/3$. It proposed a definition of an inexact higher degree oracle for strongly convex functions and a projected gradient method using this inexact oracle. For variational inequalities and saddle point problems, a higher degree inexact model and an adaptive method called Generalized Mirror Prox to solve such class of problems using the proposed inexact model were proposed. Some numerical experiments were conducted to demonstrate the effectiveness of the proposed inexact model, we test the universal fast gradient method to solve some non-smooth problems with a geometrical nature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16140v3</guid>
      <category>math.OC</category>
      <pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad Alkousa, Fedor Stonyakin, Alexander Gasnikov, Asmaa Abdo, Mohammad Alcheikh</dc:creator>
    </item>
    <item>
      <title>Data-driven distributionally robust MPC for systems with multiplicative noise: A semi-infinite semi-definite programming approach</title>
      <link>https://arxiv.org/abs/2408.15193</link>
      <description>arXiv:2408.15193v3 Announce Type: replace 
Abstract: This article introduces a novel distributionally robust model predictive control (DRMPC) algorithm for a specific class of controlled dynamical systems where the disturbance multiplies the state and control variables. These classes of systems arise in mathematical finance, where the paradigm of distributionally robust optimization (DRO) fits perfectly, and this serves as the primary motivation for this work. We recast the optimal control problem (OCP) as a semi-definite program with an infinite number of constraints, making the ensuing optimization problem a \emph{semi-infinite semi-definite program} (SI-SDP). To numerically solve the SI-SDP, we advance an approach for solving convex semi-infinite programs (SIPs) to SI-SDPs and, subsequently, solve the DRMPC problem. A numerical example is provided to show the effectiveness of the algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.15193v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Souvik Das, Siddhartha Ganguly, Ashwin Aravind, Debasish Chatterjee</dc:creator>
    </item>
    <item>
      <title>Primal-dual Accelerated Mirror-Descent Method for Constrained Bilinear Saddle-Point Problems</title>
      <link>https://arxiv.org/abs/2409.18285</link>
      <description>arXiv:2409.18285v2 Announce Type: replace 
Abstract: We develop a first-order accelerated algorithm for a class of constrained bilinear saddle-point problems with applications to network systems. The algorithm is a modified time-varying primal-dual version of an accelerated mirror-descent dynamics. It deals with constraints such as simplices and convex set constraints effectively, and converges with a rate of $O(1/t^2)$. Furthermore, we employ the acceleration scheme to constrained distributed optimization and bilinear zero-sum games, and obtain two variants of distributed accelerated algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.18285v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weijian Li, Xianlin Zeng, Lacra Pavel</dc:creator>
    </item>
    <item>
      <title>DP-SCC-PL:Differentially Private Decentralized Byzantine-Resilient Stochastic Optimization via Self-Centered Clipping Under Polyak-{\L}ojasiewicz Condition</title>
      <link>https://arxiv.org/abs/2409.18632</link>
      <description>arXiv:2409.18632v2 Announce Type: replace 
Abstract: Privacy leakage and Byzantine agents are two critical issues that bring great challenges to the intelligent decision-making process of multi-agent systems (MASs). Considering the presence of these two issues, this paper targets the resolution of a class of nonconvex optimization problems under the Polyak-{\L}ojasiewicz (P-{\L}) condition. To address this problem, we mask the local gradients with Gaussian noises and adopt a resilient aggregation method self-centered clipping (SCC) to design a differentially private (DP) decentralized Byzantine-resilient algorithm, namely DP-SCC-PL, which simultaneously achieves differential privacy and Byzantine resilience. Theoretical analysis demonstrates that DP-SCC-PL achieves the consensus among all reliable agents with a decaying step-size and sublinear (inexact) convergence with a constant step-size, where the asymptotic convergence error is characterized in both cases. It has also been proved that if there are no privacy issues and Byzantine agents, then the asymptotic exact convergence can be recovered when adopting a well-designed decaying step-size. Numerical experiments verify the differential privacy, resilience, and effectiveness of DP-SCC-PL via tackling a nonconvex optimization problem satisfying the P-{\L} condition under various Byzantine attacks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.18632v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinhui Hu, Xiaoyu Guo, Huaqing Li, Huqiang Cheng, Guo Chen</dc:creator>
    </item>
    <item>
      <title>Regret-Optimal Federated Transfer Learning for Kernel Regression with Applications in American Option Pricing</title>
      <link>https://arxiv.org/abs/2309.04557</link>
      <description>arXiv:2309.04557v2 Announce Type: replace-cross 
Abstract: We propose an optimal iterative scheme for federated transfer learning, where a central planner has access to datasets ${\cal D}_1,\dots,{\cal D}_N$ for the same learning model $f_{\theta}$. Our objective is to minimize the cumulative deviation of the generated parameters $\{\theta_i(t)\}_{t=0}^T$ across all $T$ iterations from the specialized parameters $\theta^\star_{1},\ldots,\theta^\star_N$ obtained for each dataset, while respecting the loss function for the model $f_{\theta(T)}$ produced by the algorithm upon halting. We only allow for continual communication between each of the specialized models (nodes/agents) and the central planner (server), at each iteration (round). For the case where the model $f_{\theta}$ is a finite-rank kernel regression, we derive explicit updates for the regret-optimal algorithm. By leveraging symmetries within the regret-optimal algorithm, we further develop a nearly regret-optimal heuristic that runs with $\mathcal{O}(Np^2)$ fewer elementary operations, where $p$ is the dimension of the parameter space. Additionally, we investigate the adversarial robustness of the regret-optimal algorithm showing that an adversary which perturbs $q$ training pairs by at-most $\varepsilon&gt;0$, across all training sets, cannot reduce the regret-optimal algorithm's regret by more than $\mathcal{O}(\varepsilon q \bar{N}^{1/2})$, where $\bar{N}$ is the aggregate number of training pairs. To validate our theoretical findings, we conduct numerical experiments in the context of American option pricing, utilizing a randomly generated finite-rank kernel.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.04557v2</guid>
      <category>cs.LG</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <category>q-fin.CP</category>
      <pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xuwei Yang, Anastasis Kratsios, Florian Krach, Matheus Grasselli, Aurelien Lucchi</dc:creator>
    </item>
    <item>
      <title>Unichain and Aperiodicity are Sufficient for Asymptotic Optimality of Average-Reward Restless Bandits</title>
      <link>https://arxiv.org/abs/2402.05689</link>
      <description>arXiv:2402.05689v3 Announce Type: replace-cross 
Abstract: We consider the infinite-horizon, average-reward restless bandit problem in discrete time. We propose a new class of policies that are designed to drive a progressively larger subset of arms toward the optimal distribution. We show that our policies are asymptotically optimal with an $O(1/\sqrt{N})$ optimality gap for an $N$-armed problem, assuming only a unichain and aperiodicity assumption. Our approach departs from most existing work that focuses on index or priority policies, which rely on the Global Attractor Property (GAP) to guarantee convergence to the optimum, or a recently developed simulation-based policy, which requires a Synchronization Assumption (SA).</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.05689v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yige Hong, Qiaomin Xie, Yudong Chen, Weina Wang</dc:creator>
    </item>
    <item>
      <title>Theoretical Approximation Ratios for Warm-Started QAOA on 3-Regular Max-Cut Instances at Depth $p=1$</title>
      <link>https://arxiv.org/abs/2402.12631</link>
      <description>arXiv:2402.12631v2 Announce Type: replace-cross 
Abstract: We generalize Farhi et al.'s 0.6924-approximation result technique of the Max-Cut Quantum Approximate Optimization Algorithm (QAOA) on 3-regular graphs to obtain provable lower bounds on the approximation ratio for warm-started QAOA. Given an initialization angle $\theta$, we consider warm-starts where the initial state is a product state where each qubit position is angle $\theta$ away from either the north or south pole of the Bloch sphere; of the two possible qubit positions the position of each qubit is decided by some classically obtained cut encoded as a bitstring $b$.
  We illustrate through plots how the properties of $b$ and the initialization angle $\theta$ influence the bound on the approximation ratios of warm-started QAOA. We consider various classical algorithms (and the cuts they produce which we use to generate the warm-start). Our results strongly suggest that there does not exist any choice of initialization angle that yields a (worst-case) approximation ratio that simultaneously beats standard QAOA and the classical algorithm used to create the warm-start.
  Additionally, we show that at $\theta=60^\circ$, warm-started QAOA is able to (effectively) recover the cut used to generate the warm-start, thus suggesting that in practice, this value could be a promising starting angle to explore alternate solutions in a heuristic fashion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.12631v2</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>cs.ET</category>
      <category>math.CO</category>
      <category>math.OC</category>
      <pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Reuben Tate, Stephan Eidenbenz</dc:creator>
    </item>
    <item>
      <title>MGDA Converges under Generalized Smoothness, Provably</title>
      <link>https://arxiv.org/abs/2405.19440</link>
      <description>arXiv:2405.19440v4 Announce Type: replace-cross 
Abstract: Multi-objective optimization (MOO) is receiving more attention in various fields such as multi-task learning. Recent works provide some effective algorithms with theoretical analysis but they are limited by the standard $L$-smooth or bounded-gradient assumptions, which typically do not hold for neural networks, such as Long short-term memory (LSTM) models and Transformers. In this paper, we study a more general and realistic class of generalized $\ell$-smooth loss functions, where $\ell$ is a general non-decreasing function of gradient norm. We revisit and analyze the fundamental multiple gradient descent algorithm (MGDA) and its stochastic version with double sampling for solving the generalized $\ell$-smooth MOO problems, which approximate the conflict-avoidant (CA) direction that maximizes the minimum improvement among objectives. We provide a comprehensive convergence analysis of these algorithms and show that they converge to an $\epsilon$-accurate Pareto stationary point with a guaranteed $\epsilon$-level average CA distance (i.e., the gap between the updating direction and the CA direction) over all iterations, where totally $\mathcal{O}(\epsilon^{-2})$ and $\mathcal{O}(\epsilon^{-4})$ samples are needed for deterministic and stochastic settings, respectively. We prove that they can also guarantee a tighter $\epsilon$-level CA distance in each iteration using more samples. Moreover, we analyze an efficient variant of MGDA named MGDA-FA using only $\mathcal{O}(1)$ time and space, while achieving the same performance guarantee as MGDA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19440v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qi Zhang, Peiyao Xiao, Shaofeng Zou, Kaiyi Ji</dc:creator>
    </item>
    <item>
      <title>Securing Equal Share: A Principled Approach for Learning Multiplayer Symmetric Games</title>
      <link>https://arxiv.org/abs/2406.04201</link>
      <description>arXiv:2406.04201v2 Announce Type: replace-cross 
Abstract: This paper examines multiplayer symmetric constant-sum games with more than two players in a competitive setting, including examples like Mahjong, Poker, and various board and video games. In contrast to two-player zero-sum games, equilibria in multiplayer games are neither unique nor non-exploitable, failing to provide meaningful guarantees when competing against opponents who play different equilibria or non-equilibrium strategies. This gives rise to a series of long-lasting fundamental questions in multiplayer games regarding suitable objectives, solution concepts, and principled algorithms. This paper takes an initial step towards addressing these challenges by focusing on the natural objective of equal share -- securing an expected payoff of C/n in an n-player symmetric game with a total payoff of C. We rigorously identify the theoretical conditions under which achieving an equal share is tractable and design a series of efficient algorithms, inspired by no-regret learning, that provably attain approximate equal share across various settings. Furthermore, we provide complementary lower bounds that justify the sharpness of our theoretical results. Our experimental results highlight worst-case scenarios where meta-algorithms from prior state-of-the-art systems for multiplayer games fail to secure an equal share, while our algorithm succeeds, demonstrating the effectiveness of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04201v2</guid>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiawei Ge, Yuanhao Wang, Wenzhe Li, Chi Jin</dc:creator>
    </item>
  </channel>
</rss>
