<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.ST updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.ST</link>
    <description>math.ST updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.ST" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 19 Mar 2025 05:43:52 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Stratified Permutational Berry--Esseen Bounds and Their Applications to Statistics</title>
      <link>https://arxiv.org/abs/2503.13986</link>
      <description>arXiv:2503.13986v1 Announce Type: new 
Abstract: The stratified linear permutation statistic arises in various statistics problems, including stratified and post-stratified survey sampling, stratified and post-stratified experiments, conditional permutation tests, etc. Although we can derive the Berry--Esseen bounds for the stratified linear permutation statistic based on existing bounds for the non-stratified statistics, those bounds are not sharp, and moreover, this strategy does not work in general settings with heterogeneous strata with varying sizes. We first use Stein's method to obtain a unified stratified permutational Berry--Esseen bound that can accommodate heterogeneous strata. We then apply the bound to various statistics problems, leading to stronger theoretical quantifications and thereby facilitating statistical inference in those problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13986v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pengfei Tian, Fan Yang, Peng Ding</dc:creator>
    </item>
    <item>
      <title>The covariance of causal effect estimators for binary v-structures</title>
      <link>https://arxiv.org/abs/2503.14242</link>
      <description>arXiv:2503.14242v1 Announce Type: new 
Abstract: Previously [Journal of Causal Inference, 10, 90-105 (2022)], we computed the variance of two estimators of causal effects for a v-structure of binary variables. Here we show that a linear combination of these estimators has lower variance than either. Furthermore, we show that this holds also when the treatment variable is block randomised with a predefined number receiving treatment, with analogous results to when it is sampled randomly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14242v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jack Kuipers, Giusi Moffa</dc:creator>
    </item>
    <item>
      <title>Asymptotic properties of the MLE in distributional regression under random censoring</title>
      <link>https://arxiv.org/abs/2503.14311</link>
      <description>arXiv:2503.14311v1 Announce Type: new 
Abstract: The aim of distributional regression is to find the best candidate in a given parametric family of conditional distributions to model a given dataset. As each candidate in the distribution family can be identified by the corresponding distribution parameters, a common approach for this task is using the maximum likelihood estimator (MLE) for the parameters. In this paper, we establish theoretical results for this estimator in case the response variable is subject to random right censoring. In particular, we provide proofs of almost sure consistency and asymptotic normality of the MLE under censoring. Further, the finite-sample behavior is exemplarily demonstrated in a simulation study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14311v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gitte Kremling, Gerhard Dikta</dc:creator>
    </item>
    <item>
      <title>Confidence Intervals Using Turing's Estimator: Simulations and Applications</title>
      <link>https://arxiv.org/abs/2503.14313</link>
      <description>arXiv:2503.14313v1 Announce Type: new 
Abstract: Turing's estimator allows one to estimate the probabilities of outcomes that either do not appear or only rarely appear in a given random sample. We perform a simulation study to understand the finite sample performance of several related confidence intervals (CIs) and introduce an approach for selecting the appropriate CI for a given sample. We give an application to the problem of authorship attribution and apply it to a dataset comprised of tweets from users on X (Twitter). Further, we derive several theoretical results about asymptotic normality and asymptotic Poissonity of Turing's estimator for two important discrete distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14313v1</guid>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jie Chang, Michael Grabchak, Jialin Zhang</dc:creator>
    </item>
    <item>
      <title>Robust tests for log-logistic models based on minimum density power divergence estimators</title>
      <link>https://arxiv.org/abs/2503.14447</link>
      <description>arXiv:2503.14447v1 Announce Type: new 
Abstract: The log-logistic distribution is a versatile parametric family widely used across various applied fields, including survival analysis, reliability engineering, and econometrics. When estimating parameters of the log-logistic distribution, hypothesis testing is necessary to verify assumptions about these parameters. The Wald test and Rao test provide formal methods for testing hypotheses about these parameters. However, these test statistics are not robust, and their rejection decisions may be affected by data contamination. In this paper we develop new families of Wald-type test statistics and Rao-type test statistics based on minimum density power divergence estimators (MDPDEs) for the parameters of the log-logistic distribution. These new families generalize the Wald and Rao test statistics, inheriting the robustness properties from the MDPDEs and thus addressing the lack of robustness of the classical tests. Explicit expressions for the test statistics under the log-logistic model for both simple and composite null hypotheses are derived, and their properties are analyzed in detail. An extensive simulation study empirically demonstrates the robustness of these families and compares their performance with the classical methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14447v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>A. Felipe, M. Jaenada, P. Miranda, L. Pardo</dc:creator>
    </item>
    <item>
      <title>Minimizers of U-processes and their domains of attraction</title>
      <link>https://arxiv.org/abs/2503.14467</link>
      <description>arXiv:2503.14467v1 Announce Type: new 
Abstract: In this paper, we study the minimizers of U-processes and their domains of attraction. U-processes arise in various statistical contexts, particularly in M-estimation, where estimators are defined as minimizers of certain objective functions. Our main results establish necessary and sufficient conditions for the distributional convergence of these minimizers, identifying a broad class of normalizing sequences that go beyond the standard square-root asymptotics with normal limits. We show that the limit distribution belongs to exactly one of the four classes introduced by Smirnov. These results do not only extend Smirnov's theory but also generalize existing asymptotic theories for M-estimators, including classical results by Huber and extensions to higher-degree U-statistics. Furthermore, we analyze the domain of attraction for each class, providing alternative characterizations that determine which types of statistical estimators fall into a given asymptotic regime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14467v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dietmar Ferger</dc:creator>
    </item>
    <item>
      <title>Semidefinite programming relaxations and debiasing for MAXCUT-based clustering</title>
      <link>https://arxiv.org/abs/2401.10927</link>
      <description>arXiv:2401.10927v2 Announce Type: cross 
Abstract: In this paper, we consider the problem of partitioning a small data sample of size $n$ drawn from a mixture of 2 sub-gaussian distributions in $\R^p$. We consider semidefinite programming relaxations of an integer quadratic program that is formulated as finding the maximum cut on a graph, where edge weights in the cut represent dissimilarity scores between two nodes based on their $p$ features.  We are interested in the case that individual features are of low average quality $\gamma$, and we want to use as few of them as possible to correctly partition the sample.  Denote by $\Delta^2:=p \gamma$ the $\ell_2^2$ distance between two centers (mean vectors) in $\R^p$. The goal is to allow a full range of tradeoffs between $n, p, \gamma$ in the sense that partial recovery (success  rate $&lt; 100%$) is feasible once the signal to noise ratio $s^2 := \min{np \gamma^2, \Delta^2}$ is lower bounded by a constant.  For both balanced  and unbalanced cases, we allow each population to have distinct covariance structures  with diagonal matrices as special cases.  In the present work, (a) we provide a unified framework for analyzing three computationally efficient algorithms, namely, SDP1, BalancedSDP, and Spectral clustering; and (b) we prove that the misclassification error decays exponentially  with respect to the SNR $s^2$ for SDP1. Moreover, for balanced partitions, we design an estimator $\bf {BalancedSDP}$ with a superb debiasing property. Indeed, with this new estimator, we remove an assumption (A2) on bounding the trace difference between the two population covariance matrices while proving the exponential error bound as stated above.  These estimators and their statistical analyses are novel to the best of our knowledge. We provide simulation evidence illuminating the theoretical predictions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.10927v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shuheng Zhou</dc:creator>
    </item>
    <item>
      <title>Spectrally-Corrected and Regularized QDA Classifier for Spiked Covariance Model</title>
      <link>https://arxiv.org/abs/2503.13582</link>
      <description>arXiv:2503.13582v1 Announce Type: cross 
Abstract: Quadratic discriminant analysis (QDA) is a widely used method for classification problems, particularly preferable over Linear Discriminant Analysis (LDA) for heterogeneous data. However, QDA loses its effectiveness in high-dimensional settings, where the data dimension and sample size tend to infinity. To address this issue, we propose a novel QDA method utilizing spectral correction and regularization techniques, termed SR-QDA. The regularization parameters in our method are selected by maximizing the Fisher-discriminant ratio. We compare SR-QDA with QDA, regularized quadratic discriminant analysis (R-QDA), and several other competitors. The results indicate that SR-QDA performs exceptionally well, especially in moderate and high-dimensional situations. Empirical experiments across diverse datasets further support this conclusion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13582v1</guid>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenya Luo, Hua Li, Zhidong Bai, Zhijun Liu</dc:creator>
    </item>
    <item>
      <title>A New Proof of Sub-Gaussian Norm Concentration Inequality</title>
      <link>https://arxiv.org/abs/2503.14347</link>
      <description>arXiv:2503.14347v1 Announce Type: cross 
Abstract: We present a new proof of the sub-Gaussian norm concentration inequality. Our proof is based on an averaged version of the moment generating function termed the averaged moment generating function. Compared with the widely adopted $\varepsilon$-net technique-based proof of the sub-Gaussian norm concentration inequality, our method does not rely on the union bound and promises a tighter concentration bound.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14347v1</guid>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zishun Liu, Yongxin Chen</dc:creator>
    </item>
    <item>
      <title>Optimizing High-Dimensional Oblique Splits</title>
      <link>https://arxiv.org/abs/2503.14381</link>
      <description>arXiv:2503.14381v1 Announce Type: cross 
Abstract: Orthogonal-split trees perform well, but evidence suggests oblique splits can enhance their performance. This paper explores optimizing high-dimensional $s$-sparse oblique splits from $\{(\vec{w}, \vec{w}^{\top}\boldsymbol{X}_{i}) : i\in \{1,\dots, n\}, \vec{w} \in \mathbb{R}^p, \| \vec{w} \|_{2} = 1, \| \vec{w} \|_{0} \leq s \}$ for growing oblique trees, where $ s $ is a user-defined sparsity parameter. We establish a connection between SID convergence and $s_0$-sparse oblique splits with $s_0\ge 1$, showing that the SID function class expands as $s_0$ increases, enabling the capture of more complex data-generating functions such as the $s_0$-dimensional XOR function. Thus, $s_0$ represents the unknown potential complexity of the underlying data-generating function. Learning these complex functions requires an $s$-sparse oblique tree with $s \geq s_0$ and greater computational resources. This highlights a trade-off between statistical accuracy, governed by the SID function class size depending on $s_0$, and computational cost. In contrast, previous studies have explored the problem of SID convergence using orthogonal splits with $ s_0 = s = 1 $, where runtime was less critical. Additionally, we introduce a practical framework for oblique trees that integrates optimized oblique splits alongside orthogonal splits into random forests. The proposed approach is assessed through simulations and real-data experiments, comparing its performance against various oblique tree models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14381v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chien-Ming Chi</dc:creator>
    </item>
    <item>
      <title>Likelihood ratio tests in random graph models with increasing dimensions</title>
      <link>https://arxiv.org/abs/2311.05806</link>
      <description>arXiv:2311.05806v2 Announce Type: replace 
Abstract: We explore the Wilks phenomena in two random graph models: the $\beta$-model and the Bradley-Terry model. For two increasing dimensional null hypotheses, including a specified null $H_0: \beta_i=\beta_i^0$ for $i=1,\ldots, r$ and a homogenous null $H_0: \beta_1=\cdots=\beta_r$, we reveal high dimensional Wilks' phenomena that the normalized log-likelihood ratio statistic, $[2\{\ell(\widehat{\mathbf{\beta}}) - \ell(\widehat{\mathbf{\beta}}^0)\} - r]/(2r)^{1/2}$, converges in distribution to the standard normal distribution as $r$ goes to infinity. Here, $\ell( \mathbf{\beta})$ is the log-likelihood function on the model parameter $\mathbf{\beta}=(\beta_1, \ldots, \beta_n)^\top$, $\widehat{\mathbf{\beta}}$ is its maximum likelihood estimator (MLE) under the full parameter space, and $\widehat{\mathbf{\beta}}^0$ is the restricted MLE under the null parameter space. For the homogenous null with a fixed $r$, we establish Wilks-type theorems that $2\{\ell(\widehat{\mathbf{\beta}}) - \ell(\widehat{\mathbf{\beta}}^0)\}$ converges in distribution to a chi-square distribution with $r-1$ degrees of freedom, as the total number of parameters, $n$, goes to infinity. When testing the fixed dimensional specified null, we find that its asymptotic null distribution is a chi-square distribution in the $\beta$-model. However, unexpectedly, this is not true in the Bradley-Terry model. By developing several novel technical methods for asymptotic expansion, we explore Wilks type results in a principled manner; these principled methods should be applicable to a class of random graph models beyond the $\beta$-model and the Bradley-Terry model. Simulation studies and real network data applications further demonstrate the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.05806v2</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ting Yan, Yuanzhang Li, Jinfeng Xu, Yaning Yang, Ji Zhu</dc:creator>
    </item>
    <item>
      <title>Convergence rates of non-stationary and deep Gaussian process regression</title>
      <link>https://arxiv.org/abs/2312.07320</link>
      <description>arXiv:2312.07320v4 Announce Type: replace 
Abstract: The focus of this work is the convergence of non-stationary and deep Gaussian process regression. More precisely, we follow a Bayesian approach to regression or interpolation, where the prior placed on the unknown function $f$ is a non-stationary or deep Gaussian process, and we derive convergence rates of the posterior mean to the true function $f$ in terms of the number of observed training points. In some cases, we also show convergence of the posterior variance to zero. The only assumption imposed on the function $f$ is that it is an element of a certain reproducing kernel Hilbert space, which we in particular cases show to be norm-equivalent to a Sobolev space. Our analysis includes the case of estimated hyper-parameters in the covariance kernels employed, both in an empirical Bayes' setting and the particular hierarchical setting constructed through deep Gaussian processes. We consider the settings of noise-free or noisy observations on deterministic or random training points. We establish general assumptions sufficient for the convergence of deep Gaussian process regression, along with explicit examples demonstrating the fulfilment of these assumptions. Specifically, our examples require that the H\"older or Sobolev norms of the penultimate layer are bounded almost surely.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.07320v4</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Conor Osborne, Aretha L. Teckentrup</dc:creator>
    </item>
    <item>
      <title>A flexible control function approach for survival data subject to different types of censoring</title>
      <link>https://arxiv.org/abs/2403.11860</link>
      <description>arXiv:2403.11860v2 Announce Type: replace 
Abstract: This paper addresses the problem of identifying and estimating the causal effect of a treatment in the presence of unmeasured confounding and various types of right-censoring. Examples of these censoring mechanisms are administrative censoring, competing risks and dependent censoring (e.g. loss to follow-up). Different parametric transformations are applied to each event time, resulting in a regression model with a more additive structure and error terms that are approximately normal and homoscedastic. The transformed event times are modeled using a joint regression framework, assuming multivariate Gaussian error terms with an unspecified covariance matrix. A control function approach is used to deal with unmeasured confounding. The model is shown to be identifiable and a two-step estimation procedure is proposed. This estimator is proven to yield consistent and asymptotically normal estimates. Furthermore, a goodness-of-fit test for the model's validity is developed. Simulations are conducted to examine the finite-sample performance of the proposed estimator under various scenarios. Finally, the methodology is applied to investigate the causal effect of job training programs on unemployment duration using data from the National Job Training Partnership Act (JTPA) study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11860v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ilias Willems, Sara Rutten, Gilles Crommen, Ingrid Van Keilegom</dc:creator>
    </item>
    <item>
      <title>Early Stopping for Ensemble Kalman-Bucy Inversion</title>
      <link>https://arxiv.org/abs/2403.18353</link>
      <description>arXiv:2403.18353v3 Announce Type: replace 
Abstract: Bayesian linear inverse problems aim to recover an unknown signal from noisy observations, incorporating prior knowledge. This paper analyses a data dependent method to choose the scale parameter of a Gaussian prior. The method we study arises from early stopping methods, which have been successfully applied to a range of problems, such as statistical inverse problems, in the frequentist setting. These results are extended to the Bayesian setting. We study the use of a discrepancy-based stopping rule in the setting of random noise, which allows for adaptation. Our proposed stopping rule results in optimal rates under certain conditions on the prior covariance operator. We furthermore derive for which class of signals this method is adaptive. It is also shown that the associated posterior contracts at the optimal rate and provides a conservative measure of uncertainty. We implement the proposed stopping rule using the continuous-time ensemble Kalman--Bucy filter (EnKBF). The fictitious time parameter replaces the scale parameter, and the ensemble size is appropriately adjusted in order to not lose the statistical optimality of the computed estimator. With this Monte Carlo algorithm, we extend our results numerically to a non-linear problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18353v3</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maia Tienstra, Sebastian Reich</dc:creator>
    </item>
    <item>
      <title>Asymptotic mutual information in quadratic estimation problems over compact groups</title>
      <link>https://arxiv.org/abs/2404.10169</link>
      <description>arXiv:2404.10169v2 Announce Type: replace 
Abstract: Motivated by applications to group synchronization and quadratic assignment on random data, we study a general problem of Bayesian inference of an unknown ``signal'' belonging to a high-dimensional compact group, given noisy pairwise observations of a featurization of this signal. We establish a quantitative comparison between the signal-observation mutual information in any such problem with that in a simpler model with linear observations, using interpolation methods. For group synchronization, our result proves a replica formula for the asymptotic mutual information and Bayes-optimal mean-squared-error. Via analyses of this replica formula, we show that the conjectural phase transition threshold for computationally-efficient weak recovery of the signal is determined by a classification of the real-irreducible components of the observed group representation(s), and we fully characterize the information-theoretic limits of estimation in the example of angular/phase synchronization over $SO(2)$/$U(1)$. For quadratic assignment, we study observations given by a kernel matrix of pairwise similarities and a randomly permutated and noisy counterpart, and we show in a bounded signal-to-noise regime that the asymptotic mutual information coincides with that in a Bayesian spiked model with i.i.d. signal prior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10169v2</guid>
      <category>math.ST</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.TH</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kaylee Y. Yang, Timothy L. H. Wee, Zhou Fan</dc:creator>
    </item>
    <item>
      <title>A Non-parametric Approach to Inference about the Tail of a Continuous or a Discrete Distribution</title>
      <link>https://arxiv.org/abs/2204.12350</link>
      <description>arXiv:2204.12350v2 Announce Type: replace-cross 
Abstract: This article introduces a non-parametric information-theoretic approach to inference about the tail of a continuous or a discrete distribution. Leveraging a new concept named tail profile -- a set of information-theoretic quantities developed from results of domains of attraction on countable alphabets -- theoretical evidence supports the identification of specific discrete distributional tail types through a sequence of plots. The approach discerns tail types by bench-marking against exponential, and three thicker-than-exponential families: near-exponential, sub-exponential, and power-law (zipf, Pareto). For tails thicker-than-exponential, the approach also provides point and interval estimates for some of the underlying distribution parameters. While primarily designed to streamline the selection of discrete parametric models for detailed statistical analysis, a supporting theorem enables the method's extension use to continuous data, stating that binning continuous data with a common width preserves the tail decay rate under certain conditions. Simulations are presented to demonstrate the method's performance across various scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2204.12350v2</guid>
      <category>stat.AP</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jialin Zhang, Zhiyi Zhang</dc:creator>
    </item>
    <item>
      <title>Max-Rank: Efficient Multiple Testing for Conformal Prediction</title>
      <link>https://arxiv.org/abs/2311.10900</link>
      <description>arXiv:2311.10900v4 Announce Type: replace-cross 
Abstract: Multiple hypothesis testing (MHT) frequently arises in scientific inquiries, and concurrent testing of multiple hypotheses inflates the risk of Type-I errors or false positives, rendering MHT corrections essential. This paper addresses MHT in the context of conformal prediction, a flexible framework for predictive uncertainty quantification. Some conformal applications give rise to simultaneous testing, and positive dependencies among tests typically exist. We introduce $\texttt{max-rank}$, a novel correction that exploits these dependencies whilst efficiently controlling the family-wise error rate. Inspired by existing permutation-based corrections, $\texttt{max-rank}$ leverages rank order information to improve performance and integrates readily with any conformal procedure. We establish its theoretical and empirical advantages over the common Bonferroni correction and its compatibility with conformal prediction, highlighting the potential to strengthen predictive uncertainty estimates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.10900v4</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Timans, Christoph-Nikolas Straehle, Kaspar Sakmann, Christian A. Naesseth, Eric Nalisnick</dc:creator>
    </item>
    <item>
      <title>Distributed Tensor Principal Component Analysis with Data Heterogeneity</title>
      <link>https://arxiv.org/abs/2405.11681</link>
      <description>arXiv:2405.11681v2 Announce Type: replace-cross 
Abstract: As tensors become widespread in modern data analysis, Tucker low-rank Principal Component Analysis (PCA) has become essential for dimensionality reduction and structural discovery in tensor datasets. Motivated by the common scenario where large-scale tensors are distributed across diverse geographic locations, this paper investigates tensor PCA within a distributed framework where direct data pooling is impractical.
  We offer a comprehensive analysis of three specific scenarios in distributed Tensor PCA: a homogeneous setting in which tensors at various locations are generated from a single noise-affected model; a heterogeneous setting where tensors at different locations come from distinct models but share some principal components, aiming to improve estimation across all locations; and a targeted heterogeneous setting, designed to boost estimation accuracy at a specific location with limited samples by utilizing transferred knowledge from other sites with ample data.
  We introduce novel estimation methods tailored to each scenario, establish statistical guarantees, and develop distributed inference techniques to construct confidence regions. Our theoretical findings demonstrate that these distributed methods achieve sharp rates of accuracy by efficiently aggregating shared information across different tensors, while maintaining reasonable communication costs. Empirical validation through simulations and real-world data applications highlights the advantages of our approaches, particularly in managing heterogeneous tensor data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11681v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Elynn Chen, Xi Chen, Wenbo Jing, Yichen Zhang</dc:creator>
    </item>
    <item>
      <title>Nystr\"om Kernel Stein Discrepancy</title>
      <link>https://arxiv.org/abs/2406.08401</link>
      <description>arXiv:2406.08401v4 Announce Type: replace-cross 
Abstract: Kernel methods underpin many of the most successful approaches in data science and statistics, and they allow representing probability measures as elements of a reproducing kernel Hilbert space without loss of information. Recently, the kernel Stein discrepancy (KSD), which combines Stein's method with the flexibility of kernel techniques, gained considerable attention. Through the Stein operator, KSD allows the construction of powerful goodness-of-fit tests where it is sufficient to know the target distribution up to a multiplicative constant. However, the typical U- and V-statistic-based KSD estimators suffer from a quadratic runtime complexity, which hinders their application in large-scale settings. In this work, we propose a Nystr\"om-based KSD acceleration -- with runtime $\mathcal O\left(mn+m^3\right)$ for $n$ samples and $m\ll n$ Nystr\"om points -- , show its $\sqrt{n}$-consistency with a classical sub-Gaussian assumption, and demonstrate its applicability for goodness-of-fit testing on a suite of benchmarks. We also show the $\sqrt n$-consistency of the quadratic-time KSD estimator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.08401v4</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Florian Kalinke, Zoltan Szabo, Bharath K. Sriperumbudur</dc:creator>
    </item>
    <item>
      <title>Counterfactual Generative Modeling with Variational Causal Inference</title>
      <link>https://arxiv.org/abs/2410.12730</link>
      <description>arXiv:2410.12730v3 Announce Type: replace-cross 
Abstract: Estimating an individual's counterfactual outcomes under interventions is a challenging task for traditional causal inference and supervised learning approaches when the outcome is high-dimensional (e.g. gene expressions, facial images) and covariates are relatively limited. In this case, to predict one's outcomes under counterfactual treatments, it is crucial to leverage individual information contained in the observed outcome in addition to the covariates. Prior works using variational inference in counterfactual generative modeling have been focusing on neural adaptations and model variants within the conditional variational autoencoder formulation, which we argue is fundamentally ill-suited to the notion of counterfactual in causal inference. In this work, we present a novel variational Bayesian causal inference framework and its theoretical backings to properly handle counterfactual generative modeling tasks, through which we are able to conduct counterfactual supervision end-to-end during training without any counterfactual samples, and encourage disentangled exogenous noise abduction that aids the correct identification of causal effect in counterfactual generations. In experiments, we demonstrate the advantage of our framework compared to state-of-the-art models in counterfactual generative modeling on multiple benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12730v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yulun Wu, Louie McConnell, Claudia Iriondo</dc:creator>
    </item>
    <item>
      <title>Influence functions and regularity tangents for efficient active learning</title>
      <link>https://arxiv.org/abs/2411.15292</link>
      <description>arXiv:2411.15292v2 Announce Type: replace-cross 
Abstract: In this paper we describe an efficient method for providing a regression model with a sense of curiosity about its data. In the field of machine learning, our framework for representing curiosity is called Active Learning, which concerns the problem of automatically choosing data points for which to query labels in the semi-supervised setting. The methods we propose are based on computing a "regularity tangent" vector that can be calculated (with only a constant slow-down) together with the model's parameter vector during training. We then take the inner product of this tangent vector with the gradient vector of the model's loss at a given data point to obtain a measure of the influence of that point on the complexity of the model. In the simplest instantiation, there is only a single regularity tangent vector, of the same dimension as the parameter vector. Thus, in the proposed technique, once training is complete, evaluating our "curiosity" about a potential query data point can be done as quickly as calculating the model's loss gradient at that point. The new vector only doubles the amount of storage required by the model. We show that the quantity computed by our technique is an example of an "influence function", and that it measures the expected squared change in model complexity incurred by up-weighting a given data point. We propose a number of ways for using this and other related quantities to choose new training data points for a regression model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15292v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Frederik Eaton</dc:creator>
    </item>
    <item>
      <title>Debiased Nonparametric Regression for Statistical Inference and Distributionally Robustness</title>
      <link>https://arxiv.org/abs/2412.20173</link>
      <description>arXiv:2412.20173v3 Announce Type: replace-cross 
Abstract: This study proposes a debiasing method for smooth nonparametric estimators. While machine learning techniques such as random forests and neural networks have demonstrated strong predictive performance, their theoretical properties remain relatively underexplored. In particular, many modern algorithms lack guarantees of pointwise and uniform risk convergence, as well as asymptotic normality. These properties are essential for statistical inference and robust estimation and have been well-established for classical methods such as Nadaraya-Watson regression. To ensure these properties for various nonparametric regression estimators, we introduce a model-free debiasing method. By incorporating a correction term that estimates the conditional expected residual of the original estimator, or equivalently, its estimation error, into the initial nonparametric regression estimator, we obtain a debiased estimator that satisfies pointwise and uniform risk convergence, along with asymptotic normality, under mild smoothness conditions. These properties facilitate statistical inference and enhance robustness to covariate shift, making the method broadly applicable to a wide range of nonparametric regression problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20173v3</guid>
      <category>stat.ME</category>
      <category>cs.LG</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Masahiro Kato</dc:creator>
    </item>
    <item>
      <title>Learning an Optimal Assortment Policy under Observational Data</title>
      <link>https://arxiv.org/abs/2502.06777</link>
      <description>arXiv:2502.06777v2 Announce Type: replace-cross 
Abstract: We study the fundamental problem of offline assortment optimization under the Multinomial Logit (MNL) model, where sellers must determine the optimal subset of the products to offer based solely on historical customer choice data. While most existing approaches to learning-based assortment optimization focus on the online learning of the optimal assortment through repeated interactions with customers, such exploration can be costly or even impractical in many real-world settings. In this paper, we consider the offline learning paradigm and investigate the minimal data requirements for efficient offline assortment optimization. To this end, we introduce Pessimistic Rank-Breaking (PRB), an algorithm that combines rank-breaking with pessimistic estimation. We prove that PRB is nearly minimax optimal by establishing the tight suboptimality upper bound and a nearly matching lower bound. This further shows that "optimal item coverage" - where each item in the optimal assortment appears sufficiently often in the historical data - is both sufficient and necessary for efficient offline learning. This significantly relaxes the previous requirement of observing the complete optimal assortment in the data. Our results provide fundamental insights into the data requirements for offline assortment optimization under the MNL model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06777v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuxuan Han, Han Zhong, Miao Lu, Jose Blanchet, Zhengyuan Zhou</dc:creator>
    </item>
    <item>
      <title>Estimating stationary mass, frequency by frequency</title>
      <link>https://arxiv.org/abs/2503.12808</link>
      <description>arXiv:2503.12808v2 Announce Type: replace-cross 
Abstract: Suppose we observe a trajectory of length $n$ from an $\alpha$-mixing stochastic process over a finite but potentially large state space. We consider the problem of estimating the probability mass placed by the stationary distribution of any such process on elements that occur with a certain frequency in the observed sequence. We estimate this vector of probabilities in total variation distance, showing universal consistency in $n$ and recovering known results for i.i.d. sequences as special cases. Our proposed methodology carefully combines the plug-in (or empirical) estimator with a recently-proposed modification of the Good--Turing estimator called WingIt, which was originally developed for Markovian sequences. En route to controlling the error of our estimator, we develop new performance bounds on WingIt and the plug-in estimator for $\alpha$-mixing stochastic processes. Importantly, the extensively used method of Poissonization can no longer be applied in our non i.i.d. setting, and so we develop complementary tools -- including concentration inequalities for a natural self-normalized statistic of mixing sequences -- that may prove independently useful in the design and analysis of estimators for related problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.12808v2</guid>
      <category>stat.ML</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Milind Nakul, Vidya Muthukumar, Ashwin Pananjady</dc:creator>
    </item>
  </channel>
</rss>
