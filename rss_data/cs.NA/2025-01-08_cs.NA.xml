<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NA</link>
    <description>cs.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 09 Jan 2025 02:32:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Tensor-structured PCG for finite difference solver of domain patterns in ferroelectric material</title>
      <link>https://arxiv.org/abs/2501.03377</link>
      <description>arXiv:2501.03377v1 Announce Type: new 
Abstract: This paper presents a case study of application of the preconditioned method of conjugate gradients (CG) on a problem with operator resembling the structure of sum of Kronecker products. In particular, we are solving the Poisson's equation on a sample of homogeneous isotropic ferroelectric material of cuboid shape, where the Laplacian is discretized by finite difference. We present several preconditioners that fits the Kronecker structure and thus can be efficiently implemented and applied. Preconditioner based on the Moore--Penrose pseudoinverse is extremely efficient for this particular problem, and also applicable (if we are able to store the dense right-hand side of our problem). We briefly analyze the computational cost of the method and individual preconditioners, and illustrate effectiveness of the chosen one by numerical experiments.
  Although we describe our method as preconditioned CG with pseudoinverse-based preconditioner, it can also be seen as pseudoinverse-based direct solver with iterative refinement by CG iteration.
  This work is motivated by real application, the method was already implemented in C/C++ code Ferrodo2 and first results were published in Physical Review B 107(9) (2023), paper id 094102.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03377v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>V\v{e}nceslav Chumchal, Pavel Marton, Martin Ple\v{s}inger, Martina \v{S}im\r{u}nkov\'a</dc:creator>
    </item>
    <item>
      <title>Convergence of a particle method for gradient flows on the $L^p$-Wasserstein space</title>
      <link>https://arxiv.org/abs/2501.03459</link>
      <description>arXiv:2501.03459v1 Announce Type: new 
Abstract: We study the particle method to approximate the gradient flow on the $L^p$-Wasserstein space. This method relies on the discretization of the energy introduced by [3] via nonoverlapping balls centered at the particles and preserves the gradient flow structure at the particle level. We prove the convergence of the discrete gradient flow to the continuum gradient flow on the $L^p$-Wasserstein space over $\mathbb R$, specifically to the doubly nonlinear diffusion equation in one dimension.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03459v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rong Lei</dc:creator>
    </item>
    <item>
      <title>Adaptive Residual-Driven Newton Solver for Nonlinear Systems of Equations</title>
      <link>https://arxiv.org/abs/2501.03487</link>
      <description>arXiv:2501.03487v1 Announce Type: new 
Abstract: Newton-type solvers have been extensively employed for solving a variety of nonlinear system of algebraic equations. However, for some complex nonlinear system of algebraic equations, efficiently solving these systems remains a challenging task. The primary reason for this challenge arises from the unbalanced nonlinearities within the nonlinear system. Therefore, accurately identifying and balancing the unbalanced nonlinearities in the system is essential. In this work, we propose a residual-driven adaptive strategy to identify and balance the nonlinearities in the system. The fundamental idea behind this strategy is to assign an adaptive weight multiplier to each component of the nonlinear system, with these weight multipliers increasing according to a specific update rule as the residual components increase, thereby enabling the Newton-type solver to select a more appropriate step length, ensuring that each component in the nonlinear system experiences sufficient reduction rather than competing against each other. More importantly, our strategy yields negligible additional computational overhead and can be seamlessly integrated with other Newton-type solvers, contributing to the improvement of their efficiency and robustness. We test our algorithm on a variety of benchmark problems, including a chemical equilibrium system, a convective diffusion problem, and a series of challenging nonlinear systems. The experimental results demonstrate that our algorithm not only outperforms existing Newton-type solvers in terms of computational efficiency but also exhibits superior robustness, particularly in handling systems with highly imbalanced nonlinearities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03487v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Renjie Ding, Dongling Wang</dc:creator>
    </item>
    <item>
      <title>Shape Taylor expansion for wave scattering problems</title>
      <link>https://arxiv.org/abs/2501.03719</link>
      <description>arXiv:2501.03719v1 Announce Type: new 
Abstract: The Taylor expansion of wave fields with respect to shape parameters has a wide range of applications in wave scattering problems, including inverse scattering, optimal design, and uncertainty quantification. However, deriving the high order shape derivatives required for this expansion poses significant challenges with conventional methods. This paper addresses these difficulties by introducing elegant recurrence formulas for computing high order shape derivatives. The derivation employs tools from exterior differential forms, Lie derivatives, and material derivatives. The work establishes a unified framework for computing the high order shape perturbations in scattering problems. In particular, the recurrence formulas are applicable to both acoustic and electromagnetic scattering models under a variety of boundary conditions, including Dirichlet, Neumann, impedance, and transmission types.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03719v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.DG</category>
      <pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Bao Gang, Ma Haoran, Lai Jun, Li Jingzhi</dc:creator>
    </item>
    <item>
      <title>Computing accurate eigenvalues using a mixed-precision Jacobi algorithm</title>
      <link>https://arxiv.org/abs/2501.03742</link>
      <description>arXiv:2501.03742v1 Announce Type: new 
Abstract: We provide a rounding error analysis of a mixed-precision preconditioned Jacobi algorithm, which uses low precision to compute the preconditioner, applies it in high precision (amounting to two matrix-matrix multiplications) and solves the eigenproblem using the Jacobi algorithm in working precision. Our analysis yields meaningfully smaller relative forward error bounds for the computed eigenvalues compared with those of the standard Jacobi algorithm. We further prove that, after preconditioning, if the off-diagonal entries of the preconditioned matrix are sufficiently small relative to its smallest diagonal entry, the relative forward error bound is independent of the condition number of the original matrix. We present two constructions for the preconditioner that exploit low precision, along with their error analyses. Our numerical experiments confirm our theoretical results and compare the relative forward error of the proposed algorithm with the standard Jacobi algorithm, a preconditioned Jacobi algorithm, and MATLAB's $\texttt{eig}$ function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03742v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Nicholas J. Higham, Fran\c{c}oise Tisseur, Marcus Webb, Zhengbo Zhou</dc:creator>
    </item>
    <item>
      <title>Communication-reduced Conjugate Gradient Variants for GPU-accelerated Clusters</title>
      <link>https://arxiv.org/abs/2501.03743</link>
      <description>arXiv:2501.03743v1 Announce Type: new 
Abstract: Linear solvers are key components in any software platform for scientific and engineering computing. The solution of large and sparse linear systems lies at the core of physics-driven numerical simulations relying on partial differential equations (PDEs) and often represents a significant bottleneck in datadriven procedures, such as scientific machine learning. In this paper, we present an efficient implementation of the preconditioned s-step Conjugate Gradient (CG) method, originally proposed by Chronopoulos and Gear in 1989, for large clusters of Nvidia GPU-accelerated computing nodes. The method, often referred to as communication-reduced or communication-avoiding CG, reduces global synchronizations and data communication steps compared to the standard approach, enhancing strong and weak scalability on parallel computers. Our main contribution is the design of a parallel solver that fully exploits the aggregation of low-granularity operations inherent to the s-step CG method to leverage the high throughput of GPU accelerators. Additionally, it applies overlap between data communication and computation in the multi-GPU sparse matrix-vector product. Experiments on classic benchmark datasets, derived from the discretization of the Poisson PDE, demonstrate the potential of the method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03743v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Massimo Bernaschi, Mauro G. Carrozzo, Alessandro Celestini, Giacomo Piperno, Pasqua D'Ambra</dc:creator>
    </item>
    <item>
      <title>Group Sparse-based Tensor CP Decomposition: Model, Algorithms, and Applications in Chemometrics</title>
      <link>https://arxiv.org/abs/2501.03776</link>
      <description>arXiv:2501.03776v1 Announce Type: new 
Abstract: The CANDECOMP/PARAFAC (or Canonical polyadic, CP) decomposition of tensors has numerous applications in various fields, such as chemometrics, signal processing, machine learning, etc. Tensor CP decomposition assumes the knowledge of the exact CP rank, i.e., the total number of rank-one components of a tensor. However, accurately estimating the CP rank is very challenging. In this work, to address this issue, we prove that the CP rank can be exactly estimated by minimizing the group sparsity of any one of the factor matrices under the unit length constraints on the columns of the other factor matrices. Based on this result, we propose a CP decomposition model with group sparse regularization, which integrates the rank estimation and the tensor decomposition as an optimization problem, whose set of optimal solutions is proved to be nonempty. To solve the proposed model, we propose a double-loop block-coordinate proximal gradient descent algorithm with extrapolation and prove that each accumulation point of the sequence generated by the algorithm is a stationary point of the proposed model. Furthermore, we incorporate a rank reduction strategy into the algorithm to reduce the computational complexity. Finally, we apply the proposed model and algorithms to the component separation problem in chemometrics using real data. Numerical experiments demonstrate the robustness and effectiveness of the proposed methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03776v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zihao Wang, Minru Bai, Liang Chen, Xueying Zhao</dc:creator>
    </item>
    <item>
      <title>Computer-assisted proofs for finding the monodromy of Picard-Fuchs differential equations for a family of K3 toric hypersurfaces</title>
      <link>https://arxiv.org/abs/2501.03792</link>
      <description>arXiv:2501.03792v1 Announce Type: new 
Abstract: In this paper, we present a numerical method for rigorously finding the monodromy of linear differential equations. Beginning at a base point where certain particular solutions are explicitly given by series expansions, we first compute the value of fundamental system of solutions using interval arithmetic to rigorously control truncation and rounding errors. The solutions are then analytically continued along a prescribed contour encircling the singular points of the differential equation via a rigorous integrator. From these computations, the monodromy matrices are derived, generating the monodromy group of the differential equation. This method establishes a mathematically rigorous framework for addressing the monodromy problem in differential equations. For a notable example, we apply our computer-assisted proof method to resolve the monodromy problem for a Picard--Fuchs differential equation associated with a family of K3 toric hypersurfaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03792v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AG</category>
      <pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Toshimasa Ishige, Akitoshi Takayasu</dc:creator>
    </item>
    <item>
      <title>Leveraging time and parameters for nonlinear model reduction methods</title>
      <link>https://arxiv.org/abs/2501.03853</link>
      <description>arXiv:2501.03853v1 Announce Type: new 
Abstract: In this paper, we consider model order reduction (MOR) methods for problems with slowly decaying Kolmogorov $n$-widths as, e.g., certain wave-like or transport-dominated problems. To overcome this Kolmogorov barrier within MOR, nonlinear projections are used, which are often realized numerically using autoencoders. These autoencoders generally consist of a nonlinear encoder and a nonlinear decoder and involve costly training of the hyperparameters to obtain a good approximation quality of the reduced system. To facilitate the training process, we show that extending the to-be-reduced system and its corresponding training data makes it possible to replace the nonlinear encoder with a linear encoder without sacrificing accuracy, thus roughly halving the number of hyperparameters to be trained.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03853v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Silke Glas, Benjamin Unger</dc:creator>
    </item>
    <item>
      <title>Steady and transient thermal stress analysis using a polygonal finite element method</title>
      <link>https://arxiv.org/abs/2501.03908</link>
      <description>arXiv:2501.03908v1 Announce Type: new 
Abstract: While the finite element method (FEM) has been widely used for thermal stress problems, it faces challenges in handling complex geometries, non-matching meshes, and achieving computational efficiency. To address these limitations, this study proposes an N-sides finite element method (NS-FEM) for solving steady-state and transient thermal stress problems. By employing Wachspress basis functions for interpolation within polygonal elements, the method offers enhanced adaptability and accuracy in handling intricate boundary conditions and material properties. A series of numerical examples demonstrate the advantages of the proposed NS-FEM in terms of convergence, computational cost, and solution precision, as compared to conventional FEM. The results confirm the efficacy of NS-FEM in capturing detailed thermal and stress distributions, particularly in multi-scale and non-matching mesh scenarios. This work highlights the potential of NS-FEM as a robust approach for complex thermal stress analysis in engineering applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03908v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yang Yang, Mingjiao Yan, Zongliang Zhang, Xuedong Chen, Dengmiao Hao</dc:creator>
    </item>
    <item>
      <title>Physics Informed Neural Networks for Learning the Horizon Size in Bond-Based Peridynamic Models</title>
      <link>https://arxiv.org/abs/2501.03911</link>
      <description>arXiv:2501.03911v1 Announce Type: new 
Abstract: This paper broaches the peridynamic inverse problem of determining the horizon size of the kernel function in a one-dimensional model of a linear microelastic material. We explore different kernel functions, including V-shaped, distributed, and tent kernels. The paper presents numerical experiments using PINNs to learn the horizon parameter for problems in one and two spatial dimensions. The results demonstrate the effectiveness of PINNs in solving the peridynamic inverse problem, even in the presence of challenging kernel functions. We observe and prove a one-sided convergence behavior of the Stochastic Gradient Descent method towards a global minimum of the loss function, suggesting that the true value of the horizon parameter is an unstable equilibrium point for the PINN's gradient flow dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03911v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fabio V. Difonzo, Luciano Lopez, Sabrina F. Pellegrino</dc:creator>
    </item>
    <item>
      <title>Data-driven Optimization for the Evolve-Filter-Relax regularization of convection-dominated flows</title>
      <link>https://arxiv.org/abs/2501.03933</link>
      <description>arXiv:2501.03933v1 Announce Type: new 
Abstract: Numerical stabilization techniques are often employed in under-resolved simulations of convection-dominated flows to improve accuracy and mitigate spurious oscillations. Specifically, the Evolve-Filter-Relax (EFR) algorithm is a framework which consists in evolving the solution, applying a filtering step to remove high-frequency noise, and relaxing through a convex combination of filtered and original solutions. The stability and accuracy of the EFR solution strongly depend on two parameters, the filter radius $\delta$ and the relaxation parameter $\chi$. Standard choices for these parameters are usually fixed in time, and related to the full order model setting, i.e., the grid size for $\delta$ and the time step for $\chi$. This paper makes two significant improvements to the standard EFR framework by proposing: (i) time-dependent parameters, (ii) data-driven adaptive optimization of the parameters in time, considering a fully-resolved simulation as a reference. In particular, we propose three different classes of Optimized-EFR strategies, aiming to optimize one or both parameters. Moreover, we investigate the accuracy and efficiency of the proposed optimization algorithms considering different objective functions, both local (point-valued) and global (such as the kinetic energy). The new Optimized-EFR strategies are tested in the under-resolved simulation of a turbulent flow past a cylinder at $Re=1000$. The new Optimized-EFR results are more accurate than the standard EFR solution while maintaining a similar computational time. In particular, we show that using a global objective function and including the $H^1$ velocity seminorm is crucial to accurately match the reference flow dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03933v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <category>physics.flu-dyn</category>
      <pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anna Ivagnes, Maria Strazzullo, Michele Girfoglio, Traian Iliescu, Gianluigi Rozza</dc:creator>
    </item>
    <item>
      <title>A fully well-balanced hydrodynamic reconstruction</title>
      <link>https://arxiv.org/abs/2501.03975</link>
      <description>arXiv:2501.03975v1 Announce Type: new 
Abstract: The present work focuses on the numerical approximation of the weak solutions of the shallow water model over a non-flat topography. In particular, we pay close attention to steady solutions with nonzero velocity. The goal of this work is to derive a scheme that exactly preserves these stationary solutions, as well as the commonly preserved lake at rest steady solution. These moving steady states are solution to a nonlinear equation. We emphasize that the method proposed here never requires solving this nonlinear equation; instead, a suitable linearization is derived. To address this issue, we propose an extension of the well-known hydrostatic reconstruction. By appropriately defining the reconstructed states at the interfaces, any numerical flux function, combined with a relevant source term discretization, produces a well-balanced scheme that preserves both moving and non-moving steady solutions. This eliminates the need to construct specific numerical fluxes. Additionally, we prove that the resulting scheme is consistent with the homogeneous system on flat topographies, and that it reduces to the hydrostatic reconstruction when the velocity vanishes. To increase the accuracy of the simulations, we propose a well-balanced high-order procedure, which still does not require solving any nonlinear equation. Several numerical experiments demonstrate the effectiveness of the numerical scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03975v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1515/jnma-2023-0065</arxiv:DOI>
      <arxiv:journal_reference>Journal of Numerical Mathematics, 32(3):275-299, 2024</arxiv:journal_reference>
      <dc:creator>Christophe Berthon, Victor Michel-Dansac</dc:creator>
    </item>
    <item>
      <title>TVD-MOOD schemes based on implicit-explicit time integration</title>
      <link>https://arxiv.org/abs/2501.03994</link>
      <description>arXiv:2501.03994v1 Announce Type: new 
Abstract: The context of this work is the development of first order total variation diminishing (TVD) implicit-explicit (IMEX) Runge-Kutta (RK) schemes as a basis of a Multidimensional Optimal Order detection (MOOD) approach to approximate the solution of hyperbolic multi-scale equations. A key feature of our newly proposed TVD schemes is that the resulting CFL condition does not depend on the fast waves of the considered model, as long as they are integrated implicitly. However, a result from Gottlieb et al. gives a first order barrier for unconditionally stable implicit TVD-RK schemes and TVD-IMEX-RK schemes with scale-independent CFL conditions. Therefore, the goal of this work is to consistently improve the resolution of a first-order IMEX-RK scheme, while retaining its $L^\infty$ stability and TVD properties. In this work we present a novel approach based on a convex combination between a first-order TVD IMEX Euler scheme and a potentially oscillatory high-order IMEX-RK scheme. We derive and analyse the TVD property for a scalar multi-scale equation and numerically assess the performance of our TVD schemes compared to standard $L$-stable and SSP IMEX RK schemes from the literature. Finally, the resulting TVD-MOOD schemes are applied to the isentropic Euler equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03994v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.amc.2022.127397</arxiv:DOI>
      <arxiv:journal_reference>Applied Mathematics and Computation, 433:127397, 2022</arxiv:journal_reference>
      <dc:creator>Victor Michel-Dansac, Andrea Thomann</dc:creator>
    </item>
    <item>
      <title>Refreshing idea on Fourier analysis</title>
      <link>https://arxiv.org/abs/2501.03514</link>
      <description>arXiv:2501.03514v2 Announce Type: cross 
Abstract: The "theoretical limit of time-frequency resolution in Fourier analysis" is thought to originate in certain mathematical and/or physical limitations. This, however, is not true. The actual origin arises from the numerical (technical) method deployed to reduce computation time. In addition, there is a gap between the theoretical equation for Fourier analysis and its numerical implementation. Knowing the facts brings us practical benefits. In this case, these related to boundary conditions, and complex integrals. For example, replacing a Fourier integral with a complex integral brings a hybrid method for the Laplace and Fourier transforms, and reveals another perspective on time-frequency analysis. We present such a perspective here with a simple demonstrative analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03514v2</guid>
      <category>physics.soc-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Fumihiko Ishiyama</dc:creator>
    </item>
    <item>
      <title>Impact of spatial coarsening on Parareal convergence</title>
      <link>https://arxiv.org/abs/2111.10228</link>
      <description>arXiv:2111.10228v2 Announce Type: replace 
Abstract: The Parareal parallel-in-time integration method often performs poorly when applied to hyperbolic partial differential equations. This effect is even more pronounced when the coarse propagator uses a reduced spatial resolution. However, some combinations of spatial discretization and numerical time stepping nevertheless allow for Parareal to converge with monotonically decreasing errors. This raises the question how these configurations can be distinguished theoretically from those where the error initially increases, sometimes over many orders of magnitude. For linear problems, we prove a theorem that implies that the 2-norm of the Parareal iteration matrix is not a suitable tool to predict convergence for hyperbolic problems when spatial coarsening is used. We then show numerical results that suggest that the pseudo-spectral radius can reliably indicate if a given configuration of Parareal will show transient growth or monotonic convergence. For the studied examples, it also provides a good quantitative estimate of the convergence rate in the first few Parareal iterations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2111.10228v2</guid>
      <category>math.NA</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Judith Angel, Sebastian G\"otschel, Daniel Ruprecht</dc:creator>
    </item>
    <item>
      <title>A convergent interacting particle method for computing KPP front speeds in random flows</title>
      <link>https://arxiv.org/abs/2308.14479</link>
      <description>arXiv:2308.14479v2 Announce Type: replace 
Abstract: We aim to efficiently compute spreading speeds of reaction-diffusion-advection (RDA) fronts in divergence free random flows under the Kolmogorov-Petrovsky-Piskunov (KPP) nonlinearity. We study a stochastic interacting particle method (IPM) for the reduced principal eigenvalue (Lyapunov exponent) problem of an associated linear advection-diffusion operator with spatially random coefficients. The Fourier representation of the random advection field and the Feynman-Kac (FK) formula of the principal eigenvalue (Lyapunov exponent) form the foundation of our method implemented as a genetic evolution algorithm. The particles undergo advection-diffusion, and mutation/selection through a fitness function originated in the FK semigroup. We analyze convergence of the algorithm based on operator splitting, present numerical results on representative flows such as 2D cellular flow and 3D Arnold-Beltrami-Childress (ABC) flow under random perturbations. The 2D examples serve as a consistency check with semi-Lagrangian computation. The 3D results demonstrate that IPM, being mesh free and self-adaptive, is simple to implement and efficient for computing front spreading speeds in the advection-dominated regime for high-dimensional random flows on unbounded domains where no truncation is needed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.14479v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tan Zhang, Zhongjian Wang, Jack Xin, Zhiwen Zhang</dc:creator>
    </item>
    <item>
      <title>Convergence and error control of consistent PINNs for elliptic PDEs</title>
      <link>https://arxiv.org/abs/2406.09217</link>
      <description>arXiv:2406.09217v2 Announce Type: replace 
Abstract: We provide an a priori analysis of collocation methods for solving elliptic boundary value problems. They begin with information in the form of point values of the data and utilize only this information to numerically approximate the solution u of the PDE. For such a method to provide an approximation with guaranteed error bounds, additional assumptions on the data, called model class assumptions, are needed. We determine the best error of approximating u in the energy norm, in terms of the total number of point samples, under all Besov class model assumptions for the right hand side and boundary data.
  We then turn to the study of numerical procedures and analyze whether a proposed numerical procedure achieves the optimal recovery error. We analyze numerical methods which generate the numerical approximation to $u$ by minimizing specified data driven loss functions over a set $\Sigma$ which is either a finite dimensional linear space, or more generally, a finite dimensional manifold. We show that the success of such a procedure depends critically on choosing a data driven loss function that is consistent with the PDE and provides sharp error control. Based on this analysis a new loss function is proposed.
  We also address the recent methods of Physics Informed Neural Networks. We prove that minimization of the new loss over restricted neural network spaces $\Sigma$ provides an optimal recovery of the solution $u$, provided that the optimization problem can be numerically executed and $\Sigma$ has sufficient approximation capabilities. We also analyze variants of the new loss function which are more practical for implementation. Finally, numerical examples illustrating the benefits of the proposed loss functions are given.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.09217v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Andrea Bonito, Ronald DeVore, Guergana Petrova, Jonathan W. Siegel</dc:creator>
    </item>
    <item>
      <title>Finite Element Analysis of Shear Lag Effect in Long-Span Single-Box Continuous Rigid Bridges</title>
      <link>https://arxiv.org/abs/2501.03093</link>
      <description>arXiv:2501.03093v2 Announce Type: replace 
Abstract: As the span and width of continuous rigid bridges increase, the complexity of the spatial forces acting on these structures also grows, challenging traditional design methods. Primary beam theory often fails to accurately predict the stresses in the bridge girder, leading to potential overestimation of the ultimate capacity of these bridges. This study addresses this gap by developing a detailed finite element (FE) model of a continuous rigid bridge using ABAQUS, which accounts for the complex 3D geometry, construction procedures, and nonlinear material interactions. A loading test on a 210-meter continuous rigid bridge is performed to validate the model, with the measured strain and deflection data closely matching the FE simulation results. The study also examines stress distributions under constant and live loads, as well as the shear lag coefficients of the main girder. Through parametric analysis, we explore the effects of varying the width-to-span and height-to-width ratios. The results reveal that both a wider box girder and a larger span significantly amplify the shear lag effect in the bridge girder. The findings enhance the understanding of stress distribution in large-scale rigid bridges and provide critical insights for more accurate design and as-sessment of such structures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03093v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaokun Shen, Chengtao Zhou, Dianhao Li, Yun Meng, Lvye Zhou, Ligui Yang, Chengmao He, Shaorui Wang, Shuangshuang Jin</dc:creator>
    </item>
    <item>
      <title>Unexpected Improvements to Expected Improvement for Bayesian Optimization</title>
      <link>https://arxiv.org/abs/2310.20708</link>
      <description>arXiv:2310.20708v3 Announce Type: replace-cross 
Abstract: Expected Improvement (EI) is arguably the most popular acquisition function in Bayesian optimization and has found countless successful applications, but its performance is often exceeded by that of more recent methods. Notably, EI and its variants, including for the parallel and multi-objective settings, are challenging to optimize because their acquisition values vanish numerically in many regions. This difficulty generally increases as the number of observations, dimensionality of the search space, or the number of constraints grow, resulting in performance that is inconsistent across the literature and most often sub-optimal. Herein, we propose LogEI, a new family of acquisition functions whose members either have identical or approximately equal optima as their canonical counterparts, but are substantially easier to optimize numerically. We demonstrate that numerical pathologies manifest themselves in "classic" analytic EI, Expected Hypervolume Improvement (EHVI), as well as their constrained, noisy, and parallel variants, and propose corresponding reformulations that remedy these pathologies. Our empirical results show that members of the LogEI family of acquisition functions substantially improve on the optimization performance of their canonical counterparts and surprisingly, are on par with or exceed the performance of recent state-of-the-art acquisition functions, highlighting the understated role of numerical optimization in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.20708v3</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Sebastian Ament, Samuel Daulton, David Eriksson, Maximilian Balandat, Eytan Bakshy</dc:creator>
    </item>
    <item>
      <title>An unstructured geometrical un-split VOF method for viscoelastic two-phase flows</title>
      <link>https://arxiv.org/abs/2311.10872</link>
      <description>arXiv:2311.10872v3 Announce Type: replace-cross 
Abstract: Since viscoelastic two-phase flows arise in various industrial and natural processes, developing accurate and efficient software for their detailed numerical simulation is a highly relevant and challenging research task. We present a geometrical unstructured Volume-of-Fluid (VOF) method for handling two-phase flows with viscoelastic liquid phase, where the latter is modeled via generic rate-type constitutive equations and a one-field description is derived by conditional volume averaging of the local instantaneous bulk equations and interface jump conditions. The method builds on the plicRDF-isoAdvector geometrical VOF solver that is extended and combined with the modular framework DeboRheo for viscoelastic computational fluid dynamics (CFD). A piecewise-linear geometrical interface reconstruction technique on general unstructured meshes is employed for discretizing the viscoelastic stresses across the fluid interface. DeboRheo facilitates a flexible combination of different rheological models with appropriate stabilization methods to address the high Weissenberg number problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.10872v3</guid>
      <category>physics.flu-dyn</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.cpc.2024.109475</arxiv:DOI>
      <arxiv:journal_reference>Computer Physics Communications, Volume 309, April 2025, 109475</arxiv:journal_reference>
      <dc:creator>Matthias Niethammer, Muhammad Hassan Asghar, Tomislav Maric, Dieter Bothe</dc:creator>
    </item>
    <item>
      <title>Tree-Cotree-Based Tearing and Interconnecting for 3D Magnetostatics: A Dual-Primal Approach</title>
      <link>https://arxiv.org/abs/2407.21707</link>
      <description>arXiv:2407.21707v3 Announce Type: replace-cross 
Abstract: The simulation of electromagnetic devices with complex geometries and large-scale discrete systems benefits from advanced computational methods like IsoGeometric Analysis and Domain Decomposition. In this paper, we employ both concepts in an Isogeometric Tearing and Interconnecting method to enable the use of parallel computations for magnetostatic problems. We address the underlying non-uniqueness by using a graph-theoretic approach, the tree-cotree decomposition. The classical tree-cotree gauging is adapted to be feasible for parallelization, which requires that all local subsystems are uniquely solvable. Our contribution consists of an explicit algorithm for constructing compatible trees and combining it with a dual-primal approach to enable parallelization. The correctness of the proposed approach is proved and verified by numerical experiments, showing its accuracy, scalability and optimal convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.21707v3</guid>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mario Mally, Bernard Kapidani, Melina Merkel, Sebastian Sch\"ops, Rafael V\'azquez</dc:creator>
    </item>
    <item>
      <title>Regularity of vector fields with piecewise regular curl and divergence</title>
      <link>https://arxiv.org/abs/2408.16556</link>
      <description>arXiv:2408.16556v2 Announce Type: replace-cross 
Abstract: We prove piecewise Sobolev regularity of vector fields that have piecewise regular curl and divergence, but may fail to be globally continuous. The main idea behind our approach is to employ recently developed parametrices for the curl-operator and the regularity theory of Poisson transmission problems. We conclude our work by applying our findings to the heterogeneous time-harmonic Maxwell equations with either a) impedance, b) natural or c) essential boundary conditions and providing wavenumber-explicit piecewise regularity estimates for these equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16556v2</guid>
      <category>math.AP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jens Markus Melenk, David W\"org\"otter</dc:creator>
    </item>
    <item>
      <title>Learning Lipschitz Operators with respect to Gaussian Measures with Near-Optimal Sample Complexity</title>
      <link>https://arxiv.org/abs/2410.23440</link>
      <description>arXiv:2410.23440v2 Announce Type: replace-cross 
Abstract: Operator learning, the approximation of mappings between infinite-dimensional function spaces using ideas from machine learning, has gained increasing research attention in recent years. Approximate operators, learned from data, hold promise to serve as efficient surrogate models for problems in computational science and engineering, complementing traditional numerical methods. However, despite their empirical success, our understanding of the underpinning mathematical theory is in large part still incomplete. In this paper, we study the approximation of Lipschitz operators in expectation with respect to Gaussian measures. We prove higher Gaussian Sobolev regularity of Lipschitz operators and establish lower and upper bounds on the Hermite polynomial approximation error. We further consider the reconstruction of Lipschitz operators from $m$ arbitrary (adaptive) linear samples. A key finding is the tight characterization of the smallest achievable error for all possible (adaptive) sampling and reconstruction maps in terms of $m$. It is shown that Hermite polynomial approximation is an optimal recovery strategy, but we have the following curse of sample complexity: No method to approximate Lipschitz operators based on $m$ samples can achieve algebraic convergence rates in $m$. On the positive side, we prove that a sufficiently fast spectral decay of the covariance operator of the Gaussian measure guarantees convergence rates which are arbitrarily close to any algebraic rate in the large data limit $m \to \infty$. A main focus of this work is on the recovery of Lipschitz operators from finitely many point samples. We use Christoffel sampling and weighted least-squares approximation to propose an algorithm which provably achieves near-optimal sample complexity in high probability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23440v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ben Adcock, Michael Griebel, Gregor Maier</dc:creator>
    </item>
    <item>
      <title>Reliable Uncertainty Quantification for Fiber Orientation in Composite Molding Processes using Multilevel Polynomial Surrogates</title>
      <link>https://arxiv.org/abs/2412.08459</link>
      <description>arXiv:2412.08459v2 Announce Type: replace-cross 
Abstract: Fiber orientation is decisive for the mechanical properties and thus for the performance of composite materials. During manufacturing, variations in material and process parameters can significantly influence the exact fiber orientation. We employ multilevel polynomial surrogates to model the propagation of uncertain material properties in the injection molding process. To ensure reliable uncertainty quantification, a key focus is deriving novel error bounds for statistical measures of a quantity of interest, computed via these surrogates. To verify these bounds, we conduct numerical experiments using the Cross-WLF viscosity model alongside the Hagen-Poiseuille flow in a rectangular channel. In particular, the impact of uncertainties in fiber length and matrix temperature on the fractional anisotropy of fiber orientation is investigated. The Folgar-Tucker equation and the improved anisotropic rotary diffusion model are used, incorporating recently established analytical solutions of these models as part of our verification. Our results demonstrate that the investigated method significantly improves upon standard Monte Carlo estimation, while also providing error guarantees. These findings offer the first step toward a reliable and practical tool for optimizing fiber-reinforced polymer manufacturing processes in the future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.08459v2</guid>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stjepan Salatovic, Sebastian Krumscheid, Florian Wittemann, Luise K\"arger</dc:creator>
    </item>
    <item>
      <title>Mixed-precision numerics in scientific applications: survey and perspectives</title>
      <link>https://arxiv.org/abs/2412.19322</link>
      <description>arXiv:2412.19322v2 Announce Type: replace-cross 
Abstract: The explosive demand for artificial intelligence (AI) workloads has led to a significant increase in silicon area dedicated to lower-precision computations on recent high-performance computing hardware designs. However, mixed-precision capabilities, which can achieve performance improvements of 8x compared to double-precision in extreme compute-intensive workloads, remain largely untapped in most scientific applications. A growing number of efforts have shown that mixed-precision algorithmic innovations can deliver superior performance without sacrificing accuracy. These developments should prompt computational scientists to seriously consider whether their scientific modeling and simulation applications could benefit from the acceleration offered by new hardware and mixed-precision algorithms. In this article, we review the literature on relevant applications, existing mixed-precision algorithms, theories, and the available software infrastructure. We then offer our perspective and recommendations on the potential of mixed-precision algorithms to enhance the performance of scientific simulation applications. Broadly, we find that mixed-precision methods can have a large impact on computational science in terms of time-to-solution and energy consumption. This is true not only for a few arithmetic-dominated applications but also, to a more moderate extent, to the many memory bandwidth-bound applications. In many cases, though, the choice of algorithms and regions of applicability will be domain-specific, and thus require input from domain experts. It is helpful to identify cross-cutting computational motifs and their mixed-precision algorithms in this regard. Finally, there are new algorithms being developed to utilize AI hardware and and AI methods to accelerate first-principles computational science, and these should be closely watched as hardware platforms evolve.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.19322v2</guid>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aditya Kashi, Hao Lu, Wesley Brewer, David Rogers, Michael Matheson, Mallikarjun Shankar, Feiyi Wang</dc:creator>
    </item>
  </channel>
</rss>
