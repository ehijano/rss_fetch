<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 15 Nov 2024 05:00:00 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Non-Euclidean High-Order Smooth Convex Optimization</title>
      <link>https://arxiv.org/abs/2411.08987</link>
      <description>arXiv:2411.08987v1 Announce Type: new 
Abstract: We develop algorithms for the optimization of convex objectives that have H\"older continuous $q$-th derivatives with respect to a $p$-norm by using a $q$-th order oracle, for $p, q \geq 1$. We can also optimize other structured functions. We do this by developing a non-Euclidean inexact accelerated proximal point method that makes use of an inexact uniformly convex regularizer. We also provide nearly matching lower bounds for any deterministic algorithm that interacts with the function via a local oracle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08987v1</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Juan Pablo Contreras, Crist\'obal Guzm\'an, David Mart\'inez-Rubio</dc:creator>
    </item>
    <item>
      <title>Null Controllability for Cascade systems of Coupled Backward Stochastic Parabolic Equations with One Distributed Control</title>
      <link>https://arxiv.org/abs/2411.09079</link>
      <description>arXiv:2411.09079v1 Announce Type: new 
Abstract: We prove the null controllability of a cascade system of \(n\) coupled backward stochastic parabolic equations involving both reaction and convection terms, as well as general second-order parabolic operators, with \(n \geq 2\). To achieve this, we apply a single distributed control to the first equation, while the other equations are controlled through the coupling. To obtain our results, we develop a new global Carleman estimate for the forward stochastic parabolic adjoint system with some terms in the \(H^{-1}\)-space. Subsequently, we derive the appropriate observability inequality, and by employing the classical duality argument, we establish our null controllability result. Additionally, we provide an estimate for the null control cost with respect to the final time \(T\) and the potentials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.09079v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Said Boulite, Abdellatif Elgrou, Lahcen Maniar</dc:creator>
    </item>
    <item>
      <title>Accelerating Benders decomposition for solving a sequence of sample average approximation replications</title>
      <link>https://arxiv.org/abs/2411.09091</link>
      <description>arXiv:2411.09091v1 Announce Type: new 
Abstract: Sample average approximation (SAA) is a technique for obtaining approximate solutions to stochastic programs that uses the average from a random sample to approximate the expected value that is being optimized. Since the outcome from solving an SAA is random, statistical estimates on the optimal value of the true problem can be obtained by solving multiple SAA replications with independent samples. We study techniques to accelerate the solution of this set of SAA replications, when solving them sequentially via Benders decomposition. We investigate how to exploit similarities in the problem structure, as the replications just differ in the realizations of the random samples. Our extensive computational experiments provide empirical evidence that our techniques for using information from solving previous replications can significantly reduce the solution time of later replications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.09091v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Harshit Kothari, James R. Luedtke</dc:creator>
    </item>
    <item>
      <title>FxTS-Net: Fixed-Time Stable Learning Framework for Neural ODEs</title>
      <link>https://arxiv.org/abs/2411.09118</link>
      <description>arXiv:2411.09118v1 Announce Type: new 
Abstract: Neural Ordinary Differential Equations (Neural ODEs), as a novel category of modeling big data methods, cleverly link traditional neural networks and dynamical systems. However, it is challenging to ensure the dynamics system reaches a correctly predicted state within a user-defined fixed time. To address this problem, we propose a new method for training Neural ODEs using fixed-time stability (FxTS) Lyapunov conditions. Our framework, called FxTS-Net, is based on the novel FxTS loss (FxTS-Loss) designed on Lyapunov functions, which aims to encourage convergence to accurate predictions in a user-defined fixed time. We also provide an innovative approach for constructing Lyapunov functions to meet various tasks and network architecture requirements, achieved by leveraging supervised information during training. By developing a more precise time upper bound estimation for bounded non-vanishingly perturbed systems, we demonstrate that minimizing FxTS-Loss not only guarantees FxTS behavior of the dynamics but also input perturbation robustness. For optimising FxTS-Loss, we also propose a learning algorithm, in which the simulated perturbation sampling method can capture sample points in critical regions to approximate FxTS-Loss. Experimentally, we find that FxTS-Net provides better prediction performance and better robustness under input perturbation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.09118v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chaoyang Luo, Yan Zou, Wanying Li, Nanjing Huang</dc:creator>
    </item>
    <item>
      <title>Closing the duality gap of the generalized trace ratio problem</title>
      <link>https://arxiv.org/abs/2411.09187</link>
      <description>arXiv:2411.09187v1 Announce Type: new 
Abstract: The generalized trace ratio problem {\rm (GTRP)} is to maximize a quadratic fractional objective function in trace formulation over the Stiefel manifold. In this paper, based on a newly developed matrix S-lemma, we show that {\rm (GTRP)}, if a redundant constraint is added and well scaled, has zero Lagrangian duality gap. However, this is not always true without the technique of scaling or adding the redundant constraint.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.09187v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Meijia Yang, Yong Xia</dc:creator>
    </item>
    <item>
      <title>A polynomially solvable case of unconstrained (-1,1)-quadratic fractional optimization</title>
      <link>https://arxiv.org/abs/2411.09190</link>
      <description>arXiv:2411.09190v1 Announce Type: new 
Abstract: In this paper, we consider an unconstrained (-1,1)-quadratic fractional optimization in the following form: $\min_{x\in\{-1,1\}^n}~(x^TAx+\alpha)/(x^TBx+\beta)$, where $A$ and $B$, given by their nonzero eigenvalues and associated eigenvectors, have ranks not exceeding fixed integers $r_a$ and $r_b$, respectively. We show that this problem can be solved in $O(n^{r_a+r_b+1}\log^2 n)$ by the accelerated Newton-Dinkelbach method when the matrices $A$ has nonpositive diagonal entries only, $B$ has nonnegative diagonal entries only. Furthermore, this problem can be solved in $O(n^{r_a+r_b+2}\log^2 n)$ when $A$ has $O(\log(n))$ positive diagonal entries, $B$ has $O(\log(n))$ negative diagonal entries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.09190v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Meijia Yang, Yong Xia</dc:creator>
    </item>
    <item>
      <title>Strong Metric Subregularity of the optimality mapping and second-order sufficient optimality conditions in extremal problems with constraints</title>
      <link>https://arxiv.org/abs/2411.09395</link>
      <description>arXiv:2411.09395v1 Announce Type: new 
Abstract: This is a review paper, summarizing without proofs recent results by the authors on the property of strong metric subregularity (SMSR) in optimization. It presents sufficient conditions for SMSR of the optimality mapping associated with a set of necessary optimality conditions in three types of constrained optimization problems: mathematical programming, calculus of variations, and optimal control. The conditions are based on second-order sufficient optimality conditions in the corresponding optimization problems and guarantee small changes in the optimal solution and Lagrange multipliers for small changes in the data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.09395v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Nikolai P. Osmolovskii, Vladimir M. Veliov</dc:creator>
    </item>
    <item>
      <title>Universal nonmonotone line search method for nonconvex multiobjective optimization problems with convex constraints</title>
      <link>https://arxiv.org/abs/2411.09466</link>
      <description>arXiv:2411.09466v1 Announce Type: new 
Abstract: In this work we propose a general nonmonotone line-search method for nonconvex multi\-objective optimization problems with convex constraints. At the $k$th iteration, the degree of nonmonotonicity is controlled by a vector $\nu_{k}$ with nonnegative components. Different choices for $\nu_{k}$ lead to different nonmonotone step-size rules. Assuming that the sequence $\left\{\nu_{k}\right\}_{k\geq 0}$ is summable, and that the $i$th objective function has H\"older continuous gradient with smoothness parameter $\theta_i \in(0,1]$, we show that the proposed method takes no more than $\mathcal{O}\left(\epsilon^{-\left(1+\frac{1}{\theta_{\min}}\right)}\right)$ iterations to find a $\epsilon$-approximate Pareto critical point for a problem with $m$ objectives and $\theta_{\min}= \min_{i=1,\dots, m} \{\theta_i\}$. In particular, this complexity bound applies to the methods proposed by Drummond and Iusem (Comput. Optim. Appl. 28: 5--29, 2004), by Fazzio and Schuverdt (Optim. Lett. 13: 1365--1379, 2019), and by Mita, Fukuda and Yamashita (J. Glob. Optim. 75: 63--90, 2019). The generality of our approach also allows the development of new methods for multiobjective optimization. As an example, we propose a new nonmonotone step-size rule inspired by the Metropolis criterion. Preliminary numerical results illustrate the benefit of nonmonotone line searches and suggest that our new rule is particularly suitable for multiobjective problems in which at least one of the objectives has many non-global local minimizers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.09466v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maria Eduarda Pinheiro, Geovani Nunes Grapiglia</dc:creator>
    </item>
    <item>
      <title>Perturbed Fenchel Duality and Primal-Dual Convergence of First-Order Methods</title>
      <link>https://arxiv.org/abs/2411.09503</link>
      <description>arXiv:2411.09503v1 Announce Type: new 
Abstract: It has been shown that many first-order methods satisfy the perturbed Fenchel duality inequality, which yields a unified derivation of convergence. More first-order methods are discussed in this paper, e.g., dual averaging and bundle method. We show primal-dual convergence of them on convex optimization by proving the perturbed Fenchel duality property. We also propose a single-cut bundle method for saddle problem, and prove its convergence in a similar manner.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.09503v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tiantian Zhao</dc:creator>
    </item>
    <item>
      <title>Distributed Recursion Revisited</title>
      <link>https://arxiv.org/abs/2411.09554</link>
      <description>arXiv:2411.09554v1 Announce Type: new 
Abstract: The distributed recursion (DR) algorithm is an effective method for solving the pooling problem that arises in many applications. It is based on the well-known P-formulation of the pooling problem, which involves the flow and quality variables; and it can be seen as a variant of the successive linear programming (SLP) algorithm, where the linear programming (LP) approximation problem can be transformed from the LP approximation problem derived by using the first-order Taylor series expansion technique. In this paper, we first propose a new nonlinear programming (NLP) formulation for the pooling problem involving only the flow variables, and show that the DR algorithm can be seen as a direct application of the SLP algorithm to the newly proposed formulation. With this new useful theoretical insight, we then develop a new variant of DR algorithm, called penalty DR (PDR) algorithm, based on the proposed formulation. The proposed PDR algorithm is a penalty algorithm where violations of the (linearized) nonlinear constraints are penalized in the objective function of the LP approximation problem with the penalty terms increasing when the constraint violations tend to be large. Compared with the LP approximation problem in the classic DR algorithm, the LP approximation problem in the proposed PDR algorithm can return a solution with a better objective value, which makes it more suitable for finding high-quality solutions for the pooling problem. Numerical experiments on benchmark and randomly constructed instances show that the proposed PDR algorithm is more effective than the classic SLP and DR algorithms in terms of finding a better solution for the pooling problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.09554v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Wei-Yang Zhang, Feng-Lian Dong, Zhi-Wei Wei, Yan-Ru Wang, Ze-Jin Xu, Wei-Kun Chen, Yu-Hong Dai</dc:creator>
    </item>
    <item>
      <title>Nash equilibrium seeking for a class of quadratic-bilinear Wasserstein distributionally robust games</title>
      <link>https://arxiv.org/abs/2411.09636</link>
      <description>arXiv:2411.09636v1 Announce Type: new 
Abstract: We consider a class of Wasserstein distributionally robust Nash equilibrium problems, where agents construct heterogeneous data-driven Wasserstein ambiguity sets using private samples and radii, in line with their individual risk-averse behaviour. By leveraging relevant properties of this class of games, we show that equilibria of the original seemingly infinite-dimensional problem can be obtained as a solution to a finite-dimensional Nash equilibrium problem. We then reformulate the problem as a finite-dimensional variational inequality and establish the connection between the corresponding solution sets. Our reformulation has scalable behaviour with respect to the data size and maintains a fixed number of constraints, independently of the number of samples. To compute a solution, we leverage two algorithms, based on the golden ratio algorithm. The efficiency of both algorithmic schemes is corroborated through extensive simulation studies on an illustrative example and a stochastic portfolio allocation game, where behavioural coupling among investors is modeled.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.09636v1</guid>
      <category>math.OC</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Georgios Pantazis, Reza Rahimi Bahbadorani, Sergio Grammatico</dc:creator>
    </item>
    <item>
      <title>Neural Operators Can Play Dynamic Stackelberg Games</title>
      <link>https://arxiv.org/abs/2411.09644</link>
      <description>arXiv:2411.09644v1 Announce Type: new 
Abstract: Dynamic Stackelberg games are a broad class of two-player games in which the leader acts first, and the follower chooses a response strategy to the leader's strategy. Unfortunately, only stylized Stackelberg games are explicitly solvable since the follower's best-response operator (as a function of the control of the leader) is typically analytically intractable. This paper addresses this issue by showing that the \textit{follower's best-response operator} can be approximately implemented by an \textit{attention-based neural operator}, uniformly on compact subsets of adapted open-loop controls for the leader. We further show that the value of the Stackelberg game where the follower uses the approximate best-response operator approximates the value of the original Stackelberg game. Our main result is obtained using our universal approximation theorem for attention-based neural operators between spaces of square-integrable adapted stochastic processes, as well as stability results for a general class of Stackelberg games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.09644v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <category>q-fin.CP</category>
      <pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guillermo Alvarez, Ibrahim Ekren, Anastasis Kratsios, Xuwei Yang</dc:creator>
    </item>
    <item>
      <title>Reducing Stochastic Games to Semidefinite Programming</title>
      <link>https://arxiv.org/abs/2411.09646</link>
      <description>arXiv:2411.09646v1 Announce Type: new 
Abstract: We present a polynomial-time reduction from max-average constraints to the feasibility problem for semidefinite programs. This shows that Condon's simple stochastic games, stochastic mean payoff games, and in particular mean payoff games and parity games can all be reduced to semidefinite programming.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.09646v1</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <category>cs.GT</category>
      <pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Manuel Bodirsky, Georg Loho, Mateusz Skomra</dc:creator>
    </item>
    <item>
      <title>Sensitivity of ODE Solutions and Quantities of Interest with Respect to Component Functions in the Dynamics</title>
      <link>https://arxiv.org/abs/2411.09655</link>
      <description>arXiv:2411.09655v1 Announce Type: new 
Abstract: This work analyzes the sensitivities of the solution of a system of ordinary differential equations (ODEs) and a corresponding quantity of interest (QoI) to perturbations in a state-dependent component function that appears in the governing ODEs. This extends existing ODE sensitivity results, which consider the sensitivity of the ODE solution with respect to state-independent parameters. It is shown that with Carath\'eodory-type assumptions on the ODEs, the Implicit Function Theorem can be applied to establish continuous Fr\'echet differentiability of the ODE solution with respect to the component function. These sensitivities are used to develop new estimates for the change in the ODE solution or QoI when the component function is perturbed. In applications, this new sensitivity-based bound on the ODE solution or QoI error is often much tighter than classical Gronwall-type error bounds. The sensitivity-based error bounds are applied to Zermelo's problem and to a trajectory simulation for a hypersonic vehicle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.09655v1</guid>
      <category>math.OC</category>
      <category>math.CA</category>
      <category>math.DS</category>
      <pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonathan R. Cangelosi, Matthias Heinkenschloss</dc:creator>
    </item>
    <item>
      <title>A characterization of positive spanning sets with ties to strongly connected digraphs</title>
      <link>https://arxiv.org/abs/2411.08994</link>
      <description>arXiv:2411.08994v1 Announce Type: cross 
Abstract: Positive spanning sets (PSSs) are families of vectors that span a given linear space through non-negative linear combinations. Despite certain classes of PSSs being well understood, a complete characterization of PSSs remains elusive. In this paper, we explore a relatively understudied relationship between positive spanning sets and strongly edge-connected digraphs, in that the former can be viewed as a generalization of the latter. We leverage this connection to define a decomposition structure for positive spanning sets inspired by the ear decomposition from digraph theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08994v1</guid>
      <category>cs.DM</category>
      <category>math.CO</category>
      <category>math.OC</category>
      <pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Denis Cornaz, S\'ebastien Kerleau, Cl\'ement W. Royer</dc:creator>
    </item>
    <item>
      <title>Newton's Method Applied to Nonlinear Boundary Value Problems: A Numerical Approach</title>
      <link>https://arxiv.org/abs/2411.09029</link>
      <description>arXiv:2411.09029v1 Announce Type: cross 
Abstract: This work investigates the application of the Newton's method for the numerical solution of a nonlinear boundary value problem formulated through an ordinary differential equation (ODE). Nonlinear ODEs arise in various mathematical modeling contexts, where an exact solution is often unfeasible due to the intrinsic complexity of these equations. Thus, a numerical approach is employed, using Newton's method to solve the system resulting from the discretization of the original problem. The procedure involves the iterative formulation of the method, which enables the approximation of solutions and the evaluation of convergence with respect to the problem parameters. The results demonstrate that Newton's method provides a robust and efficient solution, highlighting its applicability to complex boundary value problems and reinforcing its relevance for the numerical analysis of nonlinear systems. It is concluded that the methodology discussed is suitable for solving a wide range of boundary value problems, ensuring precision and stability in the results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.09029v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rusdrael Antony de Ara\'ujo Freire, Francisco M\'arcio Barboza, M\'arcio Matheus de Lima Barboza</dc:creator>
    </item>
    <item>
      <title>Information-Optimal Multi-Spacecraft Positioning for Interstellar Object Exploration</title>
      <link>https://arxiv.org/abs/2411.09110</link>
      <description>arXiv:2411.09110v1 Announce Type: cross 
Abstract: Interstellar objects (ISOs), astronomical objects not gravitationally bound to the sun, could present valuable opportunities to advance our understanding of the universe's formation and composition. In response to the unpredictable nature of their discoveries that inherently come with large and rapidly changing uncertainty in their state, this paper proposes a novel multi-spacecraft framework for locally maximizing information to be gained through ISO encounters with formal probabilistic guarantees. Given some approximated control and estimation policies for fully autonomous spacecraft operations, we first construct an ellipsoid around its terminal position, where the ISO would be located with a finite probability. The large state uncertainty of the ISO is formally handled here through the hierarchical property in stochastically contracting nonlinear systems. We then propose a method to find the terminal positions of the multiple spacecraft optimally distributed around the ellipsoid, which locally maximizes the information we can get from all the points of interest (POIs). This utilizes a probabilistic information cost function that accounts for spacecraft positions, camera specifications, and ISO position uncertainty, where the information is defined as visual data collected by cameras. Numerical simulations demonstrate the efficacy of this approach using synthetic ISO candidates generated from quasi-realistic empirical populations. Our method allows each spacecraft to optimally select its terminal state and determine the ideal number of POIs to investigate, potentially enhancing the ability to study these rare and fleeting interstellar visitors while minimizing resource utilization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.09110v1</guid>
      <category>eess.SY</category>
      <category>cs.MA</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arna Bhardwaj, Shishir Bhatta, Hiroyasu Tsukamoto</dc:creator>
    </item>
    <item>
      <title>Mixing Douglas' and weak majorization and factorization theorems</title>
      <link>https://arxiv.org/abs/2411.09305</link>
      <description>arXiv:2411.09305v1 Announce Type: cross 
Abstract: The Douglas' majorization and factorization theorem characterizes the inclusion of operator ranges in Hilbert spaces. Notably, it reinforces the well-established connections between the inclusion of kernels of operators in Hilbert spaces and the (inverse) inclusion of the closures of the ranges of their adjoints. This note aims to present a ''mixed'' version of these concepts for operators with a codomain in a product space. Additionally, an application in control theory of coupled systems of linear partial differential equations is presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.09305v1</guid>
      <category>math.FA</category>
      <category>math.OC</category>
      <pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pierre Lissy (CERMICS)</dc:creator>
    </item>
    <item>
      <title>Stability and Generalization for Distributed SGDA</title>
      <link>https://arxiv.org/abs/2411.09365</link>
      <description>arXiv:2411.09365v1 Announce Type: cross 
Abstract: Minimax optimization is gaining increasing attention in modern machine learning applications. Driven by large-scale models and massive volumes of data collected from edge devices, as well as the concern to preserve client privacy, communication-efficient distributed minimax optimization algorithms become popular, such as Local Stochastic Gradient Descent Ascent (Local-SGDA), and Local Decentralized SGDA (Local-DSGDA). While most existing research on distributed minimax algorithms focuses on convergence rates, computation complexity, and communication efficiency, the generalization performance remains underdeveloped, whereas generalization ability is a pivotal indicator for evaluating the holistic performance of a model when fed with unknown data. In this paper, we propose the stability-based generalization analytical framework for Distributed-SGDA, which unifies two popular distributed minimax algorithms including Local-SGDA and Local-DSGDA, and conduct a comprehensive analysis of stability error, generalization gap, and population risk across different metrics under various settings, e.g., (S)C-(S)C, PL-SC, and NC-NC cases. Our theoretical results reveal the trade-off between the generalization gap and optimization error and suggest hyperparameters choice to obtain the optimal population risk. Numerical experiments for Local-SGDA and Local-DSGDA validate the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.09365v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Miaoxi Zhu, Yan Sun, Li Shen, Bo Du, Dacheng Tao</dc:creator>
    </item>
    <item>
      <title>Safety Filter for Robust Disturbance Rejection via Online Optimization</title>
      <link>https://arxiv.org/abs/2411.09582</link>
      <description>arXiv:2411.09582v1 Announce Type: cross 
Abstract: Disturbance rejection in high-precision control applications can be significantly improved upon via online convex optimization (OCO). This includes classical techniques such as recursive least squares (RLS) and more recent, regret-based formulations. However, these methods can cause instabilities in the presence of model uncertainty. This paper introduces a safety filter for systems with OCO in the form of adaptive finite impulse response (FIR) filtering to ensure robust disturbance rejection. The safety filter enforces a robust stability constraint on the FIR coefficients while minimally altering the OCO command in the $\infty$-norm cost. Additionally, we show that the induced $\ell_\infty$-norm allows for easy online implementation of the safety filter by directly limiting the OCO command. The constraint can be tuned to trade off robustness and performance. We provide a simple example to demonstrate the safety filter.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.09582v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joyce Lai, Peter Seiler</dc:creator>
    </item>
    <item>
      <title>How to implement the Bayes' formula in the age of ML?</title>
      <link>https://arxiv.org/abs/2411.09653</link>
      <description>arXiv:2411.09653v1 Announce Type: cross 
Abstract: This chapter contains a self-contained introduction to the significance of Bayes' formula in the context of nonlinear filtering problems. Both discrete-time and continuous-time settings of the problem are considered in a unified manner. In control theory, the focus on optimization-based solution approaches is stressed together with a discussion of historical developments in this area (from 1960s onwards). The heart of this chapter contains a presentation of a novel optimal transportation formulation for the Bayes formula (developed recently by the first author) and its relationship to some of the prior joint work (feedback particle filter) from the authors. The presentation highlights how optimal transportation theory is leveraged to overcome some of the numerical challenges of implementing Bayes' law by enabling the use of machine learning (ML) tools.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.09653v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amirhossein Taghvaei, Prashant G. Mehta</dc:creator>
    </item>
    <item>
      <title>Electric Vehicle Fleet and Charging Infrastructure Planning</title>
      <link>https://arxiv.org/abs/2306.10178</link>
      <description>arXiv:2306.10178v3 Announce Type: replace 
Abstract: We study electric vehicle (EV) fleet and charging infrastructure planning in a spatial setting. With customer requests arriving continuously at rate $\lambda$ throughout the day, we determine the minimum number of vehicles and chargers for a target service level, along with matching and charging policies. While non-EV systems require extra $\Theta(\lambda^{2/3})$ vehicles due to pickup times, EV systems differ. Charging increases nominal capacity, enabling pickup time reductions and allowing for an extra fleet requirement of only $\Theta(\lambda^{\nu})$ for $\nu \in (1/2, 2/3]$, depending on charging infrastructure and battery pack sizes. We propose the Power-of-$d$ dispatching policy, which achieves this performance by selecting the closest vehicle with the highest battery level from $d$ options. We extend our results to accommodate time-varying demand patterns and discuss conditions for transitioning between EV and non-EV capacity planning. Extensive simulations verify our scaling results, insights, and policy effectiveness while also showing the viability of low-range, low-cost fleets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.10178v3</guid>
      <category>math.OC</category>
      <pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sushil Mahavir Varma, Francisco Castro, Siva Theja Maguluri</dc:creator>
    </item>
    <item>
      <title>Finite-Time Decoupled Convergence in Nonlinear Two-Time-Scale Stochastic Approximation</title>
      <link>https://arxiv.org/abs/2401.03893</link>
      <description>arXiv:2401.03893v2 Announce Type: replace 
Abstract: In two-time-scale stochastic approximation (SA), two iterates are updated at varying speeds using different step sizes, with each update influencing the other. Previous studies on linear two-time-scale SA have shown that the convergence rates of the mean-square errors for these updates depend solely on their respective step sizes, a phenomenon termed decoupled convergence. However, achieving decoupled convergence in nonlinear SA remains less understood. Our research investigates the potential for finite-time decoupled convergence in nonlinear two-time-scale SA. We demonstrate that, under a nested local linearity assumption, finite-time decoupled convergence rates can be achieved with suitable step size selection. To derive this result, we conduct a convergence analysis of the matrix cross term between the iterates and leverage fourth-order moment convergence rates to control the higher-order error terms induced by local linearity. Additionally, a numerical example is provided to explore the possible necessity of local linearity for decoupled convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.03893v2</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuze Han, Xiang Li, Zhihua Zhang</dc:creator>
    </item>
    <item>
      <title>Convergence towards a local minimum by direct search methods with a covering step</title>
      <link>https://arxiv.org/abs/2401.07097</link>
      <description>arXiv:2401.07097v4 Announce Type: replace 
Abstract: This paper introduces a new step to the Direct Search Method (DSM) to strengthen its convergence analysis. By design, this so-called covering step may ensure that for all refined points of the sequence of incumbent solutions generated by the resulting cDSM (covering DSM), the set of all evaluated trial points is dense in a neighborhood of that refined point. We prove that this additional property guarantees that all refined points are local solutions to the optimization problem. This new result holds true even for discontinuous objective function, under a mild assumption that we discuss in details. We also provide a practical construction scheme for the covering step that works at low additional cost per iteration. Finally, we show that the covering step may be adapted to classes of algorithms differing from the DSM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.07097v4</guid>
      <category>math.OC</category>
      <pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Charles Audet, Pierre-Yves Bouchet. Lo\"ic Bourdin</dc:creator>
    </item>
    <item>
      <title>Output feedback stabilisation of bilinear systems via control templates</title>
      <link>https://arxiv.org/abs/2403.01869</link>
      <description>arXiv:2403.01869v2 Announce Type: replace 
Abstract: We establish a separation principle for the output feedback stabilisation of state-affine systems that are observable at the stabilization target. Relying on control templates (recently introduced in [4]), that allow to approximate a feedback control while maintaining observability, we design a closed loop hybrid state-observer system that we show to be semi-globally asymptotically stable. Under assumption of polynomiality of the system with respect to the control, we give an explicit construction of control templates. We illustrate the results of the paper with numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01869v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>IEEE Control Systems Letters, 2024, \&amp;\#x27E8;10.1109/LCSYS.2024.3407603\&amp;\#x27E9</arxiv:journal_reference>
      <dc:creator>Ludovic Sacchelli (McTAO), Lucas Brivadis (L2S), Ulysse Serres (LAGEPP), Ita\"i Ben Yaacov (AGL)</dc:creator>
    </item>
    <item>
      <title>Adaptive Power Flow Approximations with Second-Order Sensitivity Insights</title>
      <link>https://arxiv.org/abs/2404.04391</link>
      <description>arXiv:2404.04391v2 Announce Type: replace 
Abstract: The power flow equations are fundamental to power system planning, analysis, and control. However, the inherent non-linearity and non-convexity of these equations present formidable obstacles in problem-solving processes. To mitigate these challenges, recent research has proposed adaptive power flow linearizations that aim to achieve accuracy over wide operating ranges. The accuracy of these approximations inherently depends on the curvature of the power flow equations within these ranges, which necessitates considering second-order sensitivities. In this paper, we leverage second-order sensitivities to both analyze and improve power flow approximations. We evaluate the curvature across broad operational ranges and subsequently utilize this information to inform the computation of various sample-based power flow approximation techniques. Additionally, we leverage second-order sensitivities to guide the development of rational approximations that yield linear constraints in optimization problems. This approach is extended to enhance accuracy beyond the limitations of linear functions across varied operational scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04391v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Paprapee Buason, Sidhant Misra, Jean-Paul Watson, Daniel K. Molzahn</dc:creator>
    </item>
    <item>
      <title>High-probability complexity guarantees for nonconvex minimax problems</title>
      <link>https://arxiv.org/abs/2405.14130</link>
      <description>arXiv:2405.14130v3 Announce Type: replace 
Abstract: Stochastic smooth nonconvex minimax problems are prevalent in machine learning, e.g., GAN training, fair classification, and distributionally robust learning. Stochastic gradient descent ascent (GDA)-type methods are popular in practice due to their simplicity and single-loop nature. However, there is a significant gap between the theory and practice regarding high-probability complexity guarantees for these methods on stochastic nonconvex minimax problems. Existing high-probability bounds for GDA-type single-loop methods only apply to convex/concave minimax problems and to particular non-monotone variational inequality problems under some restrictive assumptions. In this work, we address this gap by providing the first high-probability complexity guarantees for nonconvex/PL minimax problems corresponding to a smooth function that satisfies the PL-condition in the dual variable. Specifically, we show that when the stochastic gradients are light-tailed, the smoothed alternating GDA method can compute an $\varepsilon$-stationary point within $O(\frac{\ell \kappa^2 \delta^2}{\varepsilon^4} + \frac{\kappa}{\varepsilon^2}(\ell+\delta^2\log({1}/{\bar{q}})))$ stochastic gradient calls with probability at least $1-\bar{q}$ for any $\bar{q}\in(0,1)$, where $\mu$ is the PL constant, $\ell$ is the Lipschitz constant of the gradient, $\kappa=\ell/\mu$ is the condition number, and $\delta^2$ denotes a bound on the variance of stochastic gradients. We also present numerical results on a nonconvex/PL problem with synthetic data and on distributionally robust optimization problems with real data, illustrating our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14130v3</guid>
      <category>math.OC</category>
      <pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yassine Laguel, Yasa Syed, Necdet Serhat Aybat, Mert G\"urb\"uzbalaban</dc:creator>
    </item>
    <item>
      <title>The High Line: Exact Risk and Learning Rate Curves of Stochastic Adaptive Learning Rate Algorithms</title>
      <link>https://arxiv.org/abs/2405.19585</link>
      <description>arXiv:2405.19585v2 Announce Type: replace 
Abstract: We develop a framework for analyzing the training and learning rate dynamics on a large class of high-dimensional optimization problems, which we call the high line, trained using one-pass stochastic gradient descent (SGD) with adaptive learning rates. We give exact expressions for the risk and learning rate curves in terms of a deterministic solution to a system of ODEs. We then investigate in detail two adaptive learning rates -- an idealized exact line search and AdaGrad-Norm -- on the least squares problem. When the data covariance matrix has strictly positive eigenvalues, this idealized exact line search strategy can exhibit arbitrarily slower convergence when compared to the optimal fixed learning rate with SGD. Moreover we exactly characterize the limiting learning rate (as time goes to infinity) for line search in the setting where the data covariance has only two distinct eigenvalues. For noiseless targets, we further demonstrate that the AdaGrad-Norm learning rate converges to a deterministic constant inversely proportional to the average eigenvalue of the data covariance matrix, and identify a phase transition when the covariance density of eigenvalues follows a power law distribution. We provide our code for evaluation at https://github.com/amackenzie1/highline2024.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19585v2</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Elizabeth Collins-Woodfin, Inbar Seroussi, Bego\~na Garc\'ia Malaxechebarr\'ia, Andrew W. Mackenzie, Elliot Paquette, Courtney Paquette</dc:creator>
    </item>
    <item>
      <title>Mixed Newton Method for Optimization in Complex Spaces</title>
      <link>https://arxiv.org/abs/2407.20367</link>
      <description>arXiv:2407.20367v2 Announce Type: replace 
Abstract: In this paper, we modify and apply the recently introduced Mixed Newton Method, which is originally designed for minimizing real-valued functions of complex variables, to the minimization of real-valued functions of real variables by extending the functions to complex space. We show that arbitrary regularizations preserve the favorable local convergence properties of the method, and construct a special type of regularization used to prevent convergence to complex minima. We compare several variants of the method applied to training neural networks with real and complex parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.20367v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nikita Yudin, Roland Hildebrand, Sergey Bakhurin, Alexander Degtyarev, Anna Lisachenko, Ilya Kuruzov, Andrei Semenov, Mohammad Alkousa</dc:creator>
    </item>
    <item>
      <title>Auto-tuned Primal-dual Successive Convexification for Hypersonic Reentry Guidance</title>
      <link>https://arxiv.org/abs/2411.08361</link>
      <description>arXiv:2411.08361v2 Announce Type: replace 
Abstract: This paper presents auto-tuned primal-dual successive convexification (Auto-SCvx), an algorithm designed to reliably achieve dynamically-feasible trajectory solutions for constrained hypersonic reentry optimal control problems across a large mission parameter space. In Auto-SCvx, we solve a sequence of convex subproblems until convergence to a solution of the original nonconvex problem. This method iteratively optimizes dual variables in closed-form in order to update the penalty hyperparameters used in the primal variable updates. A benefit of this method is that it is auto-tuning, and requires no hand-tuning by the user with respect to the constraint penalty weights. Several example hypersonic reentry problems are posed and solved using this method, and comparative studies are conducted against current methods. In these numerical studies, our algorithm demonstrates equal and often improved performance while not requiring hand-tuning of penalty hyperparameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08361v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Skye Mceowen, Daniel J. Calderone, Aman Tiwary, Jason S. K. Zhou, Taewan Kim, Purnanand Elango, Behcet Acikmese</dc:creator>
    </item>
    <item>
      <title>Using orthogonally structured positive bases for constructing positive $k$-spanning sets with cosine measure guarantees</title>
      <link>https://arxiv.org/abs/2306.06383</link>
      <description>arXiv:2306.06383v4 Announce Type: replace-cross 
Abstract: Positive spanning sets span a given vector space by nonnegative linear combinations of their elements. These have attracted significant attention in recent years, owing to their extensive use in derivative-free optimization. In this setting, the quality of a positive spanning set is assessed through its cosine measure, a geometric quantity that expresses how well such a set covers the space of interest. In this paper, we investigate the construction of positive $k$-spanning sets with geometrical guarantees. Our results build on recently identified positive spanning sets, called orthogonally structured positive bases. We first describe how to identify such sets and compute their cosine measures efficiently. We then focus our study on positive $k$-spanning sets, for which we provide a complete description, as well as a new notion of cosine measure that accounts for the resilient nature of such sets. By combining our results, we are able to use orthogonally structured positive bases to create positive $k$-spanning sets with guarantees on the value of their cosine measures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.06383v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Warren Hare, Gabriel Jarry-Bolduc, S\'ebastien Kerleau, Cl\'ement W. Royer</dc:creator>
    </item>
    <item>
      <title>Robustness to Model Approximation, Empirical Model Learning, and Sample Complexity in Wasserstein Regular MDPs</title>
      <link>https://arxiv.org/abs/2410.14116</link>
      <description>arXiv:2410.14116v3 Announce Type: replace-cross 
Abstract: The paper studies the robustness properties of discrete-time stochastic optimal control under Wasserstein model approximation for both discounted cost and average cost criteria. Specifically, we study the performance loss when applying an optimal policy designed for an approximate model to the true dynamics compared with the optimal cost for the true model under the sup-norm-induced metric, and relate it to the Wasserstein-1 distance between the approximate and true transition kernels. A primary motivation of this analysis is empirical model learning, as well as empirical noise distribution learning, where Wasserstein convergence holds under mild conditions but stronger convergence criteria, such as total variation, may not. We discuss applications of the results to the disturbance estimation problem, where sample complexity bounds are given, and also to a general empirical model learning approach, obtained under either Markov or i.i.d.~learning settings. Further applications regarding the continuity of invariant probability measures with respect to transition kernels are also discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14116v3</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yichen Zhou, Yanglei Song, Serdar Y\"uksel</dc:creator>
    </item>
  </channel>
</rss>
