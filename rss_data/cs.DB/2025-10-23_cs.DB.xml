<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DB updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DB</link>
    <description>cs.DB updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DB" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 24 Oct 2025 01:42:46 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>FlexiDataGen: An Adaptive LLM Framework for Dynamic Semantic Dataset Generation in Sensitive Domains</title>
      <link>https://arxiv.org/abs/2510.19025</link>
      <description>arXiv:2510.19025v1 Announce Type: new 
Abstract: Dataset availability and quality remain critical challenges in machine learning, especially in domains where data are scarce, expensive to acquire, or constrained by privacy regulations. Fields such as healthcare, biomedical research, and cybersecurity frequently encounter high data acquisition costs, limited access to annotated data, and the rarity or sensitivity of key events. These issues-collectively referred to as the dataset challenge-hinder the development of accurate and generalizable machine learning models in such high-stakes domains. To address this, we introduce FlexiDataGen, an adaptive large language model (LLM) framework designed for dynamic semantic dataset generation in sensitive domains. FlexiDataGen autonomously synthesizes rich, semantically coherent, and linguistically diverse datasets tailored to specialized fields. The framework integrates four core components: (1) syntactic-semantic analysis, (2) retrieval-augmented generation, (3) dynamic element injection, and (4) iterative paraphrasing with semantic validation. Together, these components ensure the generation of high-quality, domain-relevant data. Experimental results show that FlexiDataGen effectively alleviates data shortages and annotation bottlenecks, enabling scalable and accurate machine learning model development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19025v1</guid>
      <category>cs.DB</category>
      <category>cs.AI</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hamed Jelodar, Samita Bai, Roozbeh Razavi-Far, Ali A. Ghorbani</dc:creator>
    </item>
    <item>
      <title>Fine-Grained Dichotomies for Conjunctive Queries with Minimum or Maximum</title>
      <link>https://arxiv.org/abs/2510.19197</link>
      <description>arXiv:2510.19197v1 Announce Type: new 
Abstract: We investigate the fine-grained complexity of direct access to Conjunctive Query (CQ) answers according to their position, ordered by the minimum (or maximum) value between attributes. We further use the tools we develop to explore a wealth of related tasks. We consider the task of ranked enumeration under min/max orders, as well as tasks concerning CQs with predicates of the form x &lt;= min X , where X is a set of variables and x is a single variable: counting, enumeration, direct access, and predicate elimination (i.e., transforming the pair of query and database to an equivalent pair without min-predicates). For each task, we establish a complete dichotomy for self-join-free CQs, precisely identifying the cases that are solvable in near-ideal time, i.e., (quasi)linear preprocessing time followed by constant or logarithmic time per output.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19197v1</guid>
      <category>cs.DB</category>
      <category>cs.DS</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nofar Carmeli, Nikolaos Tziavelis</dc:creator>
    </item>
    <item>
      <title>AI for Distributed Systems Design: Scalable Cloud Optimization Through Repeated LLMs Sampling And Simulators</title>
      <link>https://arxiv.org/abs/2510.18897</link>
      <description>arXiv:2510.18897v1 Announce Type: cross 
Abstract: We explore AI-driven distributed-systems policy design by combining stochastic code generation from large language models (LLMs) with deterministic verification in a domain-specific simulator. Using a Function-as-a-Service runtime (Bauplan) and its open-source simulator (Eudoxia) as a case study, we frame scheduler design as an iterative generate-and-verify loop: an LLM proposes a Python policy, the simulator evaluates it on standardized traces, and structured feedback steers subsequent generations. This setup preserves interpretability while enabling targeted search over a large design space. We detail the system architecture and report preliminary results on throughput improvements across multiple models. Beyond early gains, we discuss the limits of the current setup and outline next steps; in particular, we conjecture that AI will be crucial for scaling this methodology by helping to bootstrap new simulators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18897v1</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <category>cs.DB</category>
      <category>cs.SE</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jacopo Tagliabue</dc:creator>
    </item>
    <item>
      <title>An Encode-then-Decompose Approach to Unsupervised Time Series Anomaly Detection on Contaminated Training Data--Extended Version</title>
      <link>https://arxiv.org/abs/2510.18998</link>
      <description>arXiv:2510.18998v1 Announce Type: cross 
Abstract: Time series anomaly detection is important in modern large-scale systems and is applied in a variety of domains to analyze and monitor the operation of diverse systems. Unsupervised approaches have received widespread interest, as they do not require anomaly labels during training, thus avoiding potentially high costs and having wider applications. Among these, autoencoders have received extensive attention. They use reconstruction errors from compressed representations to define anomaly scores. However, representations learned by autoencoders are sensitive to anomalies in training time series, causing reduced accuracy. We propose a novel encode-then-decompose paradigm, where we decompose the encoded representation into stable and auxiliary representations, thereby enhancing the robustness when training with contaminated time series. In addition, we propose a novel mutual information based metric to replace the reconstruction errors for identifying anomalies. Our proposal demonstrates competitive or state-of-the-art performance on eight commonly used multi- and univariate time series benchmarks and exhibits robustness to time series with different contamination ratios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18998v1</guid>
      <category>cs.LG</category>
      <category>cs.DB</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Buang Zhang, Tung Kieu, Xiangfei Qiu, Chenjuan Guo, Jilin Hu, Aoying Zhou, Christian S. Jensen, Bin Yang</dc:creator>
    </item>
    <item>
      <title>Comparative analysis of large data processing in Apache Spark using Java, Python and Scala</title>
      <link>https://arxiv.org/abs/2510.19012</link>
      <description>arXiv:2510.19012v1 Announce Type: cross 
Abstract: During the study, the results of a comparative analysis of the process of handling large datasets using the Apache Spark platform in Java, Python, and Scala programming languages were obtained. Although prior works have focused on individual stages, comprehensive comparisons of full ETL workflows across programming languages using Apache Iceberg remain limited. The analysis was performed by executing several operations, including downloading data from CSV files, transforming and loading it into an Apache Iceberg analytical table. It was found that the performance of the Spark algorithm varies significantly depending on the amount of data and the programming language used. When processing a 5-megabyte CSV file, the best result was achieved in Python: 6.71 seconds, which is superior to Scala's score of 9.13 seconds and Java's time of 9.62 seconds. For processing a large CSV file of 1.6 gigabytes, all programming languages demonstrated similar results: the fastest performance was showed in Python: 46.34 seconds, while Scala and Java showed results of 47.72 and 50.56 seconds, respectively. When performing a more complex operation that involved combining two CSV files into a single dataset for further loading into an Apache Iceberg table, Scala demonstrated the highest performance, at 374.42 seconds. Java processing was completed in 379.8 seconds, while Python was the least efficient, with a runtime of 398.32 seconds. It follows that the programming language significantly affects the efficiency of data processing by the Apache Spark algorithm, with Scala and Java being more productive for processing large amounts of data and complex operations, while Python demonstrates an advantage in working with small amounts of data. The results obtained can be useful for optimizing data handling processes depending on specific performance requirements and the amount of information being processed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19012v1</guid>
      <category>cs.DC</category>
      <category>cs.DB</category>
      <category>cs.PL</category>
      <category>cs.SE</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Ivan Borodii, Illia Fedorovych, Halyna Osukhivska, Diana Velychko, Roman Butsii</dc:creator>
    </item>
    <item>
      <title>Next Generation Cloud-native In-Memory Stores: From Redis to Valkey and Beyond</title>
      <link>https://arxiv.org/abs/2510.19805</link>
      <description>arXiv:2510.19805v1 Announce Type: cross 
Abstract: In-memory key-value datastores have become indispensable building blocks of modern cloud-native infrastructures, yet their evolution faces scalability, compatibility, and sustainability constraints. The current literature lacks an experimental evaluation of state-of-the-art tools in the domain. This study addressed this timely gap by benchmarking Redis alternatives and systematically evaluating Valkey, KeyDB, and Garnet under realistic workloads within Kubernetes deployments. The results demonstrate clear trade-offs among the benchmarked data systems. Our study presents a comprehensive performance and viability assessment of the emerging in-memory key-value stores. Metrics include throughput, tail latency, CPU and memory efficiency, and migration complexity. We highlight trade-offs between performance, compatibility, and long-term viability, including project maturity, community support, and sustained development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19805v1</guid>
      <category>cs.DC</category>
      <category>cs.DB</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Carl-Johan Fauvelle Munck af Rosensch"old, Feras M. Awaysheh, Ahmad Awad</dc:creator>
    </item>
    <item>
      <title>Complexity of Evaluating GQL Queries</title>
      <link>https://arxiv.org/abs/2407.06766</link>
      <description>arXiv:2407.06766v3 Announce Type: replace 
Abstract: GQL has recently emerged as the standard query language over graph databases (particularly, the property graph model). Indeed, this is analogous to the role of SQL for relational databases. Unlike SQL, however, fundamental problems regarding GQL are hitherto still unsolved, most notably the complexity of query evaluation. In this paper we provide a complete solution to this problem. In particular, we show that the data complexity of GQL is $\text{P}^{\text{NP}[\log]}$-complete in general, and is $\text{NL}$-complete, when the so-called ``restrictors'' are disallowed. Using techniques from embedded finite model theory, we show that this is true, even when the queries use data from infinite concrete domains (for example the domain of real numbers where arithmetic is allowed in the query). In proving these results, we establish and exploit tight connections between GQL and query languages over relational databases, especially the extension of relational calculus with transitive closure operators, and a fragment of second-order logic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06766v3</guid>
      <category>cs.DB</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Diego Figueira, Anthony W. Lin, Liat Peterfreund</dc:creator>
    </item>
    <item>
      <title>ZipLLM: Efficient LLM Storage via Model-Aware Synergistic Data Deduplication and Compression</title>
      <link>https://arxiv.org/abs/2505.06252</link>
      <description>arXiv:2505.06252v2 Announce Type: replace 
Abstract: Modern model hubs, such as Hugging Face, store tens of petabytes of LLMs, with fine-tuned variants vastly outnumbering base models and dominating storage consumption. Existing storage reduction techniques -- such as deduplication and compression -- are either LLM-oblivious or not compatible with each other, limiting data reduction effectiveness. Our large-scale characterization study across all publicly available Hugging Face LLM repositories reveals several key insights: (1) fine-tuned models within the same family exhibit highly structured, sparse parameter differences suitable for delta compression; (2) bitwise similarity enables LLM family clustering; and (3) tensor-level deduplication is better aligned with model storage workloads, achieving high data reduction with low metadata overhead. Building on these insights, we design BitX, an effective, fast, lossless delta compression algorithm that compresses XORed difference between fine-tuned and base LLMs. We build ZipLLM, a model storage reduction pipeline that unifies tensor-level deduplication and lossless BitX compression. By synergizing deduplication and compression around LLM family clustering, ZipLLM reduces model storage consumption by 54%, over 20% higher than state-of-the-art deduplication and compression approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06252v2</guid>
      <category>cs.DB</category>
      <category>cs.DC</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zirui Wang, Tingfeng Lan, Zhaoyuan Su, Juncheng Yang, Yue Cheng</dc:creator>
    </item>
    <item>
      <title>Towards an Application-Centric Benchmark Suite for Spatiotemporal Database Systems</title>
      <link>https://arxiv.org/abs/2507.05869</link>
      <description>arXiv:2507.05869v3 Announce Type: replace 
Abstract: Spatiotemporal data play a key role for mobility-based applications and are their produced volume is growing continuously, among others, due to the increased availability of IoT devices.
  When working with spatiotemporal data, developers rely on spatiotemporal database systems such as PostGIS or MobilityDB.
  For better understanding their quality of service behavior and then choosing the best system, benchmarking is the go-to approach.
  Unfortunately, existing work in this field studies only small isolated aspects and a comprehensive application-centric benchmark suite is still missing.
  In this paper, we argue that an application-centric benchmark suite for spatiotemporal database systems is urgently needed.
  We identify requirements for such a benchmark suite, discuss domain-specific challenges, and sketch-out the architecture of a modular benchmarking suite.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.05869v3</guid>
      <category>cs.DB</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/IC2E65552.2025.00016</arxiv:DOI>
      <dc:creator>Tim C. Rese, David Bermbach</dc:creator>
    </item>
    <item>
      <title>TinySQL: A Progressive Text-to-SQL Dataset for Mechanistic Interpretability Research</title>
      <link>https://arxiv.org/abs/2503.12730</link>
      <description>arXiv:2503.12730v5 Announce Type: replace-cross 
Abstract: Mechanistic interpretability research faces a gap between analyzing simple circuits in toy tasks and discovering features in large models. To bridge this gap, we propose text-to-SQL generation as an ideal task to study, as it combines the formal structure of toy tasks with real-world complexity. We introduce TinySQL, a synthetic dataset, progressing from basic to advanced SQL operations, and train models ranging from 33M to 1B parameters to establish a comprehensive testbed for interpretability. We apply multiple complementary interpretability techniques, including Edge Attribution Patching and Sparse Autoencoders, to identify minimal circuits and components supporting SQL generation. We compare circuits for different SQL subskills, evaluating their minimality, reliability, and identifiability. Finally, we conduct a layerwise logit lens analysis to reveal how models compose SQL queries across layers: from intent recognition to schema resolution to structured generation. Our work provides a robust framework for probing and comparing interpretability methods in a structured, progressively complex setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.12730v5</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DB</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Abir Harrasse, Philip Quirke, Clement Neo, Dhruv Nathawani, Luke Marks, Amir Abdullah</dc:creator>
    </item>
    <item>
      <title>Invoice Information Extraction: Methods and Performance Evaluation</title>
      <link>https://arxiv.org/abs/2510.15727</link>
      <description>arXiv:2510.15727v2 Announce Type: replace-cross 
Abstract: This paper presents methods for extracting structured information from invoice documents and proposes a set of evaluation metrics (EM) to assess the accuracy of the extracted data against annotated ground truth. The approach involves pre-processing scanned or digital invoices, applying Docling and LlamaCloud Services to identify and extract key fields such as invoice number, date, total amount, and vendor details. To ensure the reliability of the extraction process, we establish a robust evaluation framework comprising field-level precision, consistency check failures, and exact match accuracy. The proposed metrics provide a standardized way to compare different extraction methods and highlight strengths and weaknesses in field-specific performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.15727v2</guid>
      <category>cs.AI</category>
      <category>cs.DB</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sai Yashwant, Anurag Dubey, Praneeth Paikray, Gantala Thulsiram</dc:creator>
    </item>
  </channel>
</rss>
