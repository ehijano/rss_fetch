<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 21 May 2024 04:00:31 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 21 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Optimization with Temporal and Logical Specifications via Generalized Mean-based Smooth Robustness Measures</title>
      <link>https://arxiv.org/abs/2405.10996</link>
      <description>arXiv:2405.10996v1 Announce Type: new 
Abstract: This paper introduces a generalized mean-based C^1-smooth robustness measure over discrete-time signals (D-GMSR) for signal temporal logic (STL) specifications. In conjunction with its C1-smoothness, D-GMSR is proven to be both sound and complete. Furthermore, it demonstrates favorable gradient properties and addresses locality and masking problems, which are critical for numerical optimization. The C^1-smoothness of the proposed formulations enables the implementation of robust and efficient numerical optimization algorithms to solve problems with STL specifications while preserving their theoretical guarantees. The practical utility of the proposed robustness measure is demonstrated on two real-world trajectory optimization problems: i) quadrotor flight, and ii) autonomous rocket landing. A sequential convex programming (SCP) framework, incorporating a convergence-guaranteed optimization algorithm (the prox-linear method) is used to solve inherently non-convex trajectory optimization problems with STL specifications. The implementation is available at https://github.com/UW-ACL/D-GMSR</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10996v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Samet Uzun, Purnanand Elango, Pierre-Loic Garoche, Behcet Acikmese</dc:creator>
    </item>
    <item>
      <title>New finite relaxation hierarchies for concavo-convex, disjoint bilinear programs, and facial disjunctions</title>
      <link>https://arxiv.org/abs/2405.11068</link>
      <description>arXiv:2405.11068v1 Announce Type: new 
Abstract: We introduce new relaxation hierarchies for facial disjunctive programs (FD) and concavo-convex programs, where the latter class of problems includes disjoint bilinear programming (DBP) and concave minimization (CM) as special cases. Meanwhile, FD restricts that feasible solutions belong to a collection of faces of a Cartesian product of polytopes and generalizes 0-1 programs. We construct these relaxation hierarchies by utilizing rational functions that are barycentric coordinates for polytopes and derive these expressions using the double-description (DD) procedure. The hierarchies, which have geometric and algebraic underpinnings, converge to the convex hull for these problems at a finite level. Our hierarchy provides the first unifying framework to analyze and tighten relaxations from disjunctive programming (DP) and reformulation-linearization technique (RLT) for these problem classes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11068v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohit Tawarmalani</dc:creator>
    </item>
    <item>
      <title>Majorization-minimization Bregman proximal gradient algorithms for nonnegative matrix factorization with the Kullback--Leibler divergence</title>
      <link>https://arxiv.org/abs/2405.11185</link>
      <description>arXiv:2405.11185v1 Announce Type: new 
Abstract: Nonnegative matrix factorization (NMF) is a popular method in machine learning and signal processing to decompose a given nonnegative matrix into two nonnegative matrices. In this paper, to solve NMF, we propose new algorithms, called majorization-minimization Bregman proximal gradient algorithm (MMBPG) and MMBPG with extrapolation (MMBPGe). MMBPG and MMBPGe minimize an auxiliary function majorizing the Kullback--Leibler (KL) divergence loss by the existing Bregman proximal gradient algorithms. While existing KL-based NMF methods update each variable alternately, proposed algorithms update all variables simultaneously. The proposed MMBPG and MMBPGe are equipped with a separable Bregman distance that satisfies the smooth adaptable property and that makes its subproblem solvable in closed forms. We also proved that even though these algorithms are designed to minimize an auxiliary function, MMBPG and MMBPGe monotonically decrease the objective function and a potential function, respectively. Using this fact, we show that a sequence generated by MMBPG(e) globally converges to a Karush--Kuhn--Tucker (KKT) point. In numerical experiments, we compared proposed algorithms with existing algorithms on synthetic data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11185v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shota Takahashi, Mirai Tanaka, Shiro Ikeda</dc:creator>
    </item>
    <item>
      <title>Adaptive Stabilization Based on Machine Learning for Column Generation</title>
      <link>https://arxiv.org/abs/2405.11198</link>
      <description>arXiv:2405.11198v1 Announce Type: new 
Abstract: Column generation (CG) is a well-established method for solving large-scale linear programs. It involves iteratively optimizing a subproblem containing a subset of columns and using its dual solution to generate new columns with negative reduced costs. This process continues until the dual values converge to the optimal dual solution to the original problem. A natural phenomenon in CG is the heavy oscillation of the dual values during iterations, which can lead to a substantial slowdown in the convergence rate. Stabilization techniques are devised to accelerate the convergence of dual values by using information beyond the state of the current subproblem. However, there remains a significant gap in obtaining more accurate dual values at an earlier stage. To further narrow this gap, this paper introduces a novel approach consisting of 1) a machine learning approach for accurate prediction of optimal dual solutions and 2) an adaptive stabilization technique that effectively capitalizes on accurate predictions. On the graph coloring problem, we show that our method achieves a significantly improved convergence rate compared to traditional methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11198v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yunzhuang Shen, Yuan Sun, Xiaodong Li, Zhiguang Cao, Andrew Eberhard, Guangquan Zhang</dc:creator>
    </item>
    <item>
      <title>Stability for Nash Equilibrium Problems</title>
      <link>https://arxiv.org/abs/2405.11266</link>
      <description>arXiv:2405.11266v1 Announce Type: new 
Abstract: This paper is devoted to studying the stability properties of the Karush-Kuhn-Tucker (KKT) solution mapping $S_{\rm KKT}$ for Nash equilibrium problems (NEPs) with canonical perturbations. Firstly, we obtain an exact characterization of the strong regularity of $S_{\rm KKT}$ and a sufficient condition that is easy to verify. Secondly, we propose equivalent conditions for the continuously differentiable single-valued localization of $S_{\rm KKT}$. Thirdly, the isolated calmness of $S_{\rm KKT}$ is studied based on two conditions: Property A and Property B, and Property B proves to be sufficient for the robustness of both $E(p)$ and $S_{\rm KKT}$ under the convex assumptions, where $E(p)$ denotes the Nash equilibria at perturbation $p$. Furthermore, we establish that studying the stability properties of the NEP with canonical perturbations is equivalent to studying those of the NEP with only tilt perturbations based on the prior discussions. Finally, we provide detailed characterizations of stability for NEPs whose each individual player solves a quadratic programming (QP) problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11266v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruoyu Diao, Yu-Hong Dai, Liwei Zhang</dc:creator>
    </item>
    <item>
      <title>A Position Allocation Approach to the Scheduling of Battery-Electric Bus Charging</title>
      <link>https://arxiv.org/abs/2405.11365</link>
      <description>arXiv:2405.11365v1 Announce Type: new 
Abstract: Robust charging schedules in a growing market of battery electric bus (BEB) fleets are a critical component to successful adoption. In this paper, a BEB charging scheduling framework that considers spatiotemporal schedule constraints, route schedules, fast and slow charging, and battery dynamics is modeled as a mixed integer linear program (MILP). The MILP is modeled after the Berth Allocation Problem (BAP) in a modified form known as the Position Allocation Problem (PAP). Linear battery dynamics are included to model the charging of buses while at the station. To model the BEB discharges over their respective routes, it is assumed each BEB has an average kWh charge loss while on route. The optimization coordinates BEB charging to ensure that each vehicle remains above a specified state-of-charge (SOC). The model also minimizes the total number of chargers utilized and prioritizes slow charging for battery health. The model validity is demonstrated with a set of routes sampled from the Utah Transit Authority (UTA) for \A buses and \N visits to the charging station. The model is also compared to a heuristic algorithm based on charge thresholds referred to as the Qin-Modified method. The results presented show that the slow chargers are more readily selected and the charging and spatiotemporal constraints are met while considering the battery dynamics and minimizing both the charger count and consumption cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11365v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Brown, Greg Droge, Jacob Gunther</dc:creator>
    </item>
    <item>
      <title>On the Convergence of Interior-Point Methods for Bound-Constrained Nonlinear Optimization Problems with Noise</title>
      <link>https://arxiv.org/abs/2405.11400</link>
      <description>arXiv:2405.11400v1 Announce Type: new 
Abstract: We analyze the convergence properties of a modified barrier method for solving bound-constrained optimization problems where evaluations of the objective function and its derivatives are affected by bounded and non-diminishing noise. The only modification compared to a standard barrier method is a relaxation of the Armijo line-search condition. We prove that the algorithm generates iterates at which the size of the barrier function gradient eventually falls below a threshold that converges to zero if the noise level converges to zero. Based on this result, we propose a practical stopping test that does not require estimates of unknown problem parameters and identifies iterations in which the theoretical threshold is reached. We also analyze the local convergence properties of the method when noisy second derivatives are used. Under a strict-complementarity assumption, we show that iterates stay in a neighborhood around the optimal solution once it is entered. The neighborhood is defined in a scaled norm that becomes narrower for variables with active bound constraints as the barrier parameter is decreased. As a consequence, we show that active bound constraints can be identified despite noise. Numerical results demonstrate the effectiveness of the stopping test and illustrate the active-set identification properties of the method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11400v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shima Dezfulian, Andreas W\"achter</dc:creator>
    </item>
    <item>
      <title>FESSNC: Fast Exponentially Stable and Safe Neural Controller</title>
      <link>https://arxiv.org/abs/2405.11406</link>
      <description>arXiv:2405.11406v1 Announce Type: new 
Abstract: In order to stabilize nonlinear systems modeled by stochastic differential equations, we design a Fast Exponentially Stable and Safe Neural Controller (FESSNC) for fast learning controllers. Our framework is parameterized by neural networks, and realizing both rigorous exponential stability and safety guarantees. Concretely, we design heuristic methods to learn the exponentially stable and the safe controllers, respectively, in light of the classic stochastic exponential stability theory and our established theorem on guaranteeing the almost-sure safety for stochastic dynamics. More significantly, to rigorously ensure the stability and the safety guarantees for the learned controllers, we develop a projection operator, projecting to the space of exponentially-stable and safe controllers. To reduce the high computation cost of solving the projection operation, approximate projection operators are delicately proposed with closed forms that map the learned controllers to the target controller space. Furthermore, we employ Hutchinson's trace estimator for a scalable unbiased estimate of the Hessian matrix that is used in the projection operator, which thus allows for computation cost reduction and therefore can accelerate the training and testing processes. More importantly, our approximate projection operations can be applied to the nonparametric control methods to improve their stability and safety performance. We empirically demonstrate the superiority of the FESSNC over the existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11406v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jingdong Zhang, Luan Yang, Qunxi Zhu, Wei Lin</dc:creator>
    </item>
    <item>
      <title>First and Second Order Necessary and Sufficient Optimality Conditions of Fritz John Type for Vector Problems over Cones</title>
      <link>https://arxiv.org/abs/2405.11593</link>
      <description>arXiv:2405.11593v1 Announce Type: new 
Abstract: In this paper, we obtain a new proof of Fritz John necessary optimality conditions for vector problems applying Kakutani fixed point theorem and Hadamard directional derivative. We also derive a similar proof of second-order Fritz John necessary optimality conditions. Sufficient conditions for weak global efficiency with generalized convex functions and local efficiency are provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11593v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vsevolod I. Ivanov</dc:creator>
    </item>
    <item>
      <title>Gait controllability of length-changing slender microswimmers</title>
      <link>https://arxiv.org/abs/2405.11961</link>
      <description>arXiv:2405.11961v1 Announce Type: new 
Abstract: Controllability results of four models of two-link microscale swimmers that are able to change the length of their links are obtained. The problems are formulated in the framework of Geometric Control Theory, within which the notions of fiber, total, and gait controllability are presented, together with sufficient conditions for the latter two. The dynamics of a general two-link swimmer is described by resorting to Resistive Force Theory and different mechanisms to produce a length-change in the links, namely, active deformation, a sliding hinge, growth at the tip, and telescopic links. Total controllability is proved via gait controllability in all four cases, and illustrated with the aid of numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11961v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paolo Gidoni, Marco Morandotti, Marta Zoppello</dc:creator>
    </item>
    <item>
      <title>Structured singular values and their application in computing eigenvalue backward errors of the Rosenbrock system matrix</title>
      <link>https://arxiv.org/abs/2405.11974</link>
      <description>arXiv:2405.11974v1 Announce Type: new 
Abstract: The structured singular values (aka the {\mu}-values) are essential in analyzing the stability of control systems and in the structured eigenvalue perturbation theory of matrices and matrix polynomials. In this paper, we study the {\mu}-value of a matrix under block-diagonal structured perturbations (full blocks but possibly rectangular). We provide an explicit expression for the {\mu}-value and also obtain a computable upper bound in terms of minimizing the largest singular value of a parameter-dependent matrix. This upper bound equals the {\mu}-value when the perturbation matrix has no more than three blocks on the diagonal. We then apply the {\mu}-value results in computing eigenvalue backward errors of a Rosenbrock system matrix corresponding to a rational matrix function when some or all blocks of the Rosenbrock system matrix are subject to perturbation. The results are illustrated through numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11974v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anshul Prajapati, Punit Sharma</dc:creator>
    </item>
    <item>
      <title>Multi-Agent Optimization and Learning: A Non-Expansive Operators Perspective</title>
      <link>https://arxiv.org/abs/2405.11999</link>
      <description>arXiv:2405.11999v1 Announce Type: new 
Abstract: Multi-agent systems are increasingly widespread in a range of application domains, with optimization and learning underpinning many of the tasks that arise in this context. Different approaches have been proposed to enable the cooperative solution of these optimization and learning problems, including first- and second-order methods, and dual (or Lagrangian) methods, all of which rely on consensus and message-passing. In this article we discuss these algorithms through the lens of non-expansive operator theory, providing a unifying perspective. We highlight the insights that this viewpoint delivers, and discuss how it can spark future original research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11999v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicola Bastianello, Luca Schenato, Ruggero Carli</dc:creator>
    </item>
    <item>
      <title>Randomized Gradient Descents on Riemannian Manifolds: Almost Sure Convergence to Global Minima in and beyond Quantum Optimization</title>
      <link>https://arxiv.org/abs/2405.12039</link>
      <description>arXiv:2405.12039v1 Announce Type: new 
Abstract: We analyze the convergence properties of gradient descent algorithms on Riemannian manifolds. We study randomization of the tangent space directions of Riemannian gradient flows for minimizing smooth cost functions (of Morse--Bott type) to obtain convergence to local optima. We prove that through randomly projecting Riemannian gradients according to the Haar measure, convergence to local optima can be obtained almost surely despite the existence of saddle points. As an application we consider ground state preparation through quantum optimization over the unitary group. In this setting one can efficiently approximate the Haar-random projections by implementing unitary 2-designs on quantum computers. We prove that the respective algorithm almost surely converges to the global minimum that corresponds to the ground state of a desired Hamiltonian. Finally, we discuss the time required by the algorithm to pass a saddle point in a simple two-dimensional setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12039v1</guid>
      <category>math.OC</category>
      <category>quant-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Emanuel Malvetti, Christian Arenz, Gunther Dirr, Thomas Schulte-Herbr\"uggen</dc:creator>
    </item>
    <item>
      <title>Reconstruction of unknown nonlinear operators in semilinear elliptic models using optimal inputs</title>
      <link>https://arxiv.org/abs/2405.12153</link>
      <description>arXiv:2405.12153v1 Announce Type: new 
Abstract: Physical models often contain unknown functions and relations. The goal of our work is to answer the question of how one should excite or control a system under consideration in an appropriate way to be able to reconstruct an unknown nonlinear relation. To answer this question, we propose a greedy reconstruction algorithm within an offline-online strategy. We apply this strategy to a two-dimensional semilinear elliptic model. Our identification is based on the application of several space-dependent excitations (also called controls). These specific controls are designed by the algorithm in order to obtain a deeper insight into the underlying physical problem and a more precise reconstruction of the unknown relation. We perform numerical simulations that demonstrate the effectiveness of our approach which is not limited to the current type of equation. Since our algorithm provides not only a way to determine unknown operators by existing data but also protocols for new experiments, it is a holistic concept to tackle the problem of improving physical models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12153v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Jan Bartsch, Simon Buchwald, Gabriele Ciaramella, Stefan Volkwein</dc:creator>
    </item>
    <item>
      <title>What are You Weighting For? Improved Weights for Gaussian Mixture Filtering With Application to Cislunar Orbit Determination</title>
      <link>https://arxiv.org/abs/2405.11081</link>
      <description>arXiv:2405.11081v1 Announce Type: cross 
Abstract: This work focuses on the critical aspect of accurate weight computation during the measurement incorporation phase of Gaussian mixture filters. The proposed novel approach computes weights by linearizing the measurement model about each component's posterior estimate rather than the the prior, as traditionally done. This work proves equivalence with traditional methods for linear models, provides novel sigma-point extensions to the traditional and proposed methods, and empirically demonstrates improved performance in nonlinear cases. Two illustrative examples, the Avocado and a cislunar single target tracking scenario, serve to highlight the advantages of the new weight computation technique by analyzing filter accuracy and consistency through varying the number of Gaussian mixture components.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11081v1</guid>
      <category>stat.ME</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dalton Durant, Andrey A. Popov, Renato Zanetti</dc:creator>
    </item>
    <item>
      <title>Flattened one-bit stochastic gradient descent: compressed distributed optimization with controlled variance</title>
      <link>https://arxiv.org/abs/2405.11095</link>
      <description>arXiv:2405.11095v1 Announce Type: cross 
Abstract: We propose a novel algorithm for distributed stochastic gradient descent (SGD) with compressed gradient communication in the parameter-server framework. Our gradient compression technique, named flattened one-bit stochastic gradient descent (FO-SGD), relies on two simple algorithmic ideas: (i) a one-bit quantization procedure leveraging the technique of dithering, and (ii) a randomized fast Walsh-Hadamard transform to flatten the stochastic gradient before quantization. As a result, the approximation of the true gradient in this scheme is biased, but it prevents commonly encountered algorithmic problems, such as exploding variance in the one-bit compression regime, deterioration of performance in the case of sparse gradients, and restrictive assumptions on the distribution of the stochastic gradients. In fact, we show SGD-like convergence guarantees under mild conditions. The compression technique can be used in both directions of worker-server communication, therefore admitting distributed optimization with full communication compression.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11095v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Stollenwerk, Laurent Jacques</dc:creator>
    </item>
    <item>
      <title>PDE Control Gym: A Benchmark for Data-Driven Boundary Control of Partial Differential Equations</title>
      <link>https://arxiv.org/abs/2405.11401</link>
      <description>arXiv:2405.11401v1 Announce Type: cross 
Abstract: Over the last decade, data-driven methods have surged in popularity, emerging as valuable tools for control theory. As such, neural network approximations of control feedback laws, system dynamics, and even Lyapunov functions have attracted growing attention. With the ascent of learning based control, the need for accurate, fast, and easy-to-use benchmarks has increased. In this work, we present the first learning-based environment for boundary control of PDEs. In our benchmark, we introduce three foundational PDE problems - a 1D transport PDE, a 1D reaction-diffusion PDE, and a 2D Navier-Stokes PDE - whose solvers are bundled in an user-friendly reinforcement learning gym. With this gym, we then present the first set of model-free, reinforcement learning algorithms for solving this series of benchmark problems, achieving stability, although at a higher cost compared to model-based PDE backstepping. With the set of benchmark environments and detailed examples, this work significantly lowers the barrier to entry for learning-based PDE control - a topic largely unexplored by the data-driven control community. The entire benchmark is available on Github along with detailed documentation and the presented reinforcement learning models are open sourced.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11401v1</guid>
      <category>eess.SY</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luke Bhan, Yuexin Bian, Miroslav Krstic, Yuanyuan Shi</dc:creator>
    </item>
    <item>
      <title>Quantum Neural Networks for Solving Power System Transient Simulation Problem</title>
      <link>https://arxiv.org/abs/2405.11427</link>
      <description>arXiv:2405.11427v1 Announce Type: cross 
Abstract: Quantum computing, leveraging principles of quantum mechanics, represents a transformative approach in computational methodologies, offering significant enhancements over traditional classical systems. This study tackles the complex and computationally demanding task of simulating power system transients through solving differential algebraic equations (DAEs). We introduce two novel Quantum Neural Networks (QNNs): the Sinusoidal-Friendly QNN and the Polynomial-Friendly QNN, proposing them as effective alternatives to conventional simulation techniques. Our application of these QNNs successfully simulates two small power systems, demonstrating their potential to achieve good accuracy. We further explore various configurations, including time intervals, training points, and the selection of classical optimizers, to optimize the solving of DAEs using QNNs. This research not only marks a pioneering effort in applying quantum computing to power system simulations but also expands the potential of quantum technologies in addressing intricate engineering challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11427v1</guid>
      <category>quant-ph</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammadreza Soltaninia, Junpeng Zhan</dc:creator>
    </item>
    <item>
      <title>Comparisons Are All You Need for Optimizing Smooth Functions</title>
      <link>https://arxiv.org/abs/2405.11454</link>
      <description>arXiv:2405.11454v1 Announce Type: cross 
Abstract: When optimizing machine learning models, there are various scenarios where gradient computations are challenging or even infeasible. Furthermore, in reinforcement learning (RL), preference-based RL that only compares between options has wide applications, including reinforcement learning with human feedback in large language models. In this paper, we systematically study optimization of a smooth function $f\colon\mathbb{R}^n\to\mathbb{R}$ only assuming an oracle that compares function values at two points and tells which is larger. When $f$ is convex, we give two algorithms using $\tilde{O}(n/\epsilon)$ and $\tilde{O}(n^{2})$ comparison queries to find an $\epsilon$-optimal solution, respectively. When $f$ is nonconvex, our algorithm uses $\tilde{O}(n/\epsilon^2)$ comparison queries to find an $\epsilon$-approximate stationary point. All these results match the best-known zeroth-order algorithms with function evaluation queries in $n$ dependence, thus suggest that \emph{comparisons are all you need for optimizing smooth functions using derivative-free methods}. In addition, we also give an algorithm for escaping saddle points and reaching an $\epsilon$-second order stationary point of a nonconvex $f$, using $\tilde{O}(n^{1.5}/\epsilon^{2.5})$ comparison queries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11454v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chenyi Zhang, Tongyang Li</dc:creator>
    </item>
    <item>
      <title>Global Convergence of Decentralized Retraction-Free Optimization on the Stiefel Manifold</title>
      <link>https://arxiv.org/abs/2405.11590</link>
      <description>arXiv:2405.11590v1 Announce Type: cross 
Abstract: Many classical and modern machine learning algorithms require solving optimization tasks under orthogonal constraints. Solving these tasks often require calculating retraction-based gradient descent updates on the corresponding Riemannian manifold, which can be computationally expensive. Recently Ablin et al. proposed an infeasible retraction-free algorithm, which is significantly more efficient. In this paper, we study the decentralized non-convex optimization task over a network of agents on the Stiefel manifold with retraction-free updates. We propose \textbf{D}ecentralized \textbf{R}etraction-\textbf{F}ree \textbf{G}radient \textbf{T}racking (DRFGT) algorithm, and show that DRFGT exhibits ergodic $\mathcal{O}(1/K)$ convergence rate, the same rate of convergence as the centralized, retraction-based methods. We also provide numerical experiments demonstrating that DRFGT performs on par with the state-of-the-art retraction based methods with substantially reduced computational overhead.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11590v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Youbang Sun, Shixiang Chen, Alfredo Garcia, Shahin Shahrampour</dc:creator>
    </item>
    <item>
      <title>The Limits and Potentials of Local SGD for Distributed Heterogeneous Learning with Intermittent Communication</title>
      <link>https://arxiv.org/abs/2405.11667</link>
      <description>arXiv:2405.11667v1 Announce Type: cross 
Abstract: Local SGD is a popular optimization method in distributed learning, often outperforming other algorithms in practice, including mini-batch SGD. Despite this success, theoretically proving the dominance of local SGD in settings with reasonable data heterogeneity has been difficult, creating a significant gap between theory and practice. In this paper, we provide new lower bounds for local SGD under existing first-order data heterogeneity assumptions, showing that these assumptions are insufficient to prove the effectiveness of local update steps. Furthermore, under these same assumptions, we demonstrate the min-max optimality of accelerated mini-batch SGD, which fully resolves our understanding of distributed optimization for several problem classes. Our results emphasize the need for better models of data heterogeneity to understand the effectiveness of local SGD in practice. Towards this end, we consider higher-order smoothness and heterogeneity assumptions, providing new upper bounds that imply the dominance of local SGD over mini-batch SGD when data heterogeneity is low.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11667v1</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kumar Kshitij Patel, Margalit Glasgow, Ali Zindari, Lingxiao Wang, Sebastian U. Stich, Ziheng Cheng, Nirmit Joshi, Nathan Srebro</dc:creator>
    </item>
    <item>
      <title>Goal-Oriented Communication for Networked Control Assisted by Reconfigurable Meta-Surfaces</title>
      <link>https://arxiv.org/abs/2405.12073</link>
      <description>arXiv:2405.12073v1 Announce Type: cross 
Abstract: In this paper, we develop a theoretical framework for goal-oriented communication assisted by reconfigurable meta-surfaces in the context of networked control systems. The relation to goal-oriented communication stems from the fact that optimization of the phase shifts of the meta-surfaces is guided by the performance of networked control systems tasks. To that end, we consider a networked control system in which a set of sensors observe the states of a set of physical processes, and communicate this information over an unreliable wireless channel assisted by a reconfigurable intelligent surface with multiple reflecting elements to a set of controllers that correct the behaviors of the physical processes based on the received information. Our objective is to find the optimal control policy for the controllers and the optimal phase policy for the reconfigurable intelligent surface that jointly minimize a regulation cost function associated with the networked control system. We characterize these policies, and also propose an approximate solution based on a semi-definite relaxation technique.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12073v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohamad Assaad, Touraj Soleymani</dc:creator>
    </item>
    <item>
      <title>Properties of Eventually Positive Linear Input-Output Systems</title>
      <link>https://arxiv.org/abs/1509.08392</link>
      <description>arXiv:1509.08392v3 Announce Type: replace 
Abstract: In this paper, we consider the systems with trajectories originating in the nonnegative orthant becoming nonnegative after some finite time transient. First we consider dynamical systems (i.e., fully observable systems with no inputs), which we call eventually positive. We compute forward-invariant cones and Lyapunov functions for these systems. We then extend the notion of eventually positive systems to the input-output system case. Our extension is performed in such a manner, that some valuable properties of classical internally positive input-output systems are preserved. For example, their induced norms can be computed using linear programming and the energy functions have nonnegative derivatives.</description>
      <guid isPermaLink="false">oai:arXiv.org:1509.08392v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aivar Sootla</dc:creator>
    </item>
    <item>
      <title>Deepest Cuts for Benders Decomposition</title>
      <link>https://arxiv.org/abs/2110.08448</link>
      <description>arXiv:2110.08448v2 Announce Type: replace 
Abstract: Since its inception, Benders Decomposition (BD) has been successfully applied to a wide range of large-scale mixed-integer (linear) problems. The key element of BD is the derivation of Benders cuts, which are often not unique. In this paper, we introduce a novel unifying Benders cut selection technique based on a geometric interpretation of cut ``depth'', produce deepest Benders cuts based on $\ell_p$-norms, and study their properties. Specifically, we show that deepest cuts resolve infeasibility through minimal deviation (in a distance sense) from the incumbent point, are relatively sparse, and may produce optimality cuts even when classical Benders would require a feasibility cut. Leveraging the duality between separation and projection, we develop a Guided Projections Algorithm for producing deepest cuts while exploiting the combinatorial structure and decomposability of problem instances. We then propose a generalization of our Benders separation problem, which not only brings several well-known cut selection strategies under one umbrella, but also, when endowed with a homogeneous function, enjoys several properties of geometric separation problems. We show that, when the homogeneous function is linear, the separation problem takes the form of the Minimal Infeasible Subsystems (MIS) problem. As such, we provide systematic ways of selecting the normalization coefficients of the MIS method, and introduce a Directed Depth-Maximizing Algorithm for deriving these cuts. Inspired by the geometric interpretation of distance-based cuts and the repetitive nature of two-stage stochastic programs, we introduce a tailored algorithm to further facilitate deriving these cuts. Our computational experiments on various benchmark problems illustrate effectiveness of deepest cuts in reducing both computation time and number of Benders iterations, and producing high quality bounds at early iterations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2110.08448v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mojtaba Hosseini, John Turner</dc:creator>
    </item>
    <item>
      <title>Semidefinite games</title>
      <link>https://arxiv.org/abs/2202.12035</link>
      <description>arXiv:2202.12035v3 Announce Type: replace 
Abstract: We introduce and study the class of semidefinite games, which generalizes bimatrix games and finite $N$-person games, by replacing the simplex of the mixed strategies for each player by a slice of the positive semidefinite cone in the space of real symmetric matrices.
  For semidefinite two-player zero-sum games, we show that the optimal strategies can be computed by semidefinite programming. Furthermore, we show that two-player semidefinite zero-sum games are almost equivalent to semidefinite programming, generalizing Dantzig's result on the almost equivalence of bimatrix games and linear programming.
  For general two-player semidefinite games, we prove a spectrahedral characterization of the Nash equilibria. Moreover, we give constructions of semidefinite games with many Nash equilibria. In particular, we give a construction of semidefinite games whose number of connected components of Nash equilibria exceeds the long standing best known construction for many Nash equilibria in bimatrix games, which was presented by von Stengel in 1999.</description>
      <guid isPermaLink="false">oai:arXiv.org:2202.12035v3</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Constantin Ickstadt, Thorsten Theobald, Elias Tsigaridas</dc:creator>
    </item>
    <item>
      <title>Probability Contour Constrained Optimization and A Data-based Solution Paradigm</title>
      <link>https://arxiv.org/abs/2209.01119</link>
      <description>arXiv:2209.01119v2 Announce Type: replace 
Abstract: This paper solves a new class of optimization problems under uncertainty which optimizes an objective function of decision variables and subjects to a set of probability contour constraints (PCC). The proposed PCC logically means that an optimal solution should satisfy a set of algebraic constraints for all possible high-probability realizations of the uncertain parameters. The PCC is an alternative to the conventional chance constraint while the latter cannot guarantee the solution's feasibility to high-probability realizations of uncertainty. Given that the existing solution methods of the conventional chance-constrained optimization are not suitable for solving the proposed probability contour constrained optimization (PCCO), we develop a novel data-based solution paradigm that uses historical measurements of the uncertain parameters as input samples. This solution paradigm is conceptually simple and allows us to develop effective data-reduction schemes which reduces computational burden while reserves high accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.01119v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qifeng Li</dc:creator>
    </item>
    <item>
      <title>On the continuity assumption of "Finite Adaptability in Multistage Linear Optimization'' by Bertsimas and Caramanis</title>
      <link>https://arxiv.org/abs/2305.05399</link>
      <description>arXiv:2305.05399v2 Announce Type: replace 
Abstract: Two-stage robust optimization is a fundamental paradigm for modeling and solving optimization problems with uncertain parameters. A now classical method within this paradigm is finite-adaptability, introduced by Bertsimas and Caramanis (IEEE Transactions on Automatic Control, 2010). In this note, we point out that the continuity assumption they stated to ensure the convergence of the method is not correct, and we propose an alternative assumption for which we prove the desired convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.05399v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Safia Kedad-Sidhoum, Anton Medvedev, Fr\'ed\'eric Meunier</dc:creator>
    </item>
    <item>
      <title>On the connections between optimization algorithms, Lyapunov functions, and differential equations: theory and insights</title>
      <link>https://arxiv.org/abs/2305.08658</link>
      <description>arXiv:2305.08658v3 Announce Type: replace 
Abstract: We revisit the general framework introduced by Fazylab et al. (SIAM J. Optim. 28, 2018) to construct Lyapunov functions for optimization algorithms in discrete and continuous time. For smooth, strongly convex objective functions, we relax the requirements necessary for such a construction. As a result we are able to prove for Polyak's ordinary differential equations and for a two-parameter family of Nesterov algorithms rates of convergence that improve on those available in the literature. We analyse the interpretation of Nesterov algorithms as discretizations of the Polyak equation. We show that the algorithms are instances of Additive Runge-Kutta integrators and discuss the reasons why most discretizations of the differential equation do not result in optimization algorithms with acceleration. We also introduce a modification of Polyak's equation and study its convergence properties. Finally we extend the general framework to the stochastic scenario and consider an application to random algorithms with acceleration for overparameterized models; again we are able to prove convergence rates that improve on those in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.08658v3</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paul Dobson, Jesus Maria Sanz-Serna, Konstantinos Zygalakis</dc:creator>
    </item>
    <item>
      <title>On solving a rank regularized minimization problem via equivalent factorized column-sparse regularized models</title>
      <link>https://arxiv.org/abs/2308.16690</link>
      <description>arXiv:2308.16690v2 Announce Type: replace 
Abstract: Rank regularized minimization problem is an ideal model for the low-rank matrix completion/recovery problem. The matrix factorization approach can transform the high-dimensional rank regularized problem to a low-dimensional factorized column-sparse regularized problem. The latter can greatly facilitate fast computations in applicable algorithms, but needs to overcome the simultaneous non-convexity of the loss and regularization functions. In this paper, we consider the factorized column-sparse regularized model. Firstly, we optimize this model with bound constraints, and establish a certain equivalence between the optimized factorization problem and rank regularized problem. Further, we strengthen the optimality condition for stationary points of the factorization problem and define the notion of strong stationary point. Moreover, we establish the equivalence between the factorization problem and its a nonconvex relaxation in the sense of global minimizers and strong stationary points. To solve the factorization problem, we design two types of algorithms and give an adaptive method to reduce their computation. The first algorithm is from the relaxation point of view and its iterates own some properties from global minimizers of the factorization problem after finite iterations. We give some analysis on the convergence of its iterates to the strong stationary point. The second algorithm is designed for directly solving the factorization problem. We improve the PALM algorithm introduced by Bolte et al. (Math Program Ser A 146:459-494, 2014) for the factorization problem and give its improved convergence results. Finally, we conduct numerical experiments to show the promising performance of the proposed model and algorithms for low-rank matrix completion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.16690v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenjing Li, Wei Bian, Kim-Chuan Toh</dc:creator>
    </item>
    <item>
      <title>A Safe First-Order Method for Pricing-Based Resource Allocation in Safety-Critical Networks</title>
      <link>https://arxiv.org/abs/2310.03808</link>
      <description>arXiv:2310.03808v2 Announce Type: replace 
Abstract: We introduce a novel algorithm for solving network utility maximization (NUM) problems that arise in resource allocation schemes over networks with known safety-critical constraints, where the constraints form an arbitrary convex and compact feasible set. Inspired by applications where customers' demand can only be affected through posted prices and real-time two-way communication with customers is not available, we require an algorithm to generate ``safe prices''. This means that at no iteration should the realized demand in response to the posted prices violate the safety constraints of the network. Thus, in contrast to existing distributed first-order methods, our algorithm, called safe pricing for NUM (SPNUM), is guaranteed to produce feasible primal iterates at all iterations. At the heart of the algorithm lie two key steps that must go hand in hand to guarantee safety and convergence: 1) applying a projected gradient method on a shrunk feasible set to get the desired demand, and 2) estimating the price response function of the users and determining the price so that the induced demand is close to the desired demand. We ensure safety by adjusting the shrinkage to account for the error between the induced demand and the desired demand. In addition, by gradually reducing the amount of shrinkage and the step size of the gradient method, we prove that the primal iterates produced by the SPNUM achieve a sublinear static regret of ${\cal O}(\log{(T)})$ after $T$ time steps.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.03808v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Berkay Turan, Spencer Hutchinson, Mahnoosh Alizadeh</dc:creator>
    </item>
    <item>
      <title>Integral Resolvent and Proximal Mixtures</title>
      <link>https://arxiv.org/abs/2311.04790</link>
      <description>arXiv:2311.04790v2 Announce Type: replace 
Abstract: Using the theory of Hilbert direct integrals, we introduce and study a monotonicity-preserving operation, termed the integral resolvent mixture. It combines arbitrary families of monotone operators acting on different spaces and linear operators. As a special case, we investigate the resolvent expectation, an operation which combines monotone operators in such a way that the resulting resolvent is the Lebesgue expectation of the individual resolvents. Along the same lines, we introduce an operation that mixes arbitrary families of convex functions defined on different spaces and linear operators to create a composite convex function. Such constructs have so far been limited to finite families of operators and functions. The subdifferential of the integral proximal mixture is shown to be the integral resolvent mixture of the individual subdifferentials. Applications to the relaxation of systems of composite monotone inclusions are presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.04790v2</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Minh N. B\`ui, Patrick L. Combettes</dc:creator>
    </item>
    <item>
      <title>Metric Entropy-Free Sample Complexity Bounds for Sample Average Approximation in Convex Stochastic Programming</title>
      <link>https://arxiv.org/abs/2401.00664</link>
      <description>arXiv:2401.00664v2 Announce Type: replace 
Abstract: This paper studies the sample average approximation (SAA) in solving convex or strongly convex stochastic programming problems. Under some common regularity conditions, we show -- perhaps for the first time -- that the SAA's sample complexity can be completely free from any quantification of metric entropy (such as the logarithm of the covering number), leading to a significantly more efficient rate with dimensionality $d$ than most existing results. From the newly established complexity bounds, an important revelation is that the SAA and the canonical stochastic mirror descent (SMD) method, two mainstream solution approaches to SP, entail almost identical rates of sample efficiency, rectifying a long-standing theoretical discrepancy of the SAA from the SMD by the order of $O(d)$. Furthermore, this paper explores non-Lipschitzian scenarios where the SAA maintains provable efficacy, whereas corresponding results for the SMD remain unexplored, indicating the potential of the SAA's better applicability in some irregular settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.00664v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hongcheng Liu, Jindong Tong</dc:creator>
    </item>
    <item>
      <title>A multi-objective optimization framework for reducing the impact of ship noise on marine mammals</title>
      <link>https://arxiv.org/abs/2402.02647</link>
      <description>arXiv:2402.02647v2 Announce Type: replace 
Abstract: The underwater radiated noise (URN) emanating from ships presents a significant threat to marine mammals, given their heavy reliance on hearing for essential life activities. The intensity of URN from ships is directly correlated to the speed, making speed reduction a crucial operational mitigation strategy. This paper presents a new multi-objective optimization framework to optimize the ship speed for effective URN mitigation without compromising fuel consumption. The proposed framework addresses a fixed-path voyage scheduling problem, incorporating two objective functions namely (i) noise intensity levels and (ii) fuel consumption. The optimization is performed using the state-of-the-art non-dominated sorting genetic algorithm under voyage constraints. A 2D ocean acoustic environment, comprising randomly scattered marine mammals of diverse audiogram groups and realistic conditions, including sound speed profiles and bathymetry, is simulated. To estimate the objective functions, we consider empirical relations for fuel consumption and near-field noise modeling together with a ray-tracing approach for far-field noise propagation. The optimization problem is solved using the genetic algorithm to determine the Pareto solutions and subsequently the trade-off solution. The effectiveness of the optimization framework is demonstrated via both simplified tests and practical case studies involving a large container ship. A comparative analysis illustrates the adaptability of the optimization framework across different oceanic environments, affirming its potential as a robust tool for reducing the URN from shipping.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.02647v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Akash Venkateshwaran, Indu Kant Deo, Jasmin Jelovica, Rajeev K. Jaiman</dc:creator>
    </item>
    <item>
      <title>Deep Reinforcement Learning: A Convex Optimization Approach</title>
      <link>https://arxiv.org/abs/2402.19212</link>
      <description>arXiv:2402.19212v5 Announce Type: replace 
Abstract: In this paper, we consider reinforcement learning of nonlinear systems with continuous state and action spaces. We present an episodic learning algorithm, where we for each episode use convex optimization to find a two-layer neural network approximation of the optimal $Q$-function. The convex optimization approach guarantees that the weights calculated at each episode are optimal, with respect to the given sampled states and actions of the current episode. For stable nonlinear systems, we show that the algorithm converges and that the converging parameters of the trained neural network can be made arbitrarily close to the optimal neural network parameters. In particular, if the regularization parameter in the training phase is given by $\rho$, then the parameters of the trained neural network converge to $w$, where the distance between $w$ and the optimal parameters $w^\star$ is bounded by $\mathcal{O}(\rho)$. That is, when the number of episodes goes to infinity, there exists a constant $C$ such that \[
  \|w-w^\star\| \le C\rho. \] 
  In particular, our algorithm converges arbitrarily close to the optimal neural network parameters as the regularization parameter goes to zero. As a consequence, our algorithm converges fast due to the polynomial-time convergence of convex optimization algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.19212v5</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ather Gattami</dc:creator>
    </item>
    <item>
      <title>Joint Chance Constrained Optimal Control via Linear Programming</title>
      <link>https://arxiv.org/abs/2402.19360</link>
      <description>arXiv:2402.19360v2 Announce Type: replace 
Abstract: We establish a linear programming formulation for the solution of joint chance constrained optimal control problems over finite time horizons. The joint chance constraint may represent an invariance, reachability or reach-avoid specification that the trajectory must satisfy with a predefined probability. For finite state and action spaces, the solution is exact and our method computationally superior to approaches in the literature. For continuous state or action spaces, our linear programming formulation enables basis function approximations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.19360v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Niklas Schmid, Marta Fochesato, Tobias Sutter, John Lygeros</dc:creator>
    </item>
    <item>
      <title>Data-Driven Superstabilizing Control under Quadratically-Bounded Errors-in-Variables Noise</title>
      <link>https://arxiv.org/abs/2403.03624</link>
      <description>arXiv:2403.03624v2 Announce Type: replace 
Abstract: The Error-in-Variables model of system identification/control involves nontrivial input and measurement corruption of observed data, resulting in generically nonconvex optimization problems. This paper performs full-state-feedback stabilizing control of all discrete-time linear systems that are consistent with observed data for which the input and measurement noise obey quadratic bounds. Instances of such quadratic bounds include elementwise norm bounds (at each time sample), energy bounds (across the entire signal), and chance constraints arising from (sub)gaussian noise. Superstabilizing controllers are generated through the solution of a sum-of-squares hierarchy of semidefinite programs. A theorem of alternatives is employed to eliminate the input and measurement noise process, thus improving tractability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.03624v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jared Miller, Tianyu Dai, Mario Sznaier</dc:creator>
    </item>
    <item>
      <title>Robust pointwise second order necessary conditions for singular stochastic optimal control with model uncertainty</title>
      <link>https://arxiv.org/abs/2403.15703</link>
      <description>arXiv:2403.15703v2 Announce Type: replace 
Abstract: We study the singular stochastic optimal control problem with model uncertainty, where the necessary conditions determined by the corresponding maximum principle are trivial. Robust integral form and pointwise second order necessary optimality conditions under certain compactness conditions are derived. Both the drift and diffusion terms are control dependent but the control region are assumed to be convex. The convex variational method is employed, because linear structure is essential in deriving the weak limit of uncertainty measures. Other main technical ingredients in obtaining the integral type conditions are compact analysis and minimax theorem, while for the pointwise ones it is Clark-Ocone formula and Lebesgue differentiation type theorem. Besides, a compendious example is given to illustrate the motivation and effectiveness of the results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15703v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guangdong Jing</dc:creator>
    </item>
    <item>
      <title>Convex Network Flows</title>
      <link>https://arxiv.org/abs/2404.00765</link>
      <description>arXiv:2404.00765v2 Announce Type: replace 
Abstract: We introduce a general framework for flow problems over hypergraphs. In our problem formulation, which we call the convex flow problem, we have a concave utility function for the net flow at every node and a concave utility function for each edge flow. The objective is to maximize the sum of these utilities, subject to constraints on the flows allowed at each edge, which we only assume to be a convex set. This framework not only includes many classic problems in network optimization, such as max flow, min-cost flow, and multi-commodity flows, but also generalizes these problems to allow, for example, concave edge gain functions. In addition, our framework includes applications spanning a number of fields: optimal power flow over lossy networks, routing and resource allocation in ad-hoc wireless networks, Arrow-Debreu Nash bargaining, and order routing through financial exchanges, among others. We show that the convex flow problem has a dual with a number of interesting interpretations, and that this dual decomposes over the edges of the hypergraph. Using this decomposition, we propose a fast solution algorithm that parallelizes over the edges and admits a clean problem interface. We provide an open source implementation of this algorithm in the Julia programming language, which we show is significantly faster than the state-of-the-art commercial convex solver Mosek.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00765v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Theo Diamandis, Guillermo Angeris, Alan Edelman</dc:creator>
    </item>
    <item>
      <title>Polynomial Optimization Over Unions of Sets</title>
      <link>https://arxiv.org/abs/2404.17717</link>
      <description>arXiv:2404.17717v2 Announce Type: replace 
Abstract: This paper studies the polynomial optimization problem whose feasible set is a union of several basic closed semialgebraic sets. We propose a unified hierarchy of Moment-SOS relaxations to solve it globally. Under some assumptions, we prove the asymptotic or finite convergence of the unified hierarchy. Special properties for the univariate case are discussed.The application for computing $(p,q)$-norms of matrices is also presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17717v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiawang Nie, Linghao Zhang</dc:creator>
    </item>
    <item>
      <title>Decision Machines: An Extension of Decision Trees</title>
      <link>https://arxiv.org/abs/2101.11347</link>
      <description>arXiv:2101.11347v3 Announce Type: replace-cross 
Abstract: Here is a compact representation of binary decision trees. %to overcome these deficiencies. We explicitly formulate the dependence of prediction on binary tests for binary trees and construct a procedure to guide the input sample from the root to the leaf node. And we interpret decision tree as a model combination method. Then we approximate this formulation via continuous functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2101.11347v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jinxiong Zhang</dc:creator>
    </item>
    <item>
      <title>Blessings and Curses of Covariate Shifts: Adversarial Learning Dynamics, Directional Convergence, and Equilibria</title>
      <link>https://arxiv.org/abs/2212.02457</link>
      <description>arXiv:2212.02457v3 Announce Type: replace-cross 
Abstract: Covariate distribution shifts and adversarial perturbations present robustness challenges to the conventional statistical learning framework: mild shifts in the test covariate distribution can significantly affect the performance of the statistical model learned based on the training distribution. The model performance typically deteriorates when extrapolation happens: namely, covariates shift to a region where the training distribution is scarce, and naturally, the learned model has little information. For robustness and regularization considerations, adversarial perturbation techniques are proposed as a remedy; however, careful study needs to be carried out about what extrapolation region adversarial covariate shift will focus on, given a learned model. This paper precisely characterizes the extrapolation region, examining both regression and classification in an infinite-dimensional setting. We study the implications of adversarial covariate shifts to subsequent learning of the equilibrium -- the Bayes optimal model -- in a sequential game framework. We exploit the dynamics of the adversarial learning game and reveal the curious effects of the covariate shift to equilibrium learning and experimental design. In particular, we establish two directional convergence results that exhibit distinctive phenomena: (1) a blessing in regression, the adversarial covariate shifts in an exponential rate to an optimal experimental design for rapid subsequent learning; (2) a curse in classification, the adversarial covariate shifts in a subquadratic rate to the hardest experimental design trapping subsequent learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.02457v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Journal of Machine Learning Research 25 (2024) 1-27</arxiv:journal_reference>
      <dc:creator>Tengyuan Liang</dc:creator>
    </item>
    <item>
      <title>Comparative Analysis of Optimization Strategies for K-means Clustering in Big Data Contexts: A Review</title>
      <link>https://arxiv.org/abs/2310.09819</link>
      <description>arXiv:2310.09819v3 Announce Type: replace-cross 
Abstract: This paper presents a comparative analysis of different optimization techniques for the K-means algorithm in the context of big data. K-means is a widely used clustering algorithm, but it can suffer from scalability issues when dealing with large datasets. The paper explores different approaches to overcome these issues, including parallelization, approximation, and sampling methods. The authors evaluate the performance of various clustering techniques on a large number of benchmark datasets, comparing them according to the dominance criterion provided by the "less is more" approach (LIMA), i.e., simultaneously along the dimensions of speed, clustering quality, and simplicity. The results show that different techniques are more suitable for different types of datasets and provide insights into the trade-offs between speed and accuracy in K-means clustering for big data. Overall, the paper offers a comprehensive guide for practitioners and researchers on how to optimize K-means for big data applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.09819v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Ravil Mussabayev, Rustam Mussabayev</dc:creator>
    </item>
    <item>
      <title>On the Communication Complexity of Decentralized Bilevel Optimization</title>
      <link>https://arxiv.org/abs/2311.11342</link>
      <description>arXiv:2311.11342v3 Announce Type: replace-cross 
Abstract: Decentralized bilevel optimization has been actively studied in the past few years since it has widespread applications in machine learning. However, existing algorithms suffer from large communication complexity caused by the estimation of stochastic hypergradient, limiting their application to real-world tasks. To address this issue, we develop a novel decentralized stochastic bilevel gradient descent algorithm under the heterogeneous setting, which enjoys a small communication cost in each round and a small number of communication rounds. As such, it can achieve a much better communication complexity than existing algorithms without any strong assumptions regarding heterogeneity. To the best of our knowledge, this is the first stochastic algorithm achieving these theoretical results under the heterogeneous setting. At last, the experimental results confirm the efficacy of our algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.11342v3</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yihan Zhang, My T. Thai, Jie Wu, Hongchang Gao</dc:creator>
    </item>
    <item>
      <title>Multi-scale analysis of minimizers for a second order regularization of the Perona-Malik functional</title>
      <link>https://arxiv.org/abs/2311.14565</link>
      <description>arXiv:2311.14565v2 Announce Type: replace-cross 
Abstract: We investigate the asymptotic behavior of minimizers for the singularly perturbed Perona-Malik functional in one dimension. In a previous study, we have shown that blow-ups of these minimizers at a suitable scale converge to staircase-like piecewise constant functions.
  Building upon these findings, we delve into finer scales, revealing that both the vertical and horizontal regions of the staircase steps display cubic polynomial behavior after appropriate rescaling.
  Our analysis hinges on identifying the dominant terms of the functional within each regime, elucidating the mechanisms driving the observed asymptotic behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.14565v2</guid>
      <category>math.AP</category>
      <category>math.FA</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Massimo Gobbino, Nicola Picenni</dc:creator>
    </item>
    <item>
      <title>Data-Driven Robust Covariance Control for Uncertain Linear Systems</title>
      <link>https://arxiv.org/abs/2312.05833</link>
      <description>arXiv:2312.05833v2 Announce Type: replace-cross 
Abstract: The theory of covariance control and covariance steering (CS) deals with controlling the dispersion of trajectories of a dynamical system, under the implicit assumption that accurate prior knowledge of the system being controlled is available. In this work, we consider the problem of steering the distribution of a discrete-time, linear system subject to exogenous disturbances under an unknown dynamics model. Leveraging concepts from behavioral systems theory, the trajectories of this unknown, noisy system may be (approximately) represented using system data collected through experimentation. Using this fact, we formulate a direct data-driven covariance control problem using input-state data. We then propose a maximum likelihood uncertainty quantification method to estimate and bound the noise realizations in the data collection process. Lastly, we utilize robust convex optimization techniques to solve the resulting norm-bounded uncertain convex program. We illustrate the proposed end-to-end data-driven CS algorithm on a double integrator example and showcase the efficacy and accuracy of the proposed method compared to that of model-based methods</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.05833v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joshua Pilipovsky, Panagiotis Tsiotras</dc:creator>
    </item>
    <item>
      <title>System-level Safety Guard: Safe Tracking Control through Uncertain Neural Network Dynamics Models</title>
      <link>https://arxiv.org/abs/2312.06810</link>
      <description>arXiv:2312.06810v2 Announce Type: replace-cross 
Abstract: The Neural Network (NN), as a black-box function approximator, has been considered in many control and robotics applications. However, difficulties in verifying the overall system safety in the presence of uncertainties hinder the deployment of NN modules in safety-critical systems. In this paper, we leverage the NNs as predictive models for trajectory tracking of unknown dynamical systems. We consider controller design in the presence of both intrinsic uncertainty and uncertainties from other system modules. In this setting, we formulate the constrained trajectory tracking problem and show that it can be solved using Mixed-integer Linear Programming (MILP). The proposed MILP-based approach is empirically demonstrated in robot navigation and obstacle avoidance through simulations. The demonstration videos are available at https://xiaolisean.github.io/publication/2023-11-01-L4DC2024.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.06810v2</guid>
      <category>cs.RO</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiao Li, Yutong Li, Anouck Girard, Ilya Kolmanovsky</dc:creator>
    </item>
    <item>
      <title>Rademacher Complexity of Neural ODEs via Chen-Fliess Series</title>
      <link>https://arxiv.org/abs/2401.16655</link>
      <description>arXiv:2401.16655v3 Announce Type: replace-cross 
Abstract: We show how continuous-depth neural ODE models can be framed as single-layer, infinite-width nets using the Chen--Fliess series expansion for nonlinear ODEs. In this net, the output ``weights'' are taken from the signature of the control input -- a tool used to represent infinite-dimensional paths as a sequence of tensors -- which comprises iterated integrals of the control input over a simplex. The ``features'' are taken to be iterated Lie derivatives of the output function with respect to the vector fields in the controlled ODE model. The main result of this work applies this framework to derive compact expressions for the Rademacher complexity of ODE models that map an initial condition to a scalar output at some terminal time. The result leverages the straightforward analysis afforded by single-layer architectures. We conclude with some examples instantiating the bound for some specific systems and discuss potential follow-up work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.16655v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joshua Hanson, Maxim Raginsky</dc:creator>
    </item>
    <item>
      <title>Surrogate Modeling and Control of Medical Digital Twins</title>
      <link>https://arxiv.org/abs/2402.05750</link>
      <description>arXiv:2402.05750v2 Announce Type: replace-cross 
Abstract: The vision of personalized medicine is to identify interventions that maintain or restore a person's health based on their individual biology. Medical digital twins, computational models that integrate a wide range of health-related data about a person and can be dynamically updated, are a key technology that can help guide medical decisions. Such medical digital twin models can be high-dimensional, multi-scale, and stochastic. To be practical for healthcare applications, they often need to be simplified into low-dimensional surrogate models that can be used for the optimal design of interventions. This paper introduces surrogate modeling algorithms for the purpose of optimal control applications. As a use case, we focus on agent-based models (ABMs), a common model type in biomedicine for which there are no readily available optimal control algorithms. By deriving surrogate models that are based on systems of ordinary differential equations, we show how optimal control methods can be employed to compute effective interventions, which can then be lifted back to a given ABM. The relevance of the methods introduced here extends beyond medical digital twins to other complex dynamical systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.05750v2</guid>
      <category>q-bio.QM</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Luis L. Fonseca, Lucas B\"ottcher, Borna Mehrad, Reinhard C. Laubenbacher</dc:creator>
    </item>
    <item>
      <title>Grace Period is All You Need: Individual Fairness without Revenue Loss in Revenue Management</title>
      <link>https://arxiv.org/abs/2402.08533</link>
      <description>arXiv:2402.08533v2 Announce Type: replace-cross 
Abstract: Imagine you and a friend purchase identical items at a store, yet only your friend received a discount. Would your friend's discount make you feel unfairly treated by the store? And would you be less willing to purchase from that store again in the future? Based on a large-scale online survey that we ran on Prolific, it turns out that the answers to the above questions are positive. Motivated by these findings, in this work we propose a notion of individual fairness in online revenue management and an algorithmic module (called ``Grace Period'') that can be embedded in traditional revenue management algorithms and guarantee individual fairness. Specifically, we show how to embed the Grace Period in five common revenue management algorithms including Deterministic Linear Programming with Probabilistic Assignment, Resolving Deterministic Linear Programming with Probabilistic Assignment, Static Bid Price Control, Booking Limit, and Nesting, thus covering both stochastic and adversarial customer arrival settings. Embedding the Grace Period does not incur additional regret for any of these algorithms. This finding indicates that there is no tradeoff between a seller maximizing their revenue and guaranteeing that each customer feels fairly treated.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.08533v2</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Patrick Jaillet, Chara Podimata, Zijie Zhou</dc:creator>
    </item>
    <item>
      <title>Multidimensional Blockchain Fees are (Essentially) Optimal</title>
      <link>https://arxiv.org/abs/2402.08661</link>
      <description>arXiv:2402.08661v2 Announce Type: replace-cross 
Abstract: In this paper we show that, using only mild assumptions, previously proposed multidimensional blockchain fee markets are essentially optimal, even against worst-case adversaries. In particular, we show that the average welfare gap between the following two scenarios is at most $O(1/\sqrt{T})$, where $T$ is the length of the time horizon considered. In the first scenario, the designer knows all future actions by users and is allowed to fix the optimal prices of resources ahead of time, based on the designer's oracular knowledge of those actions. In the second, the prices are updated by a very simple algorithm that does not have this oracular knowledge, a special case of which is similar to EIP-1559, the base fee mechanism used by the Ethereum blockchain. Roughly speaking, this means that, on average, over a reasonable timescale, there is no difference in welfare between 'correctly' fixing the prices, with oracular knowledge of the future, when compared to the proposed algorithm. We show a matching lower bound of $\Omega(1/\sqrt{T})$ for any implementable algorithm and also separately consider the case where the adversary is known to be stochastic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.08661v2</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guillermo Angeris, Theo Diamandis, Ciamac Moallemi</dc:creator>
    </item>
    <item>
      <title>Global controllability of Boussinesq flows by using only a temperature control</title>
      <link>https://arxiv.org/abs/2404.09903</link>
      <description>arXiv:2404.09903v2 Announce Type: replace-cross 
Abstract: We show that buoyancy driven flows can be steered in an arbitrary time towards any state by applying as control only an external temperature profile in a subset of small measure. More specifically, we prove that the 2D incompressible Boussinesq system on the torus is globally approximately controllable via physically localized heating or cooling. In addition, our controls have an explicitly prescribed structure; even without such structural requirements, large data controllability results for Boussinesq flows driven merely by a physically localized temperature profile were so far unknown. The presented method exploits various connections between the model's underlying transport-, coupling-, and scaling mechanisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.09903v2</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vahagn Nersesyan, Manuel Rissel</dc:creator>
    </item>
    <item>
      <title>Control Theoretic Approach to Fine-Tuning and Transfer Learning</title>
      <link>https://arxiv.org/abs/2404.11013</link>
      <description>arXiv:2404.11013v2 Announce Type: replace-cross 
Abstract: Given a training set in the form of a paired $(\mathcal{X},\mathcal{Y})$, we say that the control system $\dot x = f(x,u)$ has learned the paired set via the control $u^*$ if the system steers each point of $\mathcal{X}$ to its corresponding target in $\mathcal{Y}$. If the training set is expanded, most existing methods for finding a new control $u^*$ require starting from scratch, resulting in a quadratic increase in complexity with the number of points. To overcome this limitation, we introduce the concept of $\textit{ tuning without forgetting}$. We develop $\textit{an iterative algorithm}$ to tune the control $u^*$ when the training set expands, whereby points already in the paired set are still matched, and new training samples are learned. At each update of our method, the control $u^*$ is projected onto the kernel of the end-point mapping generated by the controlled dynamics at the learned samples. It ensures keeping the end-points for the previously learned samples constant while iteratively learning additional samples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11013v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erkan Bayram, Shenyu Liu, Mohamed-Ali Belabbas, Tamer Ba\c{s}ar</dc:creator>
    </item>
    <item>
      <title>A geometric decomposition of finite games: Convergence vs. recurrence under exponential weights</title>
      <link>https://arxiv.org/abs/2405.07224</link>
      <description>arXiv:2405.07224v2 Announce Type: replace-cross 
Abstract: In view of the complexity of the dynamics of learning in games, we seek to decompose a game into simpler components where the dynamics' long-run behavior is well understood. A natural starting point for this is Helmholtz's theorem, which decomposes a vector field into a potential and an incompressible component. However, the geometry of game dynamics - and, in particular, the dynamics of exponential / multiplicative weights (EW) schemes - is not compatible with the Euclidean underpinnings of Helmholtz's theorem. This leads us to consider a specific Riemannian framework based on the so-called Shahshahani metric, and introduce the class of incompressible games, for which we establish the following results: First, in addition to being volume-preserving, the continuous-time EW dynamics in incompressible games admit a constant of motion and are Poincar\'e recurrent - i.e., almost every trajectory of play comes arbitrarily close to its starting point infinitely often. Second, we establish a deep connection with a well-known decomposition of games into a potential and harmonic component (where the players' objectives are aligned and anti-aligned respectively): a game is incompressible if and only if it is harmonic, implying in turn that the EW dynamics lead to Poincar\'e recurrence in harmonic games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07224v2</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Davide Legacci, Panayotis Mertikopoulos, Bary Pradelski</dc:creator>
    </item>
    <item>
      <title>Biomarker Selection for Adaptive Systems</title>
      <link>https://arxiv.org/abs/2405.09809</link>
      <description>arXiv:2405.09809v2 Announce Type: replace-cross 
Abstract: Biomarkers enable objective monitoring of a given cell or state in a biological system and are widely used in research, biomanufacturing, and clinical practice. However, identifying appropriate biomarkers that are both robustly measurable and capture a state accurately remains challenging. We present a framework for biomarker identification based upon observability guided sensor selection. Our methods, Dynamic Sensor Selection (DSS) and Structure-Guided Sensor Selection (SGSS), utilize temporal models and experimental data, offering a template for applying observability theory to unconventional data obtained from biological systems. Unlike conventional methods that assume well-known, fixed dynamics, DSS adaptively select biomarkers or sensors that maximize observability while accounting for the time-varying nature of biological systems. Additionally, SGSS incorporates structural information and diverse data to identify sensors which are resilient against inaccuracies in our model of the underlying system. We validate our approaches by performing estimation on high dimensional systems derived from temporal gene expression data from partial observations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.09809v2</guid>
      <category>q-bio.MN</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joshua Pickard, Cooper Stansbury, Amit Surana, Anthony Bloch, Indika Rajapakse</dc:creator>
    </item>
    <item>
      <title>Neural Optimization with Adaptive Heuristics for Intelligent Marketing System</title>
      <link>https://arxiv.org/abs/2405.10490</link>
      <description>arXiv:2405.10490v2 Announce Type: replace-cross 
Abstract: Computational marketing has become increasingly important in today's digital world, facing challenges such as massive heterogeneous data, multi-channel customer journeys, and limited marketing budgets. In this paper, we propose a general framework for marketing AI systems, the Neural Optimization with Adaptive Heuristics (NOAH) framework. NOAH is the first general framework for marketing optimization that considers both to-business (2B) and to-consumer (2C) products, as well as both owned and paid channels. We describe key modules of the NOAH framework, including prediction, optimization, and adaptive heuristics, providing examples for bidding and content optimization. We then detail the successful application of NOAH to LinkedIn's email marketing system, showcasing significant wins over the legacy ranking system. Additionally, we share details and insights that are broadly useful, particularly on: (i) addressing delayed feedback with lifetime value, (ii) performing large-scale linear programming with randomization, (iii) improving retrieval with audience expansion, (iv) reducing signal dilution in targeting tests, and (v) handling zero-inflated heavy-tail metrics in statistical testing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10490v2</guid>
      <category>stat.ME</category>
      <category>cs.AI</category>
      <category>cs.IR</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Changshuai Wei, Benjamin Zelditch, Joyce Chen, Andre Assuncao Silva T Ribeiro, Jingyi Kenneth Tay, Borja Ocejo Elizondo, Keerthi Selvaraj, Aman Gupta, Licurgo Benemann De Almeida</dc:creator>
    </item>
  </channel>
</rss>
