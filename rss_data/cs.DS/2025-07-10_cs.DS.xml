<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 11 Jul 2025 01:19:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Parallel Batch-Dynamic Coreness Decomposition with Worst-Case Guarantees</title>
      <link>https://arxiv.org/abs/2507.06334</link>
      <description>arXiv:2507.06334v1 Announce Type: new 
Abstract: We present the first parallel batch-dynamic algorithm for approximating coreness decomposition with worst-case update times. Given any batch of edge insertions and deletions, our algorithm processes all these updates in $ \text{poly}(\log n)$ depth, using a worst-case work bound of $b\cdot \text{poly}(\log n)$ where $b$ denotes the batch size. This means the batch gets processed in $\tilde{O}(b/p)$ time, given $p$ processors, which is optimal up to logarithmic factors. Previously, an algorithm with similar guarantees was known by the celebrated work of Liu, Shi, Yu, Dhulipala, and Shun [SPAA'22], but with the caveat of the work bound, and thus the runtime, being only amortized.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06334v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3694906.3743328</arxiv:DOI>
      <dc:creator>Mohsen Ghaffari, Jaehyun Koo</dc:creator>
    </item>
    <item>
      <title>Parallel Batch-Dynamic Algorithms for Spanners, and Extensions</title>
      <link>https://arxiv.org/abs/2507.06338</link>
      <description>arXiv:2507.06338v1 Announce Type: new 
Abstract: This paper presents the first parallel batch-dynamic algorithms for computing spanners and sparsifiers. Our algorithms process any batch of edge insertions and deletions in an $n$-node undirected graph, in $\text{poly}(\log n)$ depth and using amortized work near-linear in the batch size. Our concrete results are as follows:
  - Our base algorithm maintains a spanner with $(2k-1)$ stretch and $\tilde{O}(n^{1+1/k})$ edges, for any $k\geq 1$.
  - Our first extension maintains a sparse spanner with only $O(n)$ edges, and $\tilde{O}(\log n)$ stretch.
  - Our second extension maintains a $t$-bundle of spanners -- i.e., $t$ spanners, each of which is the spanner of the graph remaining after removing the previous ones -- and allows us to maintain cut/spectral sparsifiers with $\tilde{O}(n)$ edges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06338v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3694906.3743322</arxiv:DOI>
      <dc:creator>Mohsen Ghaffari, Jaehyun Koo</dc:creator>
    </item>
    <item>
      <title>Multi-Queue SSD I/O Modeling &amp; Its Implications for Data Structure Design</title>
      <link>https://arxiv.org/abs/2507.06349</link>
      <description>arXiv:2507.06349v1 Announce Type: new 
Abstract: Understanding the performance profiles of storage devices and how best to utilize them has always been non-trivial due to factors such as seek times, caching, scheduling, concurrent access, flash wear-out, and garbage collection. However, analytical frameworks that provide simplified abstractions of storage performance can still be accurate enough to evaluate external memory algorithms and data structures at the design stage. For example, the Disk Access Machine (DAM) model assumes that a storage device transfers data in fixed-size blocks of size B and that all transfers have unit latency. This abstraction is already sufficient to explain some of the benefits of data structures such as B-trees and Log-Structured Merge trees (LSM trees); however, storage technology advances have significantly reduced current models' accuracy and utility.
  This paper introduces the Multi-Queue Solid State Drive (MQSSD) model, a new storage abstraction. This model builds upon previous models and aims to more accurately represent the performance characteristics of modern storage hardware. We identify key performance-critical aspects of modern multi-queue solid-state drives on which we base our model and demonstrate these characteristics on actual hardware. We then show how our model can be applied to LSM-tree-based storage engines to optimize them for modern storage hardware. We highlight that leveraging concurrent access is crucial for fully utilizing the high throughput of multi-queue SSDs, enabling designs that may appear counterintuitive under traditional paradigms We then validate these insights through experiments using Facebook's LSM-tree-based key-value store, RocksDB. We conclude that the MQSSD model offers a more accurate abstraction of modern hardware than previous models, allowing for greater insight and optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06349v1</guid>
      <category>cs.DS</category>
      <category>cs.AR</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erin Ransom, Andrew Lim, Michael Mitzenmacher</dc:creator>
    </item>
    <item>
      <title>Prediction-Augmented Mechanism Design for Weighted Facility Location</title>
      <link>https://arxiv.org/abs/2507.06509</link>
      <description>arXiv:2507.06509v2 Announce Type: new 
Abstract: Facility location is fundamental in operations research, mechanism design, and algorithmic game theory, with applications ranging from urban infrastructure planning to distributed systems. Recent research in this area has focused on augmenting classic strategyproof mechanisms with predictions to achieve an improved performance guarantee against the uncertainty under the strategic environment. Previous work has been devoted to address the trade-off obstacle of balancing the consistency (near-optimality under accurate predictions) and robustness (bounded inefficiency under poor predictions) primarily in the unweighted setting, assuming that all agents have the same importance. However, this assumption may not be true in some practical scenarios, leading to research of weighted facility location problems.
  The major contribution of the current work is to provide a prediction augmented algorithmic framework for balancing the consistency and robustness over strategic agents with non-uniform weights. In particular, through a reduction technique that identifies a subset of \emph{representative} instances and maps the other given locations to the representative ones, we prove that there exists a \emph{strategyproof} mechanism achieving a bounded consistency guarantee of $\frac{\sqrt{(1+c)^2W^2_{\min}+(1-c)^2W^2_{\max}}}{(1+c)W_{\min}}$ and a bounded robustness guarantee of $\frac{\sqrt{(1-c)^2W^2_{\min}+(1+c)^2W^2_{\max}}}{(1-c)W_{\min}}$ in weighted settings, where $c$ can be viewed as a parameter to make a trade-off between the consistency and robustness and $W_{\min}$ and $W_{\max}$ denote the minimum and maximum agents' weight. We also proved that there is no strategyproof deterministic mechanism that reach $1$-consistency and $O\left( n \cdot \frac{W_{\max}}{W_{\min}} \right)$-robustness in weighted FLP, even with fully predictions of all agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06509v2</guid>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yangguang Shi, Zhenyu Xue</dc:creator>
    </item>
    <item>
      <title>Faster Algorithms for $(2k-1)$-Stretch Distance Oracles</title>
      <link>https://arxiv.org/abs/2507.06721</link>
      <description>arXiv:2507.06721v1 Announce Type: new 
Abstract: Let $G=(V, E)$ be an undirected $n$-vertices $m$-edges graph with non-negative edge weights. In this paper, we present three new algorithms for constructing a $(2k-1)$-stretch distance oracle with $O(n^{1+\frac{1}{k}})$ space. The first algorithm runs in $\Ot(\max(n^{1+2/k}, m^{1-\frac{1}{k-1}}n^{\frac{2}{k-1}}))$ time, and improves upon the $\Ot(\min(mn^{\frac{1}{k}},n^2))$ time of Thorup and Zwick [STOC 2001, JACM 2005] and Baswana and Kavitha [FOCS 2006, SICOMP 2010], for every $k &gt; 2$ and $m=\Omega(n^{1+\frac{1}{k}+\eps})$. This yields the first truly subquadratic time construction for every $2 &lt; k &lt; 6$, and nearly resolves the open problem posed by Wulff-Nilsen [SODA 2012] on the existence of such constructions.
  The two other algorithms have a running time of the form $\Ot(m+n^{1+f(k)})$, which is near linear in $m$ if $m=\Omega(n^{1+f(k)})$, and therefore optimal in such graphs. One algorithm runs in $\Ot(m+n^{\frac32+\frac{3}{4k-6}})$-time, which improves upon the $\Ot(n^2)$-time algorithm of Baswana and Kavitha [FOCS 2006, SICOMP 2010], for $3 &lt; k &lt; 6$, and upon the $\Ot(m+n^{\frac{3}{2}+\frac{2}{k}+O(k^{-2})})$-time algorithm of Wulff-Nilsen [SODA 2012], for every $k\geq 6$. This is the first linear time algorithm for constructing a $7$-stretch distance oracle and a $9$-stretch distance oracle, for graphs with truly subquadratic density.\footnote{with $m=n^{2-\eps}$ for some $\eps &gt; 0$.} The other algorithm runs in $\Ot(\sqrt{k}m+kn^{1+\frac{2\sqrt{2}}{\sqrt{k}}})$ time, (and hence relevant only for $k\ge 16$), and improves upon the $\Ot(\sqrt{k}m+kn^{1+\frac{2\sqrt{6}}{\sqrt{k}}+O(k^{-1})})$ time algorithm of Wulff-Nilsen [SODA 2012] (which is relevant only for $k\ge 96$). ...</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06721v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Avi Kadria, Liam Roditty</dc:creator>
    </item>
    <item>
      <title>Faster Estimation of the Average Degree of a Graph Using Random Edges and Structural Queries</title>
      <link>https://arxiv.org/abs/2507.06925</link>
      <description>arXiv:2507.06925v1 Announce Type: new 
Abstract: We revisit the problem of designing sublinear algorithms for estimating the average degree of an $n$-vertex graph. The standard access model for graphs allows for the following queries: sampling a uniform random vertex, the degree of a vertex, sampling a uniform random neighbor of a vertex, and ``pair queries'' which determine if a pair of vertices form an edge. In this model, original results [Goldreich-Ron, RSA 2008; Eden-Ron-Seshadhri, SIDMA 2019] on this problem prove that the complexity of getting $(1+\varepsilon)$-multiplicative approximations to the average degree, ignoring $\varepsilon$-dependencies, is $\Theta(\sqrt{n})$. When random edges can be sampled, it is known that the average degree can estimated in $\widetilde{O}(n^{1/3})$ queries, even without pair queries [Motwani-Panigrahy-Xu, ICALP 2007; Beretta-Tetek, TALG 2024].
  We give a nearly optimal algorithm in the standard access model with random edge samples. Our algorithm makes $\widetilde{O}(n^{1/4})$ queries exploiting the power of pair queries. We also analyze the ``full neighborhood access" model wherein the entire adjacency list of a vertex can be obtained with a single query; this model is relevant in many practical applications. In a weaker version of this model, we give an algorithm that makes $\widetilde{O}(n^{1/5})$ queries. Both these results underscore the power of {\em structural queries}, such as pair queries and full neighborhood access queries, for estimating the average degree. We give nearly matching lower bounds, ignoring $\varepsilon$-dependencies, for all our results.
  So far, almost all algorithms for estimating average degree assume that the number of vertices, $n$, is known. Inspired by [Beretta-Tetek, TALG 2024], we study this problem when $n$ is unknown and show that structural queries do not help in estimating average degree in this setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06925v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lorenzo Beretta, Deeparnab Chakrabarty, C. Seshadhri</dc:creator>
    </item>
    <item>
      <title>Designing Parallel Algorithms for Community Detection using Arachne</title>
      <link>https://arxiv.org/abs/2507.06471</link>
      <description>arXiv:2507.06471v1 Announce Type: cross 
Abstract: The rise of graph data in various fields calls for efficient and scalable community detection algorithms. In this paper, we present parallel implementations of two widely used algorithms: Label Propagation and Louvain, specifically designed to leverage the capabilities of Arachne which is a Python-accessible, open-source framework for large-scale graph analysis. Our implementations achieve substantial speedups over existing Python-based tools like NetworkX and igraph, which lack efficient parallelization, and are competitive with parallel frameworks such as NetworKit. Experimental results show that Arachne-based methods outperform these baselines, achieving speedups of up to 710x over NetworkX, 75x over igraph, and 12x over NetworKit. Additionally, we analyze the scalability of our implementation under varying thread counts, demonstrating how different phases contribute to overall performance gains of the parallel Louvain algorithm. Arachne, including our community detection implementation, is open-source and available at https://github.com/Bears-R-Us/arkouda-njit .</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06471v1</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fuhuan Li, Zhihui Du, David A. Bader</dc:creator>
    </item>
    <item>
      <title>Waiting is not easy but worth it: the online TSP on the line revisited</title>
      <link>https://arxiv.org/abs/1907.00317</link>
      <description>arXiv:1907.00317v2 Announce Type: replace 
Abstract: We consider the online traveling salesman problem on the real line (OLTSPL) in which a salesman begins at the origin, traveling at no faster than unit speed along the real line, and wants to serve a sequence of requests, arriving online over time on the real line and return to the origin as quickly as possible. The problem has been widely investigated for more than two decades, but was just optimally solved by a deterministic algorithm with a competitive ratio of $(9+\sqrt{17})/8$, reported in~[Bjelde A. et al., in Proc. SODA 2017, pp.994--1005].
  In this study we present lower bounds and upper bounds for randomized algorithms in the OLTSPL. Precisely, we show, for the first time, that a simple randomized \emph{zealous} algorithm can improve the optimal deterministic algorithm. Here an algorithm is called zealous if waiting strategies are not allowed to use for the salesman as long as there are unserved requests. Moreover, we incorporate a natural waiting scheme into the randomized algorithm, which can even achieve the lower bound we propose for any randomized algorithms, and thus it is optimal. We also consider randomized algorithms against a \emph{fair} adversary, i.e. an adversary with restricted power that requires the salesman to move within the convex hull of the origin and the requests released so far. The randomized non-zealous algorithm can outperform the optimal deterministic algorithm against the fair adversary as well.</description>
      <guid isPermaLink="false">oai:arXiv.org:1907.00317v2</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pei-Chuan Chen, Erik D. Demaine, Chung-Shou Liao, Hao-Ting Wei</dc:creator>
    </item>
    <item>
      <title>Cycling in the forest with Wilson's algorithm</title>
      <link>https://arxiv.org/abs/2404.14803</link>
      <description>arXiv:2404.14803v3 Announce Type: replace 
Abstract: We consider a probability measure on cycle-rooted spanning forests (CRSFs) introduced by Kenyon. CRSFs are spanning subgraphs, each connected component of which has a unique cycle; they generalize spanning trees. A generalization of Wilson's celebrated CyclePopping algorithm for uniform spanning trees has been proposed for CRSFs, and several concise proofs have been given that the algorithm samples from Kenyon's distribution. In this survey, we flesh out all the details of such a proof of correctness, progressively generalizing a proof by Marchal for spanning trees. This detailed proof has several interests. First, it serves as a modern tutorial on Wilson's algorithm, suitable for applied probability and computer science audiences. Compared to uniform spanning trees, the more sophisticated motivating application to CRSFs brings forth connections to recent research topics such as loop measures, partial rejection sampling, and heaps of cycles. Second, the detailed proof \emph{\`a la} Marchal yields the law of the time complexity of the sampling algorithm, shedding light on practical situations where the algorithm is expected to run fast.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14803v3</guid>
      <category>cs.DS</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.PR</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Micha\"el Fanuel, R\'emi Bardenet</dc:creator>
    </item>
    <item>
      <title>New Distributed Interactive Proofs for Planarity: A Matter of Left and Right</title>
      <link>https://arxiv.org/abs/2505.00338</link>
      <description>arXiv:2505.00338v3 Announce Type: replace 
Abstract: We provide new distributed interactive proofs (DIP) for planarity and related graph families. The notion of a \emph{distributed interactive proof} (DIP) was introduced by Kol, Oshman, and Saxena (PODC 2018). In this setting, the verifier consists of $n$ nodes connected by a communication graph $G$. The prover is a single entity that communicates with all nodes by short messages. The goal is to verify that the graph $G$ satisfies a certain property (e.g., planarity) in a small number of rounds, and with a small communication bound, denoted as the \emph{proof size}.
  Prior work by Naor, Parter and Yogev (SODA 2020) presented a DIP for planarity that uses three interaction rounds and a proof size of $O(\log n)$. Feuilloley et al.\ (PODC 2020) showed that the same can be achieved with a single interaction round and without randomization, by providing a proof labeling scheme with a proof size of $O(\log n)$. In a subsequent work, Bousquet, Feuilloley, and Pierron (OPODIS 2021) achieved the same bound for related graph families such as outerplanarity, series-parallel graphs, and graphs of treewidth at most $2$. In this work, we design new DIPs that use exponentially shorter proofs compared to the state-of-the-art bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00338v3</guid>
      <category>cs.DS</category>
      <category>cs.DC</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuval Gil, Merav Parter</dc:creator>
    </item>
    <item>
      <title>Bandwidth vs BFS Width in Matrix Reordering, Graph Reconstruction, and Graph Drawing</title>
      <link>https://arxiv.org/abs/2505.10789</link>
      <description>arXiv:2505.10789v3 Announce Type: replace 
Abstract: We provide the first approximation quality guarantees for the Cuthull-McKee heuristic for reordering symmetric matrices to have low bandwidth, and we provide an algorithm for reconstructing bounded-bandwidth graphs from distance oracles with near-linear query complexity. To prove these results we introduce a new width parameter, BFS width, and we prove polylogarithmic upper and lower bounds on the BFS width of graphs of bounded bandwidth. Unlike other width parameters, such as bandwidth, pathwidth, and treewidth, BFS width can easily be computed in polynomial time. Bounded BFS width implies bounded bandwidth, pathwidth, and treewidth, which in turn imply fixed-parameter tractable algorithms for many problems that are NP-hard for general graphs. In addition to their applications to matrix ordering, we also provide applications of BFS width to graph reconstruction, to reconstruct graphs from distance queries, and graph drawing, to construct arc diagrams of small height.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.10789v3</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David Eppstein, Michael T. Goodrich, Songyu Liu</dc:creator>
    </item>
    <item>
      <title>On the Low-Temperature MCMC threshold: the cases of sparse tensor PCA, sparse regression, and a geometric rule</title>
      <link>https://arxiv.org/abs/2408.00746</link>
      <description>arXiv:2408.00746v3 Announce Type: replace-cross 
Abstract: Over the last years, there has been a significant amount of work studying the power of specific classes of computationally efficient estimators for multiple statistical parametric estimation tasks, including the estimators classes of low-degree polynomials, spectral methods, and others. Despite that, our understanding of the important class of MCMC methods remains quite poorly understood. For instance, for many models of interest, the performance of even zero-temperature (greedy-like) MCMC methods that simply maximize the posterior remains elusive.
  In this work, we provide an easy to check condition under which the low-temperature Metropolis chain maximizes the posterior in polynomial-time with high probability. The result is generally applicable, and in this work, we use it to derive positive MCMC results for two classical sparse estimation tasks: the sparse tensor PCA model and sparse regression. Interestingly, in both cases, we also leverage the Overlap Gap Property framework for inference (Gamarnik, Zadik AoS '22) to prove that our results are tight: no low-temperature local MCMC method can achieve better performance. In particular, our work identifies the "low-temperature (local) MCMC threshold" for both sparse models. Interestingly, in the sparse tensor PCA model our results indicate that low-temperature local MCMC methods significantly underperform compared to other studied time-efficient methods, such as the class of low-degree polynomials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.00746v3</guid>
      <category>math.ST</category>
      <category>cs.DS</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zongchen Chen, Conor Sheehan, Ilias Zadik</dc:creator>
    </item>
  </channel>
</rss>
