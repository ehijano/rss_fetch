<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NA</link>
    <description>cs.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 30 Apr 2024 04:01:59 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 30 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A High-order Arbitrary Lagrangian-Eulerian Virtual Element Method for Convection-Diffusion Problems</title>
      <link>https://arxiv.org/abs/2404.17661</link>
      <description>arXiv:2404.17661v1 Announce Type: new 
Abstract: A virtual element discretisation of an Arbitrary Lagrangian-Eulerian method for two-dimensional convection-diffusion equations is proposed employing an isoparametric Virtual Element Method to achieve higher-order convergence rates on curved edged polygonal meshes. The proposed method is validated with numerical experiments in which optimal $H^1$ and $L^2$ convergence are observed. This method is then successfully applied to an existing moving mesh algorithm for implicit moving boundary problems in which higher-order convergence is achieved.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17661v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>H. Wells</dc:creator>
    </item>
    <item>
      <title>Extrapolating on Taylor Series Solutions of Homotopies with Nearby Poles</title>
      <link>https://arxiv.org/abs/2404.17681</link>
      <description>arXiv:2404.17681v1 Announce Type: new 
Abstract: A polynomial homotopy is a family of polynomial systems in one parameter, which defines solution paths starting from known solutions and ending at solutions of a system that has to be solved. We consider paths leading to isolated singular solutions, to which the Taylor series converges logarithmically. Whether or not extrapolation algorithms manage to accelerate the slowly converging series depends on the proximity of poles close to the disk of convergence of the Taylor series.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17681v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jan Verschelde, Kylash Viswanathan</dc:creator>
    </item>
    <item>
      <title>Stocking and Harvesting Effects in Advection-Reaction-Diffusion Model: Exploring Decoupled Algorithms and Analysis</title>
      <link>https://arxiv.org/abs/2404.17702</link>
      <description>arXiv:2404.17702v1 Announce Type: new 
Abstract: We propose a time-dependent Advection Reaction Diffusion (ARD) $N$-species competition model to investigate the Stocking and Harvesting (SH) effect on population dynamics. For ongoing analysis, we explore the outcomes of a competition between two competing species in a heterogeneous environment under no-flux boundary conditions, meaning no individual can cross the boundaries. We establish results concerning the existence, uniqueness, and positivity of the solution. As a continuation, we propose, analyze, and test two novel fully discrete decoupled linearized algorithms for a nonlinearly coupled ARD $N$-species competition model with SH effort. The time-stepping algorithms are first and second order accurate in time and optimally accurate in space. Stability and optimal convergence theorems of the decoupled schemes are proved rigorously. We verify the predicted convergence rates of our analysis and the efficacy of the algorithms using numerical experiments and synthetic data for analytical test problems. We also study the effect of harvesting or stocking and diffusion parameters on the evolution of species population density numerically and observe the coexistence scenario subject to optimal stocking or harvesting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17702v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Mayesha Sharmim Tisha, Md. Kamrujjaman, Muhammad Mohebujjaman, Taufiquar Khan</dc:creator>
    </item>
    <item>
      <title>Fast Iterative Solver For Neural Network Method: I. 1D Diffusion Problems</title>
      <link>https://arxiv.org/abs/2404.17750</link>
      <description>arXiv:2404.17750v1 Announce Type: new 
Abstract: The discretization of the deep Ritz method [18] for the Poisson equation leads to a high-dimensional non-convex minimization problem, that is difficult and expensive to solve numerically. In this paper, we consider the shallow Ritz approximation to one-dimensional diffusion problems and introduce an effective and efficient iterative method, a damped block Newton (dBN) method, for solving the resulting non-convex minimization problem.
  The method employs the block Gauss-Seidel method as an outer iteration by dividing the parameters of a shallow neural network into the linear parameters (the weights and bias of the output layer) and the non-linear parameters (the weights and bias of the hidden layer). Per each outer iteration, the linear and the non-linear parameters are updated by exact inversion and one step of a damped Newton method, respectively. Inverses of the coefficient matrix and the Hessian matrix are tridiagonal and diagonal, respectively, and hence the cost of each dBN iteration is $\mathcal{O}(n)$. To move the breakpoints (the non-linear parameters) more efficiently, we propose an adaptive damped block Newton (AdBN) method by combining the dBN with the adaptive neuron enhancement (ANE) method [25]. Numerical examples demonstrate the ability of dBN and AdBN not only to move the breakpoints quickly and efficiently but also to achieve a nearly optimal order of convergence for AdBN. These iterative solvers are capable of outperforming BFGS for select examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17750v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhiqiang Cai, Anastassia Doktorova, Robert D. Falgout, C\'esar Herrera</dc:creator>
    </item>
    <item>
      <title>Modified Trapezoidal Product Cubature Rules. Definiteness, Monotonicity and a Posteriori Error Estimates</title>
      <link>https://arxiv.org/abs/2404.17796</link>
      <description>arXiv:2404.17796v1 Announce Type: new 
Abstract: We study two modifications of the trapezoidal product cubature formulae, approximating double integrals over the square domain $[a,b]^2=[a,b]\times [a,b]$. Our modified cubature formulae use mixed type data: except evaluations of the integrand on the points forming a uniform grid on $[a,b]^2$, they involve two or four univariate integrals. An useful property of these cubature formulae is that they are definite of order $(2,2)$, that is, they provide one-sided approximation to the double integral for real-valued integrands from the class $$ \mathcal{C}^{2,2}[a,b]=\{f(x,y)\,:\,\frac{\partial^4 f}{\partial x^2\partial y^2}\ \text{continuous and does not change sign in}\ (a,b)^2\}. $$ For integrands from $\mathcal{C}^{2,2}[a,b]$ we prove monotonicity of the remainders and derive a-posteriori error estimates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17796v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.CA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Geno Nikolov, Petar Nikolov</dc:creator>
    </item>
    <item>
      <title>Error analysis for finite element operator learning methods for solving parametric second-order elliptic PDEs</title>
      <link>https://arxiv.org/abs/2404.17868</link>
      <description>arXiv:2404.17868v1 Announce Type: new 
Abstract: In this paper, we provide a theoretical analysis of a type of operator learning method without data reliance based on the classical finite element approximation, which is called the finite element operator network (FEONet). We first establish the convergence of this method for general second-order linear elliptic PDEs with respect to the parameters for neural network approximation. In this regard, we address the role of the condition number of the finite element matrix in the convergence of the method. Secondly, we derive an explicit error estimate for the self-adjoint case. For this, we investigate some regularity properties of the solution in certain function classes for a neural network approximation, verifying the sufficient condition for the solution to have the desired regularity. Finally, we will also conduct some numerical experiments that support the theoretical findings, confirming the role of the condition number of the finite element matrix in the overall convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17868v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Youngjoon Hong, Seungchan Ko, Jaeyong Lee</dc:creator>
    </item>
    <item>
      <title>Comparative study of inner-outer Krylov solvers for linear systems in structured and high-order unstructured CFD problems</title>
      <link>https://arxiv.org/abs/2404.17870</link>
      <description>arXiv:2404.17870v1 Announce Type: new 
Abstract: Advanced Krylov subspace methods are investigated for the solution of large sparse linear systems arising from stiff adjoint-based aerodynamic shape optimization problems. A special attention is paid to the flexible inner-outer GMRES strategy combined with most relevant preconditioning and deflation techniques. The choice of this specific class of Krylov solvers for challenging problems is based on its outstanding convergence properties. Typically in our implementation the efficiency of the preconditioner is enhanced with a domain decomposition method with overlapping. However, maintaining the performance of the preconditioner may be challenging since scalability and efficiency of a preconditioning technique are properties often antagonistic to each other. In this paper we demonstrate how flexible inner-outer Krylov methods are able to overcome this critical issue. A numerical study is performed considering either a Finite Volume (FV), or a high-order Discontinuous Galerkin (DG) discretization which affect the arithmetic intensity and memory-bandwith of the algebraic operations. We consider test cases of transonic turbulent flows with RANS modelling over the two-dimensional supercritical OAT15A airfoil and the three-dimensional ONERA M6 wing. Benefits in terms of robustness and convergence compared to standard GMRES solvers are obtained. Strong scalability analysis shows satisfactory results. Based on these representative problems a discussion of the recommended numerical practices is proposed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17870v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.compfluid.2022.105575</arxiv:DOI>
      <arxiv:journal_reference>Computers and Fluids, Volume 244, 15 August 2022, 105575</arxiv:journal_reference>
      <dc:creator>Mehdi Jadoui, Christophe Blondeau, Emeric Martin, Florent Renac, Fran\c{c}ois-Xavier Roux</dc:creator>
    </item>
    <item>
      <title>Continuous Linear Finite Element Method for Biharmonic Problems on Surfaces</title>
      <link>https://arxiv.org/abs/2404.17958</link>
      <description>arXiv:2404.17958v1 Announce Type: new 
Abstract: This paper presents an innovative continuous linear finite element approach to effectively solve biharmonic problems on surfaces. The key idea behind this method lies in the strategic utilization of a surface gradient recovery operator to compute the second-order surface derivative of a piecewise continuous linear function defined on the approximate surface, as conventional notions of second-order derivatives are not directly applicable in this context. By incorporating appropriate stabilizations, we rigorously establish the stability of the proposed formulation. Despite the presence of geometric error, we provide optimal error estimates in both the energy norm and $L^2$ norm. Theoretical results are supported by numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17958v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ying Cai, Hailong Guo, Zhimin Zhang</dc:creator>
    </item>
    <item>
      <title>Estimation of uncertainties in the density driven flow in fractured porous media using MLMC</title>
      <link>https://arxiv.org/abs/2404.18003</link>
      <description>arXiv:2404.18003v1 Announce Type: new 
Abstract: We use the Multi Level Monte Carlo method to estimate uncertainties in a Henry-like salt water intrusion problem with a fracture. The flow is induced by the variation of the density of the fluid phase, which depends on the mass fraction of salt. We assume that the fracture has a known fixed location but an uncertain aperture. Other input uncertainties are the porosity and permeability fields and the recharge. In our setting, porosity and permeability vary spatially and recharge is time-dependent. For each realisation of these uncertain parameters, the evolution of the mass fraction and pressure fields is modelled by a system of non-linear and time-dependent PDEs with a jump of the solution at the fracture. The uncertainties propagate into the distribution of the salt concentration, which is an important characteristic of the quality of water resources. We show that the multilevel Monte Carlo (MLMC) method is able to reduce the overall computational cost compared to classical Monte Carlo methods. This is achieved by balancing discretisation and statistical errors. Multiple scenarios are evaluated at different spatial and temporal mesh levels. The deterministic solver ug4 is run in parallel to calculate all stochastic scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18003v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>stat.CO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dmitry Logashenko, Alexander Litvinenko, Raul Tempone, Gabriel Wittum</dc:creator>
    </item>
    <item>
      <title>Reduced-order modeling of neutron transport separated in axial and radial space by Proper Generalized Decomposition with applications to nuclear reactor physics</title>
      <link>https://arxiv.org/abs/2404.18016</link>
      <description>arXiv:2404.18016v1 Announce Type: new 
Abstract: In this article, we demonstrate the novel use of Proper Generalized Decomposition (PGD) to separate the axial and, optionally, polar dimensions of neutron transport. Doing so, the resulting Reduced-Order Models (ROMs) can exploit the fact that nuclear reactors tend to be tall, but geometrically simple, in the axial direction $z$, and so the 3D neutron flux distribution often admits a low-rank "2D/1D" approximation. Through PGD, this approximation is computed by alternately solving 2D and 1D sub-models, like in existing 2D/1D models of reactor physics. However, the present methodology is more general in that the decomposition is arbitrary-rank, rather than rank-one, and no simplifying approximations of the transverse leakage are made. To begin, we derive two original models: that of axial PGD -- which separates only $z$ and the axial streaming direction $\vartheta\in\{-1,+1\}$ -- and axial-polar PGD -- which separates both $z$ and polar angle $\mu$ from the radial domain. Additionally, we grant that the energy dependence $E$ may be ascribed to either radial or axial modes, or both, bringing the total number of candidate 2D/1D ROMs to six. To assess performance, these PGD ROMs are applied to two few-group benchmarks characteristic of Light Water Reactors. Therein, we find both the axial and axial-polar ROMs are convergent and that the latter are often more economical than the former. Ultimately, given the popularity of 2D/1D methods in reactor physics, we expect a PGD ROM which achieves a similar effect, but perhaps with superior accuracy, a quicker runtime, and/or broader applicability, would be eminently useful, especially for full-core problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18016v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Kurt A. Dominesey, Wei Ji</dc:creator>
    </item>
    <item>
      <title>Comparison between a priori and a posteriori slope limiters for high-order finite volume schemes</title>
      <link>https://arxiv.org/abs/2404.18037</link>
      <description>arXiv:2404.18037v1 Announce Type: new 
Abstract: High-order finite volume and finite element methods offer impressive accuracy and cost efficiency when solving hyperbolic conservation laws with smooth solutions. However, if the solution contains discontinuities, these high-order methods can introduce unphysical oscillations and severe overshoots/undershoots. Slope limiters are an effective remedy, combating these oscillations by preserving monotonicity. Some limiters can even maintain a strict maximum principle in the numerical solution. They can be classified into one of two categories: \textit{a priori} and \textit{a posteriori} limiters. The former revises the high-order solution based only on data at the current time $t^n$, while the latter involves computing a candidate solution at $t^{n+1}$ and iteratively recomputing it until some conditions are satisfied. These two limiting paradigms are available for both finite volume and finite element methods.
  In this work, we develop a methodology to compare \textit{a priori} and \textit{a posteriori} limiters for finite volume solvers at arbitrarily high order. We select the maximum principle preserving scheme presented in \cite{zhang2011maximum, zhang2010maximum} as our \textit{a priori} limited scheme. For \textit{a posteriori} limiting, we adopt the methodology presented in \cite{clain2011high} and search for so-called \textit{troubled cells} in the candidate solution. We revise them with a robust MUSCL fallback scheme. The linear advection equation is solved in both one and two dimensions and we compare variations of these limited schemes based on their ability to maintain a maximum principle, solution quality over long time integration and computational cost.
  ...</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18037v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jonathan Palafoutas, David A. Velasco Romero, Romain Teyssier</dc:creator>
    </item>
    <item>
      <title>Implicit Update of the Moment Equations for a Multi-Species, Homogeneous BGK Model</title>
      <link>https://arxiv.org/abs/2404.18039</link>
      <description>arXiv:2404.18039v1 Announce Type: new 
Abstract: A simple iterative approach for solving a set of implicit kinetic moment equations is proposed. This implicit solve is a key component in the IMEX discretization of the multi-species Bhatnagar-Gross-Krook (M-BGK) model with nontrivial collision frequencies depending on individual species temperatures. We prove that under mild time step restrictions, the iterative method generates a contraction mapping. Numerical simulations are provided to illustrate results of the IMEX scheme using the implicit moment solver.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18039v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Evan Habbershaw, Cory D. Hauck, Steven M. Wise</dc:creator>
    </item>
    <item>
      <title>Mass-preserving Spatio-temporal adaptive PINN for Cahn-Hilliard equations with strong nonlinearity and singularity</title>
      <link>https://arxiv.org/abs/2404.18054</link>
      <description>arXiv:2404.18054v1 Announce Type: new 
Abstract: As one kind important phase field equations, Cahn-Hilliard equations contain spatial high order derivatives, strong nonlinearities, and even singularities. When using the physics informed neural network (PINN) to simulate the long time evolution, it is necessary to decompose the time domain to capture the transition of solutions in different time. Moreover, the baseline PINN can't maintain the mass conservation property for the equations. We propose a mass-preserving spatio-temporal adaptive PINN. This method adaptively dividing the time domain according to the rate of energy decrease, and solves the Cahn-Hilliard equation in each time step using an independent neural network. To improve the prediction accuracy, spatial adaptive sampling is employed in the subdomain to select points with large residual value and add them to the training samples. Additionally, a mass constraint is added to the loss function to compensate the mass degradation problem of the PINN method in solving the Cahn-Hilliard equations. The mass-preserving spatio-temporal adaptive PINN is employed to solve a series of numerical examples. These include the Cahn-Hilliard equations with different bulk potentials, the three dimensional Cahn-Hilliard equation with singularities, and the set of Cahn-Hilliard equations. The numerical results demonstrate the effectiveness of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18054v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huang Qiumei, Ma Jiaxuan, Xu Zhen</dc:creator>
    </item>
    <item>
      <title>Local Discontinuous Galerkin method for fractional Korteweg-de Vries equation</title>
      <link>https://arxiv.org/abs/2404.18069</link>
      <description>arXiv:2404.18069v1 Announce Type: new 
Abstract: We propose a local discontinuous Galerkin (LDG) method for fractional Korteweg-de Vries equation involving the fractional Laplacian with exponent $\alpha\in (1,2)$ in one and two space dimensions. By decomposing the fractional Laplacian into a first order derivative and a fractional integral, we prove $L^2$-stability of the semi-discrete LDG scheme incorporating suitable interface and boundary fluxes. We analyze the error estimate by considering linear convection term and utilizing the estimate, we derive the error estimate for general nonlinear flux and demonstrate an order of convergence $\mathcal{O}(h^{k+1/2})$. Moreover, the stability and error analysis have been extended to multiple space dimensional case. Additionally, we devise a fully discrete LDG scheme using the four-stage fourth-order Runge-Kutta method. We prove that the scheme is strongly stable under an appropriate time step constraint by establishing a \emph{three-step strong stability} estimate. Numerical illustrations are shown to demonstrate the efficiency of the scheme by obtaining an optimal order of convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18069v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Mukul Dwivedi, Tanmay Sarkar</dc:creator>
    </item>
    <item>
      <title>Quasi-interpolation projectors for Subdivision Surfaces</title>
      <link>https://arxiv.org/abs/2404.18102</link>
      <description>arXiv:2404.18102v1 Announce Type: new 
Abstract: Subdivision surfaces are considered as an extension of splines to accommodate models with complex topologies, making them useful for addressing PDEs on models with complex topologies in isogeometric analysis. This has generated a lot of interest in the field of subdivision space approximation. The quasi-interpolation offers a highly efficient approach for spline approximation, eliminating the necessity of solving large linear systems of equations. Nevertheless, the lack of analytical expressions at extraordinary points on subdivision surfaces makes traditional techniques for creating B-spline quasi-interpolants inappropriate for subdivision spaces. To address this obstacle, this paper innovatively reframes the evaluation issue associated with subdivision surfaces as a correlation between subdivision matrices and limit points, offering a thorough method for quasi-interpolation specifically designed for subdivision surfaces. This developed quasi-interpolant, termed the subdivision space projection operator, accurately reproduces the subdivision space. We provide explicit quasi-interpolation formulas for various typical subdivision schemes. Numerical experiments demonstrate that the quasi-interpolants for Catmull-Clark and Loop subdivision exhibit third-order approximation in the (L_2) norm and second-order in the (L_\infty) norm. Furthermore, the modified Loop subdivision quasi-interpolant achieves optimal approximation rates in both the (L_2) and (L_\infty) norms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18102v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hailun Xu, Hongmei Kang</dc:creator>
    </item>
    <item>
      <title>An Arbitrarily High-Order Fully Well-balanced Hybrid Finite Element-Finite Volume Method for a One-dimensional Blood Flow Model</title>
      <link>https://arxiv.org/abs/2404.18124</link>
      <description>arXiv:2404.18124v1 Announce Type: new 
Abstract: In this paper, we propose an arbitrarily high-order accurate fully well-balanced numerical method for the one-dimensional blood flow model. The developed method is based on a continuous representation of the solution and a natural combination of the conservative and primitive formulations of the studied PDEs. The degrees of freedom are defined as point values at cell interfaces and moments of the conservative variables inside the cell, drawing inspiration from the discontinuous Galerkin method. The well-balanced property, in the sense of an exact preservation of both the zero and non-zero velocity equilibria, is achieved by a well-balanced approximation of the source term in the conservative formulation and a well-balanced residual computation in the primitive formulation. To lowest (3rd) order this method reduces to the method developed in [Abgrall and Liu, A New Approach for Designing Well-Balanced Schemes for the Shallow Water Equations: A Combination of Conservative and Primitive Formulations, arXiv preprint, arXiv:2304.07809]. Several numerical tests are shown to prove its well-balanced and high-order accuracy properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18124v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yongle Liu, Wasilij Barsukow</dc:creator>
    </item>
    <item>
      <title>An extension of the box method discrete fracture model (Box-DFM) to include low-permeable barriers with minimal additional degrees of freedom</title>
      <link>https://arxiv.org/abs/2404.18338</link>
      <description>arXiv:2404.18338v1 Announce Type: new 
Abstract: The box method discrete fracture model (Box-DFM) is an important finite volume-based discrete fracture model (DFM) to simulate flows in fractured porous media. In this paper, we investigate a simple but effective extension of the box method discrete fracture model to include low-permeable barriers. The method remains identical to the traditional Box-DFM [41, 48] in the absence of barriers. The inclusion of barriers requires only minimal additional degrees of freedom to accommodate pressure discontinuities and necessitates minor modifications to the original coding framework of the Box-DFM. We use extensive numerical tests on published benchmark problems and comparison with existing finite volume DFMs to demonstrate the validity and performance of the method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18338v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziyao Xu, Dennis Gl\"aser</dc:creator>
    </item>
    <item>
      <title>Bilinear optimal control for the Stokes-Brinkman equations: a priori and a posteriori error analyses</title>
      <link>https://arxiv.org/abs/2404.18348</link>
      <description>arXiv:2404.18348v1 Announce Type: new 
Abstract: We analyze a bilinear optimal control problem for the Stokes--Brinkman equations: the control variable enters the state equations as a coefficient. In two- and three-dimensional Lipschitz domains, we perform a complete continuous analysis that includes the existence of solutions and first- and second-order optimality conditions. We also develop two finite element methods that differ fundamentally in whether the admissible control set is discretized or not. For each of the proposed methods, we perform a convergence analysis and derive a priori error estimates; the latter under the assumption that the domain is convex. Finally, assuming that the domain is Lipschitz, we develop an a posteriori error estimator for each discretization scheme and obtain a global reliability bound.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18348v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alejandro Allendes, Gilberto Campa\~na, Enrique Otarola</dc:creator>
    </item>
    <item>
      <title>Critical grid method: An extensible Smoothed Particle Hydrodynamics fluid general interpolation method for Fluid-Structure Interaction surface coupling based on preCICE</title>
      <link>https://arxiv.org/abs/2404.18390</link>
      <description>arXiv:2404.18390v1 Announce Type: new 
Abstract: Solving Fluid-Structure Interaction (FSI) problems using traditional methods is a big challenge in the field of numerical simulation. As a powerful multi-physical field coupled library, preCICE has a bright application prospect for solving FSI, which supports many open/closed source software and commercial CFD solvers to solve FSI problems in the form of a black box. However, this library currently only supports mesh-based coupling schemes. This paper proposes a critical grid (mesh) as an intermediate medium for the particle method to connect a bidirectional coupling tool named preCICE. The particle and critical mesh are used to interpolate the displacement and force so that the pure Lagrangian Smoothed Particle Hydrodynamic (SPH) method can also solve the FSI problem. This method is called the particle mesh coupling (PMC) method, which theoretically solves the mesh mismatch problem based on the particle method to connect preCICE. In addition, we conduct experiments to verify the performance of the PMC method, in which the fluid and the structure is discretized by SPH and the Finite Element Method (FEM), respectively. The results show that the PMC method given in this paper is effective for solving FSI problems. Finally, our source code for the SPH fluid adapter is open-source and available on GitHub for further developing preCICE compatibility with more meshless methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18390v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Sifan Long, Xiaowei Guo, Xiaokang Fan, Canqun Yang</dc:creator>
    </item>
    <item>
      <title>Efficient bound preserving and asymptotic preserving semi-implicit schemes for the fast reaction-diffusion system</title>
      <link>https://arxiv.org/abs/2404.18463</link>
      <description>arXiv:2404.18463v1 Announce Type: new 
Abstract: We consider a special type of fast reaction-diffusion systems in which the coefficients of the reaction terms of the two substances are much larger than those of the diffusion terms while the diffusive motion to the substrate is negligible. Specifically speaking, the rate constants of the reaction terms are $O(1/\epsilon)$ while the diffusion coefficients are $O(1)$ where the parameter $\epsilon$ is small. When the rate constants of the reaction terms become highly large, i.e. $\epsilon$ tends to 0, the singular limit behavior of such a fast reaction-diffusion system is inscribed by the Stefan problem with latent heat, which brings great challenges in numerical simulations. In this paper, we adopt a semi-implicit scheme, which is first-order accurate in time and can accurately approximate the interface propagation even when the reaction becomes extremely fast, that is to say, the parameter $\epsilon$ is sufficiently small. The scheme satisfies the positivity, bound preserving properties and has $L^2$ stability and the linearized stability results of the system. For better performance on numerical simulations, we then construct a semi-implicit Runge-Kutta scheme which is second-order accurate in time. Numerous numerical tests are carried out to demonstrate the properties, such as the order of accuracy, positivity and bound preserving, the capturing of the sharp interface with various $\epsilon$ and to simulate the dynamics of the substances and the substrate, and to explore the heat transfer process, such as solid melting or liquid solidification in two dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18463v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu Zhao, Zhennan Zhou</dc:creator>
    </item>
    <item>
      <title>R3MG: R-tree based agglomeration of polytopal grids with applications to multilevel methods</title>
      <link>https://arxiv.org/abs/2404.18505</link>
      <description>arXiv:2404.18505v1 Announce Type: new 
Abstract: We present a novel approach to perform agglomeration of polygonal and polyhedral grids based on spatial indices. Agglomeration strategies are a key ingredient in polytopal methods for PDEs as they are used to generate (hierarchies of) computational grids from an initial grid. Spatial indices are specialized data structures that significantly accelerate queries involving spatial relationships in arbitrary space dimensions. We show how the construction of the R-tree spatial database of an arbitrary fine grid offers a natural and efficient agglomeration strategy with the following characteristics: i) the process is fully automated, robust, and dimension-independent, ii) it automatically produces a balanced and nested hierarchy of agglomerates, and iii) the shape of the agglomerates is tightly close to the respective axis aligned bounding boxes. Moreover, the R-tree approach provides a full hierarchy of nested agglomerates which permits fast query and allows for efficient geometric multigrid methods to be applied also to those cases where a hierarchy of grids is not present at construction time. We present several examples based on polygonal discontinuous Galerkin methods, confirming the effectiveness of our approach in the context of challenging three-dimensional geometries and the design of geometric multigrid preconditioners.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18505v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marco Feder, Andrea Cangiani, Luca Heltai</dc:creator>
    </item>
    <item>
      <title>Multigrid method for nonlinear eigenvalue problems based on Newton iteration</title>
      <link>https://arxiv.org/abs/2404.18568</link>
      <description>arXiv:2404.18568v1 Announce Type: new 
Abstract: In this paper, a novel multigrid method based on Newton iteration is proposed to solve nonlinear eigenvalue problems. Instead of handling the eigenvalue $\lambda$ and eigenfunction $u$ separately, we treat the eigenpair $(\lambda, u)$ as one element in a product space $\mathbb R \times H_0^1(\Omega)$. Then in the presented multigrid method, only one discrete linear boundary value problem needs to be solved for each level of the multigrid sequence. Because we avoid solving large-scale nonlinear eigenvalue problems directly, the overall efficiency is significantly improved. The optimal error estimate and linear computational complexity can be derived simultaneously. In addition, we also provide an improved multigrid method coupled with a mixing scheme to further guarantee the convergence and stability of the iteration scheme. More importantly, we prove convergence for the residuals after each iteration step. For nonlinear eigenvalue problems, such theoretical analysis is missing from the existing literatures on the mixing iteration scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18568v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fei Xu, Manting Xie, Meiling Yue</dc:creator>
    </item>
    <item>
      <title>Exponential Convergence of $hp$-ILGFEM for semilinear elliptic boundary value problems with monomial reaction</title>
      <link>https://arxiv.org/abs/2404.18569</link>
      <description>arXiv:2404.18569v1 Announce Type: new 
Abstract: We study the fully explicit numerical approximation of a semilinear elliptic boundary value model problem, which features a monomial reaction and analytic forcing, in a bounded polygon $\Omega\subset\mathbb{R}^2$ with a finite number of straight edges. In particular, we analyze the convergence of $hp$-type iterative linearized Galerkin ($hp$-ILG) solvers. Our convergence analysis is carried out for conforming $hp$-finite element (FE) Galerkin discretizations on sequences of regular, simplicial partitions of $\Omega$, with geometric corner refinement, with polynomial degrees increasing in sync with the geometric mesh refinement towards the corners of $\Omega$. For a sequence of discrete solutions generated by the ILG solver, with a stopping criterion that is consistent with the exponential convergence of the exact $hp$-FE Galerkin solution, we prove exponential convergence in $\mathrm{H}^1(\Omega)$ to the unique weak solution of the boundary value problem. Numerical experiments illustrate the exponential convergence of the numerical approximations obtained from the proposed scheme in terms of the number of degrees of freedom as well as of the computational complexity involved.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18569v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yanchen He, Paul Houston, Christoph Schwab, Thomas P. Wihler</dc:creator>
    </item>
    <item>
      <title>Beating Posits at Their Own Game: Takum Arithmetic</title>
      <link>https://arxiv.org/abs/2404.18603</link>
      <description>arXiv:2404.18603v1 Announce Type: new 
Abstract: Recent evaluations have highlighted the tapered posit number format as a promising alternative to the uniform precision IEEE 754 floating-point numbers, which suffer from various deficiencies. Although the posit encoding scheme offers superior coding efficiency at values close to unity, its efficiency markedly diminishes with deviation from unity. This reduction in efficiency leads to suboptimal encodings and a consequent diminution in dynamic range, thereby rendering posits suboptimal for general-purpose computer arithmetic.
  This paper introduces and formally proves 'takum' as a novel general-purpose logarithmic tapered-precision number format, synthesising the advantages of posits in low-bit applications with high encoding efficiency for numbers distant from unity. Takums exhibit an asymptotically constant dynamic range in terms of bit string length, which is delineated in the paper to be suitable for a general-purpose number format. It is demonstrated that takums either match or surpass existing alternatives. Moreover, takums address several issues previously identified in posits while unveiling novel and beneficial arithmetic properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18603v1</guid>
      <category>math.NA</category>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Laslo Hunhold</dc:creator>
    </item>
    <item>
      <title>Analysis for Implicit and Implicit-Explicit ADER and DeC Methods for Ordinary Differential Equations, Advection-Diffusion and Advection-Dispersion Equations</title>
      <link>https://arxiv.org/abs/2404.18626</link>
      <description>arXiv:2404.18626v1 Announce Type: new 
Abstract: In this manuscript, we present the development of implicit and implicit-explicit ADER and DeC methodologies within the DeC framework using the two-operators formulation, with a focus on their stability analysis both as solvers for ordinary differential equations (ODEs) and within the context of linear partial differential equations (PDEs). To analyze their stability, we reinterpret these methods as Runge-Kutta schemes and uncover significant variations in stability behavior, ranging from A-stable to bounded stability regions, depending on the chosen order, method, and quadrature nodes. This differentiation contrasts with their explicit counterparts. When applied to advection-diffusion and advection-dispersion equations employing finite difference spatial discretization, the von Neumann stability analysis demonstrates stability under CFL-like conditions. Particularly noteworthy is the stability maintenance observed for the advection-diffusion equation, even under spatial-independent constraints. Furthermore, we establish precise boundaries for relevant coefficients and provide suggestions regarding the suitability of specific schemes for different problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18626v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Philipp \"Offner, Louis Petri, Davide Torlo</dc:creator>
    </item>
    <item>
      <title>Efficient preconditioners for coupled Stokes-Darcy problems</title>
      <link>https://arxiv.org/abs/2404.18639</link>
      <description>arXiv:2404.18639v1 Announce Type: new 
Abstract: Coupled systems of free flow and porous media arise in a variety of technical and environmental applications. For laminar flow regimes, such systems are described by the Stokes equations in the free-flow region and Darcy's law in the porous medium. An appropriate set of coupling conditions is needed on the fluid-porous interface. Discretisations of the Stokes-Darcy problems yield large, sparse, ill-conditioned, and, depending on the interface conditions, non-symmetric linear systems. Therefore, robust and efficient preconditioners are needed to accelerate convergence of the applied Krylov method. In this work, we develop and investigate block diagonal, block triangular and constraint preconditioners for the coupled Stokes-Darcy problems. We apply two classical sets of coupling conditions considering the Beavers-Joseph and the Beavers-Joseph-Saffman condition for the tangential velocity. For the Beavers-Joseph interface condition, the resulting system is non-symmetric, therefore GMRES method is used. Spectral and field-of-values bounds independent of the grid width are derived for the exact versions of the preconditioners. Furthermore, we develop efficient inexact versions of the preconditioners. We demonstrate the effectiveness and robustness of the proposed preconditioners in numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18639v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paula Strohbeck, Iryna Rybak</dc:creator>
    </item>
    <item>
      <title>Exact symmetry conservation and automatic mesh refinement in discrete initial boundary value problems</title>
      <link>https://arxiv.org/abs/2404.18676</link>
      <description>arXiv:2404.18676v1 Announce Type: new 
Abstract: We present a novel solution procedure for initial boundary value problems. The procedure is based on an action principle, in which coordinate maps are included as dynamical degrees of freedom. This reparametrization invariant action is formulated in an abstract parameter space and an energy density scale associated with the space-time coordinates separates the dynamics of the coordinate maps and of the propagating fields. Treating coordinates as dependent, i.e. dynamical quantities, offers the opportunity to discretize the action while retaining all space-time symmetries and also provides the basis for automatic adaptive mesh refinement (AMR). The presence of unbroken space-time symmetries after discretization also ensures that the associated continuum Noether charges remain exactly conserved. The presence of coordinate maps in addition provides new freedom in the choice of boundary conditions. An explicit numerical example for wave propagation in $1+1$ dimensions is provided, using recently developed regularized summation-by-parts finite difference operators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18676v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>hep-lat</category>
      <category>hep-th</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Rothkopf, W. A. Horowitz, Jan Nordstr\"om</dc:creator>
    </item>
    <item>
      <title>Exploring Chebyshev Polynomial Approximations: Error Estimates for Functions of Bounded Variation</title>
      <link>https://arxiv.org/abs/2404.18723</link>
      <description>arXiv:2404.18723v1 Announce Type: new 
Abstract: Approximation theory plays a central role in numerical analysis, undergoing continuous evolution through a spectrum of methodologies. Notably, Lebesgue, Weierstrass, Fourier, and Chebyshev approximations stand out among these methods. However, each technique possesses inherent limitations, underscoring the critical importance of selecting an appropriate approximation method tailored to specific problem domains. This article delves into the utilization of Chebyshev polynomials at Chebyshev nodes for approximation. For sufficiently smooth functions, the partial sum of Chebyshev series expansion offers optimal polynomial approximation, rendering it a preferred choice in various applications such as digital signal processing and graph filters due to its computational efficiency. In this article, we focus on functions of bounded variation, which find numerous applications across mathematical physics, hyperbolic conservations, and optimization. We present two optimal error estimations associated with Chebyshev polynomial approximations tailored for such functions. To validate our theoretical assertions, we conduct numerical experiments. Additionally, we delineate promising future avenues aligned with this research, particularly within the realms of machine learning and related fields.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18723v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>S Akansha</dc:creator>
    </item>
    <item>
      <title>Extending h adaptivity with refinement patterns</title>
      <link>https://arxiv.org/abs/2404.18800</link>
      <description>arXiv:2404.18800v1 Announce Type: new 
Abstract: This contribution introduces the idea of refinement patterns for the generation of optimal meshes in the context of the Finite Element Method. The main idea is to generate a library of possible patterns on which elements can be refined and use this library to inform an h adaptive code on how to handle complex refinements in regions of interest. There are no restrictions on the type of elements that can be refined, and the patterns can be generated for any element type. The main advantage of this approach is that it allows for the generation of optimal meshes in a systematic way where, even if a certain pattern is not available, it can easily be included through a simple text file with nodes and sub-elements. The contribution presents a detailed methodology for incorporating refinement patterns into h adaptive Finite Element Method codes and demonstrates the effectiveness of the approach through mesh refinement of problems with complex geometries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18800v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Giovane Avancini, Nathan Shauer, Francisco T. Orlandini, Paulo Cesar A. Lucci, Philippe R. B. Devloo</dc:creator>
    </item>
    <item>
      <title>Accurate adaptive deep learning method for solving elliptic problems</title>
      <link>https://arxiv.org/abs/2404.18838</link>
      <description>arXiv:2404.18838v1 Announce Type: new 
Abstract: Deep learning method is of great importance in solving partial differential equations. In this paper, inspired by the failure-informed idea proposed by Gao et.al. (SIAM Journal on Scientific Computing 45(4)(2023)) and as an improvement, a new accurate adaptive deep learning method is proposed for solving elliptic problems, including the interface problems and the convection-dominated problems. Based on the failure probability framework, the piece-wise uniform distribution is used to approximate the optimal proposal distribution and an kernel-based method is proposed for efficient sampling. Together with the improved Levenberg-Marquardt optimization method, the proposed adaptive deep learning method shows great potential in improving solution accuracy. Numerical tests on the elliptic problems without interface conditions, on the elliptic interface problem, and on the convection-dominated problems demonstrate the effectiveness of the proposed method, as it reduces the relative errors by a factor varying from $10^2$ to $10^4$ for different cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18838v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>stat.CO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jingyong Ying, Yaqi Xie, Jiao Li, Hongqiao Wang</dc:creator>
    </item>
    <item>
      <title>Construction of local reduced spaces for Friedrichs' systems via randomized training</title>
      <link>https://arxiv.org/abs/2404.18839</link>
      <description>arXiv:2404.18839v1 Announce Type: new 
Abstract: This contribution extends the localized training approach, traditionally employed for multiscale problems and parameterized partial differential equations (PDEs) featuring locally heterogeneous coefficients, to the class of linear, positive symmetric operators, known as Friedrichs' operators. Considering a local subdomain with corresponding oversampling domain we prove the compactness of the transfer operator which maps boundary data to solutions on the interior domain. While a Caccioppoli-inequality quantifying the energy decay to the interior holds true for all Friedrichs' systems, showing a compactness result for the graph-spaces hosting the solution is additionally necessary. We discuss the mixed formulation of a convection-diffusion-reaction problem where the necessary compactness result is obtained by the Picard-Weck-Weber theorem. Our numerical results, focusing on a scenario involving heterogeneous diffusion fields with multiple high-conductivity channels, demonstrate the effectiveness of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18839v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christian Engwer, Mario Ohlberger, Lukas Renelt</dc:creator>
    </item>
    <item>
      <title>Deep orthogonal decomposition: a continuously adaptive data-driven approach to model order reduction</title>
      <link>https://arxiv.org/abs/2404.18841</link>
      <description>arXiv:2404.18841v1 Announce Type: new 
Abstract: We develop a novel deep learning technique, termed Deep Orthogonal Decomposition (DOD), for dimensionality reduction and reduced order modeling of parameter dependent partial differential equations. The approach consists in the construction of a deep neural network model that approximates the solution manifold through a continuously adaptive local basis. In contrast to global methods, such as Principal Orthogonal Decomposition (POD), the adaptivity allows the DOD to overcome the Kolmogorov barrier, making the approach applicable to a wide spectrum of parametric problems. Furthermore, due to its hybrid linear-nonlinear nature, the DOD can accommodate both intrusive and nonintrusive techniques, providing highly interpretable latent representations and tighter control on error propagation. For this reason, the proposed approach stands out as a valuable alternative to other nonlinear techniques, such as deep autoencoders. The methodology is discussed both theoretically and practically, evaluating its performances on problems featuring nonlinear PDEs, singularities, and parametrized geometries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18841v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicola Rares Franco, Andrea Manzoni, Paolo Zunino, Jan S. Hesthaven</dc:creator>
    </item>
    <item>
      <title>Finite Element Approximation of the Fractional Porous Medium Equation</title>
      <link>https://arxiv.org/abs/2404.18901</link>
      <description>arXiv:2404.18901v1 Announce Type: new 
Abstract: We construct a finite element method for the numerical solution of a fractional porous medium equation on a bounded open Lipschitz polytopal domain $\Omega \subset \mathbb{R}^{d}$, where $d = 2$ or $3$. The pressure in the model is defined as the solution of a fractional Poisson equation, involving the fractional Neumann Laplacian in terms of its spectral definition. We perform a rigorous passage to the limit as the spatial and temporal discretization parameters tend to zero and show that a subsequence of the sequence of finite element approximations defined by the proposed numerical method converges to a bounded and nonnegative weak solution of the initial-boundary-value problem under consideration. This result can be therefore viewed as a constructive proof of the existence of a nonnegative, energy-dissipative, weak solution to the initial-boundary-value problem for the fractional porous medium equation under consideration, based on the Neumann Laplacian. The convergence proof relies on results concerning the finite element approximation of the spectral fractional Laplacian and compactness techniques for nonlinear partial differential equations, together with properties of the equation, which are shown to be inherited by the numerical method. We also prove that the total energy associated with the problem under consideration exhibits exponential decay in time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18901v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jos\'e A. Carrillo, Stefano Fronzoni, Endre S\"uli</dc:creator>
    </item>
    <item>
      <title>Physically recurrent neural network for rate and path-dependent heterogeneous materials in a finite strain framework</title>
      <link>https://arxiv.org/abs/2404.17583</link>
      <description>arXiv:2404.17583v1 Announce Type: cross 
Abstract: In this work, a hybrid physics-based data-driven surrogate model for the microscale analysis of heterogeneous material is investigated. The proposed model benefits from the physics-based knowledge contained in the constitutive models used in the full-order micromodel by embedding them in a neural network. Following previous developments, this paper extends the applicability of the physically recurrent neural network (PRNN) by introducing an architecture suitable for rate-dependent materials in a finite strain framework. In this model, the homogenized deformation gradient of the micromodel is encoded into a set of deformation gradients serving as input to the embedded constitutive models. These constitutive models compute stresses, which are combined in a decoder to predict the homogenized stress, such that the internal variables of the history-dependent constitutive models naturally provide physics-based memory for the network. To demonstrate the capabilities of the surrogate model, we consider a unidirectional composite micromodel with transversely isotropic elastic fibers and elasto-viscoplastic matrix material. The extrapolation properties of the surrogate model trained to replace such micromodel are tested on loading scenarios unseen during training, ranging from different strain-rates to cyclic loading and relaxation. Speed-ups of three orders of magnitude with respect to the runtime of the original micromodel are obtained.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17583v1</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>M. A. Maia, I. B. C. M. Rocha, D. Kova\v{c}evi\'c, F. P. van der Meer</dc:creator>
    </item>
    <item>
      <title>BiLO: Bilevel Local Operator Learning for PDE inverse problems</title>
      <link>https://arxiv.org/abs/2404.17789</link>
      <description>arXiv:2404.17789v1 Announce Type: cross 
Abstract: We propose a new neural network based method for solving inverse problems for partial differential equations (PDEs) by formulating the PDE inverse problem as a bilevel optimization problem. At the upper level, we minimize the data loss with respect to the PDE parameters. At the lower level, we train a neural network to locally approximate the PDE solution operator in the neighborhood of a given set of PDE parameters, which enables an accurate approximation of the descent direction for the upper level optimization problem. The lower level loss function includes the L2 norms of both the residual and its derivative with respect to the PDE parameters. We apply gradient descent simultaneously on both the upper and lower level optimization problems, leading to an effective and fast algorithm. The method, which we refer to as BiLO (Bilevel Local Operator learning), is also able to efficiently infer unknown functions in the PDEs through the introduction of an auxiliary variable. We demonstrate that our method enforces strong PDE constraints, is robust to sparse and noisy data, and eliminates the need to balance the residual and the data loss, which is inherent to soft PDE constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17789v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ray Zirui Zhang, Xiaohui Xie, John Lowengrub</dc:creator>
    </item>
    <item>
      <title>On Quantum Algorithms for Efficient Solutions of General Classes of Structured Markov Processes</title>
      <link>https://arxiv.org/abs/2404.17959</link>
      <description>arXiv:2404.17959v1 Announce Type: cross 
Abstract: We study the fundamental problem of efficiently computing the stationary distribution of general classes of structured Markov processes. In strong contrast with previous work, we consider this problem within the context of quantum computational environments from a mathematical perspective and devise the first quantum algorithms for computing the stationary distribution of structured Markov processes. We derive a mathematical analysis of the computational properties of our quantum algorithms together with related theoretical results, establishing that our quantum algorithms provide the potential for significant computational improvements over that of the best-known classical algorithms in various settings of both theoretical and practical importance. Although motivated by structured Markov processes, our quantum algorithms have the potential for being exploited to address a much larger class of numerical computation problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17959v1</guid>
      <category>quant-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Vasileios Kalantzis, Mark S. Squillante, Shashanka Ubaru</dc:creator>
    </item>
    <item>
      <title>Swarm-based gradient descent meets simulated annealing</title>
      <link>https://arxiv.org/abs/2404.18015</link>
      <description>arXiv:2404.18015v1 Announce Type: cross 
Abstract: We introduce a novel method for non-convex optimization which is at the interface between the swarm-based gradient-descent (SBGD) [J. Lu et. al., ArXiv:2211.17157; E.Tadmor and A. Zenginoglu, Acta Applicandae Math., 190, 2024] and Simulated Annealing (SA) [V. Cerny, J. optimization theory and appl., 45:41-51, 1985; S.Kirkpatrick et. al., Science, 220(4598):671-680, 1983; S. Geman and C.-R. Hwang, SIAM J. Control and Optimization, 24(5):1031-1043, 1986]. We follow the methodology of SBGD in which a swarm of agents, each identified with a position, ${\mathbf x}$ and mass $m$, explores the ambient space. The agents proceed in gradient descent direction, and are subject to Brownian motion with annealing-rate dictated by a decreasing function of their mass. Thus, instead of the SA protocol for time-decreasing temperature, we let the swarm decide how to `cool down' agents, depending on their accumulated mass over time. The dynamics of masses is coupled with the dynamics of positions: agents at higher ground transfer (part of) their mass to those at lower ground. Consequently, the swarm is dynamically divided between heavier, cooler agents viewed as `leaders' and lighter, warmer agents viewed as `explorers'. Mean-field convergence analysis and benchmark optimizations demonstrate the effectiveness of the swarm-based method as a multi-dimensional global optimizer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18015v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhiyan Ding, Martin Guerra, Qin Li, Eitan Tadmor</dc:creator>
    </item>
    <item>
      <title>A Basis-preserving Algorithm for Computing the Bezout Matrix of Newton Polynomials</title>
      <link>https://arxiv.org/abs/2404.18117</link>
      <description>arXiv:2404.18117v1 Announce Type: cross 
Abstract: This paper tackles the problem of constructing Bezout matrices for Newton polynomials in a basis-preserving approach that operates directly with the given Newton basis, thus avoiding the need for transformation from Newton basis to monomial basis. This approach significantly reduces the computational cost and also mitigates numerical instability caused by basis transformation. For this purpose, we investigate the internal structure of Bezout matrices in Newton basis and design a basis-preserving algorithm that generates the Bezout matrix in the specified basis used to formulate the input polynomials. Furthermore, we show an application of the proposed algorithm on constructing confederate resultant matrices for Newton polynomials. Experimental results demonstrate that the proposed methods perform superior to the basis-transformation-based ones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18117v1</guid>
      <category>cs.SC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jing Yang, Wei Yang</dc:creator>
    </item>
    <item>
      <title>VoroTO: Multiscale Topology Optimization of Voronoi Structures using Surrogate Neural Networks</title>
      <link>https://arxiv.org/abs/2404.18300</link>
      <description>arXiv:2404.18300v1 Announce Type: cross 
Abstract: Cellular structures found in nature exhibit remarkable properties such as high strength, high energy absorption, excellent thermal/acoustic insulation, and fluid transfusion. Many of these structures are Voronoi-like; therefore researchers have proposed Voronoi multi-scale designs for a wide variety of engineering applications. However, designing such structures can be computationally prohibitive due to the multi-scale nature of the underlying analysis and optimization. In this work, we propose the use of a neural network (NN) to carry out efficient topology optimization (TO) of multi-scale Voronoi structures. The NN is first trained using Voronoi parameters (cell site locations, thickness, orientation, and anisotropy) to predict the homogenized constitutive properties. This network is then integrated into a conventional TO framework to minimize structural compliance subject to a volume constraint. Special considerations are given for ensuring positive definiteness of the constitutive matrix and promoting macroscale connectivity. Several numerical examples are provided to showcase the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18300v1</guid>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rahul Kumar Padhy, Krishnan Suresh, Aaditya Chandrasekhar</dc:creator>
    </item>
    <item>
      <title>Structure-preserving particle methods for the Landau collision operator using the metriplectic framework</title>
      <link>https://arxiv.org/abs/2404.18432</link>
      <description>arXiv:2404.18432v1 Announce Type: cross 
Abstract: We present a novel family of particle discretisation methods for the nonlinear Landau collision operator. We exploit the metriplectic structure underlying the Vlasov-Maxwell-Landau system in order to obtain disretisation schemes that automatically preserve mass, momentum, and energy, warrant monotonic dissipation of entropy, and are thus guaranteed to respect the laws of thermodynamics. In contrast to recent works that used radial basis functions and similar methods for regularisation, here we use an auxiliary spline or finite element representation of the distribution function to this end. Discrete gradient methods are employed to guarantee the aforementioned properties in the time discrete domain as well.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18432v1</guid>
      <category>physics.plasm-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sandra Jeyakumar, Michael Kraus, Matthew J. Hole, David Pfefferl\'e</dc:creator>
    </item>
    <item>
      <title>Optimal time sampling in physics-informed neural networks</title>
      <link>https://arxiv.org/abs/2404.18780</link>
      <description>arXiv:2404.18780v1 Announce Type: cross 
Abstract: Physics-informed neural networks (PINN) is a extremely powerful paradigm used to solve equations encountered in scientific computing applications. An important part of the procedure is the minimization of the equation residual which includes, when the equation is time-dependent, a time sampling. It was argued in the literature that the sampling need not be uniform but should overweight initial time instants, but no rigorous explanation was provided for these choice. In this paper we take some prototypical examples and, under standard hypothesis concerning the neural network convergence, we show that the optimal time sampling follows a truncated exponential distribution. In particular we explain when the time sampling is best to be uniform and when it should not be. The findings are illustrated with numerical examples on linear equation, Burgers' equation and the Lorenz system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18780v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Gabriel Turinici</dc:creator>
    </item>
    <item>
      <title>Interpolating between Optimal Transport and KL regularized Optimal Transport using R\'enyi Divergences</title>
      <link>https://arxiv.org/abs/2404.18834</link>
      <description>arXiv:2404.18834v1 Announce Type: cross 
Abstract: Regularized optimal transport (OT) has received much attention in recent years starting from Cuturi's paper with Kullback-Leibler (KL) divergence regularized OT. In this paper, we propose to regularize the OT problem using the family of $\alpha$-R\'enyi divergences for $\alpha \in (0, 1)$. R\'enyi divergences are neither $f$-divergences nor Bregman distances, but they recover the KL divergence in the limit $\alpha \nearrow 1$. The advantage of introducing the additional parameter $\alpha$ is that for $\alpha \searrow 0$ we obtain convergence to the unregularized OT problem. For the KL regularized OT problem, this was achieved by letting the regularization parameter tend to zero, which causes numerical instabilities. We present two different ways to obtain premetrics on probability measures, namely by R\'enyi divergence constraints and penalization. The latter premetric interpolates between the unregularized and KL regularized OT problem with weak convergence of the minimizer, generalizing the interpolating property of KL regularized OT. We use a nested mirror descent algorithm for solving the primal formulation. Both on real and synthetic data sets R\'enyi regularized OT plans outperform their KL and Tsallis counterparts in terms of being closer to the unregularized transport plans and recovering the ground truth in inference tasks better.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18834v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.FA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jonas Bresch, Viktor Stein</dc:creator>
    </item>
    <item>
      <title>A nonconforming primal hybrid finite element method for the two-dimensional vector Laplacian</title>
      <link>https://arxiv.org/abs/2206.10567</link>
      <description>arXiv:2206.10567v2 Announce Type: replace 
Abstract: We introduce a nonconforming hybrid finite element method for the two-dimensional vector Laplacian, based on a primal variational principle for which conforming methods are known to be inconsistent. Consistency is ensured using penalty terms similar to those used to stabilize hybridizable discontinuous Galerkin (HDG) methods, with a carefully chosen penalty parameter due to Brenner, Li, and Sung [Math. Comp., 76 (2007), pp. 573-595]. Our method accommodates elements of arbitrarily high order and, like HDG methods, it may be implemented efficiently using static condensation. The lowest-order case recovers the $P_1$-nonconforming method of Brenner, Cui, Li, and Sung [Numer. Math., 109 (2008), pp. 509-533], and we show that higher-order convergence is achieved under appropriate regularity assumptions. The analysis makes novel use of a family of weighted Sobolev spaces, due to Kondrat'ev, for domains admitting corner singularities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.10567v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mary Barker, Shuhao Cao, Ari Stern</dc:creator>
    </item>
    <item>
      <title>Distributed-Memory Randomized Algorithms for Sparse Tensor CP Decomposition</title>
      <link>https://arxiv.org/abs/2210.05105</link>
      <description>arXiv:2210.05105v3 Announce Type: replace 
Abstract: Candecomp / PARAFAC (CP) decomposition, a generalization of the matrix singular value decomposition to higher-dimensional tensors, is a popular tool for analyzing multidimensional sparse data. On tensors with billions of nonzero entries, computing a CP decomposition is a computationally intensive task. We propose the first distributed-memory implementations of two randomized CP decomposition algorithms, CP-ARLS-LEV and STS-CP, that offer nearly an order-of-magnitude speedup at high decomposition ranks over well-tuned non-randomized decomposition packages. Both algorithms rely on leverage score sampling and enjoy strong theoretical guarantees, each with varying time and accuracy tradeoffs. We tailor the communication schedule for our random sampling algorithms, eliminating expensive reduction collectives and forcing communication costs to scale with the random sample count. Finally, we optimize the local storage format for our methods, switching between analogues of compressed sparse column and compressed sparse row formats. Experiments show that our methods are fast and scalable, producing 11x speedup over SPLATT by decomposing the billion-scale Reddit tensor on 512 CPU cores in under two minutes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.05105v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3626183.3659980</arxiv:DOI>
      <dc:creator>Vivek Bharadwaj, Osman Asif Malik, Riley Murray, Aydin Bulu\c{c}, James Demmel</dc:creator>
    </item>
    <item>
      <title>Jump-preserving polynomial interpolation in non-manifold polyhedra</title>
      <link>https://arxiv.org/abs/2211.08223</link>
      <description>arXiv:2211.08223v3 Announce Type: replace 
Abstract: We construct a piecewise-polynomial interpolant $u \mapsto \Pi u$ for functions $u:\Omega \setminus \Gamma \to \mathbb{R}$, where $\Omega \subset \mathbb{R}^d$ is a Lipschitz polyhedron and $\Gamma \subset \Omega$ is a possibly non-manifold $(d-1)$-dimensional hypersurface. This interpolant enjoys approximation properties in relevant Sobolev norms, as well as a set of additional algebraic properties, namely, $\Pi^2 = \Pi$, and $\Pi$ preserves homogeneous boundary values and jumps of its argument on $\Gamma$. As an application, we obtain a bounded discrete right-inverse of the "jump" operator across $\Gamma$, and an error estimate for a Galerkin scheme to solve a second-order elliptic PDE in $\Omega$ with a prescribed jump across $\Gamma$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.08223v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martin Averseng</dc:creator>
    </item>
    <item>
      <title>Dissipative WENO stabilization of high-order discontinuous Galerkin methods for hyperbolic problems</title>
      <link>https://arxiv.org/abs/2309.12019</link>
      <description>arXiv:2309.12019v2 Announce Type: replace 
Abstract: We present a new approach to stabilizing high-order Runge-Kutta discontinuous Galerkin (RKDG) schemes using weighted essentially non-oscillatory (WENO) reconstructions in the context of hyperbolic conservation laws. In contrast to RKDG schemes that overwrite finite element solutions with WENO reconstructions, our approach employs the reconstruction-based smoothness sensor presented by Kuzmin and Vedral (J. Comput. Phys. 487:112153, 2023) to control the amount of added numerical dissipation. Incorporating a dissipation-based WENO stabilization term into a discontinuous Galerkin (DG) discretization, the proposed methodology achieves high-order accuracy while effectively capturing discontinuities in the solution. As such, our approach offers an attractive alternative to WENO-based slope limiters for DG schemes. The reconstruction procedure that we use performs Hermite interpolation on stencils composed of a mesh cell and its neighboring cells. The amount of numerical dissipation is determined by the relative differences between the partial derivatives of reconstructed candidate polynomials and those of the underlying finite element approximation. The employed smoothness sensor takes all derivatives into account to properly assess the local smoothness of a high-order DG solution. Numerical experiments demonstrate the ability of our scheme to capture discontinuities sharply. Optimal convergence rates are obtained for all polynomial degrees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.12019v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joshua Vedral</dc:creator>
    </item>
    <item>
      <title>New algebraic fast algorithms for $N$-body problems in two and three dimensions</title>
      <link>https://arxiv.org/abs/2309.14085</link>
      <description>arXiv:2309.14085v2 Announce Type: replace 
Abstract: This article presents two new algebraic algorithms to perform fast matrix-vector product for $N$-body problems in $d$ dimensions, namely nHODLR$d$D (nested algorithm) and s-nHODLR$d$D (semi-nested or partially nested algorithm). The nHODLR$d$D and s-nHODLR$d$D algorithms are the nested and semi-nested version of our previously proposed fast algorithm, the hierarchically off-diagonal low-rank matrix in $d$ dimensions (HODLR$d$D), respectively, where the admissible clusters are the certain far-field and the vertex-sharing clusters. We rely on algebraic low-rank approximation techniques (ACA and NCA) and develop both algorithms in a black-box (kernel-independent) fashion. The initialization time of the proposed hierarchical structures scales quasi-linearly. Using the nHODLR$d$D and s-nHODLR$d$D hierarchical structures, one can perform the multiplication of a dense matrix (arising out of $N$-body problems) with a vector that scales as $\mathcal{O}(pN)$ and $\mathcal{O}(pN \log(N))$, respectively, where $p$ grows at most poly logarithmically with $N$. The numerical results in $2$D and $3$D $(d=2,3)$ show that the proposed nHODLR$d$D algorithm is competitive to the algebraic Fast Multipole Method in $d$ dimensions with respect to the matrix-vector product time and space complexity. The C++ implementation with OpenMP parallelization of the proposed algorithms is available at \url{https://github.com/riteshkhan/nHODLRdD/}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.14085v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ritesh Khan, Sivaram Ambikasaran</dc:creator>
    </item>
    <item>
      <title>Constructive Representation of Functions in $N$-Dimensional Sobolev Space</title>
      <link>https://arxiv.org/abs/2312.00028</link>
      <description>arXiv:2312.00028v3 Announce Type: replace 
Abstract: A new representation is proposed for functions in a Sobolev space with dominating mixed smoothness on an $N$-dimensional hyperrectangle. In particular, it is shown that these functions can be expressed in terms of their highest-order mixed derivative, as well as their lower-order derivatives evaluated along suitable boundaries of the domain. The proposed expansion is proven to be invertible, uniquely identifying any function in the Sobolev space with its derivatives and boundary values. Since these boundary values are either finite-dimensional, or exist in the space of square-integrable functions, this offers a bijective relation between the Sobolev space and $L_{2}$. Using this bijection, it is shown how approximation of functions in Sobolev space can be performed in the less restrictive space $L_{2}$, reconstructing such an approximation of the function from an $L_{2}$-optimal projection of its boundary values and highest-order derivative. This approximation method is presented using a basis of Legendre polynomials and a basis of step functions, and results using both bases are demonstrated to exhibit better convergence behavior than a direct projection approach for two numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.00028v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Declan S. Jagt, Matthew M. Peet</dc:creator>
    </item>
    <item>
      <title>Bayesian sampling using interacting particles</title>
      <link>https://arxiv.org/abs/2401.13100</link>
      <description>arXiv:2401.13100v2 Announce Type: replace 
Abstract: Bayesian sampling is an important task in statistics and machine learning. Over the past decade, many ensemble-type sampling methods have been proposed. In contrast to the classical Markov chain Monte Carlo methods, these new methods deploy a large number of interactive samples, and the communication between these samples is crucial in speeding up the convergence. To justify the validity of these sampling strategies, the concept of interacting particles naturally calls for the mean-field theory. The theory establishes a correspondence between particle interactions encoded in a set of coupled ODEs/SDEs and a PDE that characterizes the evolution of the underlying distribution. This bridges numerical algorithms with the PDE theory used to show convergence in time. Many mathematical machineries are developed to provide the mean-field analysis, and we showcase two such examples: The coupling method and the compactness argument built upon the martingale strategy. The former has been deployed to show the convergence of ensemble Kalman sampler and ensemble Kalman inversion, and the latter will be shown to be immensely powerful in proving the validity of the Vlasov-Boltzmann simulator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.13100v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shi Chen, Zhiyan Ding, Qin Li</dc:creator>
    </item>
    <item>
      <title>Learning epidemic trajectories through Kernel Operator Learning: from modelling to optimal control</title>
      <link>https://arxiv.org/abs/2404.11130</link>
      <description>arXiv:2404.11130v2 Announce Type: replace 
Abstract: Since infectious pathogens start spreading into a susceptible population, mathematical models can provide policy makers with reliable forecasts and scenario analyses, which can be concretely implemented or solely consulted. In these complex epidemiological scenarios, machine learning architectures can play an important role, since they directly reconstruct data-driven models circumventing the specific modelling choices and the parameter calibration, typical of classical compartmental models. In this work, we discuss the efficacy of Kernel Operator Learning (KOL) to reconstruct population dynamics during epidemic outbreaks, where the transmission rate is ruled by an input strategy. In particular, we introduce two surrogate models, named KOL-m and KOL-$\partial$, which reconstruct in two different ways the evolution of the epidemics. Moreover, we evaluate the generalization performances of the two approaches with different kernels, including the Neural Tangent Kernels, and compare them with a classical neural network model learning method. Employing synthetic but semi-realistic data, we show how the two introduced approaches are suitable for realizing fast and robust forecasts and scenario analyses, and how these approaches are competitive for determining optimal intervention strategies with respect to specific performance measures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11130v2</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <category>q-bio.PE</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giovanni Ziarelli, Nicola Parolini, Marco Verani</dc:creator>
    </item>
    <item>
      <title>Structure-preserving neural networks for the regularized entropy-based closure of the Boltzmann moment system</title>
      <link>https://arxiv.org/abs/2404.14312</link>
      <description>arXiv:2404.14312v2 Announce Type: replace 
Abstract: The main challenge of large-scale numerical simulation of radiation transport is the high memory and computation time requirements of discretization methods for kinetic equations. In this work, we derive and investigate a neural network-based approximation to the entropy closure method to accurately compute the solution of the multi-dimensional moment system with a low memory footprint and competitive computational time. We extend methods developed for the standard entropy-based closure to the context of regularized entropy-based closures. The main idea is to interpret structure-preserving neural network approximations of the regularized entropy closure as a two-stage approximation to the original entropy closure. We conduct a numerical analysis of this approximation and investigate optimal parameter choices. Our numerical experiments demonstrate that the method has a much lower memory footprint than traditional methods with competitive computation times and simulation accuracy. The code and all trained networks are provided on GitHub https://github.com/ScSteffen/neuralEntropyClosures and https://github.com/CSMMLab/KiT-RT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14312v2</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Steffen Schotth\"ofer, M. Paul Laiu, Martin Frank, Cory D. Hauck</dc:creator>
    </item>
    <item>
      <title>Examining Policy Entropy of Reinforcement Learning Agents for Personalization Tasks</title>
      <link>https://arxiv.org/abs/2211.11869</link>
      <description>arXiv:2211.11869v4 Announce Type: replace-cross 
Abstract: This effort is focused on examining the behavior of reinforcement learning systems in personalization environments and detailing the differences in policy entropy associated with the type of learning algorithm utilized. We demonstrate that Policy Optimization agents often possess low-entropy policies during training, which in practice results in agents prioritizing certain actions and avoiding others. Conversely, we also show that Q-Learning agents are far less susceptible to such behavior and generally maintain high-entropy policies throughout training, which is often preferable in real-world applications. We provide a wide range of numerical experiments as well as theoretical justification to show that these differences in entropy are due to the type of learning being employed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.11869v4</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anton Dereventsov, Andrew Starnes, Clayton G. Webster</dc:creator>
    </item>
    <item>
      <title>Fast exact simulation of the first passage of a tempered stable subordinator across a non-increasing function</title>
      <link>https://arxiv.org/abs/2303.11964</link>
      <description>arXiv:2303.11964v3 Announce Type: replace-cross 
Abstract: We construct a fast exact algorithm for the simulation of the first-passage time, jointly with the undershoot and overshoot, of a tempered stable subordinator over an arbitrary non-increasing absolutely continuous function. We prove that the running time of our algorithm has finite exponential moments and provide bounds on its expected running time with explicit dependence on the characteristics of the process and the initial value of the function. The expected running time grows at most cubically in the stability parameter (as it approaches either $0$ or $1$) and is linear in the tempering parameter and the initial value of the function. Numerical performance, based on the implementation in the dedicated GitHub repository, exhibits a good agreement with our theoretical bounds. We provide numerical examples to illustrate the performance of our algorithm in Monte Carlo estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.11964v3</guid>
      <category>math.PR</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jorge Ignacio Gonz\'alez C\'azares, Feng Lin, Aleksandar Mijatovi\'c</dc:creator>
    </item>
    <item>
      <title>Reliable optimal controls for SEIR models in epidemiology</title>
      <link>https://arxiv.org/abs/2307.05415</link>
      <description>arXiv:2307.05415v3 Announce Type: replace-cross 
Abstract: We present and compare two different optimal control approaches applied to SEIR models in epidemiology, which allow us to obtain some policies for controlling the spread of an epidemic. The first approach uses Dynamic Programming to characterise the value function of the problem as the solution of a partial differential equation, the Hamilton-Jacobi-Bellman equation, and derive the optimal policy in feedback form. The second is based on Pontryagin's maximum principle and directly gives open-loop controls, via the solution of an optimality system of ordinary differential equations. This method, however, may not converge to the optimal solution. We propose a combination of the two methods in order to obtain high-quality and reliable solutions. Several simulations are presented and discussed, also checking first and second order necessary optimality conditions for the corresponding numerical solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.05415v3</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Simone Cacace, Alessio Oliviero</dc:creator>
    </item>
    <item>
      <title>Physics-constrained robust learning of open-form partial differential equations from limited and noisy data</title>
      <link>https://arxiv.org/abs/2309.07672</link>
      <description>arXiv:2309.07672v2 Announce Type: replace-cross 
Abstract: Unveiling the underlying governing equations of nonlinear dynamic systems remains a significant challenge. Insufficient prior knowledge hinders the determination of an accurate candidate library, while noisy observations lead to imprecise evaluations, which in turn result in redundant function terms or erroneous equations. This study proposes a framework to robustly uncover open-form partial differential equations (PDEs) from limited and noisy data. The framework operates through two alternating update processes: discovering and embedding. The discovering phase employs symbolic representation and a novel reinforcement learning (RL)-guided hybrid PDE generator to efficiently produce diverse open-form PDEs with tree structures. A neural network-based predictive model fits the system response and serves as the reward evaluator for the generated PDEs. PDEs with higher rewards are utilized to iteratively optimize the generator via the RL strategy and the best-performing PDE is selected by a parameter-free stability metric. The embedding phase integrates the initially identified PDE from the discovering process as a physical constraint into the predictive model for robust training. The traversal of PDE trees automates the construction of the computational graph and the embedding process without human intervention. Numerical experiments demonstrate our framework's capability to uncover governing equations from nonlinear dynamic systems with limited and highly noisy data and outperform other physics-informed neural network-based discovery methods. This work opens new potential for exploring real-world systems with limited understanding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.07672v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.AP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mengge Du, Yuntian Chen, Longfeng Nie, Siyu Lou, Dongxiao Zhang</dc:creator>
    </item>
    <item>
      <title>Convergence analysis of online algorithms for vector-valued kernel regression</title>
      <link>https://arxiv.org/abs/2309.07779</link>
      <description>arXiv:2309.07779v2 Announce Type: replace-cross 
Abstract: We consider the problem of approximating the regression function from noisy vector-valued data by an online learning algorithm using an appropriate reproducing kernel Hilbert space (RKHS) as prior. In an online algorithm, i.i.d. samples become available one by one by a random process and are successively processed to build approximations to the regression function. We are interested in the asymptotic performance of such online approximation algorithms and show that the expected squared error in the RKHS norm can be bounded by $C^2 (m+1)^{-s/(2+s)}$, where $m$ is the current number of processed data, the parameter $0&lt;s\leq 1$ expresses an additional smoothness assumption on the regression function and the constant $C$ depends on the variance of the input noise, the smoothness of the regression function and further parameters of the algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.07779v2</guid>
      <category>stat.ML</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Griebel, Peter Oswald</dc:creator>
    </item>
    <item>
      <title>Multi-Point Method using Effective Demodulation and Decomposition Techniques allowing Identification of Disturbing Loads in Power Grids</title>
      <link>https://arxiv.org/abs/2311.07129</link>
      <description>arXiv:2311.07129v2 Announce Type: replace-cross 
Abstract: The paper presents an innovative approach to identifying voltage fluctuation sources in power networks, also considering the localization understood as the indication of supply points of disturbing loads. The presented approach considers disturbance sources that change their operating state with a frequency higher than the power frequency. The implementation of the proposed solution is also proposed in such a way that its implementation in the smart meter infrastructure allows automatic localization of disturbance sources without additional expert knowledge. In the proposed approach, the modulation signal is estimated using a carrier signal estimator, which allows the estimation of a modulation signal with a frequency higher than the power frequency. The estimated modulating signal is decomposed into component signals associated with individual disturbing loads by decomposition by approximation using pulse waves. The decomposition process allows for the estimation of selected parameters associated with disturbing loads, on the basis of which the assessment of propagation of voltage fluctuations associated with the impact of individual disturbance sources is performed, which allows for the indication of their supply point. The proposed approach was verified in numerical simulation studies using MATLAB/SIMULINK and in experimental studies carried out in a real low-voltage power grid.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.07129v2</guid>
      <category>eess.SP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.epsr.2024.110335</arxiv:DOI>
      <arxiv:journal_reference>Kuwalek P., Wiczynski G., Multi-point method using effective demodulation and decomposition techniques allowing identification of disturbing loads in power grids, Electric Power Systems Research, vol. 231, art. no. 110335, 2024</arxiv:journal_reference>
      <dc:creator>Piotr Kuwa{\l}ek, Grzegorz Wiczy\'nski</dc:creator>
    </item>
    <item>
      <title>A mathematical model of the visual MacKay effect</title>
      <link>https://arxiv.org/abs/2311.07338</link>
      <description>arXiv:2311.07338v2 Announce Type: replace-cross 
Abstract: This paper investigates the intricate connection between visual perception and the mathematical modelling of neural activity in the primary visual cortex (V1). The focus is on modelling the visual MacKay effect [Mackay, Nature 1957]. While bifurcation theory has been a prominent mathematical approach for addressing issues in neuroscience, especially in describing spontaneous pattern formations in V1 due to parameter changes, it faces challenges in scenarios with localized sensory inputs. This is evident, for instance, in Mackay's psychophysical experiments, where the redundancy of visual stimuli information results in irregular shapes, making bifurcation theory and multi-scale analysis less effective. To address this, we follow a mathematical viewpoint based on the input-output controllability of an Amari-type neural fields model. In this framework, we consider sensory input as a control function, a cortical representation via the retino-cortical map of the visual stimulus that captures its distinct features. This includes highly localized information in the center of MacKay's funnel pattern "MacKay rays". From a control theory point of view, the Amari-type equation's exact controllability property is discussed for linear and nonlinear response functions. For the visual MacKay effect modelling, we adjust the parameter representing intra-neuron connectivity to ensure that cortical activity exponentially stabilizes to the stationary state in the absence of sensory input. Then, we perform quantitative and qualitative studies to demonstrate that they capture all the essential features of the induced after-image reported by MacKay.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.07338v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.NA</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cyprien Tamekue, Dario Prandi, Yacine Chitour</dc:creator>
    </item>
    <item>
      <title>End-to-End Mesh Optimization of a Hybrid Deep Learning Black-Box PDE Solver</title>
      <link>https://arxiv.org/abs/2404.11766</link>
      <description>arXiv:2404.11766v2 Announce Type: replace-cross 
Abstract: Deep learning has been widely applied to solve partial differential equations (PDEs) in computational fluid dynamics. Recent research proposed a PDE correction framework that leverages deep learning to correct the solution obtained by a PDE solver on a coarse mesh. However, end-to-end training of such a PDE correction model over both solver-dependent parameters such as mesh parameters and neural network parameters requires the PDE solver to support automatic differentiation through the iterative numerical process. Such a feature is not readily available in many existing solvers. In this study, we explore the feasibility of end-to-end training of a hybrid model with a black-box PDE solver and a deep learning model for fluid flow prediction. Specifically, we investigate a hybrid model that integrates a black-box PDE solver into a differentiable deep graph neural network. To train this model, we use a zeroth-order gradient estimator to differentiate the PDE solver via forward propagation. Although experiments show that the proposed approach based on zeroth-order gradient estimation underperforms the baseline that computes exact derivatives using automatic differentiation, our proposed method outperforms the baseline trained with a frozen input mesh to the solver. Moreover, with a simple warm-start on the neural network parameters, we show that models trained by these zeroth-order algorithms achieve an accelerated convergence and improved generalization performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11766v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shaocong Ma, James Diffenderfer, Bhavya Kailkhura, Yi Zhou</dc:creator>
    </item>
  </channel>
</rss>
