<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.IT</link>
    <description>math.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 22 Jan 2025 05:03:36 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Recent Advances of 6G Ultra-Massive MIMO Technologies in Spatial and Beam Domains</title>
      <link>https://arxiv.org/abs/2501.10429</link>
      <description>arXiv:2501.10429v1 Announce Type: new 
Abstract: To explore the full potential of ultra-massive multiple-input multiple-output (MIMO) communication systems, it is fundamental to understand new ultra-massive MIMO channel characteristics and establish pervasive channel models. On this basis, large dimensional spatial-temporal transmission and random access technologies need to be investigated and evaluated for better practical implementation. Firstly, this paper reviews recent advances of ultra-massive MIMO technologies in the traditional spatial domain, including wireless channel characterization and modeling, channel estimation, spatial multiplexing, and precoding. Secondly, considering the dramatic increase of base station (BS) antennas and access users in ultra-massive MIMO systems, the confronted high dimensional complexity and computing burden of these ultra-massive MIMO technologies are indicated. To provide efficient and systematic solution, the emerging tendency to transform related technologies from the traditional spatial domain to beam domain is introduced. The utilities of large sparsity merit, reduced energy consumption, and improved usage of radio frequency (RF) chains in the beam domain channel are elaborated. At last, future challenges of ultra-massive MIMO communication systems are discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10429v1</guid>
      <category>cs.IT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rui Feng, Cheng-Xiang Wang, Jie Huang, Xiqi Gao</dc:creator>
    </item>
    <item>
      <title>Prompt-Enabled Large AI Models for CSI Feedback</title>
      <link>https://arxiv.org/abs/2501.10629</link>
      <description>arXiv:2501.10629v1 Announce Type: new 
Abstract: Artificial intelligence (AI) has emerged as a promising tool for channel state information (CSI) feedback. While recent research primarily focuses on improving feedback accuracy through novel architectures, the underlying mechanisms of AI-based CSI feedback remain unclear. This study investigates these mechanisms by analyzing performance across diverse datasets and reveals that superior feedback performance stems from the strong fitting capabilities of AI models and their ability to leverage environmental knowledge. Building on these findings, we propose a prompt-enabled large AI model (LAM) for CSI feedback. The LAM employs powerful transformer blocks and is trained on extensive datasets from various scenarios. To further enhance reconstruction quality, the channel distribution -- represented as the mean of channel magnitude in the angular domain -- is incorporated as a prompt within the decoder. Simulation results confirm that the proposed prompt-enabled LAM significantly improves feedback accuracy and generalization performance while reducing data collection requirements in new scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10629v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiajia Guo, Yiming Cui, Chao-Kai Wen, Shi Jin</dc:creator>
    </item>
    <item>
      <title>Exploring the Potential of Large Language Models for Massive MIMO CSI Feedback</title>
      <link>https://arxiv.org/abs/2501.10630</link>
      <description>arXiv:2501.10630v1 Announce Type: new 
Abstract: Large language models (LLMs) have achieved remarkable success across a wide range of tasks, particularly in natural language processing and computer vision. This success naturally raises an intriguing yet unexplored question: Can LLMs be harnessed to tackle channel state information (CSI) compression and feedback in massive multiple-input multiple-output (MIMO) systems? Efficient CSI feedback is a critical challenge in next-generation wireless communication. In this paper, we pioneer the use of LLMs for CSI compression, introducing a novel framework that leverages the powerful denoising capabilities of LLMs -- capable of error correction in language tasks -- to enhance CSI reconstruction performance. To effectively adapt LLMs to CSI data, we design customized pre-processing, embedding, and post-processing modules tailored to the unique characteristics of wireless signals. Extensive numerical results demonstrate the promising potential of LLMs in CSI feedback, opening up possibilities for this research direction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10630v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiming Cui, Jiajia Guo, Chao-Kai Wen, Shi Jin, En Tong</dc:creator>
    </item>
    <item>
      <title>Constrained Coding for Composite DNA: Channel Capacity and Efficient Constructions</title>
      <link>https://arxiv.org/abs/2501.10645</link>
      <description>arXiv:2501.10645v1 Announce Type: new 
Abstract: Composite DNA is a recent novel method to increase the information capacity of DNA-based data storage above the theoretical limit of 2 bits/symbol. In this method, every composite symbol does not store a single DNA nucleotide but a mixture of the four nucleotides in a predetermined ratio. By using different mixtures and ratios, the alphabet can be extended to have much more than four symbols in the naive approach. While this method enables higher data content per synthesis cycle, potentially reducing the DNA synthesis cost, it also imposes significant challenges for accurate DNA sequencing since the base-level errors can easily change the mixture of bases and their ratio, resulting in changes to the composite symbols. With this motivation, we propose efficient constrained coding techniques to enforce the biological constraints, including the runlength-limited constraint and the GC-content constraint, into every DNA synthesized oligo, regardless of the mixture of bases in each composite letter and their corresponding ratio. Our goals include computing the capacity of the constrained channel, constructing efficient encoders/decoders, and providing the best options for the composite letters to obtain capacity-approaching codes. For certain codes' parameters, our methods incur only one redundant symbol.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10645v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tuan Thanh Nguyen, Chen Wang, Kui Cai, Yiwei Zhang, Zohar Yakhini</dc:creator>
    </item>
    <item>
      <title>Computing Capacity-Cost Functions for Continuous Channels in Wasserstein Space</title>
      <link>https://arxiv.org/abs/2501.10670</link>
      <description>arXiv:2501.10670v1 Announce Type: new 
Abstract: This paper investigates the problem of computing capacity-cost (C-C) functions for continuous channels. Motivated by the Kullback-Leibler divergence (KLD) proximal reformulation of the classical Blahut-Arimoto (BA) algorithm, the Wasserstein distance is introduced to the proximal term for the continuous case, resulting in an iterative algorithm related to the Wasserstein gradient descent. Practical implementation involves moving particles along the negative gradient direction of the objective function's first variation in the Wasserstein space and approximating integrals by the importance sampling (IS) technique. Such formulation is also applied to the rate-distortion (R-D) function for continuous source spaces and thus provides a unified computation framework for both problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10670v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinyang Li, Vlad C. Andrei, Ullrich J. M\"onich, Fan Liu, Holger Boche</dc:creator>
    </item>
    <item>
      <title>Energy Efficiency Maximization for Movable Antenna-Enhanced System Based on Statistical CSI</title>
      <link>https://arxiv.org/abs/2501.10694</link>
      <description>arXiv:2501.10694v1 Announce Type: new 
Abstract: This paper investigates an innovative movable antenna (MA)-enhanced multiple-input multiple-output (MIMO) system designed to enhance communication performance. We aim to maximize the energy efficiency (EE) under statistical channel state information (S-CSI) through a joint optimization of the transmit covariance matrix and the antenna position vectors (APVs). To solve the stochastic problem, we consider the large number of antennas scenario and resort to deterministic equivalent (DE) technology to reformulate the system EE w.r.t. the transmit variables, i.e., the transmit covariance matrix and APV, and the receive variables, i.e., the receive APV, respectively. Then, we propose an alternative optimization (AO) algorithm to update the transmit variables and the receive variables to maximize the system EE, respectively. Our numerical results reveal that, the proposed MA-enhanced system can significantly improve EE compared to several benchmark schemes and the optimal performance can be achieved with a finite size of movement regions for MAs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10694v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xintai Chen, Biqian Feng, Yongpeng Wu, Wenjun Zhang</dc:creator>
    </item>
    <item>
      <title>Subcodes of Second-Order Reed-Muller Codes via Recursive Subproducts</title>
      <link>https://arxiv.org/abs/2501.10700</link>
      <description>arXiv:2501.10700v1 Announce Type: new 
Abstract: We use a simple construction called `recursive subproducts' (that is known to yield good codes of lengths $n^m$, $n \geq 3$) to identify a family of codes sandwiched between first-order and second-order Reed-Muller (RM) codes. These codes are subcodes of multidimensional product codes that use first-order RM codes as components. We identify the minimum weight codewords of all the codes in this family, and numerically determine the weight distribution of some of them. While these codes have the same minimum distance and a smaller rate than second-order RM codes, they have significantly fewer minimum weight codewords. Further, these codes can be decoded via modifications to known RM decoders which yield codeword error rates within 0.25 dB of second-order RM codes and better than CRC-aided Polar codes (in terms of $E_b/N_o$ for lengths $256, 512, 1024$), thereby offering rate adaptation options for RM codes in low-capacity scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10700v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>A P Vaideeswaran, Madireddi Sai Harish, Lakshmi Prasad Natarajan</dc:creator>
    </item>
    <item>
      <title>Secure Communication in Dynamic RDARS-Driven Systems</title>
      <link>https://arxiv.org/abs/2501.10705</link>
      <description>arXiv:2501.10705v1 Announce Type: new 
Abstract: In this letter, we investigate a dynamic reconfigurable distributed antenna and reflection surface (RDARS)-driven secure communication system, where the working mode of the RDARS can be flexibly configured. We aim to maximize the secrecy rate by jointly designing the active beamforming vectors, reflection coefficients, and the channel-aware mode selection matrix. To address the non-convex binary and cardinality constraints introduced by dynamic mode selection, we propose an efficient alternating optimization (AO) framework that employs penalty-based fractional programming (FP) and successive convex approximation (SCA) transformations. Simulation results demonstrate the potential of RDARS in enhancing the secrecy rate and show its superiority compared to existing reflection surface-based schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10705v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziqian Pei, Jintao Wang, Pingping Zhang, Zheng Shi, Guanghua Yang, Shaodan Ma</dc:creator>
    </item>
    <item>
      <title>Poisson Hail on a Wireless Ground</title>
      <link>https://arxiv.org/abs/2501.10712</link>
      <description>arXiv:2501.10712v1 Announce Type: new 
Abstract: This paper defines a new model which incorporates three key ingredients of a large class of wireless communication systems: (1) spatial interactions through interference, (2) dynamics of the queueing type, with users joining and leaving, and (3) carrier sensing and collision avoidance as used in, e.g., WiFi. In systems using (3), rather than directly accessing the shared resources upon arrival, a customer is considerate and waits to access them until nearby users in service have left. This new model can be seen as a missing piece of a larger puzzle that contains such dynamics as spatial birth-and-death processes, the Poisson-Hail model, and wireless dynamics as key other pieces. It is shown that, under natural assumptions, this model can be represented as a Markov process on the space of counting measures. The main results are then two-fold. The first is on the shape of the stability region and, more precisely, on the characterization of the critical value of the arrival rate that separates stability from instability. The second is of a more qualitative or perhaps even ethical nature. There is evidence that for natural values of the system parameters, the implementation of sensing and collision avoidance stabilizes a system that would be unstable if immediate access to the shared resources would be granted. In other words, for these parameters, renouncing greedy access makes sharing sustainable, whereas indulging in greedy access kills the system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10712v1</guid>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fran\c{c}ois Baccelli, Ke Feng, Sergey Foss</dc:creator>
    </item>
    <item>
      <title>Analysis of Age-Energy Trade-off in IoT Networks Using Stochastic Geometry</title>
      <link>https://arxiv.org/abs/2501.10743</link>
      <description>arXiv:2501.10743v1 Announce Type: new 
Abstract: We study an internet of things (IoT) network where devices harvest energy from transmitter power. IoT devices use this harvested energy to operate and decode data packets. We propose a slot division scheme based on a parameter $\xi$, where the first phase is for energy harvesting (EH) and the second phase is for data transmission. We define the joint success probability (JSP) metric as the probability of the event that both the harvested energy and the received signal-to-interference ratio (SIR) exceed their respective thresholds. We provide lower and upper bounds of (JSP), as obtaining an exact JSP expression is challenging. Then, the peak age-of-information (PAoI) of data packets is determined using this framework. Higher slot intervals for EH reduce data transmission time, requiring higher link rates. In contrast, a lower EH slot interval will leave IoT devices without enough energy to decode the packets. We demonstrate that both non-preemptive and preemptive queuing disciplines may have the same optimal slot partitioning factor for maximizing the JSP and minimizing the PAoI. For different transmit powers and deployment areas, we recommend the optimal slot partitioning factor for the above two metrics under both queuing disciplines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10743v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Songita Das (Bharti School of Telecommunication Technology and Management, Indian Institute of Technology Delhi, New Delhi, India), Gourab Ghatak (Bharti School of Telecommunication Technology and Management, Indian Institute of Technology Delhi, New Delhi, India, Department of Electrical Engineering, Indian Institute of Technology Delhi, New Delhi, India)</dc:creator>
    </item>
    <item>
      <title>Pinching Antennas: Principles, Applications and Challenges</title>
      <link>https://arxiv.org/abs/2501.10753</link>
      <description>arXiv:2501.10753v1 Announce Type: new 
Abstract: Flexible-antenna systems, such as fluid antennas and movable antennas, have been recognized as key enabling technologies for sixth-generation (6G) wireless networks, as they can intelligently reconfigure the effective channel gains of the users and hence significantly improve their data transmission capabilities. However, existing flexible-antenna systems have been designed to combat small-scale fading in non-line-of-sight (NLoS) conditions. As a result, they lack the ability to establish line-of-sight links, which are typically 100 times stronger than NLoS links. In addition, existing flexible-antenna systems have limited flexibility, where adding/removing an antenna is not straightforward. This article introduces an innovative flexible-antenna system called pinching antennas, which are realized by applying small dielectric particles to waveguides. We first describe the basics of pinching-antenna systems and their ability to provide strong LoS links by deploying pinching antennas close to the users as well as their capability to scale up/down the antenna system. We then focus on communication scenarios with different numbers of waveguides and pinching antennas, where innovative approaches to implement multiple-input multiple-output and non-orthogonal multiple access are discussed. In addition, promising 6G-related applications of pinching antennas, including integrated sensing and communication and next-generation multiple access, are presented. Finally, important directions for future research, such as waveguide deployment and channel estimation, are highlighted.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10753v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zheng Yang, Ning Wang, Yanshi Sun, Zhiguo Ding, Robert Schober, George K. Karagiannidis, Vincent W. S. Wong, Octavia A. Dobre</dc:creator>
    </item>
    <item>
      <title>D2D Coded Caching Schemes for Multiaccess Networks with Combinatorial Access Topology</title>
      <link>https://arxiv.org/abs/2501.10756</link>
      <description>arXiv:2501.10756v1 Announce Type: new 
Abstract: This paper considers wireless device-to-device (D2D) coded caching in a multiaccess network, where the users communicate with each other and each user can access multiple cache nodes. Access topologies derived from two combinatorial designs known as the $t$-design and $t$-group divisible design ($t$-GDD), referred to as the $t$-design and $t$-GDD topologies respectively, which subsume a few other known topologies, have been studied for the multiaccess coded caching (MACC) network by Cheng \textit{et al.} in \cite{MACC_des}. These access topologies are extended to a multiaccess D2D coded caching (MADCC) network and novel MADCC schemes are proposed. MADCC network has been studied so far only for the cyclic wrap-around topology. Apart from the proposed novel MADCC schemes, MADCC schemes are also derived from the existing MACC schemes in \cite{MACC_des}. To compare the performance of different MADCC schemes, the metrics of load per user and subpacketization level are used while keeping the number of caches and cache memory size same. The proposed MADCC scheme with $t$-design topology performs better in terms of subpacketization level while achieving the same load per user compared to the MADCC scheme derived from the MACC scheme with $t$-design topology in \cite{MACC_des}. The proposed MADCC scheme with $t$-GDD topology performs better in terms of load per user while achieving the same subpacketization level compared to the MADCC scheme derived from the MACC scheme with $t$-GDD topology in \cite{MACC_des} in some cases. Compared to the existing MADCC scheme with cyclic wrap-around topology, the proposed MADCC scheme with $t$-design topology performs better in terms of load per user, and the proposed MADCC scheme with $t$-GDD topology performs better in terms of subpacketization level at the expense of an increase in load per user.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10756v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rashid Ummer N. T., B. Sundar Rajan</dc:creator>
    </item>
    <item>
      <title>A Novel Precoder for Peak-to-Average Power Ratio Reduction in OTFS Systems</title>
      <link>https://arxiv.org/abs/2501.10791</link>
      <description>arXiv:2501.10791v1 Announce Type: new 
Abstract: We consider the issue of high peak-to-average-power ratio (PAPR) of Orthogonal time frequency space (OTFS) modulated signals. This paper proposes a low-complexity novel iterative PAPR reduction method which achieves a PAPR reduction of roughly 5 dB when compared to a OTFS modulated signal without any PAPR compensation. Simulations reveal that the PAPR achieved by the proposed method is significantly better than that achieved by other state-of-art methods. Simulations also reveal that the error rate performance of OTFS based systems with the proposed PAPR reduction is similar to that achieved with the other state-of-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10791v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Saurabh Prakash, Venkatesh Khammammetti, Saif Khan Mohammed</dc:creator>
    </item>
    <item>
      <title>Information Content and Entropy of Finite Patterns from a Combinatorial Perspective</title>
      <link>https://arxiv.org/abs/2501.10824</link>
      <description>arXiv:2501.10824v1 Announce Type: new 
Abstract: A unified combinatorial definition of the information content and entropy of different types of patterns, compatible with the traditional concepts of information and entropy, going beyond the limitations of Shannon information interpretable for ergodic Markov processes. We compare the information content of various finite patterns and derive general properties of information quantity from these comparisons. Using these properties, we define normalized information estimation methods based on compression algorithms and Kolmogorov complexity. From a combinatorial point of view, we redefine the concept of entropy in a way that is asymptotically compatible with traditional entropy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10824v1</guid>
      <category>cs.IT</category>
      <category>cs.DM</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zsolt Pocze</dc:creator>
    </item>
    <item>
      <title>Achievable DoF Bounds for Cache-Aided Asymmetric MIMO Communications</title>
      <link>https://arxiv.org/abs/2501.10854</link>
      <description>arXiv:2501.10854v1 Announce Type: new 
Abstract: Integrating coded caching (CC) into multiple-input multiple-output (MIMO) communications can significantly enhance the achievable degrees of freedom (DoF) in wireless networks. This paper investigates a practical cache-aided asymmetric MIMO configuration with cache ratio $\gamma$, where a server equipped with $L$ transmit antennas communicates with $K$ users, each having $G_k$ receive antennas. We propose three content-aware MIMO-CC strategies: the \emph{min-G} scheme, which treats the system as symmetric by assuming all users have the same number of antennas, equal to the smallest among them; the \emph{Grouping} scheme, which maximizes spatial multiplexing gain separately within each user subset at the cost of some global caching gain; and the \emph{Phantom} scheme, which dynamically redistributes spatial resources using virtual or "phantom" antenna users, bridging the performance gains of the min-G and Grouping schemes. These strategies jointly optimize the number of users, $\Omega$, and the parallel streams decoded by each user, $\beta_k$, ensuring linear decodability for all target users. Analytical and numerical results confirm that the proposed schemes achieve significant DoF improvements across various system configurations, demonstrating the potential of content-aware MIMO-CC strategies for enhancing wireless network performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10854v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad NaseriTehrani, MohammadJavad Salehi, Antti T\"olli</dc:creator>
    </item>
    <item>
      <title>RIS Deployment Optimization with Iterative Detection and Decoding in Multiuser Multiple-Antenna Systems</title>
      <link>https://arxiv.org/abs/2501.10875</link>
      <description>arXiv:2501.10875v1 Announce Type: new 
Abstract: This work investigates a Reconfigurable Intelligent Surface (RIS)-assisted uplink system employing iterative detection and decoding (IDD) techniques. We analyze the impact of tuning system parameter tuning for several deployment configurations, including the number of users, access point (AP) antennas, and RIS elements on the IDD performance. Analytical results for both active and passive RIS in a single-input single-output (SISO) scenario demonstrate how deployment choices affect system performance. Numerical simulations confirm the robustness of the RIS-assisted IDD system to variations in these parameters, showing performance gains in certain configurations. Moreover, the findings indicate that the insights derived from SISO analysis extend to multiuser MIMO IDD systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10875v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>R. Porto, R. de Lamare</dc:creator>
    </item>
    <item>
      <title>Robust Joint Message and State Transmission under Arbitrarily Varying Jamming</title>
      <link>https://arxiv.org/abs/2501.10896</link>
      <description>arXiv:2501.10896v1 Announce Type: new 
Abstract: Joint message and state transmission under arbitrarily varying jamming attack is investigated. An inner bound of the robust capacity-distortion region is provided, which includes the worst-case communication rate and the worst-case estimation rate. The bound is optimal for the joint message and lossless state communication.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10896v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiqi Chen, Holger Boche</dc:creator>
    </item>
    <item>
      <title>A Semantic Approach to Successive Interference Cancellation for Multiple Access Networks</title>
      <link>https://arxiv.org/abs/2501.10926</link>
      <description>arXiv:2501.10926v1 Announce Type: new 
Abstract: Differing from the conventional communication system paradigm that models information source as a sequence of (i.i.d. or stationary) random variables, the semantic approach aims at extracting and sending the high-level features of the content deeply contained in the source, thereby breaking the performance limits from the statistical information theory. As a pioneering work in this area, the deep learning-enabled semantic communication (DeepSC) constitutes a novel algorithmic framework based on the transformer--which is a deep learning tool widely used to process text numerically. The main goal of this work is to extend the DeepSC approach from the point-to-point link to the multi-user multiple access channel (MAC). The inter-user interference has long been identified as the bottleneck of the MAC. In the classic information theory, the successive interference cancellation (SIC) scheme is a common way to mitigate interference and achieve the channel capacity. Our main contribution is to incorporate the SIC scheme into the DeepSC. As opposed to the traditional SIC that removes interference in the digital symbol domain, the proposed semantic SIC works in the domain of the semantic word embedding vectors. Furthermore, to enhance the training efficiency, we propose a pretraining scheme and a partial retraining scheme that quickly adjust the neural network parameters when new users are added to the MAC. We also modify the existing loss function to facilitate training. Finally, we present numerical experiments to demonstrate the advantage of the proposed semantic approach as compared to the existing benchmark methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10926v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>IEEE Internet of Things Journal 2024</arxiv:journal_reference>
      <dc:creator>Mingxiao Li, Kaiming Shen, Shuguang Cui</dc:creator>
    </item>
    <item>
      <title>Channel Coding for Gaussian Channels with Mean and Variance Constraints</title>
      <link>https://arxiv.org/abs/2501.10953</link>
      <description>arXiv:2501.10953v1 Announce Type: new 
Abstract: We consider channel coding for Gaussian channels with the recently introduced mean and variance cost constraints. Through matching converse and achievability bounds, we characterize the optimal first- and second-order performance. The main technical contribution of this paper is an achievability scheme which uses random codewords drawn from a mixture of three uniform distributions on $(n-1)$-spheres of radii $R_1, R_2$ and $R_3$, where $R_i = O(\sqrt{n})$ and $|R_i - R_j| = O(1)$. To analyze such a mixture distribution, we prove a lemma giving a uniform $O(\log n)$ bound, which holds with high probability, on the log ratio of the output distributions $Q_i^{cc}$ and $Q_j^{cc}$, where $Q_i^{cc}$ is induced by a random channel input uniformly distributed on an $(n-1)$-sphere of radius $R_i$. To facilitate the application of the usual central limit theorem, we also give a uniform $O(\log n)$ bound, which holds with high probability, on the log ratio of the output distributions $Q_i^{cc}$ and $Q^*_i$, where $Q_i^*$ is induced by a random channel input with i.i.d. components.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10953v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adeel Mahmood, Aaron B. Wagner</dc:creator>
    </item>
    <item>
      <title>Sequential Change Detection for Learning in Piecewise Stationary Bandit Environments</title>
      <link>https://arxiv.org/abs/2501.10974</link>
      <description>arXiv:2501.10974v1 Announce Type: new 
Abstract: A finite-horizon variant of the quickest change detection problem is investigated, which is motivated by a change detection problem that arises in piecewise stationary bandits. The goal is to minimize the \emph{latency}, which is smallest threshold such that the probability that the detection delay exceeds the threshold is below a desired low level, while controlling the false alarm probability to a desired low level. When the pre- and post-change distributions are unknown, two tests are proposed as candidate solutions. These tests are shown to attain order optimality in terms of the horizon. Furthermore, the growth in their latencies with respect to the false alarm probability and late detection probability satisfies a property that is desirable in regret analysis for piecewise stationary bandits. Numerical results are provided to validate the theoretical performance results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10974v1</guid>
      <category>cs.IT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <category>stat.OT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yu-Han Huang, Venugopal V. Veeravalli</dc:creator>
    </item>
    <item>
      <title>Wireless Control over Edge Networks: Joint User Association and Communication-Computation Co-Design</title>
      <link>https://arxiv.org/abs/2501.11015</link>
      <description>arXiv:2501.11015v1 Announce Type: new 
Abstract: This paper studies a wireless networked control system with multiple base stations (BSs) cooperatively coordinating the wireless control of a number of subsystems each consisting of a plant, a sensor, and an actuator. In this system, each sensor first offloads the sensing data to its associated BS, which then employs mobile edge computing (MEC) to process the data and sends the command signals back to the actuator for remote control. We consider the time-division-multiple-access (TDMA) service protocol among different BSs to facilitate the cascaded communication and computation process, in which different BSs implement the uplink data collection and downlink command broadcasting over orthogonal time slots. We also employ the massive multiple-input multiple-output (MIMO) at BSs, based on which each BS serves its associated sensors or actuators over the same time-frequency resources via spatial multiplexing. Under this setup, we jointly design the association between BSs and sensors/actuators as well as the joint communication and computation resource allocation, with the objective of minimizing the closed-loop control latency of the multiple subsystems while ensuring their control stability. The optimization takes into account the transmission uncertainty caused by both the hyper reliable and low-latency communications (HRLLC) and the inter-user interference , as well as the communication and computation resource constraints at distributed nodes. To solve the challenging non-convex joint optimization problem, we develop an efficient algorithm by employing the techniques of alternating optimization and successive convex approximation (SCA). Numerical results show that the proposed joint BS-sensor/actuator association and resource allocation design significantly outperforms other heuristic schemes and frequency-division-multiple-access (FDMA) counterpart.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11015v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhilin Liu, Yiyang Li, Huijun Xing, Ye Zhang, Jie Xu, Shuguang Cui</dc:creator>
    </item>
    <item>
      <title>Estimation Error: Distribution and Pointwise Limits</title>
      <link>https://arxiv.org/abs/2501.11109</link>
      <description>arXiv:2501.11109v1 Announce Type: new 
Abstract: In this paper, we examine the distribution and convergence properties of the estimation error $W = X - \hat{X}(Y)$, where $\hat{X}(Y)$ is the Bayesian estimator of a random variable $X$ from a noisy observation $Y = X +\sigma Z$ where $\sigma$ is the parameter indicating the strength of noise $Z$. Using the conditional expectation framework (that is, $\hat{X}(Y)$ is the conditional mean), we define the normalized error $\mathcal{E}_\sigma = \frac{W}{\sigma}$ and explore its properties.
  Specifically, in the first part of the paper, we characterize the probability density function of $W$ and $\mathcal{E}_\sigma$. Along the way, we also find conditions for the existence of the inverse functions for the conditional expectations. In the second part, we study pointwise (i.e., almost sure) convergence of $\mathcal{E}_\sigma$ under various assumptions about the noise and the underlying distributions. Our results extend some of the previous limits of $\mathcal{E}_\sigma$ studied under the $L^2$ convergence, known as the \emph{mmse dimension}, to the pointwise case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11109v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luca Barletta, Alex Dytso, Shlomo Shamai</dc:creator>
    </item>
    <item>
      <title>Optimal Functional $2^{s-1}$-Batch Codes: Exploring New Sufficient Conditions</title>
      <link>https://arxiv.org/abs/2501.11122</link>
      <description>arXiv:2501.11122v1 Announce Type: new 
Abstract: A functional $k$-batch code of dimension $s$ consists of $n$ servers storing linear combinations of $s$ linearly independent information bits. These codes are designed to recover any multiset of $k$ requests, each being a linear combination of the information bits, by $k$ disjoint subsets of servers. A recent conjecture suggests that for any set of $k = 2^{s-1}$ requests, the optimal solution requires $2^s-1$ servers. This paper shows that the problem of functional $k$-batch codes is equivalent to several other problems. Using these equivalences, we derive sufficient conditions that improve understanding of the problem and enhance the ability to find the optimal solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11122v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lev Yohananov, Isaac Barouch Essayag</dc:creator>
    </item>
    <item>
      <title>SIC-free Multicast Scheduling for Multi-antenna Coded Caching</title>
      <link>https://arxiv.org/abs/2501.11126</link>
      <description>arXiv:2501.11126v1 Announce Type: new 
Abstract: Multi-antenna coded caching (CC) with multicast beamforming often relies on complex successive interference cancellation (SIC) structures to decode a superposition of multiple streams received by each user. Traditional signal-level schemes require the regeneration of interfering signals from the cache, adding significant computational complexity. To address this, we propose a bit-level multicast scheduling scheme enabling linear, SIC-free decoding of parallel streams by repeatedly transmitting data terms with linearly independent coefficients. Two reference strategies for constructing the coefficients matrix are considered: a random strategy, which lacks control over matrix construction, and an equal-distant strategy, which balances users' interference and data terms equally. In contrast, the proposed sparse strategy minimizes the number of multicast streams transmitted in parallel during each interval, simplifying the system while optimizing resource usage. To further enhance the symmetric rate, a successive projection algorithm is applied to exploit channel properties and optimize user ordering. With the coefficients matrix and optimized user ordering in place, multicast beamformers are refined to aggregate desired data from relevant multicast streams. Numerical simulations validate the effectiveness of the sparse strategy, demonstrating significant gains in symmetric rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11126v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>MohammadJavad Sojdeh, MohammadJavad Salehi, Antti T\"olli</dc:creator>
    </item>
    <item>
      <title>Optimal Binary Variable-Length Codes with a Bounded Number of 1's per Codeword: Design, Analysis, and Applications</title>
      <link>https://arxiv.org/abs/2501.11129</link>
      <description>arXiv:2501.11129v1 Announce Type: new 
Abstract: In this paper, we consider the problem of constructing optimal average-length binary codes under the constraint that each codeword must contain at most $D$ ones, where $D$ is a given input parameter. We provide an $O(n^2D)$-time complexity algorithm for the construction of such codes, where $n$ is the number of codewords. We also describe several scenarios where the need to design these kinds of codes naturally arises. Our algorithms allow us to construct both optimal average-length prefix binary codes and optimal average-length alphabetic binary codes. In the former case, our $O(n^2D)$-time algorithm substantially improves on the previously known $O(n^{2+D})$-time complexity algorithm for the same problem. We also provide a Kraft-like inequality for the existence of (optimal) variable-length binary codes, subject to the above-described constraint on the number of 1's in each codeword.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11129v1</guid>
      <category>cs.IT</category>
      <category>cs.DS</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roberto Bruno, Roberto De Prisco, Ugo Vaccaro</dc:creator>
    </item>
    <item>
      <title>A Simultaneous Decoding Approach to Joint State and Message Communications</title>
      <link>https://arxiv.org/abs/2501.11133</link>
      <description>arXiv:2501.11133v1 Announce Type: new 
Abstract: The capacity-distortion (C-D) trade-off for joint state and message communications (JSMC) over state-dependent point-to-point, degraded broadcast, and multiple access channels are investigated, where the transmitters have access to noisy state information and feedback, while the receivers jointly decode the messages and estimate the channel state. A coding scheme is proposed based on backward simultaneous decoding of messages and compressed state descriptions without the need for the Wyner-Ziv random binning technique. For the point-to-point channel, the proposed scheme results in the optimal C-D function. For state-dependent discrete memoryless degraded broadcast channel (SD-DMDBC), the successive refinement method is adopted for designing state descriptions. With the simultaneous decoding approach, the derived achievable region is shown to be larger than the region obtained by the sequential decoding approach that is utilized in existing works. As for the state-dependent discrete memoryless multiple access channel (SD-DMMAC), in addition to the proposed scheme, Willem's coding strategy is applied to enable partial collaboration between transmitters through the feedback links. Moreover, the state descriptions are shown to enhance both communication and state estimation performance. Examples are provided for the derived results to verify the analysis, either numerically or analytically. With particular focus, simple but representative integrated sensing and communications (ISAC) systems are also considered, and their fundamental performance limits are studied.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11133v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinyang Li, Yiqi Chen, Vlad C. Andrei, Ullrich J. M\"onich, Holger Boche</dc:creator>
    </item>
    <item>
      <title>Reinforcement Learning Based Goodput Maximization with Quantized Feedback in URLLC</title>
      <link>https://arxiv.org/abs/2501.11190</link>
      <description>arXiv:2501.11190v1 Announce Type: new 
Abstract: This paper presents a comprehensive system model for goodput maximization with quantized feedback in Ultra-Reliable Low-Latency Communication (URLLC), focusing on dynamic channel conditions and feedback schemes. The study investigates a communication system, where the receiver provides quantized channel state information to the transmitter. The system adapts its feedback scheme based on reinforcement learning, aiming to maximize goodput while accommodating varying channel statistics. We introduce a novel Rician-$K$ factor estimation technique to enable the communication system to optimize the feedback scheme. This dynamic approach increases the overall performance, making it well-suited for practical URLLC applications where channel statistics vary over time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11190v1</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hasan Basri Celebi, Mikael Skoglund</dc:creator>
    </item>
    <item>
      <title>Several classes of linear codes with few weights derived from Weil sums</title>
      <link>https://arxiv.org/abs/2501.11282</link>
      <description>arXiv:2501.11282v1 Announce Type: new 
Abstract: Linear codes with few weights have applications in secret sharing, authentication codes, association schemes and strongly regular graphs. In this paper, several classes of $t$-weight linear codes over ${\mathbb F}_{q}$ are presented with the defining sets given by the intersection, difference and union of two certain sets, where $t=3,4,5,6$ and $q$ is an odd prime power. By using Weil sums and Gauss sums, the parameters and weight distributions of these codes are determined completely. Moreover, three classes of optimal codes meeting the Griesmer bound are obtained, and computer experiments show that many (almost) optimal codes can be derived from our constructions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11282v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhao Hu, Mingxiu Qiu, Nian Li, Xiaohu Tang, Liwei Wu</dc:creator>
    </item>
    <item>
      <title>Large Language Model Agents for Radio Map Generation and Wireless Network Planning</title>
      <link>https://arxiv.org/abs/2501.11283</link>
      <description>arXiv:2501.11283v1 Announce Type: new 
Abstract: Using commercial software for radio map generation and wireless network planning often require complex manual operations, posing significant challenges in terms of scalability, adaptability, and user-friendliness, due to heavy manual operations. To address these issues, we propose an automated solution that employs large language model (LLM) agents. These agents are designed to autonomously generate radio maps and facilitate wireless network planning for specified areas, thereby minimizing the necessity for extensive manual intervention. To validate the effectiveness of our proposed solution, we develop a software platform that integrates LLM agents. Experimental results demonstrate that a large amount manual operations can be saved via the proposed LLM agent, and the automated solutions can achieve an enhanced coverage and signal-to-interference-noise ratio (SINR), especially in urban environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11283v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongye Quan, Wanli Ni, Tong Zhang, Xiangyu Ye, Ziyi Xie, Shuai Wang, Yuanwei Liu, Hui Song</dc:creator>
    </item>
    <item>
      <title>Asymptotically Optimal Aperiodic and Periodic Sequence Sets with Low Ambiguity Zone Through Locally Perfect Nonlinear Functions</title>
      <link>https://arxiv.org/abs/2501.11313</link>
      <description>arXiv:2501.11313v1 Announce Type: new 
Abstract: Low ambiguity zone (LAZ) sequences play a crucial role in modern integrated sensing and communication (ISAC) systems. In this paper, we introduce a novel class of functions known as locally perfect nonlinear functions (LPNFs). By utilizing LPNFs and interleaving techniques, we propose three new classes of both periodic and aperiodic LAZ sequence sets with flexible parameters. The proposed periodic LAZ sequence sets are asymptotically optimal in relation to the periodic Ye-Zhou-Liu-Fan-Lei-Tang bound. Notably, the aperiodic LAZ sequence sets also asymptotically satisfy the aperiodic Ye-Zhou-Liu-Fan-Lei-Tang bound, marking the first construction in the literature. Finally, we demonstrate that the proposed sequence sets are cyclically distinct.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11313v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zheng Wang, Zhengchun Zhou, Avik Ranjan Adhikary, Yang Yang, Sihem Mesnager, Pingzhi Fan</dc:creator>
    </item>
    <item>
      <title>Accelerating Data Access for Single Node in Distributed Storage Systems via MDS Codes</title>
      <link>https://arxiv.org/abs/2501.11353</link>
      <description>arXiv:2501.11353v1 Announce Type: new 
Abstract: Maximum distance separable (MDS) array codes are widely employed in modern distributed storage systems to provide high data reliability with small storage overhead. Compared with the data access latency of the entire file, the data access latency of a single node in a distributed storage system is equally important. In this paper, we propose two algorithms to effectively reduce the data access latency on a single node in different scenarios for MDS codes. We show theoretically that our algorithms have an expected reduction ratio of $\frac{(n-k)(n-k+1)}{n(n+1)}$ and $\frac{n-k}{n}$ for the data access latency of a single node when it obeys uniform distribution and shifted-exponential distribution, respectively, where $n$ and $k$ are the numbers of all nodes and the number of data nodes respectively. In the worst-case analysis, we show that our algorithms have a reduction ratio of more than $60\%$ when $(n,k)=(3,2)$. Furthermore, in simulation experiments, we use the Monte Carlo simulation algorithm to demonstrate less data access latency compared with the baseline algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11353v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Shi, Zhengyi Jiang, Zhongyi Huang, Linqi Song, Hanxu Hou</dc:creator>
    </item>
    <item>
      <title>Reed-Solomon Codes Against Insertions and Deletions: Full-Length and Rate-$1/2$ Codes</title>
      <link>https://arxiv.org/abs/2501.11371</link>
      <description>arXiv:2501.11371v1 Announce Type: new 
Abstract: The performance of Reed-Solomon codes (RS codes, for short) in the presence of insertion and deletion errors has been studied recently in several papers. In this work, we further study this intriguing mathematical problem, focusing on two regimes. First, we study the question of how well full-length RS codes perform against insertions and deletions. For 2-dimensional RS codes, we fully characterize which codes cannot correct even a single insertion or deletion and show that (almost) all 2-dimensional RS codes correct at least $1$ insertion or deletion error. Moreover, for large enough field size $q$, and for any $k \ge 2$, we show that there exists a full-length $k$-dimensional RS code that corrects $q/10k$ insertions and deletions. Second, we focus on rate $1/2$ RS codes that can correct a single insertion or deletion error. We present a polynomial time algorithm that constructs such codes for $q = O(k^4)$. This result matches the existential bound given in \cite{con2023reed}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11371v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Peter Beelen, Roni Con, Anina Gruica, Maria Montanucci, Eitan Yaakobi</dc:creator>
    </item>
    <item>
      <title>Trace Reconstruction of First-Order Reed-Muller Codewords Using Run Statistics</title>
      <link>https://arxiv.org/abs/2501.11393</link>
      <description>arXiv:2501.11393v1 Announce Type: new 
Abstract: In this paper, we derive an expression for the expected number of runs in a trace of a binary sequence $x \in \{0,1\}^n$ obtained by passing $x$ through a deletion channel that independently deletes each bit with probability $q$. We use this expression to show that if $x$ is a codeword of a first-order Reed-Muller code, and the deletion probability $q$ is 1/2, then $x$ can be reconstructed, with high probability, from $\tilde{O}(n)$ many of its traces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11393v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shiv Pratap Singh Rathore, Navin Kashyap</dc:creator>
    </item>
    <item>
      <title>To BEE or not to BEE: Estimating more than Entropy with Biased Entropy Estimators</title>
      <link>https://arxiv.org/abs/2501.11395</link>
      <description>arXiv:2501.11395v1 Announce Type: new 
Abstract: Entropy estimation plays a significant role in biology, economics, physics, communication engineering and other disciplines. It is increasingly used in software engineering, e.g. in software confidentiality, software testing, predictive analysis, machine learning, and software improvement. However accurate estimation is demonstrably expensive in many contexts, including software. Statisticians have consequently developed biased estimators that aim to accurately estimate entropy on the basis of a sample. In this paper we apply 18 widely employed entropy estimators to Shannon measures useful to the software engineer: entropy, mutual information and conditional mutual information. Moreover, we investigate how the estimators are affected by two main influential factors: sample size and domain size. Our experiments range over a large set of randomly generated joint probability distributions and varying sample sizes, rather than choosing just one or two well known probability distributions as in previous investigations.
  Our most important result is identifying that the Chao-Shen and Chao-Wang-Jost estimators stand out for consistently converging more quickly to the ground truth, regardless of domain size and regardless of the measure used. They also tend to outperform the others in terms of accuracy as sample sizes increase. This discovery enables a significant reduction in data collection effort without compromising performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11395v1</guid>
      <category>cs.IT</category>
      <category>cs.SE</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ilaria Pia la Torre, David A. Kelly, Hector D. Menendez, David Clark</dc:creator>
    </item>
    <item>
      <title>Multi-Stage Active Sequential Hypothesis Testing with Clustered Hypotheses</title>
      <link>https://arxiv.org/abs/2501.11459</link>
      <description>arXiv:2501.11459v1 Announce Type: new 
Abstract: We consider the problem where an active Decision-Maker (DM) is tasked to identify the true hypothesis using as few as possible observations while maintaining accuracy. The DM collects observations according to its determined actions and knows the distributions under each hypothesis. We propose a deterministic and adaptive multi-stage hypothesis-elimination algorithm where the DM selects an action, applies it repeatedly, and discards hypotheses in light of its obtained observations. The DM selects actions based on maximal separation expressed by the distance between the parameter vectors of each distribution under each hypothesis. Close distributions can be clustered, simplifying the search and significantly reducing the number of required observations.
  Our algorithm achieves vanishing Average Bayes Risk (ABR) as the error probability approaches zero, i.e., the algorithm is asymptotically optimal. Furthermore, we show that the ABR cannot exceed the error probability when the number of hypotheses grows. Simulations are carried out to evaluate the algorithm's performance compared to another multi-stage hypothesis-elimination algorithm, where an improvement of 5 to 6 orders of magnitude in the mean number of observations required for success is observed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11459v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>George Vershinin, Asaf Cohen, Omer Gurewitz</dc:creator>
    </item>
    <item>
      <title>Strong Data Processing Properties of R\'enyi-divergences via Pinsker-type Inequalities</title>
      <link>https://arxiv.org/abs/2501.11473</link>
      <description>arXiv:2501.11473v1 Announce Type: new 
Abstract: We investigate strong data processing inequalities (SDPIs) of the R\'enyi-divergence between two discrete distributions when both distributions are passed through a fixed channel. We provide a condition on the channel for which the DPI holds with equality given two arbitrary distributions in the probability simplex. Motivated by this, we examine the contraction behavior for restricted sets of prior distributions via $f$-divergence inequalities: We provide an alternative proof of the optimal reverse Pinsker's inequality for R\'enyi-divergences first shown by Binette. We further present an improved Pinsker's inequality for R\'enyi-divergence based on the joint range technique by Harremo\"es and Vajda. The presented bound is tight whenever the value of the total variation distance is larger than $\frac{1}{\alpha}$. By framing these inequalities in a cross-channel setting, we arrive at SDPIs that can be adapted to use-case specific restrictions of input distribution and channel. We apply these results to the R\'enyi local differential privacy amplification through post-processing by channels that satisfy no local differential privacy guarantee.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11473v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Leonhard Grosse, Sara Saeidian, Tobias J. Oechtering, Mikael Skoglund</dc:creator>
    </item>
    <item>
      <title>Detecting Convolutional Codes: A Markovian Approach with LRT and DNN</title>
      <link>https://arxiv.org/abs/2501.11487</link>
      <description>arXiv:2501.11487v1 Announce Type: new 
Abstract: Identifying the unknown convolutional code corresponding to the given intercepted data is an important problem in military surveillance and in wireless communication. While a variety of code identification algorithms are available in the literature, the key contribution of our work lies in the novel solution and the corresponding analysis. In this paper, we focus on the situation when the given data corresponds to either of the two potential convolutional codes and the goal is to detect the correct code. We first provide a new interpretation of the convolutional code as a Markov chain, which is more suitable for analyzing the code detection problem. Our problem then gets reduced to identifying between the two Markov chains. We provide the closed-form expressions for the corresponding state transition matrices and estimate the error exponent for the underlying likelihood ratio test (LRT). We also provide a computationally efficient BCJR-based method for computing the likelihoods required for the LRT. We observe that BCJR-based likelihoods suffer from numerical issues for a longer data sequence, and hence, in this case, we design neural networks that have been found to achieve the optimal performance of the LRT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11487v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Harshvardhan Pandey, Pragya Khanna, Arti Yardi</dc:creator>
    </item>
    <item>
      <title>Hierarchical Coded Caching in High Memory Regime with Coded Placement</title>
      <link>https://arxiv.org/abs/2501.11502</link>
      <description>arXiv:2501.11502v1 Announce Type: new 
Abstract: We consider a two-layer hierarchical coded caching network where a server with a library of $N$ files is connected to $K_1$ mirrors, each having a cache memory of size $M_1$. Each mirror is further connected to $K_2$ users, each equipped with a dedicated cache of size $M_2$. In this paper, we propose two distinct coded caching schemes based on coded placement, corresponding to two distinct memory pairs, \( (M_1, M_2) \). We show that the proposed schemes outperform the existing schemes at these memory points given by the proposed schemes for smaller values of $K_2$. In setups where mirrors are positioned near each other, avoiding signal interference is crucial. This can be ensured by having all mirrors transmit using orthogonal carrier frequencies. To compare our schemes with existing ones, we used the composite rate metric, which accurately represents the total bandwidth utilized in such setups. The composite rate is given by $\overline{R} = R_1 + K_1 R_2$, where $R_1$ is the rate from the server to the mirrors, and $R_2$ is the rate from the mirrors to the users, with respect to $M_1$ and $M_2$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11502v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rajlaxmi Pandey, Charul Rajput, B. Sundar Rajan</dc:creator>
    </item>
    <item>
      <title>Sun-Jafar-Type Schemes for Weak Private Information Retrieval</title>
      <link>https://arxiv.org/abs/2501.11505</link>
      <description>arXiv:2501.11505v1 Announce Type: new 
Abstract: In information-theoretic private information retrieval (PIR), a client wants to retrieve one desired file out of $M$ files, stored across $N$ servers, while keeping the index of the desired file private from each $T$-sized subset of servers. A PIR protocol must ideally maximize the rate, which is the ratio of the file size to the total quantum of the download from the servers, while ensuring such privacy. In Weak-PIR (WPIR), the criterion of perfect information-theoretic privacy is relaxed. This enables higher rates to be achieved, while some information about the desired file index leaks to the servers. This leakage is captured by various known privacy metrics. By leveraging the well-established capacity-achieving schemes of Sun and Jafar under non-colluding ($T=1$) and colluding ($1&lt;T\leq N$) scenarios, we present WPIR protocols for these scenarios. We also present a new WPIR scheme for the MDS scenario, by building upon the scheme by Banawan and Ulukus for this scenario. We present corresponding explicit rate-privacy trade-offs for these setups, under the mutual-information and the maximal leakage privacy metrics. In the collusion-free setup, our presented rate-privacy trade-off under maximal leakage matches that of the previous state of the art. With respect to the MDS scenario under the maximal leakage metric, we compare with the non-explicit trade-off in the literature, and show that our scheme performs better for some numerical examples. For the $T$-collusion setup (under both privacy metrics) and for the MDS setup under the mutual information metric, our rate-privacy trade-offs are the first in the literature, to the best of our knowledge.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11505v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chandan Anand, Jayesh Seshadri, Prasad Krishnan, Gowtham R. Kurri</dc:creator>
    </item>
    <item>
      <title>Characterization of the Arithmetic Complexity of the Secrecy Capacity of Fast-Fading Gaussian Channels</title>
      <link>https://arxiv.org/abs/2501.11636</link>
      <description>arXiv:2501.11636v1 Announce Type: new 
Abstract: This paper studies the computability of the secrecy capacity of fast-fading wiretap channels from an algorithmic perspective, examining whether it can be computed algorithmically or not. To address this question, the concept of Turing machines is used, which establishes fundamental performance limits of digital computers. It is shown that certain computable continuous fading probability distribution functions yield secrecy capacities that are non-computable numbers. Additionally, we assess the secrecy capacity's classification within the arithmetical hierarchy, revealing the absence of computable achievability and converse bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11636v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Holger Boche, Andrea Grigorescu, Rafael F. Schaefer, H. Vincent Poor</dc:creator>
    </item>
    <item>
      <title>PIR Over Wireless Channels: Achieving Privacy With Public Responses</title>
      <link>https://arxiv.org/abs/2501.11740</link>
      <description>arXiv:2501.11740v1 Announce Type: new 
Abstract: This paper addresses the problem of private information retrieval (PIR) over an additive white Gaussian noise (AWGN) channel, considering the channel is public. In such settings, each server can eavesdrop on the channel, potentially compromising the user's privacy. Previous works suggested joint coding--PIR schemes, ignoring the fact that communication over a practical wireless channel is public. To address this gap, we present a novel joint wiretap--PIR coding scheme that leverages lattice codes to exploit the channel's additive properties. This scheme integrates wiretap coding and private retrieval techniques into a unified framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11740v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Or Elimelech, Asaf Cohen</dc:creator>
    </item>
    <item>
      <title>Personalized Federated Learning for Cellular VR: Online Learning and Dynamic Caching</title>
      <link>https://arxiv.org/abs/2501.11745</link>
      <description>arXiv:2501.11745v1 Announce Type: new 
Abstract: Delivering an immersive experience to virtual reality (VR) users through wireless connectivity offers the freedom to engage from anywhere at any time. Nevertheless, it is challenging to ensure seamless wireless connectivity that delivers real-time and high-quality videos to the VR users. This paper proposes a field of view (FoV) aware caching for mobile edge computing (MEC)-enabled wireless VR network. In particular, the FoV of each VR user is cached/prefetched at the base stations (BSs) based on the caching strategies tailored to each BS. Specifically, decentralized and personalized federated learning (DP-FL) based caching strategies with guarantees are presented. Considering VR systems composed of multiple VR devices and BSs, a DP-FL caching algorithm is implemented at each BS to personalize content delivery for VR users. The utilized DP-FL algorithm guarantees a probably approximately correct (PAC) bound on the conditional average cache hit. Further, to reduce the cost of communicating gradients, one-bit quantization of the stochastic gradient descent (OBSGD) is proposed, and a convergence guarantee of $\mathcal{O}(1/\sqrt{T})$ is obtained for the proposed algorithm, where $T$ is the number of iterations. Additionally, to better account for the wireless channel dynamics, the FoVs are grouped into multicast or unicast groups based on the number of requesting VR users. The performance of the proposed DP-FL algorithm is validated through realistic VR head-tracking dataset, and the proposed algorithm is shown to have better performance in terms of average delay and cache hit as compared to baseline algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11745v1</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Krishnendu S. Tharakan, Hayssam Dahrouj, Nour Kouzayha, Hesham ElSawy, Tareq Y. Al-Naffouri</dc:creator>
    </item>
    <item>
      <title>An Information Geometric Approach to Local Information Privacy with Applications to Max-lift and Local Differential Privacy</title>
      <link>https://arxiv.org/abs/2501.11757</link>
      <description>arXiv:2501.11757v1 Announce Type: new 
Abstract: We study an information-theoretic privacy mechanism design, where an agent observes useful data $Y$ and wants to reveal the information to a user. Since the useful data is correlated with the private data $X$, the agent uses a privacy mechanism to produce disclosed data $U$ that can be released. We assume that the agent observes $Y$ and has no direct access to $X$, i.e., the private data is hidden. We study the privacy mechanism design that maximizes the revealed information about $Y$ while satisfying a bounded Local Information Privacy (LIP) criterion. When the leakage is sufficiently small, concepts from information geometry allow us to locally approximate the mutual information. By utilizing this approximation the main privacy-utility trade-off problem can be rewritten as a quadratic optimization problem that has closed-form solution under some constraints. For the cases where the closed-form solution is not obtained we provide lower bounds on it. In contrast to the previous works that have complexity issues, here, we provide simple privacy designs with low complexity which are based on finding the maximum singular value and singular vector of a matrix. To do so, we follow two approaches where in the first one we find a lower bound on the main problem and then approximate it, however, in the second approach we approximate the main problem directly. In this work, we present geometrical interpretations of the proposed methods and in a numerical example we compare our results considering both approaches with the optimal solution and the previous methods. Furthermore, we discuss how our method can be generalized considering larger amounts for the privacy leakage. Finally, we discuss how the proposed methods can be applied to deal with differential privacy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11757v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amirreza Zamani, Parastoo Sadeghi, Mikael Skoglund</dc:creator>
    </item>
    <item>
      <title>PDA Construction via Union of Cartesian Product Cache Configurations for Coded Caching</title>
      <link>https://arxiv.org/abs/2501.11834</link>
      <description>arXiv:2501.11834v1 Announce Type: new 
Abstract: Caching is an efficient technique to reduce peak traffic by storing popular content in local caches. Placement delivery array (PDA) proposed by Yan et al. is a combinatorial structure to design coded caching schemes with uncoded placement and one-shot linear delivery. By taking the $m$-fold Cartesian product of a small base PDA, Wang et al. constructed a big PDA while maintaining the memory ratio and transmission load unchanged, which achieves linear growth in both the number of users and coded caching gain. In order to achieve exponential growth in both the number of users and coded caching gain, in this paper we propose a PDA construction by taking the union operation of the cache configurations from the $m$-fold Cartesian product of a base PDA. The resulting PDA leads to a coded caching scheme with subpacketization increasing sub-exponentially with the number of users while keeping the load constant for fixed memory ratio. By applying the proposed construction to existing base PDAs, three new coded caching schemes are obtained, which cover some existing schemes as special cases and can achieve lower load with simultaneously lower subpacketization for some memory ratios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11834v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinyu Wang, Minquan Cheng, Kai Wan, Giuseppe Caire</dc:creator>
    </item>
    <item>
      <title>Harnessing Rydberg Atomic Receivers: From Quantum Physics to Wireless Communications</title>
      <link>https://arxiv.org/abs/2501.11842</link>
      <description>arXiv:2501.11842v1 Announce Type: new 
Abstract: The intrinsic integration of Rydberg atomic receivers into wireless communication systems is proposed, by harnessing the principles of quantum physics in wireless communications. More particularly, we conceive a pair of Rydberg atomic receivers, one incorporates a local oscillator (LO), referred to as an LO-dressed receiver, while the other operates without an LO and is termed an LO-free receiver. The appropriate wireless model is developed for each configuration, elaborating on the receiver's responses to the radio frequency (RF) signal, on the potential noise sources, and on the system performance. Next, we investigate the association distortion effects that might occur, specifically demonstrating the boundaries of linear dynamic regions, which provides critical insights into its practical implementations in wireless systems. Extensive simulation results are provided for characterizing the performance of wireless systems, harnessing this pair of Rydberg atomic receivers. Our results demonstrate that they deliver complementary benefits: LO-free systems excel in proximity operations, while LO-dressed systems are eminently suitable for long-distance sensing at extremely low power levels. More specifically, LO-dressed systems achieve a significant signal-to-noise ratio (SNR) gain of approximately 44 dB over conventional RF receivers, exhibiting an effective coverage range extension over conventional RF receivers by a factor of 150. Furthermore, LO-dressed systems support higher-order quadrature amplitude modulation (QAM) at reduced symbol error rates (SER) compared to conventional RF receivers, hence significantly enhancing wireless communication performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11842v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yuanbin Chen, Xufeng Guo, Chau Yuen, Yufei Zhao, Yong Liang Guan, Chong Meng Samson See, Merouane D\'ebbah, Lajos Hanzo</dc:creator>
    </item>
    <item>
      <title>A New Construction Structure on Coded Caching with Linear Subpacketization: Non-Half-Sum Disjoint Packing</title>
      <link>https://arxiv.org/abs/2501.11855</link>
      <description>arXiv:2501.11855v1 Announce Type: new 
Abstract: Coded caching is a promising technique to effectively reduce peak traffic by using local caches and the multicast gains generated by these local caches. We prefer to design a coded caching scheme with the subpacketization $F$ and transmission load $R$ as small as possible since these are the key metrics for evaluating the implementation complexity and transmission efficiency of the scheme, respectively. However, most of the existing coded caching schemes have large subpacketizations which grow exponentially with the number of users $K$, and there are a few schemes with linear subpacketizations which have large transmission loads. In this paper, we focus on studying the linear subpacketization, i.e., $K=F$, coded caching scheme with low transmission load. Specifically, we first introduce a new combinatorial structure called non-half-sum disjoint packing (NHSDP) which can be used to generate a coded caching scheme with $K=F$. Then a class of new schemes is obtained by constructing NHSDP. Theoretical and numerical comparisons show that (i) compared to the existing schemes with linear subpacketization (to the number of users), the proposed scheme achieves a lower load; (ii) compared to some existing schemes with polynomial subpacketization, the proposed scheme can also achieve a lower load in some cases; (iii) compared to some existing schemes with exponential subpacketization, the proposed scheme has loads close to those of these schemes in some cases. Moreover, the new concept of NHSDP is closely related to the classical combinatorial structures such as cyclic difference packing (CDP), non-three-term arithmetic progressions (NTAP), and perfect hash family (PHF). These connections indicate that NHSDP is an important combinatorial structure in the field of combinatorial design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11855v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Minquan Cheng, Huimei Wei, Kai Wan, Giuseppe Caire</dc:creator>
    </item>
    <item>
      <title>Bayesian Despeckling of Structured Sources</title>
      <link>https://arxiv.org/abs/2501.11860</link>
      <description>arXiv:2501.11860v1 Announce Type: new 
Abstract: Speckle noise is a fundamental challenge in coherent imaging systems, significantly degrading image quality. Over the past decades, numerous despeckling algorithms have been developed for applications such as Synthetic Aperture Radar (SAR) and digital holography. In this paper, we aim to establish a theoretically grounded approach to despeckling. We propose a method applicable to general structured stationary stochastic sources. We demonstrate the effectiveness of the proposed method on piecewise constant sources. Additionally, we theoretically derive a lower bound on the despeckling performance for such sources. The proposed depseckler applied to the 1-Markov structured sources achieves better reconstruction performance with no strong simplification of the ground truth signal model or speckle noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11860v1</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>stat.AP</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ali Zafari, Shirin Jalali</dc:creator>
    </item>
    <item>
      <title>Channel Resolvability Using Multiplicative Weight Update Algorithm</title>
      <link>https://arxiv.org/abs/2501.11881</link>
      <description>arXiv:2501.11881v1 Announce Type: new 
Abstract: We study the channel resolvability problem, which is used to prove strong converse of identification via channel. Channel resolvability has been solved by only random coding in the literature. We prove channel resolvability using the multiplicative weight update algorithm. This is the first approach to channel resolvability using non-random coding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11881v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Koki Takahashi, Shun Watanabe</dc:creator>
    </item>
    <item>
      <title>An Improved Lower Bound on Oblivious Transfer Capacity Using Polarization and Interaction</title>
      <link>https://arxiv.org/abs/2501.11883</link>
      <description>arXiv:2501.11883v1 Announce Type: new 
Abstract: We consider the oblivious transfer (OT) capacities of noisy channels against the passive adversary; this problem has not been solved even for the binary symmetric channel (BSC). In the literature, the general construction of OT has been known only for generalized erasure channels (GECs); for the BSC, we convert the channel to the binary symmetric erasure channel (BSEC), which is a special instance of the GEC, via alphabet extension and erasure emulation. In a previous paper by the authors, we derived an improved lower bound on the OT capacity of BSC by proposing a method to recursively emulate BSEC via interactive communication. In this paper, we introduce two new ideas of OT construction: (i) via ``polarization" and interactive communication, we recursively emulate GECs that are not necessarily a BSEC; (ii) in addition to the GEC emulation part, we also utilize interactive communication in the key agreement part of OT protocol. By these methods, we derive lower bounds on the OT capacity of BSC that are superior to the previous one for a certain range of crossover probabilities of the BSC. Via our new lower bound, we show that, at the crossover probability being zero, the slope of tangent of the OT capacity is unbounded.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11883v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>So Suda, Shun Watanabe</dc:creator>
    </item>
    <item>
      <title>Phase Transitions in Phase-Only Compressed Sensing</title>
      <link>https://arxiv.org/abs/2501.11905</link>
      <description>arXiv:2501.11905v1 Announce Type: new 
Abstract: The goal of phase-only compressed sensing is to recover a structured signal $\mathbf{x}$ from the phases $\mathbf{z} = {\rm sign}(\mathbf{\Phi}\mathbf{x})$ under some complex-valued sensing matrix $\mathbf{\Phi}$. Exact reconstruction of the signal's direction is possible: we can reformulate it as a linear compressed sensing problem and use basis pursuit (i.e., constrained norm minimization). For $\mathbf{\Phi}$ with i.i.d. complex-valued Gaussian entries, this paper shows that the phase transition is approximately located at the statistical dimension of the descent cone of a signal-dependent norm. Leveraging this insight, we derive asymptotically precise formulas for the phase transition locations in phase-only sensing of both sparse signals and low-rank matrices. Our results prove that the minimum number of measurements required for exact recovery is smaller for phase-only measurements than for traditional linear compressed sensing. For instance, in recovering a 1-sparse signal with sufficiently large dimension, phase-only compressed sensing requires approximately 68% of the measurements needed for linear compressed sensing. This result disproves earlier conjecture suggesting that the two phase transitions coincide. Our proof hinges on the Gaussian min-max theorem and the key observation that, up to a signal-dependent orthogonal transformation, the sensing matrix in the reformulated problem behaves as a nearly Gaussian matrix.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11905v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junren Chen, Lexiao Lai, Arian Maleki</dc:creator>
    </item>
    <item>
      <title>Goal-oriented Transmission Scheduling: Structure-guided DRL with a Unified Dual On-policy and Off-policy Approach</title>
      <link>https://arxiv.org/abs/2501.11921</link>
      <description>arXiv:2501.11921v1 Announce Type: new 
Abstract: Goal-oriented communications prioritize application-driven objectives over data accuracy, enabling intelligent next-generation wireless systems. Efficient scheduling in multi-device, multi-channel systems poses significant challenges due to high-dimensional state and action spaces. We address these challenges by deriving key structural properties of the optimal solution to the goal-oriented scheduling problem, incorporating Age of Information (AoI) and channel states. Specifically, we establish the monotonicity of the optimal state value function (a measure of long-term system performance) w.r.t. channel states and prove its asymptotic convexity w.r.t. AoI states. Additionally, we derive the monotonicity of the optimal policy w.r.t. channel states, advancing the theoretical framework for optimal scheduling. Leveraging these insights, we propose the structure-guided unified dual on-off policy DRL (SUDO-DRL), a hybrid algorithm that combines the stability of on-policy training with the sample efficiency of off-policy methods. Through a novel structural property evaluation framework, SUDO-DRL enables effective and scalable training, addressing the complexities of large-scale systems. Numerical results show SUDO-DRL improves system performance by up to 45% and reduces convergence time by 40% compared to state-of-the-art methods. It also effectively handles scheduling in much larger systems, where off-policy DRL fails and on-policy benchmarks exhibit significant performance loss, demonstrating its scalability and efficacy in goal-oriented communications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11921v1</guid>
      <category>cs.IT</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiazheng Chen, Wanchun Liu</dc:creator>
    </item>
    <item>
      <title>Multi-Modal Variable-Rate CSI Reconstruction for FDD Massive MIMO Systems</title>
      <link>https://arxiv.org/abs/2501.11926</link>
      <description>arXiv:2501.11926v1 Announce Type: new 
Abstract: In frequency division duplex (FDD) systems, acquiring channel state information (CSI) at the base station (BS) traditionally relies on limited feedback from mobile terminals (MTs). However, the accuracy of channel reconstruction from feedback CSI is inherently constrained by the rate-distortion trade-off. To overcome this limitation, we propose a multi-modal channel reconstruction framework that leverages auxiliary data, such as RGB images or uplink CSI, collected at the BS. By integrating contextual information from these modalities, the framework mitigates CSI distortions caused by noise, compression, and quantization. At its core, the framework utilizes an autoencoder network capable of generating variable-length CSI, tailored for rate-adaptive multi-modal channel reconstruction. By augmenting the foundational autoencoder network using a transfer learning-based multi-modal fusion strategy, we enable accurate channel reconstruction in both single-modal and multi-modal scenarios. To train and evaluate the network under diverse and realistic wireless conditions, we construct a synthetic dataset that pairs wireless channel data with sensor data through 3D modeling and ray tracing. Simulation results demonstrate that the proposed framework achieves near-optimal beamforming gains in 5G New Radio (5G NR)-compliant scenarios, highlighting the potential of sensor data integration to improve CSI reconstruction accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11926v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yunseo Nam, Jiwook Choi</dc:creator>
    </item>
    <item>
      <title>Construction of Simultaneously Good Polar Codes and Polar Lattices</title>
      <link>https://arxiv.org/abs/2501.11931</link>
      <description>arXiv:2501.11931v1 Announce Type: new 
Abstract: In this work, we investigate the simultaneous goodness of polar codes and polar lattices. The simultaneous goodness of a code (lattice) means that it is optimal for both channel coding and source coding simultaneously. The existence of such kind of lattices was proven by using random lattice ensembles. Our work provides an explicit construction based on the polarization technique.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11931v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ling Liu, Ruimin Yuan, Shanxiang Lyu, Cong Ling, Baoming Bai</dc:creator>
    </item>
    <item>
      <title>Weight Distribution of the Weighted Coordinates Poset Block Space and Singleton Bound</title>
      <link>https://arxiv.org/abs/2501.11978</link>
      <description>arXiv:2501.11978v1 Announce Type: new 
Abstract: In this paper, we determine the complete weight distribution of the space $ \mathbb{F}_q^N $ endowed by the weighted coordinates poset block metric ($(P,w,\pi)$-metric), also known as the $(P,w,\pi)$-space, thereby obtaining it for $(P,w)$-space, $(P,\pi)$-space, $\pi$-space, and $P$-space as special cases. Further, when $P$ is a chain, the resulting space is called as Niederreiter-Rosenbloom-Tsfasman (NRT) weighted block space and when $P$ is hierarchical, the resulting space is called as weighted coordinates hierarchical poset block space. The complete weight distribution of both the spaces are deduced from the main result. Moreover, we define an $I$-ball for an ideal $I$ in $P$ and study the characteristics of it in $(P,w,\pi)$-space.
  We investigate the relationship between the $I$-perfect codes and $t$-perfect codes in $(P,w,\pi)$-space. Given an ideal $I$, we investigate how the maximum distance separability (MDS) is related with $I$-perfect codes and $t$-perfect codes in $(P,w,\pi)$-space. Duality theorem is derived for an MDS $(P,w,\pi)$-code when all the blocks are of same length. Finally, the distribution of codewords among $r$-balls is analyzed in the case of chain poset, when all the blocks are of same length.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11978v1</guid>
      <category>cs.IT</category>
      <category>math.CO</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Atul Kumar Shriwastva, R. S. Selvaraj</dc:creator>
    </item>
    <item>
      <title>Subcode Ensemble Decoding of Linear Block Codes</title>
      <link>https://arxiv.org/abs/2501.11993</link>
      <description>arXiv:2501.11993v1 Announce Type: new 
Abstract: Low-density parity-check (LDPC) codes together with belief propagation (BP) decoding yield exceptional error correction capabilities in the large block length regime. Yet, there remains a gap between BP decoding and maximum likelihood decoding for short block length LDPC codes. In this context, ensemble decoding schemes yield both reduced latency and good error rates. In this paper, we propose subcode ensemble decoding (SCED), which employs an ensemble of decodings on different subcodes of the code. To ensure that all codewords are decodable, we use the concept of linear coverings and explore approaches for sampling suitable ensembles for short block length LDPC codes. Monte-Carlo simulations conducted for three LDPC codes demonstrate that SCED improves decoding performance compared to stand-alone decoding and automorphism ensemble decoding. In particular, in contrast to existing schemes, e.g., multiple bases belief propagation and automorphism ensemble decoding, SCED does not require the NP-complete search for low-weight dual codewords or knowledge of the automorphism group of the code, which is often unknown.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11993v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jonathan Mandelbaum, Holger J\"akel, Laurent Schmalen</dc:creator>
    </item>
    <item>
      <title>Fractional Subadditivity of Submodular Functions: Equality Conditions and Their Applications</title>
      <link>https://arxiv.org/abs/2501.12058</link>
      <description>arXiv:2501.12058v1 Announce Type: new 
Abstract: Submodular functions are known to satisfy various forms of fractional subadditivity. This work investigates the conditions for equality to hold exactly or approximately in the fractional subadditivity of submodular functions. We establish that a small gap in the inequality implies that the function is close to being modular, and that the gap is zero if and only if the function is modular. We then present natural implications of these results for special cases of submodular functions, such as entropy, relative entropy, and matroid rank. As a consequence, we characterize the necessary and sufficient conditions for equality to hold in Shearer's lemma, recovering a result of Ellis \emph{et al.} (2016) as a special case. We leverage our results to propose a new multivariate mutual information, which generalizes Watanabe's total correlation (1960), Han's dual total correlation (1978), and Csisz\'ar and Narayan's shared information (2004), and analyze its properties. Among these properties, we extend Watanabe's characterization of total correlation as the maximum correlation over partitions to fractional partitions. When applied to matrix determinantal inequalities for positive definite matrices, our results recover the equality conditions of the classical determinantal inequalities of Hadamard, Sz\'asz, and Fischer as special cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12058v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gunank Jakhar, Gowtham R. Kurri, Suryajith Chillara, Vinod M. Prabhakaran</dc:creator>
    </item>
    <item>
      <title>The Generalized Chernoff-Stein Lemma, Applications and Examples</title>
      <link>https://arxiv.org/abs/2501.12066</link>
      <description>arXiv:2501.12066v1 Announce Type: new 
Abstract: In this manuscript we define the notion of "$\delta$-typicality" for both entropy and relative entropy, as well as a notion of $\epsilon$-goodness and provide an extension to Stein's lemma for continuous quantities as well as correlated setups. We apply the derived results on the Gaussian hypothesis testing problem where the observations are possibly correlated.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12066v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jihad Fahs, Ibrahim Abou Faycal, Ibrahim Issa</dc:creator>
    </item>
    <item>
      <title>Hierarchy of Pseudo-Random Array Codes</title>
      <link>https://arxiv.org/abs/2501.12124</link>
      <description>arXiv:2501.12124v1 Announce Type: new 
Abstract: Pseudo-random arrays are the two-dimensional analog of M-sequences. Pseudo-random array codes are the two-dimensional analog of sequences generated by a product of irreducible polynomials with the same exponent. The union of the arrays in such a code has the window property and the shift-and-add property, implying that these codes are linear. The folding technique is the most basic one for forming such arrays and codes. A new criterion for generating pseudo-random arrays based on folding is given. This new criterion yields pseudo-random arrays with new parameters. A general construction for such array codes is given. It appears that the arrays generated in this construction can be constructed by folding the nonzero sequences generated by a product of irreducible polynomials of the same degree and the same exponent. Two hierarchies of the pseudo-random array codes are provided. In one hierarchy codewords of one code with smaller windows are contained in codewords of another code which stands above him in the hierarchy. The second hierarchy is a partition of the pseudo-random array codes generated by folding into classes based on the polynomial types which participate in their construction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12124v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yeow Meng Chee, Tuvi Etzion, Huimin Lao</dc:creator>
    </item>
    <item>
      <title>Revisit the AWGN-goodness of Polar-like Lattices</title>
      <link>https://arxiv.org/abs/2501.12135</link>
      <description>arXiv:2501.12135v1 Announce Type: new 
Abstract: This paper aims to provide a comprehensive introduction to lattices constructed based on polar-like codes and demonstrate some of their key properties, such as AWGN goodness. We first present polar lattices directly from the perspective of their generator matrix. Next, we discuss their connection with the recently proposed PAC (polarization adjusted convolutional) lattices and analyze the structural advantages of PAC lattices, through which the AWGN-goodness of PAC lattices can be conveniently demonstrated.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12135v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ling Liu, Junjiang Yu, Shanxiang Lyu, Baoming Bai</dc:creator>
    </item>
    <item>
      <title>Deep Unfolding of Fixed-Point based Algorithm for Weighted Sum Rate Maximization</title>
      <link>https://arxiv.org/abs/2501.12148</link>
      <description>arXiv:2501.12148v1 Announce Type: new 
Abstract: In this paper, we propose a novel approach that harnesses the standard interference function, specifically tailored to address the unique challenges of non-convex optimization in wireless networks. We begin by establishing theoretical guarantees for our method under the assumption that the interference function exhibits log-concavity. Building on this foundation, we develop a Primal-Dual Algorithm (PDA) to approximate the solution to the Weighted Sum Rate (WSR) maximization problem. To further enhance computational efficiency, we leverage the deep unfolding technique, significantly reducing the complexity of the proposed algorithm. Through extensive numerical experiments, we demonstrate the competitiveness of our method compared to the state-of-the-art fractional programming benchmark, commonly referred to as FPLinQ.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12148v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jan Christian Hauffen, Chee Wei Tan, Giuseppe Caire</dc:creator>
    </item>
    <item>
      <title>Soft-Decision Decoding for LDPC Code-Based Quantitative Group Testing</title>
      <link>https://arxiv.org/abs/2501.12167</link>
      <description>arXiv:2501.12167v1 Announce Type: new 
Abstract: We consider the problem of identifying defective items in a population with non-adaptive quantitative group testing. For this scenario, Mashauri et al. recently proposed a low-density parity-check (LDPC) code-based quantitative group testing scheme with a hard-decision decoding approach (akin to peeling decoding). This scheme outperforms generalized LDPC code-based quantitative group testing schemes in terms of the misdetection rate. In this work, we propose a belief-propagation-based decoder for quantitative group testing with LDPC codes, where the messages being passed are purely soft. Through extensive simulations, we show that the proposed soft-information decoder outperforms the hard-decision decoder Mashauri et al.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12167v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marvin Xhemrishi, Johan \"Ostman, Alexandre Graell i Amat</dc:creator>
    </item>
    <item>
      <title>Removal of Small Weight Stopping Sets for Asynchronous Unsourced Multiple Access</title>
      <link>https://arxiv.org/abs/2501.12186</link>
      <description>arXiv:2501.12186v1 Announce Type: new 
Abstract: In this paper, we analyze the formation of small stopping sets in joint factor graphs describing a frame-asynchronous two-user transmission. Furthermore, we propose an algorithm to completely avoid small stopping sets in the joint factor graph over the entire range of symbol delays. The error floor caused by those stopping sets is completely mitigated. Our key observation is that, while the order of bits in the codeword is irrelevant in a single-user environment, it turns out to be crucial in the asynchronous, unsourced two-user system. Subsequently, our algorithm finds a reordering of variable nodes (VNs) which avoids the smallest stopping set in the joint graph. We show that further improvements can be achieved when girth optimization of the single-user graphs by progressive edge growth (PEG) is used in combination with our proposed algorithm. Starting with a randomized code construction with optimized degree distribution, our simulation results show that PEG followed by the proposed algorithm can improve the average per user probability of error (PUPE) in a noiseless channel by almost two orders of magnitude for a broad range of frame delays.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12186v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Frederik Ritter, Jonathan Mandelbaum, Alexander Fengler, Holger J\"akel, Laurent Schmalen</dc:creator>
    </item>
    <item>
      <title>Multi-terminal Strong Coordination over Noisy Channels with Encoder Cooperation</title>
      <link>https://arxiv.org/abs/2501.12227</link>
      <description>arXiv:2501.12227v1 Announce Type: new 
Abstract: We investigate the problem of strong coordination over a multiple-access channel (MAC) with cribbing encoders. In this configuration, two encoders observe independent and identically distributed (i.i.d.) samples of a source random variable each and encode the inputs to the MAC. The decoder which observes the output of the MAC together with side-information, must generate approximately i.i.d. samples of another random variable which is jointly distributed with the two sources and the side information. We also allow for possible encoder cooperation, where one of the encoders can non-causally crib from the other encoders input. Independent pairwise shared randomness is assumed between each encoder and the decoder at limited rates. Firstly, in the presence of cribbing, we derive an achievable region based on joint source-channel coding. We also prove that in the absence of cribbing, our inner bound is tight for the special case when the MAC is composed of deterministic links, and the sources are conditionally independent given the side information. We then explicitly compute the regions for an example both with and without cribbing between the encoders, and demonstrate that cribbing strictly improves upon the achievable region.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12227v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Viswanathan Ramachandran, Tobias J. Oechtering, Mikael Skoglund</dc:creator>
    </item>
    <item>
      <title>Solar Panel Selection using Extended WASPAS with Disc Intuitionistic Fuzzy Choquet Integral Operators: CASPAS Methodology</title>
      <link>https://arxiv.org/abs/2501.12251</link>
      <description>arXiv:2501.12251v1 Announce Type: new 
Abstract: Renewable energy is crucial for addressing the growing energy demands of modern society while mitigating the adverse effects of climate change. Unlike fossil fuels, renewable energy sources such as solar, wind, hydro, geothermal, and biomass are abundant, sustainable, and environmentally friendly. This study focuses on addressing a critical challenge in renewable energy decision-making by developing a novel framework for optimal solar panel selection, a key component of sustainable energy solutions. Solar panel selection involves evaluating multiple interdependent criteria, such as efficiency, cost, durability, and environmental impact. Traditional multi-criteria decision-making (MCDM) methods often fail to account for the interdependencies among these criteria, leading to suboptimal outcomes. To overcome this limitation, the study introduces the Choquet Aggregated Sum Product Assessment (CASPAS) method, a Choquet integral-based MCDM approach that incorporates fuzzy measures to model interactions among criteria. CASPAS generalizes the Weighted Aggregated Sum Product Assessment (WASPAS) method, thereby enhancing decision-making accuracy and reliability. This study also introduces the concept of disc intuitionistic fuzzy set (D-IFS), a generalization of the concept of circular intuitionistic fuzzy set, which employ a radius function capable of assigning varying values to individual elements instead of relying on a fixed radius. Recognizing that traditional weighted aggregation operators neglect the interaction among criteria, this study proposes disc intuitionistic fuzzy Choquet integral operators by incorporating the concept of fuzzy measures, which are effective in modeling such interactions. The proposed method is applied to a renewable energy problem on selecting optimal solar panels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12251v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Mahmut Can Bozyi\u{g}it, Mehmet \"Unver</dc:creator>
    </item>
    <item>
      <title>Faithful Simulation of Distributed Quantum Measurement with Coding for Computing</title>
      <link>https://arxiv.org/abs/2501.12271</link>
      <description>arXiv:2501.12271v1 Announce Type: new 
Abstract: This papers consider a two terminal problem, where Alice and Bob jointly want to perform a measurement on a bipartite quantum system \(\rho^{AB}\). Alice can transmit the results of her measurements to Bob on a classical channel, and Alice and Bob have common randomness. The question is what is the minimum amount of communications and common randomness needed. The paper derives an achievable rate region.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12271v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anders H{\o}st-Madsen</dc:creator>
    </item>
    <item>
      <title>Making it to First: The Random Access Problem in DNA Storage</title>
      <link>https://arxiv.org/abs/2501.12274</link>
      <description>arXiv:2501.12274v1 Announce Type: new 
Abstract: We study the Random Access Problem in DNA storage, which addresses the challenge of retrieving a specific information strand from a DNA-based storage system. Given that $k$ information strands, representing the data, are encoded into $n$ strands using a code. The goal under this paradigm is to identify and analyze codes that minimize the expected number of reads required to retrieve any of the $k$ information strand, while in each read one of the $n$ encoded strands is read uniformly at random. We fully solve the case when $k=2$, showing that the best possible code attains a random access expectation of $0.914 \cdot 2$. Moreover, we generalize a construction from \cite{GMZ24}, specific to $k=3$, for any value of $k$. Our construction uses $B_{k-1}$ sequences over $\mathbb{Z}_{q-1}$, that always exist over large finite fields. For $k=4$, we show that this generalized construction outperforms all previous constructions in terms of reducing the random access expectation .</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12274v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Avital Boruchovsky, Ohad Elishco, Ryan Gabrys, Anina Gruica, Itzhak Tamo, Eitan Yaakobi</dc:creator>
    </item>
    <item>
      <title>Bounds and Codes for General Phased Burst Errors</title>
      <link>https://arxiv.org/abs/2501.12280</link>
      <description>arXiv:2501.12280v1 Announce Type: new 
Abstract: Phased burst errors (PBEs) are bursts of errors occurring at one or more known locations. The correction of PBEs is a classical topic in coding theory, with prominent applications such as the design of array codes for memory systems or distributed storage. We propose a general yet fine-grained approach to this problem, accounting not only for the number of bursts but also the error structure in each burst. By modeling PBEs as an error set in an adversarial channel, we investigate bounds on the maximal size of codes that can correct them. The PBE-correction capability of generalized concatenated codes is analyzed, and asymptotically good PBE-correcting codes are constructed, recovering a classical construction in a specific problem instance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12280v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sebastian Bitzer, Andrea Di Giusto, Alberto Ravagnani, Eitan Yaakobi</dc:creator>
    </item>
    <item>
      <title>A Linear Programming Approach to Private Information Retrieval</title>
      <link>https://arxiv.org/abs/2501.12286</link>
      <description>arXiv:2501.12286v1 Announce Type: new 
Abstract: This work presents an algorithmic framework that uses linear programming to construct \emph{addition-based Private Information Retrieval (AB-PIR)} schemes, where retrieval is performed by downloading only linear combinations of message symbols with coefficients set to 0 or 1. The AB-PIR schemes generalize several existing capacity-achieving PIR schemes and are of practical interest because they use only addition operations -- avoiding multiplication and other complex operations -- and are compatible with any finite field, including binary. Our framework broadens the search space to include all feasible solutions and can be used to construct optimal AB-PIR schemes for the entire range of problem parameters, including the number of servers, the total number of messages, and the number of messages that need to be retrieved. The framework enables us to identify schemes that outperform the previously proposed PIR schemes in certain cases and, in other cases, achieve performance on par with the best-known AB-PIR solutions. Additionally, the schemes generated by our framework can be integrated into existing solutions for several related PIR scenarios, improving their overall performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12286v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anoosheh Heidarzadeh, Ningze Wang, Alex Sprintson</dc:creator>
    </item>
    <item>
      <title>Improved Decoding of Tanner Codes</title>
      <link>https://arxiv.org/abs/2501.12293</link>
      <description>arXiv:2501.12293v1 Announce Type: new 
Abstract: In this paper, we present improved decoding algorithms for expander-based Tanner codes. We begin by developing a randomized linear-time decoding algorithm that, under the condition that $ \delta d_0 &gt; 2 $, corrects up to $ \alpha n $ errors for a Tanner code $ T(G, C_0) $, where $ G $ is a $ (c, d, \alpha, \delta) $-bipartite expander with $n$ left vertices, and $ C_0 \subseteq \mathbb{F}_2^d $ is a linear inner code with minimum distance $ d_0 $. This result improves upon the previous work of Cheng, Ouyang, Shangguan, and Shen (RANDOM 2024), which required $ \delta d_0 &gt; 3 $. We further derandomize the algorithm to obtain a deterministic linear-time decoding algorithm with the same decoding radius. Our algorithm improves upon the previous deterministic algorithm of Cheng et al. by achieving a decoding radius of $ \alpha n $, compared with the previous radius of $ \frac{2\alpha}{d_0(1 + 0.5c\delta) }n$.
  Additionally, we investigate the size-expansion trade-off introduced by the recent work of Chen, Cheng, Li, and Ouyang (IEEE TIT 2023), and use it to provide new bounds on the minimum distance of Tanner codes. Specifically, we prove that the minimum distance of a Tanner code $T(G,C_0)$ is approximately $f_\delta^{-1} \left( \frac{1}{d_0} \right) \alpha n $, where $ f_\delta(\cdot) $ is the Size-Expansion Function. As another application, we improve the decoding radius of our decoding algorithms from $\alpha n$ to approximately $f_\delta^{-1}(\frac{2}{d_0})\alpha n$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12293v1</guid>
      <category>cs.IT</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zeyu Guo, Zhaienhe Zhou</dc:creator>
    </item>
    <item>
      <title>Wrap-Decoding in Asynchronous Unsourced Multiple Access With and Without Delay Information</title>
      <link>https://arxiv.org/abs/2501.12294</link>
      <description>arXiv:2501.12294v1 Announce Type: new 
Abstract: An asynchronous $\ka$-active-user unsourced multiple access channel (AUMAC) is a key model for uncoordinated massive access in future networks. We focus on a scenario where each transmission is subject to the maximal delay constraint ($\dm$), and the precise delay of each user is unknown at the receiver. The combined effects of asynchronicity and uncertain delays require analysis over all possible delay-codeword combinations, making the complexity of the analysis grow with $\dm$ and $\ka$ exponentially. To overcome the complexity, we employ a wrap-decoder for the AUMAC and derive a uniform upper bound on the per-user probability of error (PUPE). The numerical result shows the trade-off between energy per bit and the number of active users under various delay constraints. Furthermore, in our considered AUMAC, decoding without explicit delay information is shown to achieve nearly the same energy efficiency as decoding with perfect delay knowledge.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12294v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jyun-Sian Wu, Pin-Hsun Lin, Marcel A. Mross, Eduard A. Jorswieck</dc:creator>
    </item>
    <item>
      <title>A General Achievable Scheme for Linear Computation Broadcast Channel</title>
      <link>https://arxiv.org/abs/2501.12322</link>
      <description>arXiv:2501.12322v1 Announce Type: new 
Abstract: This paper presents a new achievable scheme for the Linear Computation Broadcast Channel (LCBC), which is based on a generalized subspace decomposition derived from representable polymatroid space. This decomposition enables the server to serve user demands with an approach of effective multicast and interference elimination. We extend existing results by introducing a linear programming framework to optimize multicast opportunities across an arbitrary number of users.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12322v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yinbin Ma, Daniela Tuninetti</dc:creator>
    </item>
    <item>
      <title>The Gap Between Principle and Practice of Lossy Image Coding</title>
      <link>https://arxiv.org/abs/2501.12330</link>
      <description>arXiv:2501.12330v1 Announce Type: new 
Abstract: Lossy image coding is the art of computing that is principally bounded by the image's rate-distortion function. This bound, though never accurately characterized, has been approached practically via deep learning technologies in recent years. Indeed, learned image coding schemes allow direct optimization of the joint rate-distortion cost, thereby outperforming the handcrafted image coding schemes by a large margin. Still, it is observed that there is room for further improvement in the rate-distortion performance of learned image coding. In this article, we identify the gap between the ideal rate-distortion function forecasted by Shannon's information theory and the empirical rate-distortion function achieved by the state-of-the-art learned image coding schemes, revealing that the gap is incurred by five different effects: modeling effect, approximation effect, amortization effect, digitization effect, and asymptotic effect. We design simulations and experiments to quantitively evaluate the last three effects, which demonstrates the high potential of future lossy image coding technologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12330v1</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haotian Zhang, Dong Liu</dc:creator>
    </item>
    <item>
      <title>Rate-Distortion-Perception Function of Bernoulli Vector Sources</title>
      <link>https://arxiv.org/abs/2501.12348</link>
      <description>arXiv:2501.12348v1 Announce Type: new 
Abstract: In this paper, we consider the rate-distortion-perception (RDP) trade-off for the lossy compression of a Bernoulli vector source, which is a finite collection of independent binary random variables. The RDP function quantifies in a way the efficient compression of a source when we impose a distortion constraint that limits the dissimilarity between the source and the reconstruction and a perception constraint that restricts the distributional discrepancy of the source and the reconstruction. In this work, we obtain an exact characterization of the RDP function of a Bernoulli vector source with the Hamming distortion function and a single-letter perception function that measures the closeness of the distributions of the components of the source. The solution can be described by partitioning the set of distortion and perception levels $(D,P)$ into three regions, where in each region the optimal distortion and perception levels we allot to the components have a similar nature. Finally, we introduce the RDP function for graph sources and apply our result to the Erd\H{o}s-R\'enyi graph model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12348v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Praneeth Kumar Vippathalla, Mihai-Alin Badiu, Justin P. Coon</dc:creator>
    </item>
    <item>
      <title>CAT and DOG: Improved Codes for Private Distributed Matrix Multiplication</title>
      <link>https://arxiv.org/abs/2501.12371</link>
      <description>arXiv:2501.12371v1 Announce Type: new 
Abstract: We present novel constructions of polynomial codes for private distributed matrix multiplication (PDMM/SDMM) using outer product partitioning (OPP). We extend the degree table framework from the literature to cyclic addition degree tables (CATs). By restricting the evaluation points to certain roots of unity, we enable modulo-addition in the degree table. This results in additional freedom when designing constructions. Based on CATs, we present an explicit construction, called CATx , that requires fewer workers than existing schemes in the low-privacy regime. Additionally, using regular degree tables, we present new families of schemes, called GASPrs and DOGrs , that outperform the state-of-the-art for a range of parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12371v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christoph Hofmeister, Rawad Bitar, Antonia Wachter-Zeh</dc:creator>
    </item>
    <item>
      <title>Constant Weight Polar Codes through Periodic Markov Processes</title>
      <link>https://arxiv.org/abs/2501.12379</link>
      <description>arXiv:2501.12379v1 Announce Type: new 
Abstract: Constant weight codes can arise from an input process sampled from a periodic Markov chain. A previous result showed that, in general, polarization does not occur for input-output processes with an underlying periodic Markov chain. In this work, we show that if we fix the initial state of an underlying periodic Markov chain, polarization does occur. Fixing the initial state is aligned with ensuring a constant weight code.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12379v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Boaz Shuval, Ido Tal</dc:creator>
    </item>
    <item>
      <title>Logarithmic Positional Partition Interval Encoding</title>
      <link>https://arxiv.org/abs/2412.11236</link>
      <description>arXiv:2412.11236v1 Announce Type: cross 
Abstract: One requirement of maintaining digital information is storage. With the latest advances in the digital world, new emerging media types have required even more storage space to be kept than before. In fact, in many cases it is required to have larger amounts of storage to keep up with protocols that support more types of information at the same time. In contrast, compression algorithms have been integrated to facilitate the transfer of larger data. Numerical representations are construed as embodiments of information. However, this correct association of a sequence could feasibly be inverted to signify an elongated series of numerals. In this work, a novel mathematical paradigm was introduced to engineer a methodology reliant on iterative logarithmic transformations, finely tuned to numeric sequences. Through this fledgling approach, an intricate interplay of polymorphic numeric manipulations was conducted. By applying repeated logarithmic operations, the data were condensed into a minuscule representation. Approximately thirteen times surpassed the compression method, ZIP. Such extreme compaction, achieved through iterative reduction of expansive integers until they manifested as single-digit entities, conferred a novel sense of informational embodiment. Instead of relegating data to classical discrete encodings, this method transformed them into a quasi-continuous, logarithmically. By contrast, this introduced approach revealed that morphing data into deeply compressed numerical substrata beyond conventional boundaries was feasible. A holistic perspective emerges, validating that numeric data can be recalibrated into ephemeral sequences of logarithmic impressions. It was not merely a matter of reducing digits, but of reinterpreting data through a resolute numeric vantage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.11236v1</guid>
      <category>cs.DS</category>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Vasileios Alevizos, Nikitas Gerolimos, Sabrina Edralin, Clark Xu, Akebu Simasiku, Georgios Priniotakis, George Papakostas, Zongliang Yue</dc:creator>
    </item>
    <item>
      <title>Investigating the Temporal Dynamics of Cyber Threat Intelligence</title>
      <link>https://arxiv.org/abs/2412.19086</link>
      <description>arXiv:2412.19086v1 Announce Type: cross 
Abstract: Indicators of Compromise (IoCs) play a crucial role in the rapid detection and mitigation of cyber threats. However, the existing body of literature lacks in-depth analytical studies on the temporal aspects of IoC publication, especially when considering up-to-date datasets related to Common Vulnerabilities and Exposures (CVEs). This paper addresses this gap by conducting an analysis of the timeliness and comprehensiveness of Cyber Threat Intelligence (CTI) pertaining to several recent CVEs. The insights derived from this study aim to enhance cybersecurity defense strategies, particularly when dealing with dynamic cyber threats that continually adapt their Tactics, Techniques, and Procedures (TTPs). Utilizing IoCs sourced from multiple providers, we scrutinize the IoC publication rate. Our analysis delves into how various factors, including the inherent nature of a threat, its evolutionary trajectory, and its observability over time, influence the publication rate of IoCs. Our preliminary findings emphasize the critical need for cyber defenders to maintain a constant state of vigilance in updating their IoCs for any given vulnerability. This vigilance is warranted because the publication rate of IoCs may exhibit fluctuations over time. We observe a recurring pattern akin to an epidemic model, with an initial phase following the public disclosure of a vulnerability characterized by sparse IoC publications, followed by a sudden surge, and subsequently, a protracted period with a slower rate of IoC publication.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.19086v1</guid>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>cs.SI</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/BigData59044.2023.10386664</arxiv:DOI>
      <arxiv:journal_reference>2023 IEEE International Conference on Big Data 1 (1), 6207 - 6211</arxiv:journal_reference>
      <dc:creator>Angel Kodituwakku, Clark Xu, Daniel Rogers, David K. Ahn, Errin W. Fulp</dc:creator>
    </item>
    <item>
      <title>Energy-Constrained Information Storage on Memristive Devices in the Presence of Resistive Drift</title>
      <link>https://arxiv.org/abs/2501.10376</link>
      <description>arXiv:2501.10376v1 Announce Type: cross 
Abstract: In this paper, we examine the problem of information storage on memristors affected by resistive drift noise under energy constraints. We introduce a novel, fundamental trade-off between the information lifetime of memristive states and the energy that must be expended to bring the device into a particular state. We then treat the storage problem as one of communication over a noisy, energy-constrained channel, and propose a joint source-channel coding (JSCC) approach to storing images in an analogue fashion. To design an encoding scheme for natural images and to model the memristive channel, we make use of data-driven techniques from the field of deep learning for communications, namely deep joint source-channel coding (DeepJSCC), employing a generative model of resistive drift as a computationally tractable differentiable channel model for end-to-end optimisation. We introduce a modified version of generalised divisive normalisation (GDN), a biologically inspired form of normalisation, that we call conditional GDN (cGDN), allowing for conditioning on continuous channel characteristics, including the initial resistive state and the delay between storage and reading. Our results show that the delay-conditioned network is able to learn an energy-aware coding scheme that achieves a higher and more balanced reconstruction quality across a range of storage delays.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10376v1</guid>
      <category>cs.ET</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Waleed El-Geresy, Christos Papavassiliou, Deniz G\"und\"uz</dc:creator>
    </item>
    <item>
      <title>On the Optimality of Random Partial Sphere Coverings in High Dimensions</title>
      <link>https://arxiv.org/abs/2501.10607</link>
      <description>arXiv:2501.10607v1 Announce Type: cross 
Abstract: Given $N$ geodesic caps on the normalized unit sphere in $\mathbb{R}^d$, and whose total surface area sums to one, what is the maximal surface area their union can cover? We show that when these caps have equal surface area, as both the dimension $d$ and the number of caps $N$ tend to infinity, the maximum proportion covered approaches $1 - e^{-1} \approx 0.632$. Furthermore, this maximum is achieved by a random partial sphere covering. Our result refines a classical estimate for the covering density of $\mathbb{R}^d$ by Erd\H{o}s, Few, and Rogers (Mathematika, 11(2):171--184, 1964).</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10607v1</guid>
      <category>math.MG</category>
      <category>cs.IT</category>
      <category>math.FA</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Steven Hoehner, Gil Kur</dc:creator>
    </item>
    <item>
      <title>Universal Discrete Filtering with Lookahead or Delay</title>
      <link>https://arxiv.org/abs/2501.10609</link>
      <description>arXiv:2501.10609v1 Announce Type: cross 
Abstract: We consider the universal discrete filtering problem, where an input sequence generated by an unknown source passes through a discrete memoryless channel, and the goal is to estimate its components based on the output sequence with limited lookahead or delay. We propose and establish the universality of a family of schemes for this setting. These schemes are induced by universal Sequential Probability Assignments (SPAs), and inherit their computational properties. We show that the schemes induced by LZ78 are practically implementable and well-suited for scenarios with limited computational resources and latency constraints. In passing, we use some of the intermediate results to obtain upper and lower bounds that appear to be new, in the purely Bayesian setting, on the optimal filtering performance in terms, respectively, of the mutual information between the noise-free and noisy sequence, and the entropy of the noise-free sequence causally conditioned on the noisy one.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10609v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pumiao Yan, Jiwon Jeong, Naomi Sagan, Tsachy Weissman</dc:creator>
    </item>
    <item>
      <title>Homotopical Entropy</title>
      <link>https://arxiv.org/abs/2501.10672</link>
      <description>arXiv:2501.10672v1 Announce Type: cross 
Abstract: We present a "homotopification" of fundamental concepts from information theory. Using homotopy type theory, we define homotopy types that behave analogously to probability spaces, random variables, and the exponentials of Shannon entropy and relative entropy. The original analytic theories emerge through homotopy cardinality, which maps homotopy types to real numbers and generalizes the cardinality of sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10672v1</guid>
      <category>math.CT</category>
      <category>cs.IT</category>
      <category>math-ph</category>
      <category>math.IT</category>
      <category>math.MP</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andr\'es Ortiz-Mu\~noz</dc:creator>
    </item>
    <item>
      <title>Efficient Reconciliation of Continuous Variable Quantum Key Distribution with Multiplicatively Repeated Non-Binary LDPC Codes</title>
      <link>https://arxiv.org/abs/2501.11009</link>
      <description>arXiv:2501.11009v1 Announce Type: cross 
Abstract: Continuous variable quantum key distribution bears the promise of simple quantum key distribution directly compatible with commercial off the shelf equipment. However, for a long time its performance was hindered by the absence of good classical postprocessing capable of distilling secret-keys in the noisy regime. Advanced coding solutions in the past years have partially addressed this problem enabling record transmission distances of up to 165 km, and 206 km over ultra-low loss fiber. In this paper, we show that a very simple coding solution with a single code is sufficient to extract keys at all noise levels. This solution has performance competitive with prior results for all levels of noise, and we show that non-zero keys can be distilled up to a record distance of 192 km assuming the standard loss of a single-mode optical fiber, and 240 km over ultra-low loss fibers. Low-rate codes are constructed using multiplicatively repeated non-binary low-density parity-check codes over a finite field of characteristic two. This construction only makes use of a (2,k)-regular non-binary low-density parity-check code as mother code, such that code design is in fact not required, thus trivializing the code construction procedure. The construction is also inherently rate-adaptive thereby allowing to easily create codes of any rate. Rate-adaptive codes are of special interest for the efficient reconciliation of errors over time or arbitrary varying channels, as is the case with quantum key distribution. In short, these codes are highly efficient when reconciling errors over a very noisy communication channel, and perform well even for short block-length codes. Finally, the proposed solution is known to be easily amenable to hardware implementations, thus addressing also the requirements for practical reconciliation in continuous variable quantum key distribution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11009v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jesus Martinez-Mateo, David Elkouss</dc:creator>
    </item>
    <item>
      <title>Federated Testing (FedTest): A New Scheme to Enhance Convergence and Mitigate Adversarial Attacks in Federating Learning</title>
      <link>https://arxiv.org/abs/2501.11167</link>
      <description>arXiv:2501.11167v1 Announce Type: cross 
Abstract: Federated Learning (FL) has emerged as a significant paradigm for training machine learning models. This is due to its data-privacy-preserving property and its efficient exploitation of distributed computational resources. This is achieved by conducting the training process in parallel at distributed users. However, traditional FL strategies grapple with difficulties in evaluating the quality of received models, handling unbalanced models, and reducing the impact of detrimental models. To resolve these problems, we introduce a novel federated learning framework, which we call federated testing for federated learning (FedTest). In the FedTest method, the local data of a specific user is used to train the model of that user and test the models of the other users. This approach enables users to test each other's models and determine an accurate score for each. This score can then be used to aggregate the models efficiently and identify any malicious ones. Our numerical results reveal that the proposed method not only accelerates convergence rates but also diminishes the potential influence of malicious users. This significantly enhances the overall efficiency and robustness of FL systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11167v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mustafa Ghaleb, Mohanad Obeed, Muhamad Felemban, Anas Chaaban, Halim Yanikomeroglu</dc:creator>
    </item>
    <item>
      <title>Successive Interference Cancellation-aided Diffusion Models for Joint Channel Estimation and Data Detection in Low Rank Channel Scenarios</title>
      <link>https://arxiv.org/abs/2501.11229</link>
      <description>arXiv:2501.11229v1 Announce Type: cross 
Abstract: This paper proposes a novel joint channel-estimation and source-detection algorithm using successive interference cancellation (SIC)-aided generative score-based diffusion models. Prior work in this area focuses on massive MIMO scenarios, which are typically characterized by full-rank channels, and fail in low-rank channel scenarios. The proposed algorithm outperforms existing methods in joint source-channel estimation, especially in low-rank scenarios where the number of users exceeds the number of antennas at the access point (AP). The proposed score-based iterative diffusion process estimates the gradient of the prior distribution on partial channels, and recursively updates the estimated channel parts as well as the source. Extensive simulation results show that the proposed method outperforms the baseline methods in terms of normalized mean squared error (NMSE) and symbol error rate (SER) in both full-rank and low-rank channel scenarios, while having a more dominant effect in the latter, at various signal-to-noise ratios (SNR).</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11229v1</guid>
      <category>cs.CV</category>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sagnik Bhattacharya, Muhammad Ahmed Mohsin, Kamyar Rajabalifardi, John M. Cioffi</dc:creator>
    </item>
    <item>
      <title>Optimum Power-Subcarrier Allocation and Time-Sharing in Multicarrier NOMA Uplink</title>
      <link>https://arxiv.org/abs/2501.11230</link>
      <description>arXiv:2501.11230v1 Announce Type: cross 
Abstract: Currently used resource allocation methods for uplink multicarrier non-orthogonal multiple access (MC-NOMA) systems have multiple shortcomings. Current approaches either allocate the same power across all subcarriers to a user, or use heuristic-based near-far, strong channel-weak channel user grouping to assign the decoding order for successive interference cancellation (SIC). This paper proposes a novel optimal power-subcarrier allocation for uplink MC-NOMA. This new allocation achieves the optimal power-subcarrier allocation as well as the optimal SIC decoding order. Furthermore, the proposed method includes a time-sharing algorithm that dynamically alters the decoding orders of the participating users to achieve the required data rates, even in cases where any single decoding order fails to do so. Extensive experimental evaluations show that the new method achieves higher sum data rates and lower power consumption compared to current NOMA methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11230v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sagnik Bhattacharya, Kamyar Rajabalifardi, Muhammad Ahmed Mohsin, John M. Cioffi</dc:creator>
    </item>
    <item>
      <title>Empirical Bayes Estimation for Lasso-Type Regularizers: Analysis of Automatic Relevance Determination</title>
      <link>https://arxiv.org/abs/2501.11280</link>
      <description>arXiv:2501.11280v1 Announce Type: cross 
Abstract: This paper focuses on linear regression models with non-conjugate sparsity-inducing regularizers such as lasso and group lasso. Although empirical Bayes approach enables us to estimate the regularization parameter, little is known on the properties of the estimators. In particular, there are many unexplained aspects regarding the specific conditions under which the mechanism of automatic relevance determination (ARD) occurs. In this paper, we derive the empirical Bayes estimators for the group lasso regularized linear regression models with a limited number of parameters. It is shown that the estimators diverge under a certain condition, giving rise to the ARD mechanism. We also prove that empirical Bayes methods can produce ARD mechanism in general regularized linear regression models and clarify the conditions under which models such as ridge, lasso, and group lasso can produce ARD mechanism.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11280v1</guid>
      <category>math.ST</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>stat.TH</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tsukasa Yoshida, Kazuho Watanabe</dc:creator>
    </item>
    <item>
      <title>Generalization and Informativeness of Weighted Conformal Risk Control Under Covariate Shift</title>
      <link>https://arxiv.org/abs/2501.11413</link>
      <description>arXiv:2501.11413v1 Announce Type: cross 
Abstract: Predictive models are often required to produce reliable predictions under statistical conditions that are not matched to the training data. A common type of training-testing mismatch is covariate shift, where the conditional distribution of the target variable given the input features remains fixed, while the marginal distribution of the inputs changes. Weighted conformal risk control (W-CRC) uses data collected during the training phase to convert point predictions into prediction sets with valid risk guarantees at test time despite the presence of a covariate shift. However, while W-CRC provides statistical reliability, its efficiency -- measured by the size of the prediction sets -- can only be assessed at test time. In this work, we relate the generalization properties of the base predictor to the efficiency of W-CRC under covariate shifts. Specifically, we derive a bound on the inefficiency of the W-CRC predictor that depends on algorithmic hyperparameters and task-specific quantities available at training time. This bound offers insights on relationships between the informativeness of the prediction sets, the extent of the covariate shift, and the size of the calibration and training sets. Experiments on fingerprinting-based localization validate the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11413v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Matteo Zecchin (Shitz), Fredrik Hellstr\"om (Shitz), Sangwoo Park (Shitz), Shlomo Shamai (Shitz), Osvaldo Simeone</dc:creator>
    </item>
    <item>
      <title>Online Clustering with Bandit Information</title>
      <link>https://arxiv.org/abs/2501.11421</link>
      <description>arXiv:2501.11421v1 Announce Type: cross 
Abstract: We study the problem of online clustering within the multi-armed bandit framework under the fixed confidence setting. In this multi-armed bandit problem, we have $M$ arms, each providing i.i.d. samples that follow a multivariate Gaussian distribution with an {\em unknown} mean and a known unit covariance. The arms are grouped into $K$ clusters based on the distance between their means using the Single Linkage (SLINK) clustering algorithm on the means of the arms. Since the true means are unknown, the objective is to obtain the above clustering of the arms with the minimum number of samples drawn from the arms, subject to an upper bound on the error probability. We introduce a novel algorithm, Average Tracking Bandit Online Clustering (ATBOC), and prove that this algorithm is order optimal, meaning that the upper bound on its expected sample complexity for given error probability $\delta$ is within a factor of 2 of an instance-dependent lower bound as $\delta \rightarrow 0$. Furthermore, we propose a computationally more efficient algorithm, Lower and Upper Confidence Bound-based Bandit Online Clustering (LUCBBOC), inspired by the LUCB algorithm for best arm identification. Simulation results demonstrate that the performance of LUCBBOC is comparable to that of ATBOC. We numerically assess the effectiveness of the proposed algorithms through numerical experiments on both synthetic datasets and the real-world MovieLens dataset. To the best of our knowledge, this is the first work on bandit online clustering that allows arms with different means in a cluster and $K$ greater than 2.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11421v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>G Dhinesh Chandran, Srinivas Reddy Kota, Srikrishna Bhashyam</dc:creator>
    </item>
    <item>
      <title>Decomposing Interventional Causality into Synergistic, Redundant, and Unique Components</title>
      <link>https://arxiv.org/abs/2501.11447</link>
      <description>arXiv:2501.11447v1 Announce Type: cross 
Abstract: We introduce a novel framework for decomposing interventional causal effects into synergistic, redundant, and unique components, building on the intuition of Partial Information Decomposition (PID) and the principle of M\"obius inversion. While recent work has explored a similar decomposition of an observational measure, we argue that a proper causal decomposition must be interventional in nature. We develop a mathematical approach that systematically quantifies how causal power is distributed among variables in a system, using a recently derived closed-form expression for the M\"obius function of the redundancy lattice. The formalism is then illustrated by decomposing the causal power in logic gates, cellular automata, and chemical reaction networks. Our results reveal how the distribution of causal power can be context- and parameter-dependent. This decomposition provides new insights into complex systems by revealing how causal influences are shared and combined among multiple variables, with potential applications ranging from attribution of responsibility in legal or AI systems, to the analysis of biological networks or climate models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11447v1</guid>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>physics.data-an</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abel Jansma</dc:creator>
    </item>
    <item>
      <title>Optimal User and Target Scheduling, User-Target Pairing, and Low-Resolution Phase-Only Beamforming for ISAC Systems</title>
      <link>https://arxiv.org/abs/2501.11593</link>
      <description>arXiv:2501.11593v1 Announce Type: cross 
Abstract: We investigate the joint user and target scheduling, user-target pairing, and low-resolution phase-only beamforming design for integrated sensing and communications (ISAC). Scheduling determines which users and targets are served, while pairing specifies which users and targets are grouped into pairs. Additionally, the beamformers are designed using few-bit constant-modulus phase shifts. This resource allocation problem is a nonconvex mixed-integer nonlinear program (MINLP) and challenging to solve. To address it, we propose an exact mixed-integer linear program (MILP) reformulation, which leads to a globally optimal solution. Our results demonstrate the superiority of an optimal joint design compared to heuristic stage-wise approaches, which are highly sensitive to scenario characteristics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11593v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luis F. Abanto-Leon, Setareh Maghsudi</dc:creator>
    </item>
    <item>
      <title>OciorABA: Improved Error-Free Asynchronous Byzantine Agreement via Partial Vector Agreement</title>
      <link>https://arxiv.org/abs/2501.11788</link>
      <description>arXiv:2501.11788v1 Announce Type: cross 
Abstract: In this work, we propose an error-free, information-theoretically secure multi-valued asynchronous Byzantine agreement (ABA) protocol, called OciorABA. This protocol achieves ABA consensus on an $\ell$-bit message with an expected communication complexity of $O(n\ell + n^3 \log q )$ bits and an expected round complexity of $O(1)$ rounds, under the optimal resilience condition $n \geq 3t + 1$ in an $n$-node network, where up to $t$ nodes may be dishonest. Here, $q$ denotes the alphabet size of the error correction code used in the protocol. In our protocol design, we introduce a new primitive: asynchronous partial vector agreement (APVA). In APVA, the distributed nodes input their vectors and aim to output a common vector, where some of the elements of those vectors may be missing or unknown. We propose an APVA protocol with an expected communication complexity of $O( n^3 \log q )$ bits and an expected round complexity of $O(1)$ rounds. This APVA protocol serves as a key building block for our OciorABA protocol.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11788v1</guid>
      <category>cs.DC</category>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinyuan Chen</dc:creator>
    </item>
    <item>
      <title>Saturation in Snapshot Compressive Imaging</title>
      <link>https://arxiv.org/abs/2501.11869</link>
      <description>arXiv:2501.11869v1 Announce Type: cross 
Abstract: Snapshot Compressive Imaging (SCI) maps three-dimensional (3D) data cubes, such as videos or hyperspectral images, into two-dimensional (2D) measurements via optical modulation, enabling efficient data acquisition and reconstruction. Recent advances have shown the potential of mask optimization to enhance SCI performance, but most studies overlook nonlinear distortions caused by saturation in practical systems. Saturation occurs when high-intensity measurements exceed the sensor's dynamic range, leading to information loss that standard reconstruction algorithms cannot fully recover. This paper addresses the challenge of optimizing binary masks in SCI under saturation. We theoretically characterize the performance of compression-based SCI recovery in the presence of saturation and leverage these insights to optimize masks for such conditions. Our analysis reveals trade-offs between mask statistics and reconstruction quality in saturated systems. Experimental results using a Plug-and-Play (PnP) style network validate the theory, demonstrating improved recovery performance and robustness to saturation with our optimized binary masks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11869v1</guid>
      <category>eess.IV</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.AP</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mengyu Zhao, Shirin Jalali</dc:creator>
    </item>
    <item>
      <title>A note on the sample complexity of multi-target detection</title>
      <link>https://arxiv.org/abs/2501.11980</link>
      <description>arXiv:2501.11980v1 Announce Type: cross 
Abstract: This work studies the sample complexity of the multi-target detection (MTD) problem, which involves recovering a signal from a noisy measurement containing multiple instances of a target signal in unknown locations, each transformed by a random group element. This problem is primarily motivated by single-particle cryo-electron microscopy (cryo-EM), a groundbreaking technology for determining the structures of biological molecules. We establish upper and lower bounds for various MTD models in the high-noise regime as a function of the group, the distribution over the group, and the arrangement of signal occurrences within the measurement. The lower bounds are established through a reduction to the related multi-reference alignment problem, while the upper bounds are derived from explicit recovery algorithms utilizing autocorrelation analysis. These findings provide fundamental insights into estimation limits in noisy environments and lay the groundwork for extending this analysis to more complex applications, such as cryo-EM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11980v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amnon Balanov, Shay Kreymer, Tamir Bendory</dc:creator>
    </item>
    <item>
      <title>Ratio Attack on G+G Convoluted Gaussian Signature</title>
      <link>https://arxiv.org/abs/2501.12009</link>
      <description>arXiv:2501.12009v1 Announce Type: cross 
Abstract: A lattice-based signature, called G+G convoluted Gaussian signature was proposed in ASIACRYPT 2023 and was proved secure in the quantum random oracle model. In this paper, we propose a ratio attack on the G+G convoluted Gaussian signature to recover the secret key. The attack exploits the fact, proved in this paper, that the secret key can be obtained from the expected value of the ratio of signatures which follows a truncated Cauchy distribution. Moreover, we also compute the number of signatures required to successfully recover the secret key. Furthermore, we simulate the ratio attack in Sagemath with a few different parameters as a proof-of-concept of the ratio attack.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12009v1</guid>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chik How Tan, Theo Fanuela Prabowo, Wei Guo Foo</dc:creator>
    </item>
    <item>
      <title>Fault-tolerance of [[6, 1, 3]] non-CSS code family generated using measurements on graph states</title>
      <link>https://arxiv.org/abs/2501.12072</link>
      <description>arXiv:2501.12072v1 Announce Type: cross 
Abstract: We construct and analyze the fault tolerance of $[[6,1,3]]$ non-CSS quantum error correcting code under the anisotropic and depolarizing noise models. This rate-optimized code achieves fault-tolerance using a single ancilla qubit for syndrome measurement under anisotropic noise conditions. This method was called fault-tolerance using bare ancilla by Brown \emph{et al.} We give explicit construction of the code using measurements on non-planar graph states. We also argue that using our approach, we can construct a family of such fault-tolerant codes. This method fills a notable gap in constructing fault-tolerant non-CSS code families.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12072v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Harsh Gupta, Pranav Maheshwari, Ankur Raina</dc:creator>
    </item>
    <item>
      <title>Data-Aided Regularization of Direct-Estimate Combiner in Distributed MIMO Systems</title>
      <link>https://arxiv.org/abs/2501.12092</link>
      <description>arXiv:2501.12092v1 Announce Type: cross 
Abstract: This paper explores the data-aided regularization of the direct-estimate combiner in the uplink of a distributed multiple-input multiple-output system. The network-wide combiner can be computed directly from the pilot signal received at each access point, eliminating the need for explicit channel estimation. However, the sample covariance matrix of the received pilot signal that is used in its computation may significantly deviate from the actual covariance matrix when the number of pilot symbols is limited. To address this, we apply a regularization to the sample covariance matrix using a shrinkage coefficient based on the received data signal. Initially, the shrinkage coefficient is determined by minimizing the difference between the sample covariance matrices obtained from the received pilot and data signals. Given the limitations of this approach in interference-limited scenarios, the shrinkage coefficient is iteratively optimized using the sample mean squared error of the hard-decision symbols, which is more closely related to the actual system's performance, e.g., the symbol error rate (SER). Numerical results demonstrate that the proposed regularization of the direct-estimate combiner significantly enhances the SER, particularly when the number of pilot symbols is limited.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12092v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bikshapathi Gouda, Italo Atzeni, Antti T\"olli</dc:creator>
    </item>
    <item>
      <title>Optimizing Leaky Private Information Retrieval Codes to Achieve ${O}(\log K)$ Leakage Ratio Exponent</title>
      <link>https://arxiv.org/abs/2501.12310</link>
      <description>arXiv:2501.12310v1 Announce Type: cross 
Abstract: We study the problem of leaky private information retrieval (L-PIR), where the amount of privacy leakage is measured by the pure differential privacy parameter, referred to as the leakage ratio exponent. Unlike the previous L-PIR scheme proposed by Samy et al., which only adjusted the probability allocation to the clean (low-cost) retrieval pattern, we optimize the probabilities assigned to all the retrieval patterns jointly. It is demonstrated that the optimal retrieval pattern probability distribution is quite sophisticated and has a layered structure: the retrieval patterns associated with the random key values of lower Hamming weights should be assigned higher probabilities. This new scheme provides a significant improvement, leading to an ${O}(\log K)$ leakage ratio exponent with fixed download cost $D$ and number of servers $N$, in contrast to the previous art that only achieves a $\Theta(K)$ exponent, where $K$ is the number of messages.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12310v1</guid>
      <category>cs.IR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenyuan Zhao, Yu-Shin Huang, Chao Tian, Alex Sprintson</dc:creator>
    </item>
    <item>
      <title>Measured Hockey-Stick Divergence and its Applications to Quantum Pufferfish Privacy</title>
      <link>https://arxiv.org/abs/2501.12359</link>
      <description>arXiv:2501.12359v1 Announce Type: cross 
Abstract: The hockey-stick divergence is a fundamental quantity characterizing several statistical privacy frameworks that ensure privacy for classical and quantum data. In such quantum privacy frameworks, the adversary is allowed to perform all possible measurements. However, in practice, there are typically limitations to the set of measurements that can be performed. To this end, here, we comprehensively analyze the measured hockey-stick divergence under several classes of practically relevant measurement classes. We prove several of its properties, including data processing and convexity. We show that it is efficiently computable by semi-definite programming for some classes of measurements and can be analytically evaluated for Werner and isotropic states. Notably, we show that the measured hockey-stick divergence characterizes optimal privacy parameters in the quantum pufferfish privacy framework. With this connection and the developed technical tools, we enable methods to quantify and audit privacy for several practically relevant settings. Lastly, we introduce the measured hockey-stick divergence of channels and explore its applications in ensuring privacy for channels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12359v1</guid>
      <category>quant-ph</category>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Theshani Nuradha, Vishal Singh, Mark M. Wilde</dc:creator>
    </item>
    <item>
      <title>Efficient Algorithm for Sparse Fourier Transform of Generalized q-ary Functions</title>
      <link>https://arxiv.org/abs/2501.12365</link>
      <description>arXiv:2501.12365v1 Announce Type: cross 
Abstract: Computing the Fourier transform of a $q$-ary function $f:\mathbb{Z}_{q}^n\rightarrow \mathbb{R}$, which maps $q$-ary sequences to real numbers, is an important problem in mathematics with wide-ranging applications in biology, signal processing, and machine learning. Previous studies have shown that, under the sparsity assumption, the Fourier transform can be computed efficiently using fast and sample-efficient algorithms. However, in many practical settings, the function is defined over a more general space -- the space of generalized $q$-ary sequences $\mathbb{Z}_{q_1} \times \mathbb{Z}_{q_2} \times \cdots \times \mathbb{Z}_{q_n}$ -- where each $\mathbb{Z}_{q_i}$ corresponds to integers modulo $q_i$. A naive approach involves setting $q=\max_i{q_i}$ and treating the function as $q$-ary, which results in heavy computational overheads. Herein, we develop GFast, an algorithm that computes the $S$-sparse Fourier transform of $f$ with a sample complexity of $O(Sn)$, computational complexity of $O(Sn \log N)$, and a failure probability that approaches zero as $N=\prod_{i=1}^n q_i \rightarrow \infty$ with $S = N^\delta$ for some $0 \leq \delta &lt; 1$. In the presence of noise, we further demonstrate that a robust version of GFast computes the transform with a sample complexity of $O(Sn^2)$ and computational complexity of $O(Sn^2 \log N)$ under the same high probability guarantees. Using large-scale synthetic experiments, we demonstrate that GFast computes the sparse Fourier transform of generalized $q$-ary functions using $16\times$ fewer samples and running $8\times$ faster than existing algorithms. In real-world protein fitness datasets, GFast explains the predictive interactions of a neural network with $&gt;25\%$ smaller normalized mean-squared error compared to existing algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12365v1</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Darin Tsui, Kunal Talreja, Amirali Aghazadeh</dc:creator>
    </item>
    <item>
      <title>The capacity of a finite field matrix channel</title>
      <link>https://arxiv.org/abs/2210.14100</link>
      <description>arXiv:2210.14100v4 Announce Type: replace 
Abstract: The Additive-Multiplicative Matrix Channel (AMMC) was introduced by Silva, Kschischang and K\"otter in 2010 to model data transmission using random linear network coding. The input and output of the channel are $n\times m$ matrices over a finite field $\mathbb{F}_q$. On input the matrix $X$, the channel outputs $Y=A(X+W)$ where $A$ is a uniformly chosen $n\times n$ invertible matrix over $\mathbb{F}_q$ and where $W$ is a uniformly chosen $n\times m$ matrix over $\mathbb{F}_q$ of rank $t$.
  Silva \emph{et al} considered the case when $2n\leq m$. They determined the asymptotic capacity of the AMMC when $t$, $n$ and $m$ are fixed and $q\rightarrow\infty$. They also determined the leading term of the capacity when $q$ is fixed, and $t$, $n$ and $m$ grow linearly. We generalise these results, showing that the condition $2n\geq m$ can be removed. (Our formula for the capacity falls into two cases, one of which generalises the $2n\geq m$ case.) We also improve the error term in the case when $q$ is fixed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.14100v4</guid>
      <category>cs.IT</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Simon R. Blackburn, Jessica Claridge</dc:creator>
    </item>
    <item>
      <title>Outer Bounds on the CEO Problem with Privacy Constraints</title>
      <link>https://arxiv.org/abs/2301.12526</link>
      <description>arXiv:2301.12526v4 Announce Type: replace 
Abstract: We investigate the rate-distortion-leakage region of the Chief Executive Officer (CEO) problem, considering the presence of a passive eavesdropper and privacy constraints. We start by examining the region where a general distortion measure quantifies the distortion. While the inner bound of the region is derived from previous work, this paper newly develops an outer bound. To derive the outer bound, we introduce a new lemma tailored for analyzing privacy constraints. Next, as a specific instance of the general distortion measure, we demonstrate that the tight bound for discrete and Gaussian sources is obtained when the eavesdropper has no side information, and the distortion is quantified by the log-loss distortion measure. We further investigate the rate-distortion-leakage region for a scenario where the eavesdropper has side information, and the distortion is quantified by the log-loss distortion measure and provide an outer bound for this case. The derived outer bound differs from the inner bound by only a minor quantity that appears in the constraints associated with the privacy-leakage rates, and these bounds match when the distortion is large.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.12526v4</guid>
      <category>cs.IT</category>
      <category>cs.CR</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TIFS.2024.3522775</arxiv:DOI>
      <dc:creator>Vamoua Yachongka, Hideki Yagi, Hideki Ochiai</dc:creator>
    </item>
    <item>
      <title>Joint Identification and Sensing for Discrete Memoryless Channels</title>
      <link>https://arxiv.org/abs/2305.06627</link>
      <description>arXiv:2305.06627v3 Announce Type: replace 
Abstract: In the identification (ID) scheme proposed by Ahlswede and Dueck, the receiver's goal is simply to verify whether a specific message of interest was sent. Unlike Shannon's transmission codes, which aim for message decoding, ID codes for a Discrete Memoryless Channel (DMC) are far more efficient: their size grows doubly exponentially with the blocklength when randomized encoding is used. This indicates that, when the receiver's objective does not require decoding, the ID paradigm is significantly more efficient than traditional Shannon transmission in terms of both energy consumption and hardware complexity. Further benefits of ID schemes can be realized by leveraging additional resources such as feedback. In this work, we address the problem of joint ID and channel state estimation over a DMC with independent and identically distributed (i.i.d.) state sequences. State estimation functions as the sensing mechanism of the model. Specifically, the sender transmits an ID message over the DMC while simultaneously estimating the channel state through strictly causal observations of the channel output. Importantly, the random channel state is unknown to both the sender and the receiver. For this system model, we present a complete characterization of the ID capacity-distortion function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.06627v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wafa Labidi, Yaning Zhao, Christian Deppe, Holger Boche</dc:creator>
    </item>
    <item>
      <title>Intersection and union of subspaces with applications to communication over authenticated classical-quantum channels and composite hypothesis testing</title>
      <link>https://arxiv.org/abs/2311.10524</link>
      <description>arXiv:2311.10524v2 Announce Type: replace 
Abstract: In information theory, we often use intersection and union of the typical sets to analyze various communication problems. However, in the quantum setting it is not very clear how to construct a measurement which behaves analogously to intersection and union of the typical sets. In this work, we construct a projection operator which behaves very similarly to intersection and union of the typical sets. Our construction relies on the Jordan's lemma. Using this construction we study the problem of communication over authenticated classical-quantum channels and derive its capacity. As another application of our construction, we also study the problem of quantum asymmetric composite hypothesis testing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.10524v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>quant-ph</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TIT.2025.3531565</arxiv:DOI>
      <dc:creator>Naqueeb Ahmad Warsi, Ayanava Dasgupta</dc:creator>
    </item>
    <item>
      <title>Coded Caching for Hierarchical Two-Layer Networks with Coded Placement</title>
      <link>https://arxiv.org/abs/2312.15024</link>
      <description>arXiv:2312.15024v2 Announce Type: replace 
Abstract: We examine a two-layered hierarchical coded caching problem, a configuration addressed in existing research. This involves a server connected to $K_1$ mirrors, each of which serves $K_2$ users. The mirrors and the users are equipped with caches of size $M_1$ and $M_2$, respectively. We propose a hierarchical coded caching scheme with coded placements that outperforms existing schemes. To ensure a fair comparison, we introduce the notion of composite rate, defined as $\overline{R} = R_1 + K_1 R_2$, where $R_1$ is the rate from the server to mirrors and $R_2$ is the rate from mirrors to users. The composite rate has not been discussed before in the literature and is pertinent when mirrors transmit with different carrier frequencies. For the proposed scheme, we show a trade-off between the global memory $\overline{M}=K_1M_1+K_1K_2M_2$ of the system and the composite rate and compare with the existing schemes. Additionally, we conduct this comparative analysis by plotting $R_1$ + $R_2$ against global memory, which is particularly beneficial for systems wherein each mirror can utilize the same carrier frequency, given their significant spatial separation. Additionally, we propose an optimized scheme for the specific case of a single mirror, showing improved performance in this scenario.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.15024v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rajlaxmi Pandey, Charul Rajput, B. Sundar Rajan</dc:creator>
    </item>
    <item>
      <title>Bounded-degree Low Rank Parity Check Codes</title>
      <link>https://arxiv.org/abs/2401.15195</link>
      <description>arXiv:2401.15195v2 Announce Type: replace 
Abstract: Low-rank parity-check (LRPC) codes are the rank-metric analogue of low-density parity-check codes and they found important applications in code-based cryptography. In this paper we investigate a sub-family of LRPC codes, which have a parity-check matrix defined over a subspace $\calV_{\alpha,d}=\Span{\Fq}{1,\alpha, \ldots, \alpha^{d-1}}\subsetneq \Fqm$, where $\Fqm$ is the finite field of $q^m$ elements and $d$ is a positive integer significantly smaller than $m $; and they are termed bounded-degree LRPC (BD-LRPC) codes. These codes are the same as the standard LRPC codes of density $2$ when the degree $d=2$, while for degree $d&gt;2$ they constitute a proper subset of LRPC codes of density $d$. Exploiting the structure of $\calV_{\alpha,d}$, the BD-LRPC codes of degree $d$ can uniquely correct errors of rank weight $r$ when $n-k \geq r + u$ for certain $u \geq 1$, in contrast to the condition $n-k\geq dr$ required for the standard LRPC codes. This underscores the superior decoding capability of the BD-LRPC codes. Moreover, as the code length $n\rightarrow \infty$, when $n/m\rightarrow 0$, the BD-LRPC codes with a code rate of $R=k/n$ can be uniquely decodable with radius $\rho=r/n$ approaching the Singleton bound $1-R$ by letting $\epsilon=u/n\rightarrow 0$; and when $n/m$ is a constant, the BD-LRPC codes can have unique decoding radius $\rho = 1-R-\epsilon $ for a small $\epsilon$, allowing for $\rho&gt;(1-R)/2$ with properly chosen parameters.
  This superior decoding capability is theoretically proved for the case $d=2$ and confirmed by experimental results for $d&gt;2$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.15195v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ermes Franch, Chunlei Li</dc:creator>
    </item>
    <item>
      <title>The Blind Normalized Stein Variational Gradient Descent-Based Detection for Intelligent Random Access in Cellular IoT</title>
      <link>https://arxiv.org/abs/2403.18846</link>
      <description>arXiv:2403.18846v2 Announce Type: replace 
Abstract: The lack of an efficient preamble detection algorithm remains a challenge for solving preamble collision problems in intelligent random access (RA) in the cellular Internet of Things (IoT). To address this problem, we present an early preamble detection scheme based on a maximum likelihood estimation (MLE) model at the first step of the grant-based RA procedure. A novel blind normalized Stein variational gradient descent (SVGD)-based detector is proposed to obtain an approximate solution to the MLE model. First, by exploring the relationship between the Hadamard transform and wavelet packet transform, a new modified Hadamard transform (MHT) is developed to separate high-frequency components from signals using the second-order derivative filter. Next, to eliminate noise and mitigate the vanishing gradients problem in the SVGD-based detectors, the block MHT layer is designed based on the MHT, scaling layer, soft-thresholding layer, inverse MHT and sparsity penalty. Then, the blind normalized SVGD algorithm is derived to perform preamble detection without prior knowledge of noise power and the number of active IoT devices. The experimental results show the proposed block MHT layer outperforms other transform-based methods in terms of computation costs and denoising performance. Furthermore, with the assistance of the block MHT layer, the proposed blind normalized SVGD algorithm achieves a higher preamble detection accuracy and throughput than other state-of-the-art detection methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18846v2</guid>
      <category>cs.IT</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xin Zhu, Ahmet Enis Cetin</dc:creator>
    </item>
    <item>
      <title>Elements Allocation for Joint Active and Passive IRS Aided Wireless Communications: A Rate-Maximization Perspective</title>
      <link>https://arxiv.org/abs/2404.06880</link>
      <description>arXiv:2404.06880v3 Announce Type: replace 
Abstract: Unlike previous works that focused solely on passive intelligent reflecting surface (PIRS) or active IRS (AIRS), a novel joint AIRS and PIRS architecture has been developed to flexibly utilize their combined advantages in mitigating multiplicative path loss cost-effectively. In this paper, we consider the AIRS-PIRS jointly aided wireless point-to-point communication system with two different deployment schemes in three-dimensional (3D) space. To balance the trade-off between the square-order beamforming gain of PIRS and the unique power amplification gain of AIRS, we optimize the elements allocation and beamforming design of the two IRSs under various practical constraints from a rate-maximization perspective. Moreover, we derive a series of element-related closed-form analytical expressions and compare the performance of the two schemes. Our analysis shows that in both schemes, PIRS should be allocated more elements than AIRS, and the received signal-to-noise ratio (SNR) increases asymptotically with the cube of the number of reflecting elements, when the distance between AIRS and PIRS is sufficiently large. Last, simulation results validate our analysis and indicate that both schemes can achieve superior rate performance over various benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06880v3</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chaoying Huang, Wen Chen, Qingqing Wu, Nan Cheng</dc:creator>
    </item>
    <item>
      <title>Alternating Optimization Approach for Computing $\alpha$-Mutual Information and $\alpha$-Capacity</title>
      <link>https://arxiv.org/abs/2404.10950</link>
      <description>arXiv:2404.10950v3 Announce Type: replace 
Abstract: This study presents alternating optimization (AO) algorithms for computing $\alpha$-mutual information ($\alpha$-MI) and $\alpha$-capacity based on variational characterizations of $\alpha$-MI using a reverse channel. Specifically, we derive several variational characterizations of Sibson, Arimoto, Augustin--Csisz{\' a}r, and Lapidoth--Pfister MI and introduce novel AO algorithms for computing $\alpha$-MI and $\alpha$-capacity; their performances for computing $\alpha$-capacity are also compared. The comparison results show that the AO algorithm based on the Sibson MI's characterization has the fastest convergence speed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10950v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Akira Kamatsuka, Koki Kazama, Takahiro Yoshida</dc:creator>
    </item>
    <item>
      <title>Frame Codes for the Block-Erasure Channel -- Extended Version</title>
      <link>https://arxiv.org/abs/2405.01172</link>
      <description>arXiv:2405.01172v4 Announce Type: replace 
Abstract: Analog codes add redundancy by expanding the dimension using real/complex-valued operations. Frame theory provides a mathematical basis for constructing such codes, with diverse applications in non-orthogonal code-division multiple access (NOMA-CDMA), distributed computation, multiple description source coding, space-time coding (STC), and more. The channel model corresponding to these applications is a combination of noise and erasures. Recent analyses showed a useful connection between spectral random-matrix theory and large equiangular tight frames (ETFs) under random uniform erasures. In this work we generalize this model to a channel where the erasures come in blocks. This particularly fits NOMA-CDMA with multiple transmit antennas for each user and STC with known spatial grouping. We present a method to adjust ETF codes to suit block erasures, and find minimum intra-block-correlation frames which outperform ETFs in this setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01172v4</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Itamar Jacoby, Ram Zamir</dc:creator>
    </item>
    <item>
      <title>On the quantization goodness of polar lattices</title>
      <link>https://arxiv.org/abs/2405.04051</link>
      <description>arXiv:2405.04051v3 Announce Type: replace 
Abstract: In this work, we prove that polar lattices, when tailored for lossy compression, are quantization-good in the sense that their normalized second moments approach $\frac{1}{2\pi e}$ as the dimension of lattices increases. It has been predicted by Zamir et al. \cite{ZamirQZ96} that the Entropy Coded Dithered Quantization (ECDQ) system using quantization-good lattices can achieve the rate-distortion bound of i.i.d. Gaussian sources. In our previous work \cite{LingQZ}, we established that polar lattices are indeed capable of attaining the same objective. It is reasonable to conjecture that polar lattices also demonstrate quantization goodness in the context of lossy compression. This study confirms this hypothesis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04051v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ling Liu, Shanxiang Lyu, Cong Ling, Baoming Bai</dc:creator>
    </item>
    <item>
      <title>Task-Oriented Lossy Compression with Data, Perception, and Classification Constraints</title>
      <link>https://arxiv.org/abs/2405.04144</link>
      <description>arXiv:2405.04144v3 Announce Type: replace 
Abstract: By extracting task-relevant information while maximally compressing the input, the information bottleneck (IB) principle has provided a guideline for learning effective and robust representations of the target inference. However, extending the idea to the multi-task learning scenario with joint consideration of generative tasks and traditional reconstruction tasks remains unexplored. This paper addresses this gap by reconsidering the lossy compression problem with diverse constraints on data reconstruction, perceptual quality, and classification accuracy. Firstly, we study two ternary relationships, namely, the rate-distortion-classification (RDC) and rate-perception-classification (RPC). For both RDC and RPC functions, we derive the closed-form expressions of the optimal rate for binary and Gaussian sources. These new results complement the IB principle and provide insights into effectively extracting task-oriented information to fulfill diverse objectives. Secondly, unlike prior research demonstrating a tradeoff between classification and perception in signal restoration problems, we prove that such a tradeoff does not exist in the RPC function and reveal that the source noise plays a decisive role in the classification-perception tradeoff. Finally, we implement a deep-learning-based image compression framework, incorporating multiple tasks related to distortion, perception, and classification. The experimental results coincide with the theoretical analysis and verify the effectiveness of our generalized IB in balancing various task objectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04144v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuhan Wang, Youlong Wu, Shuai Ma, Ying-Jun Angela Zhang</dc:creator>
    </item>
    <item>
      <title>On the Coverage Required for Diploid Genome Assembly</title>
      <link>https://arxiv.org/abs/2405.05734</link>
      <description>arXiv:2405.05734v2 Announce Type: replace 
Abstract: Repeat content and heterozygosity rate of the target genome are crucial factors in determining the ability to generate a complete telomere-to-telomere assembly. The mathematical relationship between the required coverage and read length for the purpose of unique reconstruction remains unexplored for diploid genomes. We investigate the information-theoretic conditions that the given set of sequencing reads must satisfy to achieve the complete reconstruction of the true sequence of a diploid genome. We also analyze the standard greedy and de-Bruijn graph-based assembly algorithms. Our results show that the coverage and read length requirements of the assembly algorithms are considerably higher than the lower bound because both algorithms require the double repeats in the genome to be bridged. Finally, we derive the necessary conditions for the overlap graph-based assembly paradigm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.05734v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>q-bio.GN</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Daanish Mahajan, Chirag Jain, Navin Kashyap</dc:creator>
    </item>
    <item>
      <title>Region-Specific Coarse Quantization with Check Node Awareness in 5G-LDPC Decoding</title>
      <link>https://arxiv.org/abs/2406.14233</link>
      <description>arXiv:2406.14233v4 Announce Type: replace 
Abstract: This paper presents novel techniques for improving the error correction performance and reducing the complexity of coarsely quantized 5G-LDPC decoders. The proposed decoder design supports arbitrary message-passing schedules on a base-matrix level by modeling exchanged messages with entry-specific discrete random variables. Variable nodes (VNs) and check nodes (CNs) involve compression operations designed using the information bottleneck method to maximize preserved mutual information between code bits and quantized messages. We introduce alignment regions that assign the messages to groups with aligned reliability levels to decrease the number of individual design parameters. Group compositions with degree-specific separation of messages improve performance by up to 0.4 dB. Further, we generalize our recently proposed CN-aware quantizer design to irregular LDPC codes and layered schedules. The method optimizes the VN quantizer to maximize preserved mutual information at the output of the subsequent CN update, enhancing performance by up to 0.2 dB. A schedule optimization modifies the order of layer updates, reducing the average iteration count by up to 35%. We integrate all new techniques in a rate-compatible decoder design by extending the alignment regions along a rate-dimension. Our complexity analysis shows that 2-bit decoding can double the area efficiency over 4-bit decoding at comparable performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14233v4</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Philipp Mohr, Gerhard Bauch</dc:creator>
    </item>
    <item>
      <title>Memory-Assisted Quantized LDPC Decoding</title>
      <link>https://arxiv.org/abs/2408.07437</link>
      <description>arXiv:2408.07437v3 Announce Type: replace 
Abstract: We enhance coarsely quantized LDPC decoding by reusing computed check node messages from previous iterations. Typically, variable and check nodes update and replace old messages every iteration. We show that, under coarse quantization, discarding old messages entails a significant loss of mutual information. The loss is avoided with additional memory, improving performance by up to 0.23 dB. We optimize quantization with a modified information bottleneck algorithm that considers the statistics of old messages. A simple merge operation reduces memory requirements. Depending on channel conditions and code rate, memory assistance enables up to 32 % better area efficiency for 2-bit decoding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07437v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Philipp Mohr, Gerhard Bauch</dc:creator>
    </item>
    <item>
      <title>Multi-Source Approximate Message Passing with Random Semi-Unitary Dictionaries</title>
      <link>https://arxiv.org/abs/2410.13021</link>
      <description>arXiv:2410.13021v2 Announce Type: replace 
Abstract: Motivated by the recent interest in approximate message passing (AMP) for matrix-valued linear observations with superposition of \emph{multiple statistically asymmetric signal sources}, we introduce a multi-source AMP framework in which the dictionary matrices associated with each signal source are drawn from a \emph{random semi-unitary ensemble} (rather than the standard Gaussian matrix ensemble.) While a similar model has been explored by Vehkaper{\"a}, Kabashima, and Chatterjee (2016) using the replica method, here we present an AMP algorithm and provide a high-dimensional yet \emph{finite-sample} analysis. As a proof of concept, we show the effectiveness of the proposed approach on the problem of \emph{message detection and channel estimation} in an unsourced random access scenario in wireless communication.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13021v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Burak \c{C}akmak, Giuseppe Caire</dc:creator>
    </item>
    <item>
      <title>On the Weight Spectrum of Rate-Compatible Polar Codes</title>
      <link>https://arxiv.org/abs/2410.19242</link>
      <description>arXiv:2410.19242v2 Announce Type: replace 
Abstract: The weight spectrum plays a crucial role in the performance of error-correcting codes. Despite substantial theoretical exploration into polar codes with mother code length, a framework for the weight spectrum of rate-compatible polar codes remains elusive. In this paper, we address this gap by enumerating the number of minimum-weight codewords for quasi-uniform punctured, Wang-Liu shortened, and bit-reversal shortened polar codes. Additionally, we propose efficient algorithms for computing the average spectrum of random upper-triangular pre-transformed shortened and punctured polar codes. Notably, our algorithms operate with polynomial complexity relative to the code length. Simulation results affirm that our findings can substantially enhance the practical construction of rate-compatible polar codes, and leading to an improved weight spectrum.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19242v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zicheng Ye, Yuan Li, Zhichao Liu, Huazi Zhang, Jun Wang, Guiying Yan, Zhiming Ma</dc:creator>
    </item>
    <item>
      <title>Performance-Complexity-Latency Trade-offs of Concatenated RS-SDBCH Codes</title>
      <link>https://arxiv.org/abs/2411.08895</link>
      <description>arXiv:2411.08895v2 Announce Type: replace 
Abstract: Concatenated bit-interleaved and multilevel coded modulation with outer Reed--Solomon codes, inner Chase-algorithm-based soft-decision-decoded Bose--Ray-Chaudhuri--Hocquenghem codes, and four-level pulse amplitude modulation is considered. A semi-analytical formula is derived for estimating the decoded frame error rate (FER) at the output of the additive white Gaussian noise channel, obviating the need for time-consuming Monte Carlo simulations. The formula is used to search a large space of codes (including the KP4 code) to find those achieving good trade-offs among performance (measured by the gap to the constrained Shannon limit at $10^{-13}$ FER), complexity (measured by the number of elementary decoder operations), and latency (measured by overall block length).</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08895v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/JLT.2025.3530858</arxiv:DOI>
      <dc:creator>Alvin Y. Sukmadji, Frank R. Kschischang</dc:creator>
    </item>
    <item>
      <title>Structured Tensor Decomposition Based Channel Estimation and Double Refinements for Active RIS Empowered Broadband Systems</title>
      <link>https://arxiv.org/abs/2411.16420</link>
      <description>arXiv:2411.16420v2 Announce Type: replace 
Abstract: Channel parameter recovery is critical for the next-generation reconfigurable intelligent surface (RIS)-empowered communications and sensing. Tensor-based mechanisms are particularly effective, inherently capturing the multi-dimensional nature of wireless channels. However, existing studies assume either a line-of-sight (LOS) scenario or a blocked TX-RX channel. This paper solves a novel problem: tensor-based channel parameter estimation for active RIS-aided multiple-antenna broadband connections in fully multipath environments with the TX-RX link. System settings are customized to construct a fifth-order canonical polyadic (CP) signal tensor that matches the five-dimensional channel. Four tensor factors contain redundant columns, rendering the classical Kruskal's condition for decomposition uniqueness unsatisfied. The fifth-order Vandermonde structured CP decomposition (VSCPD) is developed to address this challenge, making the tensor factorization problem solvable using only linear algebra and offering a relaxed general uniqueness condition. With VSCPD as a perfect decoupling scheme, a sequential triple-stage channel estimation algorithm is proposed based on one-dimensional parameter estimation. The first stage enables multipath identification and algebraic coarse estimation. The following two stages offer optional successive refinements at the cost of increased complexity. The closed-form Cramer-Rao lower bound (CRLB) is derived to assess the estimation performance. Herein, the noise covariance matrix depends on multipath parameters in our active-RIS scenario. Numerical results are provided to verify the effectiveness of proposed algorithms under various evaluation metrics. Our results also show that active RIS can significantly improve channel estimation performance compared to passive RIS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16420v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yirun Wang, Yongqing Wang, Yuyao Shen, Gongpu Wang, Chintha Tellambura</dc:creator>
    </item>
    <item>
      <title>What should a neuron aim for? Designing local objective functions based on information theory</title>
      <link>https://arxiv.org/abs/2412.02482</link>
      <description>arXiv:2412.02482v3 Announce Type: replace 
Abstract: In modern deep neural networks, the learning dynamics of the individual neurons is often obscure, as the networks are trained via global optimization. Conversely, biological systems build on self-organized, local learning, achieving robustness and efficiency with limited global information. We here show how self-organization between individual artificial neurons can be achieved by designing abstract bio-inspired local learning goals. These goals are parameterized using a recent extension of information theory, Partial Information Decomposition (PID), which decomposes the information that a set of information sources holds about an outcome into unique, redundant and synergistic contributions. Our framework enables neurons to locally shape the integration of information from various input classes, i.e. feedforward, feedback, and lateral, by selecting which of the three inputs should contribute uniquely, redundantly or synergistically to the output. This selection is expressed as a weighted sum of PID terms, which, for a given problem, can be directly derived from intuitive reasoning or via numerical optimization, offering a window into understanding task-relevant local information processing. Achieving neuron-level interpretability while enabling strong performance using local learning, our work advances a principled information-theoretic foundation for local learning strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02482v3</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andreas C. Schneider, Valentin Neuhaus, David A. Ehrlich, Abdullah Makkeh, Alexander S. Ecker, Viola Priesemann, Michael Wibral</dc:creator>
    </item>
    <item>
      <title>Sequence Reconstruction for the Single-Deletion Single-Substitution Channel</title>
      <link>https://arxiv.org/abs/2501.03833</link>
      <description>arXiv:2501.03833v2 Announce Type: replace 
Abstract: The central problem in sequence reconstruction is to find the minimum number of distinct channel outputs required to uniquely reconstruct the transmitted sequence. According to Levenshtein's work in 2001, this number is determined by the size of the maximum intersection between the error balls of any two distinct input sequences of the channel. In this work, we study the sequence reconstruction problem for single-deletion single-substitution channel, assuming that the transmitted sequence belongs to a $q$-ary code with minimum Hamming distance at least $2$, where $q\geq 2$ is any fixed integer. Specifically, we prove that for any two $q$-ary sequences of length $n$ and with Hamming distance $d\geq 2$, the size of the intersection of their error balls is upper bounded by $2qn-3q-2-\delta_{q,2}$, where $\delta_{i,j}$ is the Kronecker delta. We also prove the tightness of this bound by constructing two sequences the intersection size of whose error balls achieves this bound.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03833v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Wentu Song, Kui Cai, Tony Q. S. Quek</dc:creator>
    </item>
    <item>
      <title>Differential Properties of Information in Jump-diffusion Channels</title>
      <link>https://arxiv.org/abs/2501.05708</link>
      <description>arXiv:2501.05708v2 Announce Type: replace 
Abstract: We propose a channel modeling using jump-diffusion processes, and study the differential properties of entropy and mutual information. By utilizing the Kramers-Moyal and Kolmogorov-Feller equations, we express the mutual information between the input and the output in series and integral forms, presented by Fisher-type information and mismatched KL divergence. We extend de Bruijn's identity and the I-MMSE relation to encompass general Markov processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.05708v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luyao Fan, Jiayang Zou, Jia Wang</dc:creator>
    </item>
    <item>
      <title>Beyond Diagonal Reconfigurable Intelligent Surfaces in Wideband OFDM Communications: Circuit-Based Modeling and Optimization</title>
      <link>https://arxiv.org/abs/2405.07297</link>
      <description>arXiv:2405.07297v2 Announce Type: replace-cross 
Abstract: This work investigates the modeling and optimization of beyond diagonal reconfigurable intelligent surface (BD-RIS), which generalizes conventional RIS with diagonal phase shift matrices and provides additional flexibility for manipulating wireless channels, in wideband communication systems. Specifically, we start from the signal modeling of the BD-RIS-aided orthogonal frequency division multiplexing (OFDM) system, which bridges the time-domain and frequency-domain channels, and explicitly shows the frequency dependence of the BD-RIS response. We next characterize the frequency dependence of the BD-RIS response based on circuit models. Benefiting from the admittance parameter analysis, we model individually each tunable admittance component of BD-RIS and derive an approximated linear expression with respect to the frequency of the transmit signals. With the proposed signal model for the BD-RIS-aided OFDM system and the frequency-dependent BD-RIS model, we propose algorithms to optimize the BD-RIS and the power allocation at the transmitter to maximize the average rate for a BD-RIS-aided OFDM system. Finally, simulation results show that BD-RIS outperforms conventional RIS in the OFDM system. More importantly, the impact of wideband modeling of BD-RIS on the system performance becomes more significant as the circuit complexity of BD-RIS architectures increases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07297v2</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hongyu Li, Matteo Nerini, Shanpu Shen, Bruno Clerckx</dc:creator>
    </item>
    <item>
      <title>Information-driven design of imaging systems</title>
      <link>https://arxiv.org/abs/2405.20559</link>
      <description>arXiv:2405.20559v3 Announce Type: replace-cross 
Abstract: Most modern imaging systems process the data they capture computationally, either to make the measurement more interpretable for human viewing or to analyze it without a human in the loop. As a result, what matters is not how measurements appear visually, but how much information they contain. Information theory provides mathematical tools to quantify this; however, it has found limited use in imaging system design due to the challenge of developing methods that can handle the complexity of real-world measurements yet remain practical enough for widespread use. We introduce a data-driven approach for estimating the information content of imaging system measurements in order to evaluate system performance and optimize designs. Our framework requires only a dataset of experimental measurements and a means for noise characterization, enabling its use in real systems without ground truth data. We validate that these information estimates reliably predict system performance across diverse imaging modalities, including color photography, radio astronomy, lensless imaging, and label-free microscopy. We further introduce an optimization technique called Information-Driven Encoder Analysis Learning (IDEAL) for designing imaging systems that maximize information capture. This work unlocks information theory as a powerful, practical tool for analyzing and designing imaging systems across a broad range of applications.
  A video summarizing this work can be found at https://waller-lab.github.io/EncodingInformationWebsite/</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20559v3</guid>
      <category>physics.optics</category>
      <category>cs.CV</category>
      <category>cs.IT</category>
      <category>eess.IV</category>
      <category>math.IT</category>
      <category>physics.data-an</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Henry Pinkard, Leyla Kabuli, Eric Markley, Tiffany Chien, Jiantao Jiao, Laura Waller</dc:creator>
    </item>
    <item>
      <title>Rydberg Atomic Quantum Receivers for Classical Wireless Communication and Sensing</title>
      <link>https://arxiv.org/abs/2409.14501</link>
      <description>arXiv:2409.14501v2 Announce Type: replace-cross 
Abstract: The Rydberg atomic quantum receivers (RAQR) are emerging quantum precision sensing platforms designed for receiving radio frequency (RF) signals. It relies on creation of Rydberg atoms from normal atoms by exciting one or more electrons to a very high energy level, thereby making the atom sensitive to RF signals. RAQRs realize RF-to-optical conversions based on light-atom interactions relying on the so called electromagnetically induced transparency (EIT) and Aulter-Townes splitting (ATS), so that the desired RF signal can be read out optically. The large dipole moments of Rydberg atoms associated with rich choices of Rydberg states and various modulation schemes facilitate an ultra-high sensitivity ($\sim$ nV/cm/$\sqrt{\text{Hz}}$) and an ultra-broadband tunability (direct-current to Terahertz). RAQRs also exhibit compelling scalability and lend themselves to the construction of innovative, compact receivers. Initial experimental studies have demonstrated their capabilities in classical wireless communications and sensing. To fully harness their potential in a wide variety of applications, we commence by outlining the underlying fundamentals of Rydberg atoms, followed by the principles and schemes of RAQRs. Then, we overview the state-of-the-art studies from both physics and communication societies. Furthermore, we conceive Rydberg atomic quantum single-input single-output (RAQ-SISO) and multiple-input multiple-output (RAQ-MIMO) schemes for facilitating the integration of RAQRs with classical wireless systems. Finally, we conclude with a set of potent research directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.14501v2</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>quant-ph</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tierui Gong, Aveek Chandra, Chau Yuen, Yong Liang Guan, Rainer Dumke, Chong Meng Samson See, M\'erouane Debbah, Lajos Hanzo</dc:creator>
    </item>
    <item>
      <title>Eavesdropping on Goal-Oriented Communication: Timing Attacks and Countermeasures</title>
      <link>https://arxiv.org/abs/2411.07088</link>
      <description>arXiv:2411.07088v2 Announce Type: replace-cross 
Abstract: Goal-oriented communication is a new paradigm that considers the meaning of transmitted information to optimize communication. One possible application is the remote monitoring of a process under communication costs: scheduling updates based on goal-oriented considerations can significantly reduce transmission frequency while maintaining high-quality tracking performance. However, goal-oriented scheduling also opens a timing-based side-channel that an eavesdropper may exploit to obtain information about the state of the remote process, even if the content of updates is perfectly secure. In this work, we study an eavesdropping attack against pull-based goal-oriented scheduling for the tracking of remote Markov processes. We provide a theoretical framework for defining the effectiveness of the attack and of possible countermeasures, as well as a practical heuristic that can provide a balance between the performance gains offered by goal-oriented communication and the information leakage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07088v2</guid>
      <category>eess.SY</category>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Federico Mason, Federico Chiariotti, Pietro Talli, Andrea Zanella</dc:creator>
    </item>
    <item>
      <title>Empirical Coordination of Separable Quantum Correlations</title>
      <link>https://arxiv.org/abs/2412.17119</link>
      <description>arXiv:2412.17119v2 Announce Type: replace-cross 
Abstract: We introduce the notion of empirical coordination for quantum correlations. Quantum mechanics enables the calculation of probabilities for experimental outcomes, emphasizing statistical averages rather than detailed descriptions of individual events. Empirical coordination is thus a natural framework for quantum systems. Focusing on the cascade network, the optimal coordination rates are established, indicating the minimal resources required to simulate on average a quantum state. As we consider a network with classical communication links, superposition cannot be maintained, hence the quantum correlations are separable (i.e., a convex combination of product states). This precludes entanglement. Providing the users with shared randomness, before communication begins, does not affect the optimal rates for empirical coordination. We begin with a rate characterization for a basic two-node network, and then generalize to a cascade network. The special case of a network with an isolated node is considered as well. The results can be further generalized to other networks as our analysis includes a generic achievability scheme. The optimal rate formula involves optimization over a collection of state extensions. This is a unique feature of the quantum setting, as the classical parallel does not include optimization. As demonstrated through examples, the performance depends heavily on the choice of decomposition. We further discuss the consequences of our results for quantum cooperative games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17119v2</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Husein Natur, Uzi Pereg</dc:creator>
    </item>
    <item>
      <title>Sequential Portfolio Selection under Latent Side Information-Dependence Structure: Optimality and Universal Learning Algorithms</title>
      <link>https://arxiv.org/abs/2501.06701</link>
      <description>arXiv:2501.06701v2 Announce Type: replace-cross 
Abstract: This paper investigates the investment problem of constructing an optimal no-short sequential portfolio strategy in a market with a latent dependence structure between asset prices and partly unobservable side information, which is often high-dimensional. The results demonstrate that a dynamic strategy, which forms a portfolio based on perfect knowledge of the dependence structure and full market information over time, may not grow at a higher rate infinitely often than a constant strategy, which remains invariant over time. Specifically, if the market is stationary, implying that the dependence structure is statistically stable, the growth rate of an optimal dynamic strategy, utilizing the maximum capacity of the entire market information, almost surely decays over time into an equilibrium state, asymptotically converging to the growth rate of a constant strategy.
  Technically, this work reassesses the common belief that a constant strategy only attains the optimal limiting growth rate of dynamic strategies when the market process is identically and independently distributed. By analyzing the dynamic log-optimal portfolio strategy as the optimal benchmark in a stationary market with side information, we show that a random optimal constant strategy almost surely exists, even when a limiting growth rate for the dynamic strategy does not. Consequently, two approaches to learning algorithms for portfolio construction are discussed, demonstrating the safety of removing side information from the learning process while still guaranteeing an asymptotic growth rate comparable to that of the optimal dynamic strategy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.06701v2</guid>
      <category>q-fin.MF</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <category>q-fin.PM</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Duy Khanh Lam</dc:creator>
    </item>
  </channel>
</rss>
