<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.LO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.LO</link>
    <description>cs.LO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.LO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 15 Jan 2026 05:00:28 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Query Languages for Machine-Learning Models</title>
      <link>https://arxiv.org/abs/2601.09381</link>
      <description>arXiv:2601.09381v1 Announce Type: new 
Abstract: In this paper, I discuss two logics for weighted finite structures: first-order logic with summation (FO(SUM)) and its recursive extension IFP(SUM). These logics originate from foundational work by Gr\"adel, Gurevich, and Meer in the 1990s. In recent joint work with Standke, Steegmans, and Van den Bussche, we have investigated these logics as query languages for machine learning models, specifically neural networks, which are naturally represented as weighted graphs. I present illustrative examples of queries to neural networks that can be expressed in these logics and discuss fundamental results on their expressiveness and computational complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09381v1</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <category>cs.DB</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martin Grohe</dc:creator>
    </item>
    <item>
      <title>Lower Bounds in Algebraic Complexity via Symmetry and Homomorphism Polynomials</title>
      <link>https://arxiv.org/abs/2601.09343</link>
      <description>arXiv:2601.09343v1 Announce Type: cross 
Abstract: Valiant's conjecture asserts that the circuit complexity classes VP and VNP are distinct, meaning that the permanent does not admit polynomial-size algebraic circuits. As it is the case in many branches of complexity theory, the unconditional separation of these complexity classes seems elusive. In stark contrast, the symmetric analogue of Valiant's conjecture has been proven by Dawar and Wilsenach (2020): the permanent does not admit symmetric algebraic circuits of polynomial size, while the determinant does. Symmetric algebraic circuits are both a powerful computational model and amenable to proving unconditional lower bounds.
  In this paper, we develop a symmetric algebraic complexity theory by introducing symmetric analogues of the complexity classes VP, VBP, and VF called symVP, symVBP, and symVF. They comprise polynomials that admit symmetric algebraic circuits, skew circuits, and formulas, respectively, of polynomial orbit size. Having defined these classes, we show unconditionally that $\mathsf{symVF} \subsetneq \mathsf{symVBP} \subsetneq \mathsf{symVP}$. To that end, we characterise the polynomials in symVF and symVBP as those that can be written as linear combinations of homomorphism polynomials for patterns of bounded treedepth and pathwidth, respectively. This extends a previous characterisation by Dawar, Pago, and Seppelt (2026) of symVP.
  Finally, we show that symVBP and symVP contain homomorphism polynomials which are VBP- and VP-complete, respectively. We give general graph-theoretic criteria for homomorphism polynomials and their linear combinations to be VBP-, VP-, or VNP-complete. These conditional lower bounds drastically enlarge the realm of natural polynomials known to be complete for VNP, VP, or VBP. Under the assumption VFPT $\neq$ VW[1], we precisely identify the homomorphism polynomials that lie in VP as those whose patterns have bounded treewidth.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09343v1</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.LO</category>
      <category>math.GR</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Prateek Dwivedi, Benedikt Pago, Tim Seppelt</dc:creator>
    </item>
    <item>
      <title>On Numbers of Simplicial Walks and Equivalent Canonizations for Graph Recognition</title>
      <link>https://arxiv.org/abs/2601.09506</link>
      <description>arXiv:2601.09506v1 Announce Type: cross 
Abstract: Two graphs are isomorphic exactly when they admit the same number of homomorphisms from every graph. Hence, a graph is recognized up to isomorphism by homomorphism counts over the class of all graphs. Restricting to a specific graph class yields some natural isomorphism relaxations and modulates recognition to particular graph properties. A notable restriction is to the classes of bounded treewidth, yielding the isomorphism relaxation of Weisfeiler--Leman refinement (WL), as shown by Dvo\v{r}\'{a}k [JGT 2010]. The properties recognized by WL are exactly those definable in fragments of first-order logic with counting quantifiers, as shown by Cai, F\"{u}rer, and Immerman [Comb. 1992].
  We characterize the restriction to the classes of bounded pathwidth by numbers of simplicial walks, and formalize it into a refinement procedure (SW). The properties recognized by SW are exactly those definable in fragments of restricted-conjunction first-order logic with counting quantifiers, introduced by Montacute and Shah [LMCS 2024].
  Unlike WL, computing SW directly is not polynomial-time in general. We address this by representing SW in terms of multiplicity automata. We equip these automata with an involution, simplifying the canonization to standard forward reduction and omitting the backward one. The resulting canonical form is computable in time $O(kn^{3k})$ for any graph on $n$ vertices and the restriction to pathwidth at most $k$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09506v1</guid>
      <category>cs.DM</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>cs.LO</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marek \v{C}ern\'y</dc:creator>
    </item>
    <item>
      <title>Expressivity of AuDaLa: Turing Completeness and Possible Extensions</title>
      <link>https://arxiv.org/abs/2412.14938</link>
      <description>arXiv:2412.14938v4 Announce Type: replace 
Abstract: AuDaLa is a recently introduced programming language that follows the new data autonomous paradigm. In this paradigm, small pieces of data execute functions autonomously. Considering the paradigm and the design choices of AuDaLa, it is interesting to determine the expressivity of the language. In this paper, we implement Turing machines in AuDaLa and prove that implementation correct. This proves that AuDaLa is Turing complete, giving an initial indication of AuDaLa's expressivity. Additionally, we give examples of how to add extensions to AuDaLa to increase its practical expressivity and to better match conventional parallel languages, allowing for a more straightforward and performant implementation of algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.14938v4</guid>
      <category>cs.LO</category>
      <category>cs.PL</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tom T. P. Franken, Thomas Neele</dc:creator>
    </item>
    <item>
      <title>A No-go Theorem for Coalgebraic Product Construction</title>
      <link>https://arxiv.org/abs/2504.06592</link>
      <description>arXiv:2504.06592v3 Announce Type: replace 
Abstract: Verifying traces of systems is a central topic in formal verification. We study model checking of Markov chains (MCs) against temporal properties represented as (finite) automata. For instance, given an MC and a deterministic finite automaton (DFA), a simple but practically useful model checking problem asks for the probability of (terminating) traces on the MC that are accepted by the DFA. A standard approach to solving this problem constructs a product MC of the given MC and DFA, reducing the task to a simple reachability probability problem on the resulting product MC.
  In this paper, on top of our recent development of coalgebraic framework, we first present a no-go theorem for product constructions, showing a case when we cannot do product constructions for model checking. Specifically, we show that there are no coalgebraic product MCs of MCs and nondeterministic finite automata for computing the probability of the accepting traces. This no-go theorem is established via a characterisation of natural transformations between certain functors that determine the type of branching, including nondeterministic or probabilistic branching.
  Second, we present a coalgebraic product construction of MCs and multiset finite automata (MFAs) as a new instance within our framework. This construction addresses a model checking problem that asks for the expected number of accepting runs on MFAs over traces of MCs. The problem is reduced to solving linear equations, which is solvable in polynomial-time under a reasonable assumption that ensures the finiteness of the solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06592v3</guid>
      <category>cs.LO</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mayuko Kori, Kazuki Watanabe</dc:creator>
    </item>
    <item>
      <title>An Elementary Proof of the FMP for Kleene Algebra</title>
      <link>https://arxiv.org/abs/2212.10931</link>
      <description>arXiv:2212.10931v4 Announce Type: replace-cross 
Abstract: Kleene Algebra (KA) is a useful tool for proving that two programs are equivalent. Because KA's equational theory is decidable, it integrates well with interactive theorem provers. This raises the question: which equations can we (not) prove using the laws of KA? Moreover, which models of KA are complete, in the sense that they satisfy exactly the provable equations? Kozen (1994) answered these questions by characterizing KA in terms of its language model. Concretely, equivalences provable in KA are exactly those that hold for regular expressions.
  Pratt (1980) observed that KA is complete w.r.t. relational models, i.e., that its provable equations are those that hold for any relational interpretation. A less known result due to Palka (2005) says that finite models are complete for KA, i.e., that provable equivalences coincide with equations satisfied by all finite KAs. Phrased contrapositively, the latter is a finite model property (FMP): any unprovable equation is falsified by a finite KA. Both results can be argued using Kozen's theorem, but the implication is mutual: given that KA is complete w.r.t. finite (resp. relational) models, Palka's (resp. Pratt's) arguments show that it is complete w.r.t. the language model.
  We embark on a study of the different complete models of KA, and the connections between them. This yields a novel result subsuming those of Palka and Pratt, namely that KA is complete w.r.t. finite relational models. Next, we put an algebraic spin on Palka's techniques, which yield a new elementary proof of the finite model property, and by extension, of Kozen's and Pratt's theorems. In contrast with earlier approaches, this proof relies not on minimality or bisimilarity of automata, but rather on representing the regular expressions involved in terms of transformation automata.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.10931v4</guid>
      <category>cs.FL</category>
      <category>cs.LO</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tobias Kapp\'e</dc:creator>
    </item>
    <item>
      <title>Forward Symbolic Execution for Trustworthy Automation of Binary Code Verification</title>
      <link>https://arxiv.org/abs/2304.08848</link>
      <description>arXiv:2304.08848v2 Announce Type: replace-cross 
Abstract: Control flow in unstructured programs can be complex and dynamic, which makes static analysis difficult. Yet, automated reasoning about unstructured control flow is important when certifying properties of binary (machine) code in trustworthy systems, e.g., cryptographic routines. We present a theory of forward symbolic execution for unstructured programs suitable for use in theorem provers that enables automated verification of both functional and non-functional program properties. The theory's foundation is a set of inference rules where each member corresponds to an operation in a symbolic execution engine. The rules are designed to give control over the tradeoff between the preservation of precision and introduction of overapproximation. We instantiate our theory for BIR, a previously proposed intermediate language for binary analysis. We demonstrate how symbolic executors can be constructed for BIR with common optimizations such as pruning of infeasible symbolic states. We implemented our theory in the HOL4 theorem prover using the HolBA binary analysis library, obtaining machine-checked proofs of soundness of symbolic execution for BIR. We practically evaluated two applications of our theory: verification of functional properties of RISC-V binaries and verification of execution time bounds of programs running on the ARM Cortex-M0 processor. The evaluation shows that such verification can be automated with moderate overhead on medium-sized programs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.08848v2</guid>
      <category>cs.PL</category>
      <category>cs.CR</category>
      <category>cs.LO</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-032-15700-3_8</arxiv:DOI>
      <dc:creator>Andreas Lindner, Karl Palmskog, Scott Constable, Mads Dam, Roberto Guanciale, Hamed Nemati</dc:creator>
    </item>
    <item>
      <title>Path-optimal symbolic execution of heap-manipulating programs</title>
      <link>https://arxiv.org/abs/2407.16827</link>
      <description>arXiv:2407.16827v2 Announce Type: replace-cross 
Abstract: Symbolic execution is at the core of many techniques for program analysis and test generation. Traditional symbolic execution of programs with numeric inputs enjoys the property of forking as many analysis traces as the number of analyzed program paths, a property that in this paper we refer to as path optimality. On the contrary, current approaches for symbolic execution of heap-manipulating programs fail to satisfy this property, thereby incurring crucial path explosion effects. This paper introduces POSE, path-optimal symbolic execution, a symbolic execution algorithm that originally achieves path optimality against heap-manipulating programs. We formalize the POSE algorithm and experiment it against a benchmark of programs that take data structures as inputs, supporting the potential of POSE for improving on the state of the art of symbolic execution of heap-manipulating programs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16827v2</guid>
      <category>cs.SE</category>
      <category>cs.LO</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Pietro Braione, Giovanni Denaro, Luca Guglielmo</dc:creator>
    </item>
    <item>
      <title>Epistemic Skills: Reasoning about Knowledge and Oblivion</title>
      <link>https://arxiv.org/abs/2504.01733</link>
      <description>arXiv:2504.01733v3 Announce Type: replace-cross 
Abstract: This paper presents a class of epistemic logics that captures the dynamics of acquiring knowledge and descending into oblivion, while incorporating concepts of group knowledge. The approach is grounded in a system of weighted models, introducing an ``epistemic skills'' metric to represent the epistemic capacities tied to knowledge updates. Within this framework, knowledge acquisition is modeled as a process of upskilling, whereas oblivion is represented as a consequence of downskilling. The framework further enables exploration of ``knowability'' and ``forgettability,'' defined as the potential to gain knowledge through upskilling and to lapse into oblivion through downskilling, respectively. Additionally, it supports a detailed analysis of the distinctions between epistemic de re and de dicto expressions. The computational complexity of the model checking and satisfiability problems is examined, offering insights into their theoretical foundations and practical implications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01733v3</guid>
      <category>cs.AI</category>
      <category>cs.CC</category>
      <category>cs.LO</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaolong Liang, Y\`i N. W\'ang</dc:creator>
    </item>
  </channel>
</rss>
