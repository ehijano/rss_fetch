<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.data-an updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.data-an</link>
    <description>physics.data-an updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.data-an" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 20 Mar 2025 04:01:05 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Maximum likelihood estimation of burst-merging kernels for bursty time series</title>
      <link>https://arxiv.org/abs/2503.14861</link>
      <description>arXiv:2503.14861v1 Announce Type: new 
Abstract: Various time series in natural and social processes have been found to be bursty. Events in the time series rapidly occur within short time periods, forming bursts, which are alternated with long inactive periods. As the timescale defining bursts increases, individual events are sequentially merged to become small bursts and then bigger ones, eventually leading to the single burst containing all events. Such a merging pattern has been depicted by a tree that fully reveals the hierarchical structure of bursts, thus called a burst tree. The burst-tree structure can be simply characterized by a burst-merging kernel that dictates which bursts are merged together as the timescale increases. In this work, we develop the maximum likelihood estimation method of the burst-merging kernel from time series, which is successfully tested against the time series generated using several model kernels. We also apply our method to some empirical time series from various backgrounds. Our method provides a useful tool to precisely characterize the time series data, hence enabling to study their underlying mechanisms more accurately.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14861v1</guid>
      <category>physics.data-an</category>
      <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tibebe Birhanu, Hang-Hyun Jo</dc:creator>
    </item>
    <item>
      <title>Gaussian Processes enabled model calibration in the context of deep geological disposal</title>
      <link>https://arxiv.org/abs/2409.02576</link>
      <description>arXiv:2409.02576v3 Announce Type: replace-cross 
Abstract: Deep geological repositories are critical for the long-term storage of hazardous materials, where understanding the mechanical behavior of emplacement drifts is essential for safety assurance. This study presents a surrogate modeling approach for the mechanical response of emplacement drifts in rock salt formations, utilizing Gaussian Processes (GPs). The surrogate model serves as an efficient substitute for high-fidelity mechanical simulations in many-query scenarios, including time-dependent sensitivity analyses and calibration tasks. By significantly reducing computational demands, this approach facilitates faster design iterations and enhances the interpretation of monitoring data. The findings indicate that only a few key parameters are sufficient to accurately reflect in-situ conditions in complex rock salt models. Identifying these parameters is crucial for ensuring the reliability and safety of deep geological disposal systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02576v3</guid>
      <category>physics.geo-ph</category>
      <category>physics.data-an</category>
      <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lennart Paul, Jorge-Humberto Urrea-Quintero, Umer Fiaz, Ali Hussein, Hazem Yaghi, Henning Wessels, Ulrich R\"omer, Joachim Stahlmann</dc:creator>
    </item>
    <item>
      <title>DeepExtractor: Time-domain reconstruction of signals and glitches in gravitational wave data with deep learning</title>
      <link>https://arxiv.org/abs/2501.18423</link>
      <description>arXiv:2501.18423v2 Announce Type: replace-cross 
Abstract: Gravitational wave (GW) interferometers, detect faint signals from distant astrophysical events, such as binary black hole mergers. However, their high sensitivity also makes them susceptible to background noise, which can obscure these signals. This noise often includes transient artifacts called "glitches" that can mimic astrophysical signals or mask their characteristics. Fast and accurate reconstruction of both signals and glitches is crucial for reliable scientific inference. In this study, we present DeepExtractor, a deep learning framework designed to reconstruct signals and glitches with power exceeding interferometer noise, regardless of their source. We design DeepExtractor to model the inherent noise distribution of GW interferometers, following conventional assumptions that the noise is Gaussian and stationary over short time scales. It operates by predicting and subtracting the noise component of the data, retaining only the clean reconstruction. Our approach achieves superior generalization capabilities for arbitrary signals and glitches compared to methods that directly map inputs to the clean training waveforms. We validate DeepExtractor's effectiveness through three experiments: (1) reconstructing simulated glitches injected into simulated detector noise, (2) comparing performance with the state-of-the-art BayesWave algorithm, and (3) analyzing real data from the Gravity Spy dataset to demonstrate effective glitch subtraction from LIGO strain data. DeepExtractor achieves a median mismatch of only 0.9% for simulated glitches, outperforming several deep learning baselines. Additionally, DeepExtractor surpasses BayesWave in glitch recovery, offering a dramatic computational speedup by reconstructing one glitch sample in approx. 0.1 seconds on a CPU, compared to BayesWave's processing time of approx. one hour per glitch.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18423v2</guid>
      <category>gr-qc</category>
      <category>astro-ph.IM</category>
      <category>cs.LG</category>
      <category>physics.data-an</category>
      <category>physics.ins-det</category>
      <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tom Dooney, Harsh Narola, Stefano Bromuri, R. Lyana Curier, Chris Van Den Broeck, Sarah Caudill, Daniel Stanley Tan</dc:creator>
    </item>
  </channel>
</rss>
