<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CY updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CY</link>
    <description>cs.CY updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CY" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 24 Jul 2024 01:40:37 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 23 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Informational Health --Toward the Reduction of Risks in the Information Space</title>
      <link>https://arxiv.org/abs/2407.14634</link>
      <description>arXiv:2407.14634v1 Announce Type: new 
Abstract: The modern information society, markedly influenced by the advent of the internet and subsequent developments such as WEB 2.0, has seen an explosive increase in information availability, fundamentally altering human interaction with information spaces. This transformation has facilitated not only unprecedented access to information but has also raised significant challenges, particularly highlighted by the spread of ``fake news'' during critical events like the 2016 U.S. presidential election and the COVID-19 pandemic. The latter event underscored the dangers of an ``infodemic,'' where the large amount of information made distinguishing between factual and non-factual content difficult, thereby complicating public health responses and posing risks to democratic processes. In response to these challenges, this paper introduces the concept of ``informational health,'' drawing an analogy between dietary habits and information consumption. It argues that just as balanced diets are crucial for physical health, well-considered nformation behavior is essential for maintaining a healthy information environment. This paper proposes three strategies for fostering informational health: literacy education, visualization of meta-information, and informational health assessments. These strategies aim to empower users and platforms to navigate and enhance the information ecosystem effectively. By focusing on long-term informational well-being, we highlight the necessity of addressing the social risks inherent in the current attention economy, advocating for a paradigm shift towards a more sustainable information consumption model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14634v1</guid>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fujio Toriumi, Tatsuhiko Yamamoto</dc:creator>
    </item>
    <item>
      <title>Auditing the Grid-Based Placement of Private Label Products on E-commerce Search Result Pages</title>
      <link>https://arxiv.org/abs/2407.14650</link>
      <description>arXiv:2407.14650v1 Announce Type: new 
Abstract: E-commerce platforms support the needs and livelihoods of their two most important stakeholders -- customers and producers/sellers. Multiple algorithmic systems, like ``search'' systems mediate the interactions between these stakeholders by connecting customers to producers with relevant items. Search results include (i) private label (PL) products that are manufactured/sold by the platform itself, as well as (ii) third-party products on advertised / sponsored and organic positions. In this paper, we systematically quantify the extent of PL product promotion on e-commerce search results for the two largest e-commerce platforms operating in India -- Amazon.in and Flipkart. By analyzing snapshots of search results across the two platforms, we discover high PL promotion on the initial result pages (~ 15% PLs are advertised on the first SERP of Amazon). Both platforms use different strategies to promote their PL products, such as placing more PLs on the advertised positions -- while Amazon places them on the first, middle, and last rows of the search results, Flipkart places them on the first two positions and the (entire) last column of the search results. We discover that these product placement strategies of both platforms conform with existing user attention strategies proposed in the literature. Finally, to supplement the findings from the collected data, we conduct a survey among 68 participants on Amazon Mechanical Turk. The click pattern from our survey shows that users strongly prefer to click on products placed at positions that correspond to the PL products on the search results of Amazon, but not so strongly on Flipkart. The click-through rate follows previously proposed theoretically grounded user attention distribution patterns in a two-dimensional layout.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14650v1</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <category>cs.IR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Siddharth D Jaiswal, Abhisek Dash, Nitika Shroff, Yashwanth Babu Vunnam, Saptarshi Ghosh, Animesh Mukherjee</dc:creator>
    </item>
    <item>
      <title>Large-Area Emergency Lockdowns with Automated Driving Systems</title>
      <link>https://arxiv.org/abs/2407.14683</link>
      <description>arXiv:2407.14683v1 Announce Type: new 
Abstract: Region-wide restrictions on personal vehicle travel have a long history in the United States, from riot curfews in the late 1960s, to travel bans during snow events, to the 2013 shelter-in-place "lockdown" during the search for the perpetrator of the Boston Marathon bombing. Because lockdowns require tremendous resources to enforce, they are often limited in duration or scope. The introduction of automated driving systems may allow governments to quickly and cheaply effect large-area lockdowns by jamming wireless communications, spoofing road closures on digital maps, exploiting a vehicle's programming to obey all traffic control devices, or coordinating with vehicle developers. Future vehicles may lack conventional controls, rendering them undrivable by the public. As travel restrictions become easier to implement, governments may enforce them more frequently, over longer durations and wider areas. This article explores the practical, legal, and ethical implications of lockdowns when most driving is highly automated, and provides guidance for the development of lockdown policies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14683v1</guid>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Noah Goodall</dc:creator>
    </item>
    <item>
      <title>Do Generative AI Models Output Harm while Representing Non-Western Cultures: Evidence from A Community-Centered Approach</title>
      <link>https://arxiv.org/abs/2407.14779</link>
      <description>arXiv:2407.14779v1 Announce Type: new 
Abstract: Our research investigates the impact of Generative Artificial Intelligence (GAI) models, specifically text-to-image generators (T2Is), on the representation of non-Western cultures, with a focus on Indian contexts. Despite the transformative potential of T2Is in content creation, concerns have arisen regarding biases that may lead to misrepresentations and marginalizations. Through a community-centered approach and grounded theory analysis of 5 focus groups from diverse Indian subcultures, we explore how T2I outputs to English prompts depict Indian culture and its subcultures, uncovering novel representational harms such as exoticism and cultural misappropriation. These findings highlight the urgent need for inclusive and culturally sensitive T2I systems. We propose design guidelines informed by a sociotechnical perspective, aiming to address these issues and contribute to the development of more equitable and representative GAI technologies globally. Our work also underscores the necessity of adopting a community-centered approach to comprehend the sociotechnical dynamics of these models, complementing existing work in this space while identifying and addressing the potential negative repercussions and harms that may arise when these models are deployed on a global scale.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14779v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Sourojit Ghosh, Pranav Narayanan Venkit, Sanjana Gautam, Shomir Wilson, Aylin Caliskan</dc:creator>
    </item>
    <item>
      <title>Political Leanings in Web3 Betting: Decoding the Interplay of Political and Profitable Motives</title>
      <link>https://arxiv.org/abs/2407.14844</link>
      <description>arXiv:2407.14844v1 Announce Type: new 
Abstract: Harnessing the transparent blockchain user behavior data, we construct the Political Betting Leaning Score (PBLS) to measure political leanings based on betting within Web3 prediction markets. Focusing on Polymarket and starting from the 2024 U.S. Presidential Election, we synthesize behaviors over 15,000 addresses across 4,500 events and 8,500 markets, capturing the intensity and direction of their political leanings by the PBLS. We validate the PBLS through internal consistency checks and external comparisons. We uncover relationships between our PBLS and betting behaviors through over 800 features capturing various behavioral aspects. A case study of the 2022 U.S. Senate election further demonstrates the ability of our measurement while decoding the dynamic interaction between political and profitable motives. Our findings contribute to understanding decision-making in decentralized markets, enhancing the analysis of behaviors within Web3 prediction environments. The insights of this study reveal the potential of blockchain in enabling innovative, multidisciplinary studies and could inform the development of more effective online prediction markets, improve the accuracy of forecast, and help the design and optimization of platform mechanisms. The data and code for the paper are accessible at the following link: https://github.com/anonymous.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14844v1</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <category>cs.SI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongzhou Chen, Xiaolin Duan, Abdulmotaleb El Saddik, Wei Cai</dc:creator>
    </item>
    <item>
      <title>Open Problems in Technical AI Governance</title>
      <link>https://arxiv.org/abs/2407.14981</link>
      <description>arXiv:2407.14981v1 Announce Type: new 
Abstract: AI progress is creating a growing range of risks and opportunities, but it is often unclear how they should be navigated. In many cases, the barriers and uncertainties faced are at least partly technical. Technical AI governance, referring to technical analysis and tools for supporting the effective governance of AI, seeks to address such challenges. It can help to (a) identify areas where intervention is needed, (b) identify and assess the efficacy of potential governance actions, and (c) enhance governance options by designing mechanisms for enforcement, incentivization, or compliance. In this paper, we explain what technical AI governance is, why it is important, and present a taxonomy and incomplete catalog of its open problems. This paper is intended as a resource for technical researchers or research funders looking to contribute to AI governance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14981v1</guid>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anka Reuel, Ben Bucknall, Stephen Casper, Tim Fist, Lisa Soder, Onni Aarne, Lewis Hammond, Lujain Ibrahim, Alan Chan, Peter Wills, Markus Anderljung, Ben Garfinkel, Lennart Heim, Andrew Trask, Gabriel Mukobi, Rylan Schaeffer, Mauricio Baker, Sara Hooker, Irene Solaiman, Alexandra Sasha Luccioni, Nitarshan Rajkumar, Nicolas Mo\"es, Jeffrey Ladish, Neel Guha, Jessica Newman, Yoshua Bengio, Tobin South, Alex Pentland, Sanmi Koyejo, Mykel J. Kochenderfer, Robert Trager</dc:creator>
    </item>
    <item>
      <title>Fair Machine Learning for Healthcare Requires Recognizing the Intersectionality of Sociodemographic Factors, a Case Study</title>
      <link>https://arxiv.org/abs/2407.15006</link>
      <description>arXiv:2407.15006v1 Announce Type: new 
Abstract: As interest in implementing artificial intelligence (AI) in medical systems grows, discussion continues on how to evaluate the fairness of these systems, or the disparities they may perpetuate. Socioeconomic status (SES) is commonly included in machine learning models to control for health inequities, with the underlying assumption that increased SES is associated with better health. In this work, we considered a large cohort of patients from the Mount Sinai Health System in New York City to investigate the effect of patient SES, race, and sex on schizophrenia (SCZ) diagnosis rates via a logistic regression model. Within an intersectional framework, patient SES, race, and sex were found to have significant interactions. Our findings showed that increased SES is associated with a higher probability of obtaining a SCZ diagnosis in Black Americans ($\beta=4.1\times10^{-8}$, $SE=4.5\times10^{-9}$, $p &lt; 0.001$). Whereas high SES acts as a protective factor for SCZ diagnosis in White Americans ($\beta=-4.1\times10^{-8}$, $SE=6.7\times10^{-9}$, $p &lt; 0.001$). Further investigation is needed to reliably explain and quantify health disparities. Nevertheless, we advocate that building fair AI tools for the health care space requires recognizing the intersectionality of sociodemographic factors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15006v1</guid>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alissa A. Valentine, Alexander W. Charney, Isotta Landi</dc:creator>
    </item>
    <item>
      <title>RogueGPT: dis-ethical tuning transforms ChatGPT4 into a Rogue AI in 158 Words</title>
      <link>https://arxiv.org/abs/2407.15009</link>
      <description>arXiv:2407.15009v2 Announce Type: new 
Abstract: The ethical implications and potentials for misuse of Generative Artificial Intelligence are increasingly worrying topics. This paper explores how easily the default ethical guardrails of ChatGPT, using its latest customization features, can be bypassed by simple prompts and fine-tuning, that can be effortlessly accessed by the broad public. This malevolently altered version of ChatGPT, nicknamed "RogueGPT", responded with worrying behaviours, beyond those triggered by jailbreak prompts. We conduct an empirical study of RogueGPT responses, assessing its flexibility in answering questions pertaining to what should be disallowed usage. Our findings raise significant concerns about the model's knowledge about topics like illegal drug production, torture methods and terrorism. The ease of driving ChatGPT astray, coupled with its global accessibility, highlights severe issues regarding the data quality used for training the foundational model and the implementation of ethical safeguards. We thus underline the responsibilities and dangers of user-driven modifications, and the broader effects that these may have on the design of safeguarding and ethical modules implemented by AI programmers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15009v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alessio Buscemi, Daniele Proverbio</dc:creator>
    </item>
    <item>
      <title>ChatISA: A Prompt-Engineered Chatbot for Coding, Project Management, Interview and Exam Preparation Activities</title>
      <link>https://arxiv.org/abs/2407.15010</link>
      <description>arXiv:2407.15010v1 Announce Type: new 
Abstract: As generative AI continues to evolve, educators face the challenge of preparing students for a future where AI-assisted work is integral to professional success. This paper introduces ChatISA, an in-house, multi-model chatbot designed to support students in an Information Systems and Analytics department. ChatISA comprises four primary modules-Coding Companion, Project Coach, Exam Ally, and Interview Mentor-each tailored to enhance different aspects of the educational experience. Through iterative development, student feedback, and leveraging open-source frameworks, we created a robust tool that addresses coding inquiries, project management, exam preparation, and interview readiness. The implementation of ChatISA revealed significant insights and challenges, including the necessity of ethical guidelines and balancing AI usage with maintaining student agency. Our findings underscore the importance of adaptive pedagogy and proactive engagement with AI tools to maximize their educational benefits. To support broader adoption and innovation, all code for ChatISA is made publicly available on GitHub, enabling other institutions to customize and integrate similar AI-driven educational tools within their curricula.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15010v1</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Fadel M. Megahed, Ying-Ju Chen, Joshua A. Ferris, Cameron Resatar, Kaitlyn Ross, Younghwa Lee, L. Allison Jones-Farmer</dc:creator>
    </item>
    <item>
      <title>Research on Jing Dong's Self-built Logistics Based on Technology Acceptance Model</title>
      <link>https://arxiv.org/abs/2407.15011</link>
      <description>arXiv:2407.15011v1 Announce Type: new 
Abstract: Today is a time of rapid e-commerce development, and Jing Dong, China's e-commerce giant, has taken its place in the highly competitive industry with its self-built logistics system. This paper analyzed the impact of Jing Dong's self-built logistics system characteristics on user satisfaction and continuous use intention by using the Technology Acceptance Model as the theoretical framework. This paper collected 295 valid samples using a questionnaire survey; all the respondents are users and potential users of Jing Dong from mainland China. The empirical results of data analysis showed that marketing information quality, logistics system quality, and logistics service have significant effects on the perceived usefulness of Jing Dong's self-built logistics, while only marketing information quality and logistics system quality have significant effects on the perceived usefulness of self-built logistics among the self-built logistics system characteristics dimensions. Additionally, the willingness to continue using a product and user satisfaction were both directly and significantly impacted by perceived usefulness; perceived ease of use had an indirect impact on users' willingness to continue use by affecting perceived usefulness and user satisfaction, and user satisfaction has the most significant impact on users' continuous use of Jing Dong shopping and using Jing Dong self-built logistics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15011v1</guid>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.54691/bcpbm.v38i.3751</arxiv:DOI>
      <dc:creator>Yunsheng Wang, Jiaxuan Zhao</dc:creator>
    </item>
    <item>
      <title>Transformative Influence of LLM and AI Tools in Student Social Media Engagement: Analyzing Personalization, Communication Efficiency, and Collaborative Learning</title>
      <link>https://arxiv.org/abs/2407.15012</link>
      <description>arXiv:2407.15012v1 Announce Type: new 
Abstract: The advent of Large Language Models (LLMs) and Artificial Intelligence (AI) tools has revolutionized various facets of our lives, particularly in the realm of social media. For students, these advancements have unlocked unprecedented opportunities for learning, collaboration, and personal growth. AI-driven applications are transforming how students interact with social media, offering personalized content and recommendations, and enabling smarter, more efficient communication. Recent studies utilizing data from UniversityCube underscore the profound impact of AI tools on students' academic and social experiences. These studies reveal that students engaging with AI-enhanced social media platforms report higher academic performance, enhanced critical thinking skills, and increased engagement in collaborative projects.
  Moreover, AI tools assist in filtering out distracting content, allowing students to concentrate more on educational materials and pertinent discussions. The integration of LLMs in social media has further facilitated improved peer-to-peer communication and mentorship opportunities. AI algorithms effectively match students based on shared academic interests and career goals, fostering a supportive and intellectually stimulating online community, thereby contributing to increased student satisfaction and retention rates.
  In this article, we delve into the data provided by UniversityCube to explore how LLMs and AI tools are specifically transforming social media for students. Through case studies and statistical analyses, we offer a comprehensive understanding of the educational and social benefits these technologies offer. Our exploration highlights the potential of AI-driven tools to create a more enriched, efficient, and supportive educational environment for students in the digital age.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15012v1</guid>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Masoud Bashiri, Kamran Kowsari</dc:creator>
    </item>
    <item>
      <title>Teaching Digital Accessibility in Computing Education: Views of Educators in India</title>
      <link>https://arxiv.org/abs/2407.15013</link>
      <description>arXiv:2407.15013v1 Announce Type: new 
Abstract: In recent years, there has been rising interest from both governments and private industry in developing software that is accessible to all, including people with disabilities. However, the computer science (CS) courses that ought to prepare future professionals to develop such accessible software hardly cover topics related to accessibility. While there is growing literature on incorporating accessibility topics in computing education in the West, there is little work on this in the Global South, particularly in India, which has a large number of computing students and software professionals. In this replication report, we present (A) our findings from a replication of surveys used in the US and Switzerland on who teaches accessibility and barriers to teaching accessibility and (B) a qualitative analysis of perceptions of CS faculty in India about digital accessibility and teaching accessibility. Our study corroborates the findings of the earlier surveys: very few CS faculty teach accessibility, and the top barriers they perceive are the same. The qualitative analysis further reveals that the faculty in India need training on accessibility concepts and disabilities sensitization, and exposure to existing and ongoing CS education research and pedagogies. In light of these findings, we present recommendations aimed at addressing these challenges and enhancing the integration of accessibility into computing education.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15013v1</guid>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator> Parthasarathy,  Swaroop</dc:creator>
    </item>
    <item>
      <title>Influence of Personality Traits on Plagiarism Through Collusion in Programming Assignments</title>
      <link>https://arxiv.org/abs/2407.15014</link>
      <description>arXiv:2407.15014v1 Announce Type: new 
Abstract: Educating students about academic integrity expectations has been suggested as one of the ways to reduce malpractice in take-home programming assignments. We test this hypothesis using data collected from an artificial intelligence course with 105 participants (N=105) at a university in India. The AI course had two programming assignments. Plagiarism through collusion was quantified using the Measure of Software Similarity (MOSS) tool. Students were educated about what constitutes academic dishonesty and were required to take an honor pledge before the start of the second take-home programming assignment. The two programming assignments were novel and did not have solutions available on the internet. We expected the mean percentage of similar lines of code to be significantly less in the second programming assignment. However, our results show no significant difference in the mean percentage of similar lines of code across the two programming assignments. We also study how the Big-five personality traits affect the propensity for plagiarism in the two take-home assignments. Our results across both assignments show that the extraversion trait of the Big Five personality exhibits a positive association, and the conscientiousness trait exhibits a negative association with plagiarism tendencies. Our result suggests that the policy of educating students about academic integrity will have a limited impact as long as students perceive an opportunity for plagiarism to be present. We explain our results using the Fraud triangle model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15014v1</guid>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Parthasarathy PD, Ishaan Kapoor, Swaroop Joshi, Sujith Thomas</dc:creator>
    </item>
    <item>
      <title>Rethinking Digitalization and Climate: Don't Predict, Mitigate</title>
      <link>https://arxiv.org/abs/2407.15016</link>
      <description>arXiv:2407.15016v1 Announce Type: new 
Abstract: Digitalization is a core component of the green transition. Today's focus is on quantifying and pre-dicting the climate effects of digitalization through various life-cycle assessments and baseline sce-nario methodologies. Here we argue that this is a mistake. Most attempts at prediction are based on three implicit assumptions: (a) the digital carbon footprint can be quantified, (b) business-as-usual with episodic change leading to a new era of stability, and (c) investments in digitalization will be delivered within the cost, timeframe, and benefits described in their business cases. We problema-tize each assumption within the context of digitalization and argue that the digital carbon footprint is inherently unpredictable. We build on uncertainty literature to show that even if you cannot predict, you can still mitigate. On that basis, we propose to rethink practice on the digital carbon footprint from prediction to mitigation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15016v1</guid>
      <category>cs.CY</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daria Gritsenko, Jon Aaen, Bent Flyvbjerg</dc:creator>
    </item>
    <item>
      <title>Integrating Attentional Factors and Spacing in Logistic Knowledge Tracing Models to Explore the Impact of Training Sequences on Category Learning</title>
      <link>https://arxiv.org/abs/2407.15020</link>
      <description>arXiv:2407.15020v1 Announce Type: new 
Abstract: In category learning, a growing body of literature has increasingly focused on exploring the impacts of interleaving in contrast to blocking. The sequential attention hypothesis posits that interleaving draws attention to the differences between categories while blocking directs attention toward similarities within categories. Although a recent study underscores the joint influence of memory and attentional factors on sequencing effects, there remains a scarcity of effective computational models integrating both attentional and memory considerations to comprehensively understand the effect of training sequences on students' performance. This study introduces a novel integration of attentional factors and spacing into the logistic knowledge tracing (LKT) models to monitor students' performance across different training sequences (interleaving and blocking). Attentional factors were incorporated by recording the counts of comparisons between adjacent trials, considering whether they belong to the same or different category. Several features were employed to account for temporal spacing. We used cross-validations to test the model fit and predictions on the learning session and posttest. Our findings reveal that incorporating both attentional factors and spacing features in the Additive Factors Model (AFM) significantly enhances its capacity to capture the effects of interleaving and blocking and demonstrates superior predictive accuracy for students' learning outcomes. By bridging the gap between attentional factors and memory processes, our computational approach offers a more comprehensive framework for understanding and predicting category learning outcomes in educational settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15020v1</guid>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Meng Cao, Philip I. Pavlik Jr., Wei Chu, Liang Zhang</dc:creator>
    </item>
    <item>
      <title>Encouraging Responsible Use of Generative AI in Education: A Reward-Based Learning Approach</title>
      <link>https://arxiv.org/abs/2407.15022</link>
      <description>arXiv:2407.15022v1 Announce Type: new 
Abstract: This research introduces an innovative mathematical learning approach that integrates generative AI to cultivate a structured learning rather than quick solution. Our method combines chatbot capabilities and generative AI to offer interactive problem-solving exercises, enhancing learning through a stepby-step approach for varied problems, advocating for the responsible use of AI in education. Our approach emphasizes that immediate answers from ChatGPT can impede real learning. We introduce a reward-based system that requires students to solve mathematical problems effectively to receive the final answer. This encourages a progressive learning path from basic to complex problems, rewarding mastery with final solutions. The goal is to transition students from seeking quick fixes to engaging actively in a comprehensive learning experience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15022v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aditi Singh, Abul Ehtesham, Saket Kumar, Gaurav Kumar Gupta, Tala Talaei Khoei</dc:creator>
    </item>
    <item>
      <title>The dark side of the metaverse: The role of gamification in event virtualization</title>
      <link>https://arxiv.org/abs/2407.15125</link>
      <description>arXiv:2407.15125v1 Announce Type: new 
Abstract: The virtualization of cultural events in the metaverse creates opportunities to generate valuable and innovative experiences that replicate and extend in-person events; but the process faces associated challenges. In the absence of relevant empirical studies, the aim of this article is to analyze the positive and negative aspects of the user experience in a cultural event held in the metaverse. A mixed-methods approach is employed to test the proposed hypotheses. The results from three focus groups demonstrated the difficulty that users face in focusing their attention on the main elements of the metaverse, and the inability of this virtual sphere to convey the authenticity of a cultural event. Based on these findings, a metaverse-focused quantitative study was conducted to examine whether perceived gamification mitigate the negative effects of users failing to pay attention in their metaverse experiences. When users increased their attention levels, their ability to imagine the real experience and their perceptions of the authenticity of the cultural event increased, which produced positive behavioral intentions. This is one of the first studies to empirically analyze the tourist experience in the metaverse; managers and policymakers can benefit from the results to hold valuable virtual cultural events.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15125v1</guid>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.ijinfomgt.2023.102726</arxiv:DOI>
      <arxiv:journal_reference>International Journal of Information Management, 75, 102726 (2024)</arxiv:journal_reference>
      <dc:creator>Carlos Flavian, Sergio Ibanez-Sanchez, Carlos Orus, Sergio Barta</dc:creator>
    </item>
    <item>
      <title>Decoding Multilingual Moral Preferences: Unveiling LLM's Biases Through the Moral Machine Experiment</title>
      <link>https://arxiv.org/abs/2407.15184</link>
      <description>arXiv:2407.15184v1 Announce Type: new 
Abstract: Large language models (LLMs) increasingly find their way into the most diverse areas of our everyday lives. They indirectly influence people's decisions or opinions through their daily use. Therefore, understanding how and which moral judgements these LLMs make is crucial. However, morality is not universal and depends on the cultural background. This raises the question of whether these cultural preferences are also reflected in LLMs when prompted in different languages or whether moral decision-making is consistent across different languages. So far, most research has focused on investigating the inherent values of LLMs in English. While a few works conduct multilingual analyses of moral bias in LLMs in a multilingual setting, these analyses do not go beyond atomic actions. To the best of our knowledge, a multilingual analysis of moral bias in dilemmas has not yet been conducted.
  To address this, our paper builds on the moral machine experiment (MME) to investigate the moral preferences of five LLMs, Falcon, Gemini, Llama, GPT, and MPT, in a multilingual setting and compares them with the preferences collected from humans belonging to different cultures. To accomplish this, we generate 6500 scenarios of the MME and prompt the models in ten languages on which action to take. Our analysis reveals that all LLMs inhibit different moral biases to some degree and that they not only differ from the human preferences but also across multiple languages within the models themselves. Moreover, we find that almost all models, particularly Llama 3, divert greatly from human values and, for instance, prefer saving fewer people over saving more.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15184v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Karina Vida, Fabian Damken, Anne Lauscher</dc:creator>
    </item>
    <item>
      <title>AI as a Tool for Fair Journalism: Case Studies from Malta</title>
      <link>https://arxiv.org/abs/2407.15316</link>
      <description>arXiv:2407.15316v1 Announce Type: new 
Abstract: In today`s media landscape, the role of Artificial Intelligence (AI) in shaping societal perspectives and journalistic integrity is becoming increasingly apparent. This paper presents two case studies centred on Malta`s media market featuring technical novelty. Despite its relatively small scale, Malta offers invaluable insights applicable to both similar and broader media contexts. These two projects focus on media monitoring and present tools designed to analyse potential biases in news articles and television news segments. The first project uses Computer Vision and Natural Language Processing techniques to analyse the coherence between images in news articles and their corresponding captions, headlines, and article bodies. The second project employs computer vision techniques to track individuals` on-screen time or visual exposure in news videos, providing queryable data. These initiatives aim to contribute to society by providing both journalists and the public with the means to identify biases. Furthermore, we make these tools accessible to journalists to improve the trustworthiness of media outlets by offering robust tools for detecting and reducing bias.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15316v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/CAI59869.2024.00032</arxiv:DOI>
      <arxiv:journal_reference>Proceedings of the IEEE 2024 Conference on Artificial Intelligence</arxiv:journal_reference>
      <dc:creator>Dylan Seychell, Gabriel Hili, Jonathan Attard, Konstantinos Makantatis</dc:creator>
    </item>
    <item>
      <title>FAIR evaluation of ten widely used chemical datasets: Lessons learned and recommendations</title>
      <link>https://arxiv.org/abs/2407.15591</link>
      <description>arXiv:2407.15591v1 Announce Type: new 
Abstract: This document focuses on databases disseminating data on (hazardous) substances found on the North American and the European (EU) market. The goal is to analyse the FAIRness (Findability, Accessibility, Interoperability and Reusability) of published open data on these substances and to qualitatively evaluate to what extend the selected databases already fulfil the criteria set out in the commission draft regulation on a common data chemicals platform. We implemented two complementary approaches: Manual, and Automatic. The manual approach is based on online questionnaires. These questionnaires provide a structured approach to evaluating FAIRness by guiding users through a series of questions related to the FAIR principles. They are particularly useful for initiating discussions on FAIR implementation within research teams and for identifying areas that require further attention. Automated tools for FAIRness assessment, such as F-UJI and FAIR Checker, are gaining prominence and are continuously under development. Unlike manual tools, automated tools perform a series of tests automatically starting from a dereferenceable URL to the data resource to be evaluated. We analysed ten widely adopted datasets managed in Europe and North America. The highest score from automatic analysis was 54/100. The manual analysis shows that several FAIR metrics were satisfied, but not detectable by automatic tools because there is no metadata, or the format of the information was not a standard one. Thus, it was not interpretable by the tool. We present the details of the analysis and tables summarizing the outcomes, the issues, and the suggestions to address these issues.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15591v1</guid>
      <category>cs.CY</category>
      <category>cs.DB</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marcos Da Silveira, Oona Freudenthal, Louis Deladiennee</dc:creator>
    </item>
    <item>
      <title>Dressed to Gamble: How Poker Drives the Dynamics of Wearables and Visits on Decentraland's Social Virtual World</title>
      <link>https://arxiv.org/abs/2407.15625</link>
      <description>arXiv:2407.15625v1 Announce Type: new 
Abstract: Decentraland is a blockchain-based social virtual world touted to be a creative space owned by its community, unlike previous virtual worlds. Its users can create and publish wearables, virtual garments to customize avatars, which can be then sold or given away via the blockchain. Decentral Games (DG), a single project owning two prominent in-world casinos, has by far created the most wearables, with these being necessary to earn cryptocurrency in their flagship game ICE Poker. We thus present a comprehensive study that investigates how DG and ICE Poker influence the overall dynamics of Decentraland wearables and in-world visits. To this end, we analyzed 5.9 million wearable transfers made on the Polygon blockchain (and related sales) over a two-year period, and 677 million log events of in-world user positions in an overlapping 10-month period. We found that the influence of DG and Ice Poker is not only significant, but also substantial for transfers and sales monetary value of wearables, and very large for daily unique visitors and time spent in the virtual world. Despite several alternative in-world economic and artistic initiatives in Decentraland, some of which have attracted much attention from the general public, online poker appears to be the main driver of the analyzed dynamics. Our work thus contributes to the current understanding of user behavior in social virtual worlds and it is among the first to study the emerging phenomenon of blockchain-based online gambling in virtual spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15625v1</guid>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amaury Trujillo, Clara Bacciu, Matteo Abrate</dc:creator>
    </item>
    <item>
      <title>Coca4ai: checking energy behaviors on AI data centers</title>
      <link>https://arxiv.org/abs/2407.15670</link>
      <description>arXiv:2407.15670v1 Announce Type: new 
Abstract: Monitoring energy behaviors in AI data centers is crucial, both to reduce their energy consumption and to raise awareness among their users which are key actors in the AI field. This paper shows a proof of concept of easy and lightweight monitoring of energy behaviors at the scale of a whole data center, a user or a job submission. Our system uses software wattmeters and we validate our setup with per node accurate external wattmeters. Results show that there is an interesting potential from the efficiency point of view, providing arguments to create user engagement thanks to energy monitoring.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15670v1</guid>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paul Gay, \'Eric Bilinski, Anne-Laure Ligozat</dc:creator>
    </item>
    <item>
      <title>Integrating AI Tutors in a Programming Course</title>
      <link>https://arxiv.org/abs/2407.15718</link>
      <description>arXiv:2407.15718v1 Announce Type: new 
Abstract: RAGMan is an LLM-powered tutoring system that can support a variety of course-specific and homework-specific AI tutors. RAGMan leverages Retrieval Augmented Generation (RAG), as well as strict instructions, to ensure the alignment of the AI tutors' responses. By using RAGMan's AI tutors, students receive assistance with their specific homework assignments without directly obtaining solutions, while also having the ability to ask general programming-related questions.
  RAGMan was deployed as an optional resource in an introductory programming course with an enrollment of 455 students. It was configured as a set of five homework-specific AI tutors. This paper describes the interactions the students had with the AI tutors, the students' feedback, and a comparative grade analysis. Overall, about half of the students engaged with the AI tutors, and the vast majority of the interactions were legitimate homework questions. When students posed questions within the intended scope, the AI tutors delivered accurate responses 98% of the time. Within the students used AI tutors, 78% reported that the tutors helped their learning. Beyond AI tutors' ability to provide valuable suggestions, students reported appreciating them for fostering a safe learning environment free from judgment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15718v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.IR</category>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Iris Ma, Alberto Krone Martins, Cristina Videira Lopes</dc:creator>
    </item>
    <item>
      <title>Examining Inequality in Park Quality for Promoting Health Across 35 Global Cities</title>
      <link>https://arxiv.org/abs/2407.15770</link>
      <description>arXiv:2407.15770v1 Announce Type: new 
Abstract: Urban parks provide significant health benefits by offering spaces and facilities for various recreational and leisure activities. However, the capacity of specific park spaces and elements to foster health remains underexamined. Traditional studies have focused on parks' size, greenery, and accessibility, often overlooking their ability to facilitate specific health-promoting activities. To address this gap, we propose a taxonomy consisting of six categories of health-promoting activities in parks: physical, mind-body, nature appreciation, environmental, social, and cultural. We estimate the capacity of parks in 35 global cities to promote health by establishing a lexicon linking park spaces and elements with specific health-promoting activities from our taxonomy. Using this lexicon, we collected data on elements and spaces in all parks in 35 cities from OpenStreetMap. Our analysis covers 23,477 parks with a total of 827,038 elements and spaces. By first comparing similarly sized parks across cities, we found that North American parks offer more spaces for physical activities, while European parks focus more on nature appreciation. Second, by scoring parks based on both elements and spaces, we investigated the variability in their health-promoting potential. We found the most uniform provision across parks for physical activities and the highest disparities regarding social activities. Additionally, parks offering a variety of activities are usually located in city centers, while offerings diminish in parks towards the suburbs. Lastly, we identified significant inequalities in park standards across cities, regardless of their continental location: Tokyo and Paris offer the most uniform park standards, while Copenhagen and Rio de Janeiro exhibit the most pronounced disparities. Our study provides insights for making urban parks more equitable, engaging, and health-promoting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15770v1</guid>
      <category>cs.CY</category>
      <category>cs.CE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Linus W. Dietz, Sanja \v{S}\'cepanovi\'c, Ke Zhou, Andr\'e Felipe Zanella, Daniele Quercia</dc:creator>
    </item>
    <item>
      <title>Inequalities in Computational Thinking Among Incoming Students in an STEM Chilean University</title>
      <link>https://arxiv.org/abs/2407.15833</link>
      <description>arXiv:2407.15833v1 Announce Type: new 
Abstract: While computational thinking arises as an essential skill worldwide, formal primary and secondary education in Latin America rarely incorporates mechanisms to develop it in their curricula. The extent to which students in the region acquire computational thinking skills remains largely unknown. To start addressing this void, this article presents findings from a cross-sectional study that characterizes the computational thinking abilities of incoming students at a Chilean university with a strong emphasis on STEM disciplines. Based on more than 500 responses, this study provides evidence of significant inequalities in computational thinking across gender, type of school (private or no), and prior programming knowledge. The discussion offers insights into how these disparities relate to contextual factors of the country, such as a highly socio-economically segregated educational system, public policies focused mainly on technology access, and heavy reliance on voluntary initiatives, to develop computational thinking. The findings can enlighten upcoming research endeavors and formulate strategies to create a more equitable field for students entering STEM degrees in nations facing similar circumstances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15833v1</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TE.2023.3334193</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Education ( Volume: 67, Issue: 2, April 2024)</arxiv:journal_reference>
      <dc:creator>Felipe Gonz\'alez-Pizarro, Claudia L\'opez, Andrea V\'asquez, Carlos Castro</dc:creator>
    </item>
    <item>
      <title>Mitigating biases in big mobility data: a case study of monitoring large-scale transit systems</title>
      <link>https://arxiv.org/abs/2407.14541</link>
      <description>arXiv:2407.14541v1 Announce Type: cross 
Abstract: Big mobility datasets (BMD) have shown many advantages in studying human mobility and evaluating the performance of transportation systems. However, the quality of BMD remains poorly understood. This study evaluates biases in BMD and develops mitigation methods. Using Google and Apple mobility data as examples, this study compares them with benchmark data from governmental agencies. Spatio-temporal discrepancies between BMD and benchmark are observed and their impacts on transportation applications are investigated, emphasizing the urgent need to address these biases to prevent misguided policymaking. This study further proposes and tests a bias mitigation method. It is shown that the mitigated BMD could generate valuable insights into large-scale public transit systems across 100+ US counties, revealing regional disparities of the recovery of transit systems from the COVID-19. This study underscores the importance of caution when using BMD in transportation research and presents effective mitigation strategies that would benefit practitioners.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14541v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1080/19427867.2024.2379703</arxiv:DOI>
      <dc:creator>Feilong Wang, Xuegang Ban, Peng Chen, Chenxi Liu, Rong Zhao</dc:creator>
    </item>
    <item>
      <title>Using Case Studies to Teach Responsible AI to Industry Practitioners</title>
      <link>https://arxiv.org/abs/2407.14686</link>
      <description>arXiv:2407.14686v1 Announce Type: cross 
Abstract: Responsible AI (RAI) is the science and the practice of making the design, development, and use of AI socially sustainable: of reaping the benefits of innovation while controlling the risks. Naturally, industry practitioners play a decisive role in our collective ability to achieve the goals of RAI. Unfortunately, we do not yet have consolidated educational materials and effective methodologies for teaching RAI to practitioners. In this paper, we propose a novel stakeholder-first educational approach that uses interactive case studies to achieve organizational and practitioner -level engagement and advance learning of RAI. We discuss a partnership with Meta, an international technology company, to co-develop and deliver RAI workshops to a diverse audience within the company. Our assessment results indicate that participants found the workshops engaging and reported a positive shift in understanding and motivation to apply RAI to their work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14686v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Julia Stoyanovich, Rodrigo Kreis de Paula, Armanda Lewis, Chloe Zheng</dc:creator>
    </item>
    <item>
      <title>Implementing Fairness: the view from a FairDream</title>
      <link>https://arxiv.org/abs/2407.14766</link>
      <description>arXiv:2407.14766v1 Announce Type: cross 
Abstract: In this paper, we propose an experimental investigation of the problem of AI fairness in classification. We train an AI model and develop our own fairness package FairDream to detect inequalities and then to correct for them, using income prediction as a case study. Our experiments show that it is a property of FairDream to fulfill fairness objectives which are conditional on the ground truth (Equalized Odds), even when the algorithm is set the task of equalizing positives across groups (Demographic Parity). While this may be seen as an anomaly, we explain this property by comparing our approach with a closely related fairness method (GridSearch), which can enforce Demographic Parity at the expense of Equalized Odds. We grant that a fairness metric conditioned on true labels does not give a sufficient criterion to reach fairness, but we argue that it gives us at least a necessary condition to implement Demographic Parity cautiously. We also explain why neither Equal Calibration nor Equal Precision stand as relevant fairness criteria in classification. Addressing their limitations to warn the decision-maker for any disadvantaging rate, Equalized Odds avoids the peril of strict conservatism, while keeping away the utopia of a whole redistribution of resources through algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14766v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Souverain, Johnathan Nguyen, Nicolas Meric, Paul \'Egr\'e</dc:creator>
    </item>
    <item>
      <title>FairViT: Fair Vision Transformer via Adaptive Masking</title>
      <link>https://arxiv.org/abs/2407.14799</link>
      <description>arXiv:2407.14799v1 Announce Type: cross 
Abstract: Vision Transformer (ViT) has achieved excellent performance and demonstrated its promising potential in various computer vision tasks. The wide deployment of ViT in real-world tasks requires a thorough understanding of the societal impact of the model. However, most ViT-based works do not take fairness into account and it is unclear whether directly applying CNN-oriented debiased algorithm to ViT is feasible. Moreover, previous works typically sacrifice accuracy for fairness. Therefore, we aim to develop an algorithm that improves accuracy without sacrificing fairness. In this paper, we propose FairViT, a novel accurate and fair ViT framework. To this end, we introduce a novel distance loss and deploy adaptive fairness-aware masks on attention layers updating with model parameters. Experimental results show \sys can achieve accuracy better than other alternatives, even with competitive computational efficiency. Furthermore, \sys achieves appreciable fairness results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14799v1</guid>
      <category>cs.CV</category>
      <category>cs.CY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bowei Tian, Ruijie Du, Yanning Shen</dc:creator>
    </item>
    <item>
      <title>From Ad Identifiers to Global Privacy Control: The Status Quo and Future of Opting Out of Ad Tracking on Android</title>
      <link>https://arxiv.org/abs/2407.14938</link>
      <description>arXiv:2407.14938v1 Announce Type: cross 
Abstract: Apps and their integrated third party libraries often collect a variety of data from people to show them personalized ads. This practice is often privacy-invasive. Since 2013, Google has therefore allowed users to limit ad tracking on Android via system settings. Further, under the 2018 California Consumer Privacy Act (CCPA), apps must honor opt-outs from ad tracking under the Global Privacy Control (GPC). The efficacy of these two methods to limit ad tracking has not been studied in prior work. Our legal and technical analysis details how the GPC applies to mobile apps and how it could be integrated directly into Android, thereby developing a reference design for GPC on Android. Our empirical analysis of 1,896 top-ranked Android apps shows that both the Android system-level opt-out and the GPC signal rarely restrict ad tracking. In our view, deleting the AdID and opting out under the CCPA has the same meaning. Thus, the current AdID setting and APIs should be evolved towards GPC and integrated into Android's Privacy Sandbox.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14938v1</guid>
      <category>cs.CR</category>
      <category>cs.CY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sebastian Zimmeck, Nishant Aggarwal, Zachary Liu, Konrad Kollnig</dc:creator>
    </item>
    <item>
      <title>A Measure for Level of Autonomy Based on Observable System Behavior</title>
      <link>https://arxiv.org/abs/2407.14975</link>
      <description>arXiv:2407.14975v1 Announce Type: cross 
Abstract: Contemporary artificial intelligence systems are pivotal in enhancing human efficiency and safety across various domains. One such domain is autonomous systems, especially in automotive and defense use cases. Artificial intelligence brings learning and enhanced decision-making to autonomy system goal-oriented behaviors and human independence. However, the lack of clear understanding of autonomy system capabilities hampers human-machine or machine-machine interaction and interdiction. This necessitates varying degrees of human involvement for safety, accountability, and explainability purposes. Yet, measuring the level autonomous capability in an autonomous system presents a challenge. Two scales of measurement exist, yet measuring autonomy presupposes a variety of elements not available in the wild. This is why existing measures for level of autonomy are operationalized only during design or test and evaluation phases. No measure for level of autonomy based on observed system behavior exists at this time. To address this, we outline a potential measure for predicting level of autonomy using observable actions. We also present an algorithm incorporating the proposed measure. The measure and algorithm have significance to researchers and practitioners interested in a method to blind compare autonomous systems at runtime. Defense-based implementations are likewise possible because counter-autonomy depends on robust identification of autonomous systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14975v1</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jason M. Pittman</dc:creator>
    </item>
    <item>
      <title>Multiple Object Detection and Tracking in Panoramic Videos for Cycling Safety Analysis</title>
      <link>https://arxiv.org/abs/2407.15199</link>
      <description>arXiv:2407.15199v1 Announce Type: cross 
Abstract: Panoramic cycling videos can record 360{\deg} views around the cyclists. Thus, it is essential to conduct automatic road user analysis on them using computer vision models to provide data for studies on cycling safety. However, the features of panoramic data such as severe distortions, large number of small objects and boundary continuity have brought great challenges to the existing CV models, including poor performance and evaluation methods that are no longer applicable. In addition, due to the lack of data with annotations, it is not easy to re-train the models.
  In response to these problems, the project proposed and implemented a three-step methodology: (1) improve the prediction performance of the pre-trained object detection models on panoramic data by projecting the original image into 4 perspective sub-images; (2) introduce supports for boundary continuity and category information into DeepSORT, a commonly used multiple object tracking model, and set an improved detection model as its detector; (3) using the tracking results, develop an application for detecting the overtaking behaviour of the surrounding vehicles.
  Evaluated on the panoramic cycling dataset built by the project, the proposed methodology improves the average precision of YOLO v5m6 and Faster RCNN-FPN under any input resolution setting. In addition, it raises MOTA and IDF1 of DeepSORT by 7.6\% and 9.7\% respectively. When detecting the overtakes in the test videos, it achieves the F-score of 0.88.
  The code is available on GitHub at github.com/cuppp1998/360_object_tracking to ensure the reproducibility and further improvements of results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15199v1</guid>
      <category>cs.CV</category>
      <category>cs.CY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jingwei Guo, Meihui Wang, Ilya Ilyankou, Natchapon Jongwiriyanurak, Xiaowei Gao, Nicola Christie, James Haworth</dc:creator>
    </item>
    <item>
      <title>PUFFLE: Balancing Privacy, Utility, and Fairness in Federated Learning</title>
      <link>https://arxiv.org/abs/2407.15224</link>
      <description>arXiv:2407.15224v1 Announce Type: cross 
Abstract: Training and deploying Machine Learning models that simultaneously adhere to principles of fairness and privacy while ensuring good utility poses a significant challenge. The interplay between these three factors of trustworthiness is frequently underestimated and remains insufficiently explored. Consequently, many efforts focus on ensuring only two of these factors, neglecting one in the process. The decentralization of the datasets and the variations in distributions among the clients exacerbate the complexity of achieving this ethical trade-off in the context of Federated Learning (FL). For the first time in FL literature, we address these three factors of trustworthiness. We introduce PUFFLE, a high-level parameterised approach that can help in the exploration of the balance between utility, privacy, and fairness in FL scenarios. We prove that PUFFLE can be effective across diverse datasets, models, and data distributions, reducing the model unfairness up to 75%, with a maximum reduction in the utility of 17% in the worst-case scenario, while maintaining strict privacy guarantees during the FL training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15224v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CR</category>
      <category>cs.CY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luca Corbucci, Mikko A Heikkila, David Solans Noguero, Anna Monreale, Nicolas Kourtellis</dc:creator>
    </item>
    <item>
      <title>Walking in Others' Shoes: How Perspective-Taking Guides Large Language Models in Reducing Toxicity and Bias</title>
      <link>https://arxiv.org/abs/2407.15366</link>
      <description>arXiv:2407.15366v1 Announce Type: cross 
Abstract: The common toxicity and societal bias in contents generated by large language models (LLMs) necessitate strategies to reduce harm. Present solutions often demand white-box access to the model or substantial training, which is impractical for cutting-edge commercial LLMs. Moreover, prevailing prompting methods depend on external tool feedback and fail to simultaneously lessen toxicity and bias. Motivated by social psychology principles, we propose a novel strategy named \textbf{perspective-taking prompting (\textsc{PeT})} that inspires LLMs to integrate diverse human perspectives and self-regulate their responses. This self-correction mechanism can significantly diminish toxicity (up to $89\%$) and bias (up to $73\%$) in LLMs' responses. Rigorous evaluations and ablation studies are conducted on two commercial LLMs (ChatGPT and GLM) and three open-source LLMs, revealing \textsc{PeT}'s superiority in producing less harmful responses, outperforming five strong baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15366v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Rongwu Xu, Zi'an Zhou, Tianwei Zhang, Zehan Qi, Su Yao, Ke Xu, Wei Xu, Han Qiu</dc:creator>
    </item>
    <item>
      <title>Regression under demographic parity constraints via unlabeled post-processing</title>
      <link>https://arxiv.org/abs/2407.15453</link>
      <description>arXiv:2407.15453v1 Announce Type: cross 
Abstract: We address the problem of performing regression while ensuring demographic parity, even without access to sensitive attributes during inference. We present a general-purpose post-processing algorithm that, using accurate estimates of the regression function and a sensitive attribute predictor, generates predictions that meet the demographic parity constraint. Our method involves discretization and stochastic minimization of a smooth convex function. It is suitable for online post-processing and multi-class classification tasks only involving unlabeled data for the post-processing. Unlike prior methods, our approach is fully theory-driven. We require precise control over the gradient norm of the convex function, and thus, we rely on more advanced techniques than standard stochastic gradient descent. Our algorithm is backed by finite-sample analysis and post-processing bounds, with experimental results validating our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15453v1</guid>
      <category>stat.ML</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Evgenii Chzhen (LMO, CELESTE), Mohamed Hebiri (LAMA), Gayane Taturyan (LAMA, IMT)</dc:creator>
    </item>
    <item>
      <title>Breaking the Global North Stereotype: A Global South-centric Benchmark Dataset for Auditing and Mitigating Biases in Facial Recognition Systems</title>
      <link>https://arxiv.org/abs/2407.15810</link>
      <description>arXiv:2407.15810v1 Announce Type: cross 
Abstract: Facial Recognition Systems (FRSs) are being developed and deployed globally at unprecedented rates. Most platforms are designed in a limited set of countries but deployed in worldwide, without adequate checkpoints. This is especially problematic for Global South countries which lack strong legislation to safeguard persons facing disparate performance of these systems. A combination of unavailability of datasets, lack of understanding of FRS functionality and low-resource bias mitigation measures accentuate the problem. In this work, we propose a new face dataset composed of 6,579 unique male and female sportspersons from eight countries around the world. More than 50% of the dataset comprises individuals from the Global South countries and is demographically diverse. To aid adversarial audits and robust model training, each image has four adversarial variants, totaling over 40,000 images. We also benchmark five popular FRSs, both commercial and open-source, for the task of gender prediction (and country prediction for one of the open-source models as an example of red-teaming). Experiments on industrial FRSs reveal accuracies ranging from 98.2%--38.1%, with a large disparity between males and females in the Global South (max difference of 38.5%). Biases are also observed in all FRSs between females of the Global North and South (max difference of ~50%). Grad-CAM analysis identifies the nose, forehead and mouth as the regions of interest on one of the open-source FRSs. Utilizing this insight, we design simple, low-resource bias mitigation solutions using few-shot and novel contrastive learning techniques significantly improving the accuracy with disparity between males and females reducing from 50% to 1.5% in one of the settings. In the red-teaming experiment with the open-source Deepface model, contrastive learning proves more effective than simple fine-tuning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15810v1</guid>
      <category>cs.CV</category>
      <category>cs.CY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Siddharth D Jaiswal, Animesh Ganai, Abhisek Dash, Saptarshi Ghosh, Animesh Mukherjee</dc:creator>
    </item>
    <item>
      <title>A Decentralised Digital Token Architecture for Public Transport</title>
      <link>https://arxiv.org/abs/2012.01382</link>
      <description>arXiv:2012.01382v3 Announce Type: replace 
Abstract: Digitisation is often viewed as beneficial to a user. Whereas traditionally, people would physically have to identify to a service, pay for a ticket in cash, or go into a library to access a book, people can now achieve all of this through a click of a button. Such actions may seem functionally identical to their analogue counterparts, but in the digital case, a user's actions are automatically recorded. The recording of user's interactions presents a problem because once the information is collected, it is outside of the control of the person whom it concerns. This issue is only exacerbated by the centralisation of the authentication mechanisms underpinning the aforementioned services, permitting the aggregation and analysis of even more data. This work aims to motivate the need and establish the feasibility of the application of a privacy-enhancing digital token management service to public transit. A proof-of-concept implementation is developed, building upon a design proposed by Goodell and Aste. This implementation was optimised for the public transport use case. Its performance is tested in a local environment to better understand the technical challenges and assess the technical feasibility of the system in a production setting. It was observed that for loads between one and five requests per second the proof-of-concept performs comparably to other contactless payment systems, with a maximum median response time less than two seconds. Due to hardware bottlenecks, reliable throughput in our test environment was limited to five requests per second. The demonstrated throughput and latency indicate that the system can feasibly compete with solutions currently in use. Yet, further work is needed to demonstrate their performance characteristics in an environment similar to that experienced in production.</description>
      <guid isPermaLink="false">oai:arXiv.org:2012.01382v3</guid>
      <category>cs.CY</category>
      <category>cs.CR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Oscar King, Geoffrey Goodell</dc:creator>
    </item>
    <item>
      <title>Who Shares Fake News? Uncovering Insights from Social Media Users' Post Histories</title>
      <link>https://arxiv.org/abs/2203.10560</link>
      <description>arXiv:2203.10560v3 Announce Type: replace 
Abstract: We propose that social-media users' own post histories are an underused yet valuable resource for studying fake-news sharing. By extracting textual cues from their prior posts, and contrasting their prevalence against random social-media users and others (e.g., those with similar socio-demographics, political news-sharers, and fact-check sharers), researchers can identify cues that distinguish fake-news sharers, predict those most likely to share fake news, and identify promising constructs to build interventions. Our research includes studies along these lines. In Study 1, we explore the distinctive language patterns of fake-news sharers, highlighting elements such as their higher use of anger and power-related words. In Study 2, we show that adding textual cues into predictive models enhances their accuracy in predicting fake-news sharers. In Study 3, we explore the contrasting role of trait and situational anger, and show trait anger is associated with a greater propensity to share both true and fake news. In Study 4, we introduce a way to authenticate Twitter accounts in surveys, before using it to explore how crafting an ad copy that resonates with users' sense of power encourages the adoption of fact-checking tools. We hope to encourage the use of novel research methods for marketers and misinformation researchers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2203.10560v3</guid>
      <category>cs.CY</category>
      <category>cs.CL</category>
      <category>cs.SI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Verena Schoenmueller, Simon J. Blanchard, Gita V. Johar</dc:creator>
    </item>
    <item>
      <title>Characteristics of ChatGPT users from Germany: implications for the digital divide from web tracking data</title>
      <link>https://arxiv.org/abs/2309.02142</link>
      <description>arXiv:2309.02142v3 Announce Type: replace 
Abstract: A major challenge of our time is reducing disparities in access to and effective use of digital technologies, with recent discussions highlighting the role of AI in exacerbating the digital divide. We examine user characteristics that predict usage of the AI-powered conversational agent ChatGPT. We combine behavioral and survey data in a web tracked sample of N=1376 German citizens to investigate differences in ChatGPT activity (usage, visits, and adoption) during the first 11 months from the launch of the service (November 30, 2022). Guided by a model of technology acceptance (UTAUT- 2), we examine the role of socio-demographics commonly associated with the digital divide in ChatGPT activity and explore further socio-political attributes identified via stability selection in Lasso regressions. We confirm that lower age and higher education affect ChatGPT usage, but do not find that gender or income do. We find full-time employment and more children to be barriers to ChatGPT activity. Using a variety of social media was positively associated with ChatGPT activity. In terms of political variables, political knowledge and political self-efficacy as well as some political behaviors such as voting, debating political issues online and offline and political action online were all associated with ChatGPT activity, with online political debating and political self-efficacy negatively so. Finally, need for cognition and communication skills such as writing, attending meetings, or giving presentations, were also associated with ChatGPT engagement, though chairing/organizing meetings was negatively associated. Our research informs efforts to address digital disparities and promote digital literacy among underserved populations by presenting implications, recommendations, and discussions on ethical and social issues of our findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.02142v3</guid>
      <category>cs.CY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Celina Kacperski, Denis Bonnay, Juhi Kulshrestha, Peter Selb, Andreas Spitz, Roberto Ulloa</dc:creator>
    </item>
    <item>
      <title>Hierarchical accompanying and inhibiting patterns on the spatial arrangement of taxis' local hotspots</title>
      <link>https://arxiv.org/abs/2310.11806</link>
      <description>arXiv:2310.11806v3 Announce Type: replace 
Abstract: The spatial arrangement of taxi hotspots indicates their inherent distribution relationships, reflecting spatial organization structure and has received attention in urban studies. Previous studies mainly explore large-scale hotspots by visual analysis or simple indexes, where hotspots usually cover the entire central business district, train stations, or dense residential areas, reaching a radius of hundreds or even thousands of meters. However, the spatial arrangement patterns of small-scale hotspots, reflecting the specific popular pick-up and drop-off locations, have not received much attention. This study quantitatively examines the spatial arrangement of fine-grained local hotspots in Wuhan and Beijing, China, using taxi trajectory data. Hotspots are adaptatively identified with sizes of 90m*90m in Wuhan and 105m*105m in Beijing according to identification method. Findings show popular hotspots are typically surrounded by less popular ones, though regions with many popular hotspots inhibit the presence of less popular ones. We term these configurations as hierarchical accompany and inhibiting patterns. Finally, inspired by both patterns, a KNN-based model is developed to describe these relationships, successfully reproducing the spatial distribution of less popular hotspots based on the most popular ones. These insights enhance understanding of local urban structures and support urban planning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.11806v3</guid>
      <category>cs.CY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiao-Jian Chen, Quanhua Dong, Changjiang Xiao, Zhou Huang, Keli Wang, Weiyu Zhang, Yu Liu</dc:creator>
    </item>
    <item>
      <title>The Efficacy of Conversational Artificial Intelligence in Rectifying the Theory of Mind and Autonomy Biases: Comparative Analysis</title>
      <link>https://arxiv.org/abs/2406.13813</link>
      <description>arXiv:2406.13813v5 Announce Type: replace 
Abstract: Background: The increasing deployment of Conversational Artificial Intelligence (CAI) in mental health interventions necessitates an evaluation of their efficacy in rectifying cognitive biases and recognizing affect in human-AI interactions. These biases, including theory of mind and autonomy biases, can exacerbate mental health conditions such as depression and anxiety.
  Objective: This study aimed to assess the effectiveness of therapeutic chatbots (Wysa, Youper) versus general-purpose language models (GPT-3.5, GPT-4, Gemini Pro) in identifying and rectifying cognitive biases and recognizing affect in user interactions.
  Methods: The study employed virtual case scenarios simulating typical user-bot interactions. Cognitive biases assessed included theory of mind biases (anthropomorphism, overtrust, attribution) and autonomy biases (illusion of control, fundamental attribution error, just-world hypothesis). Responses were evaluated on accuracy, therapeutic quality, and adherence to Cognitive Behavioral Therapy (CBT) principles, using an ordinal scale. The evaluation involved double review by cognitive scientists and a clinical psychologist.
  Results: The study revealed that general-purpose chatbots outperformed therapeutic chatbots in rectifying cognitive biases, particularly in overtrust bias, fundamental attribution error, and just-world hypothesis. GPT-4 achieved the highest scores across all biases, while therapeutic bots like Wysa scored the lowest. Affect recognition showed similar trends, with general-purpose bots outperforming therapeutic bots in four out of six biases. However, the results highlight the need for further refinement of therapeutic chatbots to enhance their efficacy and ensure safe, effective use in digital mental health interventions. Future research should focus on improving affective response and addressing ethical considerations in AI-based therapy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13813v5</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Marcin Rz\k{a}deczka, Anna Sterna, Julia Stoli\'nska, Paulina Kaczy\'nska, Marcin Moskalewicz</dc:creator>
    </item>
    <item>
      <title>CourseAssist: Pedagogically Appropriate AI Tutor for Computer Science Education</title>
      <link>https://arxiv.org/abs/2407.10246</link>
      <description>arXiv:2407.10246v2 Announce Type: replace 
Abstract: The growing enrollments in computer science courses and increase in class sizes necessitate scalable, automated tutoring solutions to adequately support student learning. While Large Language Models (LLMs) like GPT-4 have demonstrated potential in assisting students through question-answering, educators express concerns over student overreliance, miscomprehension of generated code, and the risk of inaccurate answers. Rather than banning these tools outright, we advocate for a constructive approach that harnesses the capabilities of AI while mitigating potential risks. This poster introduces CourseAssist, a novel LLM-based tutoring system tailored for computer science education. Unlike generic LLM systems, CourseAssist uses retrieval-augmented generation, user intent classification, and question decomposition to align AI responses with specific course materials and learning objectives, thereby ensuring pedagogical appropriateness of LLMs in educational settings. We evaluated CourseAssist against a baseline of GPT-4 using a dataset of 50 question-answer pairs from a programming languages course, focusing on the criteria of usefulness, accuracy, and pedagogical appropriateness. Evaluation results show that CourseAssist significantly outperforms the baseline, demonstrating its potential to serve as an effective learning assistant. We have also deployed CourseAssist in 6 computer science courses at a large public R1 research university reaching over 500 students. Interviews with 20 student users show that CourseAssist improves computer science instruction by increasing the accessibility of course-specific tutoring help and shortening the feedback loop on their programming assignments. Future work will include extensive pilot testing at more universities and exploring better collaborative relationships between students, educators, and AI that improve computer science learning experiences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10246v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ty Feng, Sa Liu, Dipak Ghosal</dc:creator>
    </item>
    <item>
      <title>Evaluation of LLMs Biases Towards Elite Universities: A Persona-Based Exploration</title>
      <link>https://arxiv.org/abs/2407.12801</link>
      <description>arXiv:2407.12801v2 Announce Type: replace 
Abstract: Elite universities are a dream destination for not just students but also top employers who get a supply of amazing talents. When we hear about top universities, the first thing that comes to mind is their academic rigor, prestigious reputation, and highly successful alumni. However, society at large is not just represented by a few elite universities, but several others. We have seen several examples where many, even without formal education, built big businesses. There are various instances in which several people, however talented, couldn't make it to top elite universities because of several resource constraints. For recruitment of candidates, we do see candidates from a few elite universities well represented in top technology companies. However, we found during our study that LLMs go overboard in representing that. This study investigates whether popular LLMs exhibit bias towards elite universities when generating personas for technology industry professionals. We employed a novel persona-based approach to compare the educational background predictions of GPT-3.5, Gemini, and Claude 3 Sonnet with actual data from LinkedIn. The study focused on various roles at Microsoft, Meta, and Google, including VP Product, Director of Engineering, and Software Engineer. We generated 432 personas across the three LLMs and analyzed the frequency of elite universities (Stanford, MIT, UC Berkeley, and Harvard) in these personas compared to LinkedIn data. Results showed that LLMs significantly overrepresented elite universities, with 72.45% of generated personas featuring these institutions, compared to only 8.56% in the actual LinkedIn data. ChatGPT 3.5 exhibited the highest bias, followed by Claude Sonnet 3, while Gemini performed best. This research highlights the need to address educational bias in LLMs and suggests strategies for mitigating such biases in AI-driven recruitment processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12801v2</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shailja Gupta, Rajesh Ranjan</dc:creator>
    </item>
    <item>
      <title>Dynamics of Ideological Biases of Social Media Users</title>
      <link>https://arxiv.org/abs/2309.15968</link>
      <description>arXiv:2309.15968v2 Announce Type: replace-cross 
Abstract: Humanity for centuries has perfected skills of interpersonal interactions and evolved patterns that enable people to detect lies and deceiving behavior of others in face-to-face settings. Unprecedented growth of people's access to mobile phones and social media raises an important question: How does this new technology influence people's interactions and support the use of traditional patterns? In this article, we answer this question for homophily-driven patterns in social media. In our previous studies, we found that, on a university campus, changes in student opinions were driven by the desire to hold popular opinions. Here, we demonstrate that the evolution of online platform-wide opinion groups is driven by the same desire. We focus on two social media: Twitter and Parler, on which we tracked the political biases of their users. On Parler, an initially stable group of Right-biased users evolved into a permanent Right-leaning echo chamber dominating weaker, transient groups of members with opposing political biases. In contrast, on Twitter, the initial presence of two large opposing bias groups led to the evolution of a bimodal bias distribution, with a high degree of polarization. We capture the movement of users from the initial to final bias groups during the tracking period. We also show that user choices are influenced by side-effects of homophily. Users entering the platform attempt to find a sufficiently large group whose members hold political biases within the range sufficiently close to their own. If successful, they stabilize their biases and become permanent members of the group. Otherwise, they leave the platform. We believe that the dynamics of users' behavior uncovered in this article create a foundation for technical solutions supporting social groups on social media and socially aware networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.15968v2</guid>
      <category>cs.SI</category>
      <category>cs.CY</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/MCOM.001.2300333</arxiv:DOI>
      <arxiv:journal_reference>IEEE Communications Magazine, 62:(5), pp. 36-42, May 3, 2024</arxiv:journal_reference>
      <dc:creator>Mohammed Shahid Modi, James Flamino, Boleslaw K. Szymanski</dc:creator>
    </item>
    <item>
      <title>The Dark Side of NFTs: A Large-Scale Empirical Study of Wash Trading</title>
      <link>https://arxiv.org/abs/2312.12544</link>
      <description>arXiv:2312.12544v3 Announce Type: replace-cross 
Abstract: NFTs (Non-Fungible Tokens) have seen significant growth since they first captured public attention in 2021. However, the NFT market is plagued by fake transactions and economic bubbles, e.g., NFT wash trading. Wash trading typically refers to a transaction involving the same person or two colluding individuals, and has become a major threat to the NFT ecosystem. Previous studies only detect NFT wash trading from the financial aspect, while the real-world wash trading cases are much more complicated (e.g., not aiming at inflating the market value). There is still a lack of multi-dimension analysis to better understand NFT wash trading. Therefore, we present the most comprehensive study of NFT wash trading, analyzing 8,717,031 transfer events and 3,830,141 sale events from 2,701,883 NFTs. We first optimize the dataset collected via the OpenSea API. Next, we identify three types of NFT wash trading and propose identification algorithms. Our experimental results reveal 824 transfer events and 5,330 sale events (accounting for a total of \$8,857,070.41) and 370 address pairs related to NFT wash trading behaviors, causing a minimum loss of \$3,965,247.13. Furthermore, we provide insights from six aspects, i.e., marketplace design, profitability, NFT project design, payment token, user behavior, and NFT ecosystem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.12544v3</guid>
      <category>cs.CR</category>
      <category>cs.CE</category>
      <category>cs.CY</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shijian Chen, Jiachi Chen, Jiangshan Yu, Xiapu Luo, Yanlin Wang</dc:creator>
    </item>
    <item>
      <title>Turing's Test, a Beautiful Thought Experiment</title>
      <link>https://arxiv.org/abs/2401.00009</link>
      <description>arXiv:2401.00009v3 Announce Type: replace-cross 
Abstract: In the wake of the latest trends of artificial intelligence (AI), there has been a resurgence of claims and questions about the Turing test and its value, which are reminiscent of decades of practical "Turing" tests. If AI were quantum physics, by now several "Schr\"odinger's" cats would have been killed. It is time for a historical reconstruction of Turing's beautiful thought experiment. This paper presents a wealth of evidence, including new archival sources, and gives original answers to several open questions about Turing's 1950 paper, including its relation with early AI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.00009v3</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/MAHC.2024.3432278</arxiv:DOI>
      <dc:creator>Bernardo Gon\c{c}alves</dc:creator>
    </item>
    <item>
      <title>A Finger on the Pulse of Cardiovascular: Estimating Blood Pressure with Smartphone Photoplethysmography-Based Pulse Waveform Analysis</title>
      <link>https://arxiv.org/abs/2401.11117</link>
      <description>arXiv:2401.11117v2 Announce Type: replace-cross 
Abstract: Utilizing mobile phone cameras for continuous blood pressure(BP) monitoring presents a cost-effective and accessible approach, yet it is challenged by limitations in accuracy and interpretability. This study introduces four innovative strategies to enhance smartphone-based photoplethysmography for BP estimation(SPW-BP), addressing the interpretability-accuracy dilemma: First, we employ often-neglected data quality improvement techniques, such as height normalization, corrupt data removal, and boundary signal reconstruction; second, we conduct an in-depth analysis of over twenty waveform indicators across three categories to identify the most predictive features; third, we employ SHapley Additive exPlanations(SHAP) analysis to ensure the transparency and explainability of machine learning outcomes; and fourth, we utilize Bland-Altman analysis alongside AAMI and BHS standards for comparative evaluation. Analysis of data from 127 participants demonstrated a significant correlation between smartphone-captured waveform features and those from standard BP monitoring devices. Employing multiple linear regression within a cross-validation framework, waveform variables predicted systolic blood pressure(SBP) with a mean absolute error(MAE) of 9.86 6.78 mmHg and diastolic blood pressure(DBP) with an MAE of 8.01 5.15 mmHg. Further application of Random Forest models significantly improved the prediction MAE for SBP to 8.91 6.30 mmHg and for DBP to 6.68 4.54 mmHg, indicating enhanced predictive accuracy. Correlation and SHAP analysis identified key features for improving BP estimation. However, Bland-Altman analysis revealed systematic biases, and MAE analysis showed that the results did not meet AAMI and BHS accuracy standards. Our findings highlight the potential of SPW-BP, yet suggest that smartphone PPG technology is not yet a viable alternative to traditional medical devices for BP measurement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.11117v2</guid>
      <category>eess.SP</category>
      <category>cs.CY</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ivan Liu, Fangyuan Liu, Qi Zhong, Shiguang Ni</dc:creator>
    </item>
    <item>
      <title>What Radio Waves Tell Us about Sleep</title>
      <link>https://arxiv.org/abs/2405.11739</link>
      <description>arXiv:2405.11739v2 Announce Type: replace-cross 
Abstract: The ability to assess sleep at home, capture sleep stages, and detect the occurrence of apnea (without on-body sensors) simply by analyzing the radio waves bouncing off people's bodies while they sleep is quite powerful. Such a capability would allow for longitudinal data collection in patients' homes, informing our understanding of sleep and its interaction with various diseases and their therapeutic responses, both in clinical trials and routine care. In this article, we develop an advanced machine learning algorithm for passively monitoring sleep and nocturnal breathing from radio waves reflected off people while asleep. Validation results in comparison with the gold standard (i.e., polysomnography) (n=849) demonstrate that the model captures the sleep hypnogram (with an accuracy of 81% for 30-second epochs categorized into Wake, Light Sleep, Deep Sleep, or REM), detects sleep apnea (AUROC = 0.88), and measures the patient's Apnea-Hypopnea Index (ICC=0.95; 95% CI = [0.93, 0.97]). Notably, the model exhibits equitable performance across race, sex, and age. Moreover, the model uncovers informative interactions between sleep stages and a range of diseases including neurological, psychiatric, cardiovascular, and immunological disorders. These findings not only hold promise for clinical practice and interventional trials but also underscore the significance of sleep as a fundamental component in understanding and managing various diseases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11739v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao He, Chao Li, Wolfgang Ganglberger, Kaileigh Gallagher, Rumen Hristov, Michail Ouroutzoglou, Haoqi Sun, Jimeng Sun, Brandon Westover, Dina Katabi</dc:creator>
    </item>
  </channel>
</rss>
