<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 16 Apr 2025 01:59:06 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Learning in Structured Stackelberg Games</title>
      <link>https://arxiv.org/abs/2504.09006</link>
      <description>arXiv:2504.09006v1 Announce Type: new 
Abstract: We study structured Stackelberg games, in which both players (the leader and the follower) observe information about the state of the world at time of play. Importantly, this information may contain information about the follower, which the leader may use when deciding her strategy. Under this setting, we show that no-regret learning is possible if and only if the set of mappings from contexts to follower types that the leader uses to learn is not ``too complex''. Specifically, we find that standard learning theoretic measures of complexity do not characterize learnability in our setting and we give a new dimension which does, which we term the Stackelberg-Littlestone dimension. In the distributional setting, we give analogous results by showing that standard complexity measures do not characterize the sample complexity of learning, but a new dimension called the Stackelberg-Natarajan dimension does. We then show that an appropriate empirical risk minimization procedure achieves the corresponding sample complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.09006v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maria-Florina Balcan, Kiriaki Fragkia, Keegan Harris</dc:creator>
    </item>
    <item>
      <title>Nash Social Welfare with Submodular Valuations: Approximation Algorithms and Integrality Gaps</title>
      <link>https://arxiv.org/abs/2504.09669</link>
      <description>arXiv:2504.09669v1 Announce Type: new 
Abstract: We study the problem of allocating items to agents such that the (un)weighted Nash social welfare (NSW) is maximized under submodular valuations. The best-known results for unweighted and weighted problems are the $(4+\epsilon)$ approximation given by Garg, Husic, Li, Vega, and Vondrak~\cite{stoc/GargHLVV23} and the $(233+\epsilon)$ approximation given by Feng, Hu, Li, and Zhang~\cite{stoc/FHLZ25}, respectively.
  For the weighted NSW problem, we present a $(5.18+\epsilon)$-approximation algorithm, significantly improving the previous approximation ratio and simplifying the analysis. Our algorithm is based on the same configuration LP in~\cite{stoc/FHLZ25}, but with a modified rounding algorithm. For the unweighted NSW problem, we show that the local search-based algorithm in~\cite{stoc/GargHLVV23} is an approximation of $(3.914+\epsilon)$ by more careful analysis.
  On the negative side, we prove that the configuration LP for weighted NSW with submodular valuations has an integrality gap at least $2^{\ln 2}-\epsilon \approx 1.617 - \epsilon$, which is slightly larger than the current best-known $e/(e-1)-\epsilon \approx 1.582-\epsilon$ hardness of approximation~\cite{talg/GargKK23}. For the additive valuation case, we show an integrality gap of $(e^{1/e}-\epsilon)$, which proves that the ratio of $(e^{1/e}+\epsilon)$~\cite{icalp/FengLi24} is tight for algorithms based on the configuration LP. For unweighted NSW with additive valuations, we show a gap of $(2^{1/4}-\epsilon) \approx 1.189-\epsilon$, slightly larger than the current best-known $\sqrt{8/7} \approx 1.069$-hardness for the problem~\cite{mor/Garg0M24}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.09669v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xiaohui Bei, Yuda Feng, Yang Hu, Shi Li, Ruilong Zhang</dc:creator>
    </item>
    <item>
      <title>Dominated Actions in Imperfect-Information Games</title>
      <link>https://arxiv.org/abs/2504.09716</link>
      <description>arXiv:2504.09716v1 Announce Type: new 
Abstract: Dominance is a fundamental concept in game theory. In strategic-form games dominated strategies can be identified in polynomial time. As a consequence, iterative removal of dominated strategies can be performed efficiently as a preprocessing step for reducing the size of a game before computing a Nash equilibrium. For imperfect-information games in extensive form, we could convert the game to strategic form and then iteratively remove dominated strategies in the same way; however, this conversion may cause an exponential blowup in game size. In this paper we define and study the concept of dominated actions in imperfect-information games. Our main result is a polynomial-time algorithm for determining whether an action is dominated (strictly or weakly) by any mixed strategy in n-player games, which can be extended to an algorithm for iteratively removing dominated actions. This allows us to efficiently reduce the size of the game tree as a preprocessing step for Nash equilibrium computation. We explore the role of dominated actions empirically in the "All In or Fold" No-Limit Texas Hold'em poker variant.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.09716v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <category>econ.TH</category>
      <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sam Ganzfried</dc:creator>
    </item>
    <item>
      <title>Fairness and Efficiency in Two-Sided Matching Markets</title>
      <link>https://arxiv.org/abs/2504.10232</link>
      <description>arXiv:2504.10232v1 Announce Type: new 
Abstract: We propose a new fairness notion, motivated by the practical challenge of allocating teaching assistants (TAs) to courses in a department. Each course requires a certain number of TAs and each TA has preferences over the courses they want to assist. Similarly, each course instructor has preferences over the TAs who applied for their course. We demand fairness and efficiency for both sides separately, giving rise to the following criteria: (i) every course gets the required number of TAs and the average utility of the assigned TAs meets a threshold; (ii) the allocation of courses to TAs is envy-free, where a TA envies another TA if the former prefers the latter's course and has a higher or equal grade in that course. Note that the definition of envy-freeness here differs from the one in the literature, and we call it merit-based envy-freeness.
  We show that the problem of finding a merit-based envy-free and efficient matching is NP-hard even for very restricted settings, such as two courses and uniform valuations; constant degree, constant capacity of TAs for every course, valuations in the range {0,1,2,3}, identical valuations from TAs, and even more. To find tractable results, we consider some restricted instances, such as, strict valuation of TAs for courses, the difference between the number of positively valued TAs for a course and the capacity, the number of positively valued TAs/courses, types of valuation functions, and obtained some polynomial-time solvable cases, showing the contrast with intractable results. We further studied the problem in the paradigm of parameterized algorithms and designed some exact and approximation algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10232v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pallavi Jain, Palash Jha, Shubham Solanki</dc:creator>
    </item>
    <item>
      <title>The Price of Competitive Information Disclosure</title>
      <link>https://arxiv.org/abs/2504.10459</link>
      <description>arXiv:2504.10459v1 Announce Type: new 
Abstract: In many decision-making scenarios, individuals strategically choose what information to disclose to optimize their own outcomes. It is unclear whether such strategic information disclosure can lead to good societal outcomes. To address this question, we consider a competitive Bayesian persuasion model in which multiple agents selectively disclose information about their qualities to a principal, who aims to choose the candidates with the highest qualities. Using the price-of-anarchy framework, we quantify the inefficiency of such strategic disclosure. We show that the price of anarchy is at most a constant when the agents have independent quality distributions, even if their utility functions are heterogeneous. This result provides the first theoretical guarantee on the limits of inefficiency in Bayesian persuasion with competitive information disclosure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10459v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siddhartha Banerjee, Kamesh Munagala, Yiheng Shen, Kangning Wang</dc:creator>
    </item>
    <item>
      <title>High dimensional online calibration in polynomial time</title>
      <link>https://arxiv.org/abs/2504.09096</link>
      <description>arXiv:2504.09096v1 Announce Type: cross 
Abstract: In online (sequential) calibration, a forecaster predicts probability distributions over a finite outcome space $[d]$ over a sequence of $T$ days, with the goal of being calibrated. While asymptotically calibrated strategies are known to exist, they suffer from the curse of dimensionality: the best known algorithms require $\exp(d)$ days to achieve non-trivial calibration.
  In this work, we present the first asymptotically calibrated strategy that guarantees non-trivial calibration after a polynomial number of rounds. Specifically, for any desired accuracy $\epsilon &gt; 0$, our forecaster becomes $\epsilon$-calibrated after $T = d^{O(1/\epsilon^2)}$ days. We complement this result with a lower bound, proving that at least $T = d^{\Omega(\log(1/\epsilon))}$ rounds are necessary to achieve $\epsilon$-calibration. Our results resolve the open questions posed by [Abernethy-Mannor'11, Hazan-Kakade'12].
  Our algorithm is inspired by recent breakthroughs in swap regret minimization [Peng-Rubinstein'24, Dagan et al.'24]. Despite its strong theoretical guarantees, the approach is remarkably simple and intuitive: it randomly selects among a set of sub-forecasters, each of which predicts the empirical outcome frequency over recent time windows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.09096v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <category>stat.ML</category>
      <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Binghui Peng</dc:creator>
    </item>
    <item>
      <title>Nash Equilibrium Between Consumer Electronic Devices and DoS Attacker for Distributed IoT-enabled RSE Systems</title>
      <link>https://arxiv.org/abs/2504.09415</link>
      <description>arXiv:2504.09415v1 Announce Type: cross 
Abstract: In electronic consumer Internet of Things (IoT), consumer electronic devices as edge devices require less computational overhead and the remote state estimation (RSE) of consumer electronic devices is always at risk of denial-of-service (DoS) attacks. Therefore, the adversarial strategy between consumer electronic devices and DoS attackers is critical. This paper focuses on the adversarial strategy between consumer electronic devices and DoS attackers in IoT-enabled RSE Systems. We first propose a remote joint estimation model for distributed measurements to effectively reduce consumer electronic device workload and minimize data leakage risks. The Kalman filter is deployed on the remote estimator, and the DoS attacks with open-loop as well as closed-loop are considered. We further introduce advanced reinforcement learning techniques, including centralized and distributed Minimax-DQN, to address high-dimensional decision-making challenges in both open-loop and closed-loop scenarios. Especially, the Q-network instead of the Q-table is used in the proposed approaches, which effectively solves the challenge of Q-learning. Moreover, the proposed distributed Minimax-DQN reduces the action space to expedite the search for Nash Equilibrium (NE). The experimental results validate that the proposed model can expeditiously restore the RSE error covariance to a stable state in the presence of DoS attacks, exhibiting notable attack robustness. The proposed centralized and distributed Minimax-DQN effectively resolves the NE in both open and closed-loop case, showcasing remarkable performance in terms of convergence. It reveals that substantial advantages in both efficiency and stability are achieved compared with the state-of-the-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.09415v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gengcan Chen, Donghong Cai, Zahid Khan, Jawad Ahmad, Wadii Boulila</dc:creator>
    </item>
    <item>
      <title>First-order (coarse) correlated equilibria in non-concave games</title>
      <link>https://arxiv.org/abs/2403.18174</link>
      <description>arXiv:2403.18174v5 Announce Type: replace 
Abstract: We investigate first-order notions of correlated equilibria; distributions of actions for smooth, potentially non-concave games such that players do not incur any regret against small modifications to their strategies along a set of continuous vector fields. We define two such notions, based on local deviations and on stationarity of the distribution, and identify the notion of coarseness as the setting where the strategy modifications are prescribed by gradient fields. For coarse equilibria, we prove that online (projected) gradient decent has a universal approximation property for both variants of equilibrium. In the non-coarse setting, we inspect the problem of computing first-order correlated equilibria through the lens of both recent work based on the framework of ``fixed points in expectation'', and also via the classical framework of Lagrangian hedging, with the goal of identifying tractable instances with additional convergence guarantees. Finally, we study the primal-dual framework to our notion of first-order equilibria. For coarse equilibria defined by a family of functions, we find that a dual bound on the worst-case expectation of a performance metric takes the form of a generalised Lyapunov function for the dynamics of the game. Specifically, usual primal-dual price of anarchy analysis for coarse correlated equilibria as well as the smoothness framework of Roughgarden are both equivalent to a problem of general Lyapunov function estimation. For non-coarse equilibria, we instead observe a vector field fit problem for the gradient dynamics of the game. These follow from containment results in normal form games, and our work overall provides insights on how to tighten equilibrium analysis for gradient-based learning dynamics, as well as delineating notions of first-order equilibrium that may rule out cycling behaviour versus those that do not.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18174v5</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mete \c{S}eref Ahunbay</dc:creator>
    </item>
    <item>
      <title>A Competitive Posted-Price Mechanism for Online Budget-Feasible Auctions</title>
      <link>https://arxiv.org/abs/2502.18265</link>
      <description>arXiv:2502.18265v2 Announce Type: replace 
Abstract: We consider online procurement auctions, where the agents arrive sequentially, in random order, and have private costs for their services. The buyer aims to maximize a monotone submodular value function for the subset of agents whose services are procured, subject to a budget constraint on their payments. We consider a posted-price setting where upon each agent's arrival, the buyer decides on a payment offered to them. The agent accepts or rejects the offer, depending on whether the payment exceeds their cost, without revealing any other information about their private costs whatsoever. We present a randomized online posted-price mechanism with constant competitive ratio, thus resolving the main open question of (Badanidiyuru, Kleinberg and Singer, EC 2012). Posted-price mechanisms for online procurement typically operate by learning an estimation of the optimal value, denoted as OPT, and using it to determine the payments offered to the agents. The main challenge is to learn OPT within a constant factor from the agents' accept / reject responses to the payments offered. Our approach is based on an online test of whether our estimation is too low compared against OPT and a carefully designed adaptive search that gradually refines our estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.18265v2</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andreas Charalampopoulos, Dimitris Fotakis, Panagiotis Patsilinakos, Thanos Tolias</dc:creator>
    </item>
    <item>
      <title>Majority voting is not good for heaven or hell, with mirrored performance</title>
      <link>https://arxiv.org/abs/2401.00592</link>
      <description>arXiv:2401.00592v4 Announce Type: replace-cross 
Abstract: Within the ViSE (Voting in Stochastic Environment) model, we study the effectiveness of majority voting in various environments. By the pit of losses paradox identified in previous work, majority decisions in apparently hostile environments tend to reduce the capital of society. In such cases, the simple social decision rule of "rejecting all proposals without voting" outperforms majority voting. In this paper, we identify another pit of losses appearing in favorable environments. Here, the simple social decision rule of "accepting all proposals without voting" is superior to majority voting. We prove that under a version of simple majority called symmetrized majority and the antisymmetry of the voting body, the second pit of losses is a mirror image of the pit of losses in hostile environments and explain this phenomenon. Technically, we consider a voting society consisting of individualists whose strategy is supporting all proposals that increase their capital and a group (groups) whose members vote to increase the wealth of their group. According to the main result, the expected capital gain of each agent in the environment whose generator $X$ has mean $\mu&gt;0$ exceeds by $\mu$ their expected capital gain under generator $-X$. This result extends to location families of generators with distributions symmetric about their mean. The mentioned result determines the symmetry of the difference between the expected capital gain under the symmetrized majority and that under the "basic" social decision rule that rejects (resp. accepts) all proposals in unfavorable (resp. favorable) environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.00592v4</guid>
      <category>physics.soc-ph</category>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Pavel Chebotarev, Vadim Afonkin</dc:creator>
    </item>
    <item>
      <title>The Problem of Social Cost in Multi-Agent General Reinforcement Learning: Survey and Synthesis</title>
      <link>https://arxiv.org/abs/2412.02091</link>
      <description>arXiv:2412.02091v2 Announce Type: replace-cross 
Abstract: The AI safety literature is full of examples of powerful AI agents that, in blindly pursuing a specific and usually narrow objective, ends up with unacceptable and even catastrophic collateral damage to others. In this paper, we consider the problem of social harms that can result from actions taken by learning and utility-maximising agents in a multi-agent environment. The problem of measuring social harms or impacts in such multi-agent settings, especially when the agents are artificial generally intelligent (AGI) agents, was listed as an open problem in Everitt et al, 2018. We attempt a partial answer to that open problem in the form of market-based mechanisms to quantify and control the cost of such social harms. The proposed setup captures many well-studied special cases and is more general than existing formulations of multi-agent reinforcement learning with mechanism design in two ways: (i) the underlying environment is a history-based general reinforcement learning environment like in AIXI; (ii) the reinforcement-learning agents participating in the environment can have different learning strategies and planning horizons. To demonstrate the practicality of the proposed setup, we survey some key classes of learning algorithms and present a few applications, including a discussion of the Paperclips problem and pollution control with a cap-and-trade system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02091v2</guid>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kee Siong Ng, Samuel Yang-Zhao, Timothy Cadogan-Cowper</dc:creator>
    </item>
    <item>
      <title>TTC Domains</title>
      <link>https://arxiv.org/abs/2501.15422</link>
      <description>arXiv:2501.15422v2 Announce Type: replace-cross 
Abstract: We study the object reallocation problem under strict preferences. On the unrestricted domain, Ekici (2024) showed that the Top Trading Cycles (TTC) mechanism is the unique mechanism that is individually rational, pair efficient, and strategyproof. We provide an alternative proof of this result, assuming only minimal richness of the unrestricted domain. This allows us to identify a broad class of restricted domains, those satisfying our top-two condition, on which the characterization continues to hold. The condition requires that, within any subset of objects, if two objects can each be most-preferred, they can also be the top two most-preferred objects (in both possible orders). We show that this condition is also necessary in the special case of three objects. These results unify and strengthen prior findings on specific domains such as single-peaked and single-dipped domain, and more broadly, offer a useful criterion for analyzing restricted preference domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.15422v2</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sumit Goel, Yuki Tamura</dc:creator>
    </item>
    <item>
      <title>Evolution of Society Caused by Collective and Individual Decisions</title>
      <link>https://arxiv.org/abs/2502.00471</link>
      <description>arXiv:2502.00471v3 Announce Type: replace-cross 
Abstract: Decision-making societies may vary in their level of cooperation and degree of conservatism, both of which influence their overall performance. Moreover, these factors are not fixed -- they can change based on the decisions agents in the society make in their interests. But can these changes lead to cyclical patterns in societal evolution? To explore this question, we use the ViSE (Voting in Stochastic Environment) model. In this framework, the level of cooperation can be measured by group size, while the degree of conservatism is determined by the voting threshold. Agents can adopt either individualistic or group-oriented strategies when voting on stochastically generated external proposals. For Gaussian proposal generators, the expected capital gain (ECG) -- a measure of agents' performance -- can be expressed in standard mathematical functions. Our findings show that in neutral environments, societal evolution with open or democratic groups can follow cyclic patterns. We also find that highly conservative societies or conservative societies with low levels of cooperation can evolve into liberal (less conservative than majoritarian) societies and that mafia groups never let their members go when they want to.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00471v3</guid>
      <category>physics.soc-ph</category>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Pavel Chebotarev</dc:creator>
    </item>
  </channel>
</rss>
