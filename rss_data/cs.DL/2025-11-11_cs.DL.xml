<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DL</link>
    <description>cs.DL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 11 Nov 2025 05:01:03 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>LEAD: LLM-enhanced Engine for Author Disambiguation</title>
      <link>https://arxiv.org/abs/2511.07168</link>
      <description>arXiv:2511.07168v1 Announce Type: new 
Abstract: Author Name Disambiguation (AND) is a long-standing challenge in bibliometrics and scientometrics, as name ambiguity undermines the accuracy of bibliographic databases and the reliability of research evaluation. This study addresses the problem of cross-source disambiguation by linking academic career records from CercaUniversit\`a, the official registry of Italian academics, with author profiles in Scopus. We introduce LEAD (LLM-enhanced Engine for Author Disambiguation), a novel hybrid framework that combines semantic features extracted through Large Language Models (LLMs) with structural evidence derived from co-authorship and citation networks. Using a gold standard of 606 ambiguous cases, we compare five methods: (i) Label Spreading on co-authorship networks; (ii) Bibliographic Coupling on citation networks; (iii) a standalone LLM-based approach; (iv) an LLM-enriched configuration; and (v) the proposed hybrid pipeline. LEAD achieves the best performance (F1 = 96.7%, accuracy = 95.7%) with lower computational cost than full LLM models. Bibliographic Coupling emerges as the fastest and strongest single-source method. These findings demonstrate that integrating semantic and structural signals within a selective hybrid strategy offers a robust and scalable solution to cross-database author identification. Beyond the Italian case, this work highlights the potential of hybrid LLM-based methods to improve data quality and reliability in scientometric analyses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07168v1</guid>
      <category>cs.DL</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giusy Giulia Tuccari, Lorenzo Giammei, Andrea Giovanni Nuzzolese, Misael Mongiov\`i, Antonio Zinilli, Francesco Poggi</dc:creator>
    </item>
    <item>
      <title>Accessibility Gaps in U.S. Government Dashboards for Blind and Low-Vision Residents</title>
      <link>https://arxiv.org/abs/2511.06688</link>
      <description>arXiv:2511.06688v1 Announce Type: cross 
Abstract: Public dashboards are now a common way for US government agencies to share high stakes information with residents. We audited six live systems at federal, state, and city levels: CDC respiratory illness, HUD homelessness PIT and HIC, California HCD Annual Progress Report, New York City Mayor's Management Report, Houston Permitting, and Chicago public health and budget dashboards. Using a rubric based on screen reader needs and WCAG, we checked five items: (1) discoverability of key metrics by assistive tech, (2) keyboard access without mouse hover, (3) clear semantic labels for axes, series, and categories, (4) short plain language status and trend notes, and (5) machine readable tables or CSVs that mirror what sighted users see. Findings are mixed. Many charts fail basic discoverability or depend on hover, which blocks keyboard and screen reader use. Plain language summaries are common in CDC and Chicago, but rare in HUD and Houston. Machine readable data is strong for NYC, California, and HUD; it is weaker or unclear for Houston. Several sites promise service for the public or for customers yet do not name accessibility in their descriptions. Across systems we also observe urgency inversion: faster, operational dashboards tend to provide fewer accessible affordances than slower accountability dashboards. These patterns matter for equal participation and for ADA Title II compliance that references WCAG 2.1 AA. We propose three steps for any public dashboard: add a brief status and trend text at the same update cadence, publish a matching table or CSV of the visual metrics, and state an explicit accessibility commitment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06688v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <category>cs.DL</category>
      <category>cs.IR</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chadani Acharya</dc:creator>
    </item>
    <item>
      <title>A Quantitative Approach to Estimating Bias, Favouritism and Distortion in Scientific Journalism</title>
      <link>https://arxiv.org/abs/2510.21838</link>
      <description>arXiv:2510.21838v4 Announce Type: replace 
Abstract: While traditionally not considered part of the scientific method, science communication is increasingly playing a pivotal role in shaping scientific practice. Researchers are now frequently compelled to publicise their findings in response to institutional impact metrics and competitive grant environments. This shift underscores the growing influence of media narratives on both scientific priorities and public perception. In a current trend of personality-driven reporting, we examine patterns in science communication that may indicate biases of different types, towards topics and researchers. We focused and applied our methodology to a corpus of media coverage from three of the most prominent scientific media outlets: Wired, Quanta, and The New Scientist -- spanning the past 5 to 10 years. By mapping linguistic patterns, citation flows, and topical convergence, our objective was to quantify the dimensions and degree of bias that influence the credibility of scientific journalism. In doing so, we seek to illuminate the systemic features that shape science communication today and to interrogate their broader implications for epistemic integrity and public accountability in science. We present our results with anonymised journalist names but conclude that personality-driven media coverage distorts science and the practice of science flattening rather than expanding scientific coverage perception. Keywords : selective sourcing, bias, scientific journalism, Quanta, Wired, New Scientist, fairness, balance, neutrality, standard practices, distortion, personal promotion, communication, media outlets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21838v4</guid>
      <category>cs.DL</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Raghavendra Koushik, Hector Zenil</dc:creator>
    </item>
    <item>
      <title>Incorrect Citation Association for Articles in Online-Only Springer Nature Journals</title>
      <link>https://arxiv.org/abs/2511.01675</link>
      <description>arXiv:2511.01675v2 Announce Type: replace 
Abstract: We show that citation metrics of journal articles in many of the online-only Springer Nature journals and associated ones are distorted, going back to articles from 2001. We find that most likely due to an API response error, there are many incorrect references which typically lead to Article Number 1 of a given Volume. Among others, the issue affects journals such as Scientific Reports, Nature Communications, Communications journals, Cell Death &amp; Disease, Light: Science &amp; Applications, as well as many BMC, Discovery and npj journals. Beyond the negative effect of introducing incorrect reference information, this distorts the citation statistics of articles in these journals, with a few articles being massively over-cited compared to their peers, while many lose citations; e.g. both in Scientific Reports and in Nature Communications, 5 of the 10 top cited articles have article numbers of 1. We validate the distorted statistics by assessing data from multiple scientific literature databases: Crossref, OpenCitations, Semantic Scholar, and the journals' websites. The issue primarily arises from the inconsistent transition from page-based referencing of articles to article number-based referencing, as well as the improper handling of the change in the publisher's article metadata API. It seems that the most pressing problem has been present since approximately 2011, which we estimate affects the citation count of millions of authors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01675v2</guid>
      <category>cs.DL</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tam\'as Kriv\'achy</dc:creator>
    </item>
  </channel>
</rss>
