<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 19 Jan 2026 05:00:23 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 19 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Non-uniformly Stable Common Independent Sets</title>
      <link>https://arxiv.org/abs/2601.11153</link>
      <description>arXiv:2601.11153v1 Announce Type: new 
Abstract: In this paper, we consider a matroid generalization of the stable matching problem. In particular, we consider the setting where preferences may contain ties. For this generalization, we propose a polynomial-time algorithm for the problem of checking the existence of a common independent set satisfying non-uniform stability, which is a common generalization of super-stability and strong stability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.11153v1</guid>
      <category>cs.GT</category>
      <pubDate>Mon, 19 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Naoyuki Kamiyama</dc:creator>
    </item>
    <item>
      <title>Institutional AI: Governing LLM Collusion in Multi-Agent Cournot Markets via Public Governance Graphs</title>
      <link>https://arxiv.org/abs/2601.11369</link>
      <description>arXiv:2601.11369v1 Announce Type: new 
Abstract: Multi-agent LLM ensembles can converge on coordinated, socially harmful equilibria. This paper advances an experimental framework for evaluating Institutional AI, our system-level approach to AI alignment that reframes alignment from preference engineering in agent-space to mechanism design in institution-space. Central to this approach is the governance graph, a public, immutable manifest that declares legal states, transitions, sanctions, and restorative paths; an Oracle/Controller runtime interprets this manifest, attaching enforceable consequences to evidence of coordination while recording a cryptographically keyed, append-only governance log for audit and provenance. We apply the Institutional AI framework to govern the Cournot collusion case documented by prior work and compare three regimes: Ungoverned (baseline incentives from the structure of the Cournot market), Constitutional (a prompt-only policy-as-prompt prohibition implemented as a fixed written anti-collusion constitution, and Institutional (governance-graph-based). Across six model configurations including cross-provider pairs (N=90 runs/condition), the Institutional regime produces large reductions in collusion: mean tier falls from 3.1 to 1.8 (Cohen's d=1.28), and severe-collusion incidence drops from 50% to 5.6%. The prompt-only Constitutional baseline yields no reliable improvement, illustrating that declarative prohibitions do not bind under optimisation pressure. These results suggest that multi-agent alignment may benefit from being framed as an institutional design problem, where governance graphs can provide a tractable abstraction for alignment-relevant collective behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.11369v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <pubDate>Mon, 19 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marcantonio Bracale Syrnikov, Federico Pierucci, Marcello Galisai, Matteo Prandi, Piercosma Bisconti, Francesco Giarrusso, Olga Sorokoletova, Vincenzo Suriani, Daniele Nardi</dc:creator>
    </item>
    <item>
      <title>Minimizing the Cost of EFx Allocations</title>
      <link>https://arxiv.org/abs/2601.11372</link>
      <description>arXiv:2601.11372v1 Announce Type: new 
Abstract: Ensuring fairness while limiting costs, such as transportation or storage, is an important challenge in resource allocation, yet most work has focused on cost minimization without fairness or fairness without explicit cost considerations. We introduce and formally define the minCost-EFx Allocation problem, where the objective is to compute an allocation that is envy-free up to any item (EFx) and has minimum cost. We investigate the algorithmic complexity of this problem, proving that it is NP-hard already with two agents. On the positive side, we show that the problem admits a polynomial kernel with respect to the number of items, implying that a core source of intractability lies in the number of items. Building on this, we identify parameter-restricted settings that are tractable, including cases with bounded valuations and a constant number of agents, or a limited number of item types under restricted cost models. Finally, we turn to cost approximation, proving that for any $\rho&gt;1$ the problem is not $\rho$-approximable in polynomial time (unless $P=NP$), while also identifying restricted cost models where costs are agent-specific and independent of the actual items received, which admit better approximation guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.11372v1</guid>
      <category>cs.GT</category>
      <category>cs.CC</category>
      <pubDate>Mon, 19 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eva Deltl</dc:creator>
    </item>
    <item>
      <title>New Adaptive Mechanism for Large Neighborhood Search using Dual Actor-Critic</title>
      <link>https://arxiv.org/abs/2601.11414</link>
      <description>arXiv:2601.11414v1 Announce Type: new 
Abstract: Adaptive Large Neighborhood Search (ALNS) is a widely used heuristic method for solving combinatorial optimization problems. ALNS explores the solution space by iteratively using destroy and repair operators with probabilities, which are adjusted by an adaptive mechanism to find optimal solutions. However, the classic ALNS adaptive mechanism does not consider the interaction between destroy and repair operators when selecting them. To overcome this limitation, this study proposes a novel adaptive mechanism. This mechanism enhances the adaptability of the algorithm through a Dual Actor-Critic (DAC) model, which fully considers the fact that the quality of new solutions is jointly determined by the destroy and repair operators. It effectively utilizes the interaction between these operators during the weight adjustment process, greatly improving the adaptability of the ALNS algorithm. In this mechanism, the destroy and repair processes are modeled as independent Markov Decision Processes to guide the selection of operators more accurately. Furthermore, we use Graph Neural Networks to extract key features from problem instances and perform effective aggregation and normalization to enhance the algorithm's transferability to different sizes and characteristics of problems. Through a series of experiments, we demonstrate that the proposed DAC-ALNS algorithm significantly improves solution efficiency and exhibits excellent transferability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.11414v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Mon, 19 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shaohua Yu, Wenhao Mao, Zigao Wu, Jakob Puchinger</dc:creator>
    </item>
    <item>
      <title>The Poisoned Apple Effect: Strategic Manipulation of Mediated Markets via Technology Expansion of AI Agents</title>
      <link>https://arxiv.org/abs/2601.11496</link>
      <description>arXiv:2601.11496v1 Announce Type: new 
Abstract: The integration of AI agents into economic markets fundamentally alters the landscape of strategic interaction. We investigate the economic implications of expanding the set of available technologies in three canonical game-theoretic settings: bargaining (resource division), negotiation (asymmetric information trade), and persuasion (strategic information transmission). We find that simply increasing the choice of AI delegates can drastically shift equilibrium payoffs and regulatory outcomes, often creating incentives for regulators to proactively develop and release technologies. Conversely, we identify a strategic phenomenon termed the "Poisoned Apple" effect: an agent may release a new technology, which neither they nor their opponent ultimately uses, solely to manipulate the regulator's choice of market design in their favor. This strategic release improves the releaser's welfare at the expense of their opponent and the regulator's fairness objectives. Our findings demonstrate that static regulatory frameworks are vulnerable to manipulation via technology expansion, necessitating dynamic market designs that adapt to the evolving landscape of AI capabilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.11496v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.MA</category>
      <pubDate>Mon, 19 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eilam Shapira, Roi Reichart, Moshe Tennenholtz</dc:creator>
    </item>
    <item>
      <title>LLMs for Game Theory: Entropy-Guided In-Context Learning and Adaptive CoT Reasoning</title>
      <link>https://arxiv.org/abs/2601.10775</link>
      <description>arXiv:2601.10775v1 Announce Type: cross 
Abstract: We propose a novel LLM-based framework for reasoning in discrete, game-theoretic tasks, illustrated with \emph{Tic-Tac-Toe}. The method integrates in-context learning with entropy-guided chain-of-thought (CoT) reasoning and adaptive context retrieval. The model dynamically adjusts both the number of retrieved examples and reasoning paths according to token-level uncertainty: concise reasoning with minimal context is used when uncertainty is low, whereas higher uncertainty triggers expanded multi-path CoT exploration. Experimental evaluation against a sub-optimal algorithmic opponent shows that entropy-aware adaptive reasoning substantially improves decision quality, increasing the average game outcome from \(-11.6\%\) with the baseline LLM to \(+9.5\%\) with entropy-guided adaptive reasoning over 100 games (win = +1, tie = 0, loss = -1), while maintaining a relatively low number of LLM queries per game. Statistical validation confirms that the improvement is significant, and correlation analysis reveals a negative association between token-level entropy and move optimality. These findings demonstrate that uncertainty-guided adaptive reasoning effectively enhances LLM performance in sequential decision-making environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10775v1</guid>
      <category>cs.CL</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Mon, 19 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tommaso Felice Banfi, Sashenka Gamage</dc:creator>
    </item>
    <item>
      <title>The incompatibility of the Condorcet winner and loser criteria with positive involvement and resolvability</title>
      <link>https://arxiv.org/abs/2601.10506</link>
      <description>arXiv:2601.10506v2 Announce Type: replace-cross 
Abstract: We prove that there is no preferential voting method satisfying the Condorcet winner and loser criteria, positive involvement (if a candidate $x$ wins in an initial preference profile, then adding a voter who ranks $x$ uniquely first cannot cause $x$ to lose), and $n$-voter resolvability (if $x$ initially ties for winning, then $x$ can be made the unique winner by adding up to $n$ voters). In a previous note, we proved an analogous result assuming an additional axiom of ordinal margin invariance, which we now show is unnecessary for an impossibility theorem, at least if the desired voting method is defined for five-candidate elections.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10506v2</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Mon, 19 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wesley H. Holliday</dc:creator>
    </item>
  </channel>
</rss>
