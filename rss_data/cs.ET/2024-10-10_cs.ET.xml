<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 11 Oct 2024 02:24:50 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Tactile Displays Driven by Projected Light</title>
      <link>https://arxiv.org/abs/2410.05494</link>
      <description>arXiv:2410.05494v1 Announce Type: new 
Abstract: Tactile displays that lend tangible form to digital content could profoundly transform how we interact with computers, much like visual displays have driven successive revolutions in computing over the past 60 years. However, creating tactile displays with the actuation speeds, dynamic ranges, and resolutions that are required for perceptual fidelity has proved challenging. Here, we present a tactile display that directly converts projected light into visible tactile patterns using an energetically passive, photomechanical surface populated with arrays of millimeter-scale optotactile pixels. The pixels transduce incident light into mechanical displacements through rapid, light-stimulated thermal gas expansion, yielding displacements of up to 1 millimeter and response times of 2 to 100 milliseconds. Our use of projected light for power transmission and addressing enables these displays to be scaled in size and resolution at sustainable cost and complexity. We demonstrate devices with up to 1,511 independently addressable pixels. Perceptual studies confirm the capacity of the display to accurately reproduce tactile patterns in location, timing, frequency, and structure. This research establishes a foundation for practical, versatile high-resolution tactile displays driven by light.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05494v1</guid>
      <category>cs.ET</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Max Linannder, Dustin Goetz, Gregory Reardon, Elliot Hawkes, Yon Visell</dc:creator>
    </item>
    <item>
      <title>SpecTrack: Learned Multi-Rotation Tracking via Speckle Imaging</title>
      <link>https://arxiv.org/abs/2410.06028</link>
      <description>arXiv:2410.06028v1 Announce Type: new 
Abstract: Precision pose detection is increasingly demanded in fields such as personal fabrication, Virtual Reality (VR), and robotics due to its critical role in ensuring accurate positioning information. However, conventional vision-based systems used in these systems often struggle with achieving high precision and accuracy, particularly when dealing with complex environments or fast-moving objects. To address these limitations, we investigate Laser Speckle Imaging (LSI), an emerging optical tracking method that offers promising potential for improving pose estimation accuracy. Specifically, our proposed LSI-Based Tracking (SpecTrack) leverages the captures from a lensless camera and a retro-reflector marker with a coded aperture to achieve multi-axis rotational pose estimation with high precision. Our extensive trials using our in-house built testbed have shown that SpecTrack achieves an accuracy of 0.31{\deg} (std=0.43{\deg}), significantly outperforming state-of-the-art approaches and improving accuracy up to 200%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06028v1</guid>
      <category>cs.ET</category>
      <category>cs.CV</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3681756.3697875</arxiv:DOI>
      <dc:creator>Ziyang Chen, Mustafa Do\u{g}a Do\u{g}an, Josef Spjut, Kaan Ak\c{s}it</dc:creator>
    </item>
    <item>
      <title>An Intelligent Native Network Slicing Security Architecture Empowered by Federated Learning</title>
      <link>https://arxiv.org/abs/2410.05312</link>
      <description>arXiv:2410.05312v1 Announce Type: cross 
Abstract: Network Slicing (NS) has transformed the landscape of resource sharing in networks, offering flexibility to support services and applications with highly variable requirements in areas such as the next-generation 5G/6G mobile networks (NGMN), vehicular networks, industrial Internet of Things (IoT), and verticals. Although significant research and experimentation have driven the development of network slicing, existing architectures often fall short in intrinsic architectural intelligent security capabilities. This paper proposes an architecture-intelligent security mechanism to improve the NS solutions. We idealized a security-native architecture that deploys intelligent microservices as federated agents based on machine learning, providing intra-slice and architectural operation security for the Slicing Future Internet Infrastructures (SFI2) reference architecture. It is noteworthy that federated learning approaches match the highly distributed modern microservice-based architectures, thus providing a unifying and scalable design choice for NS platforms addressing both service and security. Using ML-Agents and Security Agents, our approach identified Distributed Denial-of-Service (DDoS) and intrusion attacks within the slice using generic and non-intrusive telemetry records, achieving an average accuracy of approximately $95.60\%$ in the network slicing architecture and $99.99\%$ for the deployed slice -- intra-slice. This result demonstrates the potential for leveraging architectural operational security and introduces a promising new research direction for network slicing architectures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05312v1</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.future.2024.107537</arxiv:DOI>
      <arxiv:journal_reference>Future Generation Computer Systems (FGCS); ISSN:0167-739X; 2024</arxiv:journal_reference>
      <dc:creator>Rodrigo Moreira, Rodolfo S. Villaca, Moises R. N. Ribeiro, Joberto S. B. Martins, Joao Henrique Correa, Tereza C. Carvalho, Flavio de Oliveira Silva</dc:creator>
    </item>
    <item>
      <title>Waveguide-multiplexed photonic matrix-vector multiplication processor using multiport photodetectors</title>
      <link>https://arxiv.org/abs/2410.05956</link>
      <description>arXiv:2410.05956v1 Announce Type: cross 
Abstract: The slowing down of Moore's law has driven the development of application-specific processors for deep learning. Analog photonic processors offer a promising solution for accelerating matrix-vector multiplications (MVMs) in deep learning by leveraging parallel computations in the optical domain. Intensity-based photonic MVM processors, which do not utilize the phase information of light, are appealing due to their simplified operations. However, existing intensity-based schemes for such processors often employ wavelength multiplexing or mode multiplexing, both of which have limited scalability due to high insertion loss or wavelength crosstalk. In this work, we present a scalable intensity-based photonic MVM processor based on the concept of waveguide multiplexing. This scheme employs multiport photodetectors (PDs) to sum the intensities of multiple optical signals, eliminating the need for multiple wavelengths or modes. A 16-port Ge PD with a 3 dB bandwidth of 11.8 GHz at a bias voltage of -3 V is demonstrated, and it can be further scaled up to handle 250 ports while maintaining a 6.1 GHz operation bandwidth. A 4 $\times$ 4 circuit fabricated on a Si-on-insulator (SOI) platform is used to perform MVMs in a 3-layer neural network designed for classifying Iris flowers, achieving a classification accuracy of 93.3%. Furthermore, the performance of large-scale circuits in a convolutional neural network (CNN) for Fashion-MNIST is simulated, resulting in a classification accuracy of 90.53%. This work provides a simplified and scalable approach to photonic MVM, laying a foundation for large-scale and multi-dimensional photonic matrix-matrix multiplication in optical neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05956v1</guid>
      <category>physics.optics</category>
      <category>cs.ET</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rui Tang, Makoto Okano, Chao Zhang, Kasidit Toprasertpong, Shinichi Takagi, Mitsuru Takenaka</dc:creator>
    </item>
    <item>
      <title>RealityCraft: An In-Situ CAD+CAM Interface for Novices via Scene-Aware Augmented Reality</title>
      <link>https://arxiv.org/abs/2410.06113</link>
      <description>arXiv:2410.06113v1 Announce Type: cross 
Abstract: Despite the growing accessibility of augmented reality (AR) for visualization, existing computer-aided design systems remain largely confined to traditional screens and are often inaccessible to novice users due to their complexity. We present RealityCraft, an open-sourced AR interface that enables in-situ computer-aided design and manufacturing (CAD+CAM) for novices. Unlike traditional CAD systems confined to computer screens, RealityCraft allows users to design directly within their physical environments, with primitive geometries. RealityCraft recognizes and utilizes physical constraints such as furniture and walls, enhancing user interaction through spatial awareness and depth occlusion. Furthermore, RealityCraft features an integrated AR-based 3D printing workflow, where users can drag and drop designs onto their 3D printer's virtual twin in their immediate space. Through a user study, we demonstrate that RealityCraft enhances engagement and ease of use for novices. By bridging the gap between digital creation and physical output, RealityCraft aims to transform everyday spaces into creative studios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06113v1</guid>
      <category>cs.HC</category>
      <category>cs.ET</category>
      <category>cs.GR</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>O\u{g}uz Arslan, Artun Akdo\u{g}an, Mustafa Doga Dogan</dc:creator>
    </item>
    <item>
      <title>A QUBO Formulation for the Generalized LinkedIn Queens Game</title>
      <link>https://arxiv.org/abs/2410.06429</link>
      <description>arXiv:2410.06429v1 Announce Type: cross 
Abstract: In this paper, we present a QUBO formulation designed to solve a series of generalisations of the LinkedIn queens game, a version of the N-queens problem. We adapt this formulation for several particular cases of the problem by trying to optimise the number of variables and interactions, improving the possibility of applying it on quantum hardware by means of Quantum Annealing or the Quantum Approximated Optimization Algorithm (QAOA). We also present two new types of problems, the Coloured Chess Piece Problem and the Max Chess Pieces Problem, with their corresponding QUBO formulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06429v1</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <category>physics.pop-ph</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alejandro Mata Ali, Edgar Mencia</dc:creator>
    </item>
    <item>
      <title>In-Band Full-Duplex MIMO Systems for Simultaneous Communications and Sensing: Challenges, Methods, and Future Perspectives</title>
      <link>https://arxiv.org/abs/2410.06512</link>
      <description>arXiv:2410.06512v1 Announce Type: cross 
Abstract: In-band Full-Duplex (FD) Multiple-Input Multiple-Output (MIMO) systems offer a significant opportunity for Integrated Sensing and Communications (ISAC) due to their capability to realize simultaneous signal transmissions and receptions. This feature has been recently exploited to devise spectrum-efficient simultaneous information transmission and monostatic sensing operations, a line of research typically referred to as MIMO FD-ISAC. In this article, capitalizing on a recent FD MIMO architecture with reduced complexity analog cancellation, we present an FD-enabled framework for simultaneous communications and sensing using data signals. In contrast to communications applications, the framework's goal is not to mitigate self interference, since it includes reflections of the downlink data transmissions from targets in the FD node's vicinity, but to optimize the system parameters for the intended dual functionality. The unique characteristics and challenges of a generic MIMO FD-ISAC system are discussed along with a broad overview of state-of-the-art special cases, including numerical investigations. Several directions for future work on FD-enabled ISAC relevant to signal processing communities are also provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06512v1</guid>
      <category>cs.IT</category>
      <category>cs.ET</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Besma Smida, George C. Alexandropoulos, Taneli Riihonen, Md Atiqul Islam</dc:creator>
    </item>
    <item>
      <title>Fourier-based Action Recognition for Wildlife Behavior Quantification with Event Cameras</title>
      <link>https://arxiv.org/abs/2410.06698</link>
      <description>arXiv:2410.06698v1 Announce Type: cross 
Abstract: Event cameras are novel bio-inspired vision sensors that measure pixel-wise brightness changes asynchronously instead of images at a given frame rate. They offer promising advantages, namely a high dynamic range, low latency, and minimal motion blur. Modern computer vision algorithms often rely on artificial neural network approaches, which require image-like representations of the data and cannot fully exploit the characteristics of event data. We propose approaches to action recognition based on the Fourier Transform. The approaches are intended to recognize oscillating motion patterns commonly present in nature. In particular, we apply our approaches to a recent dataset of breeding penguins annotated for "ecstatic display", a behavior where the observed penguins flap their wings at a certain frequency. We find that our approaches are both simple and effective, producing slightly lower results than a deep neural network (DNN) while relying just on a tiny fraction of the parameters compared to the DNN (five orders of magnitude fewer parameters). They work well despite the uncontrolled, diverse data present in the dataset. We hope this work opens a new perspective on event-based processing and action recognition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06698v1</guid>
      <category>cs.CV</category>
      <category>cs.ET</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Friedhelm Hamann, Suman Ghosh, Ignacio Juarez Martinez, Tom Hart, Alex Kacelnik, Guillermo Gallego</dc:creator>
    </item>
    <item>
      <title>RIS-Assisted ISAC: Precoding and Phase-Shift Optimization for Mono-Static Target Detection</title>
      <link>https://arxiv.org/abs/2410.06855</link>
      <description>arXiv:2410.06855v1 Announce Type: cross 
Abstract: The reconfigurable intelligent surface (RIS) technology emerges as a highly useful component of the rapidly evolving integrated sensing and communications paradigm, primarily owing to its remarkable signal-to-noise ratio enhancement capabilities. In this paper, our focus is on mono-static target detection while considering the communication requirement of a user equipment. Both sensing and communication benefit from the presence of an RIS, which makes the channels richer and stronger. Diverging from prior research, we comprehensively examine three target echo paths: the direct (static) channel path, the path via the RIS, and a combination of these, each characterized by distinct radar cross sections (RCSs). We take both the line-of-sight (LOS) and the non-line-of-sight (NLOS) paths into account under a clutter for which the distribution is not known, but the low-rank subspace it resides. We derive the generalized likelihood ratio test (GLRT) detector and introduce a novel approach for jointly optimizing the configuration of RIS phase-shifts and precoding. Our simulation results underscore the paramount importance of this combined design in terms of enhancing detection probability. Moreover, it becomes evident that the derived clutter-aware target detection significantly enhances detection performance, especially when the clutter is strong.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06855v1</guid>
      <category>eess.SP</category>
      <category>cs.ET</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>\"Ozlem Tu\u{g}fe Demir, Emil Bj\"ornson</dc:creator>
    </item>
    <item>
      <title>To Be or Not to Be (in the EU): Measurement of Discrepancies Presented in Cookie Paywalls</title>
      <link>https://arxiv.org/abs/2410.06920</link>
      <description>arXiv:2410.06920v2 Announce Type: cross 
Abstract: Cookie paywalls allow visitors to access the content of a website only after making a choice between paying a fee (paying option) or accepting tracking (cookie option). The practice has been studied in previous research in regard to its prevalence and legal standing, but the effects of the clients' device and geographic location remain unexplored. To address these questions, this study explores the effects of three factors: 1) the clients' browser, 2) the device type (desktop or mobile), and 3) the geographic location on the presence and behavior of cookie paywalls and the handling of users' data.
  Using an automatic crawler on our dataset composed of 804 websites that present a cookie paywall, we observed that the presence of a cookie paywall was most affected by the geographic location of the user. We further showed that both the behavior of a cookie paywall and the processing of user data are impacted by all three factors, but no patterns of significance could be found. Finally, an additional type of paywall was discovered to be used on approximately 11% of the studied websites, coined the "double paywall", which consists of a cookie paywall complemented by another paywall once tracking is accepted.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06920v2</guid>
      <category>cs.CY</category>
      <category>cs.ET</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andreas Stenwreth, Simon T\"ang, Victor Morel</dc:creator>
    </item>
    <item>
      <title>Farmer.Chat: Scaling AI-Powered Agricultural Services for Smallholder Farmers</title>
      <link>https://arxiv.org/abs/2409.08916</link>
      <description>arXiv:2409.08916v2 Announce Type: replace 
Abstract: Small and medium-sized agricultural holders face challenges like limited access to localized, timely information, impacting productivity and sustainability. Traditional extension services, which rely on in-person agents, struggle with scalability and timely delivery, especially in remote areas. We introduce FarmerChat, a generative AI-powered chatbot designed to address these issues. Leveraging Generative AI, FarmerChat offers personalized, reliable, and contextually relevant advice, overcoming limitations of previous chatbots in deterministic dialogue flows, language support, and unstructured data processing. Deployed in four countries, FarmerChat has engaged over 15,000 farmers and answered over 300,000 queries. This paper highlights how FarmerChat's innovative use of GenAI enhances agricultural service scalability and effectiveness. Our evaluation, combining quantitative analysis and qualitative insights, highlights FarmerChat's effectiveness in improving farming practices, enhancing trust, response quality, and user engagement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08916v2</guid>
      <category>cs.ET</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Namita Singh, Jacqueline Wang'ombe, Nereah Okanga, Tetyana Zelenska, Jona Repishti, Jayasankar G K, Sanjeev Mishra, Rajsekar Manokaran, Vineet Singh, Mohammed Irfan Rafiq, Rikin Gandhi, Akshay Nambi</dc:creator>
    </item>
    <item>
      <title>Stress-induced Artificial neuron spiking in Diffusive memristors</title>
      <link>https://arxiv.org/abs/2306.12853</link>
      <description>arXiv:2306.12853v2 Announce Type: replace-cross 
Abstract: Diffusive memristors owing to their ability to produce current spiking when a constant or slowly changing voltage is applied are competitive candidates for the development of artificial electronic neurons. These artificial neurons can be integrated into various prospective autonomous and robotic systems as sensors, e.g. ones implementing object grasping and classification. We report here Ag nanoparticle-based diffusive memristor prepared on a flexible polyethylene terephthalate (PET) substrate in which the electric spiking behaviour was induced by the electric voltage under an additional stimulus of external mechanical impact. By changing the magnitude and frequency of the mechanical impact, we are able to manipulate the spiking response of our artificial neuron. This functionality to control the spiking characterstics paves a pathway for the development of touch-perception sensors that can convert local pressure into electrical spikes for further processing in neural networks. We have proposed a mathematical model which captures the operation principle of the fabricated memristive sensors and qualitatively describes the measured spiking behaviour.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.12853v2</guid>
      <category>physics.app-ph</category>
      <category>cs.ET</category>
      <category>physics.ins-det</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Debi Pattnaik, Yash Sharma, Sergey Saveliev, Pavel Borisov, Amir Akther, Alexander Balanov, Pedro Ferreira</dc:creator>
    </item>
    <item>
      <title>120 GOPS Photonic Tensor Core in Thin-film Lithium Niobate for Inference and in-situ Training</title>
      <link>https://arxiv.org/abs/2311.16896</link>
      <description>arXiv:2311.16896v3 Announce Type: replace-cross 
Abstract: Photonics offers a transformative approach to artificial intelligence (AI) and neuromorphic computing by enabling low-latency, high-speed, and energy-efficient computations. However, conventional photonic tensor cores face significant challenges in constructing large-scale photonic neuromorphic networks. Here, we propose a fully integrated photonic tensor core, consisting of only two thin-film lithium niobate (TFLN) modulators, a III-V laser, and a charge-integration photoreceiver. Despite its simple architecture, it is capable of implementing an entire layer of a neural network with a computational speed of 120 GOPS, while also allowing flexible adjustment of the number of inputs (fan-in) and outputs (fan-out). Our tensor core supports rapid in-situ training with a weight update speed of 60 GHz. Furthermore, it successfully classifies (supervised learning) and clusters (unsupervised learning) 112 * 112-pixel images through in-situ training. To enable in-situ training for clustering AI tasks, we offer a solution for performing multiplications between two negative numbers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.16896v3</guid>
      <category>physics.optics</category>
      <category>cs.ET</category>
      <category>physics.app-ph</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhongjin Lin, Bhavin J. Shastri, Shangxuan Yu, Jingxiang Song, Yuntao Zhu, Arman Safarnejadian, Wangning Cai, Yanmei Lin, Wei Ke, Mustafa Hammood, Tianye Wang, Mengyue Xu, Zibo Zheng, Mohammed Al-Qadasi, Omid Esmaeeli, Mohamed Rahim, Grzegorz Pakulski, Jens Schmid, Pedro Barrios, Weihong Jiang, Hugh Morison, Matthew Mitchell, Xun Guan, Nicolas A. F. Jaeger, Leslie A. n Rusch, Sudip Shekhar, Wei Shi, Siyuan Yu, Xinlun Cai, Lukas Chrostowski</dc:creator>
    </item>
    <item>
      <title>Hybrid Quantum-inspired Resnet and Densenet for Pattern Recognition</title>
      <link>https://arxiv.org/abs/2403.05754</link>
      <description>arXiv:2403.05754v4 Announce Type: replace-cross 
Abstract: In this paper, we propose two hybrid quantum-inspired neural networks with residual and dense connections respectively for pattern recognition. We explain the concrete frameworks and illustrate the potential superiority to prevent gradient explosion of our hybrid models. A group of numerical experiments about generalization power shows that our hybrid models possess the same generalization power as the pure classical models with different noisy datasets utilized. More importantly, another group of numerical experiments of robustness demonstrates that our hybrid models outperform pure classical models notably in resistance to parameter attacks with various asymmetric noises. Also, an ablation study indicate that the recognition accuracy of our hybrid models is 2\%-3\% higher than that of the quantum neural network without residual or dense connection. Eventually, we discuss the application scenarios of our hybrid models by analyzing their computational complexities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05754v4</guid>
      <category>cs.LG</category>
      <category>cs.ET</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andi Chen, Hua-Lei Yin, Zeng-Bing Chen, Shengjun Wu</dc:creator>
    </item>
    <item>
      <title>Research Directions for Verifiable Crypto-Physically Secure TEEs</title>
      <link>https://arxiv.org/abs/2410.03183</link>
      <description>arXiv:2410.03183v2 Announce Type: replace-cross 
Abstract: A niche corner of the Web3 world is increasingly making use of hardware-based Trusted Execution Environments (TEEs) to build decentralized infrastructure. One of the motivations to use TEEs is to go beyond the current performance limitations of cryptography-based alternatives such as zero-knowledge proofs (ZKP), fully homomorphic encryption (FHE), and multi-party computation (MPC). Despite their appealing advantages, current TEEs suffer from serious limitations as they are not secure against physical attacks, and their attestation mechanism is rooted in the chip manufacturer's trust. As a result, Web3 applications have to rely on cloud infrastruture to act as trusted guardians of hardware-based TEEs and have to accept to trust chip manufacturers. This work aims at exploring how we could potentially architect and implement chips that would be secure against physical attacks and would not require putting trust in chip manufacturers. One goal of this work is to motivate the Web3 movement to acknowledge and leverage the substantial amount of relevant hardware research that already exists. In brief, a combination of: (1) physical unclonable functions (PUFs) to secure the root-of-trust; (2) masking and redundancy techniques to secure computations; (3) open source hardware and imaging techniques to verify that a chip matches its expected design; can help move towards attesting that a given TEE can be trusted without the need to trust a cloud provider and a chip manufacturer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03183v2</guid>
      <category>cs.CR</category>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sylvain Bellemare</dc:creator>
    </item>
    <item>
      <title>Applying Quantum Autoencoders for Time Series Anomaly Detection</title>
      <link>https://arxiv.org/abs/2410.04154</link>
      <description>arXiv:2410.04154v2 Announce Type: replace-cross 
Abstract: Anomaly detection is an important problem with applications in various domains such as fraud detection, pattern recognition or medical diagnosis. Several algorithms have been introduced using classical computing approaches. However, using quantum computing for solving anomaly detection problems in time series data is a widely unexplored research field.
  This paper explores the application of quantum autoencoders to time series anomaly detection. We investigate two primary techniques for classifying anomalies: (1) Analyzing the reconstruction error generated by the quantum autoencoder and (2) latent representation analysis. Our simulated experimental results, conducted across various ansaetze, demonstrate that quantum autoencoders consistently outperform classical deep learning-based autoencoders across multiple datasets. Specifically, quantum autoencoders achieve superior anomaly detection performance while utilizing 60-230 times fewer parameters and requiring five times fewer training iterations. In addition, we implement our quantum encoder on real quantum hardware. Our experimental results demonstrate that quantum autoencoders achieve anomaly detection performance on par with their simulated counterparts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04154v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>quant-ph</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Robin Frehner, Kurt Stockinger</dc:creator>
    </item>
  </channel>
</rss>
