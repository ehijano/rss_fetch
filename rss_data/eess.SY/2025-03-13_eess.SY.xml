<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>eess.SY updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/eess.SY</link>
    <description>eess.SY updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/eess.SY" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 14 Mar 2025 02:04:59 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Stochastic Model Predictive Control for Sub-Gaussian Noise</title>
      <link>https://arxiv.org/abs/2503.08795</link>
      <description>arXiv:2503.08795v1 Announce Type: new 
Abstract: We propose a stochastic Model Predictive Control (MPC) framework that ensures closed-loop chance constraint satisfaction for linear systems with general sub-Gaussian process and measurement noise. By considering sub-Gaussian noise, we can provide guarantees for a large class of distributions, including time-varying distributions. Specifically, we first provide a new characterization of sub-Gaussian random vectors using matrix variance proxies, which can more accurately represent the predicted state distribution. We then derive tail bounds under linear propagation for the new characterization, enabling tractable computation of probabilistic reachable sets of linear systems. Lastly, we utilize these probabilistic reachable sets to formulate a stochastic MPC scheme that provides closed-loop guarantees for general sub-Gaussian noise. We further demonstrate our approach in simulations, including a challenging task of surgical planning from image observations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08795v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yunke Ao, Johannes K\"ohler, Manish Prajapat, Yarden As, Melanie Zeilinger, Philipp F\"urnstahl, Andreas Krause</dc:creator>
    </item>
    <item>
      <title>High-Precision Overlay Registration via Spatial-Terminal Iterative Learning in Roll-to-Roll Manufacturing</title>
      <link>https://arxiv.org/abs/2503.08835</link>
      <description>arXiv:2503.08835v1 Announce Type: new 
Abstract: Roll-to-roll (R2R) printing technologies are promising for high-volume continuous production of substrate-based electronic products. One of the major challenges in R2R flexible electronics printing is achieving tight alignment tolerances, as specified by the device resolution (usually at the micro-meter level), for multi-layer printed electronics. The alignment of the printed patterns in different layers is known as registration. Conventional registration control methods rely on real-time feedback controllers, such as PID control, to regulate the web tension and the web speed. However, those methods may lose effectiveness in compensating for recurring disturbances and supporting effective mitigation of registration errors. In this paper, we propose a Spatial-Terminal Iterative Learning Control (STILC) method integrated with PID control to iteratively learn and reduce registration error cycle-by-cycle, converging it to zero. This approach enables unprecedented precision in the creation, integration, and manipulation of multi-layer microstructures in R2R processes. We theoretically prove the convergence of the proposed STILC-PID hybrid approach and validate its effectiveness through a simulated registration error scenario caused by axis mismatch between roller and motor, a common issue in R2R systems. The results demonstrate that the STILC-PID hybrid control method can fully eliminate the registration error after a feasible number of iterations. Additionally, we analyze the impact of different learning gains on the convergence performance of STILC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08835v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zifeng Wang, Xiaoning Jin</dc:creator>
    </item>
    <item>
      <title>Accurate Control under Voltage Drop for Rotor Drones</title>
      <link>https://arxiv.org/abs/2503.09017</link>
      <description>arXiv:2503.09017v1 Announce Type: new 
Abstract: This letter proposes an anti-disturbance control scheme for rotor drones to counteract voltage drop (VD) disturbance caused by voltage drop of the battery, which is a common case for long-time flight or aggressive maneuvers. Firstly, the refined dynamics of rotor drones considering VD disturbance are presented. Based on the dynamics, a voltage drop observer (VDO) is developed to accurately estimate the VD disturbance by decoupling the disturbance and state information of the drone, reducing the conservativeness of conventional disturbance observers. Subsequently, the control scheme integrates the VDO within the translational loop and a fixed-time sliding mode observer (SMO) within the rotational loop, enabling it to address force and torque disturbances caused by voltage drop of the battery. Sufficient real flight experiments are conducted to demonstrate the effectiveness of the proposed control scheme under VD disturbance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09017v1</guid>
      <category>eess.SY</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuhang Liu, Jindou Jia, Zihan Yang, Kexin Guo</dc:creator>
    </item>
    <item>
      <title>Data-Driven Inverse Optimal Control for Continuous-Time Nonlinear Systems</title>
      <link>https://arxiv.org/abs/2503.09090</link>
      <description>arXiv:2503.09090v1 Announce Type: new 
Abstract: This paper introduces a novel model-free and a partially model-free algorithm for inverse optimal control (IOC), also known as inverse reinforcement learning (IRL), aimed at estimating the cost function of continuous-time nonlinear deterministic systems. Using the input-state trajectories of an expert agent, the proposed algorithms separately utilize control policy information and the Hamilton-Jacobi-Bellman equation to estimate different sets of cost function parameters. This approach allows the algorithms to achieve broader applicability while maintaining a model-free framework. Also, the model-free algorithm reduces complexity compared to existing methods, as it requires solving a forward optimal control problem only once during initialization. Furthermore, in our partially model-free algorithm, this step can be bypassed entirely for systems with known input dynamics. Simulation results demonstrate the effectiveness and efficiency of our algorithms, highlighting their potential for real-world deployment in autonomous systems and robotics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09090v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hamed Jabbari Asl, Eiji Uchibe</dc:creator>
    </item>
    <item>
      <title>Reliable Solution to Dynamic Optimization Problems using Integrated Residual Regularized Direct Collocation</title>
      <link>https://arxiv.org/abs/2503.09123</link>
      <description>arXiv:2503.09123v1 Announce Type: new 
Abstract: Direct collocation is a widely used method for solving dynamic optimization problems (DOPs), but its implementation simplicity and computational efficiency are limited for challenging problems like those involving singular arcs. In this paper, we introduce the direct transcription method of integrated residual regularized direct collocation (IRR-DC). This method enforces dynamic constraints through a combination of explicit constraints and penalty terms within discretized DOPs. This method retains the implementation simplicity of direct collocation while significantly improving both solution accuracy and efficiency, particularly for challenging problem types. Through the examples, we demonstrate that for difficult problems where traditional direct collocation results in excessive fluctuations or large errors between collocation points, IRR-DC effectively suppresses oscillations and yields solutions with greater accuracy (several magnitudes lower in various error metrics) compared to other regularization alternatives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09123v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuanbo Nie, Eric C. Kerrigan</dc:creator>
    </item>
    <item>
      <title>Risk Assessment of Distribution Networks Considering Climate Change and Vegetation Management Impacts</title>
      <link>https://arxiv.org/abs/2503.09239</link>
      <description>arXiv:2503.09239v1 Announce Type: new 
Abstract: This paper presents a comprehensive risk assessment model for power distribution networks with a focus on the influence of climate conditions and vegetation management on outage risks. Using a dataset comprising outage records, meteorological indicators, and vegetation metrics, this paper develops a logistic regression model that outperformed several alternatives, effectively identifying risk factors in highly imbalanced data. Key features impacting outages include wind speed, vegetation density, quantified as the enhanced vegetation index (EVI), and snow type, with wet snow and autumn conditions exhibiting the strongest positive effects. The analysis also shows complex interactions, such as the combined effect of wind speed and EVI, suggesting that vegetation density can moderate the impact of high winds on outages. Simulation case studies, based on a test dataset of 618 samples, demonstrated that the model achieved an 80\% match rate with real-world data within an error tolerance of \(\pm 0.05\), showcasing the effectiveness and robustness of the proposed model while highlighting its potential to inform preventive strategies for mitigating outage risks in power distribution networks under high-risk environmental conditions. Future work will integrate vegetation height data from Lidar and explore alternative modeling approaches to capture potential non-linear relationships.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09239v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Di Zhao, Umar Salman, Zongjie Wang</dc:creator>
    </item>
    <item>
      <title>Task Allocation for Multi-agent Systems via Unequal-dimensional Optimal Transport</title>
      <link>https://arxiv.org/abs/2503.09369</link>
      <description>arXiv:2503.09369v1 Announce Type: new 
Abstract: We consider a probabilistic model for large-scale task allocation problems for multi-agent systems, aiming to determine an optimal deployment strategy that minimizes the overall transport cost. Specifically, we assign transportation agents to delivery tasks with given pick-up and drop-off locations, pairing the spatial distribution of transport resources with the joint distribution of task origins and destinations. This aligns with the optimal mass transport framework where the problem and is in the unequal-dimensional setting. The task allocation problem can be thus seen as a linear programming problem that minimizes a quadratic transport cost functional, optimizing the energy of all transport units. The problem is motivated by time-sensitive medical deliveries using drones, such as emergency equipment and blood transport. In this paper, we establish the existence, uniqueness, and smoothness of the optimal solution, and illustrate its properties through numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09369v1</guid>
      <category>eess.SY</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anqi Dong, Karl H. Johansson, Johan Karlsson</dc:creator>
    </item>
    <item>
      <title>Faithful and Privacy-Preserving Implementation of Average Consensus</title>
      <link>https://arxiv.org/abs/2503.09381</link>
      <description>arXiv:2503.09381v2 Announce Type: new 
Abstract: We propose a protocol based on mechanism design theory and encrypted control to solve average consensus problems among rational and strategic agents while preserving their privacy. The proposed protocol provides a mechanism that incentivizes the agents to faithfully implement the intended behavior specified in the protocol. Furthermore, the protocol runs over encrypted data using homomorphic encryption and secret sharing to protect the privacy of agents. We also analyze the security of the proposed protocol using a simulation paradigm in secure multi-party computation. The proposed protocol demonstrates that mechanism design and encrypted control can complement each other to achieve security under rational adversaries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09381v2</guid>
      <category>eess.SY</category>
      <category>cs.CR</category>
      <category>cs.SY</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kaoru Teranishi, Kiminao Kogiso, Takashi Tanaka</dc:creator>
    </item>
    <item>
      <title>Context-aware Constrained Reinforcement Learning Based Energy-Efficient Power Scheduling for Non-stationary XR Data Traffic</title>
      <link>https://arxiv.org/abs/2503.09391</link>
      <description>arXiv:2503.09391v1 Announce Type: new 
Abstract: In XR downlink transmission, energy-efficient power scheduling (EEPS) is essential for conserving power resource while delivering large data packets within hard-latency constraints. Traditional constrained reinforcement learning (CRL) algorithms show promise in EEPS but still struggle with non-convex stochastic constraints, non-stationary data traffic, and sparse delayed packet dropout feedback (rewards) in XR. To overcome these challenges, this paper models the EEPS in XR as a dynamic parameter-constrained Markov decision process (DP-CMDP) with a varying transition function linked to the non-stationary data traffic and solves it by a proposed context-aware constrained reinforcement learning (CACRL) algorithm, which consists of a context inference (CI) module and a CRL module. The CI module trains an encoder and multiple potential networks to characterize the current transition function and reshape the packet dropout rewards according to the context, transforming the original DP-CMDP into a general CMDP with immediate dense rewards. The CRL module employs a policy network to make EEPS decisions under this CMDP and optimizes the policy using a constrained stochastic successive convex approximation (CSSCA) method, which is better suited for non-convex stochastic constraints. Finally, theoretical analyses provide deep insights into the CADAC algorithm, while extensive simulations demonstrate that it outperforms advanced baselines in both power conservation and satisfying packet dropout constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09391v1</guid>
      <category>eess.SY</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kexuan Wang, An Liu</dc:creator>
    </item>
    <item>
      <title>A Model-based Approach for Glucose Control via Physical Activity</title>
      <link>https://arxiv.org/abs/2503.09435</link>
      <description>arXiv:2503.09435v1 Announce Type: new 
Abstract: The role played by physical activity in slowing down the progression of type-2 diabetes is well recognized. However, except for general clinical guidelines, quantitative real-time estimates of the recommended amount of physical activity, based on the evolving individual conditions, are {still missing} in the literature. The aim of this work is to provide a control-theoretical formulation of the exercise encoding all the exercise-related features (intensity, duration, period). Specifically, we design a feedback law in terms of recommended physical activity, following a model predictive control approach, based on a widespread compact diabetes progression model, suitably modified to account for the long-term effects of regular exercise. Preliminary simulations show promising results, well aligned with clinical evidence. These findings can be the basis for further validation of the control law on high-dimensional diabetes progression models to ultimately translate the predictions of the controller into meaningful recommendations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09435v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pierluigi Francesco De Paola, Alessandro Borri, Alessia Paglialonga, Pasquale Palumbo, Fabrizio Dabbene</dc:creator>
    </item>
    <item>
      <title>The Algorithmic State Architecture (ASA): An Integrated Framework for AI-Enabled Government</title>
      <link>https://arxiv.org/abs/2503.08725</link>
      <description>arXiv:2503.08725v2 Announce Type: cross 
Abstract: As artificial intelligence transforms public sector operations, governments struggle to integrate technological innovations into coherent systems for effective service delivery. This paper introduces the Algorithmic State Architecture (ASA), a novel four-layer framework conceptualising how Digital Public Infrastructure, Data-for-Policy, Algorithmic Government/Governance, and GovTech interact as an integrated system in AI-enabled states. Unlike approaches that treat these as parallel developments, ASA positions them as interdependent layers with specific enabling relationships and feedback mechanisms. Through comparative analysis of implementations in Estonia, Singapore, India, and the UK, we demonstrate how foundational digital infrastructure enables systematic data collection, which powers algorithmic decision-making processes, ultimately manifesting in user-facing services. Our analysis reveals that successful implementations require balanced development across all layers, with particular attention to integration mechanisms between them. The framework contributes to both theory and practice by bridging previously disconnected domains of digital government research, identifying critical dependencies that influence implementation success, and providing a structured approach for analysing the maturity and development pathways of AI-enabled government systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08725v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zeynep Engin, Jon Crowcroft, David Hand, Philip Treleaven</dc:creator>
    </item>
    <item>
      <title>Cooperative Bearing-Only Target Pursuit via Multiagent Reinforcement Learning: Design and Experiment</title>
      <link>https://arxiv.org/abs/2503.08740</link>
      <description>arXiv:2503.08740v1 Announce Type: cross 
Abstract: This paper addresses the multi-robot pursuit problem for an unknown target, encompassing both target state estimation and pursuit control. First, in state estimation, we focus on using only bearing information, as it is readily available from vision sensors and effective for small, distant targets. Challenges such as instability due to the nonlinearity of bearing measurements and singularities in the two-angle representation are addressed through a proposed uniform bearing-only information filter. This filter integrates multiple 3D bearing measurements, provides a concise formulation, and enhances stability and resilience to target loss caused by limited field of view (FoV). Second, in target pursuit control within complex environments, where challenges such as heterogeneity and limited FoV arise, conventional methods like differential games or Voronoi partitioning often prove inadequate. To address these limitations, we propose a novel multiagent reinforcement learning (MARL) framework, enabling multiple heterogeneous vehicles to search, localize, and follow a target while effectively handling those challenges. Third, to bridge the sim-to-real gap, we propose two key techniques: incorporating adjustable low-level control gains in training to replicate the dynamics of real-world autonomous ground vehicles (AGVs), and proposing spectral-normalized RL algorithms to enhance policy smoothness and robustness. Finally, we demonstrate the successful zero-shot transfer of the MARL controllers to AGVs, validating the effectiveness and practical feasibility of our approach. The accompanying video is available at https://youtu.be/HO7FJyZiJ3E.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08740v1</guid>
      <category>cs.MA</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianan Li, Zhikun Wang, Susheng Ding, Shiliang Guo, Shiyu Zhao</dc:creator>
    </item>
    <item>
      <title>Over-the-Air Time-Frequency Synchronization in Distributed ISAC Systems</title>
      <link>https://arxiv.org/abs/2503.08920</link>
      <description>arXiv:2503.08920v1 Announce Type: cross 
Abstract: A distributed integrated sensing and communication (D-ISAC) system offers significant cooperative gains for both sensing and communication performance. These gains, however, can only be fully realized when the distributed nodes are perfectly synchronized, which is a challenge that remains largely unaddressed in current ISAC research. In this paper, we propose an over-the-air time-frequency synchronization framework for the D-ISAC system, leveraging the reciprocity of bistatic sensing channels. This approach overcomes the impractical dependency of traditional methods on a direct line-of-sight (LoS) link, enabling the estimation of time offset (TO) and carrier frequency offset (CFO) between two ISAC nodes even in non-LoS (NLOS) scenarios. To achieve this, we introduce a bistatic signal matching (BSM) technique with delay-Doppler decoupling, which exploits offset reciprocity (OR) in bistatic observations. This method compresses multiple sensing links into a single offset for estimation. We further present off-grid super-resolution estimators for TO and CFO, including the maximum likelihood estimator (MLE) and the matrix pencil (MP) method, combined with BSM processing. These estimators provide accurate offset estimation compared to spectral cross-correlation techniques. Also, we extend the pairwise synchronization leveraging OR between two nodes to the synchronization of $N$ multiple distributed nodes, referred to as centralized pairwise synchronization. We analyze the Cramer-Rao bounds (CRBs) for TO and CFO estimates and evaluate the impact of D-ISAC synchronization on the bottom-line target localization performance. Simulation results validate the effectiveness of the proposed algorithm, confirm the theoretical analysis, and demonstrate that the proposed synchronization approach can recover up to 96% of the bottom-line target localization performance of the fully-synchronous D-ISAC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08920v1</guid>
      <category>eess.SP</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kawon Han, Kaitao Meng, Christos Masouros</dc:creator>
    </item>
    <item>
      <title>TetraGrip: Sensor-Driven Multi-Suction Reactive Object Manipulation in Cluttered Scenes</title>
      <link>https://arxiv.org/abs/2503.08978</link>
      <description>arXiv:2503.08978v1 Announce Type: cross 
Abstract: Warehouse robotic systems equipped with vacuum grippers must reliably grasp a diverse range of objects from densely packed shelves. However, these environments present significant challenges, including occlusions, diverse object orientations, stacked and obstructed items, and surfaces that are difficult to suction. We introduce \tetra, a novel vacuum-based grasping strategy featuring four suction cups mounted on linear actuators. Each actuator is equipped with an optical time-of-flight (ToF) proximity sensor, enabling reactive grasping.
  We evaluate \tetra in a warehouse-style setting, demonstrating its ability to manipulate objects in stacked and obstructed configurations. Our results show that our RL-based policy improves picking success in stacked-object scenarios by 22.86\% compared to a single-suction gripper. Additionally, we demonstrate that TetraGrip can successfully grasp objects in scenarios where a single-suction gripper fails due to physical limitations, specifically in two cases: (1) picking an object occluded by another object and (2) retrieving an object in a complex scenario. These findings highlight the advantages of multi-actuated, suction-based grasping in unstructured warehouse environments. The project website is available at: \href{https://tetragrip.github.io/}{https://tetragrip.github.io/}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08978v1</guid>
      <category>cs.RO</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paolo Torrado, Joshua Levin, Markus Grotz, Joshua Smith</dc:creator>
    </item>
    <item>
      <title>Traffic Regulation-aware Path Planning with Regulation Databases and Vision-Language Models</title>
      <link>https://arxiv.org/abs/2503.09024</link>
      <description>arXiv:2503.09024v1 Announce Type: cross 
Abstract: This paper introduces and tests a framework integrating traffic regulation compliance into automated driving systems (ADS). The framework enables ADS to follow traffic laws and make informed decisions based on the driving environment. Using RGB camera inputs and a vision-language model (VLM), the system generates descriptive text to support a regulation-aware decision-making process, ensuring legal and safe driving practices. This information is combined with a machine-readable ADS regulation database to guide future driving plans within legal constraints. Key features include: 1) a regulation database supporting ADS decision-making, 2) an automated process using sensor input for regulation-aware path planning, and 3) validation in both simulated and real-world environments. Particularly, the real-world vehicle tests not only assess the framework's performance but also evaluate the potential and challenges of VLMs to solve complex driving problems by integrating detection, reasoning, and planning. This work enhances the legality, safety, and public trust in ADS, representing a significant step forward in the field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09024v1</guid>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.IV</category>
      <category>eess.SY</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xu Han, Zhiwen Wu, Xin Xia, Jiaqi Ma</dc:creator>
    </item>
    <item>
      <title>ManeuverGPT Agentic Control for Safe Autonomous Stunt Maneuvers</title>
      <link>https://arxiv.org/abs/2503.09035</link>
      <description>arXiv:2503.09035v1 Announce Type: cross 
Abstract: The next generation of active safety features in autonomous vehicles should be capable of safely executing evasive hazard-avoidance maneuvers akin to those performed by professional stunt drivers to achieve high-agility motion at the limits of vehicle handling. This paper presents a novel framework, ManeuverGPT, for generating and executing high-dynamic stunt maneuvers in autonomous vehicles using large language model (LLM)-based agents as controllers. We target aggressive maneuvers, such as J-turns, within the CARLA simulation environment and demonstrate an iterative, prompt-based approach to refine vehicle control parameters, starting tabula rasa without retraining model weights. We propose an agentic architecture comprised of three specialized agents (1) a Query Enricher Agent for contextualizing user commands, (2) a Driver Agent for generating maneuver parameters, and (3) a Parameter Validator Agent that enforces physics-based and safety constraints. Experimental results demonstrate successful J-turn execution across multiple vehicle models through textual prompts that adapt to differing vehicle dynamics. We evaluate performance via established success criteria and discuss limitations regarding numeric precision and scenario complexity. Our findings underscore the potential of LLM-driven control for flexible, high-dynamic maneuvers, while highlighting the importance of hybrid approaches that combine language-based reasoning with algorithmic validation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09035v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shawn Azdam, Pranav Doma, Aliasghar Moj Arab</dc:creator>
    </item>
    <item>
      <title>Incentive Analysis for Agent Participation in Federated Learning</title>
      <link>https://arxiv.org/abs/2503.09039</link>
      <description>arXiv:2503.09039v1 Announce Type: cross 
Abstract: Federated learning offers a decentralized approach to machine learning, where multiple agents collaboratively train a model while preserving data privacy. In this paper, we investigate the decision-making and equilibrium behavior in federated learning systems, where agents choose between participating in global training or conducting independent local training. The problem is first modeled as a stage game and then extended to a repeated game to analyze the long-term dynamics of agent participation. For the stage game, we characterize the participation patterns and identify Nash equilibrium, revealing how data heterogeneity influences the equilibrium behavior-specifically, agents with similar data qualities will participate in FL as a group. We also derive the optimal social welfare and show that it coincides with Nash equilibrium under mild assumptions. In the repeated game, we propose a privacy-preserving, computationally efficient myopic strategy. This strategy enables agents to make practical decisions under bounded rationality and converges to a neighborhood of Nash equilibrium of the stage game in finite time. By combining theoretical insights with practical strategy design, this work provides a realistic and effective framework for guiding and analyzing agent behaviors in federated learning systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09039v1</guid>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lihui Yi, Xiaochun Niu, Ermin Wei</dc:creator>
    </item>
    <item>
      <title>Predictor-Based Time Delay Control of A Hex-Jet Unmanned Aerial Vehicle</title>
      <link>https://arxiv.org/abs/2503.09148</link>
      <description>arXiv:2503.09148v1 Announce Type: cross 
Abstract: Turbojet-powered VTOL UAVs have garnered increased attention in heavy-load transport and emergency services, due to their superior power density and thrust-to-weight ratio compared to existing electronic propulsion systems. The main challenge with jet-powered UAVs lies in the complexity of thrust vectoring mechanical systems, which aim to mitigate the slow dynamics of the turbojet. In this letter, we introduce a novel turbojet-powered UAV platform named Hex-Jet. Our concept integrates thrust vectoring and differential thrust for comprehensive attitude control. This approach notably simplifies the thrust vectoring mechanism. We utilize a predictor-based time delay control method based on the frequency domain model in our Hex-Jet controller design to mitigate the delay in roll attitude control caused by turbojet dynamics. Our comparative studies provide valuable insights for the UAV community, and flight tests on the scaled prototype demonstrate the successful implementation and verification of the proposed predictor-based time delay control technique.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09148v1</guid>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junning Liang, Haowen Zheng, Yuying Zhang, Yongzhuo Gao, Wei Dong, Ximin Lyu</dc:creator>
    </item>
    <item>
      <title>Large-scale Regional Traffic Signal Control Based on Single-Agent Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2503.09252</link>
      <description>arXiv:2503.09252v1 Announce Type: cross 
Abstract: In the context of global urbanization and motorization, traffic congestion has become a significant issue, severely affecting the quality of life, environment, and economy. This paper puts forward a single-agent reinforcement learning (RL)-based regional traffic signal control (TSC) model. Different from multi - agent systems, this model can coordinate traffic signals across a large area, with the goals of alleviating regional traffic congestion and minimizing the total travel time. The TSC environment is precisely defined through specific state space, action space, and reward functions. The state space consists of the current congestion state, which is represented by the queue lengths of each link, and the current signal phase scheme of intersections. The action space is designed to select an intersection first and then adjust its phase split. Two reward functions are meticulously crafted. One focuses on alleviating congestion and the other aims to minimize the total travel time while considering the congestion level. The experiments are carried out with the SUMO traffic simulation software. The performance of the TSC model is evaluated by comparing it with a base case where no signal-timing adjustments are made. The results show that the model can effectively control congestion. For example, the queuing length is significantly reduced in the scenarios tested. Moreover, when the reward is set to both alleviate congestion and minimize the total travel time, the average travel time is remarkably decreased, which indicates that the model can effectively improve traffic conditions. This research provides a new approach for large-scale regional traffic signal control and offers valuable insights for future urban traffic management.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09252v1</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qiang Li, Jin Niu, Qin Luo, Lina Yu</dc:creator>
    </item>
    <item>
      <title>Robust Fault-Tolerant Control and Agile Trajectory Planning for Modular Aerial Robotic Systems</title>
      <link>https://arxiv.org/abs/2503.09351</link>
      <description>arXiv:2503.09351v1 Announce Type: cross 
Abstract: Modular Aerial Robotic Systems (MARS) consist of multiple drone units that can self-reconfigure to adapt to various mission requirements and fault conditions. However, existing fault-tolerant control methods exhibit significant oscillations during docking and separation, impacting system stability. To address this issue, we propose a novel fault-tolerant control reallocation method that adapts to arbitrary number of modular robots and their assembly formations. The algorithm redistributes the expected collective force and torque required for MARS to individual unit according to their moment arm relative to the center of MARS mass. Furthermore, We propose an agile trajectory planning method for MARS of arbitrary configurations, which is collision-avoiding and dynamically feasible. Our work represents the first comprehensive approach to enable fault-tolerant and collision avoidance flight for MARS. We validate our method through extensive simulations, demonstrating improved fault tolerance, enhanced trajectory tracking accuracy, and greater robustness in cluttered environments. The videos and source code of this work are available at https://github.com/RuiHuangNUS/MARS-FTCC/</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09351v1</guid>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Rui Huang, Zhenyu Zhang, Siyu Tang, Zhiqian Cai, Lin Zhao</dc:creator>
    </item>
    <item>
      <title>Robust Self-Reconfiguration for Fault-Tolerant Control of Modular Aerial Robot Systems</title>
      <link>https://arxiv.org/abs/2503.09376</link>
      <description>arXiv:2503.09376v1 Announce Type: cross 
Abstract: Modular Aerial Robotic Systems (MARS) consist of multiple drone units assembled into a single, integrated rigid flying platform. With inherent redundancy, MARS can self-reconfigure into different configurations to mitigate rotor or unit failures and maintain stable flight. However, existing works on MARS self-reconfiguration often overlook the practical controllability of intermediate structures formed during the reassembly process, which limits their applicability. In this paper, we address this gap by considering the control-constrained dynamic model of MARS and proposing a robust and efficient self-reconstruction algorithm that maximizes the controllability margin at each intermediate stage. Specifically, we develop algorithms to compute optimal, controllable disassembly and assembly sequences, enabling robust self-reconfiguration. Finally, we validate our method in several challenging fault-tolerant self-reconfiguration scenarios, demonstrating significant improvements in both controllability and trajectory tracking while reducing the number of assembly steps. The videos and source code of this work are available at https://github.com/RuiHuangNUS/MARS-Reconfig/</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09376v1</guid>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Rui Huang, Siyu Tang, Zhiqian Cai, Lin Zhao</dc:creator>
    </item>
    <item>
      <title>PCLA: A Framework for Testing Autonomous Agents in the CARLA Simulator</title>
      <link>https://arxiv.org/abs/2503.09385</link>
      <description>arXiv:2503.09385v2 Announce Type: cross 
Abstract: Recent research on testing autonomous driving agents has grown significantly, especially in simulation environments. The CARLA simulator is often the preferred choice, and the autonomous agents from the CARLA Leaderboard challenge are regarded as the best-performing agents within this environment. However, researchers who test these agents, rather than training their own ones from scratch, often face challenges in utilizing them within customized test environments and scenarios. To address these challenges, we introduce PCLA (Pretrained CARLA Leaderboard Agents), an open-source Python testing framework that includes nine high-performing pre-trained autonomous agents from the Leaderboard challenges. PCLA is the first infrastructure specifically designed for testing various autonomous agents in arbitrary CARLA environments/scenarios. PCLA provides a simple way to deploy Leaderboard agents onto a vehicle without relying on the Leaderboard codebase, it allows researchers to easily switch between agents without requiring modifications to CARLA versions or programming environments, and it is fully compatible with the latest version of CARLA while remaining independent of the Leaderboard's specific CARLA version. PCLA is publicly accessible at https://github.com/MasoudJTehrani/PCLA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09385v2</guid>
      <category>cs.SE</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Masoud Jamshidiyan Tehrani, Jinhan Kim, Paolo Tonella</dc:creator>
    </item>
    <item>
      <title>Precoder Learning by Leveraging Unitary Equivariance Property</title>
      <link>https://arxiv.org/abs/2503.09398</link>
      <description>arXiv:2503.09398v1 Announce Type: cross 
Abstract: Incorporating mathematical properties of a wireless policy to be learned into the design of deep neural networks (DNNs) is effective for enhancing learning efficiency. Multi-user precoding policy in multi-antenna system, which is the mapping from channel matrix to precoding matrix, possesses a permutation equivariance property, which has been harnessed to design the parameter sharing structure of the weight matrix of DNNs. In this paper, we study a stronger property than permutation equivariance, namely unitary equivariance, for precoder learning. We first show that a DNN with unitary equivariance designed by further introducing parameter sharing into a permutation equivariant DNN is unable to learn the optimal precoder. We proceed to develop a novel non-linear weighting process satisfying unitary equivariance and then construct a joint unitary and permutation equivariant DNN. Simulation results demonstrate that the proposed DNN not only outperforms existing learning methods in learning performance and generalizability but also reduces training complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09398v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.GR</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yilun Ge, Shuyao Liao, Shengqian Han, Chenyang Yang</dc:creator>
    </item>
    <item>
      <title>Neural-Augmented Incremental Nonlinear Dynamic Inversion for Quadrotors with Payload Adaptation</title>
      <link>https://arxiv.org/abs/2503.09441</link>
      <description>arXiv:2503.09441v1 Announce Type: cross 
Abstract: The increasing complexity of multirotor applications has led to the need of more accurate flight controllers that can reliably predict all forces acting on the robot. Traditional flight controllers model a large part of the forces but do not take so called residual forces into account. A reason for this is that accurately computing the residual forces can be computationally expensive. Incremental Nonlinear Dynamic Inversion (INDI) is a method that computes the difference between different sensor measurements in order to estimate these residual forces. The main issue with INDI is it's reliance on special sensor measurements which can be very noisy. Recent work has also shown that residual forces can be predicted using learning-based methods. In this work, we demonstrate that a learning algorithm can predict a smoother version of INDI outputs without requiring additional sensor measurements. In addition, we introduce a new method that combines learning based predictions with INDI. We also adapt the two approaches to work on quadrotors carrying a slung-type payload. The results show that using a neural network to predict residual forces can outperform INDI while using the combination of neural network and INDI can yield even better results than each method individually.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09441v1</guid>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eckart Cobo-Briesewitz, Khaled Wahba, Wolfgang H\"onig</dc:creator>
    </item>
    <item>
      <title>Fast computation of the TGOSPA metric for multiple target tracking via unbalanced optimal transport</title>
      <link>https://arxiv.org/abs/2503.09449</link>
      <description>arXiv:2503.09449v1 Announce Type: cross 
Abstract: In multiple target tracking, it is important to be able to evaluate the performance of different tracking algorithms. The trajectory generalized optimal sub-pattern assignment metric (TGOSPA) is a recently proposed metric for such evaluations. The TGOSPA metric is computed as the solution to an optimization problem, but for large tracking scenarios, solving this problem becomes computationally demanding. In this paper, we present an approximation algorithm for evaluating the TGOSPA metric, based on casting the TGOSPA problem as an unbalanced multimarginal optimal transport problem. Following recent advances in computational optimal transport, we introduce an entropy regularization and derive an iterative scheme for solving the Lagrangian dual of the regularized problem. Numerical results suggest that our proposed algorithm is more computationally efficient than the alternative of computing the exact metric using a linear programming solver, while still providing an adequate approximation of the metric.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09449v1</guid>
      <category>math.OC</category>
      <category>cs.CV</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Viktor Nevelius Wernholm, Alfred W\"arns\"ater, Axel Ringh</dc:creator>
    </item>
    <item>
      <title>Input-Output Feedback Linearization Preserving Task Priority for Multivariate Nonlinear Systems Having Singular Input Gain Matrix</title>
      <link>https://arxiv.org/abs/2305.01903</link>
      <description>arXiv:2305.01903v4 Announce Type: replace 
Abstract: We propose an extension of the input-output feedback linearization for a class of multivariate systems that are not input-output linearizable in a classical manner. The key observation is that the usual input-output linearization problem can be interpreted as the problem of solving simultaneous linear equations associated with the input gain matrix: thus, even at points where the input gain matrix becomes singular, it is still possible to solve a part of linear equations, by which a subset of input-output relations is made linear or close to be linear. Based on this observation, we adopt the task priority-based approach in the input-output linearization problem. First, we generalize the classical Byrnes-Isidori normal form to a prioritized normal form having a triangular structure, so that the singularity of a subblock of the input gain matrix related to lower-priority tasks does not directly propagate to higher-priority tasks. Next, we present a prioritized input-output linearization via the multi-objective optimization with the lexicographical ordering, resulting in a prioritized semilinear form that establishes input output relations whose subset with higher priority is linear or close to be linear. Finally, Lyapunov analysis on ultimate boundedness and task achievement is provided, particularly when the proposed prioritized input-output linearization is applied to the output tracking problem. This work introduces a new control framework for complex systems having critical and noncritical control issues, by assigning higher priority to the critical ones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.01903v4</guid>
      <category>eess.SY</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TAC.2025.3547538</arxiv:DOI>
      <dc:creator>Sang-ik An, Dongheui Lee, Gyunghoon Park</dc:creator>
    </item>
    <item>
      <title>CommonPower: A Framework for Safe Data-Driven Smart Grid Control</title>
      <link>https://arxiv.org/abs/2406.03231</link>
      <description>arXiv:2406.03231v4 Announce Type: replace 
Abstract: The growing complexity of power system management has led to an increased interest in reinforcement learning (RL). To validate their effectiveness, RL algorithms have to be evaluated across multiple case studies. Case study design is an arduous task requiring the consideration of many aspects, among them the influence of available forecasts and the level of decentralization in the control structure. Furthermore, vanilla RL controllers cannot themselves ensure the satisfaction of system constraints, which makes devising a safeguarding mechanism a necessary task for every case study before deploying the system. To address these shortcomings, we introduce the Python tool CommonPower, the first general framework for the modeling and simulation of power system management tailored towards machine learning. Its modular architecture enables users to focus on specific elements without having to implement a simulation environment. Another unique contribution of CommonPower is the automatic synthesis of model predictive controllers and safeguards. Beyond offering a unified interface for single-agent RL, multi-agent RL, and optimal control, CommonPower includes a training pipeline for machine-learning-based forecasters as well as a flexible mechanism for incorporating feedback of safeguards into the learning updates of RL controllers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03231v4</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Eichelbeck, Hannah Markgraf, Matthias Althoff</dc:creator>
    </item>
    <item>
      <title>Construction of the Sparsest Maximally $r$-Robust Graphs</title>
      <link>https://arxiv.org/abs/2409.19465</link>
      <description>arXiv:2409.19465v2 Announce Type: replace 
Abstract: In recent years, the notion of r-robustness for the communication graph of the network has been introduced to address the challenge of achieving consensus in the presence of misbehaving agents. Higher r-robustness typically implies higher tolerance to malicious information towards achieving resilient consensus, but it also implies more edges for the communication graph. This in turn conflicts with the need to minimize communication due to limited resources in real-world applications (e.g., multi-robot networks). In this paper, our contributions are twofold. (a) We provide the necessary subgraph structures and tight lower bounds on the number of edges required for graphs with a given number of nodes to achieve maximum robustness. (b) We then use the results of (a) to introduce two classes of graphs that maintain maximum robustness with the least number of edges. Our work is validated through a series of simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19465v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haejoon Lee, Dimitra Panagou</dc:creator>
    </item>
    <item>
      <title>Koopman Spectral Analysis from Noisy Measurements based on Bayesian Learning and Kalman Smoothing</title>
      <link>https://arxiv.org/abs/2410.00703</link>
      <description>arXiv:2410.00703v2 Announce Type: replace 
Abstract: Koopman spectral analysis plays a crucial role in understanding and modeling nonlinear dynamical systems as it reveals key system behaviors and long-term dynamics. However, the presence of measurement noise poses a significant challenge to accurately extracting spectral properties. In this work, we propose a robust method for identifying the Koopman operator and extracting its spectral characteristics in noisy environments. To address the impact of noise, our approach tackles an identification problem that accounts for both systematic errors from finite-dimensional approximations and measurement noise in the data. By incorporating Bayesian learning and Kalman smoothing, the method simultaneously identifies the Koopman operator and estimates system states, effectively decoupling these two error sources. The method's efficiency and robustness are demonstrated through extensive experiments, showcasing its accuracy across varying noise levels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00703v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.DS</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhexuan Zeng, Jun Zhou, Yasen Wang, Zuowei Ping</dc:creator>
    </item>
    <item>
      <title>An Unsupervised C-Uniform Trajectory Sampler with Applications to Model Predictive Path Integral Control</title>
      <link>https://arxiv.org/abs/2503.05819</link>
      <description>arXiv:2503.05819v2 Announce Type: replace 
Abstract: Sampling-based model predictive controllers generate trajectories by sampling control inputs from a fixed, simple distribution such as the normal or uniform distributions. This sampling method yields trajectory samples that are tightly clustered around a mean trajectory. This clustering behavior in turn, limits the exploration capability of the controller and reduces the likelihood of finding feasible solutions in complex environments. Recent work has attempted to address this problem by either reshaping the resulting trajectory distribution or increasing the sample entropy to enhance diversity and promote exploration. In our recent work, we introduced the concept of C-Uniform trajectory generation [1] which allows the computation of control input probabilities to generate trajectories that sample the configuration space uniformly. In this work, we first address the main limitation of this method: lack of scalability due to computational complexity. We introduce Neural C-Uniform, an unsupervised C-Uniform trajectory sampler that mitigates scalability issues by computing control input probabilities without relying on a discretized configuration space. Experiments show that Neural C-Uniform achieves a similar uniformity ratio to the original C-Uniform approach and generates trajectories over a longer time horizon while preserving uniformity. Next, we present CU-MPPI, which integrates Neural C-Uniform sampling into existing MPPI variants. We analyze the performance of CU-MPPI in simulation and real-world experiments. Our results indicate that in settings where the optimal solution has high curvature, CU-MPPI leads to drastic improvements in performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05819v2</guid>
      <category>eess.SY</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>O. Goktug Poyrazoglu, Rahul Moorthy, Yukang Cao, William Chastek, Volkan Isler</dc:creator>
    </item>
    <item>
      <title>Optimal Output Feedback Learning Control for Discrete-Time Linear Quadratic Regulation</title>
      <link>https://arxiv.org/abs/2503.06226</link>
      <description>arXiv:2503.06226v2 Announce Type: replace 
Abstract: This paper studies the linear quadratic regulation (LQR) problem of unknown discrete-time systems via dynamic output feedback learning control. In contrast to the state feedback, the optimality of the dynamic output feedback control for solving the LQR problem requires an implicit condition on the convergence of the state observer. Moreover, due to unknown system matrices and the existence of observer error, it is difficult to analyze the convergence and stability of most existing output feedback learning-based control methods. To tackle these issues, we propose a generalized dynamic output feedback learning control approach with guaranteed convergence, stability, and optimality performance for solving the LQR problem of unknown discrete-time linear systems. In particular, a dynamic output feedback controller is designed to be equivalent to a state feedback controller. This equivalence relationship is an inherent property without requiring convergence of the estimated state by the state observer, which plays a key role in establishing the off-policy learning control approaches. By value iteration and policy iteration schemes, the adaptive dynamic programming based learning control approaches are developed to estimate the optimal feedback control gain. In addition, a model-free stability criterion is provided by finding a nonsingular parameterization matrix, which contributes to establishing a switched iteration scheme. Furthermore, the convergence, stability, and optimality analyses of the proposed output feedback learning control approaches are given. Finally, the theoretical results are validated by two numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.06226v2</guid>
      <category>eess.SY</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kedi Xie, Martin Guay, Shimin Wang, Fang Deng, Maobin Lu</dc:creator>
    </item>
    <item>
      <title>On discount functions for economic model predictive control without terminal conditions</title>
      <link>https://arxiv.org/abs/2405.14361</link>
      <description>arXiv:2405.14361v2 Announce Type: replace-cross 
Abstract: In this paper, we investigate discounted economic model predictive control (E-MPC) schemes without terminal conditions in scenarios where the optimal operating behavior is a periodic orbit. For such a setting, it is known that a linearly discounted stage cost guarantees asymptotic stability of any arbitrarily small neighborhood of the optimal orbit if the prediction horizon is sufficiently long. However, in some examples very long prediction horizons are needed to achieve the desired performance. In this work, we extend these results by providing the same qualitative stability guarantees for a large class of discount functions. Numerical examples illustrate the influence of the discount function and show that with suitable discounting we can achieve significantly better performance than the linearly discounted E-MPC, even for short prediction horizons.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14361v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lukas Schwenkel, Daniel Briem, Matthias A. M\"uller, Frank Allg\"ower</dc:creator>
    </item>
    <item>
      <title>Reduce, Reuse, Recycle: Categories for Compositional Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2408.13376</link>
      <description>arXiv:2408.13376v3 Announce Type: replace-cross 
Abstract: In reinforcement learning, conducting task composition by forming cohesive, executable sequences from multiple tasks remains challenging. However, the ability to (de)compose tasks is a linchpin in developing robotic systems capable of learning complex behaviors. Yet, compositional reinforcement learning is beset with difficulties, including the high dimensionality of the problem space, scarcity of rewards, and absence of system robustness after task composition. To surmount these challenges, we view task composition through the prism of category theory -- a mathematical discipline exploring structures and their compositional relationships. The categorical properties of Markov decision processes untangle complex tasks into manageable sub-tasks, allowing for strategical reduction of dimensionality, facilitating more tractable reward structures, and bolstering system robustness. Experimental results support the categorical theory of reinforcement learning by enabling skill reduction, reuse, and recycling when learning complex robotic arm tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.13376v3</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.CT</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <arxiv:DOI>10.3233/faia240797</arxiv:DOI>
      <dc:creator>Georgios Bakirtzis, Michail Savvas, Ruihan Zhao, Sandeep Chinchali, Ufuk Topcu</dc:creator>
    </item>
    <item>
      <title>Coalescing Force of Group Pressure: Consensus in Nonlinear Opinion Dynamics</title>
      <link>https://arxiv.org/abs/2410.04301</link>
      <description>arXiv:2410.04301v3 Announce Type: replace-cross 
Abstract: This work extends the recent opinion dynamics model from Cheng et al., emphasizing the role of group pressure in consensus formation. We generalize the findings to incorporate social influence algorithms with general time-varying, opinion-dependent weights and multidimensional opinions, beyond bounded confidence dynamics. We demonstrate that, with uniformly positive conformity levels, group pressure consistently drives consensus and provide a tighter estimate for the convergence rate. Unlike previous models, the common public opinion in our framework can assume arbitrary forms within the convex hull of current opinions, offering flexibility applicable to real-world scenarios such as opinion polls with random participant selection. This analysis provides deeper insights into how group pressure mechanisms foster consensus under diverse conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04301v3</guid>
      <category>physics.soc-ph</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Iryna Zabarianska, Anton V. Proskurnikov</dc:creator>
    </item>
    <item>
      <title>DeepUKF-VIN: Adaptively-tuned Deep Unscented Kalman Filter for 3D Visual-Inertial Navigation based on IMU-Vision-Net</title>
      <link>https://arxiv.org/abs/2502.00575</link>
      <description>arXiv:2502.00575v2 Announce Type: replace-cross 
Abstract: This paper addresses the challenge of estimating the orientation, position, and velocity of a vehicle operating in three-dimensional (3D) space with six degrees of freedom (6-DoF). A Deep Learning-based Adaptation Mechanism (DLAM) is proposed to adaptively tune the noise covariance matrices of Kalman-type filters for the Visual-Inertial Navigation (VIN) problem, leveraging IMU-Vision-Net. Subsequently, an adaptively tuned Deep Learning Unscented Kalman Filter for 3D VIN (DeepUKF-VIN) is introduced to utilize the proposed DLAM, thereby robustly estimating key navigation components, including orientation, position, and linear velocity. The proposed DeepUKF-VIN integrates data from onboard sensors, specifically an inertial measurement unit (IMU) and visual feature points extracted from a camera, and is applicable for GPS-denied navigation. Its quaternion-based design effectively captures navigation nonlinearities and avoids the singularities commonly encountered with Euler-angle-based filters. Implemented in discrete space, the DeepUKF-VIN facilitates practical filter deployment. The filter's performance is evaluated using real-world data collected from an IMU and a stereo camera at low sampling rates. The results demonstrate filter stability and rapid attenuation of estimation errors, highlighting its high estimation accuracy. Furthermore, comparative testing against the standard Unscented Kalman Filter (UKF) in two scenarios consistently shows superior performance across all navigation components, thereby validating the efficacy and robustness of the proposed DeepUKF-VIN. Keywords: Deep Learning, Unscented Kalman Filter, Adaptive tuning, Estimation, Navigation, Unmanned Aerial Vehicle, Sensor-fusion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00575v2</guid>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.eswa.2025.126656</arxiv:DOI>
      <dc:creator>Khashayar Ghanizadegan, Hashim A. Hashim</dc:creator>
    </item>
    <item>
      <title>Fair Play in the Fast Lane: Integrating Sportsmanship into Autonomous Racing Systems</title>
      <link>https://arxiv.org/abs/2503.03774</link>
      <description>arXiv:2503.03774v2 Announce Type: replace-cross 
Abstract: Autonomous racing has gained significant attention as a platform for high-speed decision-making and motion control. While existing methods primarily focus on trajectory planning and overtaking strategies, the role of sportsmanship in ensuring fair competition remains largely unexplored. In human racing, rules such as the one-motion rule and the enough-space rule prevent dangerous and unsportsmanlike behavior. However, autonomous racing systems often lack mechanisms to enforce these principles, potentially leading to unsafe maneuvers. This paper introduces a bi-level game-theoretic framework to integrate sportsmanship (SPS) into versus racing. At the high level, we model racing intentions using a Stackelberg game, where Monte Carlo Tree Search (MCTS) is employed to derive optimal strategies. At the low level, vehicle interactions are formulated as a Generalized Nash Equilibrium Problem (GNEP), ensuring that all agents follow sportsmanship constraints while optimizing their trajectories. Simulation results demonstrate the effectiveness of the proposed approach in enforcing sportsmanship rules while maintaining competitive performance. We analyze different scenarios where attackers and defenders adhere to or disregard sportsmanship rules and show how knowledge of these constraints influences strategic decision-making. This work highlights the importance of balancing competition and fairness in autonomous racing and provides a foundation for developing ethical and safe AI-driven racing systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03774v2</guid>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhenmin Huang, Ce Hao, Wei Zhan, Jun Ma, Masayoshi Tomizuka</dc:creator>
    </item>
    <item>
      <title>Hierarchical Neuro-Symbolic Decision Transformer</title>
      <link>https://arxiv.org/abs/2503.07148</link>
      <description>arXiv:2503.07148v2 Announce Type: replace-cross 
Abstract: We present a hierarchical neuro-symbolic control framework that couples classical symbolic planning with transformer-based policies to address complex, long-horizon decision-making tasks. At the high level, a symbolic planner constructs an interpretable sequence of operators based on logical propositions, ensuring systematic adherence to global constraints and goals. At the low level, each symbolic operator is translated into a sub-goal token that conditions a decision transformer to generate a fine-grained sequence of actions in uncertain, high-dimensional environments. We provide theoretical analysis showing how approximation errors from both the symbolic planner and the neural execution layer accumulate. Empirical evaluations in grid-worlds with multiple keys, locked doors, and item-collection tasks show that our hierarchical approach outperforms purely end-to-end neural approach in success rates and policy efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.07148v2</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ali Baheri, Cecilia O. Alm</dc:creator>
    </item>
    <item>
      <title>Hierarchical Contact-Rich Trajectory Optimization for Multi-Modal Manipulation using Tight Convex Relaxations</title>
      <link>https://arxiv.org/abs/2503.07963</link>
      <description>arXiv:2503.07963v2 Announce Type: replace-cross 
Abstract: Designing trajectories for manipulation through contact is challenging as it requires reasoning of object \&amp; robot trajectories as well as complex contact sequences simultaneously. In this paper, we present a novel framework for simultaneously designing trajectories of robots, objects, and contacts efficiently for contact-rich manipulation. We propose a hierarchical optimization framework where Mixed-Integer Linear Program (MILP) selects optimal contacts between robot \&amp; object using approximate dynamical constraints, and then a NonLinear Program (NLP) optimizes trajectory of the robot(s) and object considering full nonlinear constraints. We present a convex relaxation of bilinear constraints using binary encoding technique such that MILP can provide tighter solutions with better computational complexity. The proposed framework is evaluated on various manipulation tasks where it can reason about complex multi-contact interactions while providing computational advantages. We also demonstrate our framework in hardware experiments using a bimanual robot system. The video summarizing this paper and hardware experiments is found https://youtu.be/s2S1Eg5RsRE?si=chPkftz_a3NAHxLq</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.07963v2</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuki Shirai, Arvind Raghunathan, Devesh K. Jha</dc:creator>
    </item>
  </channel>
</rss>
