<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.EC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.EC</link>
    <description>q-fin.EC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.EC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 10 Feb 2026 05:02:26 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Bank Failures: The Roles of Solvency and Liquidity</title>
      <link>https://arxiv.org/abs/2602.07327</link>
      <description>arXiv:2602.07327v1 Announce Type: new 
Abstract: Bank failures can stem from runs on otherwise solvent banks or from losses that render banks insolvent, regardless of withdrawals. Disentangling the relative importance of liquidity and solvency in explaining bank failures is central to understanding financial crises and designing effective financial stability policies. This paper reviews evidence on the causes of bank failures. Bank failures -- both with and without runs -- are almost always related to poor fundamentals. Low recovery rates in failure suggest that most failed banks that experienced runs were likely fundamentally insolvent. Examiners' postmortem assessments also emphasize the primacy of poor asset quality and solvency problems. Before deposit insurance, runs commonly triggered the failure of insolvent banks. However, runs rarely caused the failure of strong banks, as such runs were typically resolved through other mechanisms, including interbank cooperation, equity injections, public signals of strength, or suspension of convertibility. We discuss the policy implications of these findings and outline directions for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07327v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sergio Correia, Stephan Luck, Emil Verner</dc:creator>
    </item>
    <item>
      <title>Model Restrictiveness in Functional and Structural Settings</title>
      <link>https://arxiv.org/abs/2602.07688</link>
      <description>arXiv:2602.07688v1 Announce Type: new 
Abstract: We generalize the notion of model restrictiveness in Fudenberg, Gao and Liang (2026) to a wider range of economic models with semi/non-parametric and structural ingredients. We show how restrictiveness can be defined and computed in infinite-dimensional settings using Gaussian process priors (including with shape restrictions) and other alternativess in Bayesian nonparametrics. We also extend the restrictiveness framework to structural models with endogeneity, instrumental variables, multiple equilibria, and nonparametric nuisance components. We discuss the importance of the user-specific choice of discrepancy functions in the context of Rademacher complexity and GMM criterion function, and relate restrictiveness to the limit of the average-case learning curve in machine learning. We consider applications to: (1) preferences under risk, (2) exogenous multinomial choice, and (3) multinomial choice with endogenous prices: for (1), we obtain results consistent with those in Fudenberg, Gao and Liang (2026); for (2) and (3), our findings show that nested logit and mixed logit exhibit similar restrictiveness under standard parametric specifications, and that IV exogeneity conditions substantially increase overall restrictiveness while altering model rankings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07688v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Drew Fudenberg, Wayne Yuan Gao, Zhiheng You</dc:creator>
    </item>
    <item>
      <title>Droughts and Deluges: Effects of Climate Extremes on the Gender Gap in Labor Supply</title>
      <link>https://arxiv.org/abs/2602.07808</link>
      <description>arXiv:2602.07808v1 Announce Type: new 
Abstract: Over the past three decades, extreme climate events have caused losses of worth USD 4.5 trillion. Using a panel of 151 countries (1995-2019), I examine how extreme climate conditions shape gender gap in labor force participation. Key results show that the gender gap in paid labor exhibits a U-shaped relationship with droughts and an inverted U-shaped relationship with extreme wet conditions. The drought pattern is primarily driven by gender gap in employment while wetness affects gender gap in participation through unemployment. These relationships vary with country characteristics. Countries with high disaster-displacement risk exhibit declining gender gaps in participation during excess wetness while moderate-risk economies experience expanded gaps during droughts. Furthermore, the drought U-shape is most pronounced in countries with low to moderate empowerment while the nonlinear wet responses is concentrated only in moderately empowered countries. Lastly, both droughts and excess wetness expands gender gap in countries with weak net resilience to climate shocks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07808v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jheelum Sarkar</dc:creator>
    </item>
    <item>
      <title>Double Disadvantage: How Gender and Residential Location Shape Hiring Outcomes in Pakistan's IT Sector</title>
      <link>https://arxiv.org/abs/2602.08134</link>
      <description>arXiv:2602.08134v1 Announce Type: new 
Abstract: This paper examines how gender and residential socioeconomic status shape hiring outcomes in the information technology sector using a field experiment from the city of Karachi, Pakistan. Employers in Pakistan can openly state preferences regarding gender, residential location, and other characteristics, but the majority in the information technology sector choose not to do so. This creates an opportunity to examine whether discrimination persists when such biases are not explicitly stated. An analysis of explicitly gender-targeted job ads shows that men are preferred over women across most occupations, even in traditionally pink-collar roles. Moreover, results from a resume audit experiment, submitting 2,032 applications to 508 full-time job openings, show that men receive more callbacks for job interviews than women, even in the absence of explicit gender preferences in job ads. The study also indicates a significant premium favoring candidates from high-income areas, who receive 45 percent more callbacks than applicants from low-income neighborhoods. This advantage remains robust even after controlling for commuting distance. Qualitative interviews with human resource officials suggest that employers associate productivity with both gender and neighborhood socioeconomic status. Residential address acts as a proxy for class background and signals education, skills, and perceived "fit" in professional settings. These perceptions may reinforce stereotypes, disadvantaging women and candidates from low-income backgrounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08134v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.socec.2025.102469</arxiv:DOI>
      <arxiv:journal_reference>J. Behav. Exp. Econ. 119 (2025) 102469</arxiv:journal_reference>
      <dc:creator>Sana Khalil</dc:creator>
    </item>
    <item>
      <title>On- and off-chain demand and supply drivers of Bitcoin price</title>
      <link>https://arxiv.org/abs/2602.08429</link>
      <description>arXiv:2602.08429v1 Announce Type: new 
Abstract: Around three quarters of Bitcoin transactions take place off-chain. Despite their significance, the vast majority of the empirical literature on cryptocurrencies focuses on on-chain transactions. This paper presents one of the first analysis of both on- and off-chain demand- and supply-side factors. Two hypotheses relating on-chain and off-chain demand and supply drivers to the Bitcoin price are tested in an ARDL model with daily data from 2019 to 2024. Our estimates document the differential contributions of on-chain and off-chain drivers on the Bitcoin price. Off-chain demand pressures have a significant impact on the Bitcoin price in the long-run. In the short-run, both demand and supply drivers significantly affect the Bitcoin price. Regarding transactions on the blockchain, only on-chain demand pressures are statistically significant - both in the long- and short-run. These findings confirm the dual nature of the Bitcoin price dynamics, where also market fundamentals affect the Bitcoin price in addition to speculative drivers. Bitcoin whale trading has less significant impact on price in the long-run, while is more pronounced contemporaneously and one-period lag.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08429v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Pavel Ciaian, d'Artis Kancs, Miroslava Rajcaniova</dc:creator>
    </item>
    <item>
      <title>Effectiveness of Rent Controls: Evidence from Spain</title>
      <link>https://arxiv.org/abs/2602.08631</link>
      <description>arXiv:2602.08631v1 Announce Type: new 
Abstract: Growing concerns about housing affordability have prompted the adoption of rent control policies and renewed debates over their effectiveness. This paper provides the first empirical evaluation of the 2024 rent control policy implemented in Catalonia under Spain's new national housing law. To identify the causal effect of the policy on the rental market, I use municipality-level administrative data and implement several difference-in-differences strategies and event study designs. The results point to a reduction in tenancy agreements and a less robust decrease in rental price growth. While the findings highlight important short-term consequences of rent control, they also underscore the need for caution due to data limitations and limited robustness in some estimates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08631v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luis Perez Garcia</dc:creator>
    </item>
    <item>
      <title>Platform Design, Earnings Transparency and Minimum Wage Policies: Evidence from A Natural Experiment on Lyft</title>
      <link>https://arxiv.org/abs/2602.08955</link>
      <description>arXiv:2602.08955v1 Announce Type: new 
Abstract: We study the impact of a major policy and design change at Lyft that altered both driver earnings and platform transparency, offering insights into how such changes affect stakeholders and platform outcomes. In February 2024, Lyft began a staggered rollout of a new policy that guaranteed drivers a minimum share of rider payments and increased transparency by displaying estimated earnings per ride upfront. This policy was first introduced in major urban markets, creating a natural experiment to evaluate its effects. Using data from over 47 million rides across urban and neighboring suburban markets, we apply dynamic staggered difference-in-differences and geographic border strategies to measure causal effects on driver behavior, rider experience, and platform performance. We find the policy significantly increased driver engagement-particularly among those with lower pre-policy earnings or higher income uncertainty-leading to more hours worked, higher utilization, and greater trip volume. These supply-side changes also generated positive spillovers on rider demand. We disentangle the separate effects of earnings guarantees and transparency and show that while both were beneficial, transparency may have also triggered strategic driver behaviors. In ongoing work, we develop a counterfactual simulation framework linking driver supply and rider intents to ride production, showing how small behavioral shifts could further amplify platform outcomes. We also train a self-supervised model on driver trajectories to detect multihoming, examining whether the observed supply increase reflects net expansion or substitution from other platforms. Together, our findings highlight the potential for platform-led policies to serve as alternatives to regulation and offer design insights for managing platform change.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08955v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rubing Li, Xiao Liu, Arun Sundararajan</dc:creator>
    </item>
    <item>
      <title>Analyzing Vaccine Manufacturing Supply Chain Disruptions for Pandemic Preparedness using Discrete-Event Simulation</title>
      <link>https://arxiv.org/abs/2602.08988</link>
      <description>arXiv:2602.08988v1 Announce Type: new 
Abstract: The COVID-19 pandemic exposed critical vulnerabilities in vaccine supply chains, highlighting the need for robust manufacturing for rapid pandemic response to support CEPI's 100 Days Mission. We develop a discrete-event simulation model to analyze supply chain disruptions and enables policymakers and vaccine manufacturers to quantify disruptions and assess mitigation strategies. Unlike prior studies examining components in isolation, our approach integrates production processes, quality assurance and control (QA/QC) activities, and raw material procurement to capture system-wide dynamics. A detailed mRNA case study analyzes disruption scenarios for a facility targeting 50 million doses: facility shutdowns, workforce reductions, raw material shortages, infrastructure failures, extended procurement lead times, and increased QA/QC capacity. Three main insights emerge. First, QA/QC personnel are the primary bottleneck, with utilization reaching 84.5% under normal conditions while machine utilization remains below 33%. Doubling QA/QC capacity increases annual output by 79.1%, offering greater returns than equipment investments. Second, raw material disruptions are highly detrimental, with extended lead times reducing three-year output by 19.6% and causing stockouts during 51.8% of production time. Third, the model shows differential resilience: acute disruptions (workforce shortages, shutdowns, power outages) allow recovery within 6 to 9 weeks, whereas chronic disruptions (supply delays) cause prolonged performance degradation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08988v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Robin Kelchtermans, Valentijn Stienen, Guido Dietrich, Mauro Bernuzzi, Nico Vandaele</dc:creator>
    </item>
    <item>
      <title>Is there "Secret Sauce'' in Large Language Model Development?</title>
      <link>https://arxiv.org/abs/2602.07238</link>
      <description>arXiv:2602.07238v1 Announce Type: cross 
Abstract: Do leading LLM developers possess a proprietary ``secret sauce'', or is LLM performance driven by scaling up compute? Using training and benchmark data for 809 models released between 2022 and 2025, we estimate scaling-law regressions with release-date and developer fixed effects. We find clear evidence of developer-specific efficiency advantages, but their importance depends on where models lie in the performance distribution. At the frontier, 80-90% of performance differences are explained by higher training compute, implying that scale--not proprietary technology--drives frontier advances. Away from the frontier, however, proprietary techniques and shared algorithmic progress substantially reduce the compute required to reach fixed capability thresholds. Some companies can systematically produce smaller models more efficiently. Strikingly, we also find substantial variation of model efficiency within companies; a firm can train two models with more than 40x compute efficiency difference. We also discuss the implications for AI leadership and capability diffusion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07238v1</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matthias Mertens, Natalia Fischl-Lanzoni, Neil Thompson</dc:creator>
    </item>
    <item>
      <title>Constrained Pricing under Finite Mixtures of Logit</title>
      <link>https://arxiv.org/abs/2602.08119</link>
      <description>arXiv:2602.08119v1 Announce Type: cross 
Abstract: The mixed logit model is a flexible and widely used demand model in pricing and revenue management. However, existing work on mixed-logit pricing largely focuses on unconstrained settings, limiting its applicability in practice where prices are subject to business or regulatory constraints. We study the constrained pricing problem under multinomial and mixed logit demand models. For the multinomial logit model, corresponding to a single customer segment, we show that the constrained pricing problem admits a polynomial-time approximation scheme (PTAS) via a reformulation based on exponential cone programming, yielding an $\varepsilon$-optimal solution in polynomial time. For finite mixed logit models with $T$ customer segments, we reformulate the problem as a bilinear exponential cone program with $O(T)$ bilinear terms. This structure enables a Branch-and-Bound algorithm whose complexity is exponential only in $T$. Consequently, constrained pricing under finite mixtures of logit admits a PTAS when the number of customer segments is bounded. Numerical experiments demonstrate strong performance relative to state-of-the-art baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08119v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hoang Giang Pham, Tien Mai</dc:creator>
    </item>
    <item>
      <title>Ethnic Groups' Access to State Power and Group Size</title>
      <link>https://arxiv.org/abs/2003.08064</link>
      <description>arXiv:2003.08064v2 Announce Type: replace 
Abstract: Ethnic-based political inequality is widespread, yet its underlying drivers remain poorly understood. This paper shows that an ethnic group's relative size is a key correlate of its access to central executive power. Using data on 575 groups across 181 countries from 1946 to 2021, I document a robust inverted-U-shaped relationship: groups of intermediate size are significantly more likely to gain political inclusion than both very small and very large ones. A simple model explains this pattern as the result of elite trade-offs between the risks of conflict from exclusion and the costs of sharing political rents. The model further predicts-and the data confirm-that the inverted-U is most pronounced in countries with historically competitive institutions. These findings offer new insight into the joint role of ethnic composition and institutions in shaping patterns of ethnic political inclusion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2003.08064v2</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hector Galindo-Silva</dc:creator>
    </item>
    <item>
      <title>Forecasting House Prices</title>
      <link>https://arxiv.org/abs/2509.21460</link>
      <description>arXiv:2509.21460v2 Announce Type: replace 
Abstract: This article identifies the factors that drove house prices in 13 advanced countries over the past 35 years. It does so based on Breiman s (2001) random forest model. Shapley values indicate that annual house price growth across countries is explained first and foremost by price momentum, initial valuations (proxied by price to rent ratios) and household credit growth. Partial effects of explanatory variables are also elicited and suggest important non-linearities, for instance as to what concerns the effects of CPI inflation on house price growth. The out-of-sample forecast test reveals that the random forest model delivers 44% lower house price variation root square mean errors (RMSEs) and 45% lower mean absolute errors (MAEs) when compared to an OLS model that uses the same set of 10 pre-determined explanatory variables. Notably, the same model works well for all countries, as the random forest attributes minimal values to country fixed effects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21460v2</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Emanuel Kohlscheen</dc:creator>
    </item>
    <item>
      <title>When Indemnity Insurance Fails: Parametric Coverage under Binding Budget and Risk Constraints</title>
      <link>https://arxiv.org/abs/2512.21973</link>
      <description>arXiv:2512.21973v5 Announce Type: replace 
Abstract: In high-risk environments, traditional indemnity insurance is often unaffordable or ineffective, despite its well-known optimality under expected utility. We compare excess-of-loss indemnity insurance with parametric insurance within a common mean-variance framework, allowing for fixed costs, heterogeneous premium loadings, and binding budget constraints. Motivated by the disaster insurance and risk-sharing literature, we show that, once these realistic frictions are introduced, parametric insurance can yield higher welfare for risk-averse individuals, even under the same utility objective and without relying on behavioral assumptions. The welfare advantage arises precisely when indemnity insurance becomes impractical, and disappears once both contracts are unconstrained. Our results help reconcile classical insurance theory with the growing use of parametric risk transfer in high-risk settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.21973v5</guid>
      <category>econ.GN</category>
      <category>math.OC</category>
      <category>q-fin.EC</category>
      <category>q-fin.RM</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Benjamin Avanzi, Debbie Kusch Falden, Mogens Steffensen</dc:creator>
    </item>
    <item>
      <title>Global Inequalities in Clinical Trials Participation</title>
      <link>https://arxiv.org/abs/2601.04660</link>
      <description>arXiv:2601.04660v2 Announce Type: replace 
Abstract: Clinical trials shape medical evidence and determine who gains access to experimental therapies. Whether participation in these trials reflects the global burden of disease remains unclear. Here we analyze participation inequality across more than 62,000 randomized controlled trials spanning 16 major disease categories from 2000 to 2024. Linking 36.8 million trial participants to country-level disease burden, we show that global inequality in clinical trials participation is overwhelmingly shaped by country rather than disease burden. Country-level factors explain over 90% of variation in participation, whereas disease-specific effects contribute only marginally. Removing entire disease categories-including those traditionally considered underfunded-has little effect on overall inequality. Instead, participation is highly concentrated geographically, with a small group of countries enrolling a disproportionate share of participants across nearly all diseases. These patterns have persisted despite decades of disease-targeted funding and increasing alignment between research attention and disease burden within diseases. Our findings indicate that disease-vertical strategies alone cannot correct participation inequality. Reducing global inequities in clinical research requires horizontal investments in research capacity, health infrastructure, and governance that operate across disease domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.04660v2</guid>
      <category>econ.GN</category>
      <category>cs.CE</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Wen Lou, Adri\'an A. D\'iaz-Faes, Jiangen He, Zhihao Liu, Vincent Larivi\`ere</dc:creator>
    </item>
    <item>
      <title>Modern approaches to building interpretable models of the property market using machine learning on the base of mass cadastral valuation</title>
      <link>https://arxiv.org/abs/2506.15723</link>
      <description>arXiv:2506.15723v3 Announce Type: replace-cross 
Abstract: In this paper, we review modern approaches to building interpretable models of property markets using machine learning on the base of mass valuation of property in the Primorye region, Russia. There are numerous potential difficulties one could encounter in the effort to build a good model. Their main source is the huge difference between noisy real market data and ideal data usually used in tutorials on machine learning. This paper covers all stages of modeling: collection of initial data, identification of outliers, search and analysis of patterns in the data, formation and final choice of price factors, building of the model, and evaluation of its efficiency. For each stage, we highlight potential issues and describe sound methods for overcoming emerging difficulties on actual examples. We show that the combination of classical linear regression with kriging (interpolation method of geostatistics) allows to build an effective model for land parcels. For flats, when many objects are attributed to one spatial point, the application of geostatistical methods becomes problematic. Instead, we suggest linear regression with automatic generation and selection of additional rules on the base of decision trees, so called the RuleFit method. We compare the performance of our inherently interpretable models with well-proven "black-box" Random Forest method and demonstrate similar results. Thus we show, that despite such a strong restriction as the requirement of interpretability which is important in practical aspects, for example, legal matters, it is still possible to build effective models of real property markets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.15723v3</guid>
      <category>q-fin.ST</category>
      <category>cs.LG</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <category>stat.AP</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alexey S. Tanashkin, Irina G. Tanashkina, Alexander S. Maksimchuik</dc:creator>
    </item>
  </channel>
</rss>
