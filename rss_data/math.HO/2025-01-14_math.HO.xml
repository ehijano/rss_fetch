<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.HO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.HO</link>
    <description>math.HO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.HO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 15 Jan 2025 02:34:19 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Convex pentagonal monotiles in the 15 Type families</title>
      <link>https://arxiv.org/abs/2501.07090</link>
      <description>arXiv:2501.07090v1 Announce Type: new 
Abstract: The properties of convex pentagonal monotiles in the 15 Type families and their tilings are summarized. The Venn diagrams of the 15 Type families are also shown.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.07090v1</guid>
      <category>math.HO</category>
      <category>math.CO</category>
      <category>math.MG</category>
      <pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Teruhisa Sugimoto</dc:creator>
    </item>
    <item>
      <title>Teaching "Foundations of Mathematics" with the Lean Theorem Prover</title>
      <link>https://arxiv.org/abs/2501.03352</link>
      <description>arXiv:2501.03352v3 Announce Type: replace 
Abstract: This study aims to observe if the theorem prover Lean positively influences students' understanding of mathematical proving. To this end, we perform a pilot study concerning freshmen students at the University of Zurich (UZH). While doing so, we apply certain teaching methods and gather data from the volunteer students enrolled in the ``Foundations of Mathematics'' course. After eleven weeks of study covering some exercise questions implemented with Lean, we measure Lean students' performances in proving mathematical statements, compared to other students who are not engaged with Lean. For this measurement, we interview five Lean and four Non-Lean students and we analyze the scores of all students in the final exam. Finally, we check significance by performing a $t$-test for independent samples and the Mann-Whitney $U$-test.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03352v3</guid>
      <category>math.HO</category>
      <pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mattia Luciano Bottoni, Alberto S. Cattaneo, Elif Sacikara</dc:creator>
    </item>
    <item>
      <title>Controlling Equational Reasoning in Large Language Models with Prompt Interventions</title>
      <link>https://arxiv.org/abs/2307.09998</link>
      <description>arXiv:2307.09998v5 Announce Type: replace-cross 
Abstract: This paper investigates how hallucination rates in Large Language Models (LLMs) may be controlled via a symbolic data generation framework, exploring a fundamental relationship between the rate of certain mathematical errors and types of input intervention. Specifically, we systematically generate data for a derivation generation task using a symbolic engine, applying targeted interventions to prompts to perturb features of mathematical derivations such as the surface forms of symbols, equational tree structures, and mathematical context. We then evaluate the effect of prompt interventions across a range of LLMs including fine-tuned T5 models, GPT, and LLaMa-based models. Our experiments suggest that T5-Large can outperform the few-shot performance of GPT-4 on various evaluation sets generated via the framework. However, an extensive evaluation based on human analysis, template-based error detection, and text generation metrics reveals model weaknesses beyond what the reference-based metrics singularly describe. We use these results to tie characteristic distributional footprints of interventions to the human evaluation of LLM derivation quality, potentially leading to significant control over fine-grained mathematical capabilities of language models with respect to specific types of errors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.09998v5</guid>
      <category>cs.CL</category>
      <category>math.HO</category>
      <pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jordan Meadows, Marco Valentino, Andre Freitas</dc:creator>
    </item>
  </channel>
</rss>
