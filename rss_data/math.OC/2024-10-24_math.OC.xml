<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 24 Oct 2024 04:00:36 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 24 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Two-stage heuristic algorithm for a new variant of the multi-compartment vehicle routing problem with stochastic demands</title>
      <link>https://arxiv.org/abs/2410.17302</link>
      <description>arXiv:2410.17302v1 Announce Type: new 
Abstract: This paper presents a model for a vehicle routing problem in which customer demands are stochastic and vehicles are divided into compartments. The problem is motivated by the needs of certain agricultural cooperatives that produce various types of livestock food. The vehicles and their compartments have different capacities, and each compartment can only contain one type of feed. Additionally, certain farms can only be accessed by specific vehicles, and there may be urgency constraints. To solve the problem, a two-step heuristic algorithm is proposed. First, a constructive heuristic is applied, followed by an improvement phase based on iterated tabu search. The designed algorithm is tested on several instances, including an analysis of real-world datasets where the results are compared with those provided by the model. Furthermore, multiple benchmark instances are created for this problem and an extensive simulation study is conducted. Results are presented for different model parameters, and it is shown that, despite the problems' complexity, the algorithm performs efficiently. Finally, the proposed heuristic is compared to existing solution algorithms for similar problems using benchmark instances from the literature, achieving competitive results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.17302v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 24 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Juan Carlos Gon\c{c}alves-Dosantos, Laura Davila-Pena, Balbina Casas-M\'endez</dc:creator>
    </item>
    <item>
      <title>Nonsmooth rank-one symmetric matrix factorization landscape</title>
      <link>https://arxiv.org/abs/2410.17487</link>
      <description>arXiv:2410.17487v1 Announce Type: new 
Abstract: We consider nonsmooth rank-one symmetric matrix factorization. It has no spurious second-order stationary points.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.17487v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 24 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>C\'edric Josz, Lexiao Lai</dc:creator>
    </item>
    <item>
      <title>Optimal Impulse Control for Cyber Risk Management</title>
      <link>https://arxiv.org/abs/2410.17706</link>
      <description>arXiv:2410.17706v1 Announce Type: new 
Abstract: We explore an optimal impulse control problem wherein an electronic device owner strategically calibrates protection levels against cyber attacks. Utilizing epidemiological compartment models, we qualitatively characterize the dynamics of cyber attacks within the network. We determine the optimal protective measures against effective hacking by formulating and solving a stochastic control problem with optimal switching. We demonstrate that the value function for the cluster owner constitutes a viscosity solution to a system of coupled variational inequalities associated with a fully coupled reflected backward stochastic differential equation (BSDE). Furthermore, we devise a comprehensive algorithm alongside a verification procedure to ascertain the optimal timing for network protection across various cyber attack scenarios. Our findings are illustrated through numerical approximations employing deep Galerkin methods for partial differential equations (PDEs). We visualize the optimal protection strategies in the context of two distinct attack scenarios: (1) a constant cyber attack, (2) an exogenous cyber attack strategy modeled with a Poisson process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.17706v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Thu, 24 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Caroline Hillairet (ENSAE Paris), Thibaut Mastrolia (UC Berkeley), Wissal Sabbagh (LMM)</dc:creator>
    </item>
    <item>
      <title>QICS: Quantum Information Conic Solver</title>
      <link>https://arxiv.org/abs/2410.17803</link>
      <description>arXiv:2410.17803v1 Announce Type: new 
Abstract: We introduce QICS (Quantum Information Conic Solver), an open-source primal-dual interior point solver fully implemented in Python, which is focused on solving optimization problems arising in quantum information theory. QICS has the ability to solve optimization problems involving the quantum relative entropy, noncommutative perspectives of operator convex functions, and related functions. It also includes an efficient semidefinite programming solver which exploits sparsity, as well as support for Hermitian matrices. QICS is also currently supported by the Python optimization modelling software PICOS. This paper aims to document the implementation details of the algorithm and cone oracles used in QICS, and serve as a reference guide for the software. Additionally, we showcase extensive numerical experiments which demonstrate that QICS outperforms state-of-the-art quantum relative entropy programming solvers, and has comparable performance to state-of-the-art semidefinite programming solvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.17803v1</guid>
      <category>math.OC</category>
      <category>quant-ph</category>
      <pubDate>Thu, 24 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kerry He, James Saunderson, Hamza Fawzi</dc:creator>
    </item>
    <item>
      <title>Solving the n-Queens Problem in Higher Dimensions</title>
      <link>https://arxiv.org/abs/2410.17873</link>
      <description>arXiv:2410.17873v1 Announce Type: new 
Abstract: How many mutually non-attacking queens can be placed on a d-dimensional chessboard of size n? The n-queens problem in higher dimensions is a generalization of the well-known n-queens problem. We present an integer programming formulation of the n-queens problem in higher dimensions and several strengthenings through additional valid inequalities. Compared to recent benchmarks, we achieve a speedup in computational time between 15-70x over all instances of the integer programs. Our computational results prove optimality of certificates for several large instances. Breaking additional, previously unsolved instances with the proposed methods is likely possible. On the primal side, we further discuss heuristic approaches to constructing solutions that turn out to be optimal when compared to the IP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.17873v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 24 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tim Kunt</dc:creator>
    </item>
    <item>
      <title>An extension of an RLT-based solver to MINLP polynomial problems</title>
      <link>https://arxiv.org/abs/2410.17949</link>
      <description>arXiv:2410.17949v1 Announce Type: new 
Abstract: In this paper we extend the core branch-and-bound algorithm of an RLT-based solver for continuous polynomial optimization, RAPOSa, to handle mixed-integer problems. We do so by a direct adaptation, in which LP relaxations are replaced with MILP ones and, therefore, the additional burden caused by the discrete variables is taken care of by the auxiliary MILP solver. The analysis then focuses on the impact of a number of choices that must be made for the resulting algorithm to be effective at providing good lower and upper bounds upon termination.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.17949v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 24 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julio Gonz\'alez-D\'iaz, Brais Gonz\'alez-Rodr\'iguez, Iria Rodr\'iguez-Acevedo</dc:creator>
    </item>
    <item>
      <title>Deep Uzawa for PDE constrained optimisation</title>
      <link>https://arxiv.org/abs/2410.17359</link>
      <description>arXiv:2410.17359v1 Announce Type: cross 
Abstract: In this work, we present a numerical solver for optimal control problems constrained by linear and semi-linear second-order elliptic PDEs. The approach is based on recasting the problem and includes an extension of Uzawa's algorithm to build approximating sequences for these constrained optimal control problems. We prove strong convergence of the iterative scheme in their respective norms, and this convergence is generalised to a class of restricted function spaces. We showcase the algorithm by demonstrating its use numerically with neural network methods that we coin Deep Uzawa Algorithms and show they perform favourably compared with some existing Deep Neural Network approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.17359v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 24 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Charalambos G. Makridakis, Aaron Pim, Tristan Pryer</dc:creator>
    </item>
    <item>
      <title>Experimental Designs for Optimizing Last-Mile Delivery</title>
      <link>https://arxiv.org/abs/2410.17392</link>
      <description>arXiv:2410.17392v1 Announce Type: cross 
Abstract: Companies like Amazon and UPS are heavily invested in last-mile delivery problems. Optimizing last-delivery operations not only creates tremendous cost savings for these companies but also generate broader societal and environmental benefits in terms of better delivery service and reduced air pollutants and greenhouse gas emissions. Last-mile delivery is readily formulated as the Travelling Salesman Problem (TSP), where a salesperson must visit several cities and return to the origin with the least cost. A solution to this problem is a Hamiltonian circuit in an undirected graph. Many methods exist for solving the TSP, but they often assume the travel costs are fixed. In practice, travel costs between delivery zones are random quantities, as they are subject to variation from traffic, weather, and other factors. Innovations such as truck-drone last-mile delivery creates even more uncertainties due to scarce data. A Bayesian D-optimal experimental design in conjunction with a regression model are proposed to estimate these unknown travel costs, and subsequently search for a highly efficient solution to the TSP. This framework can naturally be extended to incorporate the use of drones and any other emerging technology that has use in last-mile delivery.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.17392v1</guid>
      <category>stat.AP</category>
      <category>math.OC</category>
      <pubDate>Thu, 24 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicholas Rios, Jie Xu</dc:creator>
    </item>
    <item>
      <title>Primal-Dual Spectral Representation for Off-policy Evaluation</title>
      <link>https://arxiv.org/abs/2410.17538</link>
      <description>arXiv:2410.17538v1 Announce Type: cross 
Abstract: Off-policy evaluation (OPE) is one of the most fundamental problems in reinforcement learning (RL) to estimate the expected long-term payoff of a given target policy with only experiences from another behavior policy that is potentially unknown. The distribution correction estimation (DICE) family of estimators have advanced the state of the art in OPE by breaking the curse of horizon. However, the major bottleneck of applying DICE estimators lies in the difficulty of solving the saddle-point optimization involved, especially with neural network implementations. In this paper, we tackle this challenge by establishing a linear representation of value function and stationary distribution correction ratio, i.e., primal and dual variables in the DICE framework, using the spectral decomposition of the transition operator. Such primal-dual representation not only bypasses the non-convex non-concave optimization in vanilla DICE, therefore enabling an computational efficient algorithm, but also paves the way for more efficient utilization of historical data. We highlight that our algorithm, SpectralDICE, is the first to leverage the linear representation of primal-dual variables that is both computation and sample efficient, the performance of which is supported by a rigorous theoretical sample complexity guarantee and a thorough empirical evaluation on various benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.17538v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Thu, 24 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yang Hu, Tianyi Chen, Na Li, Kai Wang, Bo Dai</dc:creator>
    </item>
    <item>
      <title>Constraint Removal for MPC with Performance Preservation and a Hyperthermia Cancer Treatment Case Study</title>
      <link>https://arxiv.org/abs/2410.17639</link>
      <description>arXiv:2410.17639v1 Announce Type: cross 
Abstract: Model predictive control (MPC) is an optimization-based control strategy with broad industrial adoption. Unfortunately, the required computation time to solve the receding-horizon MPC optimization problem can become prohibitively large for many applications with a large number of state constraints. This large number of state constraints can, for instance, originate from spatially discretizing a partial differential equation of which the solution has to satisfy constraints over the full spatial domain. This is particularly the case in MPC for RF-based hyperthermia cancer treatments, which forms a strong motivation for this study. To address this problem, we propose a novel constraint-adaptive MPC framework for linear discrete-time systems. In this framework, we select at each time-step a subset of the state constraints that are included in the optimization problem, thereby reducing the online computational burden. Critically, our framework guarantees the same closed-loop performance, recursive feasibility, and constraint satisfaction properties as the original (non-reduced) MPC scheme. We achieve this result by efficiently exploiting reachable set computations and the MPC cost function. We will demonstrate our novel method using a hyperthermia cancer treatment case study showing a two-orders of magnitude improvement in computation time, with identical closed-loop performance as the original (non-reduced) MPC scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.17639v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 24 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1109/CDC45484.2021.9683158</arxiv:DOI>
      <dc:creator>S. A. N. Nouwens, B. de Jager, M. M. Paulides, W. P. M. H. Heemels</dc:creator>
    </item>
    <item>
      <title>Strategic Irreversible Investment</title>
      <link>https://arxiv.org/abs/2410.17673</link>
      <description>arXiv:2410.17673v1 Announce Type: cross 
Abstract: This paper studies oligopolistic irreversible investment with closed-loop strategies. These permit fully dynamic interactions that result in much richer strategic behavior than previous studies with open-loop strategies allow. The tradeoff between preemption incentives and the option value of waiting becomes distinctly visible. Strategies that depend on present capital stocks enable credible reactions that deter from excessive preemption and support positive option values in equilibrium. Simpler strategies lead into a "preemption trap" with perfectly competitive outcome and zero net present values. To obtain these results, a novel concept of Markov perfect equilibrium is developed that copes with optimal investment taking the form of singular control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.17673v1</guid>
      <category>econ.TH</category>
      <category>math.OC</category>
      <category>q-fin.GN</category>
      <pubDate>Thu, 24 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jan-Henrik Steg</dc:creator>
    </item>
    <item>
      <title>Reinforcement Learning under Latent Dynamics: Toward Statistical and Algorithmic Modularity</title>
      <link>https://arxiv.org/abs/2410.17904</link>
      <description>arXiv:2410.17904v1 Announce Type: cross 
Abstract: Real-world applications of reinforcement learning often involve environments where agents operate on complex, high-dimensional observations, but the underlying (''latent'') dynamics are comparatively simple. However, outside of restrictive settings such as small latent spaces, the fundamental statistical requirements and algorithmic principles for reinforcement learning under latent dynamics are poorly understood.
  This paper addresses the question of reinforcement learning under $\textit{general}$ latent dynamics from a statistical and algorithmic perspective. On the statistical side, our main negative result shows that most well-studied settings for reinforcement learning with function approximation become intractable when composed with rich observations; we complement this with a positive result, identifying latent pushforward coverability as a general condition that enables statistical tractability. Algorithmically, we develop provably efficient observable-to-latent reductions -- that is, reductions that transform an arbitrary algorithm for the latent MDP into an algorithm that can operate on rich observations -- in two settings: one where the agent has access to hindsight observations of the latent dynamics [LADZ23], and one where the agent can estimate self-predictive latent models [SAGHCB20]. Together, our results serve as a first step toward a unified statistical and algorithmic theory for reinforcement learning under latent dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.17904v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 24 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Philip Amortila, Dylan J. Foster, Nan Jiang, Akshay Krishnamurthy, Zakaria Mhammedi</dc:creator>
    </item>
    <item>
      <title>On the Viability of Stochastic Economic Dispatch for Real-Time Energy Market Clearing</title>
      <link>https://arxiv.org/abs/2308.06386</link>
      <description>arXiv:2308.06386v2 Announce Type: replace 
Abstract: Over the past decade, the rapid adoption of intermittent renewable energy sources (RES), especially wind and solar generation, has posed challenges in managing real-time uncertainty and variability. In the U.S., Independent System Operators (ISOs) solve a security-constrained economic dispatch (SCED) every five minutes to clear real-time electricity markets, co-optimizing energy dispatch and reserve to minimize costs while meeting physical and reliability constraints. All SCED formulations in the U.S. are deterministic and mostly consider a single time period, limiting their effectiveness in managing real-time operational uncertainty from RES intermittency. This limitation is highlighted by the recent introduction of multiple short-term ramping products in U.S. markets, aiming to bridge the gap between deterministic and stochastic SCED formulations. While stochastic formulations address uncertainty in a unified and endogenous manner, their adoption has been hindered by high computational costs and, to a lesser extent, the availability of probabilistic forecasts. This paper revisits these concerns and demonstrates that stochastic economic dispatch is now a viable technology for real-time market clearing. It introduces the stochastic look-ahead dispatch (SLAD) formulation for real-time market clearing and presents an accelerated Benders' decomposition to solve it efficiently. Extensive experiments on a real, industry-sized transmission grid demonstrate the computational scalability of the proposed approach, with SLAD instances being solved in under 5 minutes. Furthermore, results show that SLAD provides more than 50% additional savings compared to flexiramp products and is more robust to the forecasting methodology. Therefore, SLAD is a promising approach for uncertainty management in real-time electricity markets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.06386v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 24 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haoruo Zhao, Mathieu Tanneau, Pascal Van Hentenryck</dc:creator>
    </item>
    <item>
      <title>Computing Wasserstein Barycenter via operator splitting: the method of averaged marginals</title>
      <link>https://arxiv.org/abs/2309.05315</link>
      <description>arXiv:2309.05315v2 Announce Type: replace 
Abstract: The Wasserstein barycenter (WB) is an important tool for summarizing sets of probability measures. It finds applications in applied probability, clustering, image processing, etc. When the measures' supports are finite, computing a (balanced) WB can be done by solving a linear optimization problem whose dimensions generally exceed standard solvers' capabilities. In the more general setting where measures have different total masses, we propose a convex nonsmooth optimization formulation for the so-called unbalanced WB problem. Due to their colossal dimensions, we introduce a decomposition scheme based on the Douglas-Rachford splitting method that can be applied to both balanced and unbalanced WB problem variants.Our algorithm, which has the interesting interpretation of being built upon averaging marginals, operates a series of simple (and exact) projections that can be parallelized and even randomized, making it suitable for large-scale datasets. Numerical comparisons against state-of-the-art methods on several data sets from the literature illustrate the method's performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.05315v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 24 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Mimouni (IFPEN), P Malisani (IFPEN), J. Zhu (IFPEN), W. de Oliveira (CMA)</dc:creator>
    </item>
    <item>
      <title>Fourier Galerkin approximation of mean field control problems</title>
      <link>https://arxiv.org/abs/2403.15642</link>
      <description>arXiv:2403.15642v2 Announce Type: replace 
Abstract: The purpose of this work is to provide a finite dimensional approximation of the solution to a mean field optimal control problem set on the $d$-dimensional torus. The approximation is obtained by means of a Fourier-Galerkin method, the main principle of which is to convolve probability measures on the torus by the Dirichlet kernel or, equivalently, to truncate the Fourier expansion of probability measures on the torus. However, this operation has the main feature not to leave the space of probability measures invariant, which drawback is know as \textit{Gibbs}' phenomenon. In spite of this, we manage to prove that, for initial conditions in the `interior' of the space of probability measures and for sufficiently large levels of truncation, the Fourier-Galerkin method induces a new finite dimensional control problem whose trajectories take values in the space of probability measures with a finite number of Fourier coefficients. Our main result asserts that, whenever the cost functionals are smooth and convex, the distance between the optimal trajectories of the original and approximating control problems decreases at a polynomial rate as the index of truncation in the Fourier-Galerkin method tends to $\infty$. A similar result holds for the distance between the corresponding value functions. From a practical point of view, our approach provides an efficient strategy to approximate mean field control optimizers by finite dimensional parameters and opens new perspectives for the numerical analysis of mean field control problems. It may be also applied to discretize more general mean field game systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15642v2</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <category>math.PR</category>
      <pubDate>Thu, 24 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fran\c{c}ois Delarue, Mattia Martini</dc:creator>
    </item>
    <item>
      <title>Adaptive Variance Reduction for Stochastic Optimization under Weaker Assumptions</title>
      <link>https://arxiv.org/abs/2406.01959</link>
      <description>arXiv:2406.01959v2 Announce Type: replace 
Abstract: This paper explores adaptive variance reduction methods for stochastic optimization based on the STORM technique. Existing adaptive extensions of STORM rely on strong assumptions like bounded gradients and bounded function values, or suffer an additional $\mathcal{O}(\log T)$ term in the convergence rate. To address these limitations, we introduce a novel adaptive STORM method that achieves an optimal convergence rate of $\mathcal{O}(T^{-1/3})$ for non-convex functions with our newly designed learning rate strategy. Compared with existing approaches, our method requires weaker assumptions and attains the optimal convergence rate without the additional $\mathcal{O}(\log T)$ term. We also extend the proposed technique to stochastic compositional optimization, obtaining the same optimal rate of $\mathcal{O}(T^{-1/3})$. Furthermore, we investigate the non-convex finite-sum problem and develop another innovative adaptive variance reduction method that achieves an optimal convergence rate of $\mathcal{O}(n^{1/4} T^{-1/2} )$, where $n$ represents the number of component functions. Numerical experiments across various tasks validate the effectiveness of our method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01959v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 24 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wei Jiang, Sifan Yang, Yibo Wang, Lijun Zhang</dc:creator>
    </item>
    <item>
      <title>A multi-objective mixed integer linear programming model for supply chain planning of 3D printing</title>
      <link>https://arxiv.org/abs/2408.05213</link>
      <description>arXiv:2408.05213v2 Announce Type: replace 
Abstract: 3D printing is considered the future of production systems and one of the physical elements of the Fourth Industrial Revolution. 3D printing will significantly impact the product lifecycle, considering cost, energy consumption, and carbon dioxide emissions, leading to the creation of sustainable production systems. Given the importance of these production systems and their effects on the quality of life for future generations, it is expected that 3D printing will soon become one of the global industry's fundamental needs. Although three decades have passed since the emergence of 3D printers, there has not yet been much research on production planning and mass production using these devices. Therefore, we aimed to identify the existing gaps in the planning of 3D printers and to propose a model for planning and scheduling these devices. In this research, several parts with different heights, areas, and volumes have been considered for allocation on identical 3D printers for various tasks. To solve this problem, a multi-objective mixed integer linear programming model has been proposed to minimize the earliness and tardiness of parts production, considering their order delivery times, and maximizing machine utilization. Additionally, a method has been proposed for the placement of parts in 3D printers, leading to the selection of the best edge as the height. Using a numerical example, we have plotted the Pareto curve obtained from solving the model using the epsilon constraint method for several parts and analyzed the impact of the method for selecting the best edge as the height, with and without considering it. Additionally, a comprehensive sensitivity and scenario analysis has been conducted to validate the results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05213v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 24 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amirreza Talebi</dc:creator>
    </item>
    <item>
      <title>Controllability of Quasi-linear Parabolic Equations by Hierarchic Controls</title>
      <link>https://arxiv.org/abs/2410.08532</link>
      <description>arXiv:2410.08532v2 Announce Type: replace 
Abstract: This paper is devoted to studying a multi-objective control problem for a class of multi-dimensional quasi-linear parabolic equations. The considered system is driven by a leader control and two follower controls. For each leader control, a pair of follower controls is searched for as a Nash quasi-equilibrium (or Nash equilibrium) of cost functionals, while the aim for a leader control is to solve a controllability problem. This hierarchic control problem may be transformed into controllability of a strongly coupled system of quasi-linear parabolic equations through one control. Regarding controllability for quasi-linear parabolic equations of second order, the existing results usually require coefficients in principal parts to be independent of gradient of solutions, or spacial dimension to be limited. In this paper, the coefficients in principal parts for the controlled quasi-linear system contain not only the state itself but also its gradient with general spacial dimension.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08532v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 24 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yanming Dong, Xu Liu, Xu Zhang</dc:creator>
    </item>
    <item>
      <title>Convexoid: A Minimal Theory of Conjugate Convexity</title>
      <link>https://arxiv.org/abs/2410.08775</link>
      <description>arXiv:2410.08775v2 Announce Type: replace 
Abstract: A key idea in convex optimization theory is to use well-structured affine functions to approximate general functions, leading to impactful developments in conjugate functions and convex duality theory. This raises the question: what are the minimal requirements to establish these results? This paper aims to address this inquiry through a carefully crafted system called the convexoid. We demonstrate that fundamental constructs, such as conjugate functions and subdifferentials, along with their relationships, can be derived within this minimal system. Building on this, we define the associated duality systems and develop conditions for weak and strong duality, generalizing the classic results of conjugate duality theory. Due to its simplicity, our framework supports various approximation schemes, including approximating general functions using symmetric-conic, bilinear, or piecewise constant functions, and representing general structures such as graphs, set systems, fuzzy sets, or toposes using special membership functions. The associated duality results for these systems also open new opportunities for establishing bounds on objective values and verifying structural properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08775v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 24 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ningji Wei</dc:creator>
    </item>
    <item>
      <title>Out-of-distribution Robust Optimization</title>
      <link>https://arxiv.org/abs/2410.14899</link>
      <description>arXiv:2410.14899v2 Announce Type: replace 
Abstract: In this paper, we consider the contextual robust optimization problem under an out-of-distribution setting. The contextual robust optimization problem considers a risk-sensitive objective function for an optimization problem with the presence of a context vector (also known as covariates or side information) capturing related information. While the existing works mainly consider the in-distribution setting, and the resultant robustness achieved is in an out-of-sample sense, our paper studies an out-of-distribution setting where there can be a difference between the test environment and the training environment where the data are collected. We propose methods that handle this out-of-distribution setting, and the key relies on a density ratio estimation for the distribution shift. We show that additional structures such as covariate shift and label shift are not only helpful in defending distribution shift but also necessary in avoiding non-trivial solutions compared to other principled methods such as distributionally robust optimization. We also illustrate how the covariates can be useful in this procedure. Numerical experiments generate more intuitions and demonstrate that the proposed methods can help avoid over-conservative solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14899v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 24 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhongze Cai, Hansheng Jiang, Xiaocheng Li</dc:creator>
    </item>
    <item>
      <title>Using Stochastic Gradient Descent to Smooth Nonconvex Functions: Analysis of Implicit Graduated Optimization</title>
      <link>https://arxiv.org/abs/2311.08745</link>
      <description>arXiv:2311.08745v5 Announce Type: replace-cross 
Abstract: The graduated optimization approach is a heuristic method for finding global optimal solutions for nonconvex functions by using a function smoothing operation with stochastic noise. We show that stochastic noise in stochastic gradient descent (SGD) has the effect of smoothing the objective function, the degree of which is determined by the learning rate, batch size, and variance of the stochastic gradient. Using this finding, we propose and analyze a new graduated optimization algorithm that varies the degree of smoothing by varying the learning rate and batch size, and provide experimental results on image classification tasks with ResNets that support our theoretical findings. We further show that there is an interesting correlation between the degree of smoothing by SGD's stochastic noise, the well-studied ``sharpness'' indicator, and the generalization performance of the model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.08745v5</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 24 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Naoki Sato, Hideaki Iiduka</dc:creator>
    </item>
    <item>
      <title>Efficient Sign-Based Optimization: Accelerating Convergence via Variance Reduction</title>
      <link>https://arxiv.org/abs/2406.00489</link>
      <description>arXiv:2406.00489v2 Announce Type: replace-cross 
Abstract: Sign stochastic gradient descent (signSGD) is a communication-efficient method that transmits only the sign of stochastic gradients for parameter updating. Existing literature has demonstrated that signSGD can achieve a convergence rate of $\mathcal{O}(d^{1/2}T^{-1/4})$, where $d$ represents the dimension and $T$ is the iteration number. In this paper, we improve this convergence rate to $\mathcal{O}(d^{1/2}T^{-1/3})$ by introducing the Sign-based Stochastic Variance Reduction (SSVR) method, which employs variance reduction estimators to track gradients and leverages their signs to update. For finite-sum problems, our method can be further enhanced to achieve a convergence rate of $\mathcal{O}(m^{1/4}d^{1/2}T^{-1/2})$, where $m$ denotes the number of component functions. Furthermore, we investigate the heterogeneous majority vote in distributed settings and introduce two novel algorithms that attain improved convergence rates of $\mathcal{O}(d^{1/2}T^{-1/2} + dn^{-1/2})$ and $\mathcal{O}(d^{1/4}T^{-1/4})$ respectively, outperforming the previous results of $\mathcal{O}(dT^{-1/4} + dn^{-1/2})$ and $\mathcal{O}(d^{3/8}T^{-1/8})$, where $n$ represents the number of nodes. Numerical experiments across different tasks validate the effectiveness of our proposed methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00489v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 24 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wei Jiang, Sifan Yang, Wenhao Yang, Lijun Zhang</dc:creator>
    </item>
    <item>
      <title>Mitigating Information Asymmetry in Two-Stage Contracts with Non-Myopic Agents</title>
      <link>https://arxiv.org/abs/2406.12648</link>
      <description>arXiv:2406.12648v2 Announce Type: replace-cross 
Abstract: We consider a Stackelberg game in which a principal (she) establishes a two-stage contract with a non-myopic agent (he) whose type is unknown. The contract takes the form of an incentive function mapping the agent's first-stage action to his second-stage incentive. While the first-stage action reveals the agent's type under truthful play, a non-myopic agent could benefit from portraying a false type in the first stage to obtain a larger incentive in the second stage. The challenge is thus for the principal to design the incentive function so as to induce truthful play. We show that this is only possible with a constant, non-reactive incentive functions when the type space is continuous, whereas it can be achieved with reactive functions for discrete types. Additionally, we show that introducing an adjustment mechanism that penalizes inconsistent behavior across both stages allows the principal to design more flexible incentive functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12648v2</guid>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 24 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Munther A. Dahleh, Thibaut Horel, M. Umar B. Niazi</dc:creator>
    </item>
  </channel>
</rss>
