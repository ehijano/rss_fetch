<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 11 Oct 2024 02:24:44 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Exact sensitivity analysis of Markov reward processes via algebraic geometry</title>
      <link>https://arxiv.org/abs/2410.05471</link>
      <description>arXiv:2410.05471v1 Announce Type: new 
Abstract: We introduce a new approach for deterministic sensitivity analysis of Markov reward processes, commonly used in cost-effectiveness analyses, via reformulation into a polynomial system. Our approach leverages cylindrical algebraic decomposition (CAD), a technique arising from algebraic geometry that provides an exact description of all solutions to a polynomial system. While it is typically intractable to build a CAD for systems with more than a few variables, we show that a special class of polynomial systems, which includes the polynomials arising from Markov reward processes, can be analyzed much more tractably. We establish several theoretical results about such systems and develop a specialized algorithm to construct their CAD, which allows us to perform exact, multi-way sensitivity analysis for common health economic analyses. We develop an open-source software package that implements our algorithm. Finally, we apply it to two case studies, one with synthetic data and one that re-analyzes a previous cost-effectiveness analysis from the literature, demonstrating advantages of our approach over standard techniques. Our software and code are available at: \url{https://github.com/mmaaz-git/markovag}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05471v1</guid>
      <category>math.OC</category>
      <category>cs.MS</category>
      <category>math.AG</category>
      <category>math.PR</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Timothy C. Y. Chan, Muhammad Maaz</dc:creator>
    </item>
    <item>
      <title>Quadratically-Regularized Distributed Optimal Transport on Graphs</title>
      <link>https://arxiv.org/abs/2410.05509</link>
      <description>arXiv:2410.05509v1 Announce Type: new 
Abstract: Optimal transport on a graph focuses on finding the most efficient way to transfer resources from one distribution to another while considering the graph's structure. This paper introduces a new distributed algorithm that solves the optimal transport problem on directed, strongly connected graphs, unlike previous approaches which were limited to bipartite graphs. Our algorithm incorporates quadratic regularization and guarantees convergence using the Alternating Direction Method of Multipliers (ADMM). Notably, it proves convergence not only with quadratic regularization but also in cases without it, whereas earlier works required strictly convex objective functions.
  In this approach, nodes are treated as agents that collaborate through local interactions to optimize the total transportation cost, relying only on information from their neighbors. Through numerical experiments, we show how quadratic regularization affects both convergence behavior and solution sparsity under different graph structures. Additionally, we provide a practical example that highlights the algorithm's robustness through its ability to adjust to topological changes in the graph.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05509v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yacine Mokhtari, Emmanuel Moulay, Patrick Coirault, J\'er\^ome Le Ny</dc:creator>
    </item>
    <item>
      <title>Towards Robust Spacecraft Trajectory Optimization via Transformers</title>
      <link>https://arxiv.org/abs/2410.05585</link>
      <description>arXiv:2410.05585v1 Announce Type: new 
Abstract: Future multi-spacecraft missions require robust autonomous trajectory optimization capabilities to ensure safe and efficient rendezvous operations. This capability hinges on solving non-convex optimal control problems in real time, although traditional iterative methods such as sequential convex programming impose significant computational challenges. To mitigate this burden, the Autonomous Rendezvous Transformer introduced a generative model trained to provide near-optimal initial guesses. This approach provides convergence to better local optima (e.g., fuel optimality), improves feasibility rates, and results in faster convergence speed of optimization algorithms through warm-starting. This work extends the capabilities of ART to address robust chance-constrained optimal control problems. Specifically, ART is applied to challenging rendezvous scenarios in Low Earth Orbit (LEO), ensuring fault-tolerant behavior under uncertainty. Through extensive experimentation, the proposed warm-starting strategy is shown to consistently produce high-quality reference trajectories, achieving up to 30% cost improvement and 50% reduction in infeasible cases compared to conventional methods, demonstrating robust performance across multiple state representations. Additionally, a post hoc evaluation framework is proposed to assess the quality of generated trajectories and mitigate runtime failures, marking an initial step toward the reliable deployment of AI-driven solutions in safety-critical autonomous systems such as spacecraft.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05585v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.RO</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuji Takubo, Tommaso Guffanti, Daniele Gammelli, Marco Pavone, Simone D'Amico</dc:creator>
    </item>
    <item>
      <title>Data Informativity for Quadratic Stabilization under Data Perturbation</title>
      <link>https://arxiv.org/abs/2410.05702</link>
      <description>arXiv:2410.05702v1 Announce Type: new 
Abstract: Assessing data informativity, determining whether the measured data contains sufficient information for a specific control objective, is a fundamental challenge in data-driven control. In noisy scenarios, existing studies deal with system noise and measurement noise separately, using quadratic matrix inequalities. Moreover, the analysis of measurement noise requires restrictive assumptions on noise properties. To provide a unified framework without any restrictions, this study introduces data perturbation, a novel notion that encompasses both existing noise models. It is observed that the admissible system set with data perturbation does not meet preconditions necessary for applying the key lemma in the matrix S-procedure. Our analysis overcomes this limitation by developing an extended version of this lemma, making it applicable to data perturbation. Our results unify the existing analyses while eliminating the need for restrictive assumptions made in the measurement noise scenario.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05702v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Taira Kaminaga, Hampei Sasahara</dc:creator>
    </item>
    <item>
      <title>Characterization of input-to-output stability for infinite dimensional systems</title>
      <link>https://arxiv.org/abs/2410.06013</link>
      <description>arXiv:2410.06013v1 Announce Type: new 
Abstract: We prove a superposition theorem for input-to-output stability (IOS) of a broad class of nonlinear infinite-dimensional systems with outputs including both continuous-time and discrete-time systems. It contains, as a special case, the superposition theorem for input-to-state stability (ISS) of infinite-dimensional systems from [1] and the IOS superposition theorem for systems of ordinary differential equations from [2]. To achieve this result, we introduce and examine several novel stability and attractivity concepts for infinite dimensional systems with outputs: We prove criteria for the uniform limit property for systems with outputs, several of which are new already for systems with full-state output, we provide superposition theorems for systems which satisfy both the output-Lagrange stability property (OL) and IOS, give a sufficient condition for OL and characterize ISS in terms of IOS and input/output-to-state stability. Finally, by means of counterexamples, we illustrate the challenges appearing on the way of extension of the superposition theorems from [1] and [2] to infinite-dimensional systems with outputs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06013v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Patrick Bachmann, Sergey Dashkovskiy, Andrii Mironchenko</dc:creator>
    </item>
    <item>
      <title>A note on existence and asymptotic behavior of Lagrangian equilibria for first-order optimal-exit mean field games</title>
      <link>https://arxiv.org/abs/2410.06073</link>
      <description>arXiv:2410.06073v1 Announce Type: new 
Abstract: In this paper, we consider a first-order mean field game model motivated by crowd motion in which agents evolve in a (not necessarily compact) metric space and wish to reach a given target set. Each agent aims to minimize the sum of their travel time and an exit cost which depends on their exit position on the target set. Agents interact through their dynamics, the maximal speed of an agent being assumed to be a function of their position and the distribution of other agents. This interaction may model, in particular, congestion phenomena. Under suitable assumptions on the model, we prove existence of Lagrangian equilibria, analyze the asymptotic behavior for large time of the distribution of agents, and study the dependence of equilibria and asymptotic limits on the initial distribution of the agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06073v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guilherme Mazanti</dc:creator>
    </item>
    <item>
      <title>Solvability of Equilibrium Riccati Equations: A Direct Approach</title>
      <link>https://arxiv.org/abs/2410.06090</link>
      <description>arXiv:2410.06090v1 Announce Type: new 
Abstract: The solvability of equilibrium Riccati equations (EREs) plays a central role in the study of time-inconsistent stochastic linear-quadratic optimal control problems, because it paves the way to constructing a closed-loop equilibrium strategy. Under the standard conditions, Yong [29] established its well-posedness by introducing the well-known multi-person differential game method. However, this method depends on the dynamic programming principle (DPP) of the sophisticated problems on every subinterval, and thus is essentially a control theory approach. In this paper, we shall give a new and more direct proof, in which the DPP is no longer needed. We first establish a priori estimates for the ERE in the case of smooth coefficients. Using this estimate, we then demonstrate both the local and global solvability of the ERE by constructing an appropriate Picard iteration sequence, which actually provides a numerical algorithm. Additionally, a mollification method is employed to handle the case with non-smooth coefficients.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06090v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bowen Ma, Hanxiao Wang</dc:creator>
    </item>
    <item>
      <title>A column generation algorithm with dynamic constraint aggregation for minimum sum-of-squares clustering</title>
      <link>https://arxiv.org/abs/2410.06187</link>
      <description>arXiv:2410.06187v1 Announce Type: new 
Abstract: The minimum sum-of-squares clustering problem (MSSC), also known as $k$-means clustering, refers to the problem of partitioning $n$ data points into $k$ clusters, with the objective of minimizing the total sum of squared Euclidean distances between each point and the center of its assigned cluster. We propose an efficient algorithm for solving large-scale MSSC instances, which combines column generation (CG) with dynamic constraint aggregation (DCA) to effectively reduce the number of constraints considered in the CG master problem. DCA was originally conceived to reduce degeneracy in set partitioning problems by utilizing an aggregated restricted master problem obtained from a partition of the set partitioning constraints into disjoint clusters. In this work, we explore the use of DCA within a CG algorithm for MSSC exact solution. Our method is fine-tuned by a series of ablation studies on DCA design choices, and is demonstrated to significantly outperform existing state-of-the-art exact approaches available in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06187v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Antonio M. Sudoso, Daniel Aloise</dc:creator>
    </item>
    <item>
      <title>Model Predictive Control is Almost Optimal for Restless Bandit</title>
      <link>https://arxiv.org/abs/2410.06307</link>
      <description>arXiv:2410.06307v1 Announce Type: new 
Abstract: We consider the discrete time infinite horizon average reward restless markovian bandit (RMAB) problem. We propose a \emph{model predictive control} based non-stationary policy with a rolling computational horizon $\tau$. At each time-slot, this policy solves a $\tau$ horizon linear program whose first control value is kept as a control for the RMAB. Our solution requires minimal assumptions and quantifies the loss in optimality in terms of $\tau$ and the number of arms, $N$. We show that its sub-optimality gap is $O(1/\sqrt{N})$ in general, and $\exp(-\Omega(N))$ under a local-stability condition. Our proof is based on a framework from dynamic control known as \emph{dissipativity}. Our solution easy to implement and performs very well in practice when compared to the state of the art. Further, both our solution and our proof methodology can easily be generalized to more general constrained MDP settings and should thus, be of great interest to the burgeoning RMAB community.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06307v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Nicolas Gast, Dheeraj Narasimha</dc:creator>
    </item>
    <item>
      <title>Riemannian Optimization for Non-convex Euclidean Distance Geometry with Global Recovery Guarantees</title>
      <link>https://arxiv.org/abs/2410.06376</link>
      <description>arXiv:2410.06376v1 Announce Type: new 
Abstract: The problem of determining the configuration of points from partial distance information, known as the Euclidean Distance Geometry (EDG) problem, is fundamental to many tasks in the applied sciences. In this paper, we propose two algorithms grounded in the Riemannian optimization framework to address the EDG problem. Our approach formulates the problem as a low-rank matrix completion task over the Gram matrix, using partial measurements represented as expansion coefficients of the Gram matrix in a non-orthogonal basis. For the first algorithm, under a uniform sampling with replacement model for the observed distance entries, we demonstrate that, with high probability, a Riemannian gradient-like algorithm on the manifold of rank-$r$ matrices converges linearly to the true solution, given initialization via a one-step hard thresholding. This holds provided the number of samples, $m$, satisfies $m \geq \mathcal{O}(n^{7/4}r^2 \log(n))$. With a more refined initialization, achieved through resampled Riemannian gradient-like descent, we further improve this bound to $m \geq \mathcal{O}(nr^2 \log(n))$. Our analysis for the first algorithm leverages a non-self-adjoint operator and depends on deriving eigenvalue bounds for an inner product matrix of restricted basis matrices, leveraging sparsity properties for tighter guarantees than previously established. The second algorithm introduces a self-adjoint surrogate for the sampling operator. This algorithm demonstrates strong numerical performance on both synthetic and real data. Furthermore, we show that optimizing over manifolds of higher-than-rank-$r$ matrices yields superior numerical results, consistent with recent literature on overparameterization in the EDG problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06376v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chandler Smith, HanQin Cai, Abiy Tasissa</dc:creator>
    </item>
    <item>
      <title>Benders Decomposition for Robust Tactical Railway Crew Scheduling</title>
      <link>https://arxiv.org/abs/2410.06382</link>
      <description>arXiv:2410.06382v1 Announce Type: new 
Abstract: We consider robust tactical crew scheduling for a large passenger railway operator, who aims to inform crew early on about their work schedules while also maintaining the ability to respond to changes in the daily timetables. To resolve this conflict, the operator considers a template-based planning process, templates being time windows during which duties can later be scheduled. The goal is to select a cost-efficient set of templates that is robust with respect to uncertainty in the work to be performed in the operational phase. A set of templates is deemed robust when few excess duties are required to cover all work in the operational planning phase. To enable the construction of efficient template-based rosters, we impose several template rostering constraints that proxy the actual rostering rules of later planning steps. We propose a two-phase accelerated Benders decomposition algorithm that can incorporate these restrictions. Computational experiments on real-life instances from Netherlands Railways, featuring up to 948 tasks per day, show that historical planning information can be used to obtain robust templates and that parsimonious solutions can be obtained at negligible extra costs. Compared to a literature benchmark, our Benders decomposition method solves three times as many instances without rostering constraints to optimality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06382v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>B. T. C. van Rossum, T. Dollevoet, D. Huisman</dc:creator>
    </item>
    <item>
      <title>Embedded State Estimation for Optimization of Cislunar Space Domain Awareness Constellation Design</title>
      <link>https://arxiv.org/abs/2410.06425</link>
      <description>arXiv:2410.06425v1 Announce Type: new 
Abstract: The traffic in cislunar space is expected to increase over the coming years, leading to a higher likelihood of conjunction events among active satellites, orbital debris, and non-cooperative satellites. This increase necessitates enhanced space domain awareness (SDA) capabilities that include state estimation for targets of interest. Both Earth surface-based and space-based observation platforms in geosynchronous orbit or below face challenges such as range, exclusion, and occlusion that hinder observation. Motivated by the need to place space-based observers in the cislunar space regime to overcome these challenges, this paper proposes a cislunar SDA constellation design and analysis framework that integrates state estimation into an optimization problem for determining the placement of observers for optimal state estimation performance on a set of targets. The proposed multi-observer placement optimization problem samples from a range of possible target orbits. Upon convergence, the optimized constellation is validated against a broader set of targets to assess its effectiveness. Two comparative analyses are presented to evaluate the effects of changes in the sensor tasking procedure and sensor fidelity on the optimized constellation, comparing these to a single observer baseline case. The results demonstrate that the optimized constellations can provide accurate state estimation for various orbit families.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06425v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>physics.space-ph</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas H. Clareson, Matthew C. Fox, Dominic K. Amato, Hang Woon Lee</dc:creator>
    </item>
    <item>
      <title>Mirror descent method for stochastic multi-objective optimization</title>
      <link>https://arxiv.org/abs/2410.06632</link>
      <description>arXiv:2410.06632v1 Announce Type: new 
Abstract: Stochastic multi-objective optimization (SMOO) has recently emerged as a powerful framework for addressing machine learning problems with multiple objectives. The bias introduced by the nonlinearity of the subproblem solution mapping complicates the convergence analysis of multi-gradient methods. In this paper, we propose a novel SMOO method called the Multi-gradient Stochastic Mirror Descent (MSMD) method, which incorporates stochastic mirror descent method to solve the SMOO subproblem, providing convergence guarantees. By selecting an appropriate Bregman function, our method enables analytical solutions of the weighting vector and requires only a single gradient sample at each iteration. We demonstrate the sublinear convergence rate of our MSMD method under four different inner and outer step setups. For SMOO with preferences, we propose a variant of MSMD method and demonstrate its convergence rate. Through extensive numerical experiments, we compare our method with both stochastic descent methods based on weighted sum and state-of-the-art SMOO methods. Our method consistently outperforms these methods in terms of generating superior Pareto fronts on benchmark test functions while also achieving competitive results in neural network training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06632v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Linxi Yang, Liping Tang, Jiahao Lv, Yuehong He, Xinmin Yang</dc:creator>
    </item>
    <item>
      <title>Long-Term Multi-Objective Optimization for Integrated Unit Commitment and Investment Planning for District Heating Networks</title>
      <link>https://arxiv.org/abs/2410.06673</link>
      <description>arXiv:2410.06673v1 Announce Type: new 
Abstract: The need to decarbonize the energy system has intensified the focus on district heating networks in urban and suburban areas. Therefore, exploring transformation pathways with reasonable trade-offs between economic viability and environmental goals became necessary. We introduce a network-flow-based model class integrating unit commitment and long-term investment planning for multi-energy systems. While the integration of unit commitment and investment planning has been applied to multi-energy systems, a formal introduction and suitability for the application of long-term portfolio planning of an energy provider on an urban scale has yet to be met. Based on mixed integer linear programming, the model bridges the gap between overly detailed industrial modeling tools not designed for computational efficiency at scale and rather abstract academic models. The formulation is tested on Berlin's district heating network. Hence, the challenge lies in a large number of variables and constraints and the coupling of time steps, for example, through investment decisions. A case study explores different solutions on the Pareto front defined by optimal trade-offs between minimizing costs and CO2 emissions through a lexicographic optimization approach. The resulting solution catalog can provide decision-makers valuable insights into feasible transformation pathways, highlighting distinctions between robust and target-dependent investments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06673v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Stephanie Riedm\"uller, Fabian Rivetta, Janina Zittel</dc:creator>
    </item>
    <item>
      <title>Enhancing the sensing power of bike-sharing system for urban environment</title>
      <link>https://arxiv.org/abs/2410.06996</link>
      <description>arXiv:2410.06996v1 Announce Type: new 
Abstract: The development of smart cities requires innovative sensing solutions for efficient and low-cost urban environment monitoring. Bike-sharing systems, with their wide coverage, flexible mobility, and dense urban distribution, present a promising platform for pervasive sensing. At a relative early stage, research on bike-based sensing focuses on the application of data collected via passive sensing, without consideration of the optimization of data collection through sensor deployment or vehicle scheduling. To address this gap, this study integrates a binomial probability model with a mixed-integer linear programming model to optimize sensor allocation across bike stands. Additionally, an active scheduling strategy guides user bike selection to enhance the efficacy of data collection. A case study in Manhattan validates the proposed strategy, showing that equipping sensors on just 1\% of the bikes covers approximately 70\% of road segments in a day, highlighting the significant potential of bike-sharing systems for urban sensing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06996v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wen Ji, Ke Han, Qi Hao, Qian Ge, Ying Long</dc:creator>
    </item>
    <item>
      <title>Local well-posedness of the minimum energy estimator for a defocusing cubic wave equation</title>
      <link>https://arxiv.org/abs/2410.07010</link>
      <description>arXiv:2410.07010v1 Announce Type: new 
Abstract: This work is concerned with the minimum energy estimator for a nonlinear hyperbolic partial differential equation. The Mortensen observer - originally introduced for the energy-optimal reconstruction of the state of nonlinear finite-dimensional systems - is formulated for a disturbed cubic wave equation and the associated observer equation is derived. An in depth study of the associated optimal control problem and sensitivity analysis of the corresponding value function reveals that the energy optimal state estimator is well-defined. Deploying a classical fixed point argument we proceed to show that the observer equation is locally well-posed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07010v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jesper Schr\"oder</dc:creator>
    </item>
    <item>
      <title>The Euler-Lagrange equation and optimal control: Preliminary results</title>
      <link>https://arxiv.org/abs/2410.07040</link>
      <description>arXiv:2410.07040v1 Announce Type: new 
Abstract: Algebraically speaking, linear time-invariant (LTI) systems can be considered as modules. In this framework, controllability is translated as the freeness of the system module. Optimal control mainly relies on quadratic Lagrangians and the consideration of any basis of the system module leads to an open-loop control strategy via a linear Euler-Lagrange equation. In this approach, the endpoint is easily assignable and time horizon can be chosen to minimize the criterion. The loop is closed via an intelligent controller derived from model-free control, which exhibits excellent performances concerning model mismatches and disturbances. The extension to nonlinear systems is briefly discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07040v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>C\'edric Join, Emmanuel Delaleau, Michel Fliess</dc:creator>
    </item>
    <item>
      <title>GreenLight-Gym: A Reinforcement Learning Benchmark Environment for Greenhouse Crop Production Control</title>
      <link>https://arxiv.org/abs/2410.05336</link>
      <description>arXiv:2410.05336v1 Announce Type: cross 
Abstract: Controlling greenhouse crop production systems is a complex task due to uncertain and non-linear dynamics between crops, indoor and outdoor climate, and economics. The declining number of skilled growers necessitates the development of autonomous greenhouse control systems. Reinforcement Learning (RL) is a promising approach that can learn a control policy to automate greenhouse management. RL optimises a control policy through interactions with a model of the greenhouse while guided by an economic-based reward function. However, its application to real-world systems is limited due to discrepancies between models and real-world dynamics. Moreover, RL controllers may struggle to maintain state constraints while optimising the primary objective, especially when models inadequately capture the adverse effects of constraint violations on crop growth. Also, the generalisation to novel states, for example, due to unseen weather trajectories, is underexplored in RL-based greenhouse control. This work addresses these challenges through three key contributions. First, we present GreenLight-Gym, the first open-source environment designed for training and evaluating RL algorithms on the state-of-the-art greenhouse model GreenLight. GreenLight-Gym enables the community to benchmark RL-based control methodologies. Second, we compare two reward-shaping approaches, using either a multiplicative or additive penalty, to enforce state boundaries. The additive penalty achieves more stable training while better adhering to state constraints, while the multiplicative penalty yields marginally higher profits. Finally, we evaluate RL performance on a disjoint training and testing weather dataset, demonstrating improved generalisation to unseen conditions. Our environment and experiment scripts are open-sourced, facilitating innovative research on learning-based greenhouse control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05336v1</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bart van Laatum, Eldert J. van Henten, Sjoerd Boersma</dc:creator>
    </item>
    <item>
      <title>Regional Control Strategies for a Spatiotemporal SQEIAR Epidemic Model: Application to COVID-19</title>
      <link>https://arxiv.org/abs/2410.05426</link>
      <description>arXiv:2410.05426v1 Announce Type: cross 
Abstract: In this work, we look for a spacial SEIAR-type epidemic model consediring quarantined population $(Q)$, namely SQEIAR model. The dynamic of the SQEIAR model involves six partial differential equations that decribe the changes in susceptible, quarantined, exposed, asymptomatic, infected and recovered population. Our goal is to reduce the number of exposed, asymptomatic, and infected population while taking into account the environment, which plays a critical role in the spread of epidemics. Then, we implement a new strategy based on two control actions: regional quarantine for susceptible population and treatment for infected population. To demonstrate the practical utility of the obtained results, a numerical example centered on COVID-19 is presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05426v1</guid>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elghandouri Mohammed, Ezzinbi Khalil, Youness Mezzan</dc:creator>
    </item>
    <item>
      <title>Deep Learning Methods for S Shaped Utility Maximisation with a Random Reference Point</title>
      <link>https://arxiv.org/abs/2410.05524</link>
      <description>arXiv:2410.05524v1 Announce Type: cross 
Abstract: We consider the portfolio optimisation problem where the terminal function is an S-shaped utility applied at the difference between the wealth and a random benchmark process. We develop several numerical methods for solving the problem using deep learning and duality methods. We use deep learning methods to solve the associated Hamilton-Jacobi-Bellman equation for both the primal and dual problems, and the adjoint equation arising from the stochastic maximum principle. We compare the solution of this non-concave problem to that of concavified utility, a random function depending on the benchmark, in both complete and incomplete markets. We give some numerical results for power and log utilities to show the accuracy of the suggested algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05524v1</guid>
      <category>q-fin.CP</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ashley Davey, Harry Zheng</dc:creator>
    </item>
    <item>
      <title>DOPL: Direct Online Preference Learning for Restless Bandits with Preference Feedback</title>
      <link>https://arxiv.org/abs/2410.05527</link>
      <description>arXiv:2410.05527v1 Announce Type: cross 
Abstract: Restless multi-armed bandits (RMAB) has been widely used to model constrained sequential decision making problems, where the state of each restless arm evolves according to a Markov chain and each state transition generates a scalar reward. However, the success of RMAB crucially relies on the availability and quality of reward signals. Unfortunately, specifying an exact reward function in practice can be challenging and even infeasible. In this paper, we introduce Pref-RMAB, a new RMAB model in the presence of preference signals, where the decision maker only observes pairwise preference feedback rather than scalar reward from the activated arms at each decision epoch. Preference feedback, however, arguably contains less information than the scalar reward, which makes Pref-RMAB seemingly more difficult. To address this challenge, we present a direct online preference learning (DOPL) algorithm for Pref-RMAB to efficiently explore the unknown environments, adaptively collect preference data in an online manner, and directly leverage the preference feedback for decision-makings. We prove that DOPL yields a sublinear regret. To our best knowledge, this is the first algorithm to ensure $\tilde{\mathcal{O}}(\sqrt{T\ln T})$ regret for RMAB with preference feedback. Experimental results further demonstrate the effectiveness of DOPL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05527v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guojun Xiong, Ujwal Dinesha, Debajoy Mukherjee, Jian Li, Srinivas Shakkottai</dc:creator>
    </item>
    <item>
      <title>Aiding Global Convergence in Federated Learning via Local Perturbation and Mutual Similarity Information</title>
      <link>https://arxiv.org/abs/2410.05545</link>
      <description>arXiv:2410.05545v1 Announce Type: cross 
Abstract: Federated learning has emerged in the last decade as a distributed optimization paradigm due to the rapidly increasing number of portable devices able to support the heavy computational needs related to the training of machine learning models. Federated learning utilizes gradient-based optimization to minimize a loss objective shared across participating agents. To the best of our knowledge, the literature mostly lacks elegant solutions that naturally harness the reciprocal statistical similarity between clients to redesign the optimization procedure. To address this gap, by conceiving the federated network as a similarity graph, we propose a novel modified framework wherein each client locally performs a perturbed gradient step leveraging prior information about other statistically affine clients. We theoretically prove that our procedure, due to a suitably introduced adaptation in the update rule, achieves a quantifiable speedup concerning the exponential contraction factor in the strongly convex case compared with popular algorithms FedAvg and FedProx, here analyzed as baselines. Lastly, we legitimize our conclusions through experimental results on the CIFAR10 and FEMNIST datasets, where we show that our algorithm speeds convergence up to a margin of 30 global rounds compared with FedAvg while modestly improving generalization on unseen data in heterogeneous settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05545v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Emanuel Buttaci, Giuseppe Carlo Calafiore</dc:creator>
    </item>
    <item>
      <title>Linear Convergence of Data-Enabled Policy Optimization for Linear Quadratic Tracking</title>
      <link>https://arxiv.org/abs/2410.05596</link>
      <description>arXiv:2410.05596v1 Announce Type: cross 
Abstract: Data-enabled policy optimization (DeePO) is a newly proposed method to attack the open problem of direct adaptive LQR. In this work, we extend the DeePO framework to the linear quadratic tracking (LQT) with offline data. By introducing a covariance parameterization of the LQT policy, we derive a direct data-driven formulation of the LQT problem. Then, we use gradient descent method to iteratively update the parameterized policy to find an optimal LQT policy. Moreover, by revealing the connection between DeePO and model-based policy optimization, we prove the linear convergence of the DeePO iteration. Finally, a numerical experiment is given to validate the convergence results. We hope our work paves the way to direct adaptive LQT with online closed-loop data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05596v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shubo Kang, Feiran Zhao, Keyou You</dc:creator>
    </item>
    <item>
      <title>Training-free Diffusion Model Alignment with Sampling Demons</title>
      <link>https://arxiv.org/abs/2410.05760</link>
      <description>arXiv:2410.05760v1 Announce Type: cross 
Abstract: Aligning diffusion models with user preferences has been a key challenge. Existing methods for aligning diffusion models either require retraining or are limited to differentiable reward functions. To address these limitations, we propose a stochastic optimization approach, dubbed Demon, to guide the denoising process at inference time without backpropagation through reward functions or model retraining. Our approach works by controlling noise distribution in denoising steps to concentrate density on regions corresponding to high rewards through stochastic optimization. We provide comprehensive theoretical and empirical evidence to support and validate our approach, including experiments that use non-differentiable sources of rewards such as Visual-Language Model (VLM) APIs and human judgements. To the best of our knowledge, the proposed approach is the first inference-time, backpropagation-free preference alignment method for diffusion models. Our method can be easily integrated with existing diffusion models without further training. Our experiments show that the proposed approach significantly improves the average aesthetics scores for text-to-image generation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05760v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Po-Hung Yeh, Kuang-Huei Lee, Jun-Cheng Chen</dc:creator>
    </item>
    <item>
      <title>Extended convexity and smoothness and their applications in deep learning</title>
      <link>https://arxiv.org/abs/2410.05807</link>
      <description>arXiv:2410.05807v1 Announce Type: cross 
Abstract: The underlying mechanism by which simple gradient-based iterative algorithms can effectively handle the non-convex problem of deep model training remains incompletely understood within the traditional convex and non-convex analysis frameworks, which often require the Lipschitz smoothness of the gradient and strong convexity. In this paper, we introduce $\mathcal{H}(\phi)$-convexity and $\mathcal{H}(\Phi)$-smoothness, which broaden the existing concepts of smoothness and convexity, and delineate their fundamental properties. Building on these concepts, we introduce the high-order gradient descent and high-order stochastic gradient descent methods, which serve as extensions to the traditional gradient descent and stochastic gradient descent methods, respectively. Furthermore, we establish descent lemmas for the $\mathcal{H}(\phi)$-convex and $\mathcal{H}(\Phi)$-smooth objective functions when utilizing these four methods. On the basis of these findings, we develop the gradient structure control algorithm to address non-convex optimization objectives, encompassing both the functions represented by machine learning models and common loss functions in deep learning. The effectiveness of the proposed methodology is empirically validated through experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05807v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Binchuan Qi</dc:creator>
    </item>
    <item>
      <title>A second-order-like optimizer with adaptive gradient scaling for deep learning</title>
      <link>https://arxiv.org/abs/2410.05871</link>
      <description>arXiv:2410.05871v1 Announce Type: cross 
Abstract: In this empirical article, we introduce INNAprop, an optimization algorithm that combines the INNA method with the RMSprop adaptive gradient scaling. It leverages second-order information and rescaling while keeping the memory requirements of standard DL methods as AdamW or SGD with momentum.After having recalled our geometrical motivations, we provide quite extensive experiments. On image classification (CIFAR-10, ImageNet) and language modeling (GPT-2), INNAprop consistently matches or outperforms AdamW both in training speed and accuracy, with minimal hyperparameter tuning in large-scale settings. Our code is publicly available at \url{https://github.com/innaprop/innaprop}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05871v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>J\'er\^ome Bolte (TSE-R), Ryan Boustany (TSE-R), Edouard Pauwels (TSE-R, IRIT-ADRIA), Andrei Purica</dc:creator>
    </item>
    <item>
      <title>Improved Sample Complexity for Private Nonsmooth Nonconvex Optimization</title>
      <link>https://arxiv.org/abs/2410.05880</link>
      <description>arXiv:2410.05880v1 Announce Type: cross 
Abstract: We study differentially private (DP) optimization algorithms for stochastic and empirical objectives which are neither smooth nor convex, and propose methods that return a Goldstein-stationary point with sample complexity bounds that improve on existing works. We start by providing a single-pass $(\epsilon,\delta)$-DP algorithm that returns an $(\alpha,\beta)$-stationary point as long as the dataset is of size $\widetilde{\Omega}\left(1/\alpha\beta^{3}+d/\epsilon\alpha\beta^{2}+d^{3/4}/\epsilon^{1/2}\alpha\beta^{5/2}\right)$, which is $\Omega(\sqrt{d})$ times smaller than the algorithm of Zhang et al. [2024] for this task, where $d$ is the dimension. We then provide a multi-pass polynomial time algorithm which further improves the sample complexity to $\widetilde{\Omega}\left(d/\beta^2+d^{3/4}/\epsilon\alpha^{1/2}\beta^{3/2}\right)$, by designing a sample efficient ERM algorithm, and proving that Goldstein-stationary points generalize from the empirical loss to the population loss.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05880v1</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guy Kornowski, Daogao Liu, Kunal Talwar</dc:creator>
    </item>
    <item>
      <title>Improved PCRLB for radar tracking in clutter with geometry-dependent target measurement uncertainty and application to radar trajectory control</title>
      <link>https://arxiv.org/abs/2410.05883</link>
      <description>arXiv:2410.05883v1 Announce Type: cross 
Abstract: In realistic radar tracking, target measurement uncertainty (TMU) in terms of both detection probability and measurement error covariance is significantly affected by the target-to-radar (T2R) geometry. However, existing posterior Cramer-Rao Lower Bounds (PCRLBs) rarely investigate the fundamental impact of T2R geometry on target measurement uncertainty and eventually on mean square error (MSE) of state estimate, inevitably resulting in over-conservative lower bound. To address this issue, this paper firstly derives the generalized model of target measurement error covariance for bistatic radar with moving receiver and transmitter illuminating any type of signal, along with its approximated solution to specify the impact of T2R geometry on error covariance. Based upon formulated TMU model, an improved PCRLB (IPCRLB) fully accounting for both measurement origin uncertainty and geometry-dependent TMU is then re-derived, both detection probability and measurement error covariance are treated as state-dependent parameters when differentiating log-likelihood with respect to target state. Compared to existing PCRLBs that partially or completely ignore the dependence of target measurement uncertainty on T2R geometry, proposed IPCRLB provides a much accurate (less-conservative) lower bound for radar tracking in clutter with geometry-dependent TMU. The new bound is then applied to radar trajectory control to effectively optimize T2R geometry and exhibits least uncertainty of acquired target measurement and more accurate state estimate for bistatic radar tracking in clutter, compared to state-of-the-art trajectory control methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05883v1</guid>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yifang Shi, Yu Zhang, Linjiao Fu, Dongliang Peng, Qiang Lu, Jee Woong Choi, Alfonso Farina</dc:creator>
    </item>
    <item>
      <title>Single Point-Based Distributed Zeroth-Order Optimization with a Non-Convex Stochastic Objective Function</title>
      <link>https://arxiv.org/abs/2410.05942</link>
      <description>arXiv:2410.05942v1 Announce Type: cross 
Abstract: Zero-order (ZO) optimization is a powerful tool for dealing with realistic constraints. On the other hand, the gradient-tracking (GT) technique proved to be an efficient method for distributed optimization aiming to achieve consensus. However, it is a first-order (FO) method that requires knowledge of the gradient, which is not always possible in practice. In this work, we introduce a zero-order distributed optimization method based on a one-point estimate of the gradient tracking technique. We prove that this new technique converges with a single noisy function query at a time in the non-convex setting. We then establish a convergence rate of $O(\frac{1}{\sqrt[3]{K}})$ after a number of iterations K, which competes with that of $O(\frac{1}{\sqrt[4]{K}})$ of its centralized counterparts. Finally, a numerical example validates our theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05942v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Proceedings of the 40th International Conference on Machine Learning, PMLR 202:24701-24719, 2023</arxiv:journal_reference>
      <dc:creator>Elissa Mhanna, Mohamad Assaad</dc:creator>
    </item>
    <item>
      <title>Efficient Solution of State-Constrained Distributed Parabolic Optimal Control Problems</title>
      <link>https://arxiv.org/abs/2410.06021</link>
      <description>arXiv:2410.06021v1 Announce Type: cross 
Abstract: We consider a space-time finite element method for the numerical solution of a distributed tracking-type optimal control problem subject to the heat equation with state constraints. The cost or regularization term is formulated in an anisotropic Sobolev norm for the state, and the optimal state is then characterized as the unique solution of a first kind variational inequality. We discuss an efficient realization of the anisotropic Sobolev norm in the case of a space-time tensor-product finite element mesh, and the iterative solution of the resulting discrete variational inequality by means of a semi-smooth Newton method, i.e., using an active set strategy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06021v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Richard L\"oscher, Michael Reichelt, Olaf Steinbach</dc:creator>
    </item>
    <item>
      <title>Packing a Knapsack with Items Owned by Strategic Agents</title>
      <link>https://arxiv.org/abs/2410.06080</link>
      <description>arXiv:2410.06080v1 Announce Type: cross 
Abstract: This paper considers a scenario within the field of mechanism design without money where a mechanism designer is interested in selecting items with maximum total value under a knapsack constraint. The items, however, are controlled by strategic agents who aim to maximize the total value of their items in the knapsack. This is a natural setting, e.g., when agencies select projects for funding, companies select products for sale in their shops, or hospitals schedule MRI scans for the day. A mechanism governing the packing of the knapsack is strategyproof if no agent can benefit from hiding items controlled by them to the mechanism. We are interested in mechanisms that are strategyproof and $\alpha$-approximate in the sense that they always approximate the maximum value of the knapsack by a factor of $\alpha \in [0,1]$. First, we give a deterministic mechanism that is $\frac{1}{3}$-approximate. For the special case where all items have unit density, we design a $\frac{1}{\phi}$-approximate mechanism where $1/\phi \approx 0.618$ is the inverse of the golden ratio. This result is tight as we show that no deterministic strategyproof mechanism with a better approximation exists. We further give randomized mechanisms with approximation guarantees of $1/2$ for the general case and $2/3$ for the case of unit densities. For both cases, no strategyproof mechanism can achieve an approximation guarantee better than $1/(5\phi -7)\approx 0.917$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06080v1</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Javier Cembrano, Max Klimm, Martin Knaack</dc:creator>
    </item>
    <item>
      <title>Is Pontryagin's Maximum Principle all you need? Solving optimal control problems with PMP-inspired neural networks</title>
      <link>https://arxiv.org/abs/2410.06277</link>
      <description>arXiv:2410.06277v1 Announce Type: cross 
Abstract: Calculus of Variations is the mathematics of functional optimization, i.e., when the solutions are functions over a time interval. This is particularly important when the time interval is unknown like in minimum-time control problems, so that forward in time solutions are not possible. Calculus of Variations offers a robust framework for learning optimal control and inference. How can this framework be leveraged to design neural networks to solve challenges in control and inference? We propose the Pontryagin's Maximum Principle Neural Network (PMP-net) that is tailored to estimate control and inference solutions, in accordance with the necessary conditions outlined by Pontryagin's Maximum Principle. We assess PMP-net on two classic optimal control and inference problems: optimal linear filtering and minimum-time control. Our findings indicate that PMP-net can be effectively trained in an unsupervised manner to solve these problems without the need for ground-truth data, successfully deriving the classical "Kalman filter" and "bang-bang" control solution. This establishes a new approach for addressing general, possibly yet unsolved, optimal control problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06277v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kawisorn Kamtue, Jose M. F. Moura, Orathai Sangpetch</dc:creator>
    </item>
    <item>
      <title>Differentiation Through Black-Box Quadratic Programming Solvers</title>
      <link>https://arxiv.org/abs/2410.06324</link>
      <description>arXiv:2410.06324v2 Announce Type: cross 
Abstract: In recent years, many deep learning approaches have incorporated layers that solve optimization problems (e.g., linear, quadratic, and semidefinite programs). Integrating these optimization problems as differentiable layers requires computing the derivatives of the optimization problem's solution with respect to its objective and constraints. This has so far prevented the use of state-of-the-art black-box numerical solvers within neural networks, as they lack a differentiable interface. To address this issue for one of the most common convex optimization problems -- quadratic programming (QP) -- we introduce dQP, a modular framework that enables plug-and-play differentiation for any QP solver, allowing seamless integration into neural networks and bi-level optimization tasks. Our solution is based on the core theoretical insight that knowledge of the active constraint set at the QP optimum allows for explicit differentiation. This insight reveals a unique relationship between the computation of the solution and its derivative, enabling efficient differentiation of any solver, that only requires the primal solution. Our implementation, which will be made publicly available, interfaces with an existing framework that supports over 15 state-of-the-art QP solvers, providing each with a fully differentiable backbone for immediate use as a differentiable layer in learning setups. To demonstrate the scalability and effectiveness of dQP, we evaluate it on a large benchmark dataset of QPs with varying structures. We compare dQP with existing differentiable QP methods, demonstrating its advantages across a range of problems, from challenging small and dense problems to large-scale sparse ones, including a novel bi-level geometry optimization problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06324v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Connor W. Magoon, Fengyu Yang, Noam Aigerman, Shahar Z. Kovalsky</dc:creator>
    </item>
    <item>
      <title>Flipping-based Policy for Chance-Constrained Markov Decision Processes</title>
      <link>https://arxiv.org/abs/2410.06474</link>
      <description>arXiv:2410.06474v1 Announce Type: cross 
Abstract: Safe reinforcement learning (RL) is a promising approach for many real-world decision-making problems where ensuring safety is a critical necessity. In safe RL research, while expected cumulative safety constraints (ECSCs) are typically the first choices, chance constraints are often more pragmatic for incorporating safety under uncertainties. This paper proposes a \textit{flipping-based policy} for Chance-Constrained Markov Decision Processes (CCMDPs). The flipping-based policy selects the next action by tossing a potentially distorted coin between two action candidates. The probability of the flip and the two action candidates vary depending on the state. We establish a Bellman equation for CCMDPs and further prove the existence of a flipping-based policy within the optimal solution sets. Since solving the problem with joint chance constraints is challenging in practice, we then prove that joint chance constraints can be approximated into Expected Cumulative Safety Constraints (ECSCs) and that there exists a flipping-based policy in the optimal solution sets for constrained MDPs with ECSCs. As a specific instance of practical implementations, we present a framework for adapting constrained policy optimization to train a flipping-based policy. This framework can be applied to other safe RL algorithms. We demonstrate that the flipping-based policy can improve the performance of the existing safe RL algorithms under the same limits of safety constraints on Safety Gym benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06474v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xun Shen, Shuo Jiang, Akifumi Wachi, Kaumune Hashimoto, Sebastien Gros</dc:creator>
    </item>
    <item>
      <title>BiC-MPPI: Goal-Pursuing, Sampling-Based Bidirectional Rollout Clustering Path Integral for Trajectory Optimization</title>
      <link>https://arxiv.org/abs/2410.06493</link>
      <description>arXiv:2410.06493v1 Announce Type: cross 
Abstract: This paper introduces the Bidirectional Clustered MPPI (BiC-MPPI) algorithm, a novel trajectory optimization method aimed at enhancing goal-directed guidance within the Model Predictive Path Integral (MPPI) framework. BiC-MPPI incorporates bidirectional dynamics approximations and a new guide cost mechanism, improving both trajectory planning and goal-reaching performance. By leveraging forward and backward rollouts, the bidirectional approach ensures effective trajectory connections between initial and terminal states, while the guide cost helps discover dynamically feasible paths. Experimental results demonstrate that BiC-MPPI outperforms existing MPPI variants in both 2D and 3D environments, achieving higher success rates and competitive computation times across 900 simulations on a modified BARN dataset for autonomous navigation.
  GitHub: https://github.com/i-ASL/BiC-MPPI</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06493v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Minchan Jung, Kwangki Kim</dc:creator>
    </item>
    <item>
      <title>An Optimal Algorithm for the Stacker Crane Problem on Fixed Topologies</title>
      <link>https://arxiv.org/abs/2410.06764</link>
      <description>arXiv:2410.06764v1 Announce Type: cross 
Abstract: The Stacker Crane Problem (SCP) is a variant of the Traveling Salesman Problem. In SCP, pairs of pickup and delivery points are designated on a graph, and a crane must visit these points to move objects from each pickup location to its respective delivery point. The goal is to minimize the total distance traveled. SCP is known to be NP-hard, even on tree structures. The only positive results, in terms of polynomial-time solvability, apply to graphs that are topologically equivalent to a path or a cycle.
  We propose an algorithm that is optimal for each fixed topology, running in near-linear time. This is achieved by demonstrating that the problem is fixed-parameter tractable (FPT) when parameterized by both the cycle rank and the number of branch vertices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06764v1</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yike Chen, Ke Shi, Chao Xu</dc:creator>
    </item>
    <item>
      <title>First order Martingale model risk and semi-static hedging</title>
      <link>https://arxiv.org/abs/2410.06906</link>
      <description>arXiv:2410.06906v1 Announce Type: cross 
Abstract: We investigate model risk distributionally robust sensitivities for functionals on the Wasserstein space when the underlying model is constrained to the martingale class and/or is subject to constraints on the first marginal law. Our results extend the findings of Bartl, Drapeau, Obloj \&amp; Wiesel \cite{bartl2021sensitivity} and Bartl \&amp; Wiesel \cite{bartlsensitivityadapted} by introducing the minimization of the distributionally robust problem with respect to semi-static hedging strategies. We provide explicit characterizations of the model risk (first order) optimal semi-static hedging strategies. The distributional robustness is analyzed both in terms of the adapted Wasserstein metric and the more relevant standard Wasserstein metric.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06906v1</guid>
      <category>q-fin.MF</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nathan Sauldubois, Nizar Touzi</dc:creator>
    </item>
    <item>
      <title>Constrained TLBO algorithm for lightweight cable-stiffened scissor-like deployable structures</title>
      <link>https://arxiv.org/abs/2410.06958</link>
      <description>arXiv:2410.06958v1 Announce Type: cross 
Abstract: Present works discusses the efficient structural analysis and weight optimization of the cable-stiffened deployable structures. The stiffening effect of cables is incorporated through a matrix analysis based iterative strategy to identify the active and passive cables. The structural form can be easily deployed to cartesian as well as polar coordinates through the arrangement of duplet members. The large span utility of cable stiffened bar members can pose challenges to the deployability due to increased weight. A novel teaching-learning based optimization (TLBO) algorithm is utilized to optimize the overall weight of the structure through efficient section designs with proper constraint on the yield criteria. The penalty function approach is adopted to identify the unfeasible designs. A number of example cases are analysed and comparison is presented with the existing literature to show the suitability of the proposed approach. Finally, a new form of three-dimensional deployable structure is proposed. It is seen that such deployable structure can be accurately analysed using the iterative matrix analysis approach and efficiently optimized using the present algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06958v1</guid>
      <category>cs.CE</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Soumyajit Manna, Arijit Sau, Devesh Punera</dc:creator>
    </item>
    <item>
      <title>Stochastic Zeroth order Descent with Structured Directions</title>
      <link>https://arxiv.org/abs/2206.05124</link>
      <description>arXiv:2206.05124v3 Announce Type: replace 
Abstract: We introduce and analyze Structured Stochastic Zeroth order Descent (S-SZD), a finite difference approach that approximates a stochastic gradient on a set of $l\leq d$ orthogonal directions, where $d$ is the dimension of the ambient space. These directions are randomly chosen and may change at each step. For smooth convex functions we prove almost sure convergence of the iterates and a convergence rate on the function values of the form $O( (d/l) k^{-c})$ for every $c&lt;1/2$, which is arbitrarily close to the one of Stochastic Gradient Descent (SGD) in terms of number of iterations. Our bound shows the benefits of using $l$ multiple directions instead of one. For non-convex functions satisfying the Polyak-{\L}ojasiewicz condition, we establish the first convergence rates for stochastic structured zeroth order algorithms under such an assumption. We corroborate our theoretical findings with numerical simulations where the assumptions are satisfied and on the real-world problem of hyper-parameter optimization in machine learning, achieving competitive practical performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.05124v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marco Rando, Cesare Molinari, Silvia Villa, Lorenzo Rosasco</dc:creator>
    </item>
    <item>
      <title>Expert-Guided Inverse Optimization for Convex Constraint Inference</title>
      <link>https://arxiv.org/abs/2207.02894</link>
      <description>arXiv:2207.02894v3 Announce Type: replace 
Abstract: Conventional inverse optimization inputs a solution and finds the parameters of an optimization model that render a given solution optimal. The literature mostly focuses on inferring the objective function in linear problems when accepted solutions are provided as input. In this paper, we propose an inverse optimization model that inputs several accepted and rejected solutions and recovers the underlying convex optimization model that can be used to generate such solutions. The novelty of our model is two-fold: First, we focus on inferring the parameters of the underlying convex feasible region. Second, the proposed model learns the convex constraint set from a set of past observations that are either accepted or rejected by an expert. The resulting inverse model is a mixed-integer nonlinear problem that is complex to solve. To mitigate the inverse problem complexity, we employ variational inequalities and the theoretical properties of the solutions to derive a reduced formulation that retains the complexity of its forward counterpart. Using realistic breast cancer patient data, we demonstrate that our inverse model can utilize a subset of past accepted and rejected treatment plans to infer clinical criteria that can lead to nearly guaranteed acceptable treatment plans for future patients.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.02894v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Houra Mahmoudzadeh, Kimia Ghobadi</dc:creator>
    </item>
    <item>
      <title>Ensemble Kalman Methods: A Mean Field Perspective</title>
      <link>https://arxiv.org/abs/2209.11371</link>
      <description>arXiv:2209.11371v3 Announce Type: replace 
Abstract: Ensemble Kalman methods are widely used for state estimation in the geophysical sciences. Their success stems from the fact that they take an underlying (possibly noisy) dynamical system as a black box to provide a systematic, derivative-free methodology for incorporating noisy, partial and possibly indirect observations to update estimates of the state; furthermore the ensemble approach allows for sensitivities and uncertainties to be calculated. The methodology was introduced in 1994 in the context of ocean state estimation. Soon thereafter it was adopted by the numerical weather prediction community and is now a key component of the best weather prediction systems worldwide. Furthermore the methodology is starting to be widely adopted for numerous problems in the geophysical sciences and is being developed as the basis for general purpose derivative-free inversion methods that show great promise. Despite this empirical success, analysis of the accuracy of ensemble Kalman methods, in terms of their capabilities as both state estimators and quantifiers of uncertainty, is lagging. The purpose of this paper is to provide a unifying mean field based framework for the derivation and analysis of ensemble Kalman methods. Both state estimation and parameter estimation problems (inverse problems) are considered, and formulations in both discrete and continuous time are employed. For state estimation problems, both the control and filtering approaches are considered; analogously for parameter estimation problems, the optimization and Bayesian perspectives are both studied. The mean field perspective provides an elegant framework, suitable for analysis; furthermore, a variety of methods used in practice can be derived from mean field systems by using interacting particle system approximations. The approach taken also unifies a wide-ranging literature in the field and suggests open problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.11371v3</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Edoardo Calvello, Sebastian Reich, Andrew M. Stuart</dc:creator>
    </item>
    <item>
      <title>A squared smoothing Newton method for semidefinite programming</title>
      <link>https://arxiv.org/abs/2303.05825</link>
      <description>arXiv:2303.05825v4 Announce Type: replace 
Abstract: This paper proposes a squared smoothing Newton method via the Huber smoothing function for solving semidefinite programming problems (SDPs). We first study the fundamental properties of the matrix-valued mapping defined upon the Huber function. Using these results and existing ones in the literature, we then conduct rigorous convergence analysis and establish convergence properties for the proposed algorithm. In particular, we show that the proposed method is well-defined and admits global convergence. Moreover, under suitable regularity conditions, i.e., the primal and dual constraint nondegenerate conditions, the proposed method is shown to have a superlinear convergence rate. To evaluate the practical performance of the algorithm, we conduct extensive numerical experiments for solving various classes of SDPs. Comparison with the state-of-the-art SDP solvers demonstrates that our method is also efficient for computing accurate solutions of SDPs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.05825v4</guid>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ling Liang, Defeng Sun, Kim-Chuan Toh</dc:creator>
    </item>
    <item>
      <title>Convergence rate of Tsallis entropic regularized optimal transport</title>
      <link>https://arxiv.org/abs/2304.06616</link>
      <description>arXiv:2304.06616v2 Announce Type: replace 
Abstract: In this paper, we study the Tsallis entropic regularized optimal transport in the continuous setting and establish fundamental results such as the $\Gamma$-convergence of the Tsallis regularized optimal transport to the Monge--Kantorovich problem as the regularization parameter tends to zero. In addition, using the quantization and shadow arguments developed by Eckstein--Nutz, we derive the convergence rate of the Tsallis entropic regularization and provide explicit constants. Furthermore, we compare these results with the well-known case of the Kullback--Leibler (KL) divergence regularization and show that the KL regularization achieves the fastest convergence rate in the Tsallis framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.06616v2</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Takeshi Suguro, Toshiaki Yachimura</dc:creator>
    </item>
    <item>
      <title>A Moment-SOS Hierarchy for Robust Polynomial Matrix Inequality Optimization with SOS-Convexity</title>
      <link>https://arxiv.org/abs/2304.12628</link>
      <description>arXiv:2304.12628v5 Announce Type: replace 
Abstract: We study a class of polynomial optimization problems with a robust polynomial matrix inequality (PMI) constraint where the uncertainty set itself is defined also by a PMI. These can be viewed as matrix generalizations of semi-infinite polynomial programs, since they involve actually infinitely many PMI constraints in general. Under certain SOS-convexity assumptions, we construct a hierarchy of increasingly tight moment-SOS relaxations for solving such problems. Most of the nice features of the moment-SOS hierarchy for the usual polynomial optimization are extended to this more complicated setting. In particular, asymptotic convergence of the hierarchy is guaranteed and finite convergence can be certified if some flat extension condition holds true. To extract global minimizers, we provide a linear algebra procedure for recovering a finitely atomic matrix-valued measure from truncated matrix-valued moments. As an application, we are able to solve the problem of minimizing the smallest eigenvalue of a polynomial matrix subject to a PMI constraint. If SOS-convexity is replaced by convexity, we can still approximate the optimal value as closely as desired by solving a sequence of semidefinite programs, and certify global optimality in case that certain flat extension conditions hold true. Finally, an extension to the non-convexity setting is provided under a rank one condition. To obtain the above-mentioned results, techniques from real algebraic geometry, matrix-valued measure theory, and convex optimization are employed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.12628v5</guid>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1287/moor.2023.0361</arxiv:DOI>
      <dc:creator>Feng Guo, Jie Wang</dc:creator>
    </item>
    <item>
      <title>Predictability and Fairness in Load Aggregation with Deadband</title>
      <link>https://arxiv.org/abs/2305.17725</link>
      <description>arXiv:2305.17725v2 Announce Type: replace 
Abstract: Virtual power plants and load aggregation are becoming increasingly common. There, one regulates the aggregate power output of an ensemble of distributed energy resources (DERs). Marecek et al. [Automatica, Volume 147, January 2023, 110743, arXiv:2110.03001] recently suggested that long-term averages of prices or incentives offered should exist and be independent of the initial states of the operators of the DER, the aggregator, and the power grid. This can be seen as predictability, which underlies fairness. Unfortunately, the existence of such averages cannot be guaranteed with many traditional regulators, including the proportional-integral (PI) regulator with or without deadband. Here, we consider the effects of losses in the alternating current model and the deadband in the controller. This yields a non-linear dynamical system (due to the non-linear losses) exhibiting discontinuities (due to the deadband). We show that Filippov invariant measures enable reasoning about predictability and fairness while considering non-linearity of the alternating-current model and deadband.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.17725v2</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>F. V. Difonzo, M. Roubalik, J. Marecek</dc:creator>
    </item>
    <item>
      <title>SLiSeS: Subsampled Line Search Spectral Gradient Method for Finite Sums</title>
      <link>https://arxiv.org/abs/2306.07379</link>
      <description>arXiv:2306.07379v3 Announce Type: replace 
Abstract: The spectral gradient method is known to be a powerful low-cost tool for solving large-scale optimization problems. In this paper, our goal is to exploit its advantages in the stochastic optimization framework, especially in the case of mini-batch subsampling that is often used in big data settings. To allow the spectral coefficient to properly explore the underlying approximate Hessian spectrum, we keep the same subsample for several iterations before subsampling again. We analyze the required algorithmic features and the conditions for almost sure convergence, and present initial numerical results that show the advantages of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.07379v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stefania Bellavia, Nata\v{s}a Kreji\'c, Nata\v{s}a Krklec Jerinki\'c, Marcos Raydan</dc:creator>
    </item>
    <item>
      <title>Exponential Stability and Design of Sensor Feedback Amplifiers for Fast Stabilization of Magnetizable Piezoelectric Beam Equations</title>
      <link>https://arxiv.org/abs/2306.10705</link>
      <description>arXiv:2306.10705v3 Announce Type: replace 
Abstract: The dynamic partial differential equation (PDE) model governing longitudinal oscillations in magnetizable piezoelectric beams exhibits exponentially stable solutions when subjected to two boundary state feedback controllers. An analytically established exponential decay rate by the Lyapunov approach ensures stabilization of the system to equilibrium, though the actual decay rate could potentially be improved. The decay rate of the closed-loop system is highly sensitive to the choice of material parameters and the design of the state feedback amplifiers. This paper focuses on investigating the design of state feedback amplifiers to achieve a maximal exponential decay rate, which is essential for effectively suppressing oscillations in these beams. Through this design process, we explicitly determine the safe intervals of feedback amplifiers that ensure the theoretically found maximal decay rate, with the potential for even better rates. Our numerical results reaffirm the robustness of the decay rate within the chosen range of feedback amplifiers, while deviations from this range significantly impact the decay rate. To underscore the validity of our results, we present various numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.10705v3</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TAC.2024.3462917</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions of Automatic Control (2024)</arxiv:journal_reference>
      <dc:creator>Ahmet Ozkan Ozer, Ahmet Kaan Aydin, Rafi Emran</dc:creator>
    </item>
    <item>
      <title>A finitely convergent circumcenter method for the Convex Feasibility Problem</title>
      <link>https://arxiv.org/abs/2308.09849</link>
      <description>arXiv:2308.09849v3 Announce Type: replace 
Abstract: In this paper, we present a variant of the circumcenter method for the Convex Feasibility Problem (CFP), ensuring finite convergence under a Slater assumption. The method replaces exact projections onto the convex sets with projections onto separating halfspaces, perturbed by positive exogenous parameters that decrease to zero along the iterations. If the perturbation parameters decrease slowly enough, such as the terms of a diverging series, finite convergence is achieved. To the best of our knowledge, this is the first circumcenter method for CFP that guarantees finite convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.09849v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1137/23M1595412</arxiv:DOI>
      <arxiv:journal_reference>SIAM J. Optim., vol. 34, no. 3, pp. 2535-2556, Sep. 2024</arxiv:journal_reference>
      <dc:creator>Roger Behling, Yunier Bello-Cruz, Alfredo Iusem, Di Liu, Luiz-Rafael Santos</dc:creator>
    </item>
    <item>
      <title>A Projection-Free Method for Solving Convex Bilevel Optimization Problems</title>
      <link>https://arxiv.org/abs/2311.09738</link>
      <description>arXiv:2311.09738v4 Announce Type: replace 
Abstract: When faced with multiple minima of an "inner-level" convex optimization problem, the convex bilevel optimization problem selects an optimal solution which also minimizes an auxiliary "outer-level" convex objective of interest. Bilevel optimization requires a different approach compared to single-level optimization problems since the set of minimizers for the inner-level objective is not given explicitly. In this paper, we propose a new projection-free method for convex bilevel optimization which require only a linear optimization oracle over the base domain. We establish $O(t^{-1/2})$ convergence rate guarantees for our method in terms of both inner- and outer-level objectives, and demonstrate how additional assumptions such as quadratic growth and strong convexity result in accelerated rates of up to $O(t^{-1})$ and $O(t^{-2/3})$ for inner- and outer-levels respectively. Lastly, we conduct a numerical study to demonstrate the performance of our method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.09738v4</guid>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Khanh-Hung Giang-Tran, Nam Ho-Nguyen, Dabeen Lee</dc:creator>
    </item>
    <item>
      <title>Convergence towards a local minimum by direct search methods with a covering step</title>
      <link>https://arxiv.org/abs/2401.07097</link>
      <description>arXiv:2401.07097v3 Announce Type: replace 
Abstract: This paper introduces a new step to the Direct Search Method (DSM) to strengthen its convergence analysis. By design, this so-called covering step may ensure that for all refined points of the sequence of incumbent solutions generated by the resulting cDSM (covering DSM), the set of all evaluated trial points is dense in a neighborhood of that refined point. We prove that this additional property guarantees that all refined points are local solutions to the optimization problem. This new result holds true even for discontinuous objective function, under a mild assumption that we discuss in details. We also provide a practical construction scheme for the covering step that works at low additional cost per iteration. Finally, we show that the covering step may be adapted to classes of algorithms differing from the DSM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.07097v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Charles Audet, Pierre-Yves Bouchet. Lo\"ic Bourdin</dc:creator>
    </item>
    <item>
      <title>An Analytical Approach for Intermodal Urban Transportation Network Equilibrium including Shared Mobility Services</title>
      <link>https://arxiv.org/abs/2402.00735</link>
      <description>arXiv:2402.00735v2 Announce Type: replace 
Abstract: Shared Mobility Services (SMSs) are reshaping urban transportation systems by providing flexible mobility options. With their ability to decrease the number of cars on the roads, these services can potentially improve the transportation system's performance in terms of travel times and emissions. This emphasizes the importance of analyzing and understanding their impacts on the system and users' choices, especially when integrated into a complex multi-modal system, including public transport (PT). Many studies overlook the synergies between SMSs and PT, leading to inaccurate traffic estimations and planning. This research offers an extensive review of multi-modal transportation system models involving SMSs. We then introduce a traffic assignment analytical model framed as a Mixed-Integer Quadratic Problem (MIQP). This model comprises diverse travel possibilities, including SMSs, and handles intermodality by allowing commuters to combine modes to optimize time and monetary expense. An in-depth examination of commuters' behavior on two test cases and an analysis of the price of anarchy highlights the disparities between user equilibrium and system optimum in such intricate systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.00735v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Khadidja Kadem, Mostafa Ameli, Mahdi Zargayouna, Latifa Oukhellou</dc:creator>
    </item>
    <item>
      <title>Median Clipping for Zeroth-order Non-Smooth Convex Optimization and Multi-Armed Bandit Problem with Heavy-tailed Symmetric Noise</title>
      <link>https://arxiv.org/abs/2402.02461</link>
      <description>arXiv:2402.02461v4 Announce Type: replace 
Abstract: In this paper, we consider non-smooth convex optimization with a zeroth-order oracle corrupted by symmetric stochastic noise. Unlike the existing high-probability results requiring the noise to have bounded $\kappa$-th moment with $\kappa \in (1,2]$, our results allow even heavier noise with any $\kappa &gt; 0$, e.g., the noise distribution can have unbounded expectation. Our convergence rates match the best-known ones for the case of the bounded variance. To achieve this, we build the median gradient estimate with bounded second moment as the mini-batched median of the sampled gradient differences. We apply this technique to the stochastic multi-armed bandit problem with heavy-tailed distribution of rewards and achieve $\tilde{O}(\sqrt{dT})$ regret. We demonstrate the performance of our zeroth-order and MAB algorithms for different $\kappa$ on synthetic and real-world data. Our methods do not lose to SOTA approaches, moreover, they dramatically outperform SOTA for $\kappa \leq 1$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.02461v4</guid>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nikita Kornilov, Yuriy Dorn, Aleksandr Lobanov, Nikolay Kutuzov, Innokentiy Shibaev, Eduard Gorbunov, Alexander Gasnikov, Alexander Nazin</dc:creator>
    </item>
    <item>
      <title>Mean field control of droplet dynamics with high order finite element computations</title>
      <link>https://arxiv.org/abs/2402.05923</link>
      <description>arXiv:2402.05923v2 Announce Type: replace 
Abstract: Liquid droplet dynamics are widely used in biological and engineering applications, which contain complex interfacial instabilities and pattern formation such as droplet merging, splitting, and transport. This paper studies a class of mean field control formulations for these droplet dynamics, which can be used to control and manipulate droplets in applications. We first formulate the droplet dynamics as gradient flows of free energies in modified optimal transport metrics with nonlinear mobilities. We then design an optimal control problem for these gradient flows. As an example, a lubrication equation for a thin volatile liquid film laden with an active suspension is developed, with control achieved through its activity field. Lastly, we apply the primal-dual hybrid gradient algorithm with high-order finite element methods to simulate the proposed mean field control problems. Numerical examples, including droplet formation, bead-up/spreading, transport, and merging/splitting on a two-dimensional spatial domain, demonstrate the effectiveness of the proposed mean field control mechanism.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.05923v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.flu-dyn</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guosheng Fu, Hangjie Ji, Will Pazner, Wuchen Li</dc:creator>
    </item>
    <item>
      <title>Exact continuous relaxations of l0-regularized criteria with non-quadratic data terms</title>
      <link>https://arxiv.org/abs/2402.06483</link>
      <description>arXiv:2402.06483v2 Announce Type: replace 
Abstract: We propose a new class of exact continuous relaxations of l0-regularized criteria involving non-quadratic data terms such as the Kullback-Leibler divergence and the logistic regression, possibly combined with an l2 regularization. We first prove the existence of global minimizers for such problems and characterize their local minimizers.Then, we propose the l0 Bregman Relaxation (B-rex), a continuous approximation of the l0 pseudo-norm defined in terms of suitable Bregman distances, which leads to an exact continuous relaxations of the original l0-regularized problem in the sense that it does not alter its set of global minimizers and reduces the non-convexity by eliminating certain local minimizers. Both features make the relaxed problem more amenable to be solved by standard non-convex optimization algorithms. In this spirit, we consider the proximal gradient algorithm and provide explicit computation of proximal points for the B-rex penalty in several cases. Finally, we report a set of numerical results illustrating the geometrical behavior of the proposed B-rex penalty for different choices of the underlying Bregman distance, its relation with convex envelopes, as well as its exact relaxation properties in 1D/2D and higher dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.06483v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>M'hamed Essafri, Luca Calatroni, Emmanuel Soubies</dc:creator>
    </item>
    <item>
      <title>Constrained Stochastic Recursive Momentum Successive Convex Approximation</title>
      <link>https://arxiv.org/abs/2404.11790</link>
      <description>arXiv:2404.11790v2 Announce Type: replace 
Abstract: We consider stochastic optimization problems with functional constraints, such as those arising in trajectory generation, sparse approximation, and robust classification. To this end, we put forth a recursive momentum-based accelerated successive convex approximation (SCA) algorithm. At each iteration, the proposed algorithm entails constructing convex surrogates of the stochastic objective and the constraint functions, and solving the resulting convex optimization problem. A recursive update rule is employed to track the gradient of the stochastic objective function, which contributes to variance reduction and hence accelerates the algorithm convergence. A key ingredient of the proof is a new parameterized version of the standard Mangasarian-Fromowitz Constraints Qualification, that allows us to bound the dual variables and hence obtain problem-dependent bounds on the rate at which the iterates approach an $\epsilon$-stationary point. Remarkably, the proposed algorithm achieves near-optimal stochastic first order (SFO) complexity, almost at par with that achieved by state-of-the-art stochastic optimization algorithms for solving unconstrained problems. As an example, we detail a obstacle-avoiding trajectory optimization problem that can be solved using the proposed algorithm and show that its performance is superior to that of the existing algorithms used for trajectory optimization. The performance of the proposed algorithm is also shown to be comparable to that of a specialized sparse classification algorithm applied to a binary classification problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11790v2</guid>
      <category>math.OC</category>
      <category>eess.SP</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Basil M. Idrees, Lavish Arora, Ketan Rajawat</dc:creator>
    </item>
    <item>
      <title>Arrow of Time in Estimation and Control: Duality Theory Beyond the Linear Gaussian Model</title>
      <link>https://arxiv.org/abs/2405.07650</link>
      <description>arXiv:2405.07650v3 Announce Type: replace 
Abstract: Duality between estimation and control is a foundational concept in Control Theory. Most students learn about the elementary duality -- between observability and controllability -- in their first graduate course in linear systems theory. Therefore, it comes as a surprise that for a more general class of nonlinear stochastic systems (hidden Markov models or HMMs), duality is incomplete.
  Our objective in writing this article is two-fold: (i) To describe the difficulty in extending duality to HMMs; and (ii) To discuss its recent resolution by the authors. A key message is that the main difficulty in extending duality comes from time reversal in going from estimation to control. The reason for time reversal is explained with the aid of the familiar linear deterministic and linear Gaussian models. The explanation is used to motivate the difference between the linear and the nonlinear models. Once the difference is understood, duality for HMMs is described based on our recent work. The article also includes a comparison and discussion of the different types of duality considered in literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07650v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jin Won Kim, Prashant G. Mehta</dc:creator>
    </item>
    <item>
      <title>HV-symmetric polyhedra and bipolarity</title>
      <link>https://arxiv.org/abs/2406.03698</link>
      <description>arXiv:2406.03698v2 Announce Type: replace 
Abstract: Every polyhedron P in R^n can be described by an H-representation \mathcal{H}(P) consisting of half spaces or equivalently by a V-representation \mathcal{V}(P) consisting of the convex hull of a set of vertices and extreme rays. We can define n+1 column matrices H(P) and V(P) that encode these representations. Define polyhedron Q such that V(P) encodes \mathcal{H}(Q). We call P HV-symmetric if V(Q) in turn encodes \mathcal{H}(P). It is well known and often stated that polytopes that contain the origin in their interior and pointed polyhedral cones are HV-symmetric. It seems to be less well known that, more generally, a polyhedron is HV -symmetric if and only if it contains the origin, in other words it is bipolar. We show this using Minkowski's bipolar equation and discuss implications for the vertex and facet enumeration problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03698v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Avis</dc:creator>
    </item>
    <item>
      <title>What is the long-run distribution of stochastic gradient descent? A large deviations analysis</title>
      <link>https://arxiv.org/abs/2406.09241</link>
      <description>arXiv:2406.09241v2 Announce Type: replace 
Abstract: In this paper, we examine the long-run distribution of stochastic gradient descent (SGD) in general, non-convex problems. Specifically, we seek to understand which regions of the problem's state space are more likely to be visited by SGD, and by how much. Using an approach based on the theory of large deviations and randomly perturbed dynamical systems, we show that the long-run distribution of SGD resembles the Boltzmann-Gibbs distribution of equilibrium thermodynamics with temperature equal to the method's step-size and energy levels determined by the problem's objective and the statistics of the noise. In particular, we show that, in the long run, (a) the problem's critical region is visited exponentially more often than any non-critical region; (b) the iterates of SGD are exponentially concentrated around the problem's minimum energy state (which does not always coincide with the global minimum of the objective); (c) all other connected components of critical points are visited with frequency that is exponentially proportional to their energy level; and, finally (d) any component of local maximizers or saddle points is "dominated" by a component of local minimizers which is visited exponentially more often.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.09241v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wa\"iss Azizian, Franck Iutzeler, J\'er\^ome Malick, Panayotis Mertikopoulos</dc:creator>
    </item>
    <item>
      <title>Deterministic Trajectory Optimization through Probabilistic Optimal Control</title>
      <link>https://arxiv.org/abs/2407.13316</link>
      <description>arXiv:2407.13316v2 Announce Type: replace 
Abstract: This article proposes two new algorithms tailored to discrete-time deterministic finite-horizon nonlinear optimal control problems or so-called trajectory optimization problems. Both algorithms are inspired by a novel theoretical paradigm known as probabilistic optimal control, that reformulates optimal control as an equivalent probabilistic inference problem. This perspective allows to address the problem using the Expectation-Maximization algorithm. We show that the application of this algorithm results in a fixed point iteration of probabilistic policies that converge to the deterministic optimal policy. Two strategies for policy evaluation are discussed, using state-of-the-art uncertainty quantification methods resulting into two distinct algorithms. The algorithms are structurally closest related to the differential dynamic programming algorithm and related methods that use sigma-point methods to avoid direct gradient evaluations. The main advantage of our work is an improved balance between exploration and exploitation over the iterations, leading to improved numerical stability and accelerated convergence. These properties are demonstrated on different nonlinear systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13316v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mohammad Mahmoudi Filabadi, Tom Lefebvre, Guillaume Crevecoeur</dc:creator>
    </item>
    <item>
      <title>Decentralized Stochastic Control in Standard Borel Spaces: Centralized MDP Reductions, Near Optimality of Finite Window Local Information, and Q-Learning</title>
      <link>https://arxiv.org/abs/2408.13828</link>
      <description>arXiv:2408.13828v2 Announce Type: replace 
Abstract: Decentralized stochastic control problems are intrinsically difficult to study because of the inapplicability of standard tools from centralized control such as dynamic programming and the resulting computational complexity. In this paper, we address some of these challenges for decentralized stochastic control with Borel spaces under three different but tightly related information structures under a unified theme: the one-step delayed information sharing pattern, the K-step periodic information sharing pattern, and the completely decentralized information structure where no sharing of information occurs. We will show that the one-step delayed and K-step periodic problems can be reduced to a centralized MDP, generalizing prior results which considered finite, linear, or static models, by addressing several measurability questions. The separated nature of policies under both information structures is then established. We then provide sufficient conditions for the transition kernels of both centralized reductions to be weak-Feller, which facilitates rigorous approximation and learning theoretic results. We will then show that for the completely decentralized control problem finite memory local policies are near optimal under a joint conditional mixing condition. This is achieved by obtaining a bound for finite memory policies which goes to zero as memory size increases. We will also provide a performance bound for the K-periodic problem, which results from replacing the full common information by a finite sliding window of information. The latter will depend on the condition of predictor stability in expected total variation, which we will establish. We finally show that under the periodic information sharing pattern, a quantized Q-learning algorithm converges asymptotically towards a near optimal solution. Each of the above, to our knowledge, is a new contribution to the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.13828v2</guid>
      <category>math.OC</category>
      <category>cs.MA</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Omar Mrani-Zentar, Serdar Y\"uksel</dc:creator>
    </item>
    <item>
      <title>Comparative Analysis of Gradient-Based Optimization Techniques Using Multidimensional Surface 3D Visualizations and Initial Point Sensitivity</title>
      <link>https://arxiv.org/abs/2409.04470</link>
      <description>arXiv:2409.04470v2 Announce Type: replace 
Abstract: This study examines several renowned gradient-based optimization techniques and focuses on their computational efficiency and precision. In the study, the steepest descent, conjugate gradient (Fletcher-Reeves and Polak-Ribiere variants), Newton-Raphson, quasi-Newton (BFGS), and Levenberg-Marquardt techniques were evaluated. These methods were benchmarked using Rosenbrock's, Spring Force Vanderplaats', Ackley's, and Himmelblau's functions. We emphasize the critical role that initial point selection plays in optimizing optimization outcomes in our analysis. It is also important to distinguish between local and global optima since gradient-based methods may have difficulties dealing with nonlinearity and multimodality. We illustrate optimization trajectories using 3D surface visualizations in order to increase understanding. While gradient-based methods have been demonstrated to be effective, they may be limited by computational constraints and by the nature of the objective functions, necessitating the use of heuristic and metaheuristic algorithms in more complex situations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04470v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Saeed Asadi, Sonia Gharibzadeh, Shiva Zangeneh, Masoud Reihanifar, Morteza Rahimi, Lazim Abdullah</dc:creator>
    </item>
    <item>
      <title>Second-Order Stein Variational Dynamic Optimization</title>
      <link>https://arxiv.org/abs/2409.04644</link>
      <description>arXiv:2409.04644v3 Announce Type: replace 
Abstract: We present a novel second-order trajectory optimization algorithm based on Stein Variational Newton's Method and Maximum Entropy Differential Dynamic Programming. The proposed algorithm, called Stein Variational Differential Dynamic Programming, is a kernel-based extension of Maximum Entropy Differential Dynamic Programming that combines the best of the two worlds of sampling-based and gradient-based optimization. The resulting algorithm avoids known drawbacks of gradient-based dynamic optimization in terms of getting stuck to local minima, while it overcomes limitations of sampling-based stochastic optimization in terms of introducing undesirable stochasticity when applied in online fashion. To test the efficacy of the proposed algorithm, experiments are performed for both trajectory optimization and model predictive control. The experiments include comparisons with unimodal and multimodal Maximum Entropy Differential Dynamic Programming as well as Model Predictive Path Integral Control and its multimodal and Stein Variational extensions. The results demonstrate the superior performance of the proposed algorithms and confirm the hypothesis that there is a middle ground between sampling and gradient-based optimization that is indeed beneficial for the purposes of dynamic optimization. This middle ground consists of different mechanisms that combine sampling with gradient-based optimization. In this paper, we investigate these different mechanisms and show their benefits in dealing with non-convex dynamic optimization problems found in trajectory optimization and model predictive control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04644v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuichiro Aoyama, Peter Lehmamnn, Evangelos A. Theodorou</dc:creator>
    </item>
    <item>
      <title>DP-SCC-PL: Differentially Private Decentralized Byzantine-Resilient Stochastic Optimization via Self-Centered Clipping Under Polyak-{\L}ojasiewicz Condition</title>
      <link>https://arxiv.org/abs/2409.18632</link>
      <description>arXiv:2409.18632v4 Announce Type: replace 
Abstract: Privacy leakage and Byzantine failures are two critical issues presenting great challenges to the intelligent decision-making process of multi-agent systems (MASs). Considering the presence of these two issues, this paper targets the resolution of a class of nonconvex optimization problems under the Polyak-{\L}ojasiewicz (P-{\L}) condition. To address this problem, we mask the local gradients with Gaussian noises and adopt a resilient aggregation method self-centered clipping (SCC) to design a differentially private (DP) decentralized Byzantine-resilient algorithm, namely DP-SCC-PL, which simultaneously achieves differential privacy and Byzantine resilience. The convergence analysis of DP-SCC-PL is challenging since the convergence error can be contributed jointly by privacy-preserving and Byzantine-resilient mechanisms, as well as the nonconvex relaxation, which is addressed via seeking the contraction relationships among the disagreement measure of reliable agents before and after aggregation, together with the optimal gap. Theoretical results demonstrate that DP-SCC-PL achieves the consensus among all reliable agents with a decaying step-size and sublinear (inexact) convergence with a constant step-size, where the asymptotic convergence error is characterized in both cases. It has also been proved that if there are no privacy issues and Byzantine agents, then the asymptotic exact convergence can be recovered when adopting a well-designed decaying step-size. Numerical experiments verify the differential privacy, resilience, and effectiveness of DP-SCC-PL via tackling a nonconvex optimization problem satisfying the P-{\L} condition under various Byzantine attacks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.18632v4</guid>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinhui Hu, Guo Chen, Huaqing Li, Huqiang Cheng, Xiaoyu Guo</dc:creator>
    </item>
    <item>
      <title>Direct Data-Driven Discrete-time Bilinear Biquadratic Regulator</title>
      <link>https://arxiv.org/abs/2208.13843</link>
      <description>arXiv:2208.13843v2 Announce Type: replace-cross 
Abstract: We present a novel direct data-driven algorithm that learns an optimal control policy for the Bilinear Biquadratic Regulator (BBR) for an unknown bilinear system. The BBR is difficult to solve owing to the presence of the nonlinear biquadratic performance index and the bilinear cross-term in the dynamics. To address these difficulties, we apply several transformations on the state decision variables to obtain a nonlinear optimization problem with a linear performance index and affine (in the parameterized control) state-dependent equality. The adroit use of the Hamiltonian and Pontryagin's Minimum Principle allows us to derive a pair of first-order necessary conditions that, at each point in time, are easily solvable linear matrix equalities (LMEs) which give the optimal state-dependent control law. We then use the marginal sample autocorrelation of the collected data to obtain a direct data-driven equivalent of these LMEs. We demonstrate the performance of the proposed algorithm via illustrative numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.13843v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shanelle G. Clarke, Omanshu Thapliyal, Inseok Hwang</dc:creator>
    </item>
    <item>
      <title>Iterative regularization in classification via hinge loss diagonal descent</title>
      <link>https://arxiv.org/abs/2212.12675</link>
      <description>arXiv:2212.12675v2 Announce Type: replace-cross 
Abstract: Iterative regularization is a classic idea in regularization theory, that has recently become popular in machine learning. On the one hand, it allows to design efficient algorithms controlling at the same time numerical and statistical accuracy. On the other hand it allows to shed light on the learning curves observed while training neural networks. In this paper, we focus on iterative regularization in the context of classification. After contrasting this setting with that of linear inverse problems, we develop an iterative regularization approach based on the use of the hinge loss function. More precisely we consider a diagonal approach for a family of algorithms for which we prove convergence as well as rates of convergence and stability results for a suitable classification noise model. Our approach compares favorably with other alternatives, as confirmed by numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.12675v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Vassilis Apidopoulos, Tomaso Poggio, Lorenzo Rosasco, Silvia Villa</dc:creator>
    </item>
    <item>
      <title>Knowledge Gradient for Multi-Objective Bayesian Optimization with Decoupled Evaluations</title>
      <link>https://arxiv.org/abs/2302.01310</link>
      <description>arXiv:2302.01310v2 Announce Type: replace-cross 
Abstract: Multi-objective Bayesian optimization aims to find the Pareto front of trade-offs between a set of expensive objectives while collecting as few samples as possible. In some cases, it is possible to evaluate the objectives separately, and a different latency or evaluation cost can be associated with each objective. This decoupling of the objectives presents an opportunity to learn the Pareto front faster by avoiding unnecessary, expensive evaluations. We propose a scalarization based knowledge gradient acquisition function which accounts for the different evaluation costs of the objectives. We prove asymptotic consistency of the estimator of the optimum for an arbitrary, D-dimensional, real compact search space and show empirically that the algorithm performs comparably with the state of the art and significantly outperforms versions which always evaluate both objectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.01310v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jack M. Buckingham, Sebastian Rojas Gonzalez, Juergen Branke</dc:creator>
    </item>
    <item>
      <title>Approximate non-linear model predictive control with safety-augmented neural networks</title>
      <link>https://arxiv.org/abs/2304.09575</link>
      <description>arXiv:2304.09575v2 Announce Type: replace-cross 
Abstract: Model predictive control (MPC) achieves stability and constraint satisfaction for general nonlinear systems, but requires computationally expensive online optimization. This paper studies approximations of such MPC controllers via neural networks (NNs) to achieve fast online evaluation. We propose safety augmentation that yields deterministic guarantees for convergence and constraint satisfaction despite approximation inaccuracies. We approximate the entire input sequence of the MPC with NNs, which allows us to verify online if it is a feasible solution to the MPC problem. We replace the NN solution by a safe candidate based on standard MPC techniques whenever it is infeasible or has worse cost. Our method requires a single evaluation of the NN and forward integration of the input sequence online, which is fast to compute on resource-constrained systems. The proposed control framework is illustrated using two numerical non-linear MPC benchmarks of different complexity, demonstrating computational speedups that are orders of magnitude higher than online optimization. In the examples, we achieve deterministic safety through the safety-augmented NNs, where a naive NN implementation fails.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.09575v2</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Henrik Hose, Johannes K\"ohler, Melanie N. Zeilinger, Sebastian Trimpe</dc:creator>
    </item>
    <item>
      <title>Pessimistic Nonlinear Least-Squares Value Iteration for Offline Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2310.01380</link>
      <description>arXiv:2310.01380v2 Announce Type: replace-cross 
Abstract: Offline reinforcement learning (RL), where the agent aims to learn the optimal policy based on the data collected by a behavior policy, has attracted increasing attention in recent years. While offline RL with linear function approximation has been extensively studied with optimal results achieved under certain assumptions, many works shift their interest to offline RL with non-linear function approximation. However, limited works on offline RL with non-linear function approximation have instance-dependent regret guarantees. In this paper, we propose an oracle-efficient algorithm, dubbed Pessimistic Nonlinear Least-Square Value Iteration (PNLSVI), for offline RL with non-linear function approximation. Our algorithmic design comprises three innovative components: (1) a variance-based weighted regression scheme that can be applied to a wide range of function classes, (2) a subroutine for variance estimation, and (3) a planning phase that utilizes a pessimistic value iteration approach. Our algorithm enjoys a regret bound that has a tight dependency on the function class complexity and achieves minimax optimal instance-dependent regret when specialized to linear function approximation. Our work extends the previous instance-dependent results within simpler function classes, such as linear and differentiable function to a more general framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.01380v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiwei Di, Heyang Zhao, Jiafan He, Quanquan Gu</dc:creator>
    </item>
    <item>
      <title>Decision-theoretic MPC: Motion Planning with Weighted Maneuver Preferences Under Uncertainty</title>
      <link>https://arxiv.org/abs/2310.17963</link>
      <description>arXiv:2310.17963v2 Announce Type: replace-cross 
Abstract: Continuous optimization based motion planners require specifying a maneuver class before calculating the optimal trajectory for that class. In traffic, the intentions of other participants are often unclear, presenting multiple maneuver options for the autonomous vehicle. This uncertainty can make it difficult for the vehicle to decide on the best option. This work introduces a continuous optimization based motion planner that combines multiple maneuvers by weighting the trajectory of each maneuver according to the vehicle's preferences. In this way, the planner eliminates the need for committing to a single maneuver. To maintain safety despite this increased complexity, the planner considers uncertainties ranging from perception to prediction, while ensuring the feasibility of a chance-constrained emergency maneuver. Evaluations in both driving experiments and simulation studies show enhanced interaction capabilities and comfort levels compared to conventional planners, which consider only a single maneuver.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.17963v2</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>\"Omer \c{S}ahin Ta\c{s}, Philipp Heinrich Brusius, Christoph Stiller</dc:creator>
    </item>
    <item>
      <title>A Stability Principle for Learning under Non-Stationarity</title>
      <link>https://arxiv.org/abs/2310.18304</link>
      <description>arXiv:2310.18304v3 Announce Type: replace-cross 
Abstract: We develop a versatile framework for statistical learning in non-stationary environments. In each time period, our approach applies a stability principle to select a look-back window that maximizes the utilization of historical data while keeping the cumulative bias within an acceptable range relative to the stochastic error. Our theory and numerical experiments showcase the adaptivity of this approach to unknown non-stationarity. We prove regret bounds that are minimax optimal up to logarithmic factors when the population losses are strongly convex, or Lipschitz only. At the heart of our analysis lie two novel components: a measure of similarity between functions and a segmentation technique for dividing the non-stationary data sequence into quasi-stationary pieces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.18304v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chengpiao Huang, Kaizheng Wang</dc:creator>
    </item>
    <item>
      <title>Robust Regression over Averaged Uncertainty</title>
      <link>https://arxiv.org/abs/2311.06960</link>
      <description>arXiv:2311.06960v2 Announce Type: replace-cross 
Abstract: We propose a new formulation of robust regression by integrating all realizations of the uncertainty set and taking an averaged approach to obtain the optimal solution for the ordinary least squares regression problem. We show that this formulation recovers ridge regression exactly and establishes the missing link between robust optimization and the mean squared error approaches for existing regression problems. We further demonstrate that the condition of this equivalence relies on the geometric properties of the defined uncertainty set. We provide exact, closed-form, in some cases, analytical solutions to the equivalent regularization strength under uncertainty sets induced by $\ell_p$ norm, Schatten $p$-norm, and general polytopes. We then show in synthetic datasets with different levels of uncertainties, a consistent improvement of the averaged formulation over the existing worst-case formulation in out-of-sample performance. In real-world regression problems obtained from UCI datasets, similar improvements are seen in the out-of-sample datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.06960v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dimitris Bertsimas, Yu Ma</dc:creator>
    </item>
    <item>
      <title>On diffusion-based generative models and their error bounds: The log-concave case with full convergence estimates</title>
      <link>https://arxiv.org/abs/2311.13584</link>
      <description>arXiv:2311.13584v4 Announce Type: replace-cross 
Abstract: We provide full theoretical guarantees for the convergence behaviour of diffusion-based generative models under the assumption of strongly log-concave data distributions while our approximating class of functions used for score estimation is made of Lipschitz continuous functions avoiding any Lipschitzness assumption on the score function. We demonstrate via a motivating example, sampling from a Gaussian distribution with unknown mean, the powerfulness of our approach. In this case, explicit estimates are provided for the associated optimization problem, i.e. score approximation, while these are combined with the corresponding sampling estimates. As a result, we obtain the best known upper bound estimates in terms of key quantities of interest, such as the dimension and rates of convergence, for the Wasserstein-2 distance between the data distribution (Gaussian with unknown mean) and our sampling algorithm.
  Beyond the motivating example and in order to allow for the use of a diverse range of stochastic optimizers, we present our results using an $L^2$-accurate score estimation assumption, which crucially is formed under an expectation with respect to the stochastic optimizer and our novel auxiliary process that uses only known information. This approach yields the best known convergence rate for our sampling algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.13584v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefano Bruno, Ying Zhang, Dong-Young Lim, \"Omer Deniz Akyildiz, Sotirios Sabanis</dc:creator>
    </item>
    <item>
      <title>A neural network-based approach to hybrid systems identification for control</title>
      <link>https://arxiv.org/abs/2404.01814</link>
      <description>arXiv:2404.01814v2 Announce Type: replace-cross 
Abstract: We consider the problem of designing a machine learning-based model of an unknown dynamical system from a finite number of (state-input)-successor state data points, such that the model obtained is also suitable for optimal control design. We adopt a neural network (NN) architecture that, once suitably trained, yields a hybrid system with continuous piecewise-affine (PWA) dynamics that is differentiable with respect to the network's parameters, thereby enabling the use of derivative-based training procedures. We show that a careful choice of our NN's weights produces a hybrid system model with structural properties that are highly favorable when used as part of a finite horizon optimal control problem (OCP). Specifically, we rely on available results to establish that optimal solutions with strong local optimality guarantees can be computed via nonlinear programming (NLP), in contrast to classical OCPs for general hybrid systems which typically require mixed-integer optimization. Besides being well-suited for optimal control design, numerical simulations illustrate that our NN-based technique enjoys very similar performance to state-of-the-art system identification methods for hybrid systems and it is competitive on nonlinear benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01814v2</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Filippo Fabiani, Bartolomeo Stellato, Daniele Masti, Paul J. Goulart</dc:creator>
    </item>
    <item>
      <title>Backward Map for Filter Stability Analysis</title>
      <link>https://arxiv.org/abs/2405.01127</link>
      <description>arXiv:2405.01127v2 Announce Type: replace-cross 
Abstract: In this paper, a backward map is introduced for the purposes of analysis of the nonlinear (stochastic) filter stability. The backward map is important because the filter-stability in the sense of $\chisq$-divergence follows from showing a certain variance decay property for the backward map. To show this property requires additional assumptions on the model properties of the hidden Markov model (HMM). The analysis in this paper is based on introducing a Poincar\'e Inequality (PI) for HMMs with white noise observations. In finite state-space settings, PI is related to both the ergodicity of the Markov process as well as the observability of the HMM. It is shown that the Poincar\'e constant is positive if and only if the HMM is detectable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01127v2</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jin Won Kim, Anant A. Joshi, Prashant G. Mehta</dc:creator>
    </item>
    <item>
      <title>Statistical inference of convex order by Wasserstein projection</title>
      <link>https://arxiv.org/abs/2406.02840</link>
      <description>arXiv:2406.02840v2 Announce Type: replace-cross 
Abstract: Ranking distributions according to a stochastic order has wide applications in diverse areas. Although stochastic dominance has received much attention, convex order, particularly in general dimensions, has yet to be investigated from a statistical point of view. This article addresses this gap by introducing a simple statistical test for convex order based on the Wasserstein projection distance. This projection distance not only encodes whether two distributions are indeed in convex order, but also quantifies the deviation from the desired convex order and produces an optimal convex order approximation. Lipschitz stability of the backward and forward Wasserstein projection distance is proved, which leads to elegant consistency and concentration results of the estimator we employ as our test statistic. Combining these with state of the art results regarding the convergence rate of empirical distributions, we also derive upper bounds for the $p$-value and type I error of our test statistic, as well as upper bounds on the type II error for an appropriate class of strict alternatives. With proper choices of families of distributions, we further attain that the power of the proposed test increases to one as the number of samples grows to infinity. Lastly, we provide an efficient numerical scheme for our test statistic, by way of an entropic Frank-Wolfe algorithm. Experiments based on synthetic data sets illuminate the success of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.02840v2</guid>
      <category>stat.ME</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jakwang Kim, Young-Heon Kim, Yuanlong Ruan, Andrew Warren</dc:creator>
    </item>
    <item>
      <title>The Monge-Kantorovich problem on Wasserstein space</title>
      <link>https://arxiv.org/abs/2406.08585</link>
      <description>arXiv:2406.08585v2 Announce Type: replace-cross 
Abstract: We consider the Monge-Kantorovich problem between two random measuress. More precisely, given probability measures $\mathbb{P}_1,\mathbb{P}_2\in\mathcal{P}(\mathcal{P}(M))$ on the space $\mathcal{P}(M)$ of probability measures on a smooth compact manifold, we study the optimal transport problem between $\mathbb{P}_1$ and $\mathbb{P}_2 $ where the cost function is given by the squared Wasserstein distance $W_2^2(\mu,\nu)$ between $\mu,\nu \in \mathcal{P}(M)$. Under appropriate assumptions on $\mathbb{P}_1$, we prove that there exists a unique optimal plan and that it takes the form of an optimal map. An extension of this result to cost functions of the form $h(W_2(\mu,\nu))$, for strictly convex and strictly increasing functions $h$, is also established. The proofs rely heavily on a recent result of Schiavo \cite{schiavo2020rademacher}, which establishes a version of Rademacher's theorem on Wasserstein space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.08585v2</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pedram Emami, Brendan Pass</dc:creator>
    </item>
    <item>
      <title>Proximal Point Method for Online Saddle Point Problem</title>
      <link>https://arxiv.org/abs/2407.04591</link>
      <description>arXiv:2407.04591v2 Announce Type: replace-cross 
Abstract: This paper focuses on the online saddle point problem, which involves a sequence of two-player time-varying convex-concave games. Considering the nonstationarity of the environment, we adopt the duality gap and the dynamic Nash equilibrium regret as performance metrics for algorithm design. We present three variants of the proximal point method: the Online Proximal Point Method (OPPM), the Optimistic OPPM (OptOPPM), and the OptOPPM with multiple predictors. Each algorithm guarantees upper bounds for both the duality gap and dynamic Nash equilibrium regret, achieving near-optimality when measured against the duality gap. Specifically, in certain benign environments, such as sequences of stationary payoff functions, these algorithms maintain a nearly constant metric bound. Experimental results further validate the effectiveness of these algorithms. Lastly, this paper discusses potential reliability concerns associated with using dynamic Nash equilibrium regret as a performance metric. The technical appendix and code can be found at https://github.com/qingxin6174/PPM-for-OSP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04591v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qing-xin Meng, Jian-wei Liu</dc:creator>
    </item>
    <item>
      <title>OptiBench Meets ReSocratic: Measure and Improve LLMs for Optimization Modeling</title>
      <link>https://arxiv.org/abs/2407.09887</link>
      <description>arXiv:2407.09887v3 Announce Type: replace-cross 
Abstract: Large language models (LLMs) have exhibited their problem-solving abilities in mathematical reasoning. Solving realistic optimization (OPT) problems in application scenarios requires advanced and applied mathematics ability. However, current OPT benchmarks that merely solve linear programming are far from complex realistic situations. In this work, we propose OptiBench, a benchmark for End-to-end optimization problem-solving with human-readable inputs and outputs. OptiBench contains rich optimization problems, including linear and nonlinear programming with or without tabular data, which can comprehensively evaluate LLMs' solving ability. In our benchmark, LLMs are required to call a code solver to provide precise numerical answers. Furthermore, to alleviate the data scarcity for optimization problems, and to bridge the gap between open-source LLMs on a small scale (e.g., Llama-3-8b) and closed-source LLMs (e.g., GPT-4), we further propose a data synthesis method namely ReSocratic. Unlike general data synthesis methods that proceed from questions to answers, \ReSocratic first incrementally synthesizes formatted optimization demonstration with mathematical formulations step by step and then back-translates the generated demonstrations into questions. Based on this, we synthesize the ReSocratic-29k dataset. We further conduct supervised fine-tuning with ReSocratic-29k on multiple open-source models. Experimental results show that ReSocratic-29k significantly improves the performance of open-source models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09887v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Zhicheng Yang, Yiwei Wang, Yinya Huang, Zhijiang Guo, Wei Shi, Xiongwei Han, Liang Feng, Linqi Song, Xiaodan Liang, Jing Tang</dc:creator>
    </item>
    <item>
      <title>Trustworthy V2G scheduling and energy trading: A blockchain-based framework</title>
      <link>https://arxiv.org/abs/2407.13988</link>
      <description>arXiv:2407.13988v3 Announce Type: replace-cross 
Abstract: The rapid growth of electric vehicles (EVs) and the deployment of vehicle-to-grid (V2G) technology pose significant challenges for distributed power grids, particularly in fostering trust and ensuring effective coordination among stakeholders. Establishing a trustworthy V2G operation environment is crucial for enabling large-scale EV user participation and realizing V2G potential in real-world applications. In this paper, an integrated scheduling and trading framework is developed to conduct transparent and efficacious coordination in V2G operations. In blockchain implementation, a cyber-physical blockchain architecture is proposed to enhance transaction efficiency and scalability by leveraging smart charging points (SCPs) for rapid transaction validation through a fast-path practical byzantine fault tolerance (fast-path PBFT) consensus mechanism. From the energy dispatching perspective, a game-theoretical pricing strategy is employed and smart contracts are utilized for autonomous decision-making between EVs and operators, aiming to optimize the trading process and maximize economic benefits. Numerical evaluation of blockchain consensus shows the effect of the fast-path PBFT consensus in improving systems scalability with a balanced trade-off in robustness. A case study, utilizing real-world data from the Southern University of Science and Technology (SUSTech), demonstrates significant reductions in EV charging costs and the framework potential to support auxiliary grid services.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13988v3</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yunwang Chen, Xiang Lei, Songyan Niu, Linni Jian</dc:creator>
    </item>
    <item>
      <title>HJ-sampler: A Bayesian sampler for inverse problems of a stochastic process by leveraging Hamilton-Jacobi PDEs and score-based generative models</title>
      <link>https://arxiv.org/abs/2409.09614</link>
      <description>arXiv:2409.09614v2 Announce Type: replace-cross 
Abstract: The interplay between stochastic processes and optimal control has been extensively explored in the literature. With the recent surge in the use of diffusion models, stochastic processes have increasingly been applied to sample generation. This paper builds on the log transform, known as the Cole-Hopf transform in Brownian motion contexts, and extends it within a more abstract framework that includes a linear operator. Within this framework, we found that the well-known relationship between the Cole-Hopf transform and optimal transport is a particular instance where the linear operator acts as the infinitesimal generator of a stochastic process. We also introduce a novel scenario where the linear operator is the adjoint of the generator, linking to Bayesian inference under specific initial and terminal conditions. Leveraging this theoretical foundation, we develop a new algorithm, named the HJ-sampler, for Bayesian inference for the inverse problem of a stochastic differential equation with given terminal observations. The HJ-sampler involves two stages: (1) solving the viscous Hamilton-Jacobi partial differential equations, and (2) sampling from the associated stochastic optimal control problem. Our proposed algorithm naturally allows for flexibility in selecting the numerical solver for viscous HJ PDEs. We introduce two variants of the solver: the Riccati-HJ-sampler, based on the Riccati method, and the SGM-HJ-sampler, which utilizes diffusion models. We demonstrate the effectiveness and flexibility of the proposed methods by applying them to solve Bayesian inverse problems involving various stochastic processes and prior distributions, including applications that address model misspecifications and quantifying model uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.09614v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.CO</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Tingwei Meng, Zongren Zou, J\'er\^ome Darbon, George Em Karniadakis</dc:creator>
    </item>
    <item>
      <title>A Simulation-Free Deep Learning Approach to Stochastic Optimal Control</title>
      <link>https://arxiv.org/abs/2410.05163</link>
      <description>arXiv:2410.05163v2 Announce Type: replace-cross 
Abstract: We propose a simulation-free algorithm for the solution of generic problems in stochastic optimal control (SOC). Unlike existing methods, our approach does not require the solution of an adjoint problem, but rather leverages Girsanov theorem to directly calculate the gradient of the SOC objective on-policy. This allows us to speed up the optimization of control policies parameterized by neural networks since it completely avoids the expensive back-propagation step through stochastic differential equations (SDEs) used in the Neural SDE framework. In particular, it enables us to solve SOC problems in high dimension and on long time horizons. We demonstrate the efficiency of our approach in various domains of applications, including standard stochastic optimal control problems, sampling from unnormalized distributions via construction of a Schr\"odinger-F\"ollmer process, and fine-tuning of pre-trained diffusion models. In all cases our method is shown to outperform the existing methods in both the computing time and memory efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05163v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mengjian Hua, Matthieu Lauri\`ere, Eric Vanden-Eijnden</dc:creator>
    </item>
  </channel>
</rss>
