<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 29 Aug 2024 01:38:33 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>RISE-iEEG: Robust to Inter-Subject Electrodes Implantation Variability iEEG Classifier</title>
      <link>https://arxiv.org/abs/2408.14477</link>
      <description>arXiv:2408.14477v1 Announce Type: new 
Abstract: Utilization of intracranial electroencephalography (iEEG) is rapidly increasing for clinical and brain-computer interface applications. iEEG facilitates the recording of neural activity with high spatial and temporal resolution, making it a desirable neuroimaging modality for studying neural dynamics. Despite its benefits, iEEG faces challenges such as inter-subject variability in electrode implantation, which makes the development of unified neural decoder models across different patients difficult. In this research, we introduce a novel decoder model that is robust to inter-subject electrode implantation variability. We call this model RISE-iEEG, which stands for Robust Inter-Subject Electrode Implantation Variability iEEG Classifier. RISE-iEEG employs a deep neural network structure preceded by a patient-specific projection network. The projection network maps the neural data of individual patients onto a common low-dimensional space, compensating for the implantation variability. In other words, we developed an iEEG decoder model that can be applied across multiple patients' data without requiring the coordinates of electrode for each patient. The performance of RISE-iEEG across multiple datasets, including the Audio-Visual dataset, Music Reconstruction dataset, and Upper-Limb Movement dataset, surpasses that of state-of-the-art iEEG decoder models such as HTNet and EEGNet. Our analysis shows that the performance of RISE-iEEG is 10\% higher than that of HTNet and EEGNet in terms of F1 score, with an average F1 score of 83\%, which is the highest result among the evaluation methods defined. Furthermore, the analysis of projection network weights in the Music Reconstruction dataset across patients suggests that the Superior Temporal lobe serves as the primary encoding neural node. This finding aligns with the auditory processing physiology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.14477v1</guid>
      <category>q-bio.NC</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Maryam Ostadsharif Memar, Navid Ziaei, Behzad Nazari, Ali Yousefi</dc:creator>
    </item>
    <item>
      <title>Uncertainty Quantification in Alzheimer's Disease Progression Modeling</title>
      <link>https://arxiv.org/abs/2408.14478</link>
      <description>arXiv:2408.14478v1 Announce Type: new 
Abstract: With the increasing number of patients diagnosed with Alzheimer's Disease, prognosis models have the potential to aid in early disease detection. However, current approaches raise dependability concerns as they do not account for uncertainty. In this work, we compare the performance of Monte Carlo Dropout, Variational Inference, Markov Chain Monte Carlo, and Ensemble Learning trained on 512 patients to predict 4-year cognitive score trajectories with confidence bounds. We show that MC Dropout and MCMC are able to produce well-calibrated, and accurate predictions under noisy training data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.14478v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wael Mobeirek, Shirley Mao</dc:creator>
    </item>
    <item>
      <title>A CRH-HCN Theory of Obsessive-Compulsive Disorder (OCD)</title>
      <link>https://arxiv.org/abs/2408.14479</link>
      <description>arXiv:2408.14479v1 Announce Type: new 
Abstract: I present the first complete theory of OCD. OCD occurs when excessive CRH is released in the prefrontal cortex, activating cAMP. cAMP is a major inducer of HCN channels, which promote repeated neural firing. The combination of CRH, which is strongly associated with stress, and repeated firing that cannot be controlled, explains all of the features of OCD, including obsessions and compulsions of all kinds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.14479v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ari Rappoport</dc:creator>
    </item>
    <item>
      <title>Artificial intelligence for science: The easy and hard problems</title>
      <link>https://arxiv.org/abs/2408.14508</link>
      <description>arXiv:2408.14508v1 Announce Type: cross 
Abstract: A suite of impressive scientific discoveries have been driven by recent advances in artificial intelligence. These almost all result from training flexible algorithms to solve difficult optimization problems specified in advance by teams of domain scientists and engineers with access to large amounts of data. Although extremely useful, this kind of problem solving only corresponds to one part of science - the "easy problem." The other part of scientific research is coming up with the problem itself - the "hard problem." Solving the hard problem is beyond the capacities of current algorithms for scientific discovery because it requires continual conceptual revision based on poorly defined constraints. We can make progress on understanding how humans solve the hard problem by studying the cognitive science of scientists, and then use the results to design new computational agents that automatically infer and update their scientific paradigms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.14508v1</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ruairidh M. Battleday, Samuel J. Gershman</dc:creator>
    </item>
    <item>
      <title>Motion-Invariant Variational Auto-Encoding of Brain Structural Connectomes</title>
      <link>https://arxiv.org/abs/2212.04535</link>
      <description>arXiv:2212.04535v3 Announce Type: replace 
Abstract: Mapping of human brain structural connectomes via diffusion MRI offers a unique opportunity to understand brain structural connectivity and relate it to various human traits, such as cognition. However, head displacement during image acquisition can compromise the accuracy of connectome reconstructions and subsequent inference results. We develop a generative model to learn low-dimensional representations of structural connectomes invariant to motion-induced artifacts, so that we can link brain networks and human traits more accurately, and generate motion-adjusted connectomes. We apply the proposed model to data from the Adolescent Brain Cognitive Development (ABCD) study and the Human Connectome Project (HCP) to investigate how our motion-invariant connectomes facilitate understanding of the brain network and its relationship with cognition. Empirical results demonstrate that the proposed motion-invariant variational auto-encoder (inv-VAE) outperforms its competitors in various aspects. In particular, motion-adjusted structural connectomes are more strongly associated with a wide array of cognition-related traits than other approaches without motion adjustment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.04535v3</guid>
      <category>q-bio.NC</category>
      <pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yizi Zhang, Meimei Liu, Zhengwu Zhang, David Dunson</dc:creator>
    </item>
    <item>
      <title>Learning temporal relationships between symbols with Laplace Neural Manifolds</title>
      <link>https://arxiv.org/abs/2302.10163</link>
      <description>arXiv:2302.10163v2 Announce Type: replace 
Abstract: Spiking across populations of neurons in many regions of the mammalian brain maintains a temporal memory, a neural timeline of the recent past. Behavioral results demonstrate that people can not only perceive a timeline over the remembered past, but also anticipate the time of future events over an analogous internal timeline. This paper presents a mathematical framework for building this timeline of the future. We assume that the input to the system is a time series of symbols -- sparse tokenized representations of the present -- in continuous time. The goal is to record pairwise temporal relationships between symbols over a wide range of time scales. We assume that the brain has access to a temporal memory in the form of the real Laplace transform of providing information about what symbols were presented when in the recent past. Hebbian associations with a diversity of synaptic time scales are formed between the past timeline and the present symbol. Hebbian associations between the Laplace transform of two functions record the Laplace transform of the convolution of those functions. This associative memory stores the convolution between past and the present. Knowing the temporal relationships between the past and the present allows one to infer relationships between the present and the future. With appropriate normalization, this Hebbian associative matrix can store a Laplace successor representation and a Laplace predecessor representation from which measures of temporal contingency can be evaluated. This framework synthesizes a number of recent neuroscientific findings including results from dopamine neurons in the mesolimbic forebrain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.10163v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marc W. Howard, Zahra G. Esfahani, Bao Le, Per B. Sederberg</dc:creator>
    </item>
    <item>
      <title>An internal sensory model allows for balance control using muscle spindle exafferent acceleration feedback</title>
      <link>https://arxiv.org/abs/2403.00951</link>
      <description>arXiv:2403.00951v4 Announce Type: replace 
Abstract: All motor tasks with a mechanical system (a human body, a rider on a bicycle) that is approximately linear in the part of the state space where it stays most of the time (e.g., upright balance control) allow for optimal control actions that are a simple linear combination of full state sensory feedback. When the sensory feedback is not full state, optimal control for these approximately linear mechanical systems is based on an internal dynamical system that estimates the states, and that can be implemented as a recurrent neural network (RNN) in the central nervous system (CNS). It uses a sensory model to update the state estimates with the available (non-full state) sensory feedback. The weights of this RNN are fully specified by results from optimal feedback control. This is highly relevant for muscle spindle primary afferents under perfectly coordinated fusimotor and skeletomotor control because, under this condition, their firing rates scale with the exafferent joint acceleration component. A sensory model exists for this exafferent acceleration component, and this can be used by the CNS to estimate the states. As a proof of the viability of this mechanism, I demonstrate that it balances a standing body and a rider-bicycle combination using realistic parameter values and with forcing torques that are feasible for humans.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.00951v4</guid>
      <category>q-bio.NC</category>
      <pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Eric Maris</dc:creator>
    </item>
    <item>
      <title>Localising the Seizure Onset Zone from Single-Pulse Electrical Stimulation Responses with a CNN Transformer</title>
      <link>https://arxiv.org/abs/2403.20324</link>
      <description>arXiv:2403.20324v3 Announce Type: replace-cross 
Abstract: Epilepsy is one of the most common neurological disorders, often requiring surgical intervention when medication fails to control seizures. For effective surgical outcomes, precise localisation of the epileptogenic focus - often approximated through the Seizure Onset Zone (SOZ) - is critical yet remains a challenge. Active probing through electrical stimulation is already standard clinical practice for identifying epileptogenic areas. Our study advances the application of deep learning for SOZ localisation using Single-Pulse Electrical Stimulation (SPES) responses, with two key contributions. Firstly, we implement an existing deep learning model to compare two SPES analysis paradigms: divergent and convergent. These paradigms evaluate outward and inward effective connections, respectively. We assess the generalisability of these models to unseen patients and electrode placements using held-out test sets. Our findings reveal a notable improvement in moving from a divergent (AUROC: 0.574) to a convergent approach (AUROC: 0.666), marking the first application of the latter in this context. Secondly, we demonstrate the efficacy of CNN Transformers with cross-channel attention in handling heterogeneous electrode placements, increasing the AUROC to 0.730. These findings represent a significant step in modelling patient-specific intracranial EEG electrode placements in SPES. Future work will explore integrating these models into clinical decision-making processes to bridge the gap between deep learning research and practical healthcare applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.20324v3</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>q-bio.NC</category>
      <pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jamie Norris, Aswin Chari, Dorien van Blooijs, Gerald Cooray, Karl Friston, Martin Tisdall, Richard Rosch</dc:creator>
    </item>
    <item>
      <title>Quantum Multimodal Contrastive Learning Framework</title>
      <link>https://arxiv.org/abs/2408.13919</link>
      <description>arXiv:2408.13919v2 Announce Type: replace-cross 
Abstract: In this paper, we propose a novel framework for multimodal contrastive learning utilizing a quantum encoder to integrate EEG (electroencephalogram) and image data. This groundbreaking attempt explores the integration of quantum encoders within the traditional multimodal learning framework. By leveraging the unique properties of quantum computing, our method enhances the representation learning capabilities, providing a robust framework for analyzing time series and visual information concurrently. We demonstrate that the quantum encoder effectively captures intricate patterns within EEG signals and image features, facilitating improved contrastive learning across modalities. This work opens new avenues for integrating quantum computing with multimodal data analysis, particularly in applications requiring simultaneous interpretation of temporal and visual data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.13919v2</guid>
      <category>quant-ph</category>
      <category>q-bio.NC</category>
      <pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chi-Sheng Chen, Aidan Hung-Wen Tsai, Sheng-Chieh Huang</dc:creator>
    </item>
  </channel>
</rss>
