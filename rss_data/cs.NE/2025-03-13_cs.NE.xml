<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NE</link>
    <description>cs.NE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 13 Mar 2025 04:00:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>SDTrack: A Baseline for Event-based Tracking via Spiking Neural Networks</title>
      <link>https://arxiv.org/abs/2503.08703</link>
      <description>arXiv:2503.08703v1 Announce Type: new 
Abstract: Event cameras provide superior temporal resolution, dynamic range, power efficiency, and pixel bandwidth. Spiking Neural Networks (SNNs) naturally complement event data through discrete spike signals, making them ideal for event-based tracking. However, current approaches that combine Artificial Neural Networks (ANNs) and SNNs, along with suboptimal architectures, compromise energy efficiency and limit tracking performance. To address these limitations, we propose the first Transformer-based spike-driven tracking pipeline. Our Global Trajectory Prompt (GTP) method effectively captures global trajectory information and aggregates it with event streams into event images to enhance spatiotemporal representation. We then introduce SDTrack, a Transformer-based spike-driven tracker comprising a Spiking MetaFormer backbone and a simple tracking head that directly predicts normalized coordinates using spike signals. The framework is end-to-end, does not require data augmentation or post-processing. Extensive experiments demonstrate that SDTrack achieves state-of-the-art performance while maintaining the lowest parameter count and energy consumption across multiple event-based tracking benchmarks, establishing a solid baseline for future research in the field of neuromorphic vision.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08703v1</guid>
      <category>cs.NE</category>
      <category>cs.CV</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yimeng Shan, Zhenbang Ren, Haodi Wu, Wenjie Wei, Rui-Jie Zhu, Shuai Wang, Dehao Zhang, Yichen Xiao, Jieyuan Zhang, Kexin Shi, Jingzhinan Wang, Jason K. Eshraghian, Haicheng Qu, Jiqing Zhang, Malu Zhang, Yang Yang</dc:creator>
    </item>
    <item>
      <title>Fig Tree-Wasp Symbiotic Coevolutionary Optimization Algorithm</title>
      <link>https://arxiv.org/abs/2503.09340</link>
      <description>arXiv:2503.09340v1 Announce Type: new 
Abstract: The nature inspired algorithms are becoming popular due to their simplicity and wider applicability. In the recent past several such algorithms have been developed. They are mainly bio-inspired, swarm based, physics based and socio-inspired; however, the domain based on symbiotic relation between creatures is still to be explored. A novel metaheuristic optimization algorithm referred to as Fig Tree-Wasp Symbiotic Coevolutionary (FWSC) algorithm is proposed. It models the symbiotic coevolutionary relationship between fig trees and wasps. More specifically, the mating of wasps, pollinating the figs, searching for new trees for pollination and wind effect drifting of wasps are modeled in the algorithm. These phenomena help in balancing the two important aspects of exploring the search space efficiently as well as exploit the promising regions. The algorithm is successfully tested on a variety of test problems. The results are compared with existing methods and algorithms. The Wilcoxon Signed Rank Test and Friedman Test are applied for the statistical validation of the algorithm performance. The algorithm is also further applied to solve the real-world engineering problems. The performance of the FWSC underscored that the algorithm can be applied to wider variety of real-world problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09340v1</guid>
      <category>cs.NE</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anand J Kulkarni, Isha Purnapatre, Apoorva S Shastri</dc:creator>
    </item>
    <item>
      <title>Neural reservoir control of a soft bio-hybrid arm</title>
      <link>https://arxiv.org/abs/2503.09477</link>
      <description>arXiv:2503.09477v1 Announce Type: cross 
Abstract: A long-standing engineering problem, the control of soft robots is difficult because of their highly non-linear, heterogeneous, anisotropic, and distributed nature. Here, bridging engineering and biology, a neural reservoir is employed for the dynamic control of a bio-hybrid model arm made of multiple muscle-tendon groups enveloping an elastic spine. We show how the use of reservoirs facilitates simultaneous control and self-modeling across a set of challenging tasks, outperforming classic neural network approaches. Further, by implementing a spiking reservoir on neuromorphic hardware, energy efficiency is achieved, with nearly two-orders of magnitude improvement relative to standard CPUs, with implications for the on-board control of untethered, small-scale soft robots.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09477v1</guid>
      <category>cs.RO</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Noel Naughton, Arman Tekinalp, Keshav Shivam, Seung Hung Kim, Volodymyr Kindratenko, Mattia Gazzola</dc:creator>
    </item>
    <item>
      <title>Voltage-Controlled Magnetoelectric Devices for Neuromorphic Diffusion Process</title>
      <link>https://arxiv.org/abs/2407.12261</link>
      <description>arXiv:2407.12261v2 Announce Type: replace 
Abstract: Stochastic diffusion processes are pervasive in nature, from the seemingly erratic Brownian motion to the complex interactions of synaptically-coupled spiking neurons. Recently, drawing inspiration from Langevin dynamics, neuromorphic diffusion models were proposed and have become one of the major breakthroughs in the field of generative artificial intelligence. Unlike discriminative models that have been well developed to tackle classification or regression tasks, diffusion models as well as other generative models such as ChatGPT aim at creating content based upon contexts learned. However, the more complex algorithms of these models result in high computational costs using today's technologies, creating a bottleneck in their efficiency, and impeding further development. Here, we develop a spintronic voltage-controlled magnetoelectric memory hardware for the neuromorphic diffusion process. The in-memory computing capability of our spintronic devices goes beyond current Von Neumann architecture, where memory and computing units are separated. Together with the non-volatility of magnetic memory, we can achieve high-speed and low-cost computing, which is desirable for the increasing scale of generative models in the current era. We experimentally demonstrate that the hardware-based true random diffusion process can be implemented for image generation and achieve comparable image quality to software-based training as measured by the Frechet inception distance (FID) score, achieving ~10^3 better energy-per-bit-per-area over traditional hardware.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12261v2</guid>
      <category>cs.NE</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <category>physics.app-ph</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yang Cheng, Qingyuan Shu, Albert Lee, Haoran He, Ivy Zhu, Minzhang Chen, Renhe Chen, Zirui Wang, Hantao Zhang, Chih-Yao Wang, Shan-Yi Yang, Yu-Chen Hsin, Cheng-Yi Shih, Hsin-Han Lee, Ran Cheng, Kang L. Wang</dc:creator>
    </item>
    <item>
      <title>Multi-objective Memetic Algorithm with Adaptive Weights for Inverse Antenna Design</title>
      <link>https://arxiv.org/abs/2409.14245</link>
      <description>arXiv:2409.14245v2 Announce Type: replace 
Abstract: This paper deals with discrete topology optimization and describes the modification of a single-objective algorithm into its multi-objective counterpart. The result is a significant increase in the optimization speed and quality of the resulting Pareto front as compared to conventional state-of-the-art automated inverse design techniques. This advancement is possible thanks to a memetic algorithm combining a gradient-based search for local minima with heuristic optimization to maintain sufficient diversity. The local algorithm is based on rank-1 perturbations; the global algorithm is NSGA-II. An important advancement is the adaptive weighting of objective functions during optimization. The procedure is tested on four challenging examples dealing with both physical and topological metrics and multi-objective settings. The results are compared with standard techniques, and the superb performance of the proposed technique is reported. The implemented algorithm applies to antenna inverse design problems and is an efficient data miner for machine learning tools.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.14245v2</guid>
      <category>cs.NE</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Petr Kadlec, Miloslav Capek</dc:creator>
    </item>
    <item>
      <title>Discovering new robust local search algorithms with neuro-evolution</title>
      <link>https://arxiv.org/abs/2501.04747</link>
      <description>arXiv:2501.04747v2 Announce Type: replace 
Abstract: This paper explores a novel approach aimed at overcoming existing challenges in the realm of local search algorithms. Our aim is to improve the decision process that takes place within a local search algorithm so as to make the best possible transitions in the neighborhood at each iteration. To improve this process, we propose to use a neural network that has the same input information as conventional local search algorithms. In this paper, which is an extension of the work presented at EvoCOP2024, we investigate different ways of representing this information so as to make the algorithm as efficient as possible but also robust to monotonic transformations of the problem objective function. To assess the efficiency of this approach, we develop an experimental setup centered around NK landscape problems, offering the flexibility to adjust problem size and ruggedness. This approach offers a promising avenue for the emergence of new local search algorithms and the improvement of their problem-solving capabilities for black-box problems. The last version of this article is published in the journal SN Computer Science (Springer).</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04747v2</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohamed Salim Amri Sakhri, Adrien Go\"effon, Olivier Goudet, Fr\'ed\'eric Saubion, Cha\"ima\^a Touhami</dc:creator>
    </item>
    <item>
      <title>Folded Context Condensation in Path Integral Formalism for Infinite Context Transformers</title>
      <link>https://arxiv.org/abs/2405.04620</link>
      <description>arXiv:2405.04620v4 Announce Type: replace-cross 
Abstract: In this work, we present a generalized formulation of the Transformer algorithm by reinterpreting its core mechanisms within the framework of Path Integral formalism. In this perspective, the attention mechanism is recast as a process that integrates all possible transition paths leading to future token states, with temporal evolution governed by the Feed-Forward Network. By systematically mapping each component of the Transformer to its counterpart in the Path Integral formulation, we obtain a more compact and efficient representation, in which the contextual information of a sequence is condensed into memory-like segments. These segments are recurrently processed across Transformer layers, enabling more effective long-term information retention. We validate the effectiveness of this approach through the Passkey retrieval task and a summarization task, demonstrating that the proposed method preserves historical information while exhibiting memory usage that scales linearly with sequence length. This contrasts with the non-linear memory growth typically observed in standard attention mechanisms. We expect that this quantum-inspired generalization of the Transformer architecture will open new avenues for enhancing both the efficiency and expressiveness of future Transformer models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04620v4</guid>
      <category>hep-ph</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Won-Gi Paeng, Daesuk Kwon, Kyungwon Jeong, Honggyo Suh</dc:creator>
    </item>
    <item>
      <title>Large Language Model as Meta-Surrogate for Data-Driven Many-Task Optimization: A Proof-of-Principle Study</title>
      <link>https://arxiv.org/abs/2503.08301</link>
      <description>arXiv:2503.08301v2 Announce Type: replace-cross 
Abstract: In many-task optimization scenarios, surrogate models are valuable for mitigating the computational burden of repeated fitness evaluations across tasks. This study proposes a novel meta-surrogate framework to assist many-task optimization, by leveraging the knowledge transfer strengths and emergent capabilities of large language models (LLMs). We formulate a unified framework for many-task fitness prediction, by defining a universal model with metadata to fit a group of problems. Fitness prediction is performed on metadata and decision variables, enabling efficient knowledge sharing across tasks and adaptability to new tasks. The LLM-based meta-surrogate treats fitness prediction as conditional probability estimation, employing a unified token sequence representation for task metadata, inputs, and outputs. This approach facilitates efficient inter-task knowledge sharing through shared token embeddings and captures complex task dependencies via multi-task model training. Experimental results demonstrate the model's emergent generalization ability, including zero-shot performance on problems with unseen dimensions. When integrated into evolutionary transfer optimization (ETO), our framework supports dual-level knowledge transfer -- at both the surrogate and individual levels -- enhancing optimization efficiency and robustness. This work establishes a novel foundation for applying LLMs in surrogate modeling, offering a versatile solution for many-task optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08301v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xian-Rong Zhang, Yue-Jiao Gong, Jun Zhang</dc:creator>
    </item>
  </channel>
</rss>
