<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 13 Aug 2025 04:00:16 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Convergent Q-Learning for Infinite-Horizon General-Sum Markov Games through Behavioral Economics</title>
      <link>https://arxiv.org/abs/2508.08669</link>
      <description>arXiv:2508.08669v1 Announce Type: new 
Abstract: Risk-aversion and bounded rationality are two key characteristics of human decision-making. Risk-averse quantal-response equilibrium (RQE) is a solution concept that incorporates these features, providing a more realistic depiction of human decision making in various strategic environments compared to a Nash equilibrium. Furthermore a class of RQE has recently been shown in arXiv:2406.14156 to be universally computationally tractable in all finite-horizon Markov games, allowing for the development of multi-agent reinforcement learning algorithms with convergence guarantees. In this paper, we expand upon the study of RQE and analyze their computation in both two-player normal form games and discounted infinite-horizon Markov games. For normal form games we adopt a monotonicity-based approach allowing us to generalize previous results. We first show uniqueness and Lipschitz continuity of RQE with respect to player's payoff matrices under monotonicity assumptions, and then provide conditions on the players' degrees of risk aversion and bounded rationality that ensure monotonicity. We then focus on discounted infinite-horizon Markov games. We define the risk-averse quantal-response Bellman operator and prove its contraction under further conditions on the players' risk-aversion, bounded rationality, and temporal discounting. This yields a Q-learning based algorithm with convergence guarantees for all infinite-horizon general-sum Markov games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08669v1</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yizhou Zhang, Eric Mazumdar</dc:creator>
    </item>
    <item>
      <title>How to Resolve Envy by Adding Goods</title>
      <link>https://arxiv.org/abs/2508.08682</link>
      <description>arXiv:2508.08682v1 Announce Type: new 
Abstract: We consider the problem of resolving the envy of a given initial allocation by adding elements from a pool of goods. We give a characterization of the instances where envy can be resolved by adding an arbitrary number of copies of the items in the pool. From this characterization, we derive a polynomial-time algorithm returning a respective solution if it exists. If the number of copies or the total number of added items are bounded, the problem becomes computationally intractable even in various restricted cases. We perform a parameterized complexity analysis, focusing on the number of agents and the pool size as parameters. Notably, although not every instance admits an envy-free solution, our approach allows us to efficiently determine, in polynomial time, whether a solution exists-an aspect that is both theoretically interesting and far from trivial.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08682v1</guid>
      <category>cs.GT</category>
      <category>cs.CC</category>
      <pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthias Bentert, Robert Bredereck, Eva Deltl, Pallavi Jain, Leon Kellerhals</dc:creator>
    </item>
    <item>
      <title>Optimal Boost Design for Auto-bidding Mechanism with Publisher Quality Constraints</title>
      <link>https://arxiv.org/abs/2508.08772</link>
      <description>arXiv:2508.08772v1 Announce Type: new 
Abstract: Online bidding is crucial in mobile ecosystems, enabling real-time ad allocation across billions of devices to optimize performance and user experience. Improving ad allocation efficiency is a long-standing research problem, as it directly enhances the economic outcomes for all participants in advertising platforms. This paper investigates the design of optimal boost factors in online bidding while incorporating quality value (the impact of displayed ads on publishers' long-term benefits). To address the divergent interests on quality, we establish a three-party auction framework with a unified welfare metric of advertiser and publisher. Within this framework, we derive the theoretical efficiency lower bound for C-competitive boost in second-price single-slot auctions, then design a novel quality-involved Boosting (q-Boost) algorithm for computing the optimal boost factor. Experimental validation on Alibaba's public dataset (AuctionNet) demonstrates 2%-6% welfare improvements over conventional approaches, proving our method's effectiveness in real-world settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08772v1</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huanyu Yan, Yu Huo, Min Lu, Weitong Ou, Xingyan Shi, Ruihe Shi, Xiaoying Tang</dc:creator>
    </item>
    <item>
      <title>Not in My Backyard! Temporal Voting Over Public Chores</title>
      <link>https://arxiv.org/abs/2508.08810</link>
      <description>arXiv:2508.08810v1 Announce Type: new 
Abstract: We study a temporal voting model where voters have dynamic preferences over a set of public chores -- projects that benefit society, but impose individual costs on those affected by their implementation. We investigate the computational complexity of optimizing utilitarian and egalitarian welfare. Our results show that while optimizing the former is computationally straightforward, minimizing the latter is computationally intractable, even in very restricted cases. Nevertheless, we identify several settings where this problem can be solved efficiently, either exactly or by an approximation algorithm. We also examine the effects of enforcing temporal fairness and its impact on social welfare, and analyze the competitive ratio of online algorithms. We then explore the strategic behavior of agents, providing insights into potential malfeasance in such decision-making environments. Finally, we discuss a range of fairness measures and their suitability for our setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08810v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <category>econ.TH</category>
      <pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Edith Elkind, Tzeh Yuan Neoh, Nicholas Teh</dc:creator>
    </item>
    <item>
      <title>Non-participant externalities reshape the evolution of altruistic punishment</title>
      <link>https://arxiv.org/abs/2508.08302</link>
      <description>arXiv:2508.08302v1 Announce Type: cross 
Abstract: While voluntary participation is a key mechanism that enables altruistic punishment to emerge, its explanatory power typically rests on the common assumption that non-participants have no impact on the public good. Yet, given the decentralized nature of voluntary participation, opting out does not necessarily preclude individuals from influencing the public good. Here, we revisit the role of voluntary participation by allowing non-participants to exert either positive or negative impacts on the public good. Using evolutionary analysis in a well-mixed finite population, we find that positive externalities from non-participants lower the synergy threshold required for altruistic punishment to dominate. In contrast, negative externalities raise this threshold, making altruistic punishment harder to sustain. Notably, when non-participants have positive impacts, altruistic punishment thrives only if non-participation is incentivized, whereas under negative impacts, it can persist even when non-participation is discouraged. Our findings reveal that efforts to promote altruistic punishment must account for the active role of non-participants, whose influence can make or break collective outcomes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08302v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.GT</category>
      <category>q-bio.PE</category>
      <pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhao Song, Chen Shen, Valerio Capraro, The Anh Han</dc:creator>
    </item>
    <item>
      <title>Algorithmic Collusion of Pricing and Advertising on E-commerce Platforms</title>
      <link>https://arxiv.org/abs/2508.08325</link>
      <description>arXiv:2508.08325v1 Announce Type: cross 
Abstract: Online sellers have been adopting AI learning algorithms to automatically make product pricing and advertising decisions on e-commerce platforms. When sellers compete using such algorithms, one concern is that of tacit collusion - the algorithms learn to coordinate on higher than competitive. We empirically investigate whether these concerns are valid when sellers make pricing and advertising decisions together, i.e., two-dimensional decisions. Our empirical strategy is to analyze competition with multi-agent reinforcement learning, which we calibrate to a large-scale dataset collected from Amazon.com products. Our first contribution is to find conditions under which learning algorithms can facilitate win-win-win outcomes that are beneficial for consumers, sellers, and even the platform, when consumers have high search costs. In these cases the algorithms learn to coordinate on prices that are lower than competitive prices. The intuition is that the algorithms learn to coordinate on lower advertising bids, which lower advertising costs, leading to lower prices. Our second contribution is an analysis of a large-scale, high-frequency keyword-product dataset for more than 2 million products on Amazon.com. Our estimates of consumer search costs show a wide range of costs for different product keywords. We generate an algorithm usage and find a negative interaction between the estimated consumer search costs and the algorithm usage index, providing empirical evidence of beneficial collusion. Finally, we analyze the platform's strategic response. We find that reserve price adjustments will not increase profits for the platform, but commission adjustments will. Our analyses help alleviate some worries about the potentially harmful effects of competing learning algorithms, and can help sellers, platforms and policymakers to decide on whether to adopt or regulate such algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08325v1</guid>
      <category>econ.GN</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hangcheng Zhao, Ron Berman</dc:creator>
    </item>
    <item>
      <title>Dividing a cake for the irrationally entitled</title>
      <link>https://arxiv.org/abs/2508.09004</link>
      <description>arXiv:2508.09004v1 Announce Type: cross 
Abstract: A perfectly divisible cake is to be divided among a group of agents. Each agent is entitled to a share between zero and one, and these entitlements are compatible in that they sum to one. The mediator does not know the preferences of the agents, but can query the agents to make cuts and appraise slices in order to learn. We prove that if one of the entitlements is irrational, then the mediator must use a protocol that involves an arbitrarily large number of queries in order to construct an allocation that respects the entitlements regardless of preferences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09004v1</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Florian Brandl, Andrew Mackenzie</dc:creator>
    </item>
    <item>
      <title>Simultaneous Go via quantum collapse</title>
      <link>https://arxiv.org/abs/1007.3310</link>
      <description>arXiv:1007.3310v4 Announce Type: replace 
Abstract: We construct a symmetric, simultaneous, deterministic evolution game $SGo$, which is in a certain mathematical sense a symmetrization of the classical board game Go. $SGo$ is in some ways a simpler game than Go, as Komi, Ko and suicide rules are removed. On the other hand it has similar dynamics and move sensitivity, enabled by certain deterministic ``quantum state'' reduction, so that state evolution is deterministic. Using the argument of Nash, we show that $SGo$ has a mixed equilibrium strategy to draw on average.</description>
      <guid isPermaLink="false">oai:arXiv.org:1007.3310v4</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yasha Savelyev</dc:creator>
    </item>
    <item>
      <title>Adaptive Two-sided Assortment Optimization: Revenue Maximization</title>
      <link>https://arxiv.org/abs/2507.04156</link>
      <description>arXiv:2507.04156v3 Announce Type: replace 
Abstract: We study adaptive two-sided assortment optimization for revenue maximization in choice-based matching platforms. The platform has two sides of agents, an initiating side, and a responding side. The decision-maker sequentially selects agents from the initiating side, shows each an assortment of agents from the responding side, and observes their choices. After processing all initiating agents, the responding agents are shown assortments and make their selections. A match occurs when two agents mutually select each other, generating pair-dependent revenue. Choices follow Multinomial Logit (MNL) models. This setting generalizes prior work focused on maximizing the number of matches under submodular demand assumptions, which do not hold in our revenue-maximization context. Our main contribution is the design of polynomial-time approximation algorithms with constant-factor guarantees. In particular, for general pairwise revenues, we develop a randomized algorithm that achieves a $(\frac{1}{2} - \epsilon)$-approximation in expectation for any $\epsilon &gt; 0$. The algorithm is static and provides guarantees under various agent arrival settings, including fixed order, simultaneous processing, and adaptive selection. When revenues are uniform across all pairs involving any given responding-side agent, the guarantee improves to $(1 - \frac{1}{e} - \epsilon)$. In structural settings where responding-side agents share a common revenue-based ranking, we design a simpler adaptive deterministic algorithm achieving a $\frac{1}{2}$-approximation. Our approach leverages novel linear programming relaxations, correlation gap arguments, and structural properties of the revenue functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.04156v3</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammadreza Ahmadnejadsaein, Omar El Housni</dc:creator>
    </item>
    <item>
      <title>Algorithmic Delegated Choice: An Annotated Reading List</title>
      <link>https://arxiv.org/abs/2508.06562</link>
      <description>arXiv:2508.06562v2 Announce Type: replace 
Abstract: The problem of delegated choice has been of long interest in economics and recently on computer science. We overview a list of papers on delegated choice problem, from classic works to recent papers with algorithmic perspectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.06562v2</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <category>econ.TH</category>
      <pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammad T. Hajiaghayi, Suho Shin</dc:creator>
    </item>
    <item>
      <title>Finite-Sample Guarantees for Learning Dynamics in Zero-Sum Polymatrix Games</title>
      <link>https://arxiv.org/abs/2407.20128</link>
      <description>arXiv:2407.20128v3 Announce Type: replace-cross 
Abstract: We study best-response type learning dynamics for zero-sum polymatrix games under two information settings. The two settings are distinguished by the type of information that each player has about the game and their opponents' strategy. The first setting is the full information case, in which each player knows their own and their opponents' payoff matrices and observes everyone's mixed strategies. The second setting is the minimal information case, where players do not observe their opponents' strategies and are not aware of any payoff matrices (instead they only observe their realized payoffs). For this setting, also known as the radically uncoupled case in the learning in games literature, we study a two-timescale learning dynamics that combine smoothed best-response type updates for strategy estimates with a TD-learning update to estimate a local payoff function. For these dynamics, without additional exploration, we provide polynomial-time finite-sample guarantees for convergence to an $\epsilon$-Nash equilibrium.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.20128v3</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <category>stat.ML</category>
      <pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fathima Zarin Faizal, Asuman Ozdaglar, Martin J. Wainwright</dc:creator>
    </item>
    <item>
      <title>TTC Domains</title>
      <link>https://arxiv.org/abs/2501.15422</link>
      <description>arXiv:2501.15422v3 Announce Type: replace-cross 
Abstract: We study the object reallocation problem under strict preferences. On the unrestricted domain, Ekici (2024) showed that the Top Trading Cycles (TTC) mechanism is the unique mechanism that is individually rational, pair efficient, and strategyproof. We introduce a richness property on preference domains -- the top-two condition -- and show that this characterization extends to all domains satisfying it. The condition requires that within any subset of objects, if two objects can each be most-preferred, they can also be ranked as the top two (in either order). We further show that almost all domains failing the top-two condition for a triple or quadruple of objects admit non-TTC mechanisms satisfying the axioms. These results unify prior findings on specific domains, demonstrate the robustness of Ekici (2024) characterization, and suggest a minimal richness requirement that may underlie it.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.15422v3</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sumit Goel, Yuki Tamura</dc:creator>
    </item>
    <item>
      <title>Alternates, Assemble! Selecting Optimal Alternates for Citizens' Assemblies</title>
      <link>https://arxiv.org/abs/2506.15716</link>
      <description>arXiv:2506.15716v2 Announce Type: replace-cross 
Abstract: Citizens' assemblies are an increasingly influential form of deliberative democracy, where randomly selected people discuss policy questions. The legitimacy of these assemblies hinges on their representation of the broader population, but participant dropout often leads to an unbalanced composition. In practice, dropouts are replaced by preselected alternates, but existing methods do not address how to choose these alternates. To address this gap, we introduce an optimization framework for alternate selection. Our algorithmic approach, which leverages learning-theoretic machinery, estimates dropout probabilities using historical data and selects alternates to minimize expected misrepresentation. Our theoretical bounds provide guarantees on sample complexity (with implications for computational efficiency) and on loss due to dropout probability mis-estimation. Empirical evaluation using real-world data demonstrates that, compared to the status quo, our method significantly improves representation while requiring fewer alternates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.15716v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Angelos Assos, Carmel Baharav, Bailey Flanigan, Ariel Procaccia</dc:creator>
    </item>
    <item>
      <title>Frequency Point Game Environment for UAVs via Expert Knowledge and Large Language Model</title>
      <link>https://arxiv.org/abs/2508.02757</link>
      <description>arXiv:2508.02757v2 Announce Type: replace-cross 
Abstract: Unmanned Aerial Vehicles (UAVs) have made significant advancements in communication stability and security through techniques such as frequency hopping, signal spreading, and adaptive interference suppression. However, challenges remain in modeling spectrum competition, integrating expert knowledge, and predicting opponent behavior. To address these issues, we propose UAV-FPG (Unmanned Aerial Vehicle - Frequency Point Game), a game-theoretic environment model that simulates the dynamic interaction between interference and anti-interference strategies of opponent and ally UAVs in communication frequency bands. The model incorporates a prior expert knowledge base to optimize frequency selection and employs large language models for path planning, simulating a "strong adversary". Experimental results highlight the effectiveness of integrating the expert knowledge base and the large language model, with the latter significantly improving path planning in dynamic scenarios through iterative interactions, outperforming fixed-path strategies. UAV-FPG provides a robust platform for advancing anti-jamming strategies and intelligent decision-making in UAV communication systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02757v2</guid>
      <category>cs.MA</category>
      <category>cs.GT</category>
      <category>cs.RO</category>
      <pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jingpu Yang, Hang Zhang, Fengxian Ji, Yufeng Wang, Mingjie Wang, Yizhe Luo, Wenrui Ding</dc:creator>
    </item>
  </channel>
</rss>
