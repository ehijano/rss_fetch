<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.LO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.LO</link>
    <description>cs.LO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.LO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 11 Dec 2025 05:00:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 11 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A Modular Lean 4 Framework for Confluence and Strong Normalization of Lambda Calculi with Products and Sums</title>
      <link>https://arxiv.org/abs/2512.09280</link>
      <description>arXiv:2512.09280v1 Announce Type: new 
Abstract: We present Metatheory, a comprehensive library for programming language foundations in Lean 4. The library features a modular framework for proving confluence of abstract rewriting systems using three classical proof techniques: the diamond property, Newmans lemma, and the Hindley-Rosen lemma. These are instantiated across six case studies including untyped lambda calculus, combinatory logic, term rewriting, simply typed lambda calculus, and STLC with products and sums. All theorems are fully mechanized with zero axioms or sorry statements. We provide complete proofs of de Bruijn substitution infrastructure and demonstrate strong normalization via logical relations. To our knowledge, this is the first comprehensive confluence and normalization framework for Lean 4.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.09280v1</guid>
      <category>cs.LO</category>
      <pubDate>Thu, 11 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arthur Ramos, Anjolina Oliveira, Ruy de Queiroz, Tiago de Veras</dc:creator>
    </item>
    <item>
      <title>Nominal Type Theory by Nullary Internal Parametricity</title>
      <link>https://arxiv.org/abs/2512.09464</link>
      <description>arXiv:2512.09464v1 Announce Type: new 
Abstract: There are many ways to represent the syntax of a language with binders. In particular, nominal frameworks are metalanguages that feature (among others) name abstraction types, which can be used to specify the type of binders. The resulting syntax representation (nominal data types) makes alpha-equivalent terms equal, and features a name-invariant induction principle. It is known that name abstraction types can be presented either as existential or universal quantification on names. On the one hand, nominal frameworks use the existential presentation for practical reasoning since the user is allowed to match on a name-term pattern where the name is bound in the term. However inference rules for existential name abstraction are cumbersome to specify/implement because they must keep track of information about free and bound names at the type level. On the other hand, universal name abstractions are easier to specify since they are treated not as pairs, but as functions consuming fresh names. Yet the ability to pattern match on such functions is seemingly lost. In this work we show that this ability and others are recovered in a type theory consisting of (1) nullary ($0$-ary) internally parametric type theory (nullary PTT) (2) a type of names and a novel name induction principle (3) nominal data types. This extension of nullary PTT can act as a legitimate nominal framework. Indeed it has universal name abstractions, nominal pattern matching, a freshness type former, name swapping and local-scope operations and (non primitive) existential name abstractions. We illustrate how term-relevant nullary parametricity is used to recover nominal pattern matching. Our main example involves synthetic Kripke parametricity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.09464v1</guid>
      <category>cs.LO</category>
      <pubDate>Thu, 11 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Antoine Van Muylder, Andreas Nuyts, Dominique Devriese</dc:creator>
    </item>
    <item>
      <title>Two-Variable Logic for Hierarchically Partitioned and Ordered Data</title>
      <link>https://arxiv.org/abs/2512.09508</link>
      <description>arXiv:2512.09508v1 Announce Type: new 
Abstract: We study Two-Variable First-Order Logic, FO2, under semantic constraints that model hierarchically structured data. Our first logic extends FO2 with a linear order &lt; and a chain of increasingly coarser equivalence relations E_1, E_2, ... . We show that its finite satisfiability problem is NExpTime-complete. We also demonstrate that a weaker variant of this logic without the linear order enjoys the exponential model property. Our second logic extends FO2 with a chain of nested total preorders. We prove that its finite satisfiability problem is also NExpTime-complete.However, we show that the complexity increases to ExpSpace-complete once access to the successor relations of the preorders is allowed. Our last result is the undecidability of FO2 with two independent chains of nested equivalence relations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.09508v1</guid>
      <category>cs.LO</category>
      <pubDate>Thu, 11 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Oskar Fiuk, Emanuel Kieronski, Vincent Michielini</dc:creator>
    </item>
    <item>
      <title>Towards Language Model Guided TLA+ Proof Automation</title>
      <link>https://arxiv.org/abs/2512.09758</link>
      <description>arXiv:2512.09758v1 Announce Type: new 
Abstract: Formal theorem proving with TLA+ provides rigorous guarantees for system specifications, but constructing proofs requires substantial expertise and effort. While large language models have shown promise in automating proofs for tactic-based theorem provers like Lean, applying these approaches directly to TLA+ faces significant challenges due to the unique hierarchical proof structure of the TLA+ proof system. We present a prompt-based approach that leverages LLMs to guide hierarchical decomposition of complex proof obligations into simpler sub-claims, while relying on symbolic provers for verification. Our key insight is to constrain LLMs to generate normalized claim decompositions rather than complete proofs, significantly reducing syntax errors. We also introduce a benchmark suite of 119 theorems adapted from (1) established mathematical collections and (2) inductive proofs of distributed protocols. Our approach consistently outperforms baseline methods across the benchmark suite.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.09758v1</guid>
      <category>cs.LO</category>
      <pubDate>Thu, 11 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuhao Zhou, Stavros Tripakis</dc:creator>
    </item>
    <item>
      <title>Bayesian Networks, Markov Networks, Moralisation, Triangulation: a Categorical Perspective</title>
      <link>https://arxiv.org/abs/2512.09908</link>
      <description>arXiv:2512.09908v1 Announce Type: cross 
Abstract: Moralisation and Triangulation are transformations allowing to switch between different ways of factoring a probability distribution into a graphical model. Moralisation allows to view a Bayesian network (a directed model) as a Markov network (an undirected model), whereas triangulation addresses the opposite direction. We present a categorical framework where these transformations are modelled as functors between a category of Bayesian networks and one of Markov networks. The two kinds of network (the objects of these categories) are themselves represented as functors from a `syntax' domain to a `semantics' codomain. Notably, moralisation and triangulation can be defined inductively on such syntax via functor pre-composition. Moreover, while moralisation is fully syntactic, triangulation relies on semantics. This leads to a discussion of the variable elimination algorithm, reinterpreted here as a functor in its own right, that splits the triangulation procedure in two: one purely syntactic, the other purely semantic. This approach introduces a functorial perspective into the theory of probabilistic graphical models, which highlights the distinctions between syntactic and semantic modifications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.09908v1</guid>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <category>math.CT</category>
      <pubDate>Thu, 11 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Antonio Lorenzin, Fabio Zanasi</dc:creator>
    </item>
    <item>
      <title>A Unified Formal Theory on the Logical Limits of Symbol Grounding</title>
      <link>https://arxiv.org/abs/2509.20409</link>
      <description>arXiv:2509.20409v4 Announce Type: replace 
Abstract: This paper synthesizes a series of formal proofs to construct a unified theory on the logical limits of the Symbol Grounding Problem. We distinguish between internal meaning (sense), which formal systems can possess via axioms, and external grounding (reference), which is a necessary condition for connecting symbols to the world. We demonstrate through a four-stage argument that meaningful grounding within a formal system must arise from a process that is external, dynamic, and non-fixed algorithmic. First, we show that for a purely symbolic system, the impossibility of grounding is a direct consequence of its definition. Second, we extend this limitation to systems with any finite, static set of pre-established meanings (Semantic Axioms). By formally modeling the computationalist hypothesis-which equates grounding with internal derivation-we prove via G\"odelian arguments that such systems cannot consistently and completely define a "groundability predicate" for all truths. Third, we demonstrate that the "grounding act" for emergent meanings cannot be inferred from internal rules but requires an axiomatic, meta-level update. Drawing on Turing's concept of Oracle Machines and Piccinini's analysis of the mathematical objection, we identify this update as physical transduction. Finally, we prove that this process cannot be simulated by a fixed judgment algorithm, validating the logical necessity of embodied interaction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.20409v4</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <pubDate>Thu, 11 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhangchi Liu</dc:creator>
    </item>
    <item>
      <title>Towards a theory of natural directed paths</title>
      <link>https://arxiv.org/abs/2306.02792</link>
      <description>arXiv:2306.02792v4 Announce Type: replace-cross 
Abstract: We introduce the abstract setting of presheaf category on a thick category of cubes. Precubical sets, symmetric transverse sets, symmetric precubical sets and the new category of (non-symmetric) transverse sets are examples of this structure. All these presheaf categories share the same metric and homotopical properties from a directed homotopy point of view. This enables us to extend Raussen's notion of natural $d$-path for each of them. Finally, we adapt Ziemia\'{n}ski's notion of cube chain to this abstract setting and we prove that it has the expected behavior on precubical sets. As an application, we verify that the formalization of the parallel composition with synchronization of process algebra using the coskeleton functor of the category of symmetric transverse sets has a category of cube chains with the correct homotopy type.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.02792v4</guid>
      <category>math.CT</category>
      <category>cs.LO</category>
      <category>math.AT</category>
      <pubDate>Thu, 11 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Philippe Gaucher</dc:creator>
    </item>
    <item>
      <title>Ineffectiveness for Search and Undecidability of PCSP Meta-Problems</title>
      <link>https://arxiv.org/abs/2504.04639</link>
      <description>arXiv:2504.04639v3 Announce Type: replace-cross 
Abstract: It is an open question whether the search and decision versions of promise CSPs are equivalent. Most known algorithms for PCSPs solve only their \emph{decision} variant, and it is unknown whether they can be adapted to solve \emph{search} as well. The main approaches, called BLP, AIP and BLP+AIP, handle a PCSP by finding a solution to a relaxation of some integer program. We prove that rounding those solutions to a proper search certificate can be as hard as any problem in the class TFNP. In other words, these algorithms are ineffective for search. Building on the algebraic approach to PCSPs, we find sufficient conditions that imply ineffectiveness for search. Our tools are tailored to algorithms that are characterized by minions in a suitable way, and can also be used to prove undecidability results for meta-problems. This way, we show that the families of templates solvable via BLP, AIP, and BLP+AIP are undecidable.
  Using the same techniques we also analyze several algebraic conditions that are known to guarantee the tractability of finite-template CSPs. We prove that several meta-problems related to cyclic polymorphims and WNUs are undecidable for PCSPs. In particular, there is no algorithm deciding whether a finite PCSP template (1) admits cyclic a polymorphism, (2) admits a WNU.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04639v3</guid>
      <category>cs.CC</category>
      <category>cs.CL</category>
      <category>cs.DS</category>
      <category>cs.LO</category>
      <pubDate>Thu, 11 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alberto Larrauri</dc:creator>
    </item>
    <item>
      <title>A Note on the Parameterised Complexity of Coverability in Vector Addition Systems</title>
      <link>https://arxiv.org/abs/2511.19212</link>
      <description>arXiv:2511.19212v2 Announce Type: replace-cross 
Abstract: We investigate the parameterised complexity of the classic coverability problem for vector addition systems (VAS): given a finite set of vectors $V \subseteq\mathbb{Z}^d$, an initial configuration $s\in\mathbb{N}^d$, and a target configuration $t\in\mathbb{N}^d$, decide whether starting from $s$, one can iteratively add vectors from $V$ to ultimately arrive at a configuration that is larger than or equal to $t$ on every coordinate, while not observing any negative value on any coordinate along the way. We consider two natural parameters for the problem: the dimension $d$ and the size of $V$, defined as the total bitsize of its encoding. We present several results charting the complexity of those two parameterisations, among which the highlight is that coverability for VAS parameterised by the dimension and with all the numbers in the input encoded in unary is complete for the class XNL under PL-reductions. We also discuss open problems in the topic, most notably the question about fixed-parameter tractability for the parameterisation by the size of $V$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.19212v2</guid>
      <category>cs.CC</category>
      <category>cs.LO</category>
      <pubDate>Thu, 11 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Micha{\l} Pilipczuk, Sylvain Schmitz, Henry Sinclair-Banks</dc:creator>
    </item>
    <item>
      <title>Adversarial Barrier in Uniform Class Separation</title>
      <link>https://arxiv.org/abs/2512.08149</link>
      <description>arXiv:2512.08149v2 Announce Type: replace-cross 
Abstract: We identify a strong structural obstruction to Uniform Separation in constructive arithmetic. The mechanism is independent of semantic content; it emerges whenever two distinct evaluator predicates are sustained in parallel and inference remains uniformly representable in an extension of HA. Under these conditions, any putative Uniform Class Separation principle becomes a distinguished instance of a fixed point construction. The resulting limitation is stricter in scope than classical separation barriers (Baker; Rudich; Aaronson et al.) insofar as it constrains the logical form of uniform separation within HA, rather than limiting particular relativizing, naturalizing, or algebrizing techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.08149v2</guid>
      <category>math.LO</category>
      <category>cs.CC</category>
      <category>cs.LO</category>
      <pubDate>Thu, 11 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Milan Rosko</dc:creator>
    </item>
  </channel>
</rss>
