<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.ST updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.ST</link>
    <description>math.ST updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.ST" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 20 Aug 2024 02:34:00 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 19 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Sampling effects on Lasso estimation of drift functions in high-dimensional diffusion processes</title>
      <link>https://arxiv.org/abs/2408.08638</link>
      <description>arXiv:2408.08638v1 Announce Type: new 
Abstract: In this paper, we address high-dimensional parametric estimation of the drift function in diffusion models, specifically focusing on a $d$-dimensional ergodic diffusion process observed at discrete time points. Assuming sparsity of the parameter vector, we examine the statistical behavior of the Lasso estimator for the unknown parameter. Our primary contribution is the proof of an oracle inequality for the Lasso estimator, which holds on the intersection of three specific sets defined for our analysis. We carefully control the probability of these sets, tackling the central challenge of our study. This approach allows us to derive error bounds for the $l_1$ and $l_2$ norms, assessing the performance of the proposed Lasso estimator. Our results demonstrate that, under certain conditions, the discretization error becomes negligible, enabling us to achieve the same optimal rate of convergence as if the continuous trajectory of the process were observed. We validate our theoretical findings through numerical experiments, which show that the Lasso estimator significantly outperforms the maximum likelihood estimator (MLE) in terms of support recovery.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08638v1</guid>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chiara Amorino, Francisco Pina, Mark Podolskij</dc:creator>
    </item>
    <item>
      <title>Predictive performance of power posteriors</title>
      <link>https://arxiv.org/abs/2408.08806</link>
      <description>arXiv:2408.08806v1 Announce Type: new 
Abstract: We analyse the impact of using tempered likelihoods in the production of posterior predictions. Our findings reveal that once the sample size is at least moderately large and the temperature is not too small, then likelihood tempering has virtually no impact on the resulting posterior predictions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08806v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yann McLatchie, Edwin Fong, David T. Frazier, Jeremias Knoblauch</dc:creator>
    </item>
    <item>
      <title>Distributed Estimation and Inference for Semi-parametric Binary Response Models</title>
      <link>https://arxiv.org/abs/2210.08393</link>
      <description>arXiv:2210.08393v4 Announce Type: replace 
Abstract: The development of modern technology has enabled data collection of unprecedented size, which poses new challenges to many statistical estimation and inference problems. This paper studies the maximum score estimator of a semi-parametric binary choice model under a distributed computing environment without pre-specifying the noise distribution. An intuitive divide-and-conquer estimator is computationally expensive and restricted by a non-regular constraint on the number of machines, due to the highly non-smooth nature of the objective function. We propose (1) a one-shot divide-and-conquer estimator after smoothing the objective to relax the constraint, and (2) a multi-round estimator to completely remove the constraint via iterative smoothing. We specify an adaptive choice of kernel smoother with a sequentially shrinking bandwidth to achieve the superlinear improvement of the optimization error over the multiple iterations. The improved statistical accuracy per iteration is derived, and a quadratic convergence up to the optimal statistical error rate is established. We further provide two generalizations to handle the heterogeneity of datasets and high-dimensional problems where the parameter of interest is sparse.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.08393v4</guid>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xi Chen, Wenbo Jing, Weidong Liu, Yichen Zhang</dc:creator>
    </item>
    <item>
      <title>Causal Inference on Process Graphs, Part I: The Structural Equation Process Representation</title>
      <link>https://arxiv.org/abs/2305.11561</link>
      <description>arXiv:2305.11561v3 Announce Type: replace 
Abstract: When dealing with time series data, causal inference methods often employ structural vector autoregressive (SVAR) processes to model time-evolving random systems. In this work, we rephrase recursive SVAR processes with possible latent component processes as a linear Structural Causal Model (SCM) of stochastic processes on a simple causal graph, the process graph, that models every process as a single node. Using this reformulation, we generalise Wright's well-known path-rule for linear Gaussian SCMs to the newly introduced process SCMs and we express the auto-covariance sequence of an SVAR process by means of a generalised trek-rule. Employing the Fourier-Transformation, we derive compact expressions for causal effects in the frequency domain that allow us to efficiently visualise the causal interactions in a multivariate SVAR process. Finally, we observe that the process graph can be used to formulate graphical criteria for identifying causal effects and to derive algebraic relations with which these frequency domain causal effects can be recovered from the observed spectral density.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.11561v3</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicolas-Domenic Reiter, Andreas Gerhardus, Jonas Wahl, Jakob Runge</dc:creator>
    </item>
    <item>
      <title>Basic properties of generalized $\psi$-estimators</title>
      <link>https://arxiv.org/abs/2401.16127</link>
      <description>arXiv:2401.16127v2 Announce Type: replace 
Abstract: We establish several properties of (weighted) generalized $\psi$-estimators introduced by Barczy and P\'ales in 2022: mean-type, monotonicity and sensitivity properties, bisymmetry-type inequality and some asymptotic and continuity properties as well. We also illustrate these properties by providing several examples including statistical ones as well.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.16127v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matyas Barczy, Zsolt P\'ales</dc:creator>
    </item>
    <item>
      <title>Finite sample expansions and risk bounds in high-dimensional SLS models</title>
      <link>https://arxiv.org/abs/2404.14227</link>
      <description>arXiv:2404.14227v2 Announce Type: replace 
Abstract: This note extends the results of classical parametric statistics like Fisher and Wilks theorem to modern setups with a high or infinite parameter dimension, limited sample size, and possible model misspecification. We consider a special class of stochastically linear smooth (SLS) models satisfying three major conditions: the stochastic component of the log-likelihood is linear in the model parameter and the expected log-likelihood is a smooth and concave function. For the penalized maximum likelihood estimators (pMLE), we establish three types of results: (1) concentration in a small vicinity of the ``truth''; (2) Fisher and Wilks expansions; (3) risk bounds. In all results, the remainder is given explicitly and can be evaluated in terms of the effective sample size and effective parameter dimension which allows us to identify the so-called \emph{critical parameter dimension}. The results are also dimension and coordinate-free. The obtained finite sample expansions are of special interest because they can be used not only for obtaining the risk bounds but also for inference, studying the asymptotic distribution, analysis of resampling procedures, etc. The main tool for all these expansions is the so-called ``basic lemma'' about linearly perturbed optimization. Despite their generality, all the presented bounds are nearly sharp and the classical asymptotic results can be obtained as simple corollaries. Our results indicate that the use of advanced fourth-order expansions allows to relax the critical dimension condition $ \mathbb{p}^{3} \ll n $ from Spokoiny (2023a) to $ \mathbb{p}^{3/2} \ll n $. Examples for classical models like logistic regression, log-density and precision matrix estimation illustrate the applicability of general results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14227v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vladimir Spokoiny</dc:creator>
    </item>
    <item>
      <title>Causal Inference on Process Graphs, Part II: Causal Structure and Effect Identification</title>
      <link>https://arxiv.org/abs/2406.17422</link>
      <description>arXiv:2406.17422v2 Announce Type: replace 
Abstract: A structural vector autoregressive (SVAR) process is a linear causal model for variables that evolve over a discrete set of time points and between which there may be lagged and instantaneous effects. The qualitative causal structure of an SVAR process can be represented by its finite and directed process graph, in which a directed link connects two processes whenever there is a lagged or instantaneous effect between them. At the process graph level, the causal structure of SVAR processes is compactly parameterised in the frequency domain. In this paper, we consider the problem of causal discovery and causal effect estimation from the spectral density, the frequency domain analogue of the auto covariance, of the SVAR process. Causal discovery concerns the recovery of the process graph and causal effect estimation concerns the identification and estimation of causal effects in the frequency domain.
  We show that information about the process graph, in terms of $d$- and $t$-separation statements, can be identified by verifying algebraic constraints on the spectral density. Furthermore, we introduce a notion of rational identifiability for frequency causal effects that may be confounded by exogenous latent processes, and show that the recent graphical latent factor half-trek criterion can be used on the process graph to assess whether a given (confounded) effect can be identified by rational operations on the entries of the spectral density.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17422v2</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicolas-Domenic Reiter, Jonas Wahl, Andreas Gerhardus, Jakob Runge</dc:creator>
    </item>
    <item>
      <title>On the impossibility of detecting a late change-point in the preferential attachment random graph model</title>
      <link>https://arxiv.org/abs/2407.18685</link>
      <description>arXiv:2407.18685v2 Announce Type: replace 
Abstract: We consider the problem of late change-point detection under the preferential attachment random graph model with time dependent attachment function. This can be formulated as a hypothesis testing problem where the null hypothesis corresponds to a preferential attachment model with a constant affine attachment parameter $\delta_0$ and the alternative corresponds to a preferential attachment model where the affine attachment parameter changes from $\delta_0$ to $\delta_1$ at a time $\tau_n = n - \Delta_n$ where $0\leq \Delta_n \leq n$ and $n$ is the size of the graph. It was conjectured in Bet et al. that when observing only the unlabeled graph, detection of the change is not possible for $\Delta_n = o(n^{1/2})$. In this work, we make a step towards proving the conjecture by proving the impossibility of detecting the change when $\Delta_n = o(n^{1/3})$. We also study change-point detection in the case where the labeled graph is observed and show that change-point detection is possible if and only if $\Delta_n \to \infty$, thereby exhibiting a strong difference between the two settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18685v2</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ibrahim Kaddouri, Zacharie Naulet, \'Elisabeth Gassiat</dc:creator>
    </item>
    <item>
      <title>Non-standard boundary behaviour in binary mixture models</title>
      <link>https://arxiv.org/abs/2407.20162</link>
      <description>arXiv:2407.20162v2 Announce Type: replace 
Abstract: Consider a binary mixture model of the form $F_\theta = (1-\theta)F_0 + \theta F_1$, where $F_0$ is standard Gaussian and $F_1$ is a completely specified heavy-tailed distribution with the same support. For a sample of $n$ independent and identically distributed values $X_i \sim F_\theta$, the maximum likelihood estimator $\hat\theta_n$ is asymptotically normal provided that $0 &lt; \theta &lt; 1$ is an interior point. This paper investigates the large-sample behaviour for boundary points, which is entirely different and strikingly asymmetric for $\theta=0$ and $\theta=1$. The reason for the asymmetry has to do with typical choices such that $F_0$ is an extreme boundary point and $F_1$ is usually not extreme. On the right boundary, well known results on boundary parameter problems are recovered, giving $\lim \mathbb{P}_1(\hat\theta_n &lt; 1)=1/2$. On the left boundary, $\lim\mathbb{P}_0(\hat\theta_n &gt; 0)=1-1/\alpha$, where $1\leq \alpha \leq 2$ indexes the domain of attraction of the density ratio $f_1(X)/f_0(X)$ when $X\sim F_0$. For $\alpha=1$, which is the most important case in practice, we show how the tail behaviour of $F_1$ governs the rate at which $\mathbb{P}_0(\hat\theta_n &gt; 0)$ tends to zero. A new limit theorem for the joint distribution of the sample maximum and sample mean conditional on positivity establishes multiple inferential anomalies. Most notably, given $\hat\theta_n &gt; 0$, the likelihood ratio statistic has a conditional null limit distribution $G\neq\chi^2_1$ determined by the joint limit theorem. We show through this route that no advantage is gained by extending the single distribution $F_1$ to the nonparametric composite mixture generated by the same tail-equivalence class.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.20162v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Heather Battey, Peter McCullagh, Daniel Xiang</dc:creator>
    </item>
    <item>
      <title>Rate of convergence of the smoothed empirical Wasserstein distance</title>
      <link>https://arxiv.org/abs/2205.02128</link>
      <description>arXiv:2205.02128v3 Announce Type: replace-cross 
Abstract: Consider an empirical measure $\mathbb{P}_n$ induced by $n$ iid samples from a $d$-dimensional $K$-subgaussian distribution $\mathbb{P}$ and let $\gamma = N(0,\sigma^2 I_d)$ be the isotropic Gaussian measure. We study the speed of convergence of the smoothed Wasserstein distance $W_2(\mathbb{P}_n * \gamma, \mathbb{P}*\gamma) = n^{-\alpha + o(1)}$ with $*$ being the convolution of measures. For $K&lt;\sigma$ and in any dimension $d\ge 1$ we show that $\alpha = {1\over2}$. For $K&gt;\sigma$ in dimension $d=1$ we show that the rate is slower and is given by $\alpha = {(\sigma^2 + K^2)^2\over 4 (\sigma^4 + K^4)} &lt; 1/2$. This resolves several open problems in [GGNWP20], and in particular precisely identifies the amount of smoothing $\sigma$ needed to obtain a parametric rate. In addition, for any $d$-dimensional $K$-subgaussian distribution $\mathbb{P}$, we also establish that $D_{KL}(\mathbb{P}_n * \gamma \|\mathbb{P}*\gamma)$ has rate $O(1/n)$ for $K&lt;\sigma$ but only slows down to $O({(\log n)^{d+1}\over n})$ for $K&gt;\sigma$. The surprising difference of the behavior of $W_2^2$ and KL implies the failure of $T_{2}$-transportation inequality when $\sigma &lt; K$. Consequently, it follows that for $K&gt;\sigma$ the log-Sobolev inequality (LSI) for the Gaussian mixture $\mathbb{P} * N(0, \sigma^{2})$ cannot hold. This closes an open problem in [WW+16], who established the LSI under the condition $K&lt;\sigma$ and asked if their bound can be improved.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.02128v3</guid>
      <category>math.PR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Adam Block, Zeyu Jia, Yury Polyanskiy, Alexander Rakhlin</dc:creator>
    </item>
    <item>
      <title>Anytime-valid off-policy inference for contextual bandits</title>
      <link>https://arxiv.org/abs/2210.10768</link>
      <description>arXiv:2210.10768v3 Announce Type: replace-cross 
Abstract: Contextual bandit algorithms are ubiquitous tools for active sequential experimentation in healthcare and the tech industry. They involve online learning algorithms that adaptively learn policies over time to map observed contexts $X_t$ to actions $A_t$ in an attempt to maximize stochastic rewards $R_t$. This adaptivity raises interesting but hard statistical inference questions, especially counterfactual ones: for example, it is often of interest to estimate the properties of a hypothetical policy that is different from the logging policy that was used to collect the data -- a problem known as ``off-policy evaluation'' (OPE). Using modern martingale techniques, we present a comprehensive framework for OPE inference that relax unnecessary conditions made in some past works, significantly improving on them both theoretically and empirically. Importantly, our methods can be employed while the original experiment is still running (that is, not necessarily post-hoc), when the logging policy may be itself changing (due to learning), and even if the context distributions are a highly dependent time-series (such as if they are drifting over time). More concretely, we derive confidence sequences for various functionals of interest in OPE. These include doubly robust ones for time-varying off-policy mean reward values, but also confidence bands for the entire cumulative distribution function of the off-policy reward distribution. All of our methods (a) are valid at arbitrary stopping times (b) only make nonparametric assumptions, (c) do not require importance weights to be uniformly bounded and if they are, we do not need to know these bounds, and (d) adapt to the empirical variance of our estimators. In summary, our methods enable anytime-valid off-policy inference using adaptively collected contextual bandit data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.10768v3</guid>
      <category>stat.ME</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ian Waudby-Smith, Lili Wu, Aaditya Ramdas, Nikos Karampatziakis, Paul Mineiro</dc:creator>
    </item>
    <item>
      <title>Characterizing Signalling: Connections between Causal Inference and Space-time Geometry</title>
      <link>https://arxiv.org/abs/2403.00916</link>
      <description>arXiv:2403.00916v2 Announce Type: replace-cross 
Abstract: Causality is pivotal to our understanding of the world, presenting itself in different forms: information-theoretic and relativistic, the former linked to the flow of information, the latter to the structure of space-time. Leveraging a framework introduced in PRA, 106, 032204 (2022), which formally connects these two notions in general physical theories, we study their interplay. Here, information-theoretic causality is defined through a causal modelling approach. First, we improve the characterization of information-theoretic signalling as defined through so-called affects relations. Specifically, we provide conditions for identifying redundancies in different parts of such a relation, introducing techniques for causal inference in unfaithful causal models (where the observable data does not "faithfully" reflect the causal dependences). In particular, this demonstrates the possibility of causal inference using the absence of signalling between certain nodes. Second, we define an order-theoretic property called conicality, showing that it is satisfied for light cones in Minkowski space-times with $d&gt;1$ spatial dimensions but violated for $d=1$. Finally, we study the embedding of information-theoretic causal models in space-time without violating relativistic principles such as no superluminal signalling (NSS). In general, we observe that constraints imposed by NSS in a space-time and those imposed by purely information-theoretic causal inference behave differently. We then prove a correspondence between conical space-times and faithful causal models: in both cases, there emerges a parallel between these two types of constraints. This indicates a connection between informational and geometric notions of causality, and offers new insights for studying the relations between the principles of NSS and no causal loops in different space-time geometries and theories of information processing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.00916v2</guid>
      <category>gr-qc</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.ST</category>
      <category>quant-ph</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maarten Grothus, V. Vilasini</dc:creator>
    </item>
    <item>
      <title>Kernel Density Estimators in Large Dimensions</title>
      <link>https://arxiv.org/abs/2408.05807</link>
      <description>arXiv:2408.05807v2 Announce Type: replace-cross 
Abstract: This paper studies Kernel density estimation for a high-dimensional distribution $\rho(x)$. Traditional approaches have focused on the limit of large number of data points $n$ and fixed dimension $d$. We analyze instead the regime where both the number $n$ of data points $y_i$ and their dimensionality $d$ grow with a fixed ratio $\alpha=(\log n)/d$. Our study reveals three distinct statistical regimes for the kernel-based estimate of the density $\hat \rho_h^{\mathcal {D}}(x)=\frac{1}{n h^d}\sum_{i=1}^n K\left(\frac{x-y_i}{h}\right)$, depending on the bandwidth $h$: a classical regime for large bandwidth where the Central Limit Theorem (CLT) holds, which is akin to the one found in traditional approaches. Below a certain value of the bandwidth, $h_{CLT}(\alpha)$, we find that the CLT breaks down. The statistics of $\hat \rho_h^{\mathcal {D}}(x)$ for a fixed $x$ drawn from $\rho(x)$ is given by a heavy-tailed distribution (an alpha-stable distribution). In particular below a value $h_G(\alpha)$, we find that $\hat \rho_h^{\mathcal {D}}(x)$ is governed by extreme value statistics: only a few points in the database matter and give the dominant contribution to the density estimator. We provide a detailed analysis for high-dimensional multivariate Gaussian data. We show that the optimal bandwidth threshold based on Kullback-Leibler divergence lies in the new statistical regime identified in this paper. Our findings reveal limitations of classical approaches, show the relevance of these new statistical regimes, and offer new insights for Kernel density estimation in high-dimensional settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05807v2</guid>
      <category>cs.LG</category>
      <category>cond-mat.dis-nn</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giulio Biroli, Marc M\'ezard</dc:creator>
    </item>
  </channel>
</rss>
