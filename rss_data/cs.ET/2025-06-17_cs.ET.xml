<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 17 Jun 2025 04:00:42 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Machine Intelligence on Wireless Edge Networks</title>
      <link>https://arxiv.org/abs/2506.12210</link>
      <description>arXiv:2506.12210v1 Announce Type: new 
Abstract: Deep neural network (DNN) inference on power-constrained edge devices is bottlenecked by costly weight storage and data movement. We introduce MIWEN, a radio-frequency (RF) analog architecture that ``disaggregates'' memory by streaming weights wirelessly and performing classification in the analog front end of standard transceivers. By encoding weights and activations onto RF carriers and using native mixers as computation units, MIWEN eliminates local weight memory and the overhead of analog-to-digital and digital-to-analog conversion. We derive the effective number of bits of radio-frequency analog computation under thermal noise, quantify the energy--precision trade-off, and demonstrate digital-comparable MNIST accuracy at orders-of-magnitude lower energy, unlocking real-time inference on low-power, memory-free edge devices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.12210v1</guid>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sri Krishna Vadlamani, Kfir Sulimany, Zhihui Gao, Tingjun Chen, Dirk Englund</dc:creator>
    </item>
    <item>
      <title>A Novel Thermal Network Model and Electro-Thermal Coupling Study for NSFETs and CFETs Considering Thermal Crosstalk</title>
      <link>https://arxiv.org/abs/2506.12264</link>
      <description>arXiv:2506.12264v1 Announce Type: new 
Abstract: As the technology node continues to shrink, nanosheet field effect transistors (NSFETs) and complementary FETs (CFETs) become valid candidates for the 3nm and sub-nanometre nodes. However, due to the shrinking device size, self-heating and inter-device thermal crosstalk of NSFETs and CFETs become more severe. It is important to accurately calculate the self-heating and thermal crosstalk of devices and to study the electrical and thermal characteristics of logic gates, etc. In this work, a thermal network model considering the thermal crosstalk of neighboring devices is proposed, which can accurately calculate the self-heating and thermal crosstalk. The electrical and thermal characteristics of NSFETs and CFETs are compared, and it is found that CFETs have more severe self-heating and thermal crosstalk. The electro-thermal characteristics of inverters, logic gates and ring oscillators composed of NSFETs and CFETs are further investigated. Compared with NSFETs, logic gates and ring oscillators composed of CFETs are more seriously affected by self-heating and should be given extra attention. The thermal network model proposed in this paper can be further used to study the thermal optimization strategy of devices and circuits to enhance the electrical performance, achieving the design technology co-optimizations (DTCO).</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.12264v1</guid>
      <category>cs.ET</category>
      <category>cs.AR</category>
      <pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianci Miao, Qihang Zheng, Yangyang Hu, Xiaoyu Cheng, Jie Liang, Liang Chen, Aiying Guo, Jingjing Liu, Kailin Ren, Jianhua Zhang</dc:creator>
    </item>
    <item>
      <title>Spatially Consistent Air-to-Ground Channel Modeling with Probabilistic LOS/NLOS Segmentation</title>
      <link>https://arxiv.org/abs/2506.12794</link>
      <description>arXiv:2506.12794v1 Announce Type: new 
Abstract: In this paper, we present a spatially consistent A2G channel model based on probabilistic LOS/NLOS segmentation to parameterize the deterministic path loss and stochastic shadow fading model. Motivated by the limitations of existing Unmanned Aerial Vehicle (UAV) channel models that overlook spatial correlation, our approach reproduces LOS/NLOS transitions along ground user trajectories in urban environments. This model captures environment-specific obstructions by means of azimuth and elevation-dependent LOS probabilities without requiring a full detailed 3D representation of the surroundings. We validate our framework against a geometry-based simulator by evaluating it across various urban settings. The results demonstrate its accuracy and computational efficiency, enabling further realistic derivations of path loss and shadow fading models and thorough outage analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.12794v1</guid>
      <category>cs.ET</category>
      <category>eess.SP</category>
      <pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Evgenii Vinogradov, Abdul Saboor, Zhuangzhuang Cui, Aymen Fakhreddine</dc:creator>
    </item>
    <item>
      <title>Resilient-native and Intelligent NextG Systems</title>
      <link>https://arxiv.org/abs/2506.12795</link>
      <description>arXiv:2506.12795v1 Announce Type: new 
Abstract: Just like power, water and transportation systems, wireless networks are a crucial societal infrastructure. As natural and human-induced disruptions continue to grow, wireless networks must be resilient to unforeseen events, able to withstand and recover from unexpected adverse conditions, shocks, unmodeled disturbances and cascading failures. Despite its critical importance, resilience remains an elusive concept, with its mathematical foundations still underdeveloped. Unlike robustness and reliability, resilience is premised on the fact that disruptions will inevitably happen. Resilience, in terms of elasticity, focuses on the ability to bounce back to favorable states, while resilience as plasticity involves agents (or networks) that can flexibly expand their states, hypotheses and course of actions, by transforming through real-time adaptation and reconfiguration. This constant situational awareness and vigilance of adapting world models and counterfactually reasoning about potential system failures and the corresponding best responses, is a core aspect of resilience. This article seeks to first define resilience and disambiguate it from reliability and robustness, before delving into the mathematics of resilience. Finally, the article concludes by presenting nuanced metrics and discussing trade-offs tailored to the unique characteristics of network resilience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.12795v1</guid>
      <category>cs.ET</category>
      <category>cs.AI</category>
      <pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Mehdi Bennis</dc:creator>
    </item>
    <item>
      <title>Leveraging Photonic Interconnects for Scalable and Efficient Fully Homomorphic Encryption</title>
      <link>https://arxiv.org/abs/2506.12962</link>
      <description>arXiv:2506.12962v1 Announce Type: new 
Abstract: Fully Homomorphic Encryption (FHE) facilitates secure computations on encrypted data but imposes significant demands on memory bandwidth and computational power. While current FHE accelerators focus on optimizing computation, they often face bandwidth limitations that result in performance bottlenecks, particularly in memory-intensive operations. This paper presents OptoLink, a scalable photonic interconnect architecture designed to address these bandwidth and latency challenges in FHE systems. OptoLink achieves a throughput of 1.6 TB/s with 128 channels, providing 300 times the bandwidth of conventional electrical interconnects. The proposed architecture improves data throughput, scalability, and reduces latency, making it an effective solution for meeting the high memory and data transfer requirements of modern FHE accelerators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.12962v1</guid>
      <category>cs.ET</category>
      <pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Dewan Saiham, Di Wu, Sazadur Rahman</dc:creator>
    </item>
    <item>
      <title>lcpy: an open-source python package for parametric and dynamic Life Cycle Assessment and Life Cycle Costing</title>
      <link>https://arxiv.org/abs/2506.13744</link>
      <description>arXiv:2506.13744v1 Announce Type: new 
Abstract: This article describes lcpy, an open-source python package that allows for advanced parametric Life Cycle Assessment (LCA) and Life Cycle Costing (LCC) analysis. The package is designed to allow the user to model a process with a flexible, modular design based on dictionaries and lists. The modeling can consider in-time variations, uncertainty, and allows for dynamic analysis, uncertainty assessment, as well as conventional static LCA and LCC. The package is compatible with optimization and uncertainty analysis libraries as well as python packages for prospective LCA. Its goal is to allow for easy implementation of dynamic LCA and LCC and for simple integration with tools for uncertainty assessment and optimization towards a more widened implementation of advanced enviro-economic analysis. The open-source code can be found at https://github.com/spirdgk/lcpy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.13744v1</guid>
      <category>cs.ET</category>
      <pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Spiros Gkousis, Evina Katsou</dc:creator>
    </item>
    <item>
      <title>Quantum Computing and Cybersecurity in Accounting and Finance: Current and the Future Challenges and Opportunities for Securing Accounting and Finance Systems</title>
      <link>https://arxiv.org/abs/2506.12096</link>
      <description>arXiv:2506.12096v1 Announce Type: cross 
Abstract: Quantum computing is revolutionising information systems and will have a significant impact on accounting and finance, especially in the area of cybersecurity. It presents both opportunities and risks in ensuring confidentiality and protecting financial data. The purpose of this thesis is to show the application of quantum technologies in accounting cybersecurity, utilising quantum algorithms and QKD to overcome the limitations of classical computing.
  The literature review reveals the vulnerabilities of the current accounting cybersecurity to quantum attacks and the need for quantum-resistant cryptographic mechanisms. It elaborates on the risks associated with conventional encryption in the context of quantum capabilities. This study contributes to the understanding of how quantum computing can revolutionise accounting cybersecurity by enhancing quantum-resistant algorithms and utilising quantum key distribution (QKD) in accounting.
  The study employs PSALSAR systematic review methodology to ensure rigour and depth. The analysis shows that quantum computing enhances encryption techniques to superior possibilities than classical ones. Using quantum technologies in accounting minimises data breaches and unauthorised access. The study concludes that quantum-resistant algorithms and quantum key distribution (QKD) are necessary for securing the accounting and finance systems of the future.
  Keywords Quantum Computing, Cybersecurity, Accounting, Machine Learning, Artificial Intelligence, Quantum Key Distribution, Operations Management</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.12096v1</guid>
      <category>cs.CR</category>
      <category>cs.ET</category>
      <pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huma Habib Shadan (Victoria University), Sardar Islam (Victoria University)</dc:creator>
    </item>
    <item>
      <title>Component Based Quantum Machine Learning Explainability</title>
      <link>https://arxiv.org/abs/2506.12378</link>
      <description>arXiv:2506.12378v1 Announce Type: cross 
Abstract: Explainable ML algorithms are designed to provide transparency and insight into their decision-making process. Explaining how ML models come to their prediction is critical in fields such as healthcare and finance, as it provides insight into how models can help detect bias in predictions and help comply with GDPR compliance in these fields. QML leverages quantum phenomena such as entanglement and superposition, offering the potential for computational speedup and greater insights compared to classical ML. However, QML models also inherit the black-box nature of their classical counterparts, requiring the development of explainability techniques to be applied to these QML models to help understand why and how a particular output was generated.
  This paper will explore the idea of creating a modular, explainable QML framework that splits QML algorithms into their core components, such as feature maps, variational circuits (ansatz), optimizers, kernels, and quantum-classical loops. Each component will be analyzed using explainability techniques, such as ALE and SHAP, which have been adapted to analyse the different components of these QML algorithms. By combining insights from these parts, the paper aims to infer explainability to the overall QML model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.12378v1</guid>
      <category>quant-ph</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Barra White, Krishnendu Guha</dc:creator>
    </item>
    <item>
      <title>Privacy-preserving and reward-based mechanisms of proof of engagement</title>
      <link>https://arxiv.org/abs/2506.12523</link>
      <description>arXiv:2506.12523v1 Announce Type: cross 
Abstract: Proof-of-Attendance (PoA) mechanisms are typically employed to demonstrate a specific user's participation in an event, whether virtual or in-person. The goal of this study is to extend such mechanisms to broader contexts where the user wishes to digitally demonstrate her involvement in a specific activity (Proof-of-Engagement, PoE). This work explores different solutions, including DLTs as well as established technologies based on centralized systems. The main aspects we consider include the level of privacy guaranteed to users, the scope of PoA/PoE (both temporal and spatial), the transferability of the proof, and the integration with incentive mechanisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.12523v1</guid>
      <category>cs.CR</category>
      <category>cs.ET</category>
      <pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Matteo Marco Montanari, Alessandro Aldini</dc:creator>
    </item>
    <item>
      <title>Regulating Next-Generation Implantable Brain-Computer Interfaces: Recommendations for Ethical Development and Implementation</title>
      <link>https://arxiv.org/abs/2506.12540</link>
      <description>arXiv:2506.12540v1 Announce Type: cross 
Abstract: Brain-computer interfaces offer significant therapeutic opportunities for a variety of neurophysiological and neuropsychiatric disorders and may perhaps one day lead to augmenting the cognition and decision-making of the healthy brain. However, existing regulatory frameworks designed for implantable medical devices are inadequate to address the unique ethical, legal, and social risks associated with next-generation networked brain-computer interfaces. In this article, we make nine recommendations to support developers in the design of BCIs and nine recommendations to support policymakers in the application of BCIs, drawing insights from the regulatory history of IMDs and principles from AI ethics. We begin by outlining the historical development of IMDs and the regulatory milestones that have shaped their oversight. Next, we summarize similarities between IMDs and emerging implantable BCIs, identifying existing provisions for their regulation. We then use two case studies of emerging cutting-edge BCIs, the HALO and SCALO computer systems, to highlight distinctive features in the design and application of next-generation BCIs arising from contemporary chip architectures, which necessitate reevaluating regulatory approaches. We identify critical ethical considerations for these BCIs, including unique conceptions of autonomy, identity, and mental privacy. Based on these insights, we suggest potential avenues for the ethical regulation of BCIs, emphasizing the importance of interdisciplinary collaboration and proactive mitigation of potential harms. The goal is to support the responsible design and application of new BCIs, ensuring their safe and ethical integration into medical practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.12540v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <category>cs.ET</category>
      <pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Renee Sirbu, Jessica Morley, Tyler Schroder, Mariarosaria Taddeo, Raghavendra Pradyumna Pothukuchi, Muhammed Ugur, Abhishek Bhattacharjee, Luciano Floridi</dc:creator>
    </item>
    <item>
      <title>Trust-MARL: Trust-Based Multi-Agent Reinforcement Learning Framework for Cooperative On-Ramp Merging Control in Heterogeneous Traffic Flow</title>
      <link>https://arxiv.org/abs/2506.12600</link>
      <description>arXiv:2506.12600v1 Announce Type: cross 
Abstract: Intelligent transportation systems require connected and automated vehicles (CAVs) to conduct safe and efficient cooperation with human-driven vehicles (HVs) in complex real-world traffic environments. However, the inherent unpredictability of human behaviour, especially at bottlenecks such as highway on-ramp merging areas, often disrupts traffic flow and compromises system performance. To address the challenge of cooperative on-ramp merging in heterogeneous traffic environments, this study proposes a trust-based multi-agent reinforcement learning (Trust-MARL) framework. At the macro level, Trust-MARL enhances global traffic efficiency by leveraging inter-agent trust to improve bottleneck throughput and mitigate traffic shockwave through emergent group-level coordination. At the micro level, a dynamic trust mechanism is designed to enable CAVs to adjust their cooperative strategies in response to real-time behaviors and historical interactions with both HVs and other CAVs. Furthermore, a trust-triggered game-theoretic decision-making module is integrated to guide each CAV in adapting its cooperation factor and executing context-aware lane-changing decisions under safety, comfort, and efficiency constraints. An extensive set of ablation studies and comparative experiments validates the effectiveness of the proposed Trust-MARL approach, demonstrating significant improvements in safety, efficiency, comfort, and adaptability across varying CAV penetration rates and traffic densities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.12600v1</guid>
      <category>cs.MA</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.GT</category>
      <category>cs.RO</category>
      <pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jie Pan, Tianyi Wang, Christian Claudel, Jing Shi</dc:creator>
    </item>
    <item>
      <title>A Review of the Long Horizon Forecasting Problem in Time Series Analysis</title>
      <link>https://arxiv.org/abs/2506.12809</link>
      <description>arXiv:2506.12809v1 Announce Type: cross 
Abstract: The long horizon forecasting (LHF) problem has come up in the time series literature for over the last 35 years or so. This review covers aspects of LHF in this period and how deep learning has incorporated variants of trend, seasonality, fourier and wavelet transforms, misspecification bias reduction and bandpass filters while contributing using convolutions, residual connections, sparsity reduction, strided convolutions, attention masks, SSMs, normalization methods, low-rank approximations and gating mechanisms. We highlight time series decomposition techniques, input data preprocessing and dataset windowing schemes that improve performance. Multi-layer perceptron models, recurrent neural network hybrids, self-attention models that improve and/or address the performances of the LHF problem are described, with an emphasis on the feature space construction. Ablation studies are conducted over the ETTm2 dataset in the multivariate and univariate high useful load (HUFL) forecasting contexts, evaluated over the last 4 months of the dataset. The heatmaps of MSE averages per time step over test set series in the horizon show that there is a steady increase in the error proportionate to its length except with xLSTM and Triformer models and motivate LHF as an error propagation problem. The trained models are available here: https://bit.ly/LHFModelZoo</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.12809v1</guid>
      <category>cs.LG</category>
      <category>cs.ET</category>
      <category>cs.PF</category>
      <category>stat.ML</category>
      <pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Hans Krupakar, Kandappan V A</dc:creator>
    </item>
    <item>
      <title>UAV Object Detection and Positioning in a Mining Industrial Metaverse with Custom Geo-Referenced Data</title>
      <link>https://arxiv.org/abs/2506.13505</link>
      <description>arXiv:2506.13505v1 Announce Type: cross 
Abstract: The mining sector increasingly adopts digital tools to improve operational efficiency, safety, and data-driven decision-making. One of the key challenges remains the reliable acquisition of high-resolution, geo-referenced spatial information to support core activities such as extraction planning and on-site monitoring. This work presents an integrated system architecture that combines UAV-based sensing, LiDAR terrain modeling, and deep learning-based object detection to generate spatially accurate information for open-pit mining environments. The proposed pipeline includes geo-referencing, 3D reconstruction, and object localization, enabling structured spatial outputs to be integrated into an industrial digital twin platform. Unlike traditional static surveying methods, the system offers higher coverage and automation potential, with modular components suitable for deployment in real-world industrial contexts. While the current implementation operates in post-flight batch mode, it lays the foundation for real-time extensions. The system contributes to the development of AI-enhanced remote sensing in mining by demonstrating a scalable and field-validated geospatial data workflow that supports situational awareness and infrastructure safety.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.13505v1</guid>
      <category>eess.IV</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.RO</category>
      <pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vasiliki Balaska, Ioannis Tsampikos Papapetros, Katerina Maria Oikonomou, Loukas Bampis, Antonios Gasteratos</dc:creator>
    </item>
    <item>
      <title>Model Context Protocol (MCP) at First Glance: Studying the Security and Maintainability of MCP Servers</title>
      <link>https://arxiv.org/abs/2506.13538</link>
      <description>arXiv:2506.13538v1 Announce Type: cross 
Abstract: Although Foundation Models (FMs), such as GPT-4, are increasingly used in domains like finance and software engineering, reliance on textual interfaces limits these models' real-world interaction. To address this, FM providers introduced tool calling-triggering a proliferation of frameworks with distinct tool interfaces. In late 2024, Anthropic introduced the Model Context Protocol (MCP) to standardize this tool ecosystem, which has become the de facto standard with over eight million weekly SDK downloads. Despite its adoption, MCP's AI-driven, non-deterministic control flow introduces new risks to sustainability, security, and maintainability, warranting closer examination.
  Towards this end, we present the first large-scale empirical study of MCP. Using state-of-the-art health metrics and a hybrid analysis pipeline, combining a general-purpose static analysis tool with an MCP-specific scanner, we evaluate 1,899 open-source MCP servers to assess their health, security, and maintainability. Despite MCP servers demonstrating strong health metrics, we identify eight distinct vulnerabilities-only three overlapping with traditional software vulnerabilities. Additionally, 7.2% of servers contain general vulnerabilities and 5.5% exhibit MCP-specific tool poisoning. Regarding maintainability, while 66% exhibit code smells, 14.4% contain ten bug patterns overlapping prior research. These findings highlight the need for MCP-specific vulnerability detection techniques while reaffirming the value of traditional analysis and refactoring practices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.13538v1</guid>
      <category>cs.SE</category>
      <category>cs.ET</category>
      <pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammed Mehedi Hasan, Hao Li, Emad Fallahzadeh, Bram Adams, Ahmed E. Hassan</dc:creator>
    </item>
    <item>
      <title>COGNATE: Acceleration of Sparse Tensor Programs on Emerging Hardware using Transfer Learning</title>
      <link>https://arxiv.org/abs/2506.00424</link>
      <description>arXiv:2506.00424v2 Announce Type: replace-cross 
Abstract: Sparse tensor programs are essential in deep learning and graph analytics, driving the need for optimized processing. To meet this demand, specialized hardware accelerators are being developed. Optimizing these programs for accelerators is challenging for two reasons: program performance is highly sensitive to variations in sparse inputs, and early-stage accelerators rely on expensive simulators. Therefore, ML-based cost models used for optimizing such programs on general-purpose hardware are often ineffective for early-stage accelerators, as they require large datasets for proper training. To this end, we introduce COGNATE, a novel framework that leverages inexpensive data samples from general-purpose hardware (e.g., CPUs) to train cost models, followed by few-shot fine-tuning on emerging hardware. COGNATE exploits the homogeneity of input features across hardware platforms while effectively mitigating heterogeneity, enabling cost model training with just 5% of the data samples needed by accelerator-specific models to achieve comparable performance. We conduct extensive experiments to demonstrate that COGNATE outperforms existing techniques, achieving average speedups of 1.47x (up to 5.46x) for SpMM and 1.39x (up to 4.22x) for SDDMM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00424v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chamika Sudusinghe, Gerasimos Gerogiannis, Damitha Lenadora, Charles Block, Josep Torrellas, Charith Mendis</dc:creator>
    </item>
    <item>
      <title>Towards Infant Sleep-Optimized Driving: Synergizing Wearable and Vehicle Sensing in Intelligent Cruise Control</title>
      <link>https://arxiv.org/abs/2506.06459</link>
      <description>arXiv:2506.06459v2 Announce Type: replace-cross 
Abstract: Automated driving (AD) has substantially improved vehicle safety and driving comfort, but their impact on passenger well-being, particularly infant sleep, is not sufficiently studied. Sudden acceleration, abrupt braking, and sharp maneuvers can disrupt infant sleep, compromising both passenger comfort and parental convenience. To solve this problem, this paper explores the integration of reinforcement learning (RL) within AD to personalize driving behavior and optimally balance occupant comfort and travel efficiency. In particular, we propose an intelligent cruise control framework that adapts to varying driving conditions to enhance infant sleep quality by effectively synergizing wearable sensing and vehicle data. Long short-term memory (LSTM) and transformer-based neural networks are integrated with RL to model the relationship between driving behavior and infant sleep quality under diverse traffic and road conditions. Based on the sleep quality indicators from the wearable sensors, driving action data from vehicle controllers, and map data from map applications, the model dynamically computes the optimal driving aggressiveness level, which is subsequently translated into specific AD control strategies, e.g., the magnitude and frequency of acceleration, lane change, and overtaking. Simulation results demonstrate that the proposed solution significantly improves infant sleep quality compared to baseline methods, while preserving desirable travel efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.06459v2</guid>
      <category>cs.LG</category>
      <category>cs.ET</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruitao Chen, Mozhang Guo, Jinge Li</dc:creator>
    </item>
    <item>
      <title>Towards Full-Scenario Safety Evaluation of Automated Vehicles: A Volume-Based Method</title>
      <link>https://arxiv.org/abs/2506.09182</link>
      <description>arXiv:2506.09182v2 Announce Type: replace-cross 
Abstract: With the rapid development of automated vehicles (AVs) in recent years, commercially available AVs are increasingly demonstrating high-level automation capabilities. However, most existing AV safety evaluation methods are primarily designed for simple maneuvers such as car-following and lane-changing. While suitable for basic tests, these methods are insufficient for assessing high-level automation functions deployed in more complex environments. First, these methods typically use crash rate as the evaluation metric, whose accuracy heavily depends on the quality and completeness of naturalistic driving environment data used to estimate scenario probabilities. Such data is often difficult and expensive to collect. Second, when applied to diverse scenarios, these methods suffer from the curse of dimensionality, making large-scale evaluation computationally intractable. To address these challenges, this paper proposes a novel framework for full-scenario AV safety evaluation. A unified model is first introduced to standardize the representation of diverse driving scenarios. This modeling approach constrains the dimension of most scenarios to a regular highway setting with three lanes and six surrounding background vehicles, significantly reducing dimensionality. To further avoid the limitations of probability-based method, we propose a volume-based evaluation method that quantifies the proportion of risky scenarios within the entire scenario space. For car-following scenarios, we prove that the set of safe scenarios is convex under specific settings, enabling exact volume computation. Experimental results validate the effectiveness of the proposed volume-based method using both AV behavior models from existing literature and six production AV models calibrated from field-test trajectory data in the Ultra-AV dataset. Code and data will be made publicly available upon acceptance of this paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09182v2</guid>
      <category>cs.RO</category>
      <category>cs.ET</category>
      <pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hang Zhou, Chengyuan Ma, Shiyu Shen, Zhaohui Liang, Xiaopeng Li</dc:creator>
    </item>
    <item>
      <title>A Hybrid Heuristic Framework for Resource-Efficient Querying of Scientific Experiments Data</title>
      <link>https://arxiv.org/abs/2506.10422</link>
      <description>arXiv:2506.10422v2 Announce Type: replace-cross 
Abstract: Scientific experiments and modern applications are generating large amounts of data every day. Most organizations utilize In-house servers or Cloud resources to manage application data and workload. The traditional database management system (DBMS) and HTAP systems spend significant time &amp; resources to load the entire dataset into DBMS before starting query execution. On the other hand, in-situ engines may reparse required data multiple times, increasing resource utilization and data processing costs. Additionally, over or under-allocation of resources also increases application running costs. This paper proposes a lightweight Resource Availability &amp;Workload aware Hybrid Framework (RAW-HF) to optimize querying raw data by utilizing existing finite resources efficiently. RAW-HF includes modules that help optimize the resources required to execute a given workload and maximize the utilization of existing resources. The impact of applying RAW-HF to real-world scientific dataset workloads like Sloan Digital Sky Survey (SDSS) and Linked Observation Data (LOD) presented over 90% and 85% reduction in workload execution time (WET) compared to widely used traditional DBMS PostgreSQL. The overall CPU, IO resource utilization, and WET have been reduced by 26%, 25%, and 26%, respectively, while improving memory utilization by 33%, compared to the state-of-the-art workload-aware partial loading technique (WA) proposed for hybrid systems. A comparison of MUAR technique used by RAW-HF with machine learning based resource allocation techniques like PCC is also presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10422v2</guid>
      <category>cs.DB</category>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <category>cs.PF</category>
      <pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mayank Patel, Minal Bhise</dc:creator>
    </item>
    <item>
      <title>Receiving RISs: Enabling Channel Estimation and Autonomous Configuration</title>
      <link>https://arxiv.org/abs/2506.10662</link>
      <description>arXiv:2506.10662v2 Announce Type: replace-cross 
Abstract: This chapter focuses on a hardware architecture for semi-passive Reconfigurable Intelligent Surfaces (RISs) and investigates its consideration for boosting the performance of Multiple-Input Multiple-Output (MIMO) communication systems. The architecture incorporates a single or multiple radio-frequency chains to receive pilot signals via tunable absorption phase profiles realized by the metasurface front end, as well as a controller encompassing a baseband processing unit to carry out channel estimation, and consequently, the optimization of the RIS reflection coefficients. A novel channel estimation protocol, according to which the RIS receives non-orthogonal training pilot sequences from two multi-antenna terminals via tunable absorption phase profiles, and then, estimates the respective channels via its signal processing unit, is presented. The channel estimates are particularly used by the RIS controller to design the capacity-achieving reflection phase configuration of the metasurface front end. The proposed channel estimation algorithm, which is based on the Alternating Direction Method of Multipliers (ADMM), profits from the RIS random spatial absorption sampling to capture the entire signal space, and exploits the beamspace sparsity and low-rank properties of extremely large MIMO channels, which is particularly relevant for communication systems at the FR3 band and above. Our extensive numerical investigations showcase the superiority of the proposed channel estimation technique over benchmark schemes for various system and RIS hardware configuration parameters, as well as the effectiveness of using channel estimates at the RIS side to dynamically optimize the possibly phase-quantized reflection coefficients of its unit elements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10662v2</guid>
      <category>eess.SP</category>
      <category>cs.ET</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>George C. Alexandropoulos, Konstantinos D. Katsanos, Evangelos Vlachos</dc:creator>
    </item>
    <item>
      <title>Bhatt Conjectures: On Necessary-But-Not-Sufficient Benchmark Tautology for Human Like Reasoning</title>
      <link>https://arxiv.org/abs/2506.11423</link>
      <description>arXiv:2506.11423v2 Announce Type: replace-cross 
Abstract: Debates about whether Large Language or Reasoning Models (LLMs/LRMs) truly reason or merely pattern-match suffer from shifting goal posts. Two analytic--hence "tautological"--benchmarks cut through that fog in my mental model.
  https://github.com/mbhatt1/agentreasoning-sdk</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11423v2</guid>
      <category>cs.CR</category>
      <category>cs.ET</category>
      <pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Manish Bhatt</dc:creator>
    </item>
  </channel>
</rss>
