<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.CP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.CP</link>
    <description>q-fin.CP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.CP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 13 Nov 2025 05:03:57 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 13 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Proof-Carrying No-Arbitrage Surfaces: Constructive PCA-Smolyak Meets Chain-Consistent Diffusion with c-EMOT Certificates</title>
      <link>https://arxiv.org/abs/2511.09175</link>
      <description>arXiv:2511.09175v1 Announce Type: new 
Abstract: We study the construction of SPX--VIX (multi\textendash product) option surfaces that are simultaneously free of static arbitrage and dynamically chain\textendash consistent across maturities. Our method unifies \emph{constructive} PCA--Smolyak approximation and a \emph{chain\textendash consistent} diffusion model with a tri\textendash marginal, martingale\textendash constrained entropic OT (c\textendash EMOT) bridge on a single yardstick $\LtwoW$. We provide \emph{computable certificates} with explicit constant dependence: a strong\textendash convexity lower bound $\muhat$ controlled by the whitened kernel Gram's $\lambda_{\min}$, the entropic strength $\varepsilon$, and a martingale\textendash moment radius; solver correctness via $\KKT$ and geometric decay $\rgeo$; and a $1$-Lipschitz metric projection guaranteeing Dupire/Greeks stability. Finally, we report an end\textendash to\textendash end \emph{log\textendash additive} risk bound $\RiskTotal$ and a \emph{Gate\textendash V2} decision protocol that uses tolerance bands (from $\alpha$\textendash mixing concentration) and tail\textendash robust summaries, under which all tests \emph{pass}: for example $\KKT=\CTwoKKT\ (\le 4!\!\times\!10^{-2})$, $\rgeo=\CTworgeo\ (\le 1.05)$, empirical Lipschitz $\CThreelipemp\!\le\!1.01$, and Dupire nonincrease certificate $=\texttt{True}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.09175v1</guid>
      <category>q-fin.CP</category>
      <pubDate>Thu, 13 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jian'an Zhang</dc:creator>
    </item>
    <item>
      <title>Data-driven Feynman-Kac Discovery with Applications to Prediction and Data Generation</title>
      <link>https://arxiv.org/abs/2511.08606</link>
      <description>arXiv:2511.08606v1 Announce Type: cross 
Abstract: In this paper, we propose a novel data-driven framework for discovering probabilistic laws underlying the Feynman-Kac formula. Specifically, we introduce the first stochastic SINDy method formulated under the risk-neutral probability measure to recover the backward stochastic differential equation (BSDE) from a single pair of stock and option trajectories. Unlike existing approaches to identifying stochastic differential equations-which typically require ergodicity-our framework leverages the risk-neutral measure, thereby eliminating the ergodicity assumption and enabling BSDE recovery from limited financial time series data. Using this algorithm, we are able not only to make forward-looking predictions but also to generate new synthetic data paths consistent with the underlying probabilistic law.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.08606v1</guid>
      <category>q-fin.MF</category>
      <category>cs.AI</category>
      <category>q-fin.CP</category>
      <pubDate>Thu, 13 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>39th Conference on Neural Information Processing Systems (NeurIPS 2025) Workshop: Generative AI in Finance</arxiv:journal_reference>
      <dc:creator>Qi Feng, Guang Lin, Purav Matlia, Denny Serdarevic</dc:creator>
    </item>
    <item>
      <title>Reasoning on Time-Series for Financial Technical Analysis</title>
      <link>https://arxiv.org/abs/2511.08616</link>
      <description>arXiv:2511.08616v1 Announce Type: cross 
Abstract: While Large Language Models have been used to produce interpretable stock forecasts, they mainly focus on analyzing textual reports but not historical price data, also known as Technical Analysis. This task is challenging as it switches between domains: the stock price inputs and outputs lie in the time-series domain, while the reasoning step should be in natural language. In this work, we introduce Verbal Technical Analysis (VTA), a novel framework that combine verbal and latent reasoning to produce stock time-series forecasts that are both accurate and interpretable. To reason over time-series, we convert stock price data into textual annotations and optimize the reasoning trace using an inverse Mean Squared Error (MSE) reward objective. To produce time-series outputs from textual reasoning, we condition the outputs of a time-series backbone model on the reasoning-based attributes. Experiments on stock datasets across U.S., Chinese, and European markets show that VTA achieves state-of-the-art forecasting accuracy, while the reasoning traces also perform well on evaluation by industry experts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.08616v1</guid>
      <category>q-fin.ST</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>q-fin.CP</category>
      <pubDate>Thu, 13 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kelvin J. L. Koa, Jan Chen, Yunshan Ma, Huanhuan Zheng, Tat-Seng Chua</dc:creator>
    </item>
    <item>
      <title>The LLM Pro Finance Suite: Multilingual Large Language Models for Financial Applications</title>
      <link>https://arxiv.org/abs/2511.08621</link>
      <description>arXiv:2511.08621v1 Announce Type: cross 
Abstract: The financial industry's growing demand for advanced natural language processing (NLP) capabilities has highlighted the limitations of generalist large language models (LLMs) in handling domain-specific financial tasks. To address this gap, we introduce the LLM Pro Finance Suite, a collection of five instruction-tuned LLMs (ranging from 8B to 70B parameters) specifically designed for financial applications. Our approach focuses on enhancing generalist instruction-tuned models, leveraging their existing strengths in instruction following, reasoning, and toxicity control, while fine-tuning them on a curated, high-quality financial corpus comprising over 50% finance-related data in English, French, and German.
  We evaluate the LLM Pro Finance Suite on a comprehensive financial benchmark suite, demonstrating consistent improvement over state-of-the-art baselines in finance-oriented tasks and financial translation. Notably, our models maintain the strong general-domain capabilities of their base models, ensuring reliable performance across non-specialized tasks. This dual proficiency, enhanced financial expertise without compromise on general abilities, makes the LLM Pro Finance Suite an ideal drop-in replacement for existing LLMs in financial workflows, offering improved domain-specific performance while preserving overall versatility. We publicly release two 8B-parameters models to foster future research and development in financial NLP applications: https://huggingface.co/collections/DragonLLM/llm-open-finance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.08621v1</guid>
      <category>q-fin.ST</category>
      <category>cs.AI</category>
      <category>q-fin.CP</category>
      <pubDate>Thu, 13 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ga\"etan Caillaut, Raheel Qader, Jingshu Liu, Mariam Nakhl\'e, Arezki Sadoune, Massinissa Ahmim, Jean-Gabriel Barthelemy</dc:creator>
    </item>
  </channel>
</rss>
