<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 01 Jul 2025 13:30:31 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Highway toll allocation problem revisited: new methods and characterizations</title>
      <link>https://arxiv.org/abs/2506.22475</link>
      <description>arXiv:2506.22475v1 Announce Type: new 
Abstract: This paper considers the highway toll allocation problem (Wu, van den Brink, and Est\'evez-Fern\'andez in Transport Res B-Meth 180:10288, 2024). The aim is to allocate the tolls collected from the users of a highway across the various road sections. To this end, the authors propose, among others, the Segments Equal Sharing method, which is characterized and reinterpreted as a specific solution of a cooperative game associated with the problem. This paper presents two new allocation rules: the Segments Proportional Sharing method and the Segments Compensated Sharing method. We axiomatically characterize these new methods and compare their properties to those of the Segments Equal Sharing method. Furthermore, we also examine the relationship of these methods to the solution of the associated cooperative game. We conclude the methodological study by introducing a general family of segment allocation methods that includes the three aforementioned rules. Finally, we evaluate the performance of these methods using a real-world dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22475v1</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>P. Soto-Rodr\'iguez, B. Casas-M\'endez, A. Saavedra-Nieves</dc:creator>
    </item>
    <item>
      <title>Hindsight-Guided Momentum (HGM) Optimizer: An Approach to Adaptive Learning Rate</title>
      <link>https://arxiv.org/abs/2506.22479</link>
      <description>arXiv:2506.22479v1 Announce Type: new 
Abstract: We introduce Hindsight-Guided Momentum (HGM), a first-order optimization algorithm that adaptively scales learning rates based on the directional consistency of recent updates. Traditional adaptive methods, such as Adam or RMSprop , adapt learning dynamics using only the magnitude of gradients, often overlooking important geometric cues.Geometric cues refer to directional information, such as the alignment between current gradients and past updates, which reflects the local curvature and consistency of the optimization path. HGM addresses this by incorporating a hindsight mechanism that evaluates the cosine similarity between the current gradient and accumulated momentum. This allows it to distinguish between coherent and conflicting gradient directions, increasing the learning rate when updates align and reducing it in regions of oscillation or noise. The result is a more responsive optimizer that accelerates convergence in smooth regions of the loss surface while maintaining stability in sharper or more erratic areas. Despite this added adaptability, the method preserves the computational and memory efficiency of existing optimizers.By more intelligently responding to the structure of the optimization landscape, HGM provides a simple yet effective improvement over existing approaches, particularly in non-convex settings like that of deep neural network training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22479v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Krisanu Sarkar</dc:creator>
    </item>
    <item>
      <title>Mathematical Modeling of Carbon Dioxide Emissions with GDP Linkage: Sensitivity Analysis and Optimal Control Strategy</title>
      <link>https://arxiv.org/abs/2506.22483</link>
      <description>arXiv:2506.22483v1 Announce Type: new 
Abstract: Climate change and global warming are among the most significant issues that humanity is currently facing, and also among the issues that pose the greatest threats to all mankind. These issues are primarily driven by abnormal increases in greenhouse gas concentrations. Mathematical modeling serves as a powerful approach to analyze the dynamic patterns of atmospheric carbon dioxide. In this paper, we established a mathmetical model with four state variables to investigate the dynamic behavior of the interaction between atmospheric carbon dioxide, GDP, forest area and human population. Relevant theories were employed to analyze the system's boundedness and the stability of equilibrium points. The parameter values were estimated with the help of the actual data in China and numerical fitting was carried out to verify the results of the theoretical analysis. The sensitivity analysis of the compartments with respect to the model parameters was analyzed by using the Partial Rank Correlation Coefficient (PRCC) and the Latin Hypercube Sampling test. Apply the optimal control theory to regulate the atmospheric carbon dioxide level and provide the corresponding numerical fitting. Finally, corresponding discussions and suggestions were put forward with the help of the results of the theoretical analysis and numerical fitting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22483v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hua Liu, Zhuoma Gangji, Yumei Wei, Jianhua Ye, Gang Ma</dc:creator>
    </item>
    <item>
      <title>Optimal investment and consumption under forward utilities with relative performance concerns</title>
      <link>https://arxiv.org/abs/2506.22514</link>
      <description>arXiv:2506.22514v1 Announce Type: new 
Abstract: We study a n-player and mean-field portfolio optimization problem under relative performance concerns with non-zero volatility, for wealth and consumption. The consistency assumption defining forward relative performance processes leads to a sufficient characterization of such processes with mean of a Stochastic HJB equations, which highlights the link between wealth and consumption utility, and also characterizes the optimal strategies. In particular, forward relative performance processes with a wealth utility of CRRA type and separable time and space dependence necessarily have a consumption utility of the same form, with the same risk aversion parameter. This characterization gives a better understanding of the drift condition ensuring time consistency. In this setting, we establish closed form of the Nash equilibrium for both the n-player and mean eld problems. We also provide some numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22514v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anis Matoussi (LMM), Guillaume Broux-Quemerais (LMM), Zhou Chao (NUS)</dc:creator>
    </item>
    <item>
      <title>Inventory Control Using a L\'evy Process for Evaluating Total Costs under Intermittent Demand</title>
      <link>https://arxiv.org/abs/2506.22524</link>
      <description>arXiv:2506.22524v1 Announce Type: new 
Abstract: Products with intermittent demand are characterized by a high risk of sales losses and obsolescence due to the sporadic occurrence of demand events. Generally, both point forecasting and probabilistic forecasting approaches are applied to intermittent demand. In particular, probabilistic forecasting, which models demand as a stochastic process, is capable of capturing uncertainty. An example of such modeling is the use of L\'evy processes, which possess independent increments and accommodate discontinuous changes (jumps). However, to the best of our knowledge, in inventory control using L\'evy processes, no studies have investigated how the order quantity and reorder point affect the total cost. One major difficulty has been the mathematical formulation of inventory replenishment triggered at reorder points. To address this challenge, the present study formulates a reorder-point policy by modeling cumulative demand as a drifted Poisson process and introducing a stopping time to represent the timing at which the reorder point is reached. Furthermore, the validity of the proposed method is verified by comparing the total cost with that obtained from a case where an ARIMA model is combined with a reorder-point policy. As a main result, while the total cost under ARIMA-based forecasting increases linearly over time, the L\'evy process-based formulation provides an analytical expression for the total cost, revealing that random demand fluctuations cause the expected total cost to grow at a rate faster than linear.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22524v1</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <category>math.PR</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ryoya Koide, Yurika Ono, Aya Ishigaki</dc:creator>
    </item>
    <item>
      <title>Correlated Mutations for Integer Programming</title>
      <link>https://arxiv.org/abs/2506.22526</link>
      <description>arXiv:2506.22526v1 Announce Type: new 
Abstract: Even with the recent theoretical advancements that dramatically reduced the complexity of Integer Programming (IP), heuristics remain the dominant problem-solvers for this difficult category. This study seeks to establish the groundwork for Integer Evolution Strategies (IESs), a class of randomized search heuristics inherently designed for continuous spaces. IESs already excel in treating IP in practice, but accomplish it via discretization and by applying sophisticated patches to their continuous operators, while persistently using the $\ell_2$-norm as their operation pillar. We lay foundations for discrete search, by adopting the $\ell_1$-norm, accounting for the suitable step-size, and questioning alternative measures to quantify correlations over the integer lattice. We focus on mutation distributions for unbounded integer decision variables. We briefly discuss a couple of candidate discrete probabilities induced by the uniform and binomial distributions, which we show to possess less appealing theoretical properties, and then narrow down to the Truncated Normal (TN) and Double Geometric (DG) distributions. We explore their theoretical properties, including entropy functions, and propose a procedure to generate scalable correlated mutation distributions. Our investigations are accompanied by extensive numerical simulations, which consistently support the claim that the DG distribution is better suited for unbounded integer search. We link our theoretical perspective to empirical evidence indicating that an IES with correlated DG mutations outperformed other strategies over non-separable quadratic IP. We conclude that while the replacement of the default TN distribution by the DG is theoretically justified and practically beneficial, the truly crucial change lies in adopting the $\ell_1$-norm over the $\ell_2$-norm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22526v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ofer M. Shir, Michael Emmerich</dc:creator>
    </item>
    <item>
      <title>On a result by Meshulam</title>
      <link>https://arxiv.org/abs/2506.22553</link>
      <description>arXiv:2506.22553v1 Announce Type: new 
Abstract: In 1996, Meshulam proved that every sequence generated by applying projections onto affine subspaces, drawn from a finite collection in Euclidean space, must be bounded.
  In this paper, we extend his result not only from affine subspaces to convex polyhedral subsets, but also from Euclidean to general Hilbert space. Various examples are provided to illustrate the sharpness of the results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22553v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.FA</category>
      <category>math.NA</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Heinz H. Bauschke, Tran Thanh Tung</dc:creator>
    </item>
    <item>
      <title>Maximum Dispersion, Maximum Concentration: Enhancing the Quality of MOP Solutions</title>
      <link>https://arxiv.org/abs/2506.22568</link>
      <description>arXiv:2506.22568v1 Announce Type: new 
Abstract: Multi-objective optimization problems (MOPs) often require a trade-off between conflicting objectives, maximizing diversity and convergence in the objective space. This study presents an approach to improve the quality of MOP solutions by optimizing the dispersion in the decision space and the convergence in a specific region of the objective space. Our approach defines a Region of Interest (ROI) based on a cone representing the decision maker's preferences in the objective space, while enhancing the dispersion of solutions in the decision space using a uniformity measure. Combining solution concentration in the objective space with dispersion in the decision space intensifies the search for Pareto-optimal solutions while increasing solution diversity. When combined, these characteristics improve the quality of solutions and avoid the bias caused by clustering solutions in a specific region of the decision space. Preliminary experiments suggest that this method enhances multi-objective optimization by generating solutions that effectively balance dispersion and concentration, thereby mitigating bias in the decision space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22568v1</guid>
      <category>math.OC</category>
      <category>cs.CV</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gladston Moreira, Ivan Meneghini, Elzabeth Wanner</dc:creator>
    </item>
    <item>
      <title>A highly efficient single-loop smoothing damped Newton method for large-scale bilevel hyperparameter optimization of SVC</title>
      <link>https://arxiv.org/abs/2506.22603</link>
      <description>arXiv:2506.22603v1 Announce Type: new 
Abstract: Bilevel hyperparameter optimization has received growing attention thanks to the fast development of machine learning. Due to the tremendous size of data sets, the scale of bilevel hyperparameter optimization problem could be extremely large, posing great challenges in designing efficient numerical algorithms. In this paper, we focus on solving the large-scale mathematical programs with equilibrium constraints (MPEC) derived from hyperparameter selection of L1-support vector classification (L1-SVC). We propose a highly efficient single-loop smoothing damped Newton method (SDNM) for solving such MPEC. Compared with most existing algorithms where subproblems are involved and solved by on-shelf packages, our approach fully takes advantage of the structure of MPEC and therefore is single-loop. Moreover, the proposed SDNM enjoys a quadratic convergence rate under proper assumptions. Extensive numerical results over LIBSVM dataset show the superior performance of SDNM over other state-of-art algorithms including the Scholtes global relaxation method (SGRM) with subproblem solved by SNOPT and the Matlab built-in function fmincon, especially in CPU time. For example, for dataset w4a, SDNM is 20 times faster than SGRM and 3 times faster than fmincon. Further numerical results also verifies the quadratic convergence rate of SDNM as well as the fulfillment of the second order sufficient condition, while guarantees that SDNM returns a strict local minimizer of the smoothing problem of MPEC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22603v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yixin Wang, Qingna Li, Liwei Zhang</dc:creator>
    </item>
    <item>
      <title>Preconditioned Halpern iteration with adaptive anchoring parameters and an acceleration to Chambolle-Pock algorithm</title>
      <link>https://arxiv.org/abs/2506.22725</link>
      <description>arXiv:2506.22725v1 Announce Type: new 
Abstract: In this article, we propose a preconditioned Halpern iteration with adaptive anchoring parameters (PHA) algorithm by integrating a preconditioner and Halpern iteration with adaptive anchoring parameters. Then we establish the strong convergence and at least $\mathcal{O}(1/k)$ convergence rate of the PHA algorithm, and extend these convergence results to Halpern-type preconditioned proximal point method with adaptive anchoring parameters. Moreover, we develop an accelerated Chambolle--Pock algorithm (aCP) that is shown to have at least $\mathcal{O}(1/k)$ convergence rate concerning the residual mapping and the primal-dual gap. Finally, numerical experiments on the minimax matrix game and LASSO problem are provided to show advantages and outperformance of our aCP algorithm over Halpern-based accelerated Chambolle--Pock algorithm in [18].</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22725v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Fangbing Lv, Qiao-Li Dong</dc:creator>
    </item>
    <item>
      <title>Performance Estimation of second-order optimization methods on classes of univariate functions</title>
      <link>https://arxiv.org/abs/2506.22764</link>
      <description>arXiv:2506.22764v1 Announce Type: new 
Abstract: We develop a principled approach to obtain exact computer-aided worst-case guarantees on the performance of second-order optimization methods on classes of univariate functions. We first present a generic technique to derive interpolation conditions for a wide range of univariate functions, and use it to obtain such conditions for generalized self-concordant functions (including self-concordant and quasi-self-concordant functions) and functions with Lipschitz Hessian (both convex and non-convex). We then exploit these conditions within the Performance Estimation framework to tightly analyze the convergence of second-order methods on univariate functions, including (Cubic Regularized) Newton's method and several of its variants. Thereby, we improve on existing convergence rates, exhibit univariate lower bounds (that thus hold in the multivariate case), and analyze the performance of these methods with respect to the same criteria.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22764v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anne Rubbens, Nizar Bousselmi, Julien M. Hendrickx, Fran\c{c}ois Glineur</dc:creator>
    </item>
    <item>
      <title>Optimal Trajectory Planning for Space Object Tracking with Collision-Avoidance Constraints</title>
      <link>https://arxiv.org/abs/2506.22797</link>
      <description>arXiv:2506.22797v1 Announce Type: new 
Abstract: A control optimization approach is presented for a chaser spacecraft tasked with maintaining proximity to a target space object while avoiding collisions. The target object trajectory is provided numerically to account for both passive debris and actively maneuvering spacecraft. Thrusting actions for the chaser object are modeled as discrete (on/off) variables to optimize resources (e.g., fuel) while satisfying spatial, dynamical, and collision-avoidance constraints. The nonlinear equation of motion is discretized directly using a fourth-order Runge-Kutta method without the need for linearized dynamics. The resulting mixed-integer nonlinear programming (MINLP) formulation is further enhanced with scaling techniques, valid constraints based on a perspective convex reformulation, and a combination of continuous relaxations of discrete actions with rounding heuristics to recover high-quality feasible solutions. This methodology enables efficient, collision-free trajectory planning over extended time horizons while reducing computational overhead. The effectiveness and practicality of the proposed approach is validated through a numerical case study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22797v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Saif R. Kazi, Harsha Nagarajan, Hassan Hijazi, Przemek Wozniak</dc:creator>
    </item>
    <item>
      <title>Denoising Multi-Color QR Codes and Stiefel-Valued Data by Relaxed Regularizations</title>
      <link>https://arxiv.org/abs/2506.22826</link>
      <description>arXiv:2506.22826v1 Announce Type: new 
Abstract: The handling of manifold-valued data, for instance, plays a central role in color restoration tasks relying on circle- or sphere-valued color models, in the study of rotational or directional information related to the special orthogonal group, and in Gaussian image processing, where the pixel statistics are interpreted as values on the hyperbolic sheet. Especially, to denoise these kind of data, there have been proposed several generalizations of total variation (TV) and Tikhonov-type denoising models incorporating the underlying manifolds. Recently, a novel, numerically efficient denoising approach has been introduced, where the data are embedded in an Euclidean ambient space, the non-convex manifolds are encoded by a series of positive semi-definite, fixed-rank matrices, and the rank constraint is relaxed to obtain a convexification that can be solved using standard algorithms from convex analysis. The aim of the present paper is to extent this approach to new kinds of data like multi-binary and Stiefel-valued data. Multi-binary data can, for instance, be used to model multi-color QR codes whereas Stiefel-valued data occur in image and video-based recognition. For both new data types, we propose TV- and Tikhonov-based denoising modelstogether with easy-to-solve convexification. All derived methods are evaluated on proof-of-concept, synthetic experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22826v1</guid>
      <category>math.OC</category>
      <category>cs.CV</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Robert Beinert, Jonas Bresch</dc:creator>
    </item>
    <item>
      <title>Deep neural networks can provably solve Bellman equations for Markov decision processes without the curse of dimensionality</title>
      <link>https://arxiv.org/abs/2506.22851</link>
      <description>arXiv:2506.22851v1 Announce Type: new 
Abstract: Discrete time stochastic optimal control problems and Markov decision processes (MDPs) are fundamental models for sequential decision-making under uncertainty and as such provide the mathematical framework underlying reinforcement learning theory. A central tool for solving MDPs is the Bellman equation and its solution, the so-called $Q$-function. In this article, we construct deep neural network (DNN) approximations for $Q$-functions associated to MDPs with infinite time horizon and finite control set $A$. More specifically, we show that if the the payoff function and the random transition dynamics of the MDP can be suitably approximated by DNNs with leaky rectified linear unit (ReLU) activation, then the solutions $Q_d\colon \mathbb R^d\to \mathbb R^{|A|}$, $d\in \mathbb{N}$, of the associated Bellman equations can also be approximated in the $L^2$-sense by DNNs with leaky ReLU activation whose numbers of parameters grow at most polynomially in both the dimension $d\in \mathbb{N}$ of the state space and the reciprocal $1/\varepsilon$ of the prescribed error $\varepsilon\in (0,1)$. Our proof relies on the recently introduced full-history recursive multilevel fixed-point (MLFP) approximation scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22851v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arnulf Jentzen, Konrad Kleinberg, Thomas Kruse</dc:creator>
    </item>
    <item>
      <title>On the controllability of laminated beams with Venttsel-type boundary conditions</title>
      <link>https://arxiv.org/abs/2506.22887</link>
      <description>arXiv:2506.22887v1 Announce Type: new 
Abstract: This paper examines the boundary controllability of a Timoshenko laminated beam system subject to Venttsel-type boundary conditions. The study focuses on a novel configuration in which three controls are applied solely at the boundary of the beam. Controllability is established by deriving an appropriate observability inequality for the corresponding adjoint system, which is then employed within the framework of the duality method in the setup of the classical Hilbert uniqueness method (HUM) to achieve the control problem. The main contribution lies in the analysis of a system comprising three beams governed by dynamic Venttsel-type boundary conditions, as introduced by Venttsel in [Theory Probab. Appl., 4 (1959)].</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22887v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>George J. Bautista, Roberto de A. Capistrano-Filho, Juan L\'imaco</dc:creator>
    </item>
    <item>
      <title>Energy-Aware Model Predictive Control for Batch Manufacturing System Scheduling Under Different Electricity Pricing Strategies</title>
      <link>https://arxiv.org/abs/2506.22923</link>
      <description>arXiv:2506.22923v1 Announce Type: new 
Abstract: Manufacturing industries are among the highest energy-consuming sectors, facing increasing pressure to reduce energy costs. This paper presents an energy-aware Model Predictive Control (MPC) framework to dynamically schedule manufacturing processes in response to time-varying electricity prices without compromising production goals or violating production constraints. A network-based manufacturing system model is developed to capture complex material flows, batch processing, and capacities of buffers and machines. The scheduling problem is formulated as a Mixed-Integer Quadratic Program (MIQP) that balances energy costs, buffer levels, and production requirements. A case study evaluates the proposed MPC framework under four industrial electricity pricing schemes. Numerical results demonstrate that the approach reduces energy usage expenses while satisfying production goals and adhering to production constraints. The findings highlight the importance of considering the detailed electricity cost structure in manufacturing scheduling decisions and provide practical insights for manufacturers when selecting among different electricity pricing strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22923v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hongliang Li, Herschel C. Pangborn, Ilya Kovalenko</dc:creator>
    </item>
    <item>
      <title>Douglas--Rachford for multioperator comonotone inclusions with applications to multiblock optimization</title>
      <link>https://arxiv.org/abs/2506.22928</link>
      <description>arXiv:2506.22928v1 Announce Type: new 
Abstract: We study the convergence of the adaptive Douglas--Rachford (aDR) algorithm for solving a multioperator inclusion problem involving the sum of maximally comonotone operators. To address such problems, we adopt a product space reformulation that accommodates nonconvex-valued operators, which is essential when dealing with comonotone mappings. We establish convergence of the aDR method under comonotonicity assumptions, subject to suitable conditions on the algorithm parameters and comonotonicity moduli of the operators. Our analysis leverages the Attouch--Th\'{e}ra duality framework, which allows us to study the convergence of the aDR algorithm via its application to the dual inclusion problem. As an application, we derive a multiblock ADMM-type algorithm for structured convex and nonconvex optimization problems by applying the aDR algorithm to the operator inclusion formulation of the KKT system. The resulting method extends to multiblock and nonconvex settings the classical duality between the Douglas--Rachford algorithm and the alternating direction method of multipliers in the convex two-block case. Moreover, we establish convergence guarantees for both the fully convex and strongly convex-weakly convex regimes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22928v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jan Harold Alcantara, Minh N. Dao, Akiko Takeda</dc:creator>
    </item>
    <item>
      <title>Detection of coordinated fleet vehicles in route choice urban games. Part I. Inverse fleet assignment theory</title>
      <link>https://arxiv.org/abs/2506.22966</link>
      <description>arXiv:2506.22966v1 Announce Type: new 
Abstract: Detection of collectively routing fleets of vehicles in future urban systems may become important for the management of traffic, as such routing may destabilize urban networks leading to deterioration of driving conditions. Accordingly, in this paper we discuss the question whether it is possible to determine the flow of fleet vehicles on all routes given the fleet size and behaviour as well as the combined total flow of fleet and non-fleet vehicles on every route. We prove that the answer to this Inverse Fleet Assignment Problem is 'yes' for myopic fleet strategies which are more 'selfish' than 'altruistic', and 'no' otherwise, under mild assumptions on route/link performance functions. To reach these conclusions we introduce the forward fleet assignment operator and study its properties, proving that it is invertible for 'bad' objectives of fleet controllers. We also discuss the challenges of implementing myopic fleet routing in the real world and compare it to Stackelberg and Nash routing. Finally, we show that optimal Stackelberg fleet routing could involve highly variable mixed strategies in some scenarios, which would likely cause chaos in the traffic network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22966v1</guid>
      <category>math.OC</category>
      <category>cs.MA</category>
      <category>econ.TH</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Grzegorz Jamr\'oz, Rafa{\l} Kucharski</dc:creator>
    </item>
    <item>
      <title>Equilibrium Correction Iteration for A Class of Mean-Field Game Inverse Problem</title>
      <link>https://arxiv.org/abs/2506.23018</link>
      <description>arXiv:2506.23018v1 Announce Type: new 
Abstract: This work investigates the ambient potential identification problem in inverse Mean-Field Games (MFGs), where the goal is to recover the unknown potential from the value function at equilibrium. We propose a simple yet effective iterative strategy, Equilibrium Correction Iteration (ECI), that leverages the structure of MFGs rather than relying on generic optimization formulations. ECI uncovers hidden information from equilibrium measurements, offering a new perspective on inverse MFGs. To improve computational efficiency, two acceleration variants are introduced: Best Response Iteration (BRI), which uses inexact forward solvers, and Hierarchical ECI (HECI), which incorporates multilevel grids. While BRI performs efficiently in general settings, HECI proves particularly effective in recovering low-frequency potentials. We also highlight a connection between the potential identification problem in inverse MFGs and inverse linear parabolic equations, suggesting promising directions for future theoretical analysis. Finally, comprehensive numerical experiments demonstrate how viscosity, terminal time, and interaction costs can influence the well-posedness of the inverse problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23018v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jiajia Yu, Jian-Guo Liu, Hongkai Zhao</dc:creator>
    </item>
    <item>
      <title>On the Out-of-Sample Performance of Stochastic Dynamic Programming and Model Predictive Control</title>
      <link>https://arxiv.org/abs/2506.23097</link>
      <description>arXiv:2506.23097v1 Announce Type: new 
Abstract: Sample average approximation-based stochastic dynamic programming (SDP) and model predictive control (MPC) are two different methods for approaching multistage stochastic optimization. In this paper we investigate the conditions under which SDP may be outperformed by MPC. We show that, depending on the presence of concavity or convexity, MPC can be interpreted as solving a mean-constrained distributionally ambiguous version of the problem that is solved by SDP. This furnishes performance guarantees when the true mean is known and provides intuition for why MPC performs better in some applications and worse in others. We then study a multistage stochastic optimization problem that is representative of the type for which MPC may be the better choice. We find that this can indeed be the case when the probability distribution of the underlying random variable is skewed or has enough weight in the right-hand tail.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23097v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dominic S. T. Keehan, Andrew B. Philpott, Edward J. Anderson</dc:creator>
    </item>
    <item>
      <title>Conductance Estimation in Digraphs: Submodular Transformation, Lov\'asz Extension and Dinkelbach Iteration</title>
      <link>https://arxiv.org/abs/2506.23131</link>
      <description>arXiv:2506.23131v1 Announce Type: new 
Abstract: Conventional spectral digraph partitioning methods typically symmetrize the adjacency matrix, thereby transforming the directed graph partitioning problem into an undirected one, where bipartitioning is commonly linked to minimizing graph conductance. However, such symmetrization approaches disregard the directional dependencies of edges in digraphs, failing to capture the inherent imbalance crucial to directed network modeling. Building on the parallels between digraph conductance and conductance under submodular transformations, we develop a generalized framework to derive their continuous formulations. By leveraging properties of the Lov\'asz extension, this framework addresses the fundamental asymmetry problem in digraph partitioning. We then formulate an equivalent fractional programming problem, relax it via a three-step Dinkelbach iteration procedure, and design the Directed Simple Iterative ($\mathbf{DSI}$) algorithm for estimating digraph conductance. The subproblem within $\mathbf{DSI}$ is analytically solvable, and the algorithm is guaranteed to converge provably to a binary local optimum. Extensive experiments on synthetic and real-world networks demonstrate that our $\mathbf{DSI}$ algorithm significantly outperforms several state-of-the-art methods in digraph conductance minimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23131v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sihong Shao, Chuan Yang, Xinyang Ye</dc:creator>
    </item>
    <item>
      <title>Sample-Cluster-Select: A new framework to obtain diverse approximate solutions of combinatorial optimization problems</title>
      <link>https://arxiv.org/abs/2506.23278</link>
      <description>arXiv:2506.23278v1 Announce Type: new 
Abstract: When solving real-world problems, practitioners often hesitate to implement solutions obtained from mathematical models, especially for important decisions. This hesitation stems from practitioners' lack of trust in optimization models and computational results. To address these challenges, we propose Sample-Cluster-Select (SCS) for solving practical combinatorial optimization problems under the assumption of potentially acceptable solution set. SCS first samples the potential solutions, performs clustering on these solutions, and selects a representative solution for each cluster. SCS aims to build trust by helping users understand the solution space through multiple representative solutions, while simultaneously identifying promising alternatives around these solutions. We conducted experiments on randomly generated instances, comparing SCS against multi-start local search and $k$-best algorithms where efficient methods exist, or evolutionary algorithms otherwise. The results show that SCS outperforms multi-start local search and $k$-best algorithms in most cases, while showing competitive performance against evolutionary algorithms, though not surpassing some of their variants. Most importantly, we found that the clustering approach provides insights into solutions that are difficult to obtain with existing methods, such as local structures of similar potential solutions and neighboring solutions of representative solutions. Thus, our approach helps practitioners understand the solution space better, thereby increasing their confidence in implementing the proposed solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23278v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Susumu Hashimoto, Takeaki Uno</dc:creator>
    </item>
    <item>
      <title>On the boundedness of the sequence generated by minibatch stochastic gradient descent</title>
      <link>https://arxiv.org/abs/2506.23303</link>
      <description>arXiv:2506.23303v1 Announce Type: new 
Abstract: Stochastic Gradient Descent (SGD) with Polyak's stepsize has recently gained renewed attention in stochastic optimization. Recently, Orvieto, Lacoste-Julien, and Loizou introduced a decreasing variant of Polyak's stepsize, where convergence relies on a boundedness assumption of the iterates. They established that this assumption holds under strong convexity. In this paper, we extend their result by proving that boundedness also holds for a broader class of objective functions, including coercive functions. We also present a case in which boundedness may or may not hold.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23303v1</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Heinz H. Bauschke, Tran Thanh Tung</dc:creator>
    </item>
    <item>
      <title>Breaking a Logarithmic Barrier in the Stopping Time Convergence Rate of Stochastic First-order Methods</title>
      <link>https://arxiv.org/abs/2506.23335</link>
      <description>arXiv:2506.23335v1 Announce Type: new 
Abstract: This work provides a novel convergence analysis for stochastic optimization in terms of stopping times, addressing the practical reality that algorithms are often terminated adaptively based on observed progress. Unlike prior approaches, our analysis: 1. Directly characterizes convergence in terms of stopping times adapted to the underlying stochastic process. 2. Breaks a logarithmic barrier in existing results. Key to our results is the development of a Gr\"onwall-type argument tailored to such stochastic processes. This tool enables sharper bounds without restrictive assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23335v1</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yasong Feng, Yifan Jiang, Tianyu Wang, Zhiliang Ying</dc:creator>
    </item>
    <item>
      <title>Swapping objectives accelerates Davis-Yin splitting</title>
      <link>https://arxiv.org/abs/2506.23475</link>
      <description>arXiv:2506.23475v1 Announce Type: new 
Abstract: In this work, we investigate the application of Davis-Yin splitting (DYS) to convex optimization problems and demonstrate that swapping the roles of the two nonsmooth convex functions can result in a faster convergence rate. Such a swap typically yields a different sequence of iterates, but its impact on convergence behavior has been largely understudied or often overlooked. We address this gap by establishing best-known convergence rates for DYS and its swapped counterpart, using the primal--dual gap function as the performance metric. Our results indicate that variants of the Douglas--Rachford splitting algorithm (a special case of DYS) share the same worst-case rate, whereas the convergence rates of the two DYS variants differ. This discrepancy is further illustrated through concrete examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23475v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Edward Duc Hien Nguyen, Jaewook J. Suh, Xin Jiang, Shiqian Ma</dc:creator>
    </item>
    <item>
      <title>Optimized methods for composite optimization: a reduction perspective</title>
      <link>https://arxiv.org/abs/2506.23756</link>
      <description>arXiv:2506.23756v1 Announce Type: new 
Abstract: Recent advances in convex optimization have leveraged computer-assisted proofs to develop optimized first-order methods that improve over classical algorithms. However, each optimized method is specially tailored for a particular problem setting, and it is a well-documented challenge to extend optimized methods to other settings due to their highly bespoke design and analysis. We provide a general framework that derives optimized methods for composite optimization directly from those for unconstrained smooth optimization. The derived methods naturally extend the original methods, generalizing how proximal gradient descent extends gradient descent. The key to our result is certain algebraic identities that provide a unified and straightforward way of extending convergence analyses from unconstrained to composite settings. As concrete examples, we apply our framework to establish (1) the phenomenon of stepsize acceleration for proximal gradient descent; (2) a convergence rate for the proximal optimized gradient method which is faster than FISTA; (3) a new method that improves the state-of-the-art rate for minimizing gradient norm in the composite setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23756v1</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinho Bok, Jason M. Altschuler</dc:creator>
    </item>
    <item>
      <title>A Structured Proximal Stochastic Variance Reduced Zeroth-order Algorithm</title>
      <link>https://arxiv.org/abs/2506.23758</link>
      <description>arXiv:2506.23758v1 Announce Type: new 
Abstract: Minimizing finite sums of functions is a central problem in optimization, arising in numerous practical applications. Such problems are commonly addressed using first-order optimization methods. However, these procedures cannot be used in settings where gradient information is unavailable. Finite-difference methods provide an alternative by approximating gradients through function evaluations along a set of directions. For finite-sum minimization problems, it was shown that incorporating variance-reduction techniques into finite-difference methods can improve convergence rates. Additionally, recent studies showed that imposing structure on the directions (e.g., orthogonality) enhances performance. However, the impact of structured directions on variance-reduced finite-difference methods remains unexplored. In this work, we close this gap by proposing a structured variance-reduced finite-difference algorithm for non-smooth finite-sum minimization. We analyze the proposed method, establishing convergence rates for non-convex functions and those satisfying the Polyak-{\L}ojasiewicz condition. Our results show that our algorithm achieves state-of-the-art convergence rates while incurring lower per-iteration costs. Finally, numerical experiments highlight the strong practical performance of our method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23758v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marco Rando, Cheik Traor\'e, Cesare Molinari, Lorenzo Rosasco, Silvia Villa</dc:creator>
    </item>
    <item>
      <title>Production Planning Under Demand and Endogenous Supply Uncertainty</title>
      <link>https://arxiv.org/abs/2506.23780</link>
      <description>arXiv:2506.23780v1 Announce Type: new 
Abstract: We study the problem of determining how much finished goods inventory to source from different capacitated facilities in order to maximize profits resulting from sales of such inventory. We consider a problem wherein there is uncertainty in demand for finished goods inventory and production yields at facilities. Further, we consider that uncertainty in production yields is endogenous, as it depends on both the facilities where a product is produced and the volumes produced at those facilities. We model the problem as a two stage stochastic program and propose an exact, Benders-based algorithm for solving instances of the problem. We prove the correctness of the algorithm and with an extensive computational study demonstrate that it outperforms known benchmarks. Finally, we establish the value in modeling uncertainty in both demands and production yields.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23780v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1287/ijoc.2023.0067</arxiv:DOI>
      <arxiv:journal_reference>INFORMS Journal on Computing 0(0). 2024</arxiv:journal_reference>
      <dc:creator>Mike Hewitt, Giovanni Pantuso</dc:creator>
    </item>
    <item>
      <title>Data-Driven Performance Guarantees for Parametric Optimization Problems</title>
      <link>https://arxiv.org/abs/2506.23819</link>
      <description>arXiv:2506.23819v1 Announce Type: new 
Abstract: We propose a data-driven method to establish probabilistic performance guarantees for parametric optimization problems solved via iterative algorithms. Our approach addresses two key challenges: providing convergence guarantees to characterize the worst-case number of iterations required to achieve a predefined tolerance, and upper bounding a performance metric after a fixed number of iterations. These guarantees are particularly useful for online optimization problems with limited computational time, where existing performance guarantees are often unavailable or unduly conservative. We formulate the convergence analysis problem as a scenario optimization program based on a finite set of sampled parameter instances. Leveraging tools from scenario optimization theory enables us to derive probabilistic guarantees on the number of iterations needed to meet a given tolerance level. Using recent advancements in scenario optimization, we further introduce a relaxation approach to trade the number of iterations against the risk of violating convergence criteria thresholds. Additionally, we analyze the trade-off between solution accuracy and time efficiency for fixed-iteration optimization problems by casting them into scenario optimization programs. Numerical simulations demonstrate the efficacy of our approach in providing reliable probabilistic convergence guarantees and evaluating the trade-off between solution accuracy and computational cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23819v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Jingyi Huang, Paul Goulart, Kostas Margellos</dc:creator>
    </item>
    <item>
      <title>Proving the Limited Scalability of Centralized Distributed Optimization via a New Lower Bound Construction</title>
      <link>https://arxiv.org/abs/2506.23836</link>
      <description>arXiv:2506.23836v1 Announce Type: new 
Abstract: We consider centralized distributed optimization in the classical federated learning setup, where $n$ workers jointly find an $\varepsilon$-stationary point of an $L$-smooth, $d$-dimensional nonconvex function $f$, having access only to unbiased stochastic gradients with variance $\sigma^2$. Each worker requires at most $h$ seconds to compute a stochastic gradient, and the communication times from the server to the workers and from the workers to the server are $\tau_{s}$ and $\tau_{w}$ seconds per coordinate, respectively. One of the main motivations for distributed optimization is to achieve scalability with respect to $n$. For instance, it is well known that the distributed version of SGD has a variance-dependent runtime term $\frac{h \sigma^2 L \Delta}{n \varepsilon^2},$ which improves with the number of workers $n,$ where $\Delta = f(x^0) - f^*,$ and $x^0 \in R^d$ is the starting point. Similarly, using unbiased sparsification compressors, it is possible to reduce both the variance-dependent runtime term and the communication runtime term. However, once we account for the communication from the server to the workers $\tau_{s}$, we prove that it becomes infeasible to design a method using unbiased random sparsification compressors that scales both the server-side communication runtime term $\tau_{s} d \frac{L \Delta}{\varepsilon}$ and the variance-dependent runtime term $\frac{h \sigma^2 L \Delta}{\varepsilon^2},$ better than poly-logarithmically in $n$, even in the homogeneous (i.i.d.) case, where all workers access the same distribution. To establish this result, we construct a new "worst-case" function and develop a new lower bound framework that reduces the analysis to the concentration of a random sum, for which we prove a concentration bound. These results reveal fundamental limitations in scaling distributed optimization, even under the homogeneous assumption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23836v1</guid>
      <category>math.OC</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Tyurin</dc:creator>
    </item>
    <item>
      <title>Random Distributionally Robust Optimization under Phi-divergence</title>
      <link>https://arxiv.org/abs/2506.23839</link>
      <description>arXiv:2506.23839v1 Announce Type: new 
Abstract: This paper introduces a novel framework, Random Distributionally Robust Optimization (RDRO), which extends classical Distributionally Robust Optimization (DRO) by allowing the decision variable to be a random variable. We formulate the RDRO problem using a bivariate utility function and $\varphi$-divergence ambiguity sets, enabling a more flexible and realistic treatment of uncertainty. The RDRO framework encompasses a broad range of robust decision-making applications, including portfolio optimization, healthcare resource allocation, and reliable facility location. By optimal transport theory and convex analysis, we characterize key structural properties of the RDRO problem. Our main theoretical contributions include establishing the existence and uniqueness of optimal randomized decisions and proving a duality theorem that links the constrained RDRO formulation to its penalized counterpart. We further propose an efficient numerical scheme that combines the scaling algorithm for unbalanced optimal transport with projected gradient descent, and demonstrate its effectiveness through numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23839v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guohui Guan, Zongxia Liang, Xingjian Ma</dc:creator>
    </item>
    <item>
      <title>Topology optimization of actively moving rigid bodies in unsteady flows</title>
      <link>https://arxiv.org/abs/2506.23895</link>
      <description>arXiv:2506.23895v1 Announce Type: new 
Abstract: This study proposes a novel topology optimization method for unsteady fluid flows induced by actively moving rigid bodies. The key idea of the proposed method is to decouple the design and analysis domains by using separate grids. The design grid undergoes rigid body motion and is then overlapped onto the analysis grid. After the overlap, key quantities such as the Brinkman coefficient are transferred between the grids. This approach provides a direct and efficient means of representing object motion and facilitates the handling of more general and complex movements in unsteady flow conditions. Since the computational cost of solving unsteady fluid problems is substantial, we employ a solver based on the lattice kinetic scheme, which is the extended version of the lattice Boltzmann method, to evaluate the design sensitivity. The fundamental equations are derived, and the accuracy of the design sensitivity calculations is validated through comparison with finite difference approximations. The effectiveness of the method is demonstrated through numerical examples in two-dimensional and three-dimensional settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23895v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuta Tanabe, Kentaro Yaji, Kuniharu Ushijima</dc:creator>
    </item>
    <item>
      <title>Consensus-based optimization for closed-box adversarial attacks and a connection to evolution strategies</title>
      <link>https://arxiv.org/abs/2506.24048</link>
      <description>arXiv:2506.24048v1 Announce Type: new 
Abstract: Consensus-based optimization (CBO) has established itself as an efficient gradient-free optimization scheme, with attractive mathematical properties, such as mean-field convergence results for non-convex loss functions. In this work, we study CBO in the context of closed-box adversarial attacks, which are imperceptible input perturbations that aim to fool a classifier, without accessing its gradient. Our contribution is to establish a connection between the so-called consensus hopping as introduced by Riedl et al. and natural evolution strategies (NES) commonly applied in the context of adversarial attacks and to rigorously relate both methods to gradient-based optimization schemes. Beyond that, we provide a comprehensive experimental study that shows that despite the conceptual similarities, CBO can outperform NES and other evolutionary strategies in certain scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.24048v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tim Roith, Leon Bungert, Philipp Wacker</dc:creator>
    </item>
    <item>
      <title>AutoLyap: A Python package for computer-assisted Lyapunov analyses for first-order methods</title>
      <link>https://arxiv.org/abs/2506.24076</link>
      <description>arXiv:2506.24076v1 Announce Type: new 
Abstract: We introduce AutoLyap, a Python package designed to automate Lyapunov analyses for a wide class of first-order methods for solving structured optimization and inclusion problems. Lyapunov analyses are structured proof patterns, with historical roots in the study of dynamical systems, commonly used to establish convergence results for first-order methods. Building on previous works, the core idea behind AutoLyap is to recast the verification of the existence of a Lyapunov analysis as a semidefinite program (SDP), which can then be solved numerically using standard SDP solvers. Users of the package specify (i)~the class of optimization or inclusion problems, (ii)~the first-order method in question, and (iii)~the type of Lyapunov analysis they wish to test. Once these inputs are provided, AutoLyap handles the SDP modeling and proceeds with the numerical solution of the SDP. We leverage the package to numerically verify and extend several convergence results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.24076v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Manu Upadhyaya, Adrien B. Taylor, Sebastian Banert, Pontus Giselsson</dc:creator>
    </item>
    <item>
      <title>Capacity Planning in Stable Matching with Truthful or Strategic Preference Uncertainty</title>
      <link>https://arxiv.org/abs/2506.22560</link>
      <description>arXiv:2506.22560v1 Announce Type: cross 
Abstract: Recent studies on many-to-one matching markets have explored agents with flexible capacity and truthful preference reporting, focusing on mechanisms that jointly design capacities and select a matching. However, in real-world applications such as school choice and residency matching, preferences are revealed after capacity decisions are made, with matching occurring afterward; uncertainty about agents' preferences must be considered during capacity planning. Moreover, even under strategy-proof mechanisms, agents may strategically misreport preferences based on beliefs about admission chances. We introduce a two-stage stochastic matching problem with uncertain preferences, using school choice as a case study. In the first stage, the clearinghouse expands schools' capacities before observing students' reported preferences. Students either report their true preferences, producing exogenous uncertainty, or act strategically, submitting reported preferences based on their true preferences and admission chances (which depend on capacities), introducing endogenous uncertainty. In the second stage, the clearinghouse computes the student-optimal stable matching based on schools' priorities and students' reported preferences. In strategic cases, endogenous reported preferences are utility-maximizing transformations of capacity decisions and exogenous true preferences; we handle uncertainty using sample average approximation(SAA). We develop behavior-based mathematical formulations and, due to problem complexity, propose Lagrangian- and local-search-based behavior-specific heuristics for near-optimal solutions. Our SAA-based approaches outperform the average scenario approach on students' matching preferences and admission outcomes, emphasizing the impact of stochastic preferences on capacity decisions. Student behavior notably influences capacity design, stressing the need to consider misreports.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22560v1</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Maria Bazotte, Margarida Carvalho, Thibaut Vidal</dc:creator>
    </item>
    <item>
      <title>Adjoint Schr\"odinger Bridge Sampler</title>
      <link>https://arxiv.org/abs/2506.22565</link>
      <description>arXiv:2506.22565v1 Announce Type: cross 
Abstract: Computational methods for learning to sample from the Boltzmann distribution -- where the target distribution is known only up to an unnormalized energy function -- have advanced significantly recently. Due to the lack of explicit target samples, however, prior diffusion-based methods, known as diffusion samplers, often require importance-weighted estimation or complicated learning processes. Both trade off scalability with extensive evaluations of the energy and model, thereby limiting their practical usage. In this work, we propose Adjoint Schr\"odinger Bridge Sampler (ASBS), a new diffusion sampler that employs simple and scalable matching-based objectives yet without the need to estimate target samples during training. ASBS is grounded on a mathematical model -- the Schr\"odinger Bridge -- which enhances sampling efficiency via kinetic-optimal transportation. Through a new lens of stochastic optimal control theory, we demonstrate how SB-based diffusion samplers can be learned at scale via Adjoint Matching and prove convergence to the global solution. Notably, ASBS generalizes the recent Adjoint Sampling (Havens et al., 2025) to arbitrary source distributions by relaxing the so-called memoryless condition that largely restricts the design space. Through extensive experiments, we demonstrate the effectiveness of ASBS on sampling from classical energy functions, amortized conformer generation, and molecular Boltzmann distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22565v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guan-Horng Liu, Jaemoo Choi, Yongxin Chen, Benjamin Kurt Miller, Ricky T. Q. Chen</dc:creator>
    </item>
    <item>
      <title>Deep Hedging to Manage Tail Risk</title>
      <link>https://arxiv.org/abs/2506.22611</link>
      <description>arXiv:2506.22611v1 Announce Type: cross 
Abstract: Extending Buehler et al.'s 2019 Deep Hedging paradigm, we innovatively employ deep neural networks to parameterize convex-risk minimization (CVaR/ES) for the portfolio tail-risk hedging problem. Through comprehensive numerical experiments on crisis-era bootstrap market simulators -- customizable with transaction costs, risk budgets, liquidity constraints, and market impact -- our end-to-end framework not only achieves significant one-day 99% CVaR reduction but also yields practical insights into friction-aware strategy adaptation, demonstrating robustness and operational viability in realistic markets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22611v1</guid>
      <category>q-fin.PM</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>q-fin.CP</category>
      <category>q-fin.RM</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yuming Ma</dc:creator>
    </item>
    <item>
      <title>Hierarchical Modeling and Architecture Optimization: Review and Unified Framework</title>
      <link>https://arxiv.org/abs/2506.22621</link>
      <description>arXiv:2506.22621v1 Announce Type: cross 
Abstract: Simulation-based problems involving mixed-variable inputs frequently feature domains that are hierarchical, conditional, heterogeneous, or tree-structured. These characteristics pose challenges for data representation, modeling, and optimization. This paper reviews extensive literature on these structured input spaces and proposes a unified framework that generalizes existing approaches. In this framework, input variables may be continuous, integer, or categorical. A variable is described as meta if its value governs the presence of other decreed variables, enabling the modeling of conditional and hierarchical structures.
  We further introduce the concept of partially-decreed variables, whose activation depends on contextual conditions. To capture these inter-variable hierarchical relationships, we introduce design space graphs, combining principles from feature modeling and graph theory. This allows the definition of general hierarchical domains suitable for describing complex system architectures. The framework supports the use of surrogate models over such domains and integrates hierarchical kernels and distances for efficient modeling and optimization. The proposed methods are implemented in the open-source Surrogate Modeling Toolbox (SMT 2.0), and their capabilities are demonstrated through applications in Bayesian optimization for complex system design, including a case study in green aircraft architecture.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22621v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Paul Saves, Edward Hall\'e-Hannan, Jasper Bussemaker, Youssef Diouane, Nathalie Bartoli</dc:creator>
    </item>
    <item>
      <title>Momentum-based Accelerated Algorithm for Distributed Optimization under Sector-Bound Nonlinearity</title>
      <link>https://arxiv.org/abs/2506.22855</link>
      <description>arXiv:2506.22855v1 Announce Type: cross 
Abstract: Distributed optimization advances centralized machine learning methods by enabling parallel and decentralized learning processes over a network of computing nodes. This work provides an accelerated consensus-based distributed algorithm for locally non-convex optimization using the gradient-tracking technique. The proposed algorithm (i) improves the convergence rate by adding momentum towards the optimal state using the heavy-ball method, while (ii) addressing general sector-bound nonlinearities over the information-sharing network. The link nonlinearity includes any sign-preserving odd sector-bound mapping, for example, log-scale data quantization or clipping in practical applications. For admissible momentum and gradient-tracking parameters, using perturbation theory and eigen-spectrum analysis, we prove convergence even in the presence of sector-bound nonlinearity and for locally non-convex cost functions. Further, in contrast to most existing weight-stochastic algorithms, we adopt weight-balanced (WB) network design. This WB design and perturbation-based analysis allow to handle dynamic directed network of agents to address possible time-varying setups due to link failures or packet drops.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22855v1</guid>
      <category>eess.SY</category>
      <category>cs.DC</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammadreza Doostmohammadian, Hamid R. Rabiee</dc:creator>
    </item>
    <item>
      <title>Hierarchical Decentralized Stochastic Control for Cyber-Physical Systems</title>
      <link>https://arxiv.org/abs/2506.22971</link>
      <description>arXiv:2506.22971v1 Announce Type: cross 
Abstract: This paper presents a two-timescale hierarchical decentralized architecture for control of Cyber-Physical Systems. The architecture consists of $N$ independent sub-processes, a global controller, and $N$ local controllers, each formulated as a Markov Decision Process (MDP). The global controller, operating at a slower timescale optimizes the infinite-horizon discounted cumulative reward under budget constraints. For the local controllers, operating at a faster timescale, we propose two different optimization frameworks, namely the COpt and FOpt. In the COpt framework, the local controller also optimizes an infinite-horizon MDP, while in the FOpt framework, the local controller optimizes a finite-horizon MDP. The FOpt framework mimics a federal structure, where the local controllers have more autonomy in their decision making. First, the existence of stationary deterministic optimal policies for both these frameworks is established. Then, various relationships between the two frameworks are studied, including a bound on the difference between the two optimal value functions. Additionally, sufficiency conditions are provided such that the two frameworks lead to the same optimal values.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22971v1</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kesav Kazam Ramachandran Anantharaman, Rahul Meshram</dc:creator>
    </item>
    <item>
      <title>Towards a better approach to the Vehicle Routing Problem</title>
      <link>https://arxiv.org/abs/2506.23028</link>
      <description>arXiv:2506.23028v1 Announce Type: cross 
Abstract: The Vehicle Routing Problem (VRP) is a fundamental challenge in logistics management research, given its substantial influence on transportation efficiency, cost minimization, and service quality. As a combinatorial optimization problem, VRP plays a crucial role in a wide range of real world applications, particularly in transportation, logistics, and delivery systems, due to its diverse formulations and numerous extensions. Over the years, researchers have introduced various VRP variants to address specific operational constraints, emerging industry requirements and optimize specific objectives, making it one of the most extensively studied problems in operations research. This article provides a comprehensive overview of VRP by exploring its theoretical foundations, discussing the limitations of its classical model, and introducing its key extensions. By systematically reviewing the diverse constraints, objectives, and variants examined in recent literature, this study aims to contribute to a deeper understanding of VRP while highlighting its ongoing evolution and relevance in modern optimization and decision making processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23028v1</guid>
      <category>cs.CE</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Souad Abdoune, Menouar Boulif</dc:creator>
    </item>
    <item>
      <title>Markov Chains of Evolutionary Games with a Small Number of Players</title>
      <link>https://arxiv.org/abs/2506.23134</link>
      <description>arXiv:2506.23134v1 Announce Type: cross 
Abstract: We construct and study the transition probability matrix of evolutionary games in which the number of players is finite (and relatively small) of such games. We use a simplified version of the population games studied by Sandholm. After laying out a general framework we concentrate on specific examples, involving the Iterated Prisoner's Dilemma, the Iterated Stag Hunt, and the Rock-Paper-Scissors game. Also we consider several revision protocols: Best Response, Pairwise Comparison, Pairwise Proportional Comparison etc. For each of these we explicitly construct the MC transition probability matrix and study its properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23134v1</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Athanasios Kehagias</dc:creator>
    </item>
    <item>
      <title>A notion of BSDE on the Wasserstein space and its applications to control problems and PDEs</title>
      <link>https://arxiv.org/abs/2506.23177</link>
      <description>arXiv:2506.23177v1 Announce Type: cross 
Abstract: We introduce a class of backward stochastic differential equations (BSDEs) on the Wasserstein space of probability measures. This formulation extends the classical correspondence between BSDEs, stochastic control, and partial differential equations (PDEs) to the mean--field (McKean--Vlasov) setting, where the dynamics depend on the law of the state process. The standard BSDE framework becomes inadequate in this context, motivating a new definition in terms of measure--dependent solutions.
  Under suitable assumptions, we demonstrate that this formulation is in correspondence with both mean--field control problems and partial differential equations defined on the Wasserstein space. A comparison principle is established to ensure uniqueness, and existence results are obtained for generators that are linear or quadratic in the $z$--variable. This framework provides a probabilistic approach to control and analysis on the space of probability measures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23177v1</guid>
      <category>math.PR</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mao Fabrice Djete</dc:creator>
    </item>
    <item>
      <title>On the convergence of iterative regularization method assisted by the graph Laplacian with early stopping</title>
      <link>https://arxiv.org/abs/2506.23483</link>
      <description>arXiv:2506.23483v1 Announce Type: cross 
Abstract: We present a data-assisted iterative regularization method for solving ill-posed inverse problems in Hilbert space settings. The proposed approach, termed \texttt{IRMGL+\(\Psi\)}, integrates classical iterative techniques with a data-driven regularization term realized through an iteratively updated graph Laplacian. Our method commences by computing a preliminary solution using any suitable reconstruction method, which then serves as the basis for constructing the initial graph Laplacian. The solution is subsequently refined through an iterative process, where the graph Laplacian is simultaneously recalibrated at each step to effectively capture the evolving structure of the solution. A key innovation of this work lies in the formulation of this iterative scheme and the rigorous justification of the classical discrepancy principle as a reliable early stopping criterion specifically tailored to the proposed method. Under standard assumptions, we establish stability and convergence results for the scheme when the discrepancy principle is applied. Furthermore, we demonstrate the robustness and effectiveness of our method through numerical experiments utilizing four distinct initial reconstructors $\Psi$: the adjoint operator (Adj), filtered back projection (FBP), total variation (TV) denoising, and standard Tikhonov regularization (Tik). It is observed that \texttt{IRMGL+Adj} demonstrates a distinct advantage over the other initializers, producing a robust and stable approximate solution directly from a basic initial reconstruction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23483v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.FA</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Harshit Bajpai, Gaurav Mittal, Ankik Kumar Giri</dc:creator>
    </item>
    <item>
      <title>Both Asymptotic and Non-Asymptotic Convergence of Quasi-Hyperbolic Momentum using Increasing Batch Size</title>
      <link>https://arxiv.org/abs/2506.23544</link>
      <description>arXiv:2506.23544v1 Announce Type: cross 
Abstract: Momentum methods were originally introduced for their superiority to stochastic gradient descent (SGD) in deterministic settings with convex objective functions. However, despite their widespread application to deep neural networks -- a representative case of stochastic nonconvex optimization -- the theoretical justification for their effectiveness in such settings remains limited. Quasi-hyperbolic momentum (QHM) is an algorithm that generalizes various momentum methods and has been studied to better understand the class of momentum-based algorithms as a whole. In this paper, we provide both asymptotic and non-asymptotic convergence results for mini-batch QHM with an increasing batch size. We show that achieving asymptotic convergence requires either a decaying learning rate or an increasing batch size. Since a decaying learning rate adversely affects non-asymptotic convergence, we demonstrate that using mini-batch QHM with an increasing batch size -- without decaying the learning rate -- can be a more effective strategy. Our experiments show that even a finite increase in batch size can provide benefits for training neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23544v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kento Imaizumi, Hideaki Iiduka</dc:creator>
    </item>
    <item>
      <title>Tensor Train Quantum State Tomography using Compressed Sensing</title>
      <link>https://arxiv.org/abs/2506.23560</link>
      <description>arXiv:2506.23560v1 Announce Type: cross 
Abstract: Quantum state tomography (QST) is a fundamental technique for estimating the state of a quantum system from measured data and plays a crucial role in evaluating the performance of quantum devices. However, standard estimation methods become impractical due to the exponential growth of parameters in the state representation. In this work, we address this challenge by parameterizing the state using a low-rank block tensor train decomposition and demonstrate that our approach is both memory- and computationally efficient. This framework applies to a broad class of quantum states that can be well approximated by low-rank decompositions, including pure states, nearly pure states, and ground states of Hamiltonians.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23560v1</guid>
      <category>quant-ph</category>
      <category>cs.AI</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shakir Showkat Sofi, Charlotte Vermeylen, Lieven De Lathauwer</dc:creator>
    </item>
    <item>
      <title>SGD with Adaptive Preconditioning: Unified Analysis and Momentum Acceleration</title>
      <link>https://arxiv.org/abs/2506.23803</link>
      <description>arXiv:2506.23803v1 Announce Type: cross 
Abstract: In this paper, we revisit stochastic gradient descent (SGD) with AdaGrad-type preconditioning. Our contributions are twofold. First, we develop a unified convergence analysis of SGD with adaptive preconditioning under anisotropic or matrix smoothness and noise assumptions. This allows us to recover state-of-the-art convergence results for several popular adaptive gradient methods, including AdaGrad-Norm, AdaGrad, and ASGO/One-sided Shampoo. In addition, we establish the fundamental connection between two recently proposed algorithms, Scion and DASGO, and provide the first theoretical guarantees for the latter. Second, we show that the convergence of methods like AdaGrad and DASGO can be provably accelerated beyond the best-known rates using Nesterov momentum. Consequently, we obtain the first theoretical justification that AdaGrad-type algorithms can simultaneously benefit from both diagonal preconditioning and momentum, which may provide an ultimate explanation for the practical efficiency of Adam.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23803v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dmitry Kovalev</dc:creator>
    </item>
    <item>
      <title>The Jacobian and Hessian of the Kullback-Leibler Divergence between Multivariate Gaussian Distributions (Technical Report)</title>
      <link>https://arxiv.org/abs/2506.23996</link>
      <description>arXiv:2506.23996v1 Announce Type: cross 
Abstract: This document shows how to obtain the Jacobian and Hessian matrices of the Kullback-Leibler divergence between two multivariate Gaussian distributions, using the first and second-order differentials. The presented derivations are based on the theory presented by \cite{magnus99}. I've also got great inspiration from some of the derivations in \cite{minka}.
  Since I pretend to be at most didactic, the document is split into a summary of results and detailed derivations on each of the elements involved, with specific references to the tricks used in the derivations, and to many of the underlying concepts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23996v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Juan Maro\~nas</dc:creator>
    </item>
    <item>
      <title>Data Uniformity Improves Training Efficiency and More, with a Convergence Framework Beyond the NTK Regime</title>
      <link>https://arxiv.org/abs/2506.24120</link>
      <description>arXiv:2506.24120v1 Announce Type: cross 
Abstract: Data selection plays a crucial role in data-driven decision-making, including in large language models (LLMs), and is typically task-dependent. Properties such as data quality and diversity have been extensively studied and are known to enhance model performance. However, it remains unclear whether there exist other quantitative and general principles of data selection that can consistently improve performance, especially for complex tasks with limited prior knowledge. In this paper, we demonstrate that selecting more uniformly distributed data can improve training efficiency while enhancing performance. Specifically, we establish that more uniform (less biased) distribution leads to a larger minimum pairwise distance between data points, denoted by $h_{\min}$, and prove that a smaller $h_{\min}$ can slow down the training dynamics of gradient descent (GD). Moreover, we theoretically show that the approximation error of neural networks decreases as $h_{\min}$ increases. Our analysis introduces a convergence framework for GD beyond the Neural Tangent Kernel (NTK) regime, applicable to a broad class of architectures, including transformers, without requiring Lipschitz smoothness. This framework further provides theoretical justification for the use of residual connections and function compositions in deep neural architectures. In the end, we conduct comprehensive experiments for supervised fine-tuning across various settings, including different optimization strategies, model sizes, and training datasets. The results consistently demonstrate that selecting data by maximizing pairwise distance significantly accelerates training and achieves comparable or better performance in LLMs across diverse datasets. Code and Datasets are available at the link: https://github.com/SafeRL-Lab/data-uniformity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.24120v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuqing Wang, Shangding Gu</dc:creator>
    </item>
    <item>
      <title>Projected gradient descent accumulates at Bouligand stationary points</title>
      <link>https://arxiv.org/abs/2403.02530</link>
      <description>arXiv:2403.02530v3 Announce Type: replace 
Abstract: This paper considers the projected gradient descent (PGD) algorithm for the problem of minimizing a continuously differentiable function on a nonempty closed subset of a Euclidean vector space. Without further assumptions, this problem is intractable and algorithms are only expected to find a stationary point. PGD generates a sequence in the set whose accumulation points are known to be Mordukhovich stationary. In this paper, these accumulation points are proven to be Bouligand stationary, and even proximally stationary if the gradient is locally Lipschitz continuous. These are the strongest stationarity properties that can be expected for the considered problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02530v3</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1137/24M1692782</arxiv:DOI>
      <arxiv:journal_reference>SIAM Journal on Optimization, Vol. 35, Iss. 2 (2025)</arxiv:journal_reference>
      <dc:creator>Guillaume Olikier, Ir\`ene Waldspurger</dc:creator>
    </item>
    <item>
      <title>Technical Report: Pose Graph Optimization over Planar Unit Dual Quaternions: Improved Accuracy with Provably Convergent Riemannian Optimization</title>
      <link>https://arxiv.org/abs/2404.00010</link>
      <description>arXiv:2404.00010v4 Announce Type: replace 
Abstract: It is common in pose graph optimization (PGO) algorithms to assume that noise in the translations and rotations of relative pose measurements is uncorrelated. However, existing work shows that in practice these measurements can be highly correlated, which leads to degradation in the accuracy of PGO solutions that rely on this assumption. Therefore, in this paper we develop a novel algorithm derived from a realistic, correlated model of relative pose uncertainty, and we quantify the resulting improvement in the accuracy of the solutions we obtain relative to state-of-the-art PGO algorithms. Our approach utilizes Riemannian optimization on the planar unit dual quaternion (PUDQ) manifold, and we prove that it converges to first-order stationary points of a Lie-theoretic maximum likelihood objective. Then we show experimentally that, compared to state-of-the-art PGO algorithms, this algorithm produces estimation errors that are lower by 10% to 25% across several orders of magnitude of noise levels and graph sizes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00010v4</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>William D. Warke, J. Humberto Ramos, Prashant Ganesh, Kevin M. Brink, Matthew T. Hale</dc:creator>
    </item>
    <item>
      <title>On the role of semismoothness in nonsmooth numerical analysis: Theory</title>
      <link>https://arxiv.org/abs/2405.14637</link>
      <description>arXiv:2405.14637v2 Announce Type: replace 
Abstract: For the numerical solution of nonsmooth problems, sometimes it is not necessary that an exact subgradient/generalized Jacobian is at our disposal, but it suffices that a semismooth derivative, i.e., a mapping satisfying a certain semismoothness property, is available. In this paper we consider not only semismooth derivatives of single-valued mappings, but also its interplay with the semismoothness$^*$ property for multifunctions. In particular, we are interested in semismooth derivatives of solution maps to parametric semismooth$^*$ inclusions. Our results are expressed in terms of suitable generalized derivatives of the set-valued part, i.e., by limiting coderivatives or by SC (subspace containing) derivatives. Further we show that semismooth derivatives coincide a.e. with generalized Jacobians and state some consequences concerning strict proto-differentiability for semismooth$^*$ multifunctions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14637v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>H. Gfrerer, J. V. Outrata</dc:creator>
    </item>
    <item>
      <title>Optimal Control with $L^{\infty}$ cost: incorporating peak minimization</title>
      <link>https://arxiv.org/abs/2406.05526</link>
      <description>arXiv:2406.05526v3 Announce Type: replace 
Abstract: Inventory and queueing systems are often designed by controlling weighted combination of some time-averaged performance metrics (like cumulative holding, shortage, server-utilization or congestion costs); but real-world constraints, like fixed storage or limited waiting space, require attention to peak levels reached during the operating period.
  This work formulates such control problems, which are any arbitrary weighted combination of some integral cost terms and an L-infinity(peak-level) term. The resultant control problem does not fall into standard control framework, nor does it have standard solution in terms of some partial differential equations. We introduce an auxiliary state variable to track the instantaneous peak-levels, enabling reformulation into the classical framework. We then propose a smooth approximation to handle the resultant discontinuities, and show the existence of unique value function that uniquely solves the corresponding Hamilton-Jacobi-Bellman equation. We apply this framework to two key applications to obtain an optimal design that includes controlling the peak-levels. Surprisingly, the numerical results show peak inventory can be minimized with negligible revenue loss (under 6%); without considering peak-control, the peak levels were significantly higher. The peak-optimal policies for queueing-system can reduce peak-congestion by up to 27%, however, at the expense of higher cumulative-congestion costs. Thus, for inventory-control, the performance of the average-terms did not degrade much, while the same is not true for queueing-system. Hence, one would require a judiciously chosen weighted design of all the costs involved including the peak-levels for any application and such a design can now be derived numerically using the proposed framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05526v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Madhu Dhiman, Veeraruna Kavitha, Nandyala Hemachandra</dc:creator>
    </item>
    <item>
      <title>Almost sure convergence of stochastic Hamiltonian descent methods</title>
      <link>https://arxiv.org/abs/2406.16649</link>
      <description>arXiv:2406.16649v3 Announce Type: replace 
Abstract: Gradient normalization and soft clipping are two popular techniques for tackling instability issues and improving convergence of stochastic gradient descent (SGD) with momentum. In this article, we study these types of methods through the lens of dissipative Hamiltonian systems. Gradient normalization and certain types of soft clipping algorithms can be seen as (stochastic) implicit-explicit Euler discretizations of dissipative Hamiltonian systems, where the kinetic energy function determines the type of clipping that is applied. We make use of dynamical systems theory to show in a unified way that all of these schemes converge to stationary points of the objective function, almost surely, in several different settings: a) for $L$-smooth objective functions, when the variance of the stochastic gradients is possibly infinite, b) under the $(L_0,L_1)$-smoothness assumption, for heavy-tailed noise with bounded variance, and c) for $(L_0,L_1)$-smooth functions in the empirical risk minimization setting, when the variance is possibly infinite but the expectation is finite.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16649v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>M{\aa}ns Williamson, Tony Stillfjord</dc:creator>
    </item>
    <item>
      <title>Generalized Ellipsoids</title>
      <link>https://arxiv.org/abs/2407.20362</link>
      <description>arXiv:2407.20362v2 Announce Type: replace 
Abstract: We introduce a family of symmetric convex bodies called generalized ellipsoids of degree $d$ (GE-$d$s), with ellipsoids corresponding to the case of $d=0$. Generalized ellipsoids (GEs) retain many geometric, algebraic, and algorithmic properties of ellipsoids. We show that the conditions that the parameters of a GE must satisfy can be checked in strongly polynomial time, and that one can search for GEs of a given degree by solving a semidefinite program whose size grows only linearly with dimension. We give an example of a GE which does not have a second-order cone representation, but show that every GE has a semidefinite representation whose size depends linearly on both its dimension and degree. In terms of expressiveness, we prove that for any integer $m\geq 2$, every symmetric full-dimensional polytope with $2m$ facets and every intersection of $m$ co-centered ellipsoids can be represented exactly as a GE-$d$ with $d \leq 2m-3$. Using this result, we show that every symmetric convex body can be approximated arbitrarily well by a GE-$d$ and we quantify the quality of the approximation as a function of the degree $d$. Finally, we present applications of GEs to several areas, such as time-varying portfolio optimization, stability analysis of switched linear systems, robust-to-dynamics optimization, and robust polynomial regression.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.20362v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.AG</category>
      <category>math.NA</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amir Ali Ahmadi, Abraar Chaudhry, Cemil Dibek</dc:creator>
    </item>
    <item>
      <title>Uniqueness Analysis of Controllability Scores and Their Application to Brain Networks</title>
      <link>https://arxiv.org/abs/2408.03023</link>
      <description>arXiv:2408.03023v4 Announce Type: replace 
Abstract: Assessing centrality in network systems is critical for understanding node importance and guiding decision-making processes. In dynamic networks, incorporating a controllability perspective is essential for identifying key nodes. In this paper, we study two control theoretic centrality measures -- the Volumetric Controllability Score (VCS) and Average Energy Controllability Score (AECS) -- to quantify node importance in linear time-invariant network systems. We prove the uniqueness of VCS and AECS for almost all specified terminal times, thereby enhancing their applicability beyond previously recognized cases. This ensures their interpretability, comparability, and reproducibility. Our analysis reveals substantial differences between VCS and AECS in linear systems with symmetric and skew-symmetric transition matrices. We also investigate the dependence of VCS and AECS on the terminal time and prove that when this parameter is extremely small, both scores become essentially uniform. Additionally, we prove that a sequence generated by a projected gradient method for computing VCS and AECS converges linearly to both measures under several assumptions. Finally, evaluations on brain networks modeled via Laplacian dynamics using real data reveal contrasting evaluation tendencies and correlations for VCS and AECS, with AECS favoring brain regions associated with cognitive and motor functions, while VCS emphasizes sensory and emotional regions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.03023v4</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TCNS.2025.3583613</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Control of Network Systems, 2025</arxiv:journal_reference>
      <dc:creator>Kazuhiro Sato, Ryohei Kawamura</dc:creator>
    </item>
    <item>
      <title>New Heuristics for the Operation of an Ambulance Fleet under Uncertainty</title>
      <link>https://arxiv.org/abs/2409.09158</link>
      <description>arXiv:2409.09158v2 Announce Type: replace 
Abstract: The operation of an ambulance fleet involves ambulance selection decisions about which ambulance to dispatch to each emergency, and ambulance reassignment decisions about what each ambulance should do after it has finished the service associated with an emergency. For ambulance selection decisions, we propose four new heuristics: the Best Myopic (BM) heuristic, a NonMyopic (NM) heuristic, and two greedy heuristics (GHP1 and GHP2). Two variants of the greedy heuristics are also considered. We also propose an optimization problem for an extension of the BM heuristic, useful when a call for several patients arrives. For ambulance reassignment decisions, we propose several strategies to choose which emergency in queue to send an ambulance to or which ambulance station to send an ambulance to when it finishes service. These heuristics are also used in a rollout approach: each time a new decision has to be made (when a call arrives or when an ambulance finishes service), a two-stage stochastic program is solved. The proposed heuristics are used to efficiently compute the second stage cost of these problems. We apply the rollout approach with our heuristics to data of the Emergency Medical Service (EMS) of a large city, and show that these methods outperform other heuristics that have been proposed for ambulance dispatch decisions. We also show that better response times can be obtained using the rollout approach instead of using the heuristics without rollout. Moreover, each decision is computed in a few seconds, which allows these methods to be used for the real-time management of a fleet of ambulances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.09158v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vincent Guigues, Anton J. Kleywegt, Victor Hugo Nascimento</dc:creator>
    </item>
    <item>
      <title>Neural Operators for Adaptive Control of Freeway Traffic</title>
      <link>https://arxiv.org/abs/2410.20708</link>
      <description>arXiv:2410.20708v2 Announce Type: replace 
Abstract: Uncertainty and delayed reactions in human driving behavior lead to stop-and-go traffic congestion on freeways. The freeway traffic dynamics are governed by the Aw-Rascle-Zhang (ARZ) traffic Partial Differential Equation (PDE) models with unknown relaxation time. Motivated by the adaptive traffic control problem, this paper presents a neural operator (NO) based adaptive boundary control design for the coupled 2$\times$2 hyperbolic systems with uncertain spatially varying in-domain coefficients and boundary parameter. In traditional adaptive control for PDEs, solving backstepping kernel online is computationally intensive, as it requires significant resources at each time step to update the estimation of coefficients. To address this challenge, we use operator learning, i.e. DeepONet, to learn the mapping from system parameters to the kernels functions. DeepONet, a class of deep neural networks designed for approximating operators, has shown strong potential for approximating PDE backstepping designs in recent studies. Unlike previous works that focus on approximating single kernel equation associated with the scalar PDE system, we extend this framework to approximate PDE kernels for a class of the first-order coupled 2$\times$2 hyperbolic kernel equations. Our approach demonstrates that DeepONet is nearly two orders of magnitude faster than traditional PDE solvers for generating kernel functions, while maintaining a loss on the order of $10^{-3}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20708v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kaijing Lv, Junmin Wang, Yihuai Zhang, Huan Yu</dc:creator>
    </item>
    <item>
      <title>Univariate representations of solutions to generic polynomial complementarity problems</title>
      <link>https://arxiv.org/abs/2410.21810</link>
      <description>arXiv:2410.21810v3 Announce Type: replace 
Abstract: By using the squared slack variables technique, we demonstrate that the solution set of a general polynomial complementarity problem is the image, under a specific projection, of the set of real zeroes of a system of polynomials. This paper points out that, generically, this polynomial system has finitely many complex zeroes. In such a case, we use symbolic computation techniques to compute a univariate representation of the solution set. Consequently, univariate representations of special solutions, such as least-norm and sparse solutions, are obtained. After that, enumerating solutions boils down to solving problems governed by univariate polynomials. We also provide some experiments on small-scale problems with worst-case scenarios. At the end of the paper, we propose a method for computing approximate solutions to copositive polynomial complementarity problems that may have infinitely many solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21810v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vu Trung Hieu, Alfredo Noel Iusem, Paul Hugo Schm\"olling, Akiko Takeda</dc:creator>
    </item>
    <item>
      <title>A Three-Operator Splitting Scheme Derived from Three-Block ADMM</title>
      <link>https://arxiv.org/abs/2411.00166</link>
      <description>arXiv:2411.00166v2 Announce Type: replace 
Abstract: This work presents a new three-operator splitting method to handle monotone inclusion and convex optimization problems. The proposed splitting serves as another natural extension of the Douglas-Rachford splitting technique to problems involving three operators. For solving a composite convex minimization of a sum of three functions, its formula resembles but is different from Davis-Yin splitting and the dual formulation of the classical three-block ADMM. Numerical tests suggest that such a splitting scheme is robust in the sense of allowing larger step sizes. When two functions have orthogonal domains, the splitting operator can be proven 1/2-averaged, which implies convergence of the iteration scheme using any positive step size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00166v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anshika Anshika, Jiaxing Li, Debdas Ghosh, Xiangxiong Zhang</dc:creator>
    </item>
    <item>
      <title>Uniform-in-time mean-field limit estimate for the Consensus-Based Optimization</title>
      <link>https://arxiv.org/abs/2411.03986</link>
      <description>arXiv:2411.03986v2 Announce Type: replace 
Abstract: We establish a uniform-in-time estimate for the mean-field convergence of the Consensus-Based Optimization (CBO) algorithm by rescaling the consensus point in the dynamics with a small parameter $\kappa \in (0,1)$. This uniform-in-time estimate is essential, as CBO convergence relies on a sufficiently large time horizon and is crucial for ensuring stable, reliable long-term convergence, the latter being key to the practical effectiveness of CBO methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03986v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hui Huang, Hicham Kouhkouh</dc:creator>
    </item>
    <item>
      <title>Linear Convergence of the Proximal Gradient Method for Composite Optimization Under the Polyak-{\L}ojasiewicz Inequality and Its Variant</title>
      <link>https://arxiv.org/abs/2411.11628</link>
      <description>arXiv:2411.11628v2 Announce Type: replace 
Abstract: We study the linear convergence rates of the proximal gradient method for composite functions satisfying two classes of Polyak-{\L}ojasiewicz (PL) inequality: the PL inequality, the variant of PL inequality defined by the proximal map-based residual. Using the performance estimation problem, we either provide new explicit linear convergence rates or improve existing complexity bounds for minimizing composite functions under the two classes of PL inequality. Finally, we illustrate numerically the effects of our theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11628v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qingyuan Kong, Rujun Jiang, Yihan He</dc:creator>
    </item>
    <item>
      <title>Identifying Self-Amplifying Hypergraph Structures through Mathematical Optimization</title>
      <link>https://arxiv.org/abs/2412.15776</link>
      <description>arXiv:2412.15776v2 Announce Type: replace 
Abstract: In this paper, we introduce the concept of self-amplifying structures for hypergraphs, positioning it as a key element for understanding propagation and internal reinforcement in complex systems. To quantify this phenomenon, we define the maximal amplification factor, a metric that captures how effectively a subhypergraph contributes to its own amplification. We then develop an optimization-based methodology to compute this measure. Building on this foundation, we tackle the problem of identifying the subhypergraph maximizing the amplification factor, formulating it as a mixed-integer nonlinear programming (MINLP) problem. To solve it efficiently, we propose an exact iterative algorithm with proven convergence guarantees. In addition, we report the results of extensive computational experiments on realistic synthetic instances, demonstrating both the relevance and effectiveness of the proposed approach. Finally, we present a case study on chemical reaction networks, including the Formose reaction and E. coli core metabolism, where our framework successfully identifies known and novel autocatalytic subnetworks, highlighting its practical relevance to systems chemistry and biology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.15776v2</guid>
      <category>math.OC</category>
      <category>cs.CE</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>V\'ictor Blanco, Gabriel Gonz\'alez, Praful Gagrani</dc:creator>
    </item>
    <item>
      <title>Optimal Control of the Navier-Stokes equations via Pressure Boundary Conditions</title>
      <link>https://arxiv.org/abs/2501.04548</link>
      <description>arXiv:2501.04548v2 Announce Type: replace 
Abstract: In this work we study an optimal control problem subject to the instationary Navier-Stokes equations, where the control enters via an inhomogeneous Neumann/Do-Nothing boundary condition. Despite the Navier-Stokes equations with these boundary conditions not being well-posed for large times and/or data, we obtain wellposedness of the optimal control problem by choosing a proper tracking type term. In order to discuss the regularity of the optimal control, state and adjoint state, we present new results on $L^2(I;H^2(\Omega))$ regularity of solutions to a Stokes problem with mixed inhomogeneous boundary conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04548v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Boris Vexler, Jakob Wagner</dc:creator>
    </item>
    <item>
      <title>Controlled Invariance in Fully Actuated Max-plus Linear Systems with Precedence Semimodules</title>
      <link>https://arxiv.org/abs/2503.03357</link>
      <description>arXiv:2503.03357v3 Announce Type: replace 
Abstract: Given a max-plus linear system and a semimodule, the problem of computing the maximal controlled invariant subsemimodule is still open to this day. In this paper, we consider this problem for the specific class of fully actuated systems and constraints in the form of precedence semimodules. The assumption of full actuation corresponds to the existence of an input for each component of the system state. A precedence semimodule is the set of solutions of inequalities typically used to represent time-window constraints. We prove that, in this setting, it is possible to (i) compute the maximal controlled invariant subsemimodule and (ii) decide the convergence of a fixed-point algorithm introduced by R.D. Katz in strongly polynomial time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03357v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Davide Zorzenon, J\"org Raisch</dc:creator>
    </item>
    <item>
      <title>The latent variable proximal point algorithm for variational problems with inequality constraints</title>
      <link>https://arxiv.org/abs/2503.05672</link>
      <description>arXiv:2503.05672v2 Announce Type: replace 
Abstract: The latent variable proximal point (LVPP) algorithm is a framework for solving infinite-dimensional variational problems with pointwise inequality constraints. The algorithm is a saddle point reformulation of the Bregman proximal point algorithm. At the continuous level, the two formulations are equivalent, but the saddle point formulation is more amenable to discretization because it introduces a structure-preserving transformation between a latent function space and the feasible set. Working in this latent space is much more convenient for enforcing inequality constraints than the feasible set, as discretizations can employ general linear combinations of suitable basis functions, and nonlinear solvers can involve general additive updates. LVPP yields numerical methods with observed mesh-independence for obstacle problems, contact, fracture, plasticity, and others besides; in many cases, for the first time. The framework also extends to more complex constraints, providing means to enforce convexity in the Monge--Amp\`ere equation and handling quasi-variational inequalities, where the underlying constraint depends implicitly on the unknown solution. In this paper, we describe the LVPP algorithm in a general form and apply it to ten problems from across mathematics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05672v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>J{\o}rgen S. Dokken, Patrick E. Farrell, Brendan Keith, Ioannis P. A. Papadopoulos, Thomas M. Surowiec</dc:creator>
    </item>
    <item>
      <title>Are Convex Optimization Curves Convex?</title>
      <link>https://arxiv.org/abs/2503.10138</link>
      <description>arXiv:2503.10138v3 Announce Type: replace 
Abstract: In this paper, we study when we might expect the optimization curve induced by gradient descent to be \emph{convex} -- precluding, for example, an initial plateau followed by a sharp decrease, making it difficult to decide when optimization should stop. Although such undesirable behavior can certainly occur when optimizing general functions, might it also occur in the benign and well-studied case of smooth convex functions? As far as we know, this question has not been tackled in previous work. We show, perhaps surprisingly, that the answer crucially depends on the choice of the step size. In particular, for the range of step sizes which are known to result in monotonic convergence to an optimal value, we characterize a regime where the optimization curve will be provably convex, and a regime where the curve can be non-convex. We also extend our results to gradient flow, and to the closely-related but different question of whether the gradient norm decreases monotonically.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10138v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guy Barzilai, Ohad Shamir, Moslem Zamani</dc:creator>
    </item>
    <item>
      <title>Modular Distributed Nonconvex Learning with Error Feedback</title>
      <link>https://arxiv.org/abs/2503.14055</link>
      <description>arXiv:2503.14055v2 Announce Type: replace 
Abstract: In this paper, we design a novel distributed learning algorithm using stochastic compressed communications. In detail, we pursue a modular approach, merging ADMM and a gradient-based approach, benefiting from the robustness of the former and the computational efficiency of the latter. Additionally, we integrate a stochastic integral action (error feedback) enabling almost sure rejection of the compression error. We analyze the resulting method in nonconvex scenarios and guarantee almost sure asymptotic convergence to the set of stationary points of the problem. This result is obtained using system-theoretic tools based on stochastic timescale separation. We corroborate our findings with numerical simulations in nonconvex classification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14055v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/LCSYS.2025.3582677</arxiv:DOI>
      <dc:creator>Guido Carnevale, Nicola Bastianello</dc:creator>
    </item>
    <item>
      <title>Relative portfolio optimization via a value at risk based constraint</title>
      <link>https://arxiv.org/abs/2503.20340</link>
      <description>arXiv:2503.20340v2 Announce Type: replace 
Abstract: In this paper, we consider $n$ agents who invest in a general financial market that is free of arbitrage and complete. The aim of each investor is to maximize her expected utility while ensuring, with a specified probability, that her terminal wealth exceeds a benchmark defined by her competitors' performance. This setup introduces an interdependence between agents, leading to a search for Nash equilibria. In the case of two agents and CRRA utility, we are able to derive all Nash equilibria in terms of terminal wealth. For $n&gt;2$ agents and logarithmic utility we distinguish two cases. In the first case, the probabilities in the constraint are small and we can characterize all Nash equilibria. In the second case, the probabilities are larger and we look for Nash equilibria in a certain set. We also discuss the impact of the competition using some numerical examples. As a by-product, we solve some portfolio optimization problems with probability constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.20340v2</guid>
      <category>math.OC</category>
      <category>q-fin.MF</category>
      <category>q-fin.PM</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicole B\"auerle, Tamara G\"oll</dc:creator>
    </item>
    <item>
      <title>Convergence rates for polynomial optimization on set products</title>
      <link>https://arxiv.org/abs/2505.18580</link>
      <description>arXiv:2505.18580v2 Announce Type: replace 
Abstract: We consider polynomial optimization problems on Cartesian products of basic compact semialgebraic sets. The solution of such problems can be approximated as closely as desired by hierarchies of semidefinite programming relaxations, based on classical sums of squares certificates due to Putinar and Schm\"udgen. When the feasible set is the bi-sphere, i.e., the Cartesian product of two unit spheres, we show that the hierarchies based on the Schm\"udgen-type certificates converge to the global minimum of the objective polynomial at a rate in $O(1/t^2)$, where $t$ is the relaxation order. Our proof is based on the polynomial kernel method. We extend this result to arbitrary sphere products and give a general recipe to obtain convergence rates for polynomial optimization over products of distinct sets. Eventually, we rely on our results for the bi-sphere to analyze the speed of convergence of a semidefinite programming hierarchy approximating the order $2$ quantum Wasserstein distance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18580v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Victor Magron</dc:creator>
    </item>
    <item>
      <title>A Global Coordinate-Free Approach to Invariant Contraction on Homogeneous Manifolds</title>
      <link>https://arxiv.org/abs/2410.15441</link>
      <description>arXiv:2410.15441v2 Announce Type: replace-cross 
Abstract: In this work, we provide a global condition for contraction with respect to an invariant Riemannian metric on reductive homogeneous spaces. Using left-invariant frames, vector fields on the manifold are horizontally lifted to the ambient Lie group, where the Levi-Civita connection is globally characterized as a real matrix multiplication. By linearizing in these left-invariant frames, we characterize contraction using matrix measures on real square matrices, avoiding the use of local charts. Applying this global condition, we provide a necessary condition for a prescribed subset of the manifold to possibly admit a contracting system, which accounts for the underlying geometry of the invariant metric. Applied to the sphere, this condition implies that no great circle can be contained in a contraction region. Finally, we apply our results to compute reachable sets for an attitude control problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15441v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Akash Harapanahalli, Samuel Coogan</dc:creator>
    </item>
    <item>
      <title>The Oracle Complexity of Simplex-based Matrix Games: Linear Separability and Nash Equilibria</title>
      <link>https://arxiv.org/abs/2412.06990</link>
      <description>arXiv:2412.06990v2 Announce Type: replace-cross 
Abstract: We study the problem of solving matrix games of the form $\max_{\mathbf{w}\in\mathcal{W}}\min_{\mathbf{p}\in\Delta}\mathbf{p}^{\top}A\mathbf{w}$, where $A$ is some matrix and $\Delta$ is the probability simplex. This problem encapsulates canonical tasks such as finding a linear separator and computing Nash equilibria in zero-sum games. However, perhaps surprisingly, its inherent complexity (as formalized in the standard framework of oracle complexity [Nemirovski and Yudin, 1983]) is not well-understood. In this work, we first identify different oracle models which are implicitly used by prior algorithms, amounting to multiplying the matrix $A$ by a vector from either one or both sides. We then prove complexity lower bounds for algorithms under both access models, which in particular imply a separation between them. Specifically, we start by showing that algorithms for linear separability based on one-sided multiplications must require $\Omega(\gamma_A^{-2})$ iterations, where $\gamma_A$ is the margin, as matched by the Perceptron algorithm. We then prove that accelerated algorithms for this task, which utilize multiplications from both sides, must require $\tilde{\Omega}(\gamma_{A}^{-2/3})$ iterations, establishing the first oracle complexity barrier for such algorithms. Finally, by adapting our lower bound to $\ell_1$ geometry, we prove that computing an $\epsilon$-approximate Nash equilibrium requires $\tilde{\Omega}(\epsilon^{-2/5})$ iterations, which is an exponential improvement over the previously best-known lower bound due to Hadiji et al. [2024].</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06990v2</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guy Kornowski, Ohad Shamir</dc:creator>
    </item>
    <item>
      <title>A behavioral approach for LPV data-driven representations</title>
      <link>https://arxiv.org/abs/2412.18543</link>
      <description>arXiv:2412.18543v2 Announce Type: replace-cross 
Abstract: In this paper, we present a data-driven representation for linear parameter-varying (LPV) systems, which can be used for direct data-driven analysis and control of such systems. Specifically, we use the behavioral approach to develop a data-driven representation of the finite-horizon behavior of LPV systems for which there exists a kernel representation with shifted-affine scheduling dependence. Moreover, we provide a necessary and sufficient rank-based test on the available data that concludes whether the data fully represents the finite-horizon LPV behavior. Using the proposed data-driven representation, we also solve the data-driven simulation problem for LPV systems. Through multiple examples, we demonstrate that the results in this paper allow us to formulate a novel set of direct data-driven analysis and control methods for LPV systems, which are also applicable for LPV embeddings of nonlinear systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.18543v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Chris Verhoek, Ivan Markovsky, Sofie Haesaert, Roland T\'oth</dc:creator>
    </item>
    <item>
      <title>On the Convergence of Min-Max Langevin Dynamics and Algorithm</title>
      <link>https://arxiv.org/abs/2412.20471</link>
      <description>arXiv:2412.20471v3 Announce Type: replace-cross 
Abstract: We study zero-sum games in the space of probability distributions over the Euclidean space $\mathbb{R}^d$ with entropy regularization, in the setting when the interaction function between the players is smooth and strongly convex-strongly concave. We prove an exponential convergence guarantee for the mean-field min-max Langevin dynamics to compute the equilibrium distribution of the zero-sum game. We also study the finite-particle approximation of the mean-field min-max Langevin dynamics, both in continuous and discrete times. We prove biased convergence guarantees for the continuous-time finite-particle min-max Langevin dynamics to the stationary mean-field equilibrium distribution with an explicit bias term which does not scale with the number of particles. We also prove biased convergence guarantees for the discrete-time finite-particle min-max Langevin algorithm to the stationary mean-field equilibrium distribution with an additional bias term which scales with the step size and the number of particles. This provides an explicit iteration complexity for the average particle along the finite-particle algorithm to approximately compute the equilibrium distribution of the zero-sum game.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20471v3</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yang Cai, Siddharth Mitra, Xiuyuan Wang, Andre Wibisono</dc:creator>
    </item>
    <item>
      <title>Faster Convergence of Riemannian Stochastic Gradient Descent with Increasing Batch Size</title>
      <link>https://arxiv.org/abs/2501.18164</link>
      <description>arXiv:2501.18164v2 Announce Type: replace-cross 
Abstract: We have theoretically analyzed the use of Riemannian stochastic gradient descent (RSGD) and found that using an increasing batch size leads to faster RSGD convergence rate than using a constant batch size not only with a constant learning rate but also with a decaying learning rate, such as cosine annealing decay and polynomial decay. The convergence rate of RSGD improves from $O(\sqrt{T^{-1}+\text{const.}})$ with a constant batch size to $O(T^{-\frac{1}{2}})$ with an increasing batch size, where $T$ denotes the number of iterations. Using principal component analysis and low-rank matrix completion tasks, we investigated, both theoretically and numerically, how increasing batch size affects computational time as measured by stochastic first-order oracle (SFO) complexity. Increasing batch size reduces the SFO complexity of RSGD. Furthermore, our numerical results demonstrated that increasing batch size offers the advantages of both small and large constant batch sizes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18164v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kanata Oowada, Hideaki Iiduka</dc:creator>
    </item>
    <item>
      <title>Time to Rethink AI for Combinatorial Optimization: Classical Algorithms Remain Tough to Match</title>
      <link>https://arxiv.org/abs/2502.03669</link>
      <description>arXiv:2502.03669v2 Announce Type: replace-cross 
Abstract: This position paper argues that the machine learning community should fundamentally rethink how AI-inspired methods are developed and evaluated for combinatorial optimization (CO). We present comprehensive empirical benchmarks comparing various recent AI-inspired GPU-based methods with several classical CPU-based solvers on the Maximum Independent Set (MIS) problem. Strikingly, even on in-distribution random graphs, leading AI-inspired methods are consistently outperformed by the state-of-the-art classical solver KaMIS, and some AI-inspired methods frequently fail to surpass even the simplest degree-based greedy heuristic. To better understand the source of these failures, we introduce a novel analysis, serialization, which reveals that non-backtracking AI methods, such as LTFT (based on GFlowNets), end up reasoning similarly to the simplest degree-based greedy heuristic, and thus worse than KaMIS.
  Our findings reveal three core issues: (1) Limited benchmarks and evaluation - AI-inspired methods are often tested only on small instances with very limited inference time, which covers up issues with scalability and resource usage; (2) Intrinsic hardness and learning limits - even under ideal, in-distribution conditions, learning-based approaches lag behind classical heuristics, highlighting inherent barriers that receive little attention; and (3) Insufficient use and understanding of classical heuristics - current learning frameworks often neglect to incorporate effective classical techniques.
  Although we use MIS as a testbed, similar gaps and challenges have been reported in other combinatorial optimization problems, suggesting broader relevance for our recommendations. We propose that future research must address these issues by rigorous benchmarking, deepening understanding of learning limitations, and integrating classical heuristics into AI-inspired methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03669v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DM</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yikai Wu, Haoyu Zhao, Sanjeev Arora</dc:creator>
    </item>
    <item>
      <title>Mixing Time of the Proximal Sampler in Relative Fisher Information via Strong Data Processing Inequality</title>
      <link>https://arxiv.org/abs/2502.05623</link>
      <description>arXiv:2502.05623v2 Announce Type: replace-cross 
Abstract: We study the mixing time guarantee for sampling in relative Fisher information via the Proximal Sampler algorithm, which is an approximate proximal discretization of the Langevin dynamics. We show that when the target probability distribution is strongly log-concave, the relative Fisher information converges exponentially fast along the Proximal Sampler; this matches the exponential convergence rate of the relative Fisher information along the continuous-time Langevin dynamics for strongly log-concave target. When combined with a standard implementation of the Proximal Sampler via rejection sampling, this exponential convergence rate provides a high-accuracy iteration complexity guarantee for the Proximal Sampler in relative Fisher information when the target distribution is strongly log-concave and log-smooth. Our proof proceeds by establishing a strong data processing inequality for relative Fisher information along the Gaussian channel under strong log-concavity, and a data processing inequality along the reverse Gaussian channel for a special distribution. The forward and reverse Gaussian channels compose to form the Proximal Sampler, and these data processing inequalities imply the exponential convergence rate of the relative Fisher information along the Proximal Sampler.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05623v2</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andre Wibisono</dc:creator>
    </item>
    <item>
      <title>DGSAM: Domain Generalization via Individual Sharpness-Aware Minimization</title>
      <link>https://arxiv.org/abs/2503.23430</link>
      <description>arXiv:2503.23430v2 Announce Type: replace-cross 
Abstract: Domain generalization (DG) aims to learn models that perform well on unseen target domains by training on multiple source domains. Sharpness-Aware Minimization (SAM), known for finding flat minima that improve generalization, has therefore been widely adopted in DG. However, our analysis reveals that SAM in DG may converge to \textit{fake flat minima}, where the total loss surface appears flat in terms of global sharpness but remains sharp with respect to individual source domains. To understand this phenomenon more precisely, we formalize the average worst-case domain risk as the maximum loss under domain distribution shifts within a bounded divergence, and derive a generalization bound that reveals the limitations of global sharpness-aware minimization. In contrast, we show that individual sharpness provides a valid upper bound on this risk, making it a more suitable proxy for robust domain generalization. Motivated by these insights, we shift the DG paradigm toward minimizing individual sharpness across source domains. We propose \textit{Decreased-overhead Gradual SAM (DGSAM)}, which applies gradual domain-wise perturbations in a computationally efficient manner to consistently reduce individual sharpness. Extensive experiments demonstrate that DGSAM not only improves average accuracy but also reduces performance variance across domains, while incurring less computational overhead than SAM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23430v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.AP</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Youngjun Song, Youngsik Hwang, Jonghun Lee, Heechang Lee, Dong-Young Lim</dc:creator>
    </item>
    <item>
      <title>The Ces\`aro Value Iteration</title>
      <link>https://arxiv.org/abs/2504.04889</link>
      <description>arXiv:2504.04889v3 Announce Type: replace-cross 
Abstract: In this paper, we consider undiscouted infinitehorizon optimal control for deterministic systems with an uncountable state and input space. We specifically address the case when the classic value iteration does not converge. For such systems, we use the Ces`aro mean to define the infinite-horizon optimal control problem and the corresponding infinite-horizon value function. Moreover, for this value function, we introduce the Ces\`aro value iteration and prove its convergence for the special case of systems with periodic optimal operating behavior. For this instance, we also show that the Ces\`aro value function recovers the undiscounted infinite-horizon optimal cost, if the latter is well-defined.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04889v3</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jonas Mair, Lukas Schwenkel, Matthias A. M\"uller, Frank Allg\"ower</dc:creator>
    </item>
    <item>
      <title>Controlling Complex Systems</title>
      <link>https://arxiv.org/abs/2504.07579</link>
      <description>arXiv:2504.07579v2 Announce Type: replace-cross 
Abstract: This chapter provides a comprehensive overview of controlling collective behavior in complex systems comprising large ensembles of interacting dynamical agents. Building upon traditional control theory's foundation in individual systems, we introduce tools designed to address the unique challenges of coordinating networks that exhibit emergent phenomena, including consensus, synchronization, and pattern formation. We analyze how local agent interactions generate macroscopic behaviors and investigate the fundamental role of network topology in determining system dynamics. Inspired by natural systems, we emphasize control strategies that achieve global coordination through localized interventions while considering practical implementation challenges. The chapter concludes by presenting novel frameworks for managing very large agent ensembles and leveraging interacting networks for control purposes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.07579v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1016/B978-0-443-14081-5.00167-7</arxiv:DOI>
      <dc:creator>Marco Coraggio, Davide Salzano, Mario di Bernardo</dc:creator>
    </item>
    <item>
      <title>A Formal Analysis of Algorithms for Matroids and Greedoids</title>
      <link>https://arxiv.org/abs/2505.19816</link>
      <description>arXiv:2505.19816v2 Announce Type: replace-cross 
Abstract: We present a formal analysis, in Isabelle/HOL, of optimisation algorithms for matroids, which are useful generalisations of combinatorial structures that occur in optimisation, and greedoids, which are a generalisation of matroids. Although some formalisation work has been done earlier on matroids, our work here presents the first formalisation of results on greedoids, and many results we formalise in relation to matroids are also formalised for the first time in this work. We formalise the analysis of a number of optimisation algorithms for matroids and greedoids. We also derive from those algorithms executable implementations of Kruskal's algorithm for minimum spanning trees, an algorithm for maximum cardinality matching for bi-partite graphs, and Prim's algorithm for computing minimum weight spanning trees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19816v2</guid>
      <category>cs.LO</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad Abdulaziz, Thomas Ammer, Shriya Meenakshisundaram, Adem Rimpapa</dc:creator>
    </item>
    <item>
      <title>Global Convergence of Iteratively Reweighted Least Squares for Robust Subspace Recovery</title>
      <link>https://arxiv.org/abs/2506.20533</link>
      <description>arXiv:2506.20533v2 Announce Type: replace-cross 
Abstract: Robust subspace estimation is fundamental to many machine learning and data analysis tasks. Iteratively Reweighted Least Squares (IRLS) is an elegant and empirically effective approach to this problem, yet its theoretical properties remain poorly understood. This paper establishes that, under deterministic conditions, a variant of IRLS with dynamic smoothing regularization converges linearly to the underlying subspace from any initialization. We extend these guarantees to affine subspace estimation, a setting that lacks prior recovery theory. Additionally, we illustrate the practical benefits of IRLS through an application to low-dimensional neural network training. Our results provide the first global convergence guarantees for IRLS in robust subspace recovery and, more broadly, for nonconvex IRLS on a Riemannian manifold.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.20533v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gilad Lerman, Kang Li, Tyler Maunu, Teng Zhang</dc:creator>
    </item>
  </channel>
</rss>
