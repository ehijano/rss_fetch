<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>eess.SP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/eess.SP</link>
    <description>eess.SP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/eess.SP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 26 May 2025 04:00:09 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Interference Modulation: A Novel Technique for Low-Rate and Power Efficient Multiple Access</title>
      <link>https://arxiv.org/abs/2505.17526</link>
      <description>arXiv:2505.17526v1 Announce Type: new 
Abstract: The majority of spatial signal processing techniques focus on increasing the total system capacity and providing high data rates for intended user(s). Unlike the existing studies, this paper introduces a novel interference modulation method that exploits the correlation between wireless channels to enable low-data-rate transmission towards additional users with a minimal power allocation. The proposed method changes the interference power at specific channels to modulate a low-rate on-off keying signal. This is achieved by appropriately setting the radiation pattern of front-end components of a transmitter, i.e., analog beamforming weights or metasurface configuration. The paper investigates theoretical performance limits and analyzes the efficiency in terms of sum rate. Bit error rate simulation results are closely matched with theoretical findings. The initial findings indicate that the proposed technique can be instrumental in providing reduced capability communication using minimal power consumption in 6G networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.17526v1</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>M. Yaser Yagan, Ali E. Pusane, Ali Gorcin, Ibrahim Hokelek</dc:creator>
    </item>
    <item>
      <title>GPS-Aided Deep Learning for Beam Prediction and Tracking in UAV mmWave Communication</title>
      <link>https://arxiv.org/abs/2505.17530</link>
      <description>arXiv:2505.17530v1 Announce Type: new 
Abstract: Millimeter-wave (mmWave) communication enables high data rates for cellular-connected Unmanned Aerial Vehicles (UAVs). However, a robust beam management remains challenging due to significant path loss and the dynamic mobility of UAVs, which can destabilize the UAV-base station (BS) link. This research presents a GPS-aided deep learning (DL) model that simultaneously predicts current and future optimal beams for UAV mmWave communications, maintaining a Top-1 prediction accuracy exceeding 70% and an average power loss below 0.6 dB across all prediction steps. These outcomes stem from a proposed data set splitting method ensuring balanced label distribution, paired with a GPS preprocessing technique that extracts key positional features, and a DL architecture that maps sequential position data to beam index predictions. The model reduces overhead by approximately 93% (requiring the training of 2 ~ 3 beams instead of 32 beams) with 95% beam prediction accuracy guarantees, and ensures 94% to 96% of predictions exhibit mean power loss not exceeding 1 dB.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.17530v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Vendi Ardianto Nugroho, Byung Moo Lee</dc:creator>
    </item>
    <item>
      <title>LLM4SP: Large Language Models for Scatterer Prediction via Synesthesia of Machines</title>
      <link>https://arxiv.org/abs/2505.17879</link>
      <description>arXiv:2505.17879v1 Announce Type: new 
Abstract: Guided by Synesthesia of Machines (SoM), the nonlinear mapping relationship between sensory and communication information serves as a powerful tool to enhance both the accuracy and generalization of vehicle-to-vehicle (V2V) multi-modal intelligent channel modeling (MMICM) in intelligent transportation systems (ITSs). To explore the general mapping relationship between physical environment and electromagnetic space, a new intelligent sensing-communication integration dataset, named V2V-M3, is constructed for multiple scenarios in V2V communications with multiple frequency bands and multiple vehicular traffic densities (VTDs). Leveraging the strong representation and cross-modal inference capabilities of large language models (LLMs), a novel LLM-based method for Scatterer Prediction (LLM4SP) from light detection and ranging (LiDAR) point clouds is developed. To address the inherent and significant differences across multi-modal data, synergistically optimized four-module architecture, i.e., preprocessor, embedding, backbone, and output modules, are designed by considering the sensing/channel characteristics and electromagnetic propagation mechanism. On the basis of cross-modal representation alignment and positional encoding, the network of LLM4SP is fine-tuned to capture the general mapping relationship between LiDAR point clouds and scatterers. Simulation results demonstrate that the proposed LLM4SP achieves superior performance in full-sample and generalization testing, significantly outperforming small models across different frequency bands, scenarios, and VTDs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.17879v1</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zengrui Han, Lu Bai, Ziwei Huang, Xiang Cheng</dc:creator>
    </item>
    <item>
      <title>Faulty RIS-aided Integrated Sensing and Communication: Modeling and Optimization</title>
      <link>https://arxiv.org/abs/2505.17970</link>
      <description>arXiv:2505.17970v1 Announce Type: new 
Abstract: This work investigates a practical reconfigurable intelligent surface (RIS)-aided integrated sensing and communication (ISAC) system, where a subset of RIS elements fail to function properly and reflect incident signals randomly towards unintended directions, thereby degrading system performance. To date, no study has addressed such impairments caused by faulty RIS elements in ISAC systems. This work aims to fill the gap. First, to quantify the impact of faulty elements on ISAC performance, we derive the misspecified Cram\'er-Rao bound (MCRB) for sensing parameter estimation and signal-to-interference-and-noise ratio (SINR) for communication quality. Then, to mitigate the performance loss caused by faulty elements, we jointly design the remaining functional RIS phase shifts and transmit beamforming to minimize the MCRB, subject to the communication SINR and transmit power constraints. The resulting optimization problem is highly non-convex due to the intricate structure of the MCRB expression and constant-modulus constraint imposed on RIS. To address this, we reformulate it into a more tractable form and propose a block coordinate descent (BCD) algorithm that incorporates majorization-minimization (MM), successive convex approximation (SCA), and penalization techniques. Simulation results demonstrate that our proposed approach reduces the MCRB performance loss by 24.36% on average compared to the case where the presence of faulty elements is ignored. Furthermore, the performance gain becomes more evident as the number of faulty elements increases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.17970v1</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lu Wang, Gui Zhou, Changheng Li, Luis F. Abanto-Leon, Nairy Moghadas Gholian, Matthias Hollick, Arash Asadi</dc:creator>
    </item>
    <item>
      <title>Analysis on Energy Efficiency of RIS-Assisted Multiuser Downlink Near-Field Communications</title>
      <link>https://arxiv.org/abs/2505.18076</link>
      <description>arXiv:2505.18076v1 Announce Type: new 
Abstract: In this paper, we focus on the energy efficiency (EE) optimization and analysis of reconfigurable intelligent surface (RIS)-assisted multiuser downlink near-field communications. Specifically, we conduct a comprehensive study on several key factors affecting EE performance, including the number of RIS elements, the types of reconfigurable elements, reconfiguration resolutions, and the maximum transmit power. To accurately capture the power characteristics of RISs, we adopt more practical power consumption models for three commonly used reconfigurable elements in RISs: PIN diodes, varactor diodes, and radio frequency (RF) switches. These different elements may result in RIS systems exhibiting significantly different energy efficiencies (EEs), even when their spectral efficiencies (SEs) are similar. Considering discrete phases implemented at most RISs in practice, which makes their optimization NP-hard, we develop a nested alternating optimization framework to maximize EE, consisting of an outer integer-based optimization for discrete RIS phase reconfigurations and a nested non-convex optimization for continuous transmit power allocation within each iteration. Extensive comparisons with multiple benchmark schemes validate the effectiveness and efficiency of the proposed framework. Furthermore, based on the proposed optimization method, we analyze the EE performance of RISs across different key factors and identify the optimal RIS architecture yielding the highest EE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18076v1</guid>
      <category>eess.SP</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wei Wang, Xiaoyu Ou, Zhihan Ren, Waqas Bin Abbas, Shuping Dang, Angela Doufexi, Mark A. Beach</dc:creator>
    </item>
    <item>
      <title>Interpreting Deep Neural Network-Based Receiver Under Varying Signal-To-Noise Ratios</title>
      <link>https://arxiv.org/abs/2409.16768</link>
      <description>arXiv:2409.16768v2 Announce Type: cross 
Abstract: We propose a novel method for interpreting neural networks, focusing on convolutional neural network-based receiver model. The method identifies which unit or units of the model contain most (or least) information about the channel parameter(s) of the interest, providing insights at both global and local levels -- with global explanations aggregating local ones. Experiments on link-level simulations demonstrate the method's effectiveness in identifying units that contribute most (and least) to signal-to-noise ratio processing. Although we focus on a radio receiver model, the method generalizes to other neural network architectures and applications, offering robust estimation even in high-dimensional settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.16768v2</guid>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/ICASSP49660.2025.10888682</arxiv:DOI>
      <dc:creator>Marko Tuononen, Dani Korpi, Ville Hautam\"aki</dc:creator>
    </item>
    <item>
      <title>Adaptive Implicit-Based Deep Learning Channel Estimation for 6G Communications</title>
      <link>https://arxiv.org/abs/2505.17421</link>
      <description>arXiv:2505.17421v1 Announce Type: cross 
Abstract: With the widespread deployment of fifth-generation (5G) wireless networks, research on sixth-generation (6G) technology is gaining momentum. Artificial Intelligence (AI) is anticipated to play a significant role in 6G, particularly through integration with the physical layer for tasks such as channel estimation. Considering resource limitations in real systems, the AI algorithm should be designed to have the ability to balance the accuracy and resource consumption according to the scenarios dynamically. However, conventional explicit multilayer-stacked Deep Learning (DL) models struggle to adapt due to their heavy reliance on the structure of deep neural networks. This article proposes an adaptive Implicit-layer DL Channel Estimation Network (ICENet) with a lightweight framework for vehicle-to-everything communications. This novel approach balances computational complexity and channel estimation accuracy by dynamically adjusting computational resources based on input data conditions, such as channel quality. Unlike explicit multilayer-stacked DL-based channel estimation models, ICENet offers a flexible framework, where specific requirements can be achieved by adaptively changing the number of iterations of the iterative layer. Meanwhile, ICENet requires less memory while maintaining high performance. The article concludes by highlighting open research challenges and promising future research directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.17421v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhen Qiao, Jiang Xue, Junkai Zhang, Guanzhang Liu, Xiaoqin Ma, Runhua Li, Faheem A. Khan, John S. Thompson, Zongben Xu</dc:creator>
    </item>
    <item>
      <title>Enhancing Fourier-based Doppler Resolution with Diffusion Models</title>
      <link>https://arxiv.org/abs/2505.17567</link>
      <description>arXiv:2505.17567v1 Announce Type: cross 
Abstract: In radar systems, high resolution in the Doppler dimension is important for detecting slow-moving targets as it allows for more distinct separation between these targets and clutter, or stationary objects. However, achieving sufficient resolution is constrained by hardware capabilities and physical factors, leading to the development of processing techniques to enhance the resolution after acquisition. In this work, we leverage artificial intelligence to increase the Doppler resolution in range-Doppler maps. Based on a zero-padded FFT, a refinement via the generative neural networks of diffusion models is achieved. We demonstrate that our method overcomes the limitations of traditional FFT, generating data where closely spaced targets are effectively separated.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.17567v1</guid>
      <category>cs.CV</category>
      <category>eess.SP</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Denisa Qosja, Kilian Barth, Simon Wagner</dc:creator>
    </item>
    <item>
      <title>Characterization of IRS-aided Indoor Wireless Virtual-Reality with Hybrid Beamforming</title>
      <link>https://arxiv.org/abs/2505.17737</link>
      <description>arXiv:2505.17737v1 Announce Type: cross 
Abstract: This paper introduces an optimum solution for a utility function that increases spectral efficiency in wireless Virtual Reality (VR) systems. This system uses Multi-user Multiple Input Multiple Output Orthogonal Frequency Division Multiplexing (MU-MIMO OFDM) with hybrid beamforming in indoor Intelligent Reflecting Surface (IRS) based Downlink (DL) scenario. Given the critical need to maximize the rate for transmitting VR traffic to meet the low-latency requirements, a substantial bandwidth allocation is essential. This bandwidth is assumed to be in the mmWave band, according to the IEEE 802.11ad/ay standard. The proposed utility function takes into account various delays, including processing, transmission and queuing delays, on both DL and Uplink (UL). Moreover, the relation between transmission delay and the utility function is examined in different Signal-to-Noise Ratio (SNR) levels, using both mean and minimum channel gain metrics. An optimization approach is applied to iteratively determine the IRS phase shifts and effective channel gain. The simulation results are benchmarked against NS3 simulations, showing a high degree of consistency. With an average accuracy of 81.57% the calculated DL and UL rates match the NS3 results when considering the IRS. Also, our proposed method achieves superior performance in the case of complexity over the existing designs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.17737v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Nasim Alikhani, Abbas Mohammadi</dc:creator>
    </item>
    <item>
      <title>Unsupervised Clustering for Fault Analysis in High-Voltage Power Systems Using Voltage and Current Signals</title>
      <link>https://arxiv.org/abs/2505.17763</link>
      <description>arXiv:2505.17763v1 Announce Type: cross 
Abstract: The widespread use of sensors in modern power grids has led to the accumulation of large amounts of voltage and current waveform data, especially during fault events. However, the lack of labeled datasets poses a significant challenge for fault classification and analysis. This paper explores the application of unsupervised clustering techniques for fault diagnosis in high-voltage power systems. A dataset provided by the Reseau de Transport d'Electricite (RTE) is analyzed, with frequency domain features extracted using the Fast Fourier Transform (FFT). The K-Means algorithm is then applied to identify underlying patterns in the data, enabling automated fault categorization without the need for labeled training samples. The resulting clusters are evaluated in collaboration with power system experts to assess their alignment with real-world fault characteristics. The results demonstrate the potential of unsupervised learning for scalable and data-driven fault analysis, providing a robust approach to detecting and classifying power system faults with minimal prior assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.17763v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julian Oelhaf, Georg Kordowich, Andreas Maier, Johann Jager, Siming Bayer</dc:creator>
    </item>
    <item>
      <title>Emergence of Hebbian Dynamics in Regularized Non-Local Learners</title>
      <link>https://arxiv.org/abs/2505.18069</link>
      <description>arXiv:2505.18069v1 Announce Type: cross 
Abstract: Stochastic Gradient Descent (SGD) has emerged as a remarkably effective learning algorithm, underpinning nearly all state-of-the-art machine learning models, from large language models to autonomous vehicles. Despite its practical success, SGD appears fundamentally distinct from biological learning mechanisms. It is widely believed that the biological brain can not implement gradient descent because it is nonlocal, and we have found little (if any) experimental evidence for it. In contrast, the brain is widely thought to learn via local Hebbian learning principles, which have been seen as incompatible with gradient descent. In this paper, we establish a theoretical and empirical connection between the learning signals of neural networks trained using SGD with weight decay and those trained with Hebbian learning near convergence. We show that SGD with regularization can appear to learn according to a Hebbian rule, and SGD with injected noise according to an anti-Hebbian rule. We also provide empirical evidence that Hebbian learning properties can emerge in a network with weight decay from virtually any learning rule--even random ones. These results may bridge a long-standing gap between artificial and biological learning, revealing Hebbian properties as an epiphenomenon of deeper optimization principles and cautioning against interpreting their presence in neural data as evidence against more complex hetero-synaptic mechanisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18069v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David Koplow, Tomaso Poggio, Liu Ziyin</dc:creator>
    </item>
    <item>
      <title>Soil analysis with machine-learning-based processing of stepped-frequency GPR field measurements: Preliminary study</title>
      <link>https://arxiv.org/abs/2404.15961</link>
      <description>arXiv:2404.15961v2 Announce Type: replace 
Abstract: Ground Penetrating Radar (GPR) has been widely studied as a tool for extracting soil parameters relevant to agriculture and horticulture. When combined with Machine Learning (ML) methods, air-coupled Stepped Frequency Continuous Wave Ground Penetrating Radar (SFCW GPR) measurements could offer a cost-effective way to obtain depth-resolved soil data. As a first step of our study in this direction, we conducted an extensive field survey using a tractor-mounted air-coupled SFCW GPR instrument. Leveraging ML-based data processing, we evaluate the GPR instrument's ability by predicting the apparent electrical conductivity (ECaR) measured by a co-recorded Electromagnetic Induction (EMI) instrument. The large-scale field measurement campaign with 3472 co-registered and geo-located GPR and EMI data samples distributed over approximately 6600 square meters was performed on a golf course. This terrain offers high surface homogeneity but also presents the challenge of subtle soil parameter variations. Based on the results, we discuss challenges in this multi-sensor regression setting and propose the use of the nugget-to-sill ratio as a performance metric for evaluating ML models in agricultural field survey applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15961v2</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chunlei Xu, Michael Pregesbauer, Naga Sravani Chilukuri, Daniel Windhager, Mahsa Yousefi, Pedro Julian, Lothar Ratschbacher</dc:creator>
    </item>
    <item>
      <title>Semi-Supervised Model-Free Bayesian State Estimation from Compressed Measurements</title>
      <link>https://arxiv.org/abs/2407.07368</link>
      <description>arXiv:2407.07368v4 Announce Type: replace 
Abstract: We consider data-driven Bayesian state estimation from compressed measurements (BSCM) of a model-free process. The dimension of the temporal measurement vector is lower than that of the temporal state vector to be estimated, leading to an under-determined inverse problem. The underlying dynamical model of the state's evolution is unknown for a 'model-free process.' Hence, it is difficult to use traditional model-driven methods, for example, Kalman and particle filters. Instead, we consider data-driven methods. We experimentally show that two existing unsupervised learning-based data-driven methods fail to address the BSCM problem in a model-free process. The methods are -- data-driven nonlinear state estimation (DANSE) and deep Markov model (DMM). While DANSE provides good predictive/forecasting performance to model the temporal measurement data as a time series, its unsupervised learning lacks suitable regularization for tackling the BSCM task. We then propose a semi-supervised learning approach and develop a semi-supervised learning-based DANSE method, referred to as SemiDANSE. In SemiDANSE, we use a large amount of unlabelled data along with a limited amount of labelled data, i.e., pairwise measurement-and-state data, which provides the desired regularization. Using three benchmark dynamical systems, we empirically show that the data-driven SemiDANSE provides competitive state estimation performance for BSCM using a handful of different measurement systems, against a hybrid method called KalmanNet and two model-driven methods (extended Kalman filter and unscented Kalman filter) that know the dynamical models exactly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07368v4</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anubhab Ghosh, Yonina C. Eldar, Saikat Chatterjee</dc:creator>
    </item>
    <item>
      <title>Comparing Differentiable and Dynamic Ray Tracing: Introducing the Multipath Lifetime Map</title>
      <link>https://arxiv.org/abs/2410.14535</link>
      <description>arXiv:2410.14535v5 Announce Type: replace 
Abstract: With the increasing presence of dynamic scenarios, such as Vehicle-to-Vehicle communications, radio propagation modeling tools must adapt to the rapidly changing nature of the radio channel. Recently, both Differentiable and Dynamic Ray Tracing frameworks have emerged to address these challenges. However, there is often confusion about how these approaches differ and which one should be used in specific contexts. In this paper, we provide an overview of these two techniques and a comparative analysis against two state-of-the-art tools: 3DSCAT from UniBo and Sionna from NVIDIA. To provide a more precise characterization of the scope of these methods, we introduce a novel simulation-based metric, the Multipath Lifetime Map, which enables the evaluation of spatial and temporal coherence in radio channels only based on the geometrical description of the environment. Finally, our metrics are evaluated on a classic urban street canyon scenario, yielding similar results to those obtained from measurement campaigns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14535v5</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.23919/EuCAP63536.2025.10999736</arxiv:DOI>
      <arxiv:journal_reference>2025 19th European Conference on Antennas and Propagation (EuCAP)</arxiv:journal_reference>
      <dc:creator>J\'erome Eertmans, Enrico Maria Vittuci, Vittorio Degli-Esposti, Laurent Jacques, Claude Oestges</dc:creator>
    </item>
    <item>
      <title>Harnessing Wavefront Curvature and Spatial Correlation in Noncoherent MIMO Communications</title>
      <link>https://arxiv.org/abs/2501.18000</link>
      <description>arXiv:2501.18000v3 Announce Type: replace 
Abstract: Noncoherent communication systems have regained interest due to the growing demand for high-mobility and low-latency applications. Most existing studies using large antenna arrays rely on the far-field approximation, which assumes locally plane wavefronts. This assumption becomes inaccurate at higher frequencies and shorter ranges, where wavefront curvature plays a significant role and antenna arrays may operate in the radiative near field. In this letter, we adopt a model for the channel spatial correlation matrix that remains valid in both near and far field scenarios. Using this model, we demonstrate that energy-based noncoherent systems can leverage the benefits of wavefront spherical curvature, even beyond the Fraunhofer distance, revealing that the classical far-field approximation may significantly underestimate system performance. Moreover, we show that large antenna arrays enable the multiplexing of various users even with a noncoherent processing, as well as permitting near-optimal detection with low computational complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18000v3</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/LWC.2025.3572761</arxiv:DOI>
      <dc:creator>Aniol Mart\'i, Luca Sanguinetti, Meritxell Lamarca, Jaume Riba</dc:creator>
    </item>
    <item>
      <title>Integrated Communication and RIS-aided Track-Before-Detect Radar Sensing</title>
      <link>https://arxiv.org/abs/2503.03013</link>
      <description>arXiv:2503.03013v2 Announce Type: replace 
Abstract: This paper investigates an integrated sensing and communication system where the base station serves multiple downlink users, while employing a passive reconfigurable intelligent surface to detect small, noncooperative airborne targets. We propose a method to design the two-way beampattern of the RIS-assisted monostatic radar, which allows controlling the sidelobe levels in the presence of eavesdroppers, jammers, and other scattering objects and avoiding any radar interference to the users. To obtain more favorable system tradeoffs, we exploit the correlation of the target echoes over consecutive scans by resorting to a multi-frame radar detector, which includes a detector, a plot-extractor, and a track-before-detect processor. A numerical analysis is provided to verify the effectiveness of the proposed solutions and to assess the achievable tradeoffs. Our results show that, by increasing the number of scans processed by the radar detector (and therefore its implementation complexity), we can reduce the amount of power dedicated to the radar function while maintaining the same sensing performance (measured in terms of probability of target detection and root mean square error in the estimation of target position); this excess power can be reused to increase the user sum-rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03013v2</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1109/OJCOMS.2025.3572081</arxiv:DOI>
      <dc:creator>Georgios Mylonopoulos, Luca Venturino, Emanuele Grossi, Stefano Buzzi, Ciro D'Elia</dc:creator>
    </item>
    <item>
      <title>A Method for Localization of Cellular Users from Call Detail Records</title>
      <link>https://arxiv.org/abs/2503.23263</link>
      <description>arXiv:2503.23263v2 Announce Type: replace 
Abstract: A common problem in justice applications is localization of a user of a cellular network using a call detail record (CDR), which typically reveals only the base station and sector to which the user was connected. This precludes precise estimation of location. Instead, one is limited to estimating a region of plausible locations (RPL) using static information such as sector antenna orientation, beamwidth, and locations of nearby base stations. In this paper, we propose a method for RPL estimation in which the shape bounding the RPL is derived from a model of the antenna pattern via the Friis Transmission Equation, and the size of the RPL is determined by mean distance to nearby base stations. The performance of the proposed method is evaluated by "best server" analysis of measurements acquired from drive testing in the vicinity of Winter Garden, Florida, observing three 700 MHz-band LTE cellular networks serving this area. Of the 16 sectors evaluated, the aggregate error rate (i.e., fraction of users located outside the RPL estimated for the associated sector) is found to be 1.3%, with worst per-sector error rate of about 13.3% and error rates below 1.8% for 13 of the 16 sectors. The principal difficulty is shown to be estimation of RPL size, which entails a tradeoff between minimizing RPL area (yielding the "tightest" localization) and minimizing error rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23263v2</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Steven W. Ellingson</dc:creator>
    </item>
    <item>
      <title>Implicit Neural Representation of Waveform Measurements in Power Systems Waveform Data Analysis</title>
      <link>https://arxiv.org/abs/2505.09789</link>
      <description>arXiv:2505.09789v2 Announce Type: replace 
Abstract: There is currently a paradigm shift in several power system monitoring applications, such as incipient fault detection and monitoring inverter-based resources, to transition from traditional phasor analytics to more informative waveform analytics. This paper contributes to this transition by developing a novel approach to modeling voltage and current waveform measurements using implicit neural representations (INRs). INRs are continuous function approximators that are recently used in vision and signal processing. The proposed INR models are specifically designed to meet the requirements of waveform analytics in power systems, such as by using sinusoidal activation functions that capture the periodic nature of voltage and current waveforms. We also propose extended models that can efficiently represent correlated waveforms, such as three-phase waveforms and synchro-waveforms. Real-world case studies demonstrate the effectiveness of the proposed INR models in terms of accuracy (&lt;1-2% MSE) and model size (4-6x compression). We also investigate the application of INR models in oscillation monitoring, for single mode oscillations and dual mode modulated oscillations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09789v2</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Narges Ehsani, Vishwanath Saragadam, Hamed Mohsenian-Rad</dc:creator>
    </item>
    <item>
      <title>Distributed Beamforming Using Decentralized Time Synchronization in a Six-Element Array</title>
      <link>https://arxiv.org/abs/2505.13248</link>
      <description>arXiv:2505.13248v2 Announce Type: replace 
Abstract: We demonstrate a distributed beamforming and beamsteering from a six-node distributed phased array using fully wireless coordination with decentralized time synchronization. In wireless applications such as distributed beamforming, high-accuracy time synchronization across the array is crucial for high coherent gain. The decentralized time synchronization method employed is based on the average consensus algorithm and the two-way time transfer method presented in our previous work, which achieved picosecond time synchronization with a cabled frequency reference. The system presented in this paper utilizes a centralized wireless frequency transfer method to achieve wireless frequency syntonization in a fully wireless coordination and a distributed computing system architecture. We experimentally evaluate system performance through beamforming and beamsteering to a receiver 16.3 m away from the six-node non-uniformly distributed antenna array, achieving an average coherent gain of 98% of the ideal gain at a carrier frequency of 1.05 GHz. The average time synchronization accuracy achieved was less than 36 ps.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13248v2</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Naim Shandi, Jason M. Merlo, Jeffrey A. Nanzer</dc:creator>
    </item>
    <item>
      <title>Experimental Study of Low-Latency Video Streaming in an ORAN Setup with Generative AI</title>
      <link>https://arxiv.org/abs/2412.12751</link>
      <description>arXiv:2412.12751v2 Announce Type: replace-cross 
Abstract: Video streaming services depend on the underlying communication infrastructure and available network resources to offer ultra-low latency, high-quality content delivery. Open Radio Access Network (ORAN) provides a dynamic, programmable, and flexible RAN architecture that can be configured to support the requirements of time-critical applications. This work considers a setup in which the constrained network resources are supplemented by \gls{GAI} and \gls{MEC} {techniques} in order to reach a satisfactory video quality. Specifically, we implement a novel semantic control channel that enables \gls{MEC} to support low-latency applications by tight coupling among the ORAN xApp, \gls{MEC}, and the control channel. The proposed concepts are experimentally verified with an actual ORAN setup that supports video streaming. The performance evaluation includes the \gls{PSNR} metric and end-to-end latency. Our findings reveal that latency adjustments can yield gains in image \gls{PSNR}, underscoring the trade-off potential for optimized video quality in resource-limited environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12751v2</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Andreas Casparsen, Van-Phuc Bui, Shashi Raj Pandey, Jimmy Jessen Nielsen, Petar Popovski</dc:creator>
    </item>
    <item>
      <title>Impact of Microphone Array Mismatches to Learning-based Replay Speech Detection</title>
      <link>https://arxiv.org/abs/2503.07357</link>
      <description>arXiv:2503.07357v2 Announce Type: replace-cross 
Abstract: In this work, we investigate the generalization of a multi-channel learning-based replay speech detector, which employs adaptive beamforming and detection, across different microphone arrays. In general, deep neural network-based microphone array processing techniques generalize poorly to unseen array types, i.e., showing a significant training-test mismatch of performance. We employ the ReMASC dataset to analyze performance degradation due to inter- and intra-device mismatches, assessing both single- and multi-channel configurations. Furthermore, we explore fine-tuning to mitigate the performance loss when transitioning to unseen microphone arrays. Our findings reveal that array mismatches significantly decrease detection accuracy, with intra-device generalization being more robust than inter-device. However, fine-tuning with as little as ten minutes of target data can effectively recover performance, providing insights for practical deployment of replay detection systems in heterogeneous automatic speaker verification environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.07357v2</guid>
      <category>eess.AS</category>
      <category>eess.SP</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Neri, Tuomas Virtanen</dc:creator>
    </item>
    <item>
      <title>Open-Set Gait Recognition from Sparse mmWave Radar Point Clouds</title>
      <link>https://arxiv.org/abs/2503.07435</link>
      <description>arXiv:2503.07435v3 Announce Type: replace-cross 
Abstract: The adoption of Millimeter-Wave (mmWave) radar devices for human sensing, particularly gait recognition, has recently gathered significant attention due to their efficiency, resilience to environmental conditions, and privacy-preserving nature. In this work, we tackle the challenging problem of Open-set Gait Recognition (OSGR) from sparse mmWave radar point clouds. Unlike most existing research, which assumes a closed-set scenario, our work considers the more realistic open-set case, where unknown subjects might be present at inference time, and should be correctly recognized by the system. Point clouds are well-suited for edge computing applications with resource constraints, but are more significantly affected by noise and random fluctuations than other representations, like the more common micro-Doppler signature. This is the first work addressing open-set gait recognition with sparse point cloud data. To do so, we propose a novel neural network architecture that combines supervised classification with unsupervised reconstruction of the point clouds, creating a robust, rich, and highly regularized latent space of gait features. To detect unknown subjects at inference time, we introduce a probabilistic novelty detection algorithm that leverages the structured latent space and offers a tunable trade-off between inference speed and prediction accuracy. Along with this paper, we release mmGait10, an original human gait dataset featuring over five hours of measurements from ten subjects, under varied walking modalities. Extensive experimental results show that our solution attains F1-Score improvements by 24% over state-of-the-art methods, on average, and across multiple openness levels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.07435v3</guid>
      <category>cs.CV</category>
      <category>eess.SP</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Riccardo Mazzieri, Jacopo Pegoraro, Michele Rossi</dc:creator>
    </item>
    <item>
      <title>TimeCapsule: Solving the Jigsaw Puzzle of Long-Term Time Series Forecasting with Compressed Predictive Representations</title>
      <link>https://arxiv.org/abs/2504.12721</link>
      <description>arXiv:2504.12721v3 Announce Type: replace-cross 
Abstract: Recent deep learning models for Long-term Time Series Forecasting (LTSF) often emphasize complex, handcrafted designs, while simpler architectures like linear models or MLPs have often outperformed these intricate solutions. In this paper, we revisit and organize the core ideas behind several key techniques, such as redundancy reduction and multi-scale modeling, which are frequently employed in advanced LTSF models. Our goal is to streamline these ideas for more efficient deep learning utilization. To this end, we introduce TimeCapsule, a model built around the principle of high-dimensional information compression that unifies these techniques in a generalized yet simplified framework. Specifically, we model time series as a 3D tensor, incorporating temporal, variate, and level dimensions, and leverage mode production to capture multi-mode dependencies while achieving dimensionality compression. We propose an internal forecast within the compressed representation domain, supported by the Joint-Embedding Predictive Architecture (JEPA), to monitor the learning of predictive representations. Extensive experiments on challenging benchmarks demonstrate the versatility of our method, showing that TimeCapsule can achieve state-of-the-art performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.12721v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>eess.SP</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yihang Lu, Yangyang Xu, Qitao Qing, Xianwei Meng</dc:creator>
    </item>
    <item>
      <title>U-SAM: An audio language Model for Unified Speech, Audio, and Music Understanding</title>
      <link>https://arxiv.org/abs/2505.13880</link>
      <description>arXiv:2505.13880v2 Announce Type: replace-cross 
Abstract: The text generation paradigm for audio tasks has opened new possibilities for unified audio understanding. However, existing models face significant challenges in achieving a comprehensive understanding across diverse audio types, such as speech, general audio events, and music. Furthermore, their exclusive reliance on cross-entropy loss for alignment often falls short, as it treats all tokens equally and fails to account for redundant audio features, leading to weaker cross-modal alignment. To deal with the above challenges, this paper introduces U-SAM, an advanced audio language model that integrates specialized encoders for speech, audio, and music with a pre-trained large language model (LLM). U-SAM employs a Mixture of Experts (MoE) projector for task-aware feature fusion, dynamically routing and integrating the domain-specific encoder outputs. Additionally, U-SAM incorporates a Semantic-Aware Contrastive Loss Module, which explicitly identifies redundant audio features under language supervision and rectifies their semantic and spectral representations to enhance cross-modal alignment. Extensive experiments demonstrate that U-SAM consistently outperforms both specialized models and existing audio language models across multiple benchmarks. Moreover, it exhibits emergent capabilities on unseen tasks, showcasing its generalization potential. Code is available (https://github.com/Honee-W/U-SAM/).</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13880v2</guid>
      <category>eess.AS</category>
      <category>cs.SD</category>
      <category>eess.SP</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziqian Wang, Xianjun Xia, Xinfa Zhu, Lei Xie</dc:creator>
    </item>
  </channel>
</rss>
