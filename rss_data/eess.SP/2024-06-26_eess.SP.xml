<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>eess.SP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/eess.SP</link>
    <description>eess.SP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/eess.SP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 27 Jun 2024 01:35:07 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 26 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Neural Network-based Two-Dimensional Filtering for OTFS Symbol Detection</title>
      <link>https://arxiv.org/abs/2406.16868</link>
      <description>arXiv:2406.16868v1 Announce Type: new 
Abstract: Orthogonal time frequency space (OTFS) is a promising modulation scheme for wireless communication in high-mobility scenarios. Recently, a reservoir computing (RC) based approach has been introduced for online subframe-based symbol detection in the OTFS system, where only the limited over-the-air (OTA) pilot symbols are utilized for training. However, the previous RC-based approach does not design the RC architecture based on the properties of the OTFS system to fully unlock the potential of RC. This paper introduces a novel two-dimensional RC (2D-RC) approach for online symbol detection on a subframe basis in the OTFS system. The 2D-RC is designed to have a two-dimensional (2D) filtering structure to equalize the 2D circular channel effect in the delay-Doppler (DD) domain of the OTFS system. With the introduced architecture, the 2D-RC can operate in the DD domain with only a single neural network, unlike our previous work which requires multiple RCs to track channel variations in the time domain. Experimental results demonstrate the advantages of the 2D-RC approach over the previous RC-based approach and the compared model-based methods across different modulation orders.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16868v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiarui Xu, Karim Said, Lizhong Zheng, Lingjia Liu</dc:creator>
    </item>
    <item>
      <title>Multi-channel Time Series Decomposition Network For Generalizable Sensor-Based Activity Recognition</title>
      <link>https://arxiv.org/abs/2406.16872</link>
      <description>arXiv:2406.16872v1 Announce Type: new 
Abstract: Sensor-based human activity recognition is important in daily scenarios such as smart healthcare and homes due to its non-intrusive privacy and low cost advantages, but the problem of out-of-domain generalization caused by differences in focusing individuals and operating environments can lead to significant accuracy degradation on cross-person behavior recognition due to the inconsistent distributions of training and test data. To address the above problems, this paper proposes a new method, Multi-channel Time Series Decomposition Network (MTSDNet). Firstly, MTSDNet decomposes the original signal into a combination of multiple polynomials and trigonometric functions by the trainable parameterized temporal decomposition to learn the low-rank representation of the original signal for improving the extraterritorial generalization ability of the model. Then, the different components obtained by the decomposition are classified layer by layer and the layer attention is used to aggregate components to obtain the final classification result. Extensive evaluation on DSADS, OPPORTUNITY, PAMAP2, UCIHAR and UniMib public datasets shows the advantages in predicting accuracy and stability of our method compared with other competing strategies, including the state-of-the-art ones. And the visualization is conducted to reveal MTSDNet's interpretability and layer-by-layer characteristics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16872v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianguo Pan, Zhengxin Hu, Lingdun Zhang, Xia Cai</dc:creator>
    </item>
    <item>
      <title>A Survey of Machine Learning Techniques for Improving Global Navigation Satellite Systems</title>
      <link>https://arxiv.org/abs/2406.16873</link>
      <description>arXiv:2406.16873v1 Announce Type: new 
Abstract: Global Navigation Satellite Systems (GNSS)-based positioning plays a crucial role in various applications, including navigation, transportation, logistics, mapping, and emergency services. Traditional GNSS positioning methods are model-based and they utilize satellite geometry and the known properties of satellite signals. However, model-based methods have limitations in challenging environments and often lack adaptability to uncertain noise models. This paper highlights recent advances in Machine Learning (ML) and its potential to address these limitations. It covers a broad range of ML methods, including supervised learning, unsupervised learning, deep learning, and hybrid approaches. The survey provides insights into positioning applications related to GNSS such as signal analysis, anomaly detection, multi-sensor integration, prediction, and accuracy enhancement using ML. It discusses the strengths, limitations, and challenges of current ML-based approaches for GNSS positioning, providing a comprehensive overview of the field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16873v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.RO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adyasha Mohanty, Grace Gao</dc:creator>
    </item>
    <item>
      <title>Multi-Stage Fusion Architecture for Small-Drone Localization and Identification Using Passive RF and EO Imagery: A Case Study</title>
      <link>https://arxiv.org/abs/2406.16875</link>
      <description>arXiv:2406.16875v1 Announce Type: new 
Abstract: Reliable detection, localization and identification of small drones is essential to promote safe, secure and privacy-respecting operation of Unmanned-Aerial Systems (UAS), or simply, drones. This is an increasingly challenging problem with only single modality sensing, especially, to detect and identify small drones. In this work, a multi-stage fusion architecture using passive radio frequency (RF) and electro-optic (EO) imagery data is developed to leverage the synergies of the modalities to improve the overall tracking and classification capabilities. For detection with EO-imagery, supervised deep learning based techniques as well as unsupervised foreground/background separation techniques are explored to cope with challenging environments. Using real collected data for Group 1 and 2 drones, the capability of each algorithm is quantified. In order to compensate for any performance gaps in detection with only EO imagery as well as to provide a unique device identifier for the drones, passive RF is integrated with EO imagery whenever available. In particular, drone detections in the image plane are combined with passive RF location estimates via detection-to-detection association after 3D to 2D transformation. Final tracking is performed on the composite detections in the 2D image plane. Each track centroid is given a unique identification obtained via RF fingerprinting. The proposed fusion architecture is tested and the tracking and performance is quantified over the range to illustrate the effectiveness of the proposed approaches using simultaneously collected passive RF and EO data at the Air Force Research Laboratory (AFRL) through ESCAPE-21 (Experiments, Scenarios, Concept of Operations, and Prototype Engineering) data collect</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16875v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thakshila Wimalajeewa Wewelwala, Thomas W. Tedesso, Tony Davis</dc:creator>
    </item>
    <item>
      <title>Near-Field Mobile Tracking: A Framework of Using XL-RIS Information</title>
      <link>https://arxiv.org/abs/2406.16876</link>
      <description>arXiv:2406.16876v1 Announce Type: new 
Abstract: This paper introduces a novel mobile tracking framework leveraging the high-dimensional signal received from extremely large-scale (XL) reconfigurable intelligent surfaces (RIS). This received signal, named XL-RIS information, has a much larger data dimension and therefore offers a richer feature set compared to the traditional base station (BS) received signal, i.e., BS information, enabling more accurate tracking of mobile users (MUs). As the first step, we present an XL-RIS information reconstruction (XL-RIS-IR) algorithm to reconstruct the high-dimensional XL-RIS information from the low-dimensional BS information. Building on this, this paper proposes a comprehensive framework for mobile tracking, consisting of a Feature Extraction Module and a Mobile Tracking Module. The Feature Extraction Module incorporates a convolutional neural network (CNN) extractor for spatial features, a time and frequency (T$\&amp;$F) extractor for domain features, and a near-field angles of arrival (AoAs) extractor for capturing AoA features within the XL-RIS. These features are combined into a comprehensive feature vector, forming a time-varying sequence fed into the Mobile Tracking Module, which employs an Auto-encoder (AE) with a stacked bidirectional long short-term memory (Bi-LSTM) encoder and a standard LSTM decoder to predict MUs' positions in the upcoming time slot. Simulation results confirm that the tracking accuracy of our proposed framework is significantly enhanced by using reconstructed XL-RIS information and exhibits substantial robustness to signal-to-noise ratio (SNR) variations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16876v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tuo Wu, Cunhua Pan, Kangda Zhi, Hong Ren, Maged Elkashlan, Chau Yuen</dc:creator>
    </item>
    <item>
      <title>Rational-Exponent Filters with Applications to Generalized Auditory Filterbanks</title>
      <link>https://arxiv.org/abs/2406.16877</link>
      <description>arXiv:2406.16877v1 Announce Type: new 
Abstract: We present filters with rational exponents in order to provide a continuum of filter behavior not classically achievable. We discuss their stability, the flexibility they afford, and various representations useful for analysis, design and implementations. We do this for a generalization of second order filters which we refer to as rational-exponent Generalized Auditory Filters/Filterbanks (GAFs) that are useful for a diverse array of applications. We present equivalent representations for rational-order GAFs in the time and frequency domains: transfer functions, impulse responses, and integral expressions - the last of which allows for efficient real-time processing without preprocessing requirements. Rational-exponent filters enable filter characteristics to be on a continuum rather than limiting them to discrete values thereby resulting in greater flexibility in the behavior of these filters. In the case of GAFs, this allows for having arbitrary continuous rather than discrete values for filter characteristics such as (1) the ratio of 3dB quality factor to maximum group delay - particularly important for filterbanks which have simultaneous requirements on frequency selectivity and synchronization; and (2) the ratio of 3dB to 15dB quality factors that dictates the shape of the frequency response magnitude.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16877v1</guid>
      <category>eess.SP</category>
      <category>cs.SD</category>
      <category>cs.SY</category>
      <category>eess.AS</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Samiya A Alkhairy</dc:creator>
    </item>
    <item>
      <title>Benchmarking Semantic Communications for Image Transmission Over MIMO Interference Channels</title>
      <link>https://arxiv.org/abs/2406.16878</link>
      <description>arXiv:2406.16878v1 Announce Type: new 
Abstract: Semantic communications offer promising prospects for enhancing data transmission efficiency. However, existing schemes have predominantly concentrated on point-to-point transmissions. In this paper, we aim to investigate the validity of this claim in interference scenarios compared to baseline approaches. Specifically, our focus is on general multiple-input multiple-output (MIMO) interference channels, where we propose an interference-robust semantic communication (IRSC) scheme. This scheme involves the development of transceivers based on neural networks (NNs), which integrate channel state information (CSI) either solely at the receiver or at both transmitter and receiver ends. Moreover, we establish a composite loss function for training IRSC transceivers, along with a dynamic mechanism for updating the weights of various components in the loss function to enhance system fairness among users. Experimental results demonstrate that the proposed IRSC scheme effectively learns to mitigate interference and outperforms baseline approaches, particularly in low signal-to-noise (SNR) regimes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16878v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yanhu Wang, Shuaishuai Guo, Anming Dong, Hui Zhao</dc:creator>
    </item>
    <item>
      <title>Sensor Data Augmentation from Skeleton Pose Sequences for Improving Human Activity Recognition</title>
      <link>https://arxiv.org/abs/2406.16886</link>
      <description>arXiv:2406.16886v1 Announce Type: new 
Abstract: The proliferation of deep learning has significantly advanced various fields, yet Human Activity Recognition (HAR) has not fully capitalized on these developments, primarily due to the scarcity of labeled datasets. Despite the integration of advanced Inertial Measurement Units (IMUs) in ubiquitous wearable devices like smartwatches and fitness trackers, which offer self-labeled activity data from users, the volume of labeled data remains insufficient compared to domains where deep learning has achieved remarkable success. Addressing this gap, in this paper, we propose a novel approach to improve wearable sensor-based HAR by introducing a pose-to-sensor network model that generates sensor data directly from 3D skeleton pose sequences. our method simultaneously trains the pose-to-sensor network and a human activity classifier, optimizing both data reconstruction and activity recognition. Our contributions include the integration of simultaneous training, direct pose-to-sensor generation, and a comprehensive evaluation on the MM-Fit dataset. Experimental results demonstrate the superiority of our framework with significant performance improvements over baseline methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16886v1</guid>
      <category>eess.SP</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Parham Zolfaghari, Vitor Fortes Rey, Lala Ray, Hyun Kim, Sungho Suh, Paul Lukowicz</dc:creator>
    </item>
    <item>
      <title>Efficient UAV Hovering, Resource Allocation, and Trajectory Design for ISAC with Limited Backhaul Capacity</title>
      <link>https://arxiv.org/abs/2406.16888</link>
      <description>arXiv:2406.16888v1 Announce Type: new 
Abstract: In this paper, we investigate the joint resource allocation and trajectory design for a multi-user, multi-target unmanned aerial vehicle (UAV)-enabled integrated sensing and communication (ISAC) system, where the link capacity between a ground base station (BS) and the UAV is limited. The UAV conducts target sensing and information transmission in orthogonal time slots to prevent interference. As is common in practical systems, sensing is performed while the UAV hovers, allowing the UAV to acquire high-quality sensing data. Subsequently, the acquired sensing data is offloaded to the ground BS for further processing. We jointly optimize the UAV trajectory, UAV velocity, beamforming for the communication users, power allocated to the sensing beam, and time of hovering for sensing to minimize the power consumption of the UAV while ensuring the communication quality of service (QoS) and successful sensing. Due to the prohibitively high complexity of the resulting non-convex mixed integer non-linear program (MINLP), we employ a series of transformations and optimization techniques, including semidefinite relaxation, big-M method, penalty approach, and successive convex approximation, to obtain a low-complexity suboptimal solution. Our simulation results reveal that 1) the proposed design achieves significant power savings compared to two baseline schemes; 2) stricter sensing requirements lead to longer sensing times, highlighting the challenge of efficiently managing both sensing accuracy and sensing time; 3) the optimized trajectory design ensures precise hovering directly above the targets during sensing, enhancing sensing quality and enabling the application of energy-focused beams; and 4) the proposed trajectory design balances the capacity of the backhaul link and the downlink rate of the communication users.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16888v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ata Khalili, Atefeh Rezaei, Dongfang Xu, Falko Dressler, Robert Schober</dc:creator>
    </item>
    <item>
      <title>Rapid Shear Capacity Prediction of TRM-Strengthened Unreinforced Masonry Walls through Interpretable Machine Learning using a Web App</title>
      <link>https://arxiv.org/abs/2406.16889</link>
      <description>arXiv:2406.16889v1 Announce Type: new 
Abstract: The presented study aims to provide an efficient and reliable tool for rapid estimation of the shear capacity of a TRM-strengthened masonry wall. For this purpose, a data-driven methodology based on a machine learning system is proposed using a dataset constituted of experimental results selected from the bibliography. The outlier points were detected using Cook's distance methodology and removed from the raw dataset, which consisted of 113 examples and 11 input variables. In the processed dataset, 17 Machine Learning methods were trained, optimized through hyperparameter tuning, and compared on the test set. The most effective models are combined into a voting model to leverage the predictive capacity of more than a single regressor. The final blended model shows remarkable predicting capacity with the determination factor ($R^2$) equal to 0.95 and the mean absolute percentage error equal to 8.03\%. In sequence, machine learning interpretation methods are applied to find how the predictors influence the target output. $A_m$, $f_t$, and $n\cdot t_f$ were identified as the most significant predictors with a mainly positive influence on the shear capacity. Finally, the built ML system is employed in a user-friendly web app for easy access and usage by professionals and researchers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16889v1</guid>
      <category>eess.SP</category>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Petros Lazaridis, Athanasia Thomoglou</dc:creator>
    </item>
    <item>
      <title>An Initial Study of Human-Scale Blockage in sub-THz Radio Propagation with Application to Indoor Passive Localization</title>
      <link>https://arxiv.org/abs/2406.16894</link>
      <description>arXiv:2406.16894v1 Announce Type: new 
Abstract: This paper empirically investigates the body induced electromagnetic (EM) effects, namely the human body blockage, by conducting indoor measurement campaigns in the unexplored sub-THz W-band (75-110 GHz) and G-band (170-260 GHz). The proposed analysis focuses on both the alterations of channel frequency response induced by body presence, fully or partially obstructing the line-of-sight (LoS) between transmitter and recevier, as well as on the channel impulse response (CIR) for selected movements of the target, i.e. crossing the LoS of the radio link. Modelling of large scale parameters is also presented using a phantom body object. The proposed study has applications in device-free radio localization and radio frequency (RF) sensing scenarios where the EM radiation or environmental radio signals are collected and processed to detect and locate people without requiring them to wear any electronic devices. Although preliminary, the study reveals that discrimination of the blockage micro-movements is possible, achieving higher precision compared to classical RF sensing and localization using cm-scale wavelengths (2.4-6GHz bands).</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16894v1</guid>
      <category>eess.SP</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>F. Paonessa, G. Virone, S. Kianoush, A. Nordio, S. Savazzi</dc:creator>
    </item>
    <item>
      <title>Coronary Artery Disease Classification Using One-dimensional Convolutional Neural Network</title>
      <link>https://arxiv.org/abs/2406.16895</link>
      <description>arXiv:2406.16895v1 Announce Type: new 
Abstract: Coronary Artery Disease (CAD) diagnostic to be a major global cause of death, necessitating innovative solutions. Addressing the critical importance of early CAD detection and its impact on the mortality rate, we propose the potential of one-dimensional convolutional neural networks (1D-CNN) to enhance detection accuracy and reduce network complexity. This study goes beyond traditional diagnostic methodologies, leveraging the remarkable ability of 1D-CNN to interpret complex patterns within Electrocardiogram (ECG) signals without depending on feature extraction techniques. We explore the impact of varying sample lengths on model performance and conduct experiments involving layers reduction. The ECG data employed were obtained from the PhysioNet databases, namely the MIMIC III and Fantasia datasets, with respective sampling frequencies of 125 Hz and 250 Hz. The highest accuracy for unseen data obtained with a sample length of 250. These initial findings demonstrate the potential of 1D-CNNs in CAD diagnosis using ECG signals and highlight the sample size's role in achieving high accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16895v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Atitaya Phoemsuk, Vahid Abolghasemi</dc:creator>
    </item>
    <item>
      <title>f-GAN: A frequency-domain-constrained generative adversarial network for PPG to ECG synthesis</title>
      <link>https://arxiv.org/abs/2406.16896</link>
      <description>arXiv:2406.16896v1 Announce Type: new 
Abstract: Electrocardiograms (ECGs) and photoplethysmograms (PPGs) are generally used to monitor an individual's cardiovascular health. In clinical settings, ECGs and fingertip PPGs are the main signals used for assessing cardiovascular health, but the equipment necessary for their collection precludes their use in daily monitoring. Although PPGs obtained from wrist-worn devices are susceptible to noise due to motion, they have been widely used to continuously monitor cardiovascular health because of their convenience. Therefore, we would like to combine the ease with which PPGs can be collected with the information that ECGs provide about cardiovascular health by developing models to synthesize ECG signals from paired PPG signals. We tackled this problem using generative adversarial networks (GANs) and found that models trained using the original GAN formulations can be successfully used to synthesize ECG signals from which heart rate can be extracted using standard signal processing pipelines. Incorporating a frequency-domain constraint to model training improved the stability of model performance and also the performance on heart rate estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16896v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Nathan C. L. Kong, Dae Lee, Huyen Do, Dae Hoon Park, Cong Xu, Hongda Mao, Jonathan Chung</dc:creator>
    </item>
    <item>
      <title>ECGrecover: a Deep Learning Approach for Electrocardiogram Signal Completion</title>
      <link>https://arxiv.org/abs/2406.16901</link>
      <description>arXiv:2406.16901v2 Announce Type: new 
Abstract: In this work, we address the challenge of reconstructing the complete 12-lead ECG signal from incomplete parts of it. We focus on two main scenarii: (i) reconstructing missing signal segments within an ECG lead and (ii) recovering missing leads from a single-lead. We propose a model with a U-Net architecture trained on a novel objective function to address the reconstruction problem. This function incorporates both spatial and temporal aspects of the ECG by combining the distance in amplitude between the reconstructed and real signals with the signal trend. Through comprehensive assessments using both a real-life dataset and a publicly accessible one, we demonstrate that the proposed approach consistently outperforms state-of-the-art methods based on generative adversarial networks and a CopyPaste strategy. Our proposed model demonstrates superior performance in standard distortion metrics and preserves critical ECG characteristics, particularly the P, Q, R, S, and T wave coordinates. Two emerging clinical applications emphasize the relevance of our work. The first is the increasing need to digitize paper-stored ECGs for utilization in AI-based applications (automatic annotation and risk-quantification), often limited to digital ECG complete 10s recordings. The second is the widespread use of wearable devices that record ECGs but typically capture only a small subset of the 12 standard leads. In both cases, a non-negligible amount of information is lost or not recorded, which our approach aims to recover to overcome these limitations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16901v2</guid>
      <category>eess.SP</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alex Lence, Ahmad Fall, Federica Granese, Blaise Hanczar, Joe-Elie Salem, Jean-Daniel Zucker, Edi Prifti</dc:creator>
    </item>
    <item>
      <title>Learning Exemplar Representations in Single-Trial EEG Category Decoding</title>
      <link>https://arxiv.org/abs/2406.16902</link>
      <description>arXiv:2406.16902v1 Announce Type: new 
Abstract: Within neuroimgaing studies it is a common practice to perform repetitions of trials in an experiment when working with a noisy class of data acquisition system, such as electroencephalography (EEG) or magnetoencephalography (MEG). While this approach can be useful in some experimental designs, it presents significant limitations for certain types of analyses, such as identifying the category of an object observed by a subject. In this study we demonstrate that when trials relating to a single object are allowed to appear in both the training and testing sets, almost any classification algorithm is capable of learning the representation of an object given only category labels. This ability to learn object representations is of particular significance as it suggests that the results of several published studies which predict the category of observed objects from EEG signals may be affected by a subtle form of leakage which has inflated their reported accuracies. We demonstrate the ability of both simple classification algorithms, and sophisticated deep learning models, to learn object representations given only category labels. We do this using two datasets; the Kaneshiro et al. (2015) dataset and the Gifford et al. (2022) dataset. Our results raise doubts about the true generalizability of several published models and suggests that the reported performance of these models may be significantly inflated.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16902v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jack Kilgallen, Barak Pearlmutter, Jeffery Mark Siskind</dc:creator>
    </item>
    <item>
      <title>Intelligent energy management of steam generators</title>
      <link>https://arxiv.org/abs/2406.16904</link>
      <description>arXiv:2406.16904v1 Announce Type: new 
Abstract: This paper introduces a smart model for intelligent energy management of steam generators which are utilized for steam generator and controlling the air to fuel ratio for steam generator all over the firing curve and transient mode operation. Nowadays, the environment faces a lot of pollution and global warming phenomena. With the spread of electrical devices, electric cars with conventional electrical generation sources, and the increase in electrical consumption, instead of minimizing the pollution level the situation becomes disastrous. Steam generators have a lot of pros which cannot be neglected, such as: high efficiency, reliable operation, low emission (with regular maintenance), and big variety of fuel source. However, regular maintenance overlooks some parameters, especially the air to fuel ratio that achieves green environment, high efficiency and low fuel consumption. The steam generator system is simulated utilizing Simulink/MATLAB. The system is operated at different loading and generation conditions to determine the variation of air to fuel ratio against power variation. Neural Network (NN) unit is added in different locations and scenarios. It is effective in controlling the main bus of air, fuel, auxiliary and inverter speed. By testing the NN on the simulated tested system, the results are satisfied.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16904v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ahmed S. Hussein, Noha H. El-Amary, Loai Saad El-din Nasrat, Ali Selim</dc:creator>
    </item>
    <item>
      <title>REST: Efficient and Accelerated EEG Seizure Analysis through Residual State Updates</title>
      <link>https://arxiv.org/abs/2406.16906</link>
      <description>arXiv:2406.16906v1 Announce Type: new 
Abstract: EEG-based seizure detection models face challenges in terms of inference speed and memory efficiency, limiting their real-time implementation in clinical devices. This paper introduces a novel graph-based residual state update mechanism (REST) for real-time EEG signal analysis in applications such as epileptic seizure detection. By leveraging a combination of graph neural networks and recurrent structures, REST efficiently captures both non-Euclidean geometry and temporal dependencies within EEG data. Our model demonstrates high accuracy in both seizure detection and classification tasks. Notably, REST achieves a remarkable 9-fold acceleration in inference speed compared to state-of-the-art models, while simultaneously demanding substantially less memory than the smallest model employed for this task. These attributes position REST as a promising candidate for real-time implementation in clinical devices, such as Responsive Neurostimulation or seizure alert systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16906v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arshia Afzal, Grigorios Chrysos, Volkan Cevher, Mahsa Shoaran</dc:creator>
    </item>
    <item>
      <title>RayProNet: A Neural Point Field Framework for Radio Propagation Modeling in 3D Environments</title>
      <link>https://arxiv.org/abs/2406.16907</link>
      <description>arXiv:2406.16907v1 Announce Type: new 
Abstract: The radio wave propagation channel is central to the performance of wireless communication systems. In this paper, we introduce a novel machine learning-empowered methodology for wireless channel modeling. The key ingredients include a point-cloud-based neural network and a Spherical Harmonics encoder with light probes. Our approach offers several significant advantages, including the flexibility to adjust antenna radiation patterns and transmitter/receiver locations, the capability to predict radio power maps, and the scalability of large-scale wireless scenes. As a result, it lays the groundwork for an end-to-end pipeline for network planning and deployment optimization. The proposed work is validated in various outdoor and indoor radio environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16907v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ge Cao, Zhen Peng</dc:creator>
    </item>
    <item>
      <title>Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection</title>
      <link>https://arxiv.org/abs/2406.16908</link>
      <description>arXiv:2406.16908v1 Announce Type: new 
Abstract: The neonatal period is the most vulnerable time for the development of seizures. Seizures in the immature brain lead to detrimental consequences, therefore require early diagnosis. The gold-standard for neonatal seizure detection currently relies on continuous video-EEG monitoring; which involves recording multi-channel electroencephalogram (EEG) alongside real-time video monitoring within a neonatal intensive care unit (NICU). However, video-EEG monitoring technology requires clinical expertise and is often limited to technologically advanced and resourceful settings. Cost-effective new techniques could help the medical fraternity make an accurate diagnosis and advocate treatment without delay. In this work, a novel explainable deep learning model to automate the neonatal seizure detection process with a reduced EEG montage is proposed, which employs convolutional nets, graph attention layers, and fully connected layers. Beyond its ability to detect seizures in real-time with a reduced montage, this model offers the unique advantage of real-time interpretability. By evaluating the performance on the Zenodo dataset with 10-fold cross-validation, the presented model achieves an absolute improvement of 8.31% and 42.86% in area under curve (AUC) and recall, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16908v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dinuka Sandun Udayantha, Kavindu Weerasinghe, Nima Wickramasinghe, Akila Abeyratne, Kithmin Wickremasinghe, Jithangi Wanigasinghe, Anjula De Silva, Chamira Edussooriya</dc:creator>
    </item>
    <item>
      <title>Enhancing Computational Efficiency of Motor Imagery BCI Classification with Block-Toeplitz Augmented Covariance Matrices and Siegel Metric</title>
      <link>https://arxiv.org/abs/2406.16909</link>
      <description>arXiv:2406.16909v1 Announce Type: new 
Abstract: Electroencephalographic signals are represented as multidimensional datasets. We introduce an enhancement to the augmented covariance method (ACM), exploiting more thoroughly its mathematical properties, in order to improve motor imagery classification.Standard ACM emerges as a combination of phase space reconstruction of dynamical systems and of Riemannian geometry. Indeed, it is based on the construction of a Symmetric Positive Definite matrix to improve classification. But this matrix also has a Block-Toeplitz structure that was previously ignored. This work treats such matrices in the real manifold to which they belong: the set of Block-Toeplitz SPD matrices. After some manipulation, this set is can be seen as the product of an SPD manifold and a Siegel Disk Space.The proposed methodology was tested using the MOABB framework with a within-session evaluation procedure. It achieves a similar classification performance to ACM, which is typically better than -- or at worse comparable to -- state-of-the-art methods. But, it also improves consequently the computational efficiency over ACM, making it even more suitable for real time experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16909v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <category>math.DG</category>
      <category>nlin.CD</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Igor Carrara (UniCA, CRONOS), Theodore Papadopoulo (UniCA, CRONOS)</dc:creator>
    </item>
    <item>
      <title>Mind's Eye: Image Recognition by EEG via Multimodal Similarity-Keeping Contrastive Learning</title>
      <link>https://arxiv.org/abs/2406.16910</link>
      <description>arXiv:2406.16910v1 Announce Type: new 
Abstract: Decoding images from non-invasive electroencephalographic (EEG) signals has been a grand challenge in understanding how the human brain process visual information in real-world scenarios. To cope with the issues of signal-to-noise ratio and nonstationarity, this paper introduces a MUltimodal Similarity-keeping contrastivE learning (MUSE) framework for zero-shot EEG-based image classification. We develop a series of multivariate time-series encoders tailored for EEG signals and assess the efficacy of regularized contrastive EEG-Image pretraining using an extensive visual EEG dataset. Our method achieves state-of-the-art performance, with a top-1 accuracy of 19.3% and a top-5 accuracy of 48.8% in 200-way zero-shot image classification. Furthermore, we visualize neural patterns via model interpretation, shedding light on the visual processing dynamics in the human brain. The code repository for this work is available at: https://github.com/ChiShengChen/MUSE_EEG.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16910v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chi-Sheng Chen, Chun-Shu Wei</dc:creator>
    </item>
    <item>
      <title>L-SFAN: Lightweight Spatially-focused Attention Network for Pain Behavior Detection</title>
      <link>https://arxiv.org/abs/2406.16913</link>
      <description>arXiv:2406.16913v1 Announce Type: new 
Abstract: Chronic Low Back Pain (CLBP) afflicts millions globally, significantly impacting individuals' well-being and imposing economic burdens on healthcare systems. While artificial intelligence (AI) and deep learning offer promising avenues for analyzing pain-related behaviors to improve rehabilitation strategies, current models, including convolutional neural networks (CNNs), recurrent neural networks, and graph-based neural networks, have limitations. These approaches often focus singularly on the temporal dimension or require complex architectures to exploit spatial interrelationships within multivariate time series data. To address these limitations, we introduce \hbox{L-SFAN}, a lightweight CNN architecture incorporating 2D filters designed to meticulously capture the spatial-temporal interplay of data from motion capture and surface electromyography sensors. Our proposed model, enhanced with an oriented global pooling layer and multi-head self-attention mechanism, prioritizes critical features to better understand CLBP and achieves competitive classification accuracy. Experimental results on the EmoPain database demonstrate that our approach not only enhances performance metrics with significantly fewer parameters but also promotes model interpretability, offering valuable insights for clinicians in managing CLBP. This advancement underscores the potential of AI in transforming healthcare practices for chronic conditions like CLBP, providing a sophisticated framework for the nuanced analysis of complex biomedical data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16913v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jorge Ortigoso-Narro, Fernando Diaz-de-Maria, Mohammad Mahdi Dehshibi, Ana Tajadura-Jim\'enez</dc:creator>
    </item>
    <item>
      <title>Co-Design of Low-Profile Linear Microstrip Arrays with Wide-Band Spatial Filtering Capabilities</title>
      <link>https://arxiv.org/abs/2406.16914</link>
      <description>arXiv:2406.16914v1 Announce Type: new 
Abstract: The design of low-profile linear microstrip arrays with wide-band spatial filtering capabilities is dealt with. An innovative architecture, leveraging the angular selectivity of offset stacked patch (OSP) radiators, is proposed to implement phased arrays (PAs) with inter-element spacing larger than half-wavelength that feature remarkable grating lobes (GLs) suppression properties and an enhanced gain within a non-negligible down-looking scanning angular range. The PA layout is then obtained by optimizing the optimal micro-scale geometrical descriptors of the radiating elements so that the macro-scale electromagnetic (EM) features of the arising finite-size PA fulfill the user-defined requirements. A set of numerical test cases, concerned with a variation of the array size and its polarization, is presented to assess the capabilities, the flexibility, and the potentialities of the proposed spatial filtering technique (SFT) also in comparison with competitive state-of-the-art alternatives. The performance of a printed circuit board (PCB)-manufactured prototype are experimentally assessed, as well.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16914v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arianna Benoni, Marco Salucci, Andrea Massa</dc:creator>
    </item>
    <item>
      <title>Unlocking Telemetry Potential: Self-Supervised Learning for Continuous Clinical Electrocardiogram Monitoring</title>
      <link>https://arxiv.org/abs/2406.16915</link>
      <description>arXiv:2406.16915v1 Announce Type: new 
Abstract: Machine learning (ML) applied to routine patient monitoring within intensive care units (ICUs) has the potential to improve care by providing clinicians with novel insights into each patient's health and expected response to interventions. This paper applies deep learning to a large volume of unlabeled electrocardiogram (ECG) telemetry signals, which are commonly used for continuous patient monitoring in hospitals but have important differences from the standard, single time-point 12-lead ECG used in many prior machine learning studies. We applied self-supervised learning to pretrain a spectrum of deep networks on approximately 147,000 hours of ECG telemetry data. Our approach leverages this dataset to train models that significantly improve performance on four distinct downstream tasks compared with direct supervised learning using labeled data. These pretrained models enable medically useful predictions and estimates in smaller patient cohorts that are typically limited by the scarcity of labels. Notably, we demonstrate that our pretrained networks can continuously annotate ECG telemetry signals, thereby providing monitoring capabilities that are often unavailable due to the requirement for specialized expertise and time-consuming professional annotations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16915v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thomas Kite, Uzair Tahamid Siam, Brian Ayers, Nicholas Houstis, Aaron D Aguirre</dc:creator>
    </item>
    <item>
      <title>GreenShield: CNN-Based Real-Time Forest Monitoring and Response</title>
      <link>https://arxiv.org/abs/2406.16917</link>
      <description>arXiv:2406.16917v1 Announce Type: new 
Abstract: This research introduces an innovative forest monitoring system designed to detect and mitigate the threats of forest fires. The proposed system leverages Arduino-based technology integrated with state-of-the-art sensors, including DHT11 for temperature and humidity detection and Flame sensor along with GSM module for gas and smoke detection. The integration of these sensors enables real-time data acquisition and analysis, providing a comprehensive and accurate assessment of environmental conditions within the forest ecosystem. The Arduino platform serves as the central processing unit, orchestrating the communication and synchronization of the sensor data. The DHT11 sensor monitors ambient temperature and humidity levels, crucial indicators for assessing fire risk and identifying potential deforestation activities. Simultaneously, the Flame sensor module detects the occurrence of fire flames nearby thus indicating it by a buzzer. The collected data is processed through an intelligent algorithm that employs machine learning techniques to discern patterns indicative of potential threats. The system is equipped with an adaptive threshold mechanism, allowing it to dynamically adjust to changing environmental conditions. In the event of abnormal readings or anomalies, the system triggers immediate alerts, notifying forest rangers and relevant authorities to facilitate timely response and intervention. The integration of low-cost, easily deployable Arduino-based devices makes this solution scalable and accessible for implementation across diverse forest environments. The proposed system represents a significant step towards leveraging technology to address environmental challenges and protect our forests.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16917v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Avishek Bhattacharjee, Swarup Samanta, Jagadish Bhattacharya, Manish Kumar Singh</dc:creator>
    </item>
    <item>
      <title>Quantifying the Impact of Energy System Model Resolution on Siting, Cost, Reliability, and Emissions</title>
      <link>https://arxiv.org/abs/2406.16924</link>
      <description>arXiv:2406.16924v1 Announce Type: new 
Abstract: Energy systems models, critical for power sector decision support, incur non-linear memory and runtime penalties when scaling up under typical formulations. Even hardware improvements cannot make large models tractable, requiring omission of detail which affects siting, cost, and emission outputs to an unknown degree. Recent algorithmic innovations have enabled large scale, high resolution modeling. Newly tractable, granular systems can be compared with coarse ones for better understanding of inaccuracies from low resolution. Here we use a state of the art model to quantify the impact of resolution on results salient to policymakers and planners, affording confidence in decision quality. We find more realistic siting in recommendations from high resolution energy systems models, improving emissions, reliability, and price outcomes. Errors are generally stronger from low spatial resolution. When models have low resolution in multiple dimensions, errors are introduced by the coarser of temporal or spatial resolution. We see no diminishing returns in accuracy for several key metrics when increasing resolution. We recommend using computationally efficient techniques to maximize granularity and allocating resolution without leaving any aspect (spatial, temporal, operational) of systems unduly coarse.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16924v1</guid>
      <category>eess.SP</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Anna F. Jacobson, Denise L. Mauzerall, Jesse D. Jenkins</dc:creator>
    </item>
    <item>
      <title>Enhancing Wearable based Real-Time Glucose Monitoring via Phasic Image Representation Learning based Deep Learning</title>
      <link>https://arxiv.org/abs/2406.16926</link>
      <description>arXiv:2406.16926v1 Announce Type: new 
Abstract: In the U.S., over a third of adults are pre-diabetic, with 80\% unaware of their status. This underlines the need for better glucose monitoring to prevent type 2 diabetes and related heart diseases. Existing wearable glucose monitors are limited by the lack of models trained on small datasets, as collecting extensive glucose data is often costly and impractical. Our study introduces a novel machine learning method using modified recurrence plots in the frequency domain to improve glucose level prediction accuracy from wearable device data, even with limited datasets. This technique combines advanced signal processing with machine learning to extract more meaningful features. We tested our method against existing models using historical data, showing that our approach surpasses the current 87\% accuracy benchmark in predicting real-time interstitial glucose levels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16926v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>46th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC) 2024</arxiv:journal_reference>
      <dc:creator>Yidong Zhu, Nadia B Aimandi, Mohammad Arif Ul Alam</dc:creator>
    </item>
    <item>
      <title>Anomaly Detection Utilizing a Riemann Metric for Robust Myoelectric Pattern Recognition</title>
      <link>https://arxiv.org/abs/2406.16927</link>
      <description>arXiv:2406.16927v1 Announce Type: new 
Abstract: Traditional myoelectric pattern recognition (MPR) systems excel within controlled laboratory environments but they are interfered when confronted with anomaly or novel motions not encountered during the training phase. Utilizing metric ways to distinguish the target and novel motions based on extractors compared to training set is a prevalent idea to alleviate such interference. An innovative method for anomaly motion detection was proposed based on simplified log-Euclidean distance (SLED) of symmetric positive definite manifolds. The SLED enhances the discrimination between target and novel motions. Moreover, it generates a more flexible shaping of motion boundaries to segregate target and novel motions, therefore effectively detecting the novel ones. The proposed method was evaluated using surface-electromyographic (sEMG) armband data recorded while performing 6 target and 8 novel hand motions. Based on linear discriminate analysis (LDA) and convolution prototype network (CPN) feature extractors, the proposed method achieved accuracies of 89.7% and 93.9% in novel motion detection respectively, while maintaining a target motion classification accuracy of 90%, outperforming the existing ones with statistical significance (p&lt;0.05). This study provided a valuable solution for improving the robustness of MPR systems against anomaly motion interference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16927v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>ZongYe Hu, Ge Gao, Xiang Chen, Xu Zhang</dc:creator>
    </item>
    <item>
      <title>A Multi-Resolution Mutual Learning Network for Multi-Label ECG Classification</title>
      <link>https://arxiv.org/abs/2406.16928</link>
      <description>arXiv:2406.16928v1 Announce Type: new 
Abstract: Electrocardiograms (ECG), which record the electrophysiological activity of the heart, have become a crucial tool for diagnosing these diseases. In recent years, the application of deep learning techniques has significantly improved the performance of ECG signal classification. Multi-resolution feature analysis, which captures and processes information at different time scales, can extract subtle changes and overall trends in ECG signals, showing unique advantages. However, common multi-resolution analysis methods based on simple feature addition or concatenation may lead to the neglect of low-resolution features, affecting model performance. To address this issue, this paper proposes the Multi-Resolution Mutual Learning Network (MRM-Net). MRM-Net includes a dual-resolution attention architecture and a feature complementary mechanism. The dual-resolution attention architecture processes high-resolution and low-resolution features in parallel. Through the attention mechanism, the high-resolution and low-resolution branches can focus on subtle waveform changes and overall rhythm patterns, enhancing the ability to capture critical features in ECG signals. Meanwhile, the feature complementary mechanism introduces mutual feature learning after each layer of the feature extractor. This allows features at different resolutions to reinforce each other, thereby reducing information loss and improving model performance and robustness. Experiments on the PTB-XL and CPSC2018 datasets demonstrate that MRM-Net significantly outperforms existing methods in multi-label ECG classification performance. The code for our framework will be publicly available at https://github.com/wxhdf/MRM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16928v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wei Huang, Ning Wang, Panpan Feng, Haiyan Wang, Zongmin Wang, Bing Zhou</dc:creator>
    </item>
    <item>
      <title>Modelling the 5G Energy Consumption using Real-world Data: Energy Fingerprint is All You Need</title>
      <link>https://arxiv.org/abs/2406.16929</link>
      <description>arXiv:2406.16929v1 Announce Type: new 
Abstract: The introduction of fifth-generation (5G) radio technology has revolutionized communications, bringing unprecedented automation, capacity, connectivity, and ultra-fast, reliable communications. However, this technological leap comes with a substantial increase in energy consumption, presenting a significant challenge. To improve the energy efficiency of 5G networks, it is imperative to develop sophisticated models that accurately reflect the influence of base station (BS) attributes and operational conditions on energy usage.Importantly, addressing the complexity and interdependencies of these diverse features is particularly challenging, both in terms of data processing and model architecture design.
  This paper proposes a novel 5G base stations energy consumption modelling method by learning from a real-world dataset used in the ITU 5G Base Station Energy Consumption Modelling Challenge in which our model ranked second. Unlike existing methods that omit the Base Station Identifier (BSID) information and thus fail to capture the unique energy fingerprint in different base stations, we incorporate the BSID into the input features and encoding it with an embedding layer for precise representation. Additionally, we introduce a novel masked training method alongside an attention mechanism to further boost the model's generalization capabilities and accuracy. After evaluation, our method demonstrates significant improvements over existing models, reducing Mean Absolute Percentage Error (MAPE) from 12.75% to 4.98%, leading to a performance gain of more than 60%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16929v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tingwei Chen, Yantao Wang, Hanzhi Chen, Zijian Zhao, Xinhao Li, Nicola Piovesan, Guangxu Zhu, Qingjiang Shi</dc:creator>
    </item>
    <item>
      <title>Xi-Net: Transformer Based Seismic Waveform Reconstructor</title>
      <link>https://arxiv.org/abs/2406.16932</link>
      <description>arXiv:2406.16932v1 Announce Type: new 
Abstract: Missing/erroneous data is a major problem in today's world. Collected seismic data sometimes contain gaps due to multitude of reasons like interference and sensor malfunction. Gaps in seismic waveforms hamper further signal processing to gain valuable information. Plethora of techniques are used for data reconstruction in other domains like image, video, audio, but translation of those methods to address seismic waveforms demands adapting them to lengthy sequence inputs, which is practically complex. Even if that is accomplished, high computational costs and inefficiency would still persist in these predominantly convolution-based reconstruction models. In this paper, we present a transformer-based deep learning model, Xi-Net, which utilizes multi-faceted time and frequency domain inputs for accurate waveform reconstruction. Xi-Net converts the input waveform to frequency domain, employs separate encoders for time and frequency domains, and one decoder for getting reconstructed output waveform from the fused features. 1D shifted-window transformer blocks form the elementary units of all parts of the model. To the best of our knowledge, this is the first transformer-based deep learning model for seismic waveform reconstruction. We demonstrate this model's prowess by filling 0.5-1s random gaps in 120s waveforms, resembling the original waveform quite closely. The code, models can be found at: https://github.com/Anshuman04/waveformReconstructor.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16932v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.17023/pn92-d609</arxiv:DOI>
      <dc:creator>Anshuman Gaharwar, Parth Parag Kulkarni, Joshua Dickey, Mubarak Shah</dc:creator>
    </item>
    <item>
      <title>SGSM: A Foundation-model-like Semi-generalist Sensing Model</title>
      <link>https://arxiv.org/abs/2406.16933</link>
      <description>arXiv:2406.16933v1 Announce Type: new 
Abstract: The significance of intelligent sensing systems is growing in the realm of smart services. These systems extract relevant signal features and generate informative representations for particular tasks. However, building the feature extraction component for such systems requires extensive domain-specific expertise or data. The exceptionally rapid development of foundation models is likely to usher in newfound abilities in such intelligent sensing. We propose a new scheme for sensing model, which we refer to as semi-generalist sensing model (SGSM). SGSM is able to semiautomatically solve various tasks using relatively less task-specific labeled data compared to traditional systems. Built through the analysis of the common theoretical model, SGSM can depict different modalities, such as the acoustic and Wi-Fi signal. Experimental results on such two heterogeneous sensors illustrate that SGSM functions across a wide range of scenarios, thereby establishing its broad applicability. In some cases, SGSM even achieves better performance than sensor-specific specialized solutions. Wi-Fi evaluations indicate a 20\% accuracy improvement when applying SGSM to an existing sensing model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16933v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianjian Yang, Hao Zhou, Shuo Liu, Kaiwen Guo, Yiwen Hou, Haohua Du, Zhi Liu, Xiang-Yang Li</dc:creator>
    </item>
    <item>
      <title>Multi-UAV Multi-RIS QoS-Aware Aerial Communication Systems using DRL and PSO</title>
      <link>https://arxiv.org/abs/2406.16934</link>
      <description>arXiv:2406.16934v1 Announce Type: new 
Abstract: Recently, Unmanned Aerial Vehicles (UAVs) have attracted the attention of researchers in academia and industry for providing wireless services to ground users in diverse scenarios like festivals, large sporting events, natural and man-made disasters due to their advantages in terms of versatility and maneuverability. However, the limited resources of UAVs (e.g., energy budget and different service requirements) can pose challenges for adopting UAVs for such applications. Our system model considers a UAV swarm that navigates an area, providing wireless communication to ground users with RIS support to improve the coverage of the UAVs. In this work, we introduce an optimization model with the aim of maximizing the throughput and UAVs coverage through optimal path planning of UAVs and multi-RIS phase configurations. The formulated optimization is challenging to solve using standard linear programming techniques, limiting its applicability in real-time decision-making. Therefore, we introduce a two-step solution using deep reinforcement learning and particle swarm optimization. We conduct extensive simulations and compare our approach to two competitive solutions presented in the recent literature. Our simulation results demonstrate that our adopted approach is 20 \% better than the brute-force approach and 30\% better than the baseline solution in terms of QoS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16934v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Marwan Dhuheir, Aiman Erbad, Ala Al-Fuqaha, Mohsen Guizani</dc:creator>
    </item>
    <item>
      <title>Benchmarking Out-of-Distribution Generalization Capabilities of DNN-based Encoding Models for the Ventral Visual Cortex</title>
      <link>https://arxiv.org/abs/2406.16935</link>
      <description>arXiv:2406.16935v1 Announce Type: new 
Abstract: We characterized the generalization capabilities of DNN-based encoding models when predicting neuronal responses from the visual cortex. We collected \textit{MacaqueITBench}, a large-scale dataset of neural population responses from the macaque inferior temporal (IT) cortex to over $300,000$ images, comprising $8,233$ unique natural images presented to seven monkeys over $109$ sessions. Using \textit{MacaqueITBench}, we investigated the impact of distribution shifts on models predicting neural activity by dividing the images into Out-Of-Distribution (OOD) train and test splits. The OOD splits included several different image-computable types including image contrast, hue, intensity, temperature, and saturation. Compared to the performance on in-distribution test images -- the conventional way these models have been evaluated -- models performed worse at predicting neuronal responses to out-of-distribution images, retaining as little as $20\%$ of the performance on in-distribution test images. The generalization performance under OOD shifts can be well accounted by a simple image similarity metric -- the cosine distance between image representations extracted from a pre-trained object recognition model is a strong predictor of neural predictivity under different distribution shifts. The dataset of images, neuronal firing rate recordings, and computational benchmarks are hosted publicly at: https://bit.ly/3zeutVd.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16935v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Spandan Madan, Will Xiao, Mingran Cao, Hanspeter Pfister, Margaret Livingstone, Gabriel Kreiman</dc:creator>
    </item>
    <item>
      <title>Unmixing Noise from Hawkes Process to Model Learned Physiological Events</title>
      <link>https://arxiv.org/abs/2406.16938</link>
      <description>arXiv:2406.16938v1 Announce Type: new 
Abstract: Physiological signal analysis often involves identifying events crucial to understanding biological dynamics. Traditional methods rely on handcrafted procedures or supervised learning, presenting challenges such as expert dependence, lack of robustness, and the need for extensive labeled data. Data-driven methods like Convolutional Dictionary Learning (CDL) offer an alternative but tend to produce spurious detections. This work introduces UNHaP (Unmix Noise from Hawkes Processes), a novel approach addressing the joint learning of temporal structures in events and the removal of spurious detections. Leveraging marked Hawkes processes, UNHaP distinguishes between events of interest and spurious ones. By treating the event detection output as a mixture of structured and unstructured events, UNHaP efficiently unmixes these processes and estimates their parameters. This approach significantly enhances the understanding of event distributions while minimizing false detection rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16938v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guillaume Staerman, Virginie Loison, Thomas Moreau</dc:creator>
    </item>
    <item>
      <title>Towards Deep Learning for Predicting Microbial Fuel Cell Energy Output</title>
      <link>https://arxiv.org/abs/2406.16939</link>
      <description>arXiv:2406.16939v1 Announce Type: new 
Abstract: Soil microbial fuel cells (SMFCs) are an emerging technology which offer clean and renewable energy in environments where more traditional power sources, such as chemical batteries or solar, are not suitable. With further development, SMFCs show great promise for use in robust and affordable outdoor sensor networks, particularly for farmers. One of the greatest challenges in the development of this technology is understanding and predicting the fluctuations of SMFC energy generation, as the electro-generative process is not yet fully understood. Very little work currently exists attempting to model and predict the relationship between soil conditions and SMFC energy generation, and we are the first to use machine learning to do so. In this paper, we train Long Short Term Memory (LSTM) models to predict the future energy generation of SMFCs across timescales ranging from 3 minutes to 1 hour, with results ranging from 2.33% to 5.71% MAPE for median voltage prediction. For each timescale, we use quantile regression to obtain point estimates and to establish bounds on the uncertainty of these estimates. When comparing the median predicted vs. actual values for the total energy generated during the testing period, the magnitude of prediction errors ranged from 2.29% to 16.05%. To demonstrate the real-world utility of this research, we also simulate how the models could be used in an automated environment where SMFC-powered devices shut down and activate intermittently to preserve charge, with promising initial results. Our deep learning-based prediction and simulation framework would allow a fully automated SMFC-powered device to achieve a median 100+% increase in successful operations, compared to a naive model that schedules operations based on the average voltage generated in the past.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16939v1</guid>
      <category>eess.SP</category>
      <category>cs.ET</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Adam Hess-Dunlop, Harshitha Kakani, Colleen Josephson</dc:creator>
    </item>
    <item>
      <title>Sub-mW 30GHz Variable-Gain LNA in 22nm FDSOI CMOS for Low-Power Tapered mm-Wave 5G/6G Phased-Array Receivers</title>
      <link>https://arxiv.org/abs/2406.16941</link>
      <description>arXiv:2406.16941v1 Announce Type: new 
Abstract: Next-generation cellular systems require low-power mm-wave phased-array ICs. Variable-gain LNAs (VG-LNAs) are key blocks enabling reduced hardware complexity, performance improvement and added functionalities. This paper reports a low-power 30GHz VG-LNA for mm-wave 5G/6G phased-array ICs, with a gain control of 8 dB for 18dB Taylor taper in a 30GHz 8x8 antenna array. The VG-LNA exhibits a peak gain of 16 dB in the high-gain state, consumes less than 1 mW and occupies an area of 0.20 x 0.22 mm2.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16941v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>M. Spasaro, D. Zito</dc:creator>
    </item>
    <item>
      <title>EarDA: Towards Accurate and Data-Efficient Earable Activity Sensing</title>
      <link>https://arxiv.org/abs/2406.16943</link>
      <description>arXiv:2406.16943v1 Announce Type: new 
Abstract: In the realm of smart sensing with the Internet of Things, earable devices are empowered with the capability of multi-modality sensing and intelligence of context-aware computing, leading to its wide usage in Human Activity Recognition (HAR). Nonetheless, unlike the movements captured by Inertial Measurement Unit (IMU) sensors placed on the upper or lower body, those motion signals obtained from earable devices show significant changes in amplitudes and patterns, especially in the presence of dynamic and unpredictable head movements, posing a significant challenge for activity classification. In this work, we present EarDA, an adversarial-based domain adaptation system to extract the domain-independent features across different sensor locations. Moreover, while most deep learning methods commonly rely on training with substantial amounts of labeled data to offer good accuracy, the proposed scheme can release the potential usage of publicly available smartphone-based IMU datasets. Furthermore, we explore the feasibility of applying a filter-based data processing method to mitigate the impact of head movement. EarDA, the proposed system, enables more data-efficient and accurate activity sensing. It achieves an accuracy of 88.8% under HAR task, demonstrating a significant 43% improvement over methods without domain adaptation. This clearly showcases its effectiveness in mitigating domain gaps.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16943v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/CSCAIoT62585.2024.00005</arxiv:DOI>
      <dc:creator>Shengzhe Lyu, Yongliang Chen, Di Duan, Renqi Jia, Weitao Xu</dc:creator>
    </item>
    <item>
      <title>Networked ISAC for Low-Altitude Economy: Coordinated Transmit Beamforming and UAV Trajectory Design</title>
      <link>https://arxiv.org/abs/2406.16946</link>
      <description>arXiv:2406.16946v1 Announce Type: new 
Abstract: This paper exploits the networked integrated sensing and communications (ISAC) to support low-altitude economy (LAE), in which a set of networked ground base stations (GBSs) cooperatively transmit joint information and sensing signals to communicate with multiple authorized unmanned aerial vehicles (UAVs) and concurrently detect unauthorized objects over the interested region in the three-dimensional (3D) space. We assume that each GBS is equipped with uniform linear array (ULA) antennas, which are deployed either horizontally or vertically to the ground. We also consider two types of UAV receivers, which have and do not have the capability of canceling the interference caused by dedicated sensing signals, respectively. Under each setup, we jointly design the coordinated transmit beamforming at multiple GBSs together with the authorized UAVs' trajectory control and their GBS associations, for enhancing the authorized UAVs' communication performance while ensuring the sensing requirements. In particular, we aim to maximize the average sum rate of authorized UAVs over a given flight period, subject to the minimum illumination power constraints toward the interested 3D sensing region, the maximum transmit power constraints at individual GBSs, and the flight constraints of UAVs. These problems are highly non-convex and challenging to solve, due to the involvement of binary UAV-GBS association variables as well as the coupling of beamforming and trajectory variables. To solve these non-convex problems, we propose efficient algorithms by using the techniques of alternating optimization, successive convex approximation, and semi-definite relaxation. Numerical results show that the proposed joint coordinated transmit beamforming and UAV trajectory designs efficiently balance the sensing-communication performance tradeoffs and significantly outperform various benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16946v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gaoyuan Cheng, Xianxin Song, Zhonghao Lyu, Jie Xu</dc:creator>
    </item>
    <item>
      <title>Energy-Efficient Seizure Detection Suitable for low-power Applications</title>
      <link>https://arxiv.org/abs/2406.16948</link>
      <description>arXiv:2406.16948v1 Announce Type: new 
Abstract: Epilepsy is the most common, chronic, neurological disease worldwide and is typically accompanied by reoccurring seizures. Neuro implants can be used for effective treatment by suppressing an upcoming seizure upon detection. Due to the restricted size and limited battery lifetime of those medical devices, the employed approach also needs to be limited in size and have low energy requirements. We present an energy-efficient seizure detection approach involving a TC-ResNet and time-series analysis which is suitable for low-power edge devices. The presented approach allows for accurate seizure detection without preceding feature extraction while considering the stringent hardware requirements of neural implants. The approach is validated using the CHB-MIT Scalp EEG Database with a 32-bit floating point model and a hardware suitable 4-bit fixed point model. The presented method achieves an accuracy of 95.28%, a sensitivity of 92.34% and an AUC score of 0.9384 on this dataset with 4-bit fixed point representation. Furthermore, the power consumption of the model is measured with the low-power AI accelerator UltraTrail, which only requires 495 nW on average. Due to this low-power consumption this classification approach is suitable for real-time seizure detection on low-power wearable devices such as neural implants.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16948v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julia Werner, Bhavya Kohli, Paul Palomero Bernardo, Christoph Gerum, Oliver Bringmann</dc:creator>
    </item>
    <item>
      <title>Validation of a new, minimally-invasive, software smartphone device to predict sleep apnea and its severity: transversal study</title>
      <link>https://arxiv.org/abs/2406.16953</link>
      <description>arXiv:2406.16953v1 Announce Type: new 
Abstract: Obstructive sleep apnea (OSA) is frequent and responsible for cardiovascular complications and excessive daytime sleepiness. It is underdiagnosed due to the difficulty to access the gold standard for diagnosis, polysomnography (PSG). Alternative methods using smartphone sensors could be useful to increase diagnosis. The objective is to assess the performances of Apneal, an application that records the sound using a smartphone's microphone and movements thanks to a smartphone's accelerometer and gyroscope, to estimate patients' AHI. In this article, we perform a monocentric proof-of-concept study with a first manual scoring step, and then an automatic detection of respiratory events from the recorded signals using a sequential deep-learning model which was released internally at Apneal at the end of 2022 (version 0.1 of Apneal automatic scoring of respiratory events), in adult patients during in-hospital polysomnography.46 patients (women 34 per cent, mean BMI 28.7 kg per m2) were included. For AHI superior to 15, sensitivity of manual scoring was 0.91, and positive predictive value (PPV) 0.89. For AHI superior to 30, sensitivity was 0.85, PPV 0.94. We obtained an AUC-ROC of 0.85 and an AUC-PR of 0.94 for the identification of AHI superior to 15, and AUC-ROC of 0.95 and AUC-PR of 0.93 for AHI superior to 30. Promising results are obtained for the automatic annotations of events.This article shows that manual scoring of smartphone-based signals is possible and accurate compared to PSG-based scorings. Automatic scoring method based on a deep learning model provides promising results. A larger multicentric validation study, involving subjects with different SAHS severity is required to confirm these results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16953v1</guid>
      <category>eess.SP</category>
      <category>cs.CL</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Justine Frija, Juliette Millet, Emilie Bequignon, Ala Covali, Guillaume Cathelain, Josselin Houenou, Helene Benzaquen, Pierre Alexis Geoffroy, Emmanuel Bacry, Mathieu Grajoszex, Marie-Pia d Ortho</dc:creator>
    </item>
    <item>
      <title>SRViT: Vision Transformers for Estimating Radar Reflectivity from Satellite Observations at Scale</title>
      <link>https://arxiv.org/abs/2406.16955</link>
      <description>arXiv:2406.16955v1 Announce Type: new 
Abstract: We introduce a transformer-based neural network to generate high-resolution (3km) synthetic radar reflectivity fields at scale from geostationary satellite imagery. This work aims to enhance short-term convective-scale forecasts of high-impact weather events and aid in data assimilation for numerical weather prediction over the United States. Compared to convolutional approaches, which have limited receptive fields, our results show improved sharpness and higher accuracy across various composite reflectivity thresholds. Additional case studies over specific atmospheric phenomena support our quantitative findings, while a novel attribution method is introduced to guide domain experts in understanding model outputs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16955v1</guid>
      <category>eess.SP</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jason Stock, Kyle Hilburn, Imme Ebert-Uphoff, Charles Anderson</dc:creator>
    </item>
    <item>
      <title>Towards a data-driven and scalable approach for window operation detection in multi-family residential buildings</title>
      <link>https://arxiv.org/abs/2406.16957</link>
      <description>arXiv:2406.16957v1 Announce Type: new 
Abstract: Natural cooling, utilizing non-mechanical cooling, presents a low-carbon and low-cost way to provide thermal comfort in residential buildings. However, designing naturally cooled buildings requires a clear understanding of how opening and closing windows affect occupants' comfort. Predicting when and why occupants open windows is a challenging task, often relying on specialized sensors and building-specific training data. This limits the scalability of natural cooling solutions. Here, we, propose a novel unsupervised method that utilizes easily deployable off-the-shelf temperature and humidity sensors to detect window operations. The effectiveness of our approach is evaluated using an empirical dataset and compared with a state-of-the-art support vector machine (SVM) model. The results demonstrate that our proposed method outperforms the SVM on key indicators, except when indoor and outdoor temperatures have small differences. Unlike the SVM's sensitivity to time series characteristics, our proposed method relies solely on indoor temperature and exhibits robust performance in pilot studies, making it a promising candidate for developing a highly scalable and generalizable window operation detection model This work demonstrates the potential of unsupervised data-driven methods for understanding window operations in residential buildings. By enabling more accurate modeling of naturally cooled buildings, our work aims to facilitate the widespread adoption of this low-cost and low-carbon technology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16957v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Juliet Nwagwu Ume-Ezeoke, Kopal Nihar, Catherine Gorle, Rishee Jain</dc:creator>
    </item>
    <item>
      <title>Remaining useful life prediction of rolling bearings based on refined composite multi-scale attention entropy and dispersion entropy</title>
      <link>https://arxiv.org/abs/2406.16967</link>
      <description>arXiv:2406.16967v1 Announce Type: new 
Abstract: Remaining useful life (RUL) prediction based on vibration signals is crucial for ensuring the safe operation and effective health management of rotating machinery. Existing studies often extract health indicators (HI) from time domain and frequency domain features to analyze complex vibration signals, but these features may not accurately capture the degradation process. In this study, we propose a degradation feature extraction method called Fusion of Multi-Modal Multi-Scale Entropy (FMME), which utilizes multi-modal Refined Composite Multi-scale Attention Entropy (RCMATE) and Fluctuation Dispersion Entropy (RCMFDE), to solve the problem that the existing degradation features cannot accurately reflect the degradation process. Firstly, the Empirical Mode Decomposition (EMD) is employed to decompose the dual-channel vibration signals of bearings into multiple modals. The main modals are then selected for further analysis. The subsequent step involves the extraction of RCMATE and RCMFDE from each modal, followed by wavelet denoising. Next, a novel metric is proposed to evaluate the quality of degradation features. The attention entropy and dispersion entropy of the optimal scales under different modals are fused using Laplacian Eigenmap (LE) to obtain the health indicators. Finally, RUL prediction is performed through the similarity of health indicators between fault samples and bearings to be predicted. Experimental results demonstrate that the proposed method yields favorable outcomes across diverse operating conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16967v1</guid>
      <category>eess.SP</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yunchong Long, Qinkang Pang, Guangjie Zhu, Junxian Cheng, Xiangshun Li</dc:creator>
    </item>
    <item>
      <title>Improving Rehabilitative Assessment with Statistical and Shape Preserving Surrogate Data and Singular Spectrum Analysis</title>
      <link>https://arxiv.org/abs/2406.16970</link>
      <description>arXiv:2406.16970v1 Announce Type: new 
Abstract: Time series data are collected in temporal order and are widely used to train systems for prediction, modeling and classification to name a few. These systems require large amounts of data to improve generalization and prevent over-fitting. However there is a comparative lack of time series data due to operational constraints. This situation is alleviated by synthesizing data which have a suitable spread of features yet retain the distinctive features of the original data. These would be its basic statistical properties and overall shape which are important for short time series such as in rehabilitative applications or in quickly changing portions of lengthy data. In our earlier work synthesized surrogate time series were used to augment rehabilitative data. This gave good results in classification but the resulting waveforms did not preserve the original signal shape. To remedy this, we use singular spectrum analysis (SSA) to separate a signal into trends and cycles to describe the shape of the signal and low level components. In a novel way we subject the low level component to randomizing processes then recombine this with the original trend and cycle components to form a synthetic time series. We compare our approach with other methods, using statistical and shape measures and demonstrate its effectiveness in classification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16970v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.23919/SPA53010.2022.9927805</arxiv:DOI>
      <arxiv:journal_reference>2022 Signal Processing: Algorithms, Architectures, Arrangements, and Applications (SPA), Poznan, Poland, 2022, pp. 58-63</arxiv:journal_reference>
      <dc:creator>T. K. M. Lee, H. W. Chan, K. H. Leo, E. Chew, Ling Zhao, S. Sanei</dc:creator>
    </item>
    <item>
      <title>AI for Equitable Tennis Training: Leveraging AI for Equitable and Accurate Classification of Tennis Skill Levels and Training Phases</title>
      <link>https://arxiv.org/abs/2406.16987</link>
      <description>arXiv:2406.16987v1 Announce Type: new 
Abstract: Numerous studies have demonstrated the manifold benefits of tennis, such as increasing overall physical and mental health. Unfortunately, many children and youth from low-income families are unable to engage in this sport mainly due to financial constraints such as private lesson expenses as well as logistical concerns to and back from such lessons and clinics. While several tennis self-training systems exist, they are often tailored for professionals and are prohibitively expensive. The present study aims to classify tennis players' skill levels and classify tennis strokes into phases characterized by motion attributes for a future development of an AI-based tennis self-training model for affordable and convenient applications running on devices used in daily life such as an iPhone or an Apple Watch for tennis skill improvement. We collected motion data, including Motion Yaw, Roll and Pitch from inertial measurement units (IMUs) worn by participating junior tennis players. For this pilot study, data from twelve participants were processed using Support Vector Machine (SVM) algorithms. The SVM models demonstrated an overall accuracy of 77% in classifying players as beginners or intermediates, with low rates of false positives and false negatives, effectively distinguishing skill levels. Additionally, the tennis swings were successfully classified into five phases based on the collected motion data. These findings indicate that SVM-based classification can be a reliable foundation for developing an equitable and accessible AI-driven tennis training system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16987v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gyanna Gao, Hao-Yu Liao, Zhenhong Hu</dc:creator>
    </item>
    <item>
      <title>Quantum Multi-Agent Reinforcement Learning for Cooperative Mobile Access in Space-Air-Ground Integrated Networks</title>
      <link>https://arxiv.org/abs/2406.16994</link>
      <description>arXiv:2406.16994v1 Announce Type: new 
Abstract: Achieving global space-air-ground integrated network (SAGIN) access only with CubeSats presents significant challenges such as the access sustainability limitations in specific regions (e.g., polar regions) and the energy efficiency limitations in CubeSats. To tackle these problems, high-altitude long-endurance unmanned aerial vehicles (HALE-UAVs) can complement these CubeSat shortcomings for providing cooperatively global access sustainability and energy efficiency. However, as the number of CubeSats and HALE-UAVs, increases, the scheduling dimension of each ground station (GS) increases. As a result, each GS can fall into the curse of dimensionality, and this challenge becomes one major hurdle for efficient global access. Therefore, this paper provides a quantum multi-agent reinforcement Learning (QMARL)-based method for scheduling between GSs and CubeSats/HALE-UAVs in order to improve global access availability and energy efficiency. The main reason why the QMARL-based scheduler can be beneficial is that the algorithm facilitates a logarithmic-scale reduction in scheduling action dimensions, which is one critical feature as the number of CubeSats and HALE-UAVs expands. Additionally, individual GSs have different traffic demands depending on their locations and characteristics, thus it is essential to provide differentiated access services. The superiority of the proposed scheduler is validated through data-intensive experiments in realistic CubeSat/HALE-UAV settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16994v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gyu Seon Kim, Yeryeong Cho, Jaehyun Chung, Soohyun Park, Soyi Jung, Zhu Han, Joongheon Kim</dc:creator>
    </item>
    <item>
      <title>Benchmarking mortality risk prediction from electrocardiograms</title>
      <link>https://arxiv.org/abs/2406.17002</link>
      <description>arXiv:2406.17002v2 Announce Type: new 
Abstract: Several recent high-impact studies leverage large hospital-owned electrocardiographic (ECG) databases to model and predict patient mortality. MIMIC-IV, released September 2023, is the first comparable public dataset and includes 800,000 ECGs from a U.S. hospital system. Previously, the largest public ECG dataset was Code-15, containing 345,000 ECGs collected during routine care in Brazil. These datasets now provide an excellent resource for a broader audience to explore ECG survival modeling. Here, we benchmark survival model performance on Code-15 and MIMIC-IV with two neural network architectures, compare four deep survival modeling approaches to Cox regressions trained on classifier outputs, and evaluate performance at one to ten years. Our results yield AUROC and concordance scores comparable to past work (circa 0.8) and reasonable AUPRC scores (MIMIC-IV: 0.4-0.5, Code-15: 0.05-0.13) considering the fraction of ECG samples linked to a mortality (MIMIC-IV: 27\%, Code-15: 4\%). When evaluating models on the opposite dataset, AUROC and concordance values drop by 0.1-0.15, which may be due to cohort differences. All code and results are made public.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17002v2</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Platon Lukyanenko, Joshua Mayourian, Mingxuan Liu, John K. Triedman, Sunil J. Ghelani, William G. La Cava</dc:creator>
    </item>
    <item>
      <title>MIMO-OFDM ISAC Waveform Design for Range-Doppler Sidelobe Suppression</title>
      <link>https://arxiv.org/abs/2406.17218</link>
      <description>arXiv:2406.17218v1 Announce Type: new 
Abstract: Integrated sensing and communication (ISAC) is a key enabling technique for future wireless networks owing to its efficient hardware and spectrum utilization. In this paper, we focus on dual-functional waveform design for a multi-input multi-output (MIMO) orthogonal frequency division multiplexing (OFDM) ISAC system, which is considered to be a promising solution for practical deployment. Since the dual-functional waveform carries communication information, its random nature leads to high range-Doppler sidelobes in the ambiguity function, which in turn degrades radar sensing performance. To suppress range-Doppler sidelobes, we propose a novel symbol-level precoding (SLP) based waveform design for MIMO-OFDM ISAC systems by fully exploiting the temporal degrees of freedom (DoFs). Our goal is to minimize the range-Doppler integrated sidelobe level (ISL) while satisfying the constraints of target illumination power, multi-user communication quality of service (QoS), and constant-modulus transmission. To solve the resulting non-convex waveform design problem, we develop an efficient algorithm using the majorization-minimization (MM) and alternative direction method of multipliers (ADMM) methods. Simulation results show that the proposed waveform has significantly reduced range-Doppler sidelobes compared with signals designed only for communications and other baselines. In addition, the proposed waveform design achieves target detection and estimation performance close to that achievable by waveforms designed only for radar, which demonstrates the superiority of the proposed SLP-based ISAC approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17218v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peishi Li, Ming Li, Rang Liu, Qian Liu, A. Lee Swindlehurst</dc:creator>
    </item>
    <item>
      <title>A Near-Field Super-Resolution Network for Accelerating Antenna Characterization</title>
      <link>https://arxiv.org/abs/2406.17244</link>
      <description>arXiv:2406.17244v1 Announce Type: new 
Abstract: We present a deep neural network-enabled method to accelerate near-field (NF) antenna measurement. We develop a Near-field Super-resolution Network (NFS-Net) to reconstruct significantly undersampled near-field data as high-resolution data, which considerably reduces the number of sampling points required for NF measurement and thus improves measurement efficiency. The high-resolution near-field data reconstructed by the network is further processed by a near-field-to-far-field (NF2FF) transformation to obtain far-field antenna radiation patterns. Our experiments demonstrate that the NFS-Net exhibits both accuracy and generalizability in restoring high-resolution near-field data from low-resolution input. The NF measurement workflow that combines the NFS-Net and the NF2FF algorithm enables accurate radiation pattern characterization with only 11% of the Nyquist rate samples. Though the experiments in this study are conducted on a planar setup with a uniform grid, the proposed method can serve as a universal strategy to accelerate measurements under different setups and conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17244v1</guid>
      <category>eess.SP</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuchen Gu, Hai-Han Sun, Daniel W. van der Weide</dc:creator>
    </item>
    <item>
      <title>Consistent Spectrogram Separation from Nonstationary Mixture</title>
      <link>https://arxiv.org/abs/2406.17314</link>
      <description>arXiv:2406.17314v1 Announce Type: new 
Abstract: We present a spectrogram separation method tailored for mixtures comprising two nonstationary components. By exploiting the unique characteristics of their time-frequency representations, we propose an inverse problem formulation to estimate the spectrograms of the components. We then introduce an alternating optimization algorithm that ensures the consistency of the estimated spectrograms. The efficacy of the algorithm is evaluated through testing on synthetic mixtures and is applied to a bioacoustic signal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17314v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>EUSIPCO 2024, Aug 2024, Lyon, France</arxiv:journal_reference>
      <dc:creator>Adrien Meynard (Phys-ENS), Ama Marina Kreme (LIS, I2M)</dc:creator>
    </item>
    <item>
      <title>Relaxed Multi-Tx DDM Online Calibration</title>
      <link>https://arxiv.org/abs/2406.17320</link>
      <description>arXiv:2406.17320v1 Announce Type: new 
Abstract: In multiple-input and multiple-output (MIMO) radar systems based on Doppler-division multiplexing (DDM), phase shifters are employed in the transmit paths and require calibration strategies to maintain optimal performance all along the radar system's life cycle. In this paper, we propose a novel family of DDM codes that enable an online calibration of the phase shifters that scale realistically to any number of simultaneously activated transmit (Tx)-channels during the calibration frames. To achieve this goal we employ the previously developed odd-DDM (ODDM) sequences to design calibration DDM codes with reduced inter-Tx leakage. The proposed calibration sequence is applied to an automotive radar data set modulated with erroneous phase shifters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17320v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mayeul Jeannin, Oliver Lang, Farhan Bin Khalid, Dian Tresna Nugraha, Mario Huemer</dc:creator>
    </item>
    <item>
      <title>Speaker-Independent Acoustic-to-Articulatory Inversion through Multi-Channel Attention Discriminator</title>
      <link>https://arxiv.org/abs/2406.17329</link>
      <description>arXiv:2406.17329v1 Announce Type: new 
Abstract: We present a novel speaker-independent acoustic-to-articulatory inversion (AAI) model, overcoming the limitations observed in conventional AAI models that rely on acoustic features derived from restricted datasets. To address these challenges, we leverage representations from a pre-trained self-supervised learning (SSL) model to more effectively estimate the global, local, and kinematic pattern information in Electromagnetic Articulography (EMA) signals during the AAI process. We train our model using an adversarial approach and introduce an attention-based Multi-duration phoneme discriminator (MDPD) designed to fully capture the intricate relationship among multi-channel articulatory signals. Our method achieves a Pearson correlation coefficient of 0.847, marking state-of-the-art performance in speaker-independent AAI models. The implementation details and code can be found online.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17329v1</guid>
      <category>eess.SP</category>
      <category>cs.SD</category>
      <category>eess.AS</category>
      <category>physics.bio-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Woo-Jin Chung, Hong-Goo Kang</dc:creator>
    </item>
    <item>
      <title>Development of a digital tool for monitoring the behaviour of pre-weaned calves using accelerometer neck-collars</title>
      <link>https://arxiv.org/abs/2406.17352</link>
      <description>arXiv:2406.17352v1 Announce Type: new 
Abstract: Automatic monitoring of calf behaviour is a promising way of assessing animal welfare from their first week on farms. This study aims to (i) develop machine learning models from accelerometer data to classify the main behaviours of pre-weaned calves and (ii) set up a digital tool for monitoring the behaviour of pre-weaned calves from the models' prediction. Thirty pre-weaned calves were equipped with a 3-D accelerometer attached to a neck-collar for two months and filmed simultaneously. The behaviours were annotated, resulting in 27.4 hours of observation aligned with the accelerometer data. The time-series were then split into 3 seconds windows. Two machine learning models were tuned using data from 80% of the calves: (i) a Random Forest model to classify between active and inactive behaviours using a set of 11 hand-craft features [model 1] and (ii) a RidgeClassifierCV model to classify between lying, running, drinking milk and other behaviours using ROCKET features [model 2]. The performance of the models was tested using data from the remaining 20% of the calves. Model 1 achieved a balanced accuracy of 0.92. Model 2 achieved a balanced accuracy of 0.84. Behavioural metrics such as daily activity ratio and episodes of running, lying, drinking milk, and other behaviours expressed over time were deduced from the predictions. All the development was finally embedded into a Python dashboard so that the individual calf metrics could be displayed directly from the raw accelerometer files.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17352v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>European Conference on Precision Livestock Farming, Sep 2024, Bologne (ITA), Italy</arxiv:journal_reference>
      <dc:creator>Oshana Dissanayake (UCD), Sarah E. Mcpherson (Teagasc, WUR), Joseph Allyndr\'ee (UCD), Emer Kennedy (Teagasc), P\'adraig Cunningham (UCD), Lucile Riaboff (GenPhySE, INRAE)</dc:creator>
    </item>
    <item>
      <title>Environmental Variation or Instrumental Drift? A Probabilistic Approach to Gas Sensor Drift Modeling and Evaluation</title>
      <link>https://arxiv.org/abs/2406.17488</link>
      <description>arXiv:2406.17488v1 Announce Type: new 
Abstract: Drift is a significant issue that undermines the reliability of gas sensors. This paper introduces a probabilistic model to distinguish between environmental variation and instrumental drift, using low-cost non-dispersive infrared (NDIR) CO2 sensors as a case study. Data from a long-term field experiment is analyzed to evaluate both sensor performance and environmental changes over time. Our approach employs importance sampling to isolate instrumental drift from environmental variation, providing a more accurate assessment of sensor performance. The results show that failing to account for environmental variation can significantly affect the evaluation of sensor drift, leading to improper calibration processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17488v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cheng Yang, Gustav Bohlin, Tobias Oechtering</dc:creator>
    </item>
    <item>
      <title>Experimental Investigation of a Recurrent Optical Spectrum Slicing Receiver for Intensity Modulation/Direct Detection systems using Programmable Photonics</title>
      <link>https://arxiv.org/abs/2406.16869</link>
      <description>arXiv:2406.16869v1 Announce Type: cross 
Abstract: In this paper, we experimentally validate our previous numerical works in recurrent optical spectrum slicing (ROSS) accelerators for dispersion compensation in high-speed IM/DD links. For this, we utilize recurrent filters implemented both through a waveshaper and by exploiting novel integrated programmable photonic platforms. Different recurrent configurations are tested. The ROSS accelerators exploit frequency processing through recurrent optical filter nodes in order to mitigate the power fading effect, which hinders the transmission distance and baudrate scalability of IM/DD systems. By equalizing even 80 km of 64 Gb/s PAM-4 transmission in C-band, we prove that our system can offer an appealing solution in highly dispersive channels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16869v1</guid>
      <category>physics.optics</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kostas Sozos, Francesco Da Ros, Metodi P. Yankov, George Sarantoglou, Stavros Deligiannidis, Charis Mesaritakis, Adonis Bogris</dc:creator>
    </item>
    <item>
      <title>Evaluating the Influence of Temporal Context on Automatic Mouse Sleep Staging through the Application of Human Models</title>
      <link>https://arxiv.org/abs/2406.16911</link>
      <description>arXiv:2406.16911v1 Announce Type: cross 
Abstract: In human sleep staging models, augmenting the temporal context of the input to the range of tens of minutes has recently demonstrated performance improvement. In contrast, the temporal context of mouse sleep staging models is typically in the order of tens of seconds. While long-term time patterns are less clear in mouse sleep, increasing the temporal context further than that of the current mouse sleep staging models might still result in a performance increase, given that the current methods only model very short term patterns. In this study, we examine the influence of increasing the temporal context in mouse sleep staging up to 15 minutes in three mouse cohorts using two recent and high-performing human sleep staging models that account for long-term dependencies. These are compared to two prominent mouse sleep staging models that use a local context of 12 s and 20 s, respectively. An increase in context up to 28 s is observed to have a positive impact on sleep stage classification performance, especially in REM sleep. However, the impact is limited for longer context windows. One of the human sleep scoring models, L-SeqSleepNet, outperforms both mouse models in all cohorts. This suggests that mouse sleep staging can benefit from more temporal context than currently used.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16911v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Javier Garc\'ia Ciudad, Morten M{\o}rup, Birgitte Rahbek Kornum, Alexander Neergaard Zahid</dc:creator>
    </item>
    <item>
      <title>Research on Feature Extraction Data Processing System For MRI of Brain Diseases Based on Computer Deep Learning</title>
      <link>https://arxiv.org/abs/2406.16981</link>
      <description>arXiv:2406.16981v1 Announce Type: cross 
Abstract: Most of the existing wavelet image processing techniques are carried out in the form of single-scale reconstruction and multiple iterations. However, processing high-quality fMRI data presents problems such as mixed noise and excessive computation time. This project proposes the use of matrix operations by combining mixed noise elimination methods with wavelet analysis to replace traditional iterative algorithms. Functional magnetic resonance imaging (fMRI) of the auditory cortex of a single subject is analyzed and compared to the wavelet domain signal processing technology based on repeated times and the world's most influential SPM8. Experiments show that this algorithm is the fastest in computing time, and its detection effect is comparable to the traditional iterative algorithm. However, this has a higher practical value for the processing of FMRI data. In addition, the wavelet analysis method proposed signal processing to speed up the calculation rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16981v1</guid>
      <category>eess.IV</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Lingxi Xiao, Jinxin Hu, Yutian Yang, Yinqiu Feng, Zichao Li, Zexi Chen</dc:creator>
    </item>
    <item>
      <title>Optimizing Configuration Selection in Reconfigurable-Antenna MIMO Systems: Physics-Inspired Heuristic Solvers</title>
      <link>https://arxiv.org/abs/2406.17339</link>
      <description>arXiv:2406.17339v1 Announce Type: cross 
Abstract: Reconfigurable antenna multiple-input multiple-output (MIMO) is a foundational technology for the continuing evolution of cellular systems, including upcoming 6G communication systems. In this paper, we address the problem of flexible/reconfigurable antenna configuration selection for point-to-point MIMO antenna systems by using physics-inspired heuristics. Firstly, we optimize the antenna configuration to maximize the signal-to-noise ratio (SNR) at the receiver by leveraging two basic heuristic solvers, i.e., coherent Ising machines (CIMs), that mimic quantum mechanical dynamics, and quantum annealing (QA), where a real-world QA architecture is considered (D-Wave). A mathematical framework that converts the configuration selection problem into CIM- and QA- compatible unconstrained quadratic formulations is investigated. Numerical and experimental results show that the proposed designs outperform classical counterparts and achieve near-optimal performance (similar to exhaustive search with exponential complexity) while ensuring polynomial complexity. Moreover, we study the optimal antenna configuration that maximizes the end-to-end Shannon capacity. A simulated annealing (SA) heuristic which achieves near-optimal performance through appropriate parameterization is adopted. A modified version of the basic SA that exploits parallel tempering to avoid local maxima is also studied, which provides additional performance gains. Extended numerical studies show that the SA solutions outperform conventional heuristics (which are also developed for comparison purposes), while the employment of the SNR-based solutions is highly sub-optimal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17339v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>IEEE Transactions on Communications, 2004</arxiv:journal_reference>
      <dc:creator>I. Krikidis, C. Psomas, A. K. Singh, K. Jamieson</dc:creator>
    </item>
    <item>
      <title>SincVAE: a New Approach to Improve Anomaly Detection on EEG Data Using SincNet and Variational Autoencoder</title>
      <link>https://arxiv.org/abs/2406.17537</link>
      <description>arXiv:2406.17537v1 Announce Type: cross 
Abstract: Over the past few decades, electroencephalography (EEG) monitoring has become a pivotal tool for diagnosing neurological disorders, particularly for detecting seizures. Epilepsy, one of the most prevalent neurological diseases worldwide, affects approximately the 1 \% of the population. These patients face significant risks, underscoring the need for reliable, continuous seizure monitoring in daily life. Most of the techniques discussed in the literature rely on supervised Machine Learning (ML) methods. However, the challenge of accurately labeling variations in epileptic EEG waveforms complicates the use of these approaches. Additionally, the rarity of ictal events introduces an high imbalancing within the data, which could lead to poor prediction performance in supervised learning approaches. Instead, a semi-supervised approach allows to train the model only on data not containing seizures, thus avoiding the issues related to the data imbalancing. This work proposes a semi-supervised approach for detecting epileptic seizures from EEG data, utilizing a novel Deep Learning-based method called SincVAE. This proposal incorporates the learning of an ad-hoc array of bandpass filter as a first layer of a Variational Autoencoder (VAE), potentially eliminating the preprocessing stage where informative band frequencies are identified and isolated. Results indicate that SincVAE improves seizure detection in EEG data and is capable of identifying early seizures during the preictal stage as well as monitoring patients throughout the postictal stage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17537v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrea Pollastro, Francesco Isgr\`o, Roberto Prevete</dc:creator>
    </item>
    <item>
      <title>Constructing structured tensor priors for Bayesian inverse problems</title>
      <link>https://arxiv.org/abs/2406.17597</link>
      <description>arXiv:2406.17597v1 Announce Type: cross 
Abstract: Specifying a prior distribution is an essential part of solving Bayesian inverse problems. The prior encodes a belief on the nature of the solution and this regularizes the problem. In this article we completely characterize a Gaussian prior that encodes the belief that the solution is a structured tensor. We first define the notion of (A,b)-constrained tensors and show that they describe a large variety of different structures such as Hankel, circulant, triangular, symmetric, and so on. Then we completely characterize the Gaussian probability distribution of such tensors by specifying its mean vector and covariance matrix. Furthermore, explicit expressions are proved for the covariance matrix of tensors whose entries are invariant under a permutation. These results unlock a whole new class of priors for Bayesian inverse problems. We illustrate how new kernel functions can be designed and efficiently computed and apply our results on two particular Bayesian inverse problems: completing a Hankel matrix from a few noisy measurements and learning an image classifier of handwritten digits. The effectiveness of the proposed priors is demonstrated for both problems. All applications have been implemented as reactive Pluto notebooks in Julia.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17597v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kim Batselier</dc:creator>
    </item>
    <item>
      <title>Distributed Training of Large Graph Neural Networks with Variable Communication Rates</title>
      <link>https://arxiv.org/abs/2406.17611</link>
      <description>arXiv:2406.17611v1 Announce Type: cross 
Abstract: Training Graph Neural Networks (GNNs) on large graphs presents unique challenges due to the large memory and computing requirements. Distributed GNN training, where the graph is partitioned across multiple machines, is a common approach to training GNNs on large graphs. However, as the graph cannot generally be decomposed into small non-interacting components, data communication between the training machines quickly limits training speeds. Compressing the communicated node activations by a fixed amount improves the training speeds, but lowers the accuracy of the trained GNN. In this paper, we introduce a variable compression scheme for reducing the communication volume in distributed GNN training without compromising the accuracy of the learned model. Based on our theoretical analysis, we derive a variable compression method that converges to a solution equivalent to the full communication case, for all graph partitioning schemes. Our empirical results show that our method attains a comparable performance to the one obtained with full communication. We outperform full communication at any fixed compression ratio for any communication budget.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17611v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Juan Cervino, Md Asadullah Turja, Hesham Mostafa, Nageen Himayat, Alejandro Ribeiro</dc:creator>
    </item>
    <item>
      <title>RAPID: Retrofitting IEEE 802.11ay Access Points for Indoor Human Detection and Sensing</title>
      <link>https://arxiv.org/abs/2109.04819</link>
      <description>arXiv:2109.04819v4 Announce Type: replace 
Abstract: In this work we present RAPID, the first joint communication and radar system based on next-generation IEEE 802.11ay WiFi networks operating in the 60 GHz band. Unlike existing approaches for human sensing at millimeter-wave frequencies, which rely on special-purpose radars, RAPID achieves radar-level sensing accuracy with IEEE 802.11ay access points, thus avoiding the burden of installing ad-hoc sensors. RAPID enables contactless human sensing applications, such as people tracking, Human Activity Recognition (HAR), and person identification without requiring modifications to the standard packet structure. Specifically, we leverage IEEE 802.11ay beam training to accurately localize and track multiple individuals within the same environment. Then, we propose a new way of using beam tracking to extract micro-Doppler signatures from the time-varying Channel Impulse Response (CIR) estimated from reflected packets. Such signatures are fed to a deep learning classifier to perform HAR and person identification. RAPID is implemented on a cutting-edge IEEE 802.11ay-compatible FPGA platform with phased antenna arrays, and evaluated on a large dataset of CIR measurements. It is robust across different environments and subjects, and outperforms state-of-the-art sub-6 GHz WiFi sensing techniques. Using two access points, RAPID reliably tracks multiple subjects, reaching HAR and person identification accuracies of 94% and 90%, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2109.04819v4</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TMC.2023.3291882</arxiv:DOI>
      <dc:creator>Jacopo Pegoraro, Jesus Omar Lacruz, Francesca Meneghello, Enver Bashirov, Michele Rossi, Joerg Widmer</dc:creator>
    </item>
    <item>
      <title>Empirical Validation of a Class of Ray-Based Fading Models</title>
      <link>https://arxiv.org/abs/2307.15467</link>
      <description>arXiv:2307.15467v2 Announce Type: replace 
Abstract: As new wireless standards are developed, the use of higher operation frequencies comes in hand with new use cases and propagation effects that differ from the well-established state of the art. Numerous stochastic fading models have recently emerged under the umbrella of generalized fading conditions, to provide a fine-grain characterization of propagation channels in the mmWave and sub-THz bands. For the first time in literature, this work carries out an experimental validation of a class of such ray-based models, in a wide range of propagation conditions (anechoic, reverberation and indoor) at mmWave bands. We show that the independently fluctuating two-ray (IFTR) model has good capabilities to recreate rather dissimilar environments with high accuracy. We also put forth that the key limitations of the IFTR model arise in the presence of reduced diffuse propagation, and also due to a limited phase variability for the dominant specular components.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.15467v2</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Juan E. Galeote-Cazorla, Alejandro Ram\'irez-Arroyo, F. Javier Lopez-Martinez, Juan F. Valenzuela-Vald\'es</dc:creator>
    </item>
    <item>
      <title>Few-Shot Recognition and Classification Framework for Jamming Signal: A CGAN-Based Fusion CNN Approach</title>
      <link>https://arxiv.org/abs/2311.05273</link>
      <description>arXiv:2311.05273v3 Announce Type: replace 
Abstract: Subject to intricate environmental variables, the precise classification of jamming signals holds paramount significance in the effective implementation of anti-jamming strategies within communication systems. In light of this imperative, we propose an innovative fusion algorithm based on conditional generative adversarial network (CGAN) and convolutional neural network (CNN), which aims to deal with the difficulty in applying deep learning (DL) algorithms due to the instantaneous nature of jamming signals in practical communication systems. Compared with previous methods, our algorithm embeds jamming category labels to constrain the range of generated signals in the frequency domain by using the CGAN model, which simultaneously captures potential label information while learning the distribution of signal data thus achieves an 8% improvement in accuracy even when working with a few-sample dataset. Real-world satellite communication scenarios are simulated by adopting hardware platform, and we validate our algorithm by using the resulting time-domain waveform data. The experimental results indicate that our algorithm still performs extremely well, which demonstrates significant potential for practical application in real-world communication scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.05273v3</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xuhui Ding, Yue Zhang, Gaoyang Li, Xiaozheng Gao, Neng Ye, Dusit Niyato, Kai Yang</dc:creator>
    </item>
    <item>
      <title>Pseudorange Rigidity and Solvability of Cooperative GNSS Positioning</title>
      <link>https://arxiv.org/abs/2401.05025</link>
      <description>arXiv:2401.05025v2 Announce Type: replace 
Abstract: Global Navigation Satellite Systems (GNSS) are a widely used technology for positioning and navigation. GNSS positioning relies on pseudorange measurements from satellites to receivers. A pseudorange is the apparent distance between two agents deduced from the time-of-flight of a signal sent from one agent to the other. Because of the lack of synchronization between the agents' clocks, it is a biased version of their distance. This paper introduces a new rigidity theory adapted to pseudorange measurements. The peculiarity of pseudoranges is that they are asymmetrical measurements. Therefore, unlike other usual rigidities, the graphs of pseudorange frameworks are directed. In this paper, pseudorange rigidity is proved to be a generic property of the underlying undirected graph of constraints. The main result is a characterization of rigid pseudorange graphs as combinations of rigid distance graphs and connected graphs. This new theory is adapted for GNSS. It provides new insights into the minimum number of satellites needed to locate a receiver, and is applied to the localization of GNSS cooperative networks of receivers. The interests of asymmetrical constraints in the context of formation control are also discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.05025v2</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Colin Cros (GIPSA-INFINITY, GIPSA-GAIA), Pierre-Olivier Amblard (GIPSA-GAIA), Christophe Prieur (GIPSA-INFINITY), Jean-Fran\c{c}ois Da Rocha</dc:creator>
    </item>
    <item>
      <title>Sensing in Bi-Static ISAC Systems with Clock Asynchronism: A Signal Processing Perspective</title>
      <link>https://arxiv.org/abs/2402.09048</link>
      <description>arXiv:2402.09048v2 Announce Type: replace 
Abstract: Integrated Sensing and Communication (ISAC) has been identified as a pillar usage scenario for the impending 6G era. Bi-static sensing, a major type of sensing in ISAC, is promising to expedite ISAC in the near future, as it requires minimal changes to the existing network infrastructure. However, a critical challenge for bi-static sensing is clock asynchronism due to the use of different clocks at far-separated transmitters and receivers. This causes the received signal to be affected by time-varying random phase offsets, severely degrading, or even failing, direct sensing. Hence, to effectively enable ISAC, considerable research has been directed toward addressing the clock asynchronism issue in bi-static sensing. This paper provides an overview of the issue and existing techniques developed in an ISAC background. Based on the review and comparison, we also draw insights into the future research directions and open problems, aiming to nurture the maturation of bi-static sensing in ISAC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.09048v2</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Kai Wu, Jacopo Pegoraro, Francesca Meneghello, J. Andrew Zhang, Jesus O. Lacruz, Joerg Widmer, Francesco Restuccia, Michele Rossi, Xiaojing Huang, Daqing Zhang, Giuseppe Caire, Y. Jay Guo</dc:creator>
    </item>
    <item>
      <title>A Probabilistic Focalization Approach for Single Receiver Underwater Localization</title>
      <link>https://arxiv.org/abs/2403.03384</link>
      <description>arXiv:2403.03384v2 Announce Type: replace 
Abstract: We introduce a Bayesian estimation approach for the passive localization of an acoustic source in shallow water using a single mobile receiver. The proposed probabilistic focalization method estimates the time-varying source location in the presence of measurement-origin uncertainty. In particular, probabilistic data association is performed to match time-differences-of-arrival (TDOA) observations extracted from the acoustic signal to TDOAs predictions provided by the statistical model. The performance of our approach is evaluated using real acoustic data recorded by a single mobile receiver.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.03384v2</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luisa Watkins, Pietro Stinco, Alessandra Tesei, Florian Meyer</dc:creator>
    </item>
    <item>
      <title>Full-Space Wireless Sensing Enabled by Multi-Sector Intelligent Surfaces</title>
      <link>https://arxiv.org/abs/2406.15945</link>
      <description>arXiv:2406.15945v2 Announce Type: replace 
Abstract: The multi-sector intelligent surface (IS), benefiting from a smarter wave manipulation capability, has been shown to enhance channel gain and offer full-space coverage in communications. However, the benefits of multi-sector IS in wireless sensing remain unexplored. This paper introduces the application of multi-sector IS for wireless sensing/localization. Specifically, we propose a new self-sensing system, where an active source controller uses the multi-sector IS geometry to reflect/scatter the emitted signals towards the entire space, thereby achieving full-space coverage for wireless sensing. Additionally, dedicated sensors are installed aligned with the IS elements at each sector, which collect echo signals from the target and cooperate to sense the target angle. In this context, we develop a maximum likelihood estimator of the target angle for the proposed multi-sector IS self-sensing system, along with the corresponding theoretical limits defined by the Cram\'er-Rao Bound. The analysis reveals that the advantages of the multi-sector IS self-sensing system stem from two aspects: enhancing the probing power on targets (thereby improving power efficiency) and increasing the rate of target angle (thereby enhancing the transceiver's sensitivity to target angles). Finally, our analysis and simulations confirm that the multi-sector IS self-sensing system, particularly the 4-sector architecture, achieves full-space sensing capability beyond the single-sector IS configuration. Furthermore, similarly to communications, employing directive antenna patterns on each sector's IS elements and sensors significantly enhances sensing capabilities. This enhancement originates from both aspects of improved power efficiency and target angle sensitivity, with the former also being observed in communications while the latter being unique in sensing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15945v2</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yumeng Zhang, Xiaodan Shao, Hongyu Li, Bruno Clerckx, Rui Zhang</dc:creator>
    </item>
    <item>
      <title>Probabilistic Approach for Detection of High-Frequency Periodic Signals using an Event Camera</title>
      <link>https://arxiv.org/abs/2205.04691</link>
      <description>arXiv:2205.04691v4 Announce Type: replace-cross 
Abstract: Being inspired by the biological eye, event camera is a novel asynchronous technology that pose a paradigm shift in acquisition of visual information. This paradigm enables event cameras to capture pixel-size fast motions much more naturally compared to classical cameras.
  In this paper we present a new asynchronous event-driven algorithm for detection of high-frequency pixel-size periodic signals using an event camera. Development of such new algorithms, to efficiently process the asynchronous information of event cameras, is essential and being a main challenge in the research community, in order to utilize its special properties and potential.
  It turns out that this algorithm, that was developed in order to satisfy the new paradigm, is related to an untreated theoretical problem in probability: let $0\leq\tau_{1}\leq\tau_{2}\leq\cdots\leq\tau_{m}\leq1$, originated from an unknown distribution. Let also $\epsilon,\delta\in\mathbb{R}$, and $d\in\mathbb{N}$. What can be said about the probability $\Phi(m,d)$ of having more than $d$ adjacent $\tau_{i}$-s pairs that the distance between them is $\delta$, up to an error $\epsilon$ ? This problem, that reminds the area of order statistic, shows how the new visualization paradigm is also an opportunity to develop new areas and problems in mathematics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.04691v4</guid>
      <category>cs.CV</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David El-Chai Ben-Ezra, Ron Arad, Ayelet Padowicz, Israel Tugendhaft</dc:creator>
    </item>
    <item>
      <title>Design Space Exploration for Particle Detector Read-out Implementations in Matlab and Simulink on the Example of the SHiP SBT</title>
      <link>https://arxiv.org/abs/2402.03122</link>
      <description>arXiv:2402.03122v3 Announce Type: replace-cross 
Abstract: On a very fundamental level, particle detectors share similar requirements for their read-out chain. This is reflected in the way that typical read-out solutions are developed, where a previous design is taken and modified to fit some changes in requirements. One of the two common approaches is the current-based read-out, where the waveform of the sensor output is sampled in order to later extract information from there. This approach is used in many detector applications using scintillation based detectors, including PET. With this contribution, we will introduce how we use Matlab in order to simulate the read-out electronics of particle detectors. We developed this simulation approach as a base for our ongoing development of software-defined read-out ASICs that cover the requirements of a variety of particle detector types. Simulink was chosen as a base for our developments as it allows simulation of mixed-signal systems and comes with built-in toolkits to aid in developments of such systems. With our approach, we want to take a new look at how we approach designing such a read-out, with a focus on digital signal processing close to the sensor, making use of known signal characteristics and modern methods of communications engineering. We are taking into account the time profile of an event, the bandwidth-limiting properties of the sensor and attached electronics, digitization stages and finally the parameterization of approaches for digital processing of the signal. We will show how we are applying the design approach to the development of a read-out for the proposed SHiP SBT detector, which is a scintillation based detector relying on SiPMs sensors, using this as an example for our modelling approach and show preliminary results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.03122v3</guid>
      <category>physics.ins-det</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Florian R\"ossing, David Arutinov, Alessia Brignoli, Horst Fischer, Christian Grewing, Heiko Lacker, Fairhurst Lyons, Andr\'e Zambanini, Stefan van Waasen</dc:creator>
    </item>
    <item>
      <title>On the Spectral Efficiency of Indoor Wireless Networks with a Rotary Uniform Linear Array</title>
      <link>https://arxiv.org/abs/2402.05583</link>
      <description>arXiv:2402.05583v2 Announce Type: replace-cross 
Abstract: Contemporary wireless communication systems rely on Multi-User Multiple-Input Multiple-Output (MU-MIMO) techniques. In such systems, each Access Point (AP) is equipped with multiple antenna elements and serves multiple devices simultaneously. Notably, traditional systems utilize fixed antennas, i.e., antennas without any movement capabilities, while the idea of movable antennas has recently gained traction among the research community. By moving in a confined region, movable antennas are able to exploit the wireless channel variation in the continuous domain. This additional degree of freedom may enhance the quality of the wireless links, and consequently the communication performance. However, movable antennas for MU-MIMO proposed in the literature are complex, bulky, expensive and present a high power consumption. In this paper, we propose an alternative to such systems that has lower complexity and lower cost. More specifically, we propose the incorporation of rotation capabilities to APs equipped with Uniform Linear Arrays (ULAs) of antennas. We consider the uplink of an indoor scenario where the AP serves multiple devices simultaneously. The optimal rotation of the ULA is computed based on estimates of the positions of the active devices and aiming at maximizing the per-user mean achievable Spectral Efficiency (SE). Adopting a spatially correlated Rician channel model, our numerical results show that the rotation capabilities of the AP can bring substantial improvements in the SE in scenarios where the line-of-sight component of the channel vectors is strong. Moreover, our proposed system is robust against imperfect positioning estimates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.05583v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eduardo Noboro Tominaga, Onel Luis Alcaraz L\'opez, Tommy Svensson, Richard Demo Souza, Hirley Alves</dc:creator>
    </item>
    <item>
      <title>Fast Group Scheduling for Downlink Large-Scale Multi-Group Multicast Beamforming</title>
      <link>https://arxiv.org/abs/2403.10002</link>
      <description>arXiv:2403.10002v2 Announce Type: replace-cross 
Abstract: Next-generation wireless networks need to handle massive user access effectively. This paper addresses the problem of joint group scheduling and multicast beamforming for downlink transmission with many active user groups. Aiming to maximize the minimum user throughput, we propose a three-phase approach to tackle this difficult joint optimization problem efficiently. In Phase 1, we utilize the optimal multicast beamforming structure obtained recently to find the group-channel directions for all groups. We propose two low-complexity group scheduling algorithms in Phase 2, which determine the subset of groups in each time slot sequentially and the total number of time slots required for all groups. The first algorithm measures the level of spatial separation among groups and selects the dissimilar groups that maximize the minimum user rate into the same time slot. In contrast, the second algorithm first identifies the spatially correlated groups via a learning-based clustering method based on the group-channel directions, and then separates spatially similar groups into different time slots. Finally, the multicast beamformers for the scheduled groups are obtained in each time slot by a computationally efficient method. Simulation results show that our proposed scheduling methods can effectively capture the level of spatial separation among groups to improve the minimum user throughput over the conventional approach that serves all groups in a single time slot or one group per time slot, and can be executed with low computational complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10002v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chong Zhang, Min Dong, Ben Liang, Ali Afana, Yahia Ahmed</dc:creator>
    </item>
    <item>
      <title>Detection of Malicious Agents in Social Learning</title>
      <link>https://arxiv.org/abs/2403.12619</link>
      <description>arXiv:2403.12619v4 Announce Type: replace-cross 
Abstract: Non-Bayesian social learning is a framework for distributed hypothesis testing aimed at learning the true state of the environment. Traditionally, the agents are assumed to receive observations conditioned on the same true state, although it is also possible to examine the case of heterogeneous models across the graph. One important special case is when heterogeneity is caused by the presence of malicious agents whose goal is to move the agents toward a wrong hypothesis. In this work, we propose an algorithm that allows discovering the true state of every individual agent based on the sequence of their beliefs. In so doing, the methodology is also able to locate malicious behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12619v4</guid>
      <category>cs.SI</category>
      <category>cs.MA</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Valentina Shumovskaia, Mert Kayaalp, Ali H. Sayed</dc:creator>
    </item>
    <item>
      <title>Optimal sensing policy with interference-model uncertainty</title>
      <link>https://arxiv.org/abs/2406.06280</link>
      <description>arXiv:2406.06280v3 Announce Type: replace-cross 
Abstract: Assume that an interferer behaves according to a parametric model but one does not know the value of the model parameters. Sensing enables to improve the model knowledge and therefore perform a better link adaptation. However, we consider a half-duplex scenario where, at each time slot, the communication system should decide between sensing and communication. We thus propose to investigate the optimal policy to maximize the expected sum rate given a finite-time communication. % the following question therefore arises: At a given time slot, should one sense or communicate? We first show that this problem can be modelled in the Markov decision process (MDP) framework. We then demonstrate that the optimal open-loop and closed-loop policies can be found significantly faster than the standard backward-induction algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06280v3</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vincent Corlay, Jean-Christophe Sibel, Nicolas Gresset</dc:creator>
    </item>
  </channel>
</rss>
