<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 25 Dec 2024 02:30:27 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Temporal Explorability Games</title>
      <link>https://arxiv.org/abs/2412.16328</link>
      <description>arXiv:2412.16328v1 Announce Type: new 
Abstract: Temporal graphs extend ordinary graphs with discrete time that affects the availability of edges. We consider solving games played on temporal graphs where one player aims to explore the graph, i.e., visit all vertices. The complexity depends majorly on two factors: the presence of an adversary and how edge availability is specified.
  We demonstrate that on static graphs, where edges are always available, solving explorability games is just as hard as solving reachability games. In contrast, on temporal graphs, the complexity of explorability coincides with generalized reachability (NP-complete for one-player and PSPACE- complete for two player games). We further show that if temporal graphs are given symbolically, even one-player reachability and thus explorability and generalized reachability games are PSPACE-hard. For one player, all these are also solvable in PSPACE and for two players, they are in PSPACE, EXP and EXP, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16328v1</guid>
      <category>cs.GT</category>
      <category>cs.LO</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pete Austin, Nicolas Mazzocchi, Sougata Bose, Patrick Totzke</dc:creator>
    </item>
    <item>
      <title>Algorithmic Contract Theory: A Survey</title>
      <link>https://arxiv.org/abs/2412.16384</link>
      <description>arXiv:2412.16384v1 Announce Type: new 
Abstract: A contract is an economic tool used by a principal to incentivize one or more agents to exert effort on her behalf, by defining payments based on observable performance measures. A key challenge addressed by contracts -- known in economics as moral hazard -- is that, absent a properly set up contract, agents might engage in actions that are not in the principal's best interest. Another common feature of contracts is limited liability, which means that payments can go only from the principal -- who has the deep pocket -- to the agents.
  With classic applications of contract theory moving online, growing in scale, and becoming more data-driven, tools from contract theory become increasingly important for incentive-aware algorithm design. At the same time, algorithm design offers a whole new toolbox for reasoning about contracts, ranging from additional tools for studying the tradeoff between simple and optimal contracts, through a language for discussing the computational complexity of contracts in combinatorial settings, to a formalism for analyzing data-driven contracts.
  This survey aims to provide a computer science-friendly introduction to the basic concepts of contract theory. We give an overview of the emerging field of "algorithmic contract theory" and highlight work that showcases the potential for interaction between the two areas. We also discuss avenues for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16384v1</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Paul Duetting, Michal Feldman, Inbal Talgam-Cohen</dc:creator>
    </item>
    <item>
      <title>Efficiently Solving Turn-Taking Stochastic Games with Extensive-Form Correlation</title>
      <link>https://arxiv.org/abs/2412.16934</link>
      <description>arXiv:2412.16934v1 Announce Type: new 
Abstract: We study equilibrium computation with extensive-form correlation in two-player turn-taking stochastic games. Our main results are two-fold: (1) We give an algorithm for computing a Stackelberg extensive-form correlated equilibrium (SEFCE), which runs in time polynomial in the size of the game, as well as the number of bits required to encode each input number. (2) We give an efficient algorithm for approximately computing an optimal extensive-form correlated equilibrium (EFCE) up to machine precision, i.e., the algorithm achieves approximation error $\varepsilon$ in time polynomial in the size of the game, as well as $\log(1 / \varepsilon)$.
  Our algorithm for SEFCE is the first polynomial-time algorithm for equilibrium computation with commitment in such a general class of stochastic games. Existing algorithms for SEFCE typically make stronger assumptions such as no chance moves, and are designed for extensive-form games in the less succinct tree form. Our algorithm for approximately optimal EFCE is, to our knowledge, the first algorithm that achieves 3 desiderata simultaneously: approximate optimality, polylogarithmic dependency on the approximation error, and compatibility with stochastic games in the more succinct graph form. Existing algorithms achieve at most 2 of these desiderata, often also relying on additional technical assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16934v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hanrui Zhang, Yu Cheng, Vincent Conitzer</dc:creator>
    </item>
    <item>
      <title>To Travel Quickly or to Park Conveniently: Coupled Resource Allocations with Multi-Karma Economies</title>
      <link>https://arxiv.org/abs/2412.17002</link>
      <description>arXiv:2412.17002v1 Announce Type: new 
Abstract: The large-scale allocation of public resources (e.g., transportation, energy) is among the core challenges of future Cyber-Physical-Human Systems (CPHS). In order to guarantee that these systems are efficient and fair, recent works have investigated non-monetary resource allocation schemes, including schemes that employ karma. Karma is a non-tradable token that flows from users gaining resources to users yielding resources. Thus far karma-based solutions considered the allocation of a single public resource, however, modern CPHS are complex as they involve the allocation of multiple coupled resources. For example, a user might want to trade-off fast travel on highways for convenient parking in the city center, and different users could have heterogeneous preferences for such coupled resources. In this paper, we explore how to optimally combine multiple karma economies for coupled resource allocations, using two mechanism-design instruments: (non-uniform) karma redistribution; and (non-unit) exchange rates. We first extend the existing Dynamic Population Game (DPG) model that predicts the Stationary Nash Equilibrium (SNE) of the multi-karma economies. Then, in a numerical case study, we demonstrate that the design of redistribution significantly affects the coupled resource allocations, while non-unit exchange rates play a minor role. To assess the allocation outcomes under user heterogeneity, we adopt Nash welfare as our social welfare function, since it makes no interpersonal comparisons and it is axiomatically rooted in social choice theory. Our findings suggest that the simplest mechanism design, that is, uniform redistribution with unit exchange rates, also attains maximum social welfare.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17002v1</guid>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ezzat Elokda, Andrea Censi, Saverio Bolognani, Florian D\"orfler, Emilio Frazzoli</dc:creator>
    </item>
    <item>
      <title>Matching Markets with Chores</title>
      <link>https://arxiv.org/abs/2412.17134</link>
      <description>arXiv:2412.17134v1 Announce Type: new 
Abstract: The fair division of chores, as well as mixed manna (goods and chores), has received substantial recent attention in the fair division literature; however, ours is the first paper to extend this research to matching markets. Indeed, our contention is that matching markets are a natural setting for this purpose, since the manna that fit into the limited number of hours available in a day can be viewed as one unit of allocation. We extend several well-known results that hold for goods to the settings of chores and mixed manna. In addition, we show that the natural notion of an earnings-based equilibrium, which is more natural in the case of all chores, is equivalent to the pricing-based equilibrium given by Hylland and Zeckhauser for the case of goods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17134v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jugal Garg, Thorben Tr\"obst, Vijay V. Vazirani</dc:creator>
    </item>
    <item>
      <title>Robin Hood Reachability Bidding Games</title>
      <link>https://arxiv.org/abs/2412.17718</link>
      <description>arXiv:2412.17718v1 Announce Type: new 
Abstract: Two-player graph games are a fundamental model for reasoning about the interaction of agents. These games are played between two players who move a token along a graph. In bidding games, the players have some monetary budget, and at each step they bid for the privilege of moving the token. Typically, the winner of the bid either pays the loser or the bank, or a combination thereof. We introduce Robin Hood bidding games, where at the beginning of every step the richer player pays the poorer a fixed fraction of the difference of their wealth. After the bid, the winner pays the loser. Intuitively, this captures the setting where a regulating entity prevents the accumulation of wealth to some degree.
  We show that the central property of bidding games, namely the existence of a threshold function, is retained in Robin Hood bidding games. We show that finding the threshold can be formulated as a Mixed-Integer Linear Program. Surprisingly, we show that the games are not always determined exactly at the threshold, unlike their standard counterpart.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17718v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shaull Almagor, Guy Avni, Neta Dafni</dc:creator>
    </item>
    <item>
      <title>Sharp Results for Hypothesis Testing with Risk-Sensitive Agents</title>
      <link>https://arxiv.org/abs/2412.16452</link>
      <description>arXiv:2412.16452v1 Announce Type: cross 
Abstract: Statistical protocols are often used for decision-making involving multiple parties, each with their own incentives, private information, and ability to influence the distributional properties of the data. We study a game-theoretic version of hypothesis testing in which a statistician, also known as a principal, interacts with strategic agents that can generate data. The statistician seeks to design a testing protocol with controlled error, while the data-generating agents, guided by their utility and prior information, choose whether or not to opt in based on expected utility maximization. This strategic behavior affects the data observed by the statistician and, consequently, the associated testing error. We analyze this problem for general concave and monotonic utility functions and prove an upper bound on the Bayes false discovery rate (FDR). Underlying this bound is a form of prior elicitation: we show how an agent's choice to opt in implies a certain upper bound on their prior null probability. Our FDR bound is unimprovable in a strong sense, achieving equality at a single point for an individual agent and at any countable number of points for a population of agents. We also demonstrate that our testing protocols exhibit a desirable maximin property when the principal's utility is considered. To illustrate the qualitative predictions of our theory, we examine the effects of risk aversion, reward stochasticity, and signal-to-noise ratio, as well as the implications for the Food and Drug Administration's testing protocols.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16452v1</guid>
      <category>stat.ME</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Flora C. Shi, Stephen Bates, Martin J. Wainwright</dc:creator>
    </item>
    <item>
      <title>Online Learning from Strategic Human Feedback in LLM Fine-Tuning</title>
      <link>https://arxiv.org/abs/2412.16834</link>
      <description>arXiv:2412.16834v2 Announce Type: cross 
Abstract: Reinforcement learning from human feedback (RLHF) has become an essential step in fine-tuning large language models (LLMs) to align them with human preferences. However, human labelers are selfish and have diverse preferences. They may strategically misreport their online feedback to influence the system's aggregation towards their own preferences. Current practice simply averages labelers' feedback per time and fails to identify the most accurate human labeler, leading to linear regret $\mathcal{O}(T)$ for $T$ time slots. To our best knowledge, we are the first to study online learning mechanisms against strategic human labelers in the LLM fine-tuning process. We formulate a new dynamic Bayesian game and dynamically adjust human labelers' weights in the preference aggregation, ensuring their truthful feedback and sublinear regret $\mathcal{O}(T^{1/2})$. Simulation results demonstrate our mechanism's great advantages over the existing benchmark schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16834v2</guid>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shugang Hao, Lingjie Duan</dc:creator>
    </item>
    <item>
      <title>FedCross: Intertemporal Federated Learning Under Evolutionary Games</title>
      <link>https://arxiv.org/abs/2412.16968</link>
      <description>arXiv:2412.16968v1 Announce Type: cross 
Abstract: Federated Learning (FL) mitigates privacy leakage in decentralized machine learning by allowing multiple clients to train collaboratively locally. However, dynamic mobile networks with high mobility, intermittent connectivity, and bandwidth limitation severely hinder model updates to the cloud server. Although previous studies have typically addressed user mobility issue through task reassignment or predictive modeling, frequent migrations may result in high communication overhead. Overcoming this obstacle involves not only dealing with resource constraints, but also finding ways to mitigate the challenges posed by user migrations. We therefore propose an intertemporal incentive framework, FedCross, which ensures the continuity of FL tasks by migrating interrupted training tasks to feasible mobile devices. Specifically, FedCross comprises two distinct stages. In Stage 1, we address the task allocation problem across regions under resource constraints by employing a multi-objective migration algorithm to quantify the optimal task receivers. Moreover, we adopt evolutionary game theory to capture the dynamic decision-making of users, forecasting the evolution of user proportions across different regions to mitigate frequent migrations. In Stage 2, we utilize a procurement auction mechanism to allocate rewards among base stations, ensuring that those providing high-quality models receive optimal compensation. This approach incentivizes sustained user participation, thereby ensuring the overall feasibility of FedCross. Finally, experimental results validate the theoretical soundness of FedCross and demonstrate its significant reduction in communication overhead.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16968v1</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>cs.GT</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianfeng Lu, Ying Zhang, Riheng Jia, Shuqin Cao, Jing Liu, Hao Fu</dc:creator>
    </item>
    <item>
      <title>Observation Interference in Partially Observable Assistance Games</title>
      <link>https://arxiv.org/abs/2412.17797</link>
      <description>arXiv:2412.17797v1 Announce Type: cross 
Abstract: We study partially observable assistance games (POAGs), a model of the human-AI value alignment problem which allows the human and the AI assistant to have partial observations. Motivated by concerns of AI deception, we study a qualitatively new phenomenon made possible by partial observability: would an AI assistant ever have an incentive to interfere with the human's observations? First, we prove that sometimes an optimal assistant must take observation-interfering actions, even when the human is playing optimally, and even when there are otherwise-equivalent actions available that do not interfere with observations. Though this result seems to contradict the classic theorem from single-agent decision making that the value of perfect information is nonnegative, we resolve this seeming contradiction by developing a notion of interference defined on entire policies. This can be viewed as an extension of the classic result that the value of perfect information is nonnegative into the cooperative multiagent setting. Second, we prove that if the human is simply making decisions based on their immediate outcomes, the assistant might need to interfere with observations as a way to query the human's preferences. We show that this incentive for interference goes away if the human is playing optimally, or if we introduce a communication channel for the human to communicate their preferences to the assistant. Third, we show that if the human acts according to the Boltzmann model of irrationality, this can create an incentive for the assistant to interfere with observations. Finally, we use an experimental model to analyze tradeoffs faced by the AI assistant in practice when considering whether or not to take observation-interfering actions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17797v1</guid>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Scott Emmons, Caspar Oesterheld, Vincent Conitzer, Stuart Russell</dc:creator>
    </item>
    <item>
      <title>Reducing Leximin Fairness to Utilitarian Optimization</title>
      <link>https://arxiv.org/abs/2409.10395</link>
      <description>arXiv:2409.10395v3 Announce Type: replace 
Abstract: Two prominent objectives in social choice are utilitarian - maximizing the sum of agents' utilities, and leximin - maximizing the smallest agent's utility, then the second-smallest, etc. Utilitarianism is typically computationally easier to attain but is generally viewed as less fair. This paper presents a general reduction scheme that, given a utilitarian solver, produces a distribution over states (deterministic outcomes) that is leximin in expectation. Importantly, the scheme is robust in the sense that, given an approximate utilitarian solver, it produces a lottery that is approximately-leximin (in expectation) - with the same approximation factor. We apply our scheme to several social choice problems: stochastic allocations of indivisible goods, giveaway lotteries, and fair lotteries for participatory budgeting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.10395v3</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <category>cs.MA</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eden Hartman, Yonatan Aumann, Avinatan Hassidim, Erel Segal-Halevi</dc:creator>
    </item>
    <item>
      <title>Strategyproof Learning with Advice</title>
      <link>https://arxiv.org/abs/2411.07354</link>
      <description>arXiv:2411.07354v2 Announce Type: replace 
Abstract: An important challenge in robust machine learning is when training data is provided by strategic sources who may intentionally report erroneous data for their own benefit. A line of work at the intersection of machine learning and mechanism design aims to deter strategic agents from reporting erroneous training data by designing learning algorithms that are strategyproof. Strategyproofness is a strong and desirable property, but it comes at a cost in the approximation ratio of even simple risk minimization problems.
  In this paper, we study strategyproof regression and classification problems in a model with advice. This model is part of a recent line on mechanism design with advice where the goal is to achieve both an improved approximation ratio when the advice is correct (consistency) and a bounded approximation ratio when the advice is incorrect (robustness). We provide the first non-trivial consistency-robustness tradeoffs for strategyproof regression and classification, which hold for simple yet interesting classes of functions. For classes of constant functions, we give a deterministic and strategyproof mechanism that is, for any $\gamma \in (0, 2]$, $1+\gamma$ consistent and $1 + 4/\gamma$ robust and provide a lower bound that shows that this tradeoff is optimal. We extend this mechanism and its guarantees to homogeneous linear regression over $\mathbb{R}$. In the binary classification problem of selecting from three or more labelings, we present strong impossibility results for both deterministic and randomized mechanism. Finally, we provide deterministic and randomized mechanisms for selecting from two labelings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07354v2</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eric Balkanski, Cherlin Zhu</dc:creator>
    </item>
    <item>
      <title>Consumer-Optimal Segmentation in Multi-Product Markets</title>
      <link>https://arxiv.org/abs/2401.12366</link>
      <description>arXiv:2401.12366v2 Announce Type: replace-cross 
Abstract: We analyze how market segmentation affects consumer welfare when a monopolist can engage in both second-degree price discrimination (through product differentiation) and third-degree price discrimination (through market segmentation). We characterize the consumer-optimal market segmentation and show that it has several striking properties: (1) the market segmentation displays monotonicity$\unicode{x2014}$higher-value customers always receive higher quality product than lower-value regardless of their segment and across any segment; and (2) when aggregate demand elasticity exceeds a threshold determined by marginal costs, no segmentation maximizes consumer surplus. Our results demonstrate that strategic market segmentation can benefit consumers even when it enables price discrimination, but these benefits depend critically on demand elasticities and cost structures. The findings have implications for regulatory policy regarding price discrimination and market segmentation practices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.12366v2</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dirk Bergemann, Tibor Heumann, Michael C. Wang</dc:creator>
    </item>
    <item>
      <title>Learning to Manipulate under Limited Information</title>
      <link>https://arxiv.org/abs/2401.16412</link>
      <description>arXiv:2401.16412v3 Announce Type: replace-cross 
Abstract: By classic results in social choice theory, any reasonable preferential voting method sometimes gives individuals an incentive to report an insincere preference. The extent to which different voting methods are more or less resistant to such strategic manipulation has become a key consideration for comparing voting methods. Here we measure resistance to manipulation by whether neural networks of various sizes can learn to profitably manipulate a given voting method in expectation, given different types of limited information about how other voters will vote. We trained over 100,000 neural networks of 26 sizes to manipulate against 8 different voting methods, under 6 types of limited information, in committee-sized elections with 5-21 voters and 3-6 candidates. We find that some voting methods, such as Borda, are highly manipulable by networks with limited information, while others, such as Instant Runoff, are not, despite being quite profitably manipulated by an ideal manipulator with full information. For the three probability models for elections that we use, the overall least manipulable of the 8 methods we study are Condorcet methods, namely Minimax and Split Cycle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.16412v3</guid>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <category>econ.TH</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wesley H. Holliday, Alexander Kristoffersen, Eric Pacuit</dc:creator>
    </item>
  </channel>
</rss>
