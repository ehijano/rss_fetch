<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 05 Mar 2024 14:39:35 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 05 Mar 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Speaker-Independent Dysarthria Severity Classification using Self-Supervised Transformers and Multi-Task Learning</title>
      <link>https://arxiv.org/abs/2403.00854</link>
      <description>arXiv:2403.00854v1 Announce Type: new 
Abstract: Dysarthria, a condition resulting from impaired control of the speech muscles due to neurological disorders, significantly impacts the communication and quality of life of patients. The condition's complexity, human scoring and varied presentations make its assessment and management challenging. This study presents a transformer-based framework for automatically assessing dysarthria severity from raw speech data. It can offer an objective, repeatable, accessible, standardised and cost-effective and compared to traditional methods requiring human expert assessors. We develop a transformer framework, called Speaker-Agnostic Latent Regularisation (SALR), incorporating a multi-task learning objective and contrastive learning for speaker-independent multi-class dysarthria severity classification. The multi-task framework is designed to reduce reliance on speaker-specific characteristics and address the intrinsic intra-class variability of dysarthric speech. We evaluated on the Universal Access Speech dataset using leave-one-speaker-out cross-validation, our model demonstrated superior performance over traditional machine learning approaches, with an accuracy of $70.48\%$ and an F1 score of $59.23\%$. Our SALR model also exceeded the previous benchmark for AI-based classification, which used support vector machines, by $16.58\%$. We open the black box of our model by visualising the latent space where we can observe how the model substantially reduces speaker-specific cues and amplifies task-specific ones, thereby showing its robustness. In conclusion, SALR establishes a new benchmark in speaker-independent multi-class dysarthria severity classification using generative AI. The potential implications of our findings for broader clinical applications in automated dysarthria severity assessments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.00854v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <category>cs.SD</category>
      <category>eess.AS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lauren Stumpf, Balasundaram Kadirvelu, Sigourney Waibel, A. Aldo Faisal</dc:creator>
    </item>
    <item>
      <title>History-dependence shapes causal inference of brain-behaviour relationships</title>
      <link>https://arxiv.org/abs/2403.00947</link>
      <description>arXiv:2403.00947v1 Announce Type: new 
Abstract: Behavioural and neural time series are often correlated with the past. This history-dependence may represent a fundamental property of the measured variables, or may arise from how confounding variables change over time. Here we argue that undecidability about the ground-truth of history-dependence is a general computational property of systems that exchange information with its environment, and show that the resulting uncertainty has a direct impact on causal inference. We first argue that uncertainty in the ground truth of history-dependence is an inherent property of open systems that cannot be explicitly falsified. Simple model systems are then simulated to show how different assumptions about history-dependence can lead to spurious correlations and statistical properties of data distributions that are typically unaccounted for. We then consider this problem from an interventionist perspective, showing that interventions can only be guaranteed to remedy the spurious correlation problem when the latent dynamics between the intervention and measured processes are known a priori, and the effect of the intervention is invariant at the chosen level of analysis. We conclude that uncertainty about history-dependence is a fundamental property of the study of neural systems, and in light of this discuss how causality should be assessed in neuroscience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.00947v1</guid>
      <category>q-bio.NC</category>
      <category>q-bio.QM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Brandon Caie, Gunnar Blohm</dc:creator>
    </item>
    <item>
      <title>An internal sensory model allows for balance control based on non-actionable proprioceptive feedback</title>
      <link>https://arxiv.org/abs/2403.00951</link>
      <description>arXiv:2403.00951v1 Announce Type: new 
Abstract: All motor tasks with a mechanical system (a human body, a rider on a bicycle) that is approximately linear in the part of the state space where it stays most of the time (e.g., upright balance control) have the following property: actionable sensory feedback allows for optimal control actions that are a simple linear combination of the sensory feedback. When only non-actionable sensory feedback is available, optimal control for these approximately linear mechanical systems is based on an internal dynamical system that estimates the states, and that can be implemented as a recurrent neural network (RNN). It uses a sensory model to update the state estimates with the non-actionable sensory feedback, and the weights of this RNN are fully specified by results from optimal feedback control. This is highly relevant for muscle spindle afferent firing rates which, under perfectly coordinated fusimotor and skeletomotor control, scale with the exafferent joint acceleration component. The resulting control mechanism balances a standing body and a rider-bicycle combination using realistic parameter values and with forcing torques that are feasible for humans.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.00951v1</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Eric Maris</dc:creator>
    </item>
    <item>
      <title>BrainMass: Advancing Brain Network Analysis for Diagnosis with Large-scale Self-Supervised Learning</title>
      <link>https://arxiv.org/abs/2403.01433</link>
      <description>arXiv:2403.01433v1 Announce Type: cross 
Abstract: Foundation models pretrained on large-scale datasets via self-supervised learning demonstrate exceptional versatility across various tasks. Due to the heterogeneity and hard-to-collect medical data, this approach is especially beneficial for medical image analysis and neuroscience research, as it streamlines broad downstream tasks without the need for numerous costly annotations. However, there has been limited investigation into brain network foundation models, limiting their adaptability and generalizability for broad neuroscience studies. In this study, we aim to bridge this gap. In particular, (1) we curated a comprehensive dataset by collating images from 30 datasets, which comprises 70,781 samples of 46,686 participants. Moreover, we introduce pseudo-functional connectivity (pFC) to further generates millions of augmented brain networks by randomly dropping certain timepoints of the BOLD signal. (2) We propose the BrainMass framework for brain network self-supervised learning via mask modeling and feature alignment. BrainMass employs Mask-ROI Modeling (MRM) to bolster intra-network dependencies and regional specificity. Furthermore, Latent Representation Alignment (LRA) module is utilized to regularize augmented brain networks of the same participant with similar topological properties to yield similar latent representations by aligning their latent embeddings. Extensive experiments on eight internal tasks and seven external brain disorder diagnosis tasks show BrainMass's superior performance, highlighting its significant generalizability and adaptability. Nonetheless, BrainMass demonstrates powerful few/zero-shot learning abilities and exhibits meaningful interpretation to various diseases, showcasing its potential use for clinical applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01433v1</guid>
      <category>cs.CE</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yanwu Yang, Chenfei Ye, Guinan Su, Ziyao Zhang, Zhikai Chang, Hairui Chen, Piu Chan, Yue Yu, Ting Ma</dc:creator>
    </item>
    <item>
      <title>Reconciling Shared versus Context-Specific Information in a Neural Network Model of Latent Causes</title>
      <link>https://arxiv.org/abs/2312.08519</link>
      <description>arXiv:2312.08519v2 Announce Type: replace 
Abstract: It has been proposed that, when processing a stream of events, humans divide their experiences in terms of inferred latent causes (LCs) to support context-dependent learning. However, when shared structure is present across contexts, it is still unclear how the "splitting" of LCs and learning of shared structure can be simultaneously achieved. Here, we present the Latent Cause Network (LCNet), a neural network model of LC inference. Through learning, it naturally stores structure that is shared across tasks in the network weights. Additionally, it represents context-specific structure using a context module, controlled by a Bayesian nonparametric inference algorithm, which assigns a unique context vector for each inferred LC. Across three simulations, we found that LCNet could 1) extract shared structure across LCs in a function learning task while avoiding catastrophic interference, 2) capture human data on curriculum effects in schema learning, and 3) infer the underlying event structure when processing naturalistic videos of daily events. Overall, these results demonstrate a computationally feasible approach to reconciling shared structure and context-specific structure in a model of LCs that is scalable from laboratory experiment settings to naturalistic settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.08519v2</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qihong Lu, Tan T. Nguyen, Qiong Zhang, Uri Hasson, Thomas L. Griffiths, Jeffrey M. Zacks, Samuel J. Gershman, Kenneth A. Norman</dc:creator>
    </item>
    <item>
      <title>Layerwise complexity-matched learning yields an improved model of cortical area V2</title>
      <link>https://arxiv.org/abs/2312.11436</link>
      <description>arXiv:2312.11436v2 Announce Type: replace 
Abstract: Human ability to recognize complex visual patterns arises through transformations performed by successive areas in the ventral visual cortex. Deep neural networks trained end-to-end for object recognition approach human capabilities, and offer the best descriptions to date of neural responses in the late stages of the hierarchy. But these networks provide a poor account of the early stages, compared to traditional hand-engineered models, or models optimized for coding efficiency or prediction. Moreover, the gradient backpropagation used in end-to-end learning is generally considered to be biologically implausible. Here, we overcome both of these limitations by developing a bottom-up self-supervised training methodology that operates independently on successive layers. Specifically, we maximize feature similarity between pairs of locally-deformed natural image patches, while decorrelating features across patches sampled from other images. Crucially, the deformation amplitudes are adjusted proportionally to receptive field sizes in each layer, thus matching the task complexity to the capacity at each stage of processing. In comparison with architecture-matched versions of previous models, we demonstrate that our layerwise complexity-matched learning (LCL) formulation produces a two-stage model (LCL-V2) that is better aligned with selectivity properties and neural activity in primate area V2. We demonstrate that the complexity-matched learning paradigm is critical for the emergence of the improved biological alignment. Finally, when the two-stage model is used as a fixed front-end for a deep network trained to perform object recognition, the resultant model (LCL-V2Net) is significantly better than standard end-to-end self-supervised, supervised, and adversarially-trained models in terms of generalization to out-of-distribution tasks and alignment with human behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.11436v2</guid>
      <category>q-bio.NC</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nikhil Parthasarathy, Olivier J. H\'enaff, Eero P. Simoncelli</dc:creator>
    </item>
    <item>
      <title>Identification of Craving Maps among Marijuana Users via Analysis of Functional Brain Networks with High-Order Attention Graph Neural Networks</title>
      <link>https://arxiv.org/abs/2403.00033</link>
      <description>arXiv:2403.00033v2 Announce Type: replace 
Abstract: The consumption of high doses of marijuana can have significant psychological and social impacts. In this study, we propose an interpretable novel framework called the HOGAB (High-Order Graph Attention Neural Networks) model for addictive Marijuana classification and analysis of the localized network clusters that demonstrated abnormal brain activities among chronic marijuana users. The HOGAB integrates dynamic intrinsic functional networks with LSTM technology to capture temporal patterns in fMRI time series of marijuana users. We employed the high-order attention module in neighborhood nodes for information fusion and message passing, enhancing community clustering analysis for long-term marijuana users. Furthermore, we improve the overall classification ability of the model by incorporating attention mechanisms, achieving an AUC of 85.1% and an accuracy of 80.7% in classification, higher than the comparison algoirthms. Specifically, we identified the most relevant subnetworks and cognitive regions that are influenced by persistent marijuana usage, revealing that chronic marijuana consumption adversely affects cognitive control, particularly within the Dorsal Attention and Frontoparietal networks, which are essential for attentional, cognitive and higher cognitive functions. The results show that our proposed model is capable of accurately predicting craving bahavior and identifying brain maps associated with long-term cravings, and thus pinpointing brain regions that are important for analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.00033v2</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jun-En Ding, Shihao Yang, Anna Zilverstand, Feng Liu</dc:creator>
    </item>
    <item>
      <title>From asynchronous states to Griffiths phases and back: structural heterogeneity and homeostasis in excitatory-inhibitory networks</title>
      <link>https://arxiv.org/abs/2310.02369</link>
      <description>arXiv:2310.02369v2 Announce Type: replace-cross 
Abstract: Balanced neural networks -- in which excitatory and inhibitory inputs compensate each other on average -- give rise to a dynamical phase dominated by fluctuations called asynchronous state, crucial for brain functioning. However, structural disorder -- which is inherent to random networks -- can hinder such an excitation-inhibition balance. Indeed, structural and synaptic heterogeneities can generate extended regions in phase space akin to critical points, called Griffiths phases, with dynamical features very different from those of asynchronous states. Here, we study a simple neural-network model with tunable levels of heterogeneity able to display these two types of dynamical regimes -- i.e., asynchronous states and Griffiths phases -- putting them together within a single phase diagram. Using this simple model, we are able to emphasize the crucial role played by synaptic plasticity and homeostasis to re-establish balance in intrinsically heterogeneous networks. Overall, we shed light onto how diverse dynamical regimes, each with different functional advantages, can emerge from a given network as a result of self-organizing homeostatic mechanisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.02369v2</guid>
      <category>cond-mat.stat-mech</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jorge Pretel, Victor Buend\'ia, Joaqu\'in J. Torres, Miguel A. Mu\~noz</dc:creator>
    </item>
    <item>
      <title>Broken detailed balance and entropy production in directed networks</title>
      <link>https://arxiv.org/abs/2402.19157</link>
      <description>arXiv:2402.19157v2 Announce Type: replace-cross 
Abstract: The structure of a complex network plays a crucial role in determining its dynamical properties. In this work, we show that the directed, hierarchical organisation of a network causes the system to break detailed balance and dictates the production of entropy through non-equilibrium dynamics. We consider a wide range of dynamical processes and show how different directed network features govern their thermodynamics. Next, we analyse a collection of 97 empirical networks and show that strong directedness and non-equilibrium dynamics are both ubiquitous in real-world systems. Finally, we present a simple method for inferring broken detailed balance and directed network structure from multivariate time-series and apply our method to identify non-equilibrium and hierarchical organisation in both human neuroimaging and financial time-series. Overall, our results shed light on the thermodynamic consequences of directed network structure and indicate the importance and ubiquity of hierarchical organisation and non-equilibrium dynamics in real-world systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.19157v2</guid>
      <category>physics.soc-ph</category>
      <category>cond-mat.stat-mech</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ram\'on Nartallo-Kaluarachchi, Malbor Asllani, Gustavo Deco, Morten L. Kringelbach, Alain Goriely, Renaud Lambiotte</dc:creator>
    </item>
  </channel>
</rss>
