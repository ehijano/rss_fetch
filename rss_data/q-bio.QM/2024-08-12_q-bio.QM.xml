<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.QM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.QM</link>
    <description>q-bio.QM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.QM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 13 Aug 2024 04:00:36 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 13 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Facilitating bootstrapped and rarefaction-based microbiome diversity analysis with q2-boots</title>
      <link>https://arxiv.org/abs/2408.05420</link>
      <description>arXiv:2408.05420v1 Announce Type: new 
Abstract: Background: We present q2-boots, a QIIME 2 plugin that facilitates bootstrapped and rarefaction-based microbiome diversity analysis. This plugin provides eight new actions that allow users to apply any of thirty different alpha diversity metrics and twenty-two beta diversity metrics to bootstrapped or rarefied feature tables, using a single QIIME 2 Pipeline command, or more granular QIIME 2 Action commands.
  Results: Given a feature table, an even sampling depth, and the number of iterations to perform (n), the command qiime boots core-metrics will resample the feature table n times and compute alpha and beta diversity metrics on each resampled table. The results will be integrated in summary data artifacts that are identical in structure and type to results that would be generated by applying diversity metrics to a single table. This enables all of the same downstream analytic tools to be applied to these tables, and ensures that all collected data is considered when computing microbiome diversity metrics.
  Conclusions: A challenge of this work was deciding how to integrate distance matrices that were computed on n resampled feature tables, as a simple average of pairwise distances (median or mean) does not account for the structure of distance matrices. q2-boots provides three options, and we show here that the results of these approaches are highly correlated. q2-boots is free and open source. Source code, installation instructions, and a tutorial can be found at https://github.com/caporaso-lab/q2-boots.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05420v1</guid>
      <category>q-bio.QM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Isaiah Raspet, Elizabeth Gehret, Chloe Herman, Jeff Meilander, Andrew Manley, Anthony Simard, Evan Bolyen, J. Gregory Caporaso</dc:creator>
    </item>
    <item>
      <title>The evolution of systems biology and systems medicine: From mechanistic models to uncertainty quantification</title>
      <link>https://arxiv.org/abs/2408.05395</link>
      <description>arXiv:2408.05395v1 Announce Type: cross 
Abstract: Understanding the mechanisms of interactions within cells, tissues, and organisms is crucial to driving developments across biology and medicine. Mathematical modeling is an essential tool for simulating biological systems and revealing biochemical regulatory mechanisms. Building on experiments, mechanistic models are widely used to describe small-scale intracellular networks and uncover biochemical mechanisms in healthy and diseased states. The rapid development of high-throughput sequencing techniques and computational tools has recently enabled models that span multiple scales, often integrating signaling, gene regulatory, and metabolic networks. These multiscale models enable comprehensive investigations of cellular networks and thus reveal previously unknown disease mechanisms and pharmacological interventions. Here, we review systems biology models from classical mechanistic models to larger, multiscale models that integrate multiple layers of cellular networks. We introduce several examples of models of hypertrophic cardiomyopathy, exercise, and cancer cell proliferation. Additionally, we discuss methods that increase the certainty and accuracy of model predictions. Integrating multiscale models has become a powerful tool for understanding disease and inspiring drug discoveries by incorporating omics data within the cell and across tissues and organisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05395v1</guid>
      <category>q-bio.MN</category>
      <category>q-bio.QM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Lingxia Qiao, Ali Khalilimeybodi, Nathaniel J Linden-Santangeli, Padmini Rangamani</dc:creator>
    </item>
    <item>
      <title>TGL-Lambda: An implementation of TrapGrid to estimate trap attractiveness from heterogeneous field data</title>
      <link>https://arxiv.org/abs/2408.05408</link>
      <description>arXiv:2408.05408v1 Announce Type: cross 
Abstract: This paper describes a recently developed software called ``TGL-Lambda'' enables quantifying lure attractiveness under a variety of field capture scenarios including mixed lure/trap combinations. TGL-Lambda delivers a flexible approach to simultaneously estimating the {\lambda} value for multiple trap types, accommodating a common situation in ``Mark-release-recapture'' (MRR) experiments in the field. Specifically, where researchers release a known number of marked insects in a field and count how many are recaptured in two to five trap and lure types, and the trap and release locations are known, TGL-Lambda can be used to estimate the attractiveness ({\lambda}) of each of the trap types.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05408v1</guid>
      <category>q-bio.PE</category>
      <category>q-bio.QM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Ben Scalero, Nicholas C. Manoukis</dc:creator>
    </item>
    <item>
      <title>SMILES-Mamba: Chemical Mamba Foundation Models for Drug ADMET Prediction</title>
      <link>https://arxiv.org/abs/2408.05696</link>
      <description>arXiv:2408.05696v1 Announce Type: cross 
Abstract: In drug discovery, predicting the absorption, distribution, metabolism, excretion, and toxicity (ADMET) properties of small-molecule drugs is critical for ensuring safety and efficacy. However, the process of accurately predicting these properties is often resource-intensive and requires extensive experimental data. To address this challenge, we propose SMILES-Mamba, a two-stage model that leverages both unlabeled and labeled data through a combination of self-supervised pretraining and fine-tuning strategies. The model first pre-trains on a large corpus of unlabeled SMILES strings to capture the underlying chemical structure and relationships, before being fine-tuned on smaller, labeled datasets specific to ADMET tasks. Our results demonstrate that SMILES-Mamba exhibits competitive performance across 22 ADMET datasets, achieving the highest score in 14 tasks, highlighting the potential of self-supervised learning in improving molecular property prediction. This approach not only enhances prediction accuracy but also reduces the dependence on large, labeled datasets, offering a promising direction for future research in drug discovery.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05696v1</guid>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bohao Xu, Yingzhou Lu, Chenhao Li, Ling Yue, Xiao Wang, Nan Hao, Tianfan Fu, Jim Chen</dc:creator>
    </item>
    <item>
      <title>Inferring directed spectral information flow between mixed-frequency time series</title>
      <link>https://arxiv.org/abs/2408.06109</link>
      <description>arXiv:2408.06109v1 Announce Type: cross 
Abstract: Identifying directed spectral information flow between multivariate time series is important for many applications in finance, climate, geophysics and neuroscience. Spectral Granger causality (SGC) is a prediction-based measure characterizing directed information flow at specific oscillatory frequencies. However, traditional vector autoregressive (VAR) approaches are insufficient to assess SGC when time series have mixed frequencies (MF) or are coupled by nonlinearity. Here we propose a time-frequency canonical correlation analysis approach ("MF-TFCCA") to assess the strength and driving frequency of spectral information flow. We validate the approach with intensive computer simulations on MF time series under various interaction conditions and assess statistical significance of the estimate with surrogate data. We further apply MF-TFCCA to real-life finance, climate and neuroscience data. Our analysis framework provides an exploratory and computationally efficient approach to quantify directed information flow between MF time series in the presence of complex and nonlinear interactions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06109v1</guid>
      <category>eess.SP</category>
      <category>q-bio.QM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiqi Xian, Zhe Sage Chen</dc:creator>
    </item>
    <item>
      <title>Adapting Differential Molecular Representation with Hierarchical Prompts for Multi-label Property Prediction</title>
      <link>https://arxiv.org/abs/2405.18724</link>
      <description>arXiv:2405.18724v2 Announce Type: replace 
Abstract: Accurate prediction of molecular properties is crucial in drug discovery. Traditional methods often overlook that real-world molecules typically exhibit multiple property labels with complex correlations. To this end, we propose a novel framework, HiPM, which stands for hierarchical prompted molecular representation learning framework. HiPM leverages task-aware prompts to enhance the differential expression of tasks in molecular representations and mitigate negative transfer caused by conflicts in individual task information. Our framework comprises two core components: the Molecular Representation Encoder (MRE) and the Task-Aware Prompter (TAP). MRE employs a hierarchical message-passing network architecture to capture molecular features at both the atom and motif levels. Meanwhile, TAP utilizes agglomerative hierarchical clustering algorithm to construct a prompt tree that reflects task affinity and distinctiveness, enabling the model to consider multi-granular correlation information among tasks, thereby effectively handling the complexity of multi-label property prediction. Extensive experiments demonstrate that HiPM achieves state-of-the-art performance across various multi-label datasets, offering a novel perspective on multi-label molecular representation learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18724v2</guid>
      <category>q-bio.QM</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Linjia Kang, Songhua Zhou, Shuyan Fang, Shichao Liu</dc:creator>
    </item>
    <item>
      <title>Autonomous self-evolving research on biomedical data: the DREAM paradigm</title>
      <link>https://arxiv.org/abs/2407.13637</link>
      <description>arXiv:2407.13637v2 Announce Type: replace 
Abstract: In contemporary biomedical research, the efficiency of data-driven approaches is hindered by large data volumes, tool selection complexity, and human resource limitations, necessitating the development of fully autonomous research systems to meet complex analytical needs. Such a system should include the ability to autonomously generate research questions, write analytical code, configure the computational environment, judge and interpret the results, and iteratively generate in-depth questions or solutions, all without human intervention. Here we developed DREAM, the first biomedical Data-dRiven self-Evolving Autonomous systeM, which can independently conduct scientific research without human involvement. Utilizing a clinical dataset and two omics datasets, DREAM demonstrated its ability to raise and deepen scientific questions, with difficulty scores for clinical data questions surpassing top published articles by 5.7% and outperforming GPT-4 and bioinformatics graduate students by 58.6% and 56.0%, respectively. Overall, DREAM has a success rate of 80% in autonomous clinical data mining. Certainly, human can participate in different steps of DREAM to achieve more personalized goals. After evolution, 10% of the questions exceeded the average scores of top published article questions on originality and complexity. In the autonomous environment configuration of the eight bioinformatics workflows, DREAM exhibited an 88% success rate, whereas GPT-4 failed to configure any workflows. In clinical dataset, DREAM was over 10,000 times more efficient than the average scientist with a single computer core, and capable of revealing new discoveries. As a self-evolving autonomous research system, DREAM provides an efficient and reliable solution for future biomedical research. This paradigm may also have a revolutionary impact on other data-driven scientific research fields.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13637v2</guid>
      <category>q-bio.QM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luojia Deng, Yijie Wu, Yongyong Ren, Hui Lu</dc:creator>
    </item>
    <item>
      <title>A Text-guided Protein Design Framework</title>
      <link>https://arxiv.org/abs/2302.04611</link>
      <description>arXiv:2302.04611v3 Announce Type: replace-cross 
Abstract: Current AI-assisted protein design mainly utilizes protein sequential and structural information. Meanwhile, there exists tremendous knowledge curated by humans in the text format describing proteins' high-level functionalities. Yet, whether the incorporation of such text data can help protein design tasks has not been explored. To bridge this gap, we propose ProteinDT, a multi-modal framework that leverages textual descriptions for protein design. ProteinDT consists of three subsequent steps: ProteinCLAP which aligns the representation of two modalities, a facilitator that generates the protein representation from the text modality, and a decoder that creates the protein sequences from the representation. To train ProteinDT, we construct a large dataset, SwissProtCLAP, with 441K text and protein pairs. We quantitatively verify the effectiveness of ProteinDT on three challenging tasks: (1) over 90\% accuracy for text-guided protein generation; (2) best hit ratio on 12 zero-shot text-guided protein editing tasks; (3) superior performance on four out of six protein property prediction benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.04611v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>q-bio.QM</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shengchao Liu, Yanjing Li, Zhuoxinran Li, Anthony Gitter, Yutao Zhu, Jiarui Lu, Zhao Xu, Weili Nie, Arvind Ramanathan, Chaowei Xiao, Jian Tang, Hongyu Guo, Anima Anandkumar</dc:creator>
    </item>
    <item>
      <title>Computer Vision for Primate Behavior Analysis in the Wild</title>
      <link>https://arxiv.org/abs/2401.16424</link>
      <description>arXiv:2401.16424v2 Announce Type: replace-cross 
Abstract: Advances in computer vision as well as increasingly widespread video-based behavioral monitoring have great potential for transforming how we study animal cognition and behavior. However, there is still a fairly large gap between the exciting prospects and what can actually be achieved in practice today, especially in videos from the wild. With this perspective paper, we want to contribute towards closing this gap, by guiding behavioral scientists in what can be expected from current methods and steering computer vision researchers towards problems that are relevant to advance research in animal behavior. We start with a survey of the state-of-the-art methods for computer vision problems that are directly relevant to the video-based study of animal behavior, including object detection, multi-individual tracking, individual identification, and (inter)action recognition. We then review methods for effort-efficient learning, which is one of the biggest challenges from a practical perspective. Finally, we close with an outlook into the future of the emerging field of computer vision for animal behavior, where we argue that the field should develop approaches to unify detection, tracking, identification and (inter)action recognition in a single, video-based framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.16424v2</guid>
      <category>cs.CV</category>
      <category>q-bio.QM</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Richard Vogg, Timo L\"uddecke, Jonathan Henrich, Sharmita Dey, Matthias Nuske, Valentin Hassler, Derek Murphy, Julia Fischer, Julia Ostner, Oliver Sch\"ulke, Peter M. Kappeler, Claudia Fichtel, Alexander Gail, Stefan Treue, Hansj\"org Scherberger, Florentin W\"org\"otter, Alexander S. Ecker</dc:creator>
    </item>
  </channel>
</rss>
