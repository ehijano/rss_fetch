<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 03 Oct 2025 04:00:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Psychoacoustic study of simple-tone dyads: frequency ratio and pitch</title>
      <link>https://arxiv.org/abs/2510.01201</link>
      <description>arXiv:2510.01201v1 Announce Type: new 
Abstract: This study investigates how listeners perceive consonance and dissonance in dyads composed of simple (sine) tones, focusing on the effects of frequency ratio ($R$) and mean frequency ($F$). Seventy adult participants - categorized by musical training, gender, and age group - rated randomly ordered dyads using binary preference responses (``like'' or ``dislike''). Dyads represented standard Western intervals but were constructed with sine tones rather than musical notes, preserving interval ratios while varying absolute pitch. Statistical analyses reveal a consistent decrease in preference with increasing mean frequency, regardless of interval class or participant group. Octaves, fifths, fourths, and sixths showed a nearly linear decline in preference with increasing $F$. Major seconds were among the least preferred. Musicians rated octaves and certain consonant intervals more positively than non-musicians, while gender and age groups exhibited different sensitivity to high frequencies. The findings suggest that both interval structure and pitch range shape the perception of consonance in simple-tone dyads, with possible psychoacoustic explanations involving frequency sensitivity and auditory fatigue at higher frequencies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01201v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefania Kaklamani, Constantinos Simserides</dc:creator>
    </item>
    <item>
      <title>A Single-Equation Approach to Classifying Neuronal Operational Modes</title>
      <link>https://arxiv.org/abs/2510.01386</link>
      <description>arXiv:2510.01386v1 Announce Type: new 
Abstract: The neural coding is yet to be discovered. The neuronal operational modes that arise with fixed inputs but with varying degrees of stimulation help to elucidate their coding properties. In neurons receiving in vivo stimulation, we show that two operation modes can be described with simplified models: the coincidence detection mode and the integration mode. Our derivations include a simplified polynomial model with non-linear coefficients betam that captures the subthreshold dynamics of these modes of operation. The resulting model can explain these transitions with the sign and size of the smallest nonlinear coefficient of the polynomial alone. Defining neuronal operational modes provides insight into the processing and transmission of information through electrical currents. Requisite operational modes for proper neuronal functioning may explain disorders involving dysfunction of electrophysiological behavior, such as channelopathies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01386v1</guid>
      <category>q-bio.NC</category>
      <category>math.DS</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lindsey Knowles, Cesar Ceballos, Rodrigo Pena</dc:creator>
    </item>
    <item>
      <title>Aligning Video Models with Human Social Judgments via Behavior-Guided Fine-Tuning</title>
      <link>https://arxiv.org/abs/2510.01502</link>
      <description>arXiv:2510.01502v1 Announce Type: new 
Abstract: Humans intuitively perceive complex social signals in visual scenes, yet it remains unclear whether state-of-the-art AI models encode the same similarity structure. We study (Q1) whether modern video and language models capture human-perceived similarity in social videos, and (Q2) how to instill this structure into models using human behavioral data. To address this, we introduce a new benchmark of over 49,000 odd-one-out similarity judgments on 250 three-second video clips of social interactions, and discover a modality gap: despite the task being visual, caption-based language embeddings align better with human similarity than any pretrained video model. We close this gap by fine-tuning a TimeSformer video model on these human judgments with our novel hybrid triplet-RSA objective using low-rank adaptation (LoRA), aligning pairwise distances to human similarity. This fine-tuning protocol yields significantly improved alignment with human perceptions on held-out videos in terms of both explained variance and odd-one-out triplet accuracy. Variance partitioning shows that the fine-tuned video model increases shared variance with language embeddings and explains additional unique variance not captured by the language model. Finally, we test transfer via linear probes and find that human-similarity fine-tuning strengthens the encoding of social-affective attributes (intimacy, valence, dominance, communication) relative to the pretrained baseline. Overall, our findings highlight a gap in pretrained video models' social recognition and demonstrate that behavior-guided fine-tuning shapes video representations toward human social perception.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01502v1</guid>
      <category>q-bio.NC</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kathy Garcia, Leyla Isik</dc:creator>
    </item>
    <item>
      <title>Promoting arm movement practice with a novel wheelchair armrest early after stroke: A randomized controlled trial</title>
      <link>https://arxiv.org/abs/2510.01753</link>
      <description>arXiv:2510.01753v1 Announce Type: new 
Abstract: Chronic upper extremity (UE) impairment is common after stroke. This study evaluated Boost, a novel wheelchair-mounted rehabilitation device designed to assist individuals in UE motor recovery during inpatient rehabilitation. Thirty-five stroke inpatients were randomized to perform additional UE exercises alongside standard therapy, using either Boost or a therapist-customized booklet for self-practice. Outcomes included the UE Fugl-Meyer (UEFM) Exam, Box and Block Test, Motor Activity Log, Modified Ashworth Scale, shoulder subluxation, and shoulder pain. At baseline, mean days post-stroke were 11.9$\pm$4.6 and 13.1$\pm$5.9, and UEFM scores were 20.5$\pm$10.1 and 21.0$\pm$13.5. Intervention durations averaged 11.9$\pm$4.0 and 17.2$\pm$8.8 days, respectively. Participants in the Boost group completed 3,359$\pm$3,137 additional arm movements. No significant between-group differences were found at the three-month follow-up. However, the Boost group showed a trend toward greater UEFM improvement immediately post-intervention (11.8 vs. 6.9 points, p=0.06). Importantly, UEFM gains were predicted by the number of Boost exercises performed (p=0.02, R-square=0.34). Subgroup analysis revealed that patients with less severe impairment (baseline UEFM &gt;21) achieved significantly greater UEFM improvements at discharge with Boost compared to controls (15.8 vs. 7.8 points, p=0.01). These findings demonstrate the feasibility of achieving thousands of additional UE practice movements while seated in a wheelchair without direct supervision during subacute rehabilitation. The added movement practice was well tolerated and may offer short-term impairment-reduction benefits, particularly in those with less severe impairment. Larger trials are needed to confirm efficacy, establish optimal dosage, and determine long-term clinical and functional benefits of Boost-assisted therapy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01753v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sangjoon J. Kim (Bionics Research Center, Korea Institute of Science and Technology, Department of Mechanical and Aerospace Engineering, University of California-Irvine, Irvine, CA, USA), Vicky Chan (Department of Mechanical and Aerospace Engineering, University of California-Irvine, Irvine, CA, USA), Niko Fullmer (Casa Colina Research Institute, Casa Colina Hospital and Centers for Healthcare, Pomona, CA, USA), Emily R. Rosario (Casa Colina Research Institute, Casa Colina Hospital and Centers for Healthcare, Pomona, CA, USA), Christine Kim (Rancho Research Institute, Rancho Los Amigos National Rehabilitation Center, Downey, USA), Charles Y. Liu (Casa Colina Research Institute, Casa Colina Hospital and Centers for Healthcare, Pomona, CA, USA, USC Neurorestoration Center and Department of Neurosurgery, Los Angeles, CA, USA), Marti Comellas (University of Lleida - Polytechnic School, Lleida, Spain), Daniel K. Zondervan (Flint Rehabilitation Devices, LCC, Irvine, CA, USA), David J. Reinkensmeyer (Department of Mechanical and Aerospace Engineering, University of California-Irvine, Irvine, CA, USA), An H. Do (Department of Neurology, UC Irvine School of Medicine, Irvine, CA, USA)</dc:creator>
    </item>
    <item>
      <title>A Modular Theory of Subjective Consciousness for Natural and Artificial Minds</title>
      <link>https://arxiv.org/abs/2510.01864</link>
      <description>arXiv:2510.01864v1 Announce Type: new 
Abstract: Understanding how subjective experience arises from information processing remains a central challenge in neuroscience, cognitive science, and AI research. The Modular Consciousness Theory (MCT) proposes a biologically grounded and computationally explicit framework in which consciousness is a discrete sequence of Integrated Informational States (IISs). Each IIS is a packet of integrated information tagged with a multidimensional density vector that quantifies informational richness. Its magnitude correlates with subjective intensity, shaping memory, behavior, and continuity of experience. Inputs from body and environment are adaptively filtered, processed by modules (abstraction, narration, evaluation, self-evaluation), and integrated into an IIS. The resulting packet, tagged with its density vector, is transmitted to behavioral readiness, memory, and decision-making modules, closing the loop. This explains why strongly tagged states exert greater influence on long-term memory and action. Unlike Global Workspace Theory, Integrated Information Theory, or Higher-Order Thought, MCT specifies a full computational pipeline producing discrete informational units with quantifiable internal structure. Subjectivity is reframed as a correlate of the density-tagging signal with functional consequences. MCT generates testable predictions, such as stress enhancing memory encoding, and provides a naturalistic blueprint for both biological and artificial architectures. Consciousness, in this view, is not an irreducible essence but an evolvable, quantifiable, and constructible feature of complex information processing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01864v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Micha\"el Gillon</dc:creator>
    </item>
    <item>
      <title>Uncovering Semantic Selectivity of Latent Groups in Higher Visual Cortex with Mutual Information-Guided Diffusion</title>
      <link>https://arxiv.org/abs/2510.02182</link>
      <description>arXiv:2510.02182v1 Announce Type: new 
Abstract: Understanding how neural populations in higher visual areas encode object-centered visual information remains a central challenge in computational neuroscience. Prior works have investigated representational alignment between artificial neural networks and the visual cortex. Nevertheless, these findings are indirect and offer limited insights to the structure of neural populations themselves. Similarly, decoding-based methods have quantified semantic features from neural populations but have not uncovered their underlying organizations. This leaves open a scientific question: "how feature-specific visual information is distributed across neural populations in higher visual areas, and whether it is organized into structured, semantically meaningful subspaces." To tackle this problem, we present MIG-Vis, a method that leverages the generative power of diffusion models to visualize and validate the visual-semantic attributes encoded in neural latent subspaces. Our method first uses a variational autoencoder to infer a group-wise disentangled neural latent subspace from neural populations. Subsequently, we propose a mutual information (MI)-guided diffusion synthesis procedure to visualize the specific visual-semantic features encoded by each latent group. We validate MIG-Vis on multi-session neural spiking datasets from the inferior temporal (IT) cortex of two macaques. The synthesized results demonstrate that our method identifies neural latent groups with clear semantic selectivity to diverse visual features, including object pose, inter-category transformations, and intra-class content. These findings provide direct, interpretable evidence of structured semantic representation in the higher visual cortex and advance our understanding of its encoding principles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02182v1</guid>
      <category>q-bio.NC</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yule Wang, Joseph Yu, Chengrui Li, Weihan Li, Anqi Wu</dc:creator>
    </item>
    <item>
      <title>Compositional meta-learning through probabilistic task inference</title>
      <link>https://arxiv.org/abs/2510.01858</link>
      <description>arXiv:2510.01858v1 Announce Type: cross 
Abstract: To solve a new task from minimal experience, it is essential to effectively reuse knowledge from previous tasks, a problem known as meta-learning. Compositional solutions, where common elements of computation are flexibly recombined into new configurations, are particularly well-suited for meta-learning. Here, we propose a compositional meta-learning model that explicitly represents tasks as structured combinations of reusable computations. We achieve this by learning a generative model that captures the underlying components and their statistics shared across a family of tasks. This approach transforms learning a new task into a probabilistic inference problem, which allows for finding solutions without parameter updates through highly constrained hypothesis testing. Our model successfully recovers ground truth components and statistics in rule learning and motor learning tasks. We then demonstrate its ability to quickly infer new solutions from just single examples. Together, our framework joins the expressivity of neural networks with the data-efficiency of probabilistic inference to achieve rapid compositional meta-learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01858v1</guid>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jacob J. W. Bakermans, Pablo Tano, Reidar Riveland, Charles Findling, Alexandre Pouget</dc:creator>
    </item>
    <item>
      <title>Reducing Discomfort in Driving Simulators: Motion Cueing for Motion Sickness Mitigation</title>
      <link>https://arxiv.org/abs/2510.01986</link>
      <description>arXiv:2510.01986v1 Announce Type: cross 
Abstract: Driving simulators are increasingly used in research and development. However, simulators often cause motion sickness due to downscaled motion and unscaled veridical visuals. In this paper, a motion cueing algorithm is proposed that reduces motion sickness as predicted by the subjective vertical conflict (SVC) model using model predictive control (MPC). Both sensory conflict and specific force errors are penalised in the cost function, allowing the algorithm to jointly optimise fidelity and comfort.
  Human-in-the-loop experiments were conducted to compare four simulator motion settings: two variations of our MPC-based algorithm, one focused on pure specific force tracking and the second compromising specific force tracking and motion sickness minimisation, as well as reference adaptive washout and no motion cases. The experiments were performed on a hexapod driving simulator with participants exposed to passive driving.
  Experimental motion sickness results closely matched the sickness model predictions. As predicted by the model, the no motion condition yielded the lowest sickness levels. However, it was rated lowest in terms of fidelity. The compromise solution reduced sickness by over 50% (average MISC level 3 to 1.5) compared to adaptive washout and the algorithm focusing on specific force tracking, without any significant reduction in fidelity rating.
  The proposed approach for developing MCA that takes into account both the simulator dynamics and time evolution of motion sickness offers a significant advancement in achieving an optimal control of motion sickness and specific force recreation in driving simulators, supporting broader simulator use.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01986v1</guid>
      <category>cs.RO</category>
      <category>cs.HC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Varun Kotian, Vishrut Jain, Andrea Michelle Rios Lazcano, Daan Marinus Pool, Riender Happee, Barys Shyrokau</dc:creator>
    </item>
    <item>
      <title>VarCoNet: A variability-aware self-supervised framework for functional connectome extraction from resting-state fMRI</title>
      <link>https://arxiv.org/abs/2510.02120</link>
      <description>arXiv:2510.02120v1 Announce Type: cross 
Abstract: Accounting for inter-individual variability in brain function is key to precision medicine. Here, by considering functional inter-individual variability as meaningful data rather than noise, we introduce VarCoNet, an enhanced self-supervised framework for robust functional connectome (FC) extraction from resting-state fMRI (rs-fMRI) data. VarCoNet employs self-supervised contrastive learning to exploit inherent functional inter-individual variability, serving as a brain function encoder that generates FC embeddings readily applicable to downstream tasks even in the absence of labeled data. Contrastive learning is facilitated by a novel augmentation strategy based on segmenting rs-fMRI signals. At its core, VarCoNet integrates a 1D-CNN-Transformer encoder for advanced time-series processing, enhanced with a robust Bayesian hyperparameter optimization. Our VarCoNet framework is evaluated on two downstream tasks: (i) subject fingerprinting, using rs-fMRI data from the Human Connectome Project, and (ii) autism spectrum disorder (ASD) classification, using rs-fMRI data from the ABIDE I and ABIDE II datasets. Using different brain parcellations, our extensive testing against state-of-the-art methods, including 13 deep learning methods, demonstrates VarCoNet's superiority, robustness, interpretability, and generalizability. Overall, VarCoNet provides a versatile and robust framework for FC analysis in rs-fMRI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02120v1</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Charalampos Lamprou, Aamna Alshehhi, Leontios J. Hadjileontiadis, Mohamed L. Seghier</dc:creator>
    </item>
    <item>
      <title>State-space kinetic Ising model reveals task-dependent entropy flow in sparsely active nonequilibrium neuronal dynamics</title>
      <link>https://arxiv.org/abs/2502.15440</link>
      <description>arXiv:2502.15440v2 Announce Type: replace 
Abstract: Neuronal ensemble activity, including coordinated and oscillatory patterns, exhibits hallmarks of nonequilibrium systems with time-asymmetric trajectories to maintain their organization. However, assessing time asymmetry from neuronal spiking activity remains challenging. The kinetic Ising model provides a framework for studying the causal, nonequilibrium dynamics in spiking recurrent neural networks. Recent theoretical advances in this model have enabled time-asymmetry estimation from large-scale steady-state data. Yet, neuronal activity often exhibits time-varying firing rates and coupling strengths, violating the steady-state assumption. To overcome these limitations, we developed a state-space kinetic Ising model that accounts for non-stationary and nonequilibrium properties of neural systems. This approach incorporates a mean-field method for estimating time-varying entropy flow, a key measure for maintaining the system's organization by dissipation. Applying this method to mouse visual cortex data revealed greater variability in causal couplings during task engagement despite the reduced neuronal activity with increased sparsity. Moreover, higher-performing mice exhibited increased coupling-related entropy flow per spike during task engagement, suggesting economical computation in the higher-performing mice. These findings underscore the model's utility in uncovering intricate asymmetric causal dynamics in neuronal ensembles and linking them to behavior through the thermodynamic underpinnings of neural computation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.15440v2</guid>
      <category>q-bio.NC</category>
      <category>cond-mat.dis-nn</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ken Ishihara, Hideaki Shimazaki</dc:creator>
    </item>
    <item>
      <title>Hyperbolic embedding of multilayer networks</title>
      <link>https://arxiv.org/abs/2505.20378</link>
      <description>arXiv:2505.20378v3 Announce Type: replace-cross 
Abstract: Multilayer networks offer a powerful framework for modeling complex systems across diverse domains, effectively capturing multiple types of connections and interdependent subsystems commonly found in real world scenarios. To analyze these networks, embedding techniques that project nodes into a lower-dimensional geometric space are essential. This paper introduces a novel hyperbolic embedding framework that advances the state of the art in multilayer network analysis. Our method, which supports heterogeneous node sets across networks and inter-layer connections, generates layer-specific hyperbolic embeddings, enabling detailed intra-layer analysis and inter-layer comparisons, while simultaneously preserving the global multilayer structure within hyperbolic space, a capability that sets it apart from existing approaches, which typically rely on independent embedding of layers. Through experiments on synthetic multilayer stochastic block models, we demonstrate that our approach effectively preserves community structure, even when layers consist of different node sets. When applied to real brain networks, the method successfully clusters disease-related brain regions from different patients, outperforming layer-independent approaches and highlighting its relevance for comparative analysis. Overall, this work provides a robust tool for multilayer network analysis, enhancing interpretability and offering new insights into the structure and function of complex systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20378v3</guid>
      <category>cs.SI</category>
      <category>physics.data-an</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martin Guillemaud, Vera Dinkelacker, Mario Chavez</dc:creator>
    </item>
    <item>
      <title>Learning Task-Agnostic Motifs to Capture the Continuous Nature of Animal Behavior</title>
      <link>https://arxiv.org/abs/2506.15190</link>
      <description>arXiv:2506.15190v2 Announce Type: replace-cross 
Abstract: Animals flexibly recombine a finite set of core motor motifs to meet diverse task demands, but existing behavior segmentation methods oversimplify this process by imposing discrete syllables under restrictive generative assumptions. To better capture the continuous structure of behavior generation, we introduce motif-based continuous dynamics (MCD) discovery, a framework that (1) uncovers interpretable motif sets as latent basis functions of behavior by leveraging representations of behavioral transition structure, and (2) models behavioral dynamics as continuously evolving mixtures of these motifs. We validate MCD on a multi-task gridworld, a labyrinth navigation task, and freely moving animal behavior. Across settings, it identifies reusable motif components, captures continuous compositional dynamics, and generates realistic trajectories beyond the capabilities of traditional discrete segmentation models. By providing a generative account of how complex animal behaviors emerge from dynamic combinations of fundamental motor motifs, our approach advances the quantitative study of natural behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.15190v2</guid>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiyi Wang, Jingyang Ke, Bo Dai, Anqi Wu</dc:creator>
    </item>
  </channel>
</rss>
