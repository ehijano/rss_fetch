<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.ST updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.ST</link>
    <description>math.ST updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.ST" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 22 Aug 2025 04:01:57 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 22 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Ties, Tails and Spectra: On Rank-Based Dependency Measures in High Dimensions</title>
      <link>https://arxiv.org/abs/2508.14992</link>
      <description>arXiv:2508.14992v1 Announce Type: new 
Abstract: This work is concerned with the limiting spectral distribution of rank-based dependency measures in high dimensions. We provide distribution-free results for multivariate empirical versions of Kendall's $\tau$ and Spearman's $\rho$ in a setting where the dimension $p$ grows at most proportionally to the sample size $n$. Although rank-based measures are known to be well suited for discrete and heavy-tailed data, previous works in the field focused mostly on the continuous and light-tailed case. We close this gap by imposing mild assumptions and allowing for general types of distributions. Interestingly, our analysis reveals that a non-trivial adjustment of classical Kendall's $\tau$ is needed to obtain a pivotal limiting distribution in the presence of tied data. The proof for Spearman's $\rho$ is facilitated by a result regarding the limiting eigenvalue distribution of a general class of random matrices with rows on the Euclidean unit sphere, which is of independent interest. For instance, this finding can be used to derive the limiting spectral distribution of sample correlation matrices, which, in contrast to most existing works, accommodates heavy-tailed data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.14992v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Fri, 22 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nina D\"ornemann, Michael Fleermann, Johannes Heiny</dc:creator>
    </item>
    <item>
      <title>Multiply Robust Conformal Risk Control with Coarsened Data</title>
      <link>https://arxiv.org/abs/2508.15489</link>
      <description>arXiv:2508.15489v1 Announce Type: new 
Abstract: Conformal Prediction (CP) has recently received a tremendous amount of interest, leading to a wide range of new theoretical and methodological results for predictive inference with formal theoretical guarantees. However, the vast majority of CP methods assume that all units in the training data have fully observed data on both the outcome and covariates of primary interest, an assumption that rarely holds in practice. In reality, training data are often missing the outcome, a subset of covariates, or both on some units. In addition, time-to-event outcomes in the training set may be censored due to dropout or administrative end-of-follow-up. Accurately accounting for such coarsened data in the training sample while fulfilling the primary objective of well-calibrated conformal predictive inference, requires robustness and efficiency considerations. In this paper, we consider the general problem of obtaining distribution-free valid prediction regions for an outcome given coarsened training data. Leveraging modern semiparametric theory, we achieve our goal by deriving the efficient influence function of the quantile of the outcome we aim to predict, under a given semiparametric model for the coarsened data, carefully combined with a novel conformal risk control procedure. Our principled use of semiparametric theory has the key advantage of facilitating flexible machine learning methods such as random forests to learn the underlying nuisance functions of the semiparametric model. A straightforward application of the proposed general framework produces prediction intervals with stronger coverage properties under covariate shift, as well as the construction of multiply robust prediction sets in monotone missingness scenarios. We further illustrate the performance of our methods through various simulation studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.15489v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 22 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Manit Paul, Arun Kumar Kuchibhotla, Eric J. Tchetgen Tchetgen</dc:creator>
    </item>
    <item>
      <title>Robust Estimation Under Heterogeneous Corruption Rates</title>
      <link>https://arxiv.org/abs/2508.15051</link>
      <description>arXiv:2508.15051v1 Announce Type: cross 
Abstract: We study the problem of robust estimation under heterogeneous corruption rates, where each sample may be independently corrupted with a known but non-identical probability. This setting arises naturally in distributed and federated learning, crowdsourcing, and sensor networks, yet existing robust estimators typically assume uniform or worst-case corruption, ignoring structural heterogeneity. For mean estimation for multivariate bounded distributions and univariate gaussian distributions, we give tight minimax rates for all heterogeneous corruption patterns. For multivariate gaussian mean estimation and linear regression, we establish the minimax rate for squared error up to a factor of $\sqrt{d}$, where $d$ is the dimension. Roughly, our findings suggest that samples beyond a certain corruption threshold may be discarded by the optimal estimators -- this threshold is determined by the empirical distribution of the corruption rates given.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.15051v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 22 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Syomantak Chaudhuri, Jerry Li, Thomas A. Courtade</dc:creator>
    </item>
    <item>
      <title>Large-dimensional Factor Analysis with Weighted PCA</title>
      <link>https://arxiv.org/abs/2508.15675</link>
      <description>arXiv:2508.15675v1 Announce Type: cross 
Abstract: Principal component analysis (PCA) is arguably the most widely used approach for large-dimensional factor analysis. While it is effective when the factors are sufficiently strong, it can be inconsistent when the factors are weak and/or the noise has complex dependence structure. We argue that the inconsistency often stems from bias and introduce a general approach to restore consistency. Specifically, we propose a general weighting scheme for PCA and show that with a suitable choice of weighting matrices, it is possible to deduce consistent and asymptotic normal estimators under much weaker conditions than the usual PCA. While the optimal weight matrix may require knowledge about the factors and covariance of the idiosyncratic noise that are not known a priori, we develop an agnostic approach to adaptively choose from a large class of weighting matrices that can be viewed as PCA for weighted linear combinations of auto-covariances among the observations. Theoretical and numerical results demonstrate the merits of our methodology over the usual PCA and other recently developed techniques for large-dimensional approximate factor models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.15675v1</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 22 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhongyuan Lyu, Ming Yuan</dc:creator>
    </item>
    <item>
      <title>Comparing Scale Parameter Estimators for Gaussian Process Interpolation with the Brownian Motion Prior: Leave-One-Out Cross Validation and Maximum Likelihood</title>
      <link>https://arxiv.org/abs/2307.07466</link>
      <description>arXiv:2307.07466v3 Announce Type: replace 
Abstract: Gaussian process (GP) regression is a Bayesian nonparametric method for regression and interpolation, offering a principled way of quantifying the uncertainties of predicted function values. For the quantified uncertainties to be well-calibrated, however, the kernel of the GP prior has to be carefully selected. In this paper, we theoretically compare two methods for choosing the kernel in GP regression: cross-validation and maximum likelihood estimation. Focusing on the scale-parameter estimation of a Brownian motion kernel in the noiseless setting, we prove that cross-validation can yield asymptotically well-calibrated credible intervals for a broader class of ground-truth functions than maximum likelihood estimation, suggesting an advantage of the former over the latter. Finally, motivated by the findings, we propose interior cross validation, a procedure that adapts to an even broader class of ground-truth functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.07466v3</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 22 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1137/23M1586884</arxiv:DOI>
      <arxiv:journal_reference>SIAM/ASA Journal on Uncertainty Quantification (2025), 13(2), pp. 679--717</arxiv:journal_reference>
      <dc:creator>Masha Naslidnyk, Motonobu Kanagawa, Toni Karvonen, Maren Mahsereci</dc:creator>
    </item>
    <item>
      <title>Dynamic clustering for heterophilic stochastic block models with time-varying node memberships</title>
      <link>https://arxiv.org/abs/2403.05654</link>
      <description>arXiv:2403.05654v2 Announce Type: replace 
Abstract: We consider a time-ordered sequence of networks stemming from stochastic block models where nodes gradually change their memberships over time, and no network at any single time point contains sufficient signal strength to recover its community structure. To estimate the time-varying community structure, we develop KD-SoS (kernel debiased sum-of-squares), a method that performs spectral clustering after a debiased sum-of-squared aggregation of adjacency matrices. Our theory demonstrates, via a novel bias-variance decomposition, that KD-SoS achieves consistent community detection in each network, even when heterophilic networks do not require smoothness in the time-varying dynamics of between-community connectivities. We also prove the identifiability of aligning community structures across time based on how rapidly nodes change communities, and develop a data-adaptive bandwidth tuning procedure for KD-SoS. We demonstrate the utility and advantages of KD-SoS through simulations and a novel analysis of the time-varying dynamics in gene coordination in the human developing brain system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05654v2</guid>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <pubDate>Fri, 22 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kevin Z Lin, Jing Lei</dc:creator>
    </item>
    <item>
      <title>Approximation rates for finite mixtures of location-scale models</title>
      <link>https://arxiv.org/abs/2508.10612</link>
      <description>arXiv:2508.10612v2 Announce Type: replace 
Abstract: Finite mixture models provide useful methods for approximation and estimation of probability density functions. In the context of location-scale mixture models, we improve upon previous results to show that it is possible to quantitatively bound the ${\cal L}_{p}$ approximation error in terms of the number of mixture components $m$ for any $p\in\left(1,\infty\right)$. In particular, for approximation on $\mathbb{R}^{d}$ of targets $f_{0}\in{\cal W}^{s,p}$, the (fractional) Sobolev spaces with smoothness order $s\in\left(0,1\right]$, if $p&lt;2$ then the error has size $O\left(m^{-\frac{s}{sq+d}}\right)$, while if $p\ge2$, the error has size $O\left(m^{-\frac{2s}{2\left(sq+d\right)}}\right)$, where $q=1/\left(p-1\right)$. We demonstrate that these results can be used to derive estimation rates for a location-scale mixture-based adaptive least-squares estimator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10612v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 22 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hien Duy Nguyen, TrungTin Nguyen, Jacob Westerhout, Xin Guo</dc:creator>
    </item>
    <item>
      <title>Multi-period static hedging of European options</title>
      <link>https://arxiv.org/abs/2310.01104</link>
      <description>arXiv:2310.01104v3 Announce Type: replace-cross 
Abstract: We consider the hedging of European options when the price of the underlying asset follows a single-factor Markovian framework. By working in such a setting, Carr and Wu \cite{carr2014static} derived a spanning relation between a given option and a continuum of shorter-term options written on the same asset. In this paper, we have extended their approach to simultaneously include options over multiple short maturities. We then show a practical implementation of this with a finite set of shorter-term options to determine the hedging error using a Gaussian Quadrature method. We perform a wide range of experiments for both the \textit{Black-Scholes} and \textit{Merton Jump Diffusion} models, illustrating the comparative performance of the two methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.01104v3</guid>
      <category>q-fin.MF</category>
      <category>econ.EM</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 22 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.21314/JCF.2024.009</arxiv:DOI>
      <dc:creator>Purba Banerjee, Srikanth Iyer, Shashi Jain</dc:creator>
    </item>
    <item>
      <title>A General Framework for Multiple Testing via E-value Aggregation and Data-Dependent Weighting</title>
      <link>https://arxiv.org/abs/2312.02905</link>
      <description>arXiv:2312.02905v2 Announce Type: replace-cross 
Abstract: Motivated by recent findings in Li and Zhang (2025), which established an equivalence between certain p-value-based multiple testing procedures and the e-Benjamini-Hochberg procedure (Wang and Ramdas, 2022), we introduce a general framework for constructing novel multiple testing methods through the aggregation and combination of e-values. Specifically, we propose methodologies for three distinct scenarios: (i) assembly of e-values obtained from different subsets of data, simultaneously controlling group-wise and overall false discovery rates; (ii) aggregation of e-values derived from different procedures or the same procedure employing different test statistics; and (iii) adaptive multiple testing methods that incorporate external structural information to enhance statistical power. A notable feature of our approach is the use of data-dependent weighting of e-values, significantly improving the efficiency of the resulting e-Benjamini-Hochberg procedures. The construction of these weights is non-trivial and inspired by leave-one-out analysis, a widely utilized technique for proving false discovery rate control in p-value-based methodologies. We theoretically establish that the proposed e-Benjamini-Hochberg procedures, when equipped with data-dependent weights, guarantee finite-sample false discovery rate control across all three considered applications. Additionally, numerical studies illustrate the efficacy and advantages of the proposed methods within each application scenario.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.02905v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 22 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guanxun Li, Xianyang Zhang</dc:creator>
    </item>
    <item>
      <title>Fluctuation of the Largest Eigenvalue of a Kernel Matrix with application in Graphon-based Random Graphs</title>
      <link>https://arxiv.org/abs/2401.01866</link>
      <description>arXiv:2401.01866v3 Announce Type: replace-cross 
Abstract: In this article, we explore the spectral properties of general random kernel matrices $[K(U_i,U_j)]_{1\leq i\neq j\leq n}$ from a Lipschitz kernel $K$ with $n$ independent random variables $U_1,U_2,\ldots, U_n$ distributed uniformly over $[0,1]$. In particular we identify a dichotomy in the extreme eigenvalue of the kernel matrix, where, if the kernel $K$ is degenerate, the largest eigenvalue of the kernel matrix (after proper normalization) converges weakly to a weighted sum of independent chi-squared random variables. In contrast, for non-degenerate kernels, it converges to a normal distribution extending and reinforcing earlier results from Koltchinskii and Gin\'e (2000). Further, we apply this result to show a dichotomy in the asymptotic behavior of extreme eigenvalues of $W$-random graphs, which are pivotal in modeling complex networks and analyzing large-scale graph behavior. These graphs are generated using a kernel $W$, termed as graphon, by connecting vertices $i$ and $j$ with probability $W(U_i, U_j)$. Our results show that for a Lipschitz graphon $W$, if the degree function is constant, the fluctuation of the largest eigenvalue (after proper normalization) converges to the weighted sum of independent chi-squared random variables and an independent normal distribution. Otherwise, it converges to a normal distribution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.01866v3</guid>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 22 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anirban Chatterjee, Jiaoyang Huang</dc:creator>
    </item>
    <item>
      <title>Penalized GEE for Complex Carry-Over in Repeated-Measures Crossover Designs</title>
      <link>https://arxiv.org/abs/2402.16362</link>
      <description>arXiv:2402.16362v3 Announce Type: replace-cross 
Abstract: It has been argued for many years that models used to analyze data from crossover designs are not appropriate when simple carryover effects are assumed. Furthermore, a statistical model that could estimate complex carry-over effects in crossover designs had never been found. However, in this paper, the estimability conditions of the complex carryover effects and a theoretical result that supports them are found. In addition, a simulation example is developed in a non-linear dose-response test for a typical AB/BA crossover design with repeated measures. This simulation shows that a semiparametric model can detect complex carryover effects and that this estimation improves the precision of the estimators of the treatment effect. It is concluded that when there are at least five replicates in each observation period per individual, semiparametric statistical models provide a good estimator of the treatment effect and reduce bias with respect to models that assume the absence of carryover effects or simplex carryover effects. Furthermore, an application of the methodology is shown and the wealth of analysis gained by estimating complex carryover effects is evident.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.16362v3</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 22 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>N. A. Cruz, K. Mylona, O. O. Melo</dc:creator>
    </item>
    <item>
      <title>Central limit theorems for interacting innovation processes, related statistical tools and general results</title>
      <link>https://arxiv.org/abs/2501.09648</link>
      <description>arXiv:2501.09648v3 Announce Type: replace-cross 
Abstract: We study a networked system of innovation processes, where each process is modeled as an urn with infinitely many colors-a classical framework for capturing the emergence of novelties. Extending this paradigm, we analyze a model of interacting urns, where the probability of generating or reusing elements in one process is influenced by the histories of others. This interaction is governed by two matrices that control innovation triggering and reinforcement dynamics across the system. The core contribution of this work is a detailed analysis of the second-order asymptotic behavior of the model. Building on these theoretical results, we develop statistical tools to infer the structure and strength of inter-process influence. The methodology is framed in a general setting, making it broadly applicable. We validate our approach with applications to two real-world datasets from Reddit discussions and Gutenberg text corpora.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09648v3</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 22 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Giacomo Aletti, Irene Crimaldi, Andrea Ghiglietti</dc:creator>
    </item>
  </channel>
</rss>
