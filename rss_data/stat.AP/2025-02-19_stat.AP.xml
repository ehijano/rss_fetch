<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 19 Feb 2025 05:01:55 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>The impact of job stability on monetary poverty in Italy: causal small area estimation</title>
      <link>https://arxiv.org/abs/2502.12376</link>
      <description>arXiv:2502.12376v1 Announce Type: new 
Abstract: Job stability - encompassing secure contracts, adequate wages, social benefits, and career opportunities - is a critical determinant in reducing monetary poverty, as it provides households with reliable income and enhances economic well-being. This study leverages EU-SILC survey and census data to estimate the causal effect of job stability on monetary poverty across Italian provinces, quantifying its influence and analyzing regional disparities. We introduce a novel causal small area estimation (CSAE) framework that integrates global and local estimation strategies for heterogeneous treatment effect estimation, effectively addressing data sparsity at the provincial level. Furthermore, we develop a general bootstrap scheme to construct reliable confidence intervals, applicable regardless of the method used for estimating nuisance parameters. Extensive simulation studies demonstrate that our proposed estimators outperform classical causal inference methods in terms of stability while maintaining computational scalability for large datasets. Applying this methodology to real-world data, we uncover significant relationships between job stability and poverty across six Italian regions, offering critical insights into regional disparities and their implications for evidence-based policy design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12376v1</guid>
      <category>stat.AP</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Katarzyna Reluga, Dehan Kong, Setareh Ranjbar, Nicola Salvati, Mark van der Laan</dc:creator>
    </item>
    <item>
      <title>Bridging the Data Gap in AI Reliability Research and Establishing DR-AIR, a Comprehensive Data Repository for AI Reliability</title>
      <link>https://arxiv.org/abs/2502.12386</link>
      <description>arXiv:2502.12386v1 Announce Type: new 
Abstract: Artificial intelligence (AI) technology and systems have been advancing rapidly. However, ensuring the reliability of these systems is crucial for fostering public confidence in their use. This necessitates the modeling and analysis of reliability data specific to AI systems. A major challenge in AI reliability research, particularly for those in academia, is the lack of readily available AI reliability data. To address this gap, this paper focuses on conducting a comprehensive review of available AI reliability data and establishing DR-AIR: a data repository for AI reliability. Specifically, we introduce key measurements and data types for assessing AI reliability, along with the methodologies used to collect these data. We also provide a detailed description of the currently available datasets with illustrative examples. Furthermore, we outline the setup of the DR-AIR repository and demonstrate its practical applications. This repository provides easy access to datasets specifically curated for AI reliability research. We believe these efforts will significantly benefit the AI research community by facilitating access to valuable reliability data and promoting collaboration across various academic domains within AI. We conclude our paper with a call to action, encouraging the research community to contribute and share AI reliability data to further advance this critical field of study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12386v1</guid>
      <category>stat.AP</category>
      <category>cs.AI</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Simin Zheng, Jared M. Clark, Fatemeh Salboukh, Priscila Silva, Karen da Mata, Fenglian Pan, Jie Min, Jiayi Lian, Caleb B. King, Lance Fiondella, Jian Liu, Xinwei Deng, Yili Hong</dc:creator>
    </item>
    <item>
      <title>Performance Evaluation of Large Language Models in Statistical Programming</title>
      <link>https://arxiv.org/abs/2502.13117</link>
      <description>arXiv:2502.13117v1 Announce Type: new 
Abstract: The programming capabilities of large language models (LLMs) have revolutionized automatic code generation and opened new avenues for automatic statistical analysis. However, the validity and quality of these generated codes need to be systematically evaluated before they can be widely adopted. Despite their growing prominence, a comprehensive evaluation of statistical code generated by LLMs remains scarce in the literature. In this paper, we assess the performance of LLMs, including two versions of ChatGPT and one version of Llama, in the domain of SAS programming for statistical analysis. Our study utilizes a set of statistical analysis tasks encompassing diverse statistical topics and datasets. Each task includes a problem description, dataset information, and human-verified SAS code. We conduct a comprehensive assessment of the quality of SAS code generated by LLMs through human expert evaluation based on correctness, effectiveness, readability, executability, and the accuracy of output results. The analysis of rating scores reveals that while LLMs demonstrate usefulness in generating syntactically correct code, they struggle with tasks requiring deep domain understanding and may produce redundant or incorrect results. This study offers valuable insights into the capabilities and limitations of LLMs in statistical programming, providing guidance for future advancements in AI-assisted coding systems for statistical analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13117v1</guid>
      <category>stat.AP</category>
      <category>cs.AI</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinyi Song, Kexin Xie, Lina Lee, Ruizhe Chen, Jared M. Clark, Hao He, Haoran He, Jie Min, Xinlei Zhang, Simin Zheng, Zhiyang Zhang, Xinwei Deng, Yili Hong</dc:creator>
    </item>
    <item>
      <title>Bayesian inference from time series of allele frequency data using exact simulation techniques</title>
      <link>https://arxiv.org/abs/2502.12279</link>
      <description>arXiv:2502.12279v1 Announce Type: cross 
Abstract: A central statistical problem in population genetics is to infer evolutionary and biological parameters such as the strength of natural selection and allele age from DNA samples extracted from a contemporary population. That all samples come only from the present-day has long been known to limit statistical inference; there is potentially more information available if one also has access to ancient DNA so that inference is based on a time-series of historical changes in allele frequencies. We introduce a Markov Chain Monte Carlo (MCMC) method for Bayesian inference from allele frequency time-series data based on an underlying Wright--Fisher diffusion model of evolution, through which one can infer the parameters of essentially any selection model including those with frequency-dependent effects. The chief novelty is that we show this method to be exact in the sense that it is possible to augment the state space explored by MCMC with the unobserved diffusion trajectory, even though the transition function of this diffusion is intractable. Through careful design of a proposal distribution, we describe an efficient method in which updates to the trajectory and accept/reject decisions are calculated without error. We illustrate the method on data capturing changes in coat colour over the past 20,000 years, and find evidence to support previous findings that the mutant alleles ASIP and MC1R responsible for changes in coat color have experienced very strong, possibly overdominant, selection and further provide estimates for the ages of these genes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12279v1</guid>
      <category>q-bio.PE</category>
      <category>math.PR</category>
      <category>q-bio.QM</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jaromir Sant, Paul A. Jenkins, Jere Koskela, Dario Spano</dc:creator>
    </item>
    <item>
      <title>Locally-Deployed Chain-of-Thought (CoT) Reasoning Model in Chemical Engineering: Starting from 30 Experimental Data</title>
      <link>https://arxiv.org/abs/2502.12383</link>
      <description>arXiv:2502.12383v1 Announce Type: cross 
Abstract: In the field of chemical engineering, traditional data-processing and prediction methods face significant challenges. Machine-learning and large-language models (LLMs) also have their respective limitations. This paper explores the application of the Chain-of-Thought (CoT) reasoning model in chemical engineering, starting from 30 experimental data points. By integrating traditional surrogate models like Gaussian processes and random forests with powerful LLMs such as DeepSeek-R1, a hierarchical architecture is proposed. Two CoT-building methods, Large Language Model-Chain of Thought (LLM-CoT) and Machine Learning-Large Language Model-Chain of Thought (ML-LLM-CoT), are studied. The LLM-CoT combines local models DeepSeek-r1:14b and Qwen2:7b with Ollama. The ML-LLM-CoT integrates a pre-trained Gaussian ML model with the LLM-based CoT framework. Our results show that during construction, ML-LLM-CoT is more efficient. It only has 2 points that require rethink and a total of 4 rethink times, while LLM-CoT has 5 points that need to be re-thought and 34 total rethink times. In predicting the solubility of 20 molecules with dissimilar structures, the number of molecules with a prediction deviation higher than 100\% for the Gaussian model, LLM-CoT, and ML-LLM-CoT is 7, 6, and 4 respectively. These results indicate that ML-LLM-CoT performs better in controlling the number of high-deviation molecules, optimizing the average deviation, and achieving a higher success rate in solubility judgment, providing a more reliable method for chemical engineering and molecular property prediction. This study breaks through the limitations of traditional methods and offers new solutions for rapid property prediction and process optimization in chemical engineering.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12383v1</guid>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Tianhang Zhou, Yingchun Niu, Xingying Lan, Chunming Xu</dc:creator>
    </item>
    <item>
      <title>Correlation between upstreamness and downstreamness in random global value chains</title>
      <link>https://arxiv.org/abs/2303.06603</link>
      <description>arXiv:2303.06603v3 Announce Type: replace 
Abstract: This paper is concerned with upstreamness and downstreamness of industries and countries. Upstreamness and downstreamness measure respectively the average distance of an industrial sector from final consumption and from primary inputs. Recently, Antr\`as and Chor reported a puzzling and counter-intuitive finding in data from the period 1995-2011, namely that (at country level) upstreamness appears to be positively correlated with downstreamness, with a correlation slope close to $+1$. We first analyze a simple model of random Input/Output tables, and we show that, under minimal and realistic structural assumptions, there is a natural positive correlation emerging between upstreamness and downstreamness of the same industrial sector/country, with correlation slope equal to $+1$. This effect is robust against changes in the randomness of the entries of the I/O table and different aggregation protocols. Secondly, we perform experiments by randomly reshuffling the entries of the empirical I/O table where these puzzling correlations are detected, in such a way that the global structural constraints are preserved. Again, we find that the upstreamness and downstreamness of the same industrial sector/country are positively correlated with slope close to $+1$. Our results strongly suggest that (i) extra care is needed when interpreting these measures as simple representations of each sector's positioning along the value chain, as the ``curse of the input-output identities'' and labor effects effectively force the value chain to acquire additional links from primary factors of production, and (ii) the empirically observed puzzling correlation may rather be a necessary consequence of the few structural constraints (positive entries, and sub-stochasticity) that Input/Output tables and their surrogates must meet.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.06603v3</guid>
      <category>stat.AP</category>
      <category>cond-mat.stat-mech</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <category>q-fin.ST</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Silvia Bartolucci, Fabio Caccioli, Francesco Caravelli, Pierpaolo Vivo</dc:creator>
    </item>
    <item>
      <title>A Closer Look at Mortality Risk Prediction from Electrocardiograms</title>
      <link>https://arxiv.org/abs/2406.17002</link>
      <description>arXiv:2406.17002v3 Announce Type: replace-cross 
Abstract: Several recent studies combine large private ECG databases with AI to predict patient mortality. These studies typically use a few, highly variable, modeling approaches. While benchmarking these approaches has historically been limited by a lack of public ECG datasets, this changed with the 2023 release of MIMIC-IV, containing 795,546 ECGs from a U.S. hospital system, and the 2020 release of Code-15, containing 345,779 ECGs collected during routine care in Brazil. We benchmark over 500 AI-ECG survival models predicting all-cause mortality on Code-15 and MIMIC-IV with 2 neural architectures, 4 Deep-Survival-Analysis approaches, and classifiers predicting mortality at 4 time horizons. We extend the highest-performing approach to a dataset from Boston Children's Hospital (BCH, 225,379 ECGs). Models train with and without demographics (age/sex) and evaluate across datasets. The best performing Deep-Survival-Analysis models trained with ECG and demographics yield good median Concordance Indices (Code-15: 0.82, MIMIC-IV: 0.78, BCH: 0.76) and AUPRC scores (median 1-yr/5-yr, Code-15: 0.07/0.15; MIMIC-IV: 0.45/0.55; BCH: 0.04/0.13) considering the percentage of ECGs linked to mortality (1-yr/5-yr, Code-15: 1.2%/3.4%; MIMIC-IV: 14.8%/24.5%; BCH: 0.9%/4.8%). Contrasting with Deep-Survival-Analysis models, classifier-based AI-ECG models exhibit significant, site-dependent sensitivity to the choice of time horizon (median Pearson's R, Code-15: 0.69, p&lt;1E-5; MIMIC-IV: -0.80 p&lt;1E-5). Demographic-only models perform surprisingly well on Code-15. Concordance drops 0.03-0.24 on external validation. We recommend Deep-Survival-Analysis over Classifier-Cox approaches and the inclusion of demographic covariates in ECG survival modeling. Comparisons to demographic-only and baseline models is crucial. External evaluations support fine-tuning models on site-specific data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17002v3</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <category>stat.AP</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Platon Lukyanenko, Joshua Mayourian, Mingxuan Liu, John K. Triedman, Sunil J. Ghelani, William G. La Cava</dc:creator>
    </item>
  </channel>
</rss>
