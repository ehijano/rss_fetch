<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 13 Jan 2026 05:00:34 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Gamma2Patterns: Deep Cognitive Attention Region Identification and Gamma-Alpha Pattern Analysis</title>
      <link>https://arxiv.org/abs/2601.06257</link>
      <description>arXiv:2601.06257v1 Announce Type: new 
Abstract: Deep cognitive attention is characterized by heightened gamma oscillations and coordinated visual behavior. Despite the physiological importance of these mechanisms, computational studies rarely synthesize these modalities or identify the neural regions most responsible for sustained focus. To address this gap, this work introduces Gamma2Patterns, a multimodal framework that characterizes deep cognitive attention by leveraging complementary Gamma and Alpha band EEG activity alongside Eye-tracking measurements. Using the SEED-IV dataset [1], we extract spectral power, burst-based temporal dynamics, and fixation-saccade-pupil signals across 62 channels or electrodes to analyze how neural activation differs between high-focus (Gamma-dominant) and low-focus (Alpha-dominant) states. Our findings reveal that frontopolar, temporal, anterior frontal, and parieto-occipital regions exhibit the strongest Gamma power and burst rates, indicating their dominant role in deep attentional engagement, while Eye-tracking signals confirm complementary contributions from frontal, frontopolar, and frontotemporal regions. Furthermore, we show that Gamma power and burst duration provide more discriminative markers of deep focus than Alpha power alone, demonstrating their value for attention decoding. Collectively, these results establish a multimodal, evidence-based map of cortical regions and oscillatory signatures underlying deep focus, providing a neurophysiological foundation for future brain-inspired attention mechanisms in AI systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06257v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sobhana Jahan, Saydul Akbar Murad, Nick Rahimi, Noorbakhsh Amiri Golilarz</dc:creator>
    </item>
    <item>
      <title>Learning Principles for Overcoming Non-ideal Factors in Brain</title>
      <link>https://arxiv.org/abs/2601.06531</link>
      <description>arXiv:2601.06531v1 Announce Type: new 
Abstract: The human brain's computational prowess emerges not despite but because of its inherent "non-ideal factors"-noise, heterogeneity, structural irregularities, decentralized plasticity, systemic errors, and chaotic dynamics-challenging classical neuroscience's idealized models. These traits, long dismissed as flaws, are evolutionary adaptations that endow the brain with robustness, creativity, and adaptability. Classical frameworks falter under the brain's complexity: simulating 86 billion neurons and 100 trillion synapses is intractable, stochastic neurotransmitter release confounds signal interpretation, and the absence of global idealized models invalidates deterministic learning frameworks. Technological gaps further obscure whole-brain dynamics, revealing a disconnect between biological reality and computational abstraction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06531v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Da-Zheng Feng, Hao-Xuan Du</dc:creator>
    </item>
    <item>
      <title>Neuronal Spike Trains as Functional-Analytic Distributions: Representation, Analysis, and Significance</title>
      <link>https://arxiv.org/abs/2601.07215</link>
      <description>arXiv:2601.07215v1 Announce Type: new 
Abstract: The action potential constitutes the digital component of the signaling dynamics of neurons. But the biophysical nature of the full time course of the action potential associated with changes in membrane potential is fundamentally and mathematically distinct from its representation as a discrete set of events that encode when action potentials triggered in a collection spike trains. In this paper, we rigorously explore from first principles the transition and modeling from the standard biophysical picture of a single action potential to its representation as a spike in a spike train. In particular, we adopt a functional-analytic framework, using Schwartz distribution theory to represent spike trains as generalized Dirac delta functions acting on smooth test functions. We then show how and why this representation transcends a purely descriptive formalism to support deep downstream analysis and modeling of spike train neural dynamics in a mathematically consistent way.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07215v1</guid>
      <category>q-bio.NC</category>
      <category>math.FA</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gabriel A. Silva</dc:creator>
    </item>
    <item>
      <title>Charting the velocity of brain growth and development</title>
      <link>https://arxiv.org/abs/2601.07591</link>
      <description>arXiv:2601.07591v1 Announce Type: new 
Abstract: Brain charts have emerged as a highly useful approach for understanding brain development and aging on the basis of brain imaging and have shown substantial utility in describing typical and atypical brain development with respect to a given reference model. However, all existing models are fundamentally cross-sectional and cannot capture change over time at the individual level. We address this using velocity centiles, which directly map change over time and can be overlaid onto cross-sectionally derived population centiles. We demonstrate this by modelling rates of change for 24062 scans from 10795 healthy individuals with up to 8 longitudinal measurements across the lifespan. We provide a method to detect individual deviations from a stable trajectory, generalising the notion of thrive lines, which are used in pediatric medicine to declare failure to thrive. Using this approach, we predict transition from mild cognitive impairment to dementia more accurately than by using either time point alone, replicated across two datasets. Last, by taking into account multiple time points, we improve the sensitivity of velocity models for predicting the future trajectory of brain change. This highlights the value of predicting change over time and makes a fundamental step towards precision medicine.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07591v1</guid>
      <category>q-bio.NC</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Johanna M. M. Bayer, Augustijn A. A. de Boer, Barbora Rehak-Bucova, Charlotte J. Fraza, Tobias Banaschewski, Gareth J. Barker, Arun L. W. Bokde, Ruediger Bruehl, Sylvane Desrivieres, Herta Flor, Hugh Garavan, Penny Gowland, Antoine Grigis, Andreas Heinz, Herve Lemaitre, Jean-Luc Martinot, Marie-Laure Paillere Martinot, Eric Artigues, Frauke Nees, Dimitri Papadopoulos Orfanos, Tomas Paus, Luise Poustka, Michael N. Smolka, Nathalie Holz, Nilakshi Vaidya, Henrik Walter, Robert Whelan, Paul Wirsching, Gunter Schumann, Alzheimers Disease Neuroimaging Initiative, Nina Kraguljac, Christian F. Beckmann, Andre F. Marquand</dc:creator>
    </item>
    <item>
      <title>DeeperBrain: A Neuro-Grounded EEG Foundation Model Towards Universal BCI</title>
      <link>https://arxiv.org/abs/2601.06134</link>
      <description>arXiv:2601.06134v1 Announce Type: cross 
Abstract: Electroencephalography (EEG) foundation models hold significant promise for universal Brain-Computer Interfaces (BCIs). However, existing approaches often rely on end-to-end fine-tuning and exhibit limited efficacy under frozen-probing protocols, lacking the intrinsic universality required for broad generalization. This limitation stems from adapting general-purpose sequence architectures that overlook the biophysical and dynamical principles of neural activity. To bridge this gap, we propose DeeperBrain, a neuro-grounded foundation model integrating domain-specific inductive biases into its model design and learning objectives. Architecturally, DeeperBrain incorporates a volume conduction-aware channel encoding to model spatial mixing via 3D geometry, and a neurodynamics-aware temporal encoding capturing slow adaptations using oscillatory and exponential bases. For pretraining, we introduce a dual-objective strategy combining Masked EEG Reconstruction (MER) for local fidelity and Neurodynamics Statistics Prediction (NSP). NSP enforces alignment with macroscopic brain states by predicting interpretable order parameters, including spectral power, functional connectivity, cross-frequency coupling, and dynamic complexity. Extensive experiments demonstrate that DeeperBrain achieves state-of-the-art or highly competitive performance under end-to-end fine-tuning. Crucially, it maintains superior efficacy under a rigorous frozen-probing protocol, verifying that embedding neuroscientific first principles endows learned representations with the intrinsic universality essential for universal BCI. The code will be publicly available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06134v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiquan Wang, Sha Zhao, Yangxuan Zhou, Yiming Kang, Shijian Li, Gang Pan</dc:creator>
    </item>
    <item>
      <title>Continuous Energy Landscape Model for Analyzing Brain State Transitions</title>
      <link>https://arxiv.org/abs/2601.06991</link>
      <description>arXiv:2601.06991v1 Announce Type: cross 
Abstract: Energy landscape models characterize neural dynamics by assigning energy values to each brain state that reflect their stability or probability of occurrence. The conventional energy landscape models rely on binary brain state representation, where each region is considered either active or inactive based on some signal threshold. However, this binarization leads to significant information loss and an exponential increase in the number of possible brain states, making the calculation of energy values infeasible for large numbers of brain regions. To overcome these limitations, we propose a novel continuous energy landscape framework that employs Graph Neural Networks (GNNs) to learn a continuous precision matrix directly from functional MRI (fMRI) signals, preserving the full range of signal values during energy landscape computation. We validated our approach using both synthetic data and real-world fMRI datasets from brain tumor patients. Our results on synthetic data generated from a switching linear dynamical system (SLDS) and a Kuramoto model show that the continuous energy model achieved higher likelihood and more accurate recovery of basin geometry, state occupancy, and transition dynamics than conventional binary energy landscape models. In addition, results from the fMRI dataset indicate a 0.27 increase in AUC for predicting working memory and executive function, along with a 0.35 improvement in explained variance (R2) for predicting reaction time. These findings highlight the advantages of utilizing the full signal values in energy landscape models for capturing neuronal dynamics, with strong implications for diagnosing and monitoring neurological disorders.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06991v1</guid>
      <category>eess.SP</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Triet M. Tran, Seyed Majid Razavi, Dee H. Wu, Sina Khanmohammadi</dc:creator>
    </item>
    <item>
      <title>Optimal Learning Rate Schedule for Balancing Effort and Performance</title>
      <link>https://arxiv.org/abs/2601.07830</link>
      <description>arXiv:2601.07830v1 Announce Type: cross 
Abstract: Learning how to learn efficiently is a fundamental challenge for biological agents and a growing concern for artificial ones. To learn effectively, an agent must regulate its learning speed, balancing the benefits of rapid improvement against the costs of effort, instability, or resource use. We introduce a normative framework that formalizes this problem as an optimal control process in which the agent maximizes cumulative performance while incurring a cost of learning. From this objective, we derive a closed-form solution for the optimal learning rate, which has the form of a closed-loop controller that depends only on the agent's current and expected future performance. Under mild assumptions, this solution generalizes across tasks and architectures and reproduces numerically optimized schedules in simulations. In simple learning models, we can mathematically analyze how agent and task parameters shape learning-rate scheduling as an open-loop control solution. Because the optimal policy depends on expectations of future performance, the framework predicts how overconfidence or underconfidence influence engagement and persistence, linking the control of learning speed to theories of self-regulated learning. We further show how a simple episodic memory mechanism can approximate the required performance expectations by recalling similar past learning experiences, providing a biologically plausible route to near-optimal behaviour. Together, these results provide a normative and biologically plausible account of learning speed control, linking self-regulated learning, effort allocation, and episodic memory estimation within a unified and tractable mathematical framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07830v1</guid>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Valentina Njaradi, Rodrigo Carrasco-Davis, Peter E. Latham, Andrew Saxe</dc:creator>
    </item>
    <item>
      <title>Backpropagation through space, time, and the brain</title>
      <link>https://arxiv.org/abs/2403.16933</link>
      <description>arXiv:2403.16933v4 Announce Type: replace 
Abstract: How physical networks of neurons, bound by spatio-temporal locality constraints, can perform efficient credit assignment, remains, to a large extent, an open question. In machine learning, the answer is almost universally given by the error backpropagation algorithm, through both space and time. However, this algorithm is well-known to rely on biologically implausible assumptions, in particular with respect to spatio-temporal (non-)locality. Alternative forward-propagation models such as real-time recurrent learning only partially solve the locality problem, but only at the cost of scaling, due to prohibitive storage requirements. We introduce Generalized Latent Equilibrium (GLE), a computational framework for fully local spatio-temporal credit assignment in physical, dynamical networks of neurons. We start by defining an energy based on neuron-local mismatches, from which we derive both neuronal dynamics via stationarity and parameter dynamics via gradient descent. The resulting dynamics can be interpreted as a real-time, biologically plausible approximation of backpropagation through space and time in deep cortical networks with continuous-time neuronal dynamics and continuously active, local synaptic plasticity. In particular, GLE exploits the morphology of dendritic trees to enable more complex information storage and processing in single neurons, as well as the ability of biological neurons to phase-shift their output rate with respect to their membrane potential, which is essential in both directions of information propagation. For the forward computation, it enables the mapping of time-continuous inputs to neuronal space, effectively performing a spatio-temporal convolution. For the backward computation, it permits the temporal inversion of feedback signals, which consequently approximate the adjoint variables necessary for useful parameter updates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16933v4</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <category>eess.SP</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1038/s41467-025-66666-z</arxiv:DOI>
      <arxiv:journal_reference>Nat. Commun. 17, 66 (2026)</arxiv:journal_reference>
      <dc:creator>Benjamin Ellenberger, Paul Haider, Jakob Jordan, Kevin Max, Ismael Jaras, Laura Kriener, Federico Benitez, Mihai A. Petrovici</dc:creator>
    </item>
    <item>
      <title>Synthetic Data Generation for Classifying Electrophysiological and Morpho-Electrophysiological Neurons from Mouse Visual Cortex</title>
      <link>https://arxiv.org/abs/2508.06514</link>
      <description>arXiv:2508.06514v2 Announce Type: replace 
Abstract: The accurate classification of neuronal cell types is central to decoding brain function, yet remains hindered by data scarcity and cellular heterogeneity. Here, we benchmarked classical and deep generative synthetic data augmentation strategies -- including SMOTE, GANs, VAEs, Normalizing Flows, and DDPMs -- for supervised classification of both electrophysiological (e-type) and morpho-electrophysiological (mee-type) neuron types from the mouse visual cortex. Using a curated dataset annotated with 48 electrophysiological and 24 morphological features, we established baseline classifiers and introduced synthetic data generated by each method. Our results demonstrate that SMOTE-based augmentation yields the highest classification accuracies (absolute gains of 0.16 for e-types, 0.12 for mee-types), outperforming deep generative models. GANs approached similar performance when hyperparameters and sample sizes were optimized, but were more sensitive to model specification. In addition, we benchmarked synthetic neuron fidelity by comparing mean absolute errors between synthetic and real class profiles against the natural phenotypic variability observed between real neuronal classes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.06514v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s12021-025-09761-2</arxiv:DOI>
      <arxiv:journal_reference>Vasques, X., Cif, L. Synthetic Data Generation for Classifying Electrophysiological and Morpho-Electrophysiological Neurons from Mouse Visual Cortex. Neuroinform 24, 2 (2026)</arxiv:journal_reference>
      <dc:creator>Xavier Vasques, Laura Cif</dc:creator>
    </item>
    <item>
      <title>A Disproof of Large Language Model Consciousness: The Necessity of Continual Learning for Consciousness</title>
      <link>https://arxiv.org/abs/2512.12802</link>
      <description>arXiv:2512.12802v2 Announce Type: replace 
Abstract: Scientific theories of consciousness should be falsifiable and non-trivial. Recent research has given us formal tools to analyze these requirements of falsifiability and non-triviality for theories of consciousness. Surprisingly, many contemporary theories of consciousness fail to pass this bar, including theories based on causal structure but also (as I demonstrate) theories based on function. Herein I show these requirements of falsifiability and non-triviality especially constrain the potential consciousness of contemporary Large Language Models (LLMs) because of their proximity to systems that are equivalent to LLMs in terms of input/output function; yet, for these functionally equivalent systems, there cannot be any falsifiable and non-trivial theory of consciousness that judges them conscious. This forms the basis of a disproof of contemporary LLM consciousness. I then show a positive result, which is that theories of consciousness based on (or requiring) continual learning do satisfy the stringent formal constraints for a theory of consciousness in humans. Intriguingly, this work supports a hypothesis: If continual learning is linked to consciousness in humans, the current limitations of LLMs (which do not continually learn) are intimately tied to their lack of consciousness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.12802v2</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erik Hoel</dc:creator>
    </item>
    <item>
      <title>How much neuroscience does a neuroscientist need to know?</title>
      <link>https://arxiv.org/abs/2601.02063</link>
      <description>arXiv:2601.02063v2 Announce Type: replace 
Abstract: How much of the brain's learned algorithms depend on the fact it is a brain? We argue: a lot, but surprisingly few details matter. We point to simple biological details -- e.g. nonnegative firing and energetic/space budgets in connectionist architectures -- which, when mixed with the requirements of solving a task, produce models that predict brain responses down to single-neuron tuning. We understand this as details constraining the set of plausible algorithms, and their implementations, such that only `brain-like' algorithms are learned. In particular, each biological detail breaks a symmetry in connectionist models (scale, rotation, permutation) leading to interpretable single-neuron responses that are meaningfully characteristic of particular algorithms. This view helps us not only understand the brain's choice of algorithm but also infer algorithm from measured neural responses. Further, this perspective aligns computational neuroscience with mechanistic interpretability in AI, suggesting a more unified approach to studying the mechanisms of intelligence, both natural and artificial.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.02063v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>James C. R. Whittington, William Dorrell</dc:creator>
    </item>
    <item>
      <title>EEG-to-fMRI synthesis of task-evoked and spontaneous brain activity: addressing issues of statistical significance and generalizability</title>
      <link>https://arxiv.org/abs/2504.10752</link>
      <description>arXiv:2504.10752v2 Announce Type: replace-cross 
Abstract: A growing interest has developed in the problem of training models of EEG features to predict brain activity measured using fMRI, i.e. the problem of EEG-to-fMRI synthesis. Despite some reported success, the statistical significance and generalizability of EEG-to-fMRI predictions remains to be fully demonstrated. Here, we investigate the predictive power of EEG for both task-evoked and spontaneous activity of the somatomotor network measured by fMRI, based on data collected from healthy subjects in two different sessions. We trained subject-specific distributed-lag linear models of time-varying, multi-channel EEG spectral power using Sparse Group LASSO regularization, and we showed that learned models outperformed conventional EEG somatomotor rhythm predictors as well as massive univariate correlation models. Furthermore, we showed that learned models were statistically significantly better than appropriate null models in most subjects and conditions, although less frequently for spontaneous compared to task-evoked activity. Critically, predictions improved significantly when training and testing on data acquired in the same session relative to across sessions, highlighting the importance of temporally separating the collection of train and test data to avoid data leakage and optimistic bias in model generalization. In sum, while we demonstrate that EEG models can provide fMRI predictions with statistical significance, we also show that predictive power is impaired for spontaneous fluctuations in brain activity and for models trained on data acquired in a different session. Our findings highlight the need to explicitly consider these often overlooked issues in the growing literature of EEG-to-fMRI synthesis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10752v2</guid>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Neil Mehta, Ines Goncalves, Alberto Montagna, Mathis Fleury, Gustavo Caetano, Ines Esteves, Athanasios Vourvopoulos, Pulkit Grover, Patricia Figueiredo</dc:creator>
    </item>
    <item>
      <title>Surface Waves and Axoplasmic Pressure Waves in Action Potential Propagation: Fundamentally Different Physics or Two Sides of the Same Coin?</title>
      <link>https://arxiv.org/abs/2505.24580</link>
      <description>arXiv:2505.24580v3 Announce Type: replace-cross 
Abstract: In this commentary, we argue that El Hady and Machta's "surface wave" model for mechanical waves accompanying action potential (AP) propagation describes the same underlying process as the "axoplasmic pressure wave" model introduced earlier by Rvachev. Both models describe mechanical modes that store potential energy in the elastic components of the axon (axonal membrane, cytoskeleton, bulk axoplasmic deformation), with kinetic energy carried by the axoplasmic fluid and axoplasmic viscosity playing a significant role. The "surface wave" model quantitatively considers driving by the traveling electrical depolarization wave of the AP, whereas the "axoplasmic pressure wave" model qualitatively considers driving not only by the AP's electrical depolarization but also by other mechanisms, such as cytoskeletal actomyosin contractility. In addition, the "axoplasmic pressure wave" model considers mechanisms for synchronizing the depolarization wave and the pressure wave. Although derived using different approaches, the two models yield identical dependencies for the mechanical modes in key limits. The confusion in the literature, which treats these models as describing distinct processes, needs to be resolved to improve comprehensive understanding of the AP phenomenon and to guide future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.24580v3</guid>
      <category>physics.bio-ph</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1142/S1793048025500055</arxiv:DOI>
      <arxiv:journal_reference>Biophys. Rev. Lett. 20, 283-289 (2025)</arxiv:journal_reference>
      <dc:creator>Marat M. Rvachev, Benjamin Drukarch</dc:creator>
    </item>
    <item>
      <title>HuiduRep: A Robust Self-Supervised Framework for Learning Neural Representations from Extracellular Recordings</title>
      <link>https://arxiv.org/abs/2507.17224</link>
      <description>arXiv:2507.17224v3 Announce Type: replace-cross 
Abstract: Extracellular recordings are transient voltage fluctuations in the vicinity of neurons, serving as a fundamental modality in neuroscience for decoding brain activity at single-neuron resolution. Spike sorting, the process of attributing each detected spike to its corresponding neuron, is a pivotal step in brain sensing pipelines. However, it remains challenging under low signal-to-noise ratio (SNR), electrode drift and cross-session variability. In this paper, we propose HuiduRep, a robust self-supervised representation learning framework that extracts discriminative and generalizable features from extracellular recordings. By integrating contrastive learning with a denoising autoencoder, HuiduRep learns latent representations that are robust to noise and drift. With HuiduRep, we develop a spike sorting pipeline that clusters spike representations without ground truth labels. Experiments on hybrid and real-world datasets demonstrate that HuiduRep achieves strong robustness. Furthermore, the pipeline outperforms state-of-the-art tools such as KiloSort4 and MountainSort5. These findings demonstrate the potential of self-supervised spike representation learning as a foundational tool for robust and generalizable processing of extracellular recordings. Code is available at: https://github.com/IgarashiAkatuki/HuiduRep</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.17224v3</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Feng Cao, Zishuo Feng, Jicong Zhang, Wei Shi</dc:creator>
    </item>
  </channel>
</rss>
