<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.QM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.QM</link>
    <description>q-bio.QM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.QM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 11 Nov 2025 03:48:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 10 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>PySlyde: A Lightweight, Open-Source Toolkit for Pathology Preprocessing</title>
      <link>https://arxiv.org/abs/2511.05183</link>
      <description>arXiv:2511.05183v1 Announce Type: new 
Abstract: The integration of artificial intelligence (AI) into pathology is advancing precision medicine by improving diagnosis, treatment planning, and patient outcomes. Digitised whole-slide images (WSIs) capture rich spatial and morphological information vital for understanding disease biology, yet their gigapixel scale and variability pose major challenges for standardisation and analysis. Robust preprocessing, covering tissue detection, tessellation, stain normalisation, and annotation parsing is critical but often limited by fragmented and inconsistent workflows. We present PySlyde, a lightweight, open-source Python toolkit built on OpenSlide to simplify and standardise WSI preprocessing. PySlyde provides an intuitive API for slide loading, annotation management, tissue detection, tiling, and feature extraction, compatible with modern pathology foundation models. By unifying these processes, it streamlines WSI preprocessing, enhances reproducibility, and accelerates the generation of AI-ready datasets, enabling researchers to focus on model development and downstream analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.05183v1</guid>
      <category>q-bio.QM</category>
      <category>cs.CV</category>
      <category>eess.IV</category>
      <pubDate>Mon, 10 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gregory Verghese, Anthony Baptista, Chima Eke, Holly Rafique, Mengyuan Li, Fathima Mohamed, Ananya Bhalla, Lucy Ryan, Michael Pitcher, Enrico Parisini, Concetta Piazzese, Liz Ing-Simmons, Anita Grigoriadis</dc:creator>
    </item>
    <item>
      <title>Persistent reachability homology in machine learning applications</title>
      <link>https://arxiv.org/abs/2511.04825</link>
      <description>arXiv:2511.04825v1 Announce Type: cross 
Abstract: We explore the recently introduced persistent reachability homology (PRH) of digraph data, i.e. data in the form of directed graphs. In particular, we study the effectiveness of PRH in network classification task in a key neuroscience problem: epilepsy detection. PRH is a variation of the persistent homology of digraphs, more traditionally based on the directed flag complex (DPH). A main advantage of PRH is that it considers the condensations of the digraphs appearing in the persistent filtration and thus is computed from smaller digraphs. We compare the effectiveness of PRH to that of DPH and we show that PRH outperforms DPH in the classification task. We use the Betti curves and their integrals as topological features and implement our pipeline on support vector machine.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.04825v1</guid>
      <category>cs.LG</category>
      <category>math.AT</category>
      <category>q-bio.QM</category>
      <pubDate>Mon, 10 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luigi Caputi, Nicholas Meadows, Henri Riihim\"aki</dc:creator>
    </item>
    <item>
      <title>SigmaDock: Untwisting Molecular Docking With Fragment-Based SE(3) Diffusion</title>
      <link>https://arxiv.org/abs/2511.04854</link>
      <description>arXiv:2511.04854v1 Announce Type: cross 
Abstract: Determining the binding pose of a ligand to a protein, known as molecular docking, is a fundamental task in drug discovery. Generative approaches promise faster, improved, and more diverse pose sampling than physics-based methods, but are often hindered by chemically implausible outputs, poor generalisability, and high computational cost. To address these challenges, we introduce a novel fragmentation scheme, leveraging inductive biases from structural chemistry, to decompose ligands into rigid-body fragments. Building on this decomposition, we present SigmaDock, an SE(3) Riemannian diffusion model that generates poses by learning to reassemble these rigid bodies within the binding pocket. By operating at the level of fragments in SE(3), SigmaDock exploits well-established geometric priors while avoiding overly complex diffusion processes and unstable training dynamics. Experimentally, we show SigmaDock achieves state-of-the-art performance, reaching Top-1 success rates (RMSD&lt;2 &amp; PB-valid) above 79.9% on the PoseBusters set, compared to 12.7-30.8% reported by recent deep learning approaches, whilst demonstrating consistent generalisation to unseen proteins. SigmaDock is the first deep learning approach to surpass classical physics-based docking under the PB train-test split, marking a significant leap forward in the reliability and feasibility of deep learning for molecular modelling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.04854v1</guid>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Mon, 10 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alvaro Prat, Leo Zhang, Charlotte M. Deane, Yee Whye Teh, Garrett M. Morris</dc:creator>
    </item>
    <item>
      <title>BiPETE: A Bi-Positional Embedding Transformer Encoder for Risk Assessment of Alcohol and Substance Use Disorder with Electronic Health Records</title>
      <link>https://arxiv.org/abs/2511.04998</link>
      <description>arXiv:2511.04998v1 Announce Type: cross 
Abstract: Transformer-based deep learning models have shown promise for disease risk prediction using electronic health records(EHRs), but modeling temporal dependencies remains a key challenge due to irregular visit intervals and lack of uniform structure. We propose a Bi-Positional Embedding Transformer Encoder or BiPETE for single-disease prediction, which integrates rotary positional embeddings to encode relative visit timing and sinusoidal embeddings to preserve visit order. Without relying on large-scale pretraining, BiPETE is trained on EHR data from two mental health cohorts-depressive disorder and post-traumatic stress disorder (PTSD)-to predict the risk of alcohol and substance use disorders (ASUD). BiPETE outperforms baseline models, improving the area under the precision-recall curve (AUPRC) by 34% and 50% in the depression and PTSD cohorts, respectively. An ablation study further confirms the effectiveness of the dual positional encoding strategy. We apply the Integrated Gradients method to interpret model predictions, identifying key clinical features associated with ASUD risk and protection, such as abnormal inflammatory, hematologic, and metabolic markers, as well as specific medications and comorbidities. Overall, these key clinical features identified by the attribution methods contribute to a deeper understanding of the risk assessment process and offer valuable clues for mitigating potential risks. In summary, our study presents a practical and interpretable framework for disease risk prediction using EHR data, which can achieve strong performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.04998v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>q-bio.QM</category>
      <pubDate>Mon, 10 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel S. Lee, Mayra S. Haedo-Cruz, Chen Jiang, Oshin Miranda, LiRong Wang</dc:creator>
    </item>
    <item>
      <title>Detecting active L\'evy particles using differential dynamic microscopy</title>
      <link>https://arxiv.org/abs/2511.00775</link>
      <description>arXiv:2511.00775v2 Announce Type: replace-cross 
Abstract: Detecting L\'evy flights of cells has been a challenging problem in experiments. The challenge lies in accessing data in spatiotemporal scales across orders of magnitude, which is necessary for reliably extracting a power-law scaling. Differential dynamic microscopy has been shown to be a powerful method that allows one to acquire statistics of cell motion across scales, which is a potentially versatile method for detecting L\'evy walks in biological systems. In this article, we extend the differential dynamic microscopy method to self-propelled L\'evy particles, whose run-time distribution has a algebraic tail. We validate our protocol using synthetic imaging data and show that a reliable detection of active L\'evy particles requires accessing length scales of one order of magnitude larger than its persistence length. Applying the protocol to experimental data of E. coli and E. gracilis, we find that E. coli does not exhibit a signature of L\'evy walks, while E. gracilis is better described as active L\'evy particles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00775v2</guid>
      <category>cond-mat.soft</category>
      <category>q-bio.QM</category>
      <pubDate>Mon, 10 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mingyang Li, Yu'an Li, H. P. Zhang, Yongfeng Zhao</dc:creator>
    </item>
  </channel>
</rss>
