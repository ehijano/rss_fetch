<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>astro-ph.IM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/astro-ph.IM</link>
    <description>astro-ph.IM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/astro-ph.IM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 25 Feb 2025 05:03:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Rotating black holes: The most fantastic source of energy in the universe</title>
      <link>https://arxiv.org/abs/2502.15784</link>
      <description>arXiv:2502.15784v1 Announce Type: new 
Abstract: Rotating black holes are the most powerful source of energy in the known universe, and are the cause of some of the most spectacular and extreme astronomical phenomena. The goal of this article is to analyze in simple terms the physics of energy extraction in rotating black holes. Specifically, the source of said energy, the efficiency of the energy extraction process, and some specific mechanisms that allow said extraction are analyzed. The article is intended primarily for undergraduate students of physics, astronomy and related fields.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.15784v1</guid>
      <category>astro-ph.IM</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Revista Mexicana de Fisica E 2025</arxiv:journal_reference>
      <dc:creator>Jorge Pinochet</dc:creator>
    </item>
    <item>
      <title>Imaging and Spectral Performance of a Wide-gap CdTe Double-Sided Strip Detector</title>
      <link>https://arxiv.org/abs/2502.15899</link>
      <description>arXiv:2502.15899v1 Announce Type: new 
Abstract: The fourth flight of the Focusing Optics X-ray Solar Imager sounding rocket experiment (FOXSI-4) aimed to achieve the first imaging spectroscopic observations of mid-to-large class ( &gt;= GOES C5 class) solar flares, in contrast to the previous three flights that targeted relatively quiet regions of the Sun. To meet the emerging requirements for hard X-ray focal plane detectors for providing simultaneous diagnostics of spectrally (&lt;1 keV FWHM) and spatially (&lt;50 um) separated coronal and chromospheric emissions from solar flares, we developed a new strip-configuration detector called the wide-gap CdTe semiconductor double-sided strip detector (CdTe-DSD). The wide-gap CdTe-DSD employs a unique design principle to enhance position resolution. This enhancement is realized by expanding the gaps between electrodes to induce charge-sharing across adjacent strip electrodes and using this sharing energy information for position reconstruction to a level finer than the strip-pitch. However, the detector response becomes complex and requires consideration of various factors, such as the charge loss due to wider gaps and the dependence on the depth of photon interaction. Thus, we developed an energy reconstruction method that fully leverages the energy information between adjacent strips and from both the cathode and anode sides, achieving an energy resolution of 0.75 keV (FWHM) at 14 keV. Furthermore, we conducted an X-ray scanning experiment using a synchrotron beam at Spring-8 to evaluate the detector response with a fine scale of 10 um. Based on these results, we established a sub-strip position reconstruction method, demonstrating that X-rays interacting at the center of the gap can be determined with an accuracy of 20 um, and even those at the strip center can be determined with an accuracy of 50 um.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.15899v1</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.SR</category>
      <category>hep-ex</category>
      <category>physics.ins-det</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shunsaku Nagasawa, Takahiro Minami, Shin Watanabe, Tadayuki Takahashi</dc:creator>
    </item>
    <item>
      <title>Infrared spectroscopy of astrophysical ice analogs at oblique angles</title>
      <link>https://arxiv.org/abs/2502.16720</link>
      <description>arXiv:2502.16720v1 Announce Type: new 
Abstract: In astrochemical exploration, infrared (IR) spectroscopy is vital for understanding the composition and structure of ice in various space environments. This article explores the impact of incident angles on IR spectroscopy, focusing on molecular components present in interstellar and circumstellar ice mantles such as CO, CO$_2$, H$_2$O, CH$_3$OH, NH$_3$, CH$_4$, H$_2$S. The experiment involves changing the angle at which the infrared beam hits the surface used for ice deposition. It is important to measure the density of the ice layer accurately, especially for experiments that involve using different angles in infrared spectroscopy. Furthermore, the experimental methodology allowed us to derive the {\it effective} refraction index values in the infrared range for each ice component. Existing corrections typically consider geometric configurations but overlook the refractive index of the ice ($n$), a factor dependent on ice composition. The study reveals that the incident angle and the refractive index, determine the pathlength of the IR beam across the ice sample. This insight challenges conventional corrections, impacting the integrated absorption values of the IR bands and column densities. In addition, for certain ice components, variations in the incidence angle affect the longitudinal (LO) and transverse (TO) optical modes of the ice, leading to observable changes in the IR band profiles that provide information on the amorphous or crystalline structure of the ice. The practical implications of this work apply to experimental setups where normal IR measurements are unfeasible. Researchers using, for example, the standard 45$^{\circ}$ angle for IR spectroscopy, will benefit from a more accurate estimation of ice column density.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16720v1</guid>
      <category>astro-ph.IM</category>
      <category>physics.optics</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Crist\'obal Gonz\'alez D\'iaz, Hector Carrascosa, Guillermo M. Mu\~noz Caro</dc:creator>
    </item>
    <item>
      <title>Astronomical image denoising by self-supervised deep learning and restoration processes</title>
      <link>https://arxiv.org/abs/2502.16807</link>
      <description>arXiv:2502.16807v1 Announce Type: new 
Abstract: Image denoising based on deep learning has witnessed significant advancements in recent years. However, existing deep learning methods lack quantitative control of the deviation or error on denoised images. The neural networks Self2Self is designed for denoising single-image, training on it and denoising itself, during which training is costly. In this work we explore training Self2Self on an astronomical image and denoising other images of the same kind, which is suitable for quickly denoising massive images in astronomy. To address the deviation issue, the abnormal pixels whose deviation exceeds a predefined threshold are restored to their initial values. The noise reduction includes training, denoising, restoring and named TDR-method, by which the noise level of the solar magnetograms is improved from about 8 G to 2 G. Furthermore, the TDR-method is applied to galaxy images from the Hubble Space Telescope and makes weak galaxy structures become much clearer. This capability of enhancing weak signals makes the TDR-method applicable in various disciplines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16807v1</guid>
      <category>astro-ph.IM</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1038/s41550-025-02484-z</arxiv:DOI>
      <dc:creator>Tie Liu, Yuhui Quan, Yingna Su, Yang Guo, Shu Liu, Haisheng Ji, Qi Hao, Yulong Gao, Yuxia Liu, Yikang Wang, Wenqing Sun, Mingde Ding</dc:creator>
    </item>
    <item>
      <title>TESSELLATE: Piecing Together the Variable Sky With TESS</title>
      <link>https://arxiv.org/abs/2502.16905</link>
      <description>arXiv:2502.16905v1 Announce Type: new 
Abstract: We present TESSELLATE, a dedicated pipeline for performing an untargeted search documenting all variable phenomena captured by the TESS space telescope. Building on the TESSreduce difference imaging pipeline, TESSELLATE extracts calibrated and reduced photometric data for every full frame image in the TESS archive. Using this data, we systematically identify transient, variable and non-sidereal signals across timescales ranging from minutes to weeks. The high cadence and wide field of view of TESS enables us to conduct a comprehensive search of the entire sky to a depth of ~17 $m_i$. Based on the volumetric rates for known fast transients, we expect there to be numerous Fast Blue Optical Transients and Gamma Ray Burst afterglows present in the existing TESS dataset. Beyond transients, TESSELLATE can also identify new variable stars and exoplanet candidates, and recover known asteroids. We classify events using machine learning techniques and the work of citizen scientists via the Zooniverse Cosmic Cataclysms project. Finally, we introduce the TESSELLATE Sky Survey: a complete, open catalog of the variable sky observed by TESS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16905v1</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.EP</category>
      <category>astro-ph.HE</category>
      <category>astro-ph.SR</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hugh Roxburgh, Ryan Ridden-Harper, Andrew Moore, Clarinda Montilla, Brayden Leicester, Zachary G. Lane, James Freeburn, Armin Rest, Michele T. Bannister, Andrew R. Ridden-Harper, Lancia Hubley, Qinan Wang, Rebekah Hounsell, Jeff Cooke, Dave A. Coulter, Michael M. Fausnaugh</dc:creator>
    </item>
    <item>
      <title>Joint multi-band deconvolution for $Euclid$ and $Vera$ $C.$ $Rubin$ images</title>
      <link>https://arxiv.org/abs/2502.17177</link>
      <description>arXiv:2502.17177v1 Announce Type: new 
Abstract: With the advent of surveys like $Euclid$ and $Vera$ $C.$ $Rubin$, astrophysicists will have access to both deep, high-resolution images, and multi-band images. However, these two conditions are not simultaneously available in any single dataset. It is therefore vital to devise image deconvolution algorithms that exploit the best of the two worlds and that can jointly analyze datasets spanning a range of resolutions and wavelengths. In this work, we introduce a novel multi-band deconvolution technique aimed at improving the resolution of ground-based astronomical images by leveraging higher-resolution space-based observations. The method capitalizes on the fortunate fact that the $Vera$ $C.$ $Rubin$ $r$-, $i$-, and $z$-bands lie within the $Euclid$ $VIS$ band. The algorithm jointly deconvolves all the data to turn the $r$-, $i$-, and $z$-band $Vera$ $C.$ $Rubin$ images to the resolution of $Euclid$ by enabling us to leverage the correlations between the different bands. We also investigate the performance of deep learning-based denoising with DRUNet to further improve the results. We illustrate the effectiveness of our method in terms of resolution and morphology recovery, flux preservation, and generalization to different noise levels. This approach extends beyond the specific $Euclid$-$Rubin$ combination, offering a versatile solution to improve the resolution of ground-based images in multiple photometric bands by jointly using any space-based images with overlapping filters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.17177v1</guid>
      <category>astro-ph.IM</category>
      <category>cs.CV</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Utsav Akhaury, Pascale Jablonka, Fr\'ed\'eric Courbin, Jean-Luc Starck</dc:creator>
    </item>
    <item>
      <title>A benchmark analysis of saliency-based explainable deep learning methods for the morphological classification of radio galaxies</title>
      <link>https://arxiv.org/abs/2502.17207</link>
      <description>arXiv:2502.17207v1 Announce Type: new 
Abstract: This work proposes a saliency-based attribution framework to evaluate and compare 10 state-of-the-art explainability methods for deep learning models in astronomy, focusing on the classification of radio galaxy images. While previous work has primarily emphasized classification accuracy, we prioritize model interpretability. Qualitative assessments reveal that Score-CAM, Grad-CAM, and Grad-CAM++ consistently produce meaningful attribution maps, highlighting the brightest regions of FRI and FRII galaxies in alignment with known astrophysical features. In contrast, other methods often emphasize irrelevant or noisy areas, reducing their effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.17207v1</guid>
      <category>astro-ph.IM</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>M. T. Atemkeng, C. Chuma, S. Zaza, C. D. Nunhokee, O. M. Smirnov</dc:creator>
    </item>
    <item>
      <title>Modeling coupled constellation dynamics for TianQin under self-gravity</title>
      <link>https://arxiv.org/abs/2502.14552</link>
      <description>arXiv:2502.14552v1 Announce Type: cross 
Abstract: TianQin is a dedicated geocentric mission for space-based gravitational wave (GW) detection. Among its core technologies, the drag-free and pointing control subsystem (DFPCS) - consisting of suspension, drag-free and pointing controls - keeps the two test masses (TMs) centered and aligned within their housings while maintaining drag-free conditions and precise telescope pointing along the laser-arm directions. This results in orbit-attitude coupled dynamics for the constellation. The coupling is made more prominent due to satellite self-gravity, which requires compensation from DFPCS and generally makes the satellites deviate from pure free-fall orbits. Previous studies assumed that the orbit and attitude dynamics could be decoupled in numerical simulation, neglecting the back-action from the closed-loop control to orbit propagation. To address this, we develop a comprehensive model that can propagate the full 9-body (6 TMs + 3 satellites, orbits and attitudes) dynamics inter-dependently under the inter-satellite pointing and drag-free conditions. This paper is threefold. First, we reassess the applicability of the two TMs and telescope pointing scheme to TianQin using the new model, and confirm the previous conclusion. Second, to meet the constellation stability requirements, it is found that the DC common self-gravity in the flight direction should be minimized, or kept close for the three satellites. Finally, we simulate the long-range light path between two TMs/satellites with a precision of sub-pm/Hz$^{1/2}$, and the results support the decoupling of the closed-loop dynamics and high-precision orbit for computational efficiency. The method is instrumental to other future missions where the orbit-attitude coupling needs careful consideration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14552v1</guid>
      <category>gr-qc</category>
      <category>astro-ph.IM</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuzhou Fang, Xuefeng Zhang, Hongyin Li</dc:creator>
    </item>
    <item>
      <title>TDCOSMO XIX: Measuring stellar velocity dispersion with sub-percent accuracy for cosmography</title>
      <link>https://arxiv.org/abs/2502.16034</link>
      <description>arXiv:2502.16034v1 Announce Type: cross 
Abstract: Stellar velocity dispersion ($\sigma$) of massive elliptical galaxies is a key ingredient to breaking the mass-sheet degeneracy and obtaining precise and accurate cosmography from gravitational time delays. The relative uncertainty on the Hubble constant H$_0$ is double the relative error on $\sigma$. Therefore, time-delay cosmography imposes much more demanding requirements on the precision and accuracy of $\sigma$ than galaxy studies. While precision can be achieved with an adequate signal-to-noise ratio (SNR), accuracy depends critically on factors such as elemental abundances and temperature of stellar templates, flux calibration, and wavelength ranges. We carry out a detailed study of the problem using multiple sets of galaxy spectra of massive elliptical galaxies with SNR$\sim$30-160 \AA$^{-1}$, and state-of-the-art empirical and semi-empirical stellar libraries and stellar population synthesis templates. We show that the choice of stellar library is generally the dominant source of residual systematic error. We propose a general recipe to mitigate and account for residual uncertainties. We show that sub-percent accuracy can be achieved on individual spectra with our data quality. Covariance between velocity dispersions measured for a sample of spectra can also be reduced to sub-percent levels. We recommend this recipe for all applications that require high precision and accurate stellar kinematics, and make all software publicly available to facilitate its implementation. This recipe will be used in future TDCOSMO collaboration papers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16034v1</guid>
      <category>astro-ph.GA</category>
      <category>astro-ph.CO</category>
      <category>astro-ph.IM</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shawn Knabel, Pritom Mozumdar, Anowar J. Shajib, Tommaso Treu, Michele Cappellari, Chiara Spiniello, Simon Birrer</dc:creator>
    </item>
    <item>
      <title>Asteroid shape inversion with light curves using deep learning</title>
      <link>https://arxiv.org/abs/2502.16455</link>
      <description>arXiv:2502.16455v1 Announce Type: cross 
Abstract: Asteroid shape inversion using photometric data has been a key area of study in planetary science and astronomical research.However, the current methods for asteroid shape inversion require extensive iterative calculations, making the process time-consuming and prone to becoming stuck in local optima. We directly established a mapping between photometric data and shape distribution through deep neural networks. In addition, we used 3D point clouds to represent asteroid shapes and utilized the deviation between the light curves of non-convex asteroids and their convex hulls to predict the concave areas of non-convex asteroids. We compared the results of different shape models using the Chamfer distance between traditional methods and ours and found that our method performs better, especially when handling special shapes. For the detection of concave areas on the convex hull, the intersection over union (IoU) of our predictions reached 0.89. We further validated this method using observational data from the Lowell Observatory to predict the convex shapes of the asteroids 3337 Milo and 1289 Kuta, and conducted light curve fitting experiments. The experimental results demonstrated the robustness and adaptability of the method</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16455v1</guid>
      <category>astro-ph.EP</category>
      <category>astro-ph.IM</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>YiJun Tang, ChenChen Ying, ChengZhe Xia, XiaoMing Zhang, XiaoJun Jiang</dc:creator>
    </item>
    <item>
      <title>Transformer-based Approach for Accurate Asteroid Spectra taxonomy and albedo estimation</title>
      <link>https://arxiv.org/abs/2502.16458</link>
      <description>arXiv:2502.16458v1 Announce Type: cross 
Abstract: China plans to launch a probe (Tianwen-2) around 2025, mainly for exploring the near-Earth asteroid 2016 HO3 . The mission involves close-range exploration, landing, and mining operations that require three-dimensional modeling of the asteroid, which requires prior knowledge of its material composition and uniformity. This information is crucial in progressive or ground exploration processes. Our research focuses on high-precision intelligent inversion of complex physical properties of asteroids based on spectral data, providing support for further analysis of aster oid materials, density, and structure. We have developed a platform for asteroid spectral classification, albedo estimation, and composition analysis, which includes three types of neural networks based on Transformer attention mechanism: One for spectral classification, achieving a four-class classification accuracy of 97.28% and an eleven-class classification accuracy of 95.69%; second one for albedo estimation, with an average absolute error of 0.0308 in S-type asteroid albedo estimation, and the third one for composition analysis, with a predicted spectral angular distance of only 0.0340 and a root mean square error of 0.1759 for the abundance of end members. These results indicate that our network can provide high-precision asteroid spectral classification, albedo estimation, and composition analysis results. In addition, we utilized the platform to analyze and provide results for six asteroids.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16458v1</guid>
      <category>astro-ph.EP</category>
      <category>astro-ph.IM</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yijun Tang, Jiang Yunxiao, Yuxiang Feng, Xiaoming Zhang, Xiaojun Jiang</dc:creator>
    </item>
    <item>
      <title>Unbiased estimates of the shapes of haloes using the positions of satellite galaxies</title>
      <link>https://arxiv.org/abs/2502.17135</link>
      <description>arXiv:2502.17135v1 Announce Type: cross 
Abstract: The shapes of dark matter haloes are sensitive to both cosmology and baryon physics, but are difficult to measure observationally. A promising way to constrain them is to use the positions of satellite galaxies as tracers of the underlying dark matter, but there are typically too few galaxies per halo for reliable shape estimates, resulting in biased shapes. We present a method to model sampling noise to correct for the shape bias. We compare our predicted median shape bias with that obtained from the FLAMINGO suite of simulations and find reasonable agreement. We check that our results are robust to resolution effects and baryonic feedback. We also explore the validity of our bias correction at various redshifts and we discuss how our method might be applied to observations in the future. We show that median projected halo axis ratios are on average biased low by 0.31 when they are traced by only 5 satellites. Using the satellite galaxies, the projected host halo axis ratio can be corrected with a residual bias of ~ 0.1, by accounting for sampling bias. Hence, about two-thirds of the projected axis ratio bias can be explained by sampling noise. This enables the statistical measurement of halo shapes at lower masses than previously possible. Our method will also allow improved estimates of halo shapes in cosmological simulations using fewer particles than currently required.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.17135v1</guid>
      <category>astro-ph.CO</category>
      <category>astro-ph.IM</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>A. Herle, N. E. Chisari, H. Hoekstra, R. J. McGibbon, J. Schaye, M. Schaller, R. Kugel</dc:creator>
    </item>
    <item>
      <title>Accounting for the Known Unkown: A Parametric Framework to Incorporate Systematic Waveform Errors in Gravitational-Wave Parameter Estimation</title>
      <link>https://arxiv.org/abs/2502.17400</link>
      <description>arXiv:2502.17400v1 Announce Type: cross 
Abstract: The Parameter Estimation (PE) for Gravitational Waves (GW) merger events relies on a waveform model calibrated using numerical simulations. Within the Bayesian framework, this waveform model represents the GW signal produced during the merger and is crucial for estimating the likelihood function. However, these waveform models may possess systematic errors that can differ across the parameter space. Addressing these errors in the current data analysis pipeline is an active area of research. This work presents a framework for accounting for uncertainties in waveform modeling. We introduce two parametrizations, relative and absolute errors in the phase of the waveform, to modify the base waveform model, which can account for uncertainties. When the waveform errors are known, those error budgets can be used as a prior distribution in the Bayesian framework. We also show that conservative priors can be used to quantify uncertainties in waveform modeling without any knowledge of waveform error budgets. By conducting zero-noise injections and recoveries, we demonstrate through PE results that even 1-2% of errors in relative phase to the actual waveform model can introduce biases in the recovered parameters. These biases can be corrected when we account for waveform uncertainties within the PE framework. By injecting a series of precessing waveform models and using the nonspinning model for recovery, we show that our method can account for the missing physics by making the posterior samples broad enough to account for bias. We also present a Python package that is easily integrated with the publicly available GW analysis tool PyCBC and can be used to do PE with the parametrization presented in this paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.17400v1</guid>
      <category>gr-qc</category>
      <category>astro-ph.HE</category>
      <category>astro-ph.IM</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sumit Kumar, Max Melching, Frank Ohme</dc:creator>
    </item>
    <item>
      <title>Mind the gap: addressing data gaps and assessing noise mismodeling in LISA</title>
      <link>https://arxiv.org/abs/2502.17426</link>
      <description>arXiv:2502.17426v1 Announce Type: cross 
Abstract: Due to the sheer complexity of the Laser Interferometer Space Antenna (LISA) space mission, data gaps arising from instrumental irregularities and/or scheduled maintenance are unavoidable. Focusing on merger-dominated massive black hole binary signals, we test the appropriateness of the Whittle-likelihood on gapped data in a variety of cases. From first principles, we derive the likelihood valid for gapped data in both the time and frequency domains. Cheap-to-evaluate proxies to p-p plots are derived based on a Fisher-based formalism, and verified through Bayesian techniques. Our tools allow to predict the altered variance in the parameter estimates that arises from noise mismodeling, as well as the information loss represented by the broadening of the posteriors. The result of noise mismodeling with gaps is sensitive to the characteristics of the noise model, with strong low-frequency (red) noise and strong high-frequency (blue) noise giving statistically significant fluctuations in recovered parameters. We demonstrate that the introduction of a tapering window reduces statistical inconsistency errors, at the cost of less precise parameter estimates. We also show that the assumption of independence between inter-gap segments appears to be a fair approximation even if the data set is inherently coherent. However, if one instead assumes fictitious correlations in the data stream, when the data segments are actually independent, then the resultant parameter recoveries could be inconsistent with the true parameters. The theoretical and numerical practices that are presented in this work could readily be incorporated into global-fit pipelines operating on gapped data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.17426v1</guid>
      <category>gr-qc</category>
      <category>astro-ph.HE</category>
      <category>astro-ph.IM</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ollie Burke, Sylvain Marsat, Jonathan R. Gair, Michael L. Katz</dc:creator>
    </item>
    <item>
      <title>The Legacy of Henrietta Leavitt: A Re-analysis of the First Cepheid Period-Luminosity Relation</title>
      <link>https://arxiv.org/abs/2502.17438</link>
      <description>arXiv:2502.17438v1 Announce Type: cross 
Abstract: Henrietta Swan Leavitt's discovery of the relationship between the period and luminosity (hereafter the Leavitt Law) of 25 variable stars in the Small Magellanic Cloud, published in 1912, revolutionized cosmology. These variables, eventually identified as Cepheids, became the first known "standard candles" for measuring extragalactic distances and remain the gold standard for this task today. Leavitt measured light curves, periods, and minimum and maximum magnitudes from painstaking visual inspection of photographic plates. Her work paved the way for the first precise series of distance measurements that helped set the scale of the Universe, and later the discovery of its expansion by Edwin Hubble in 1929. Here, we re-analyze Leavitt's first Period-Luminosity relation using observations of the same set of stars but with modern data and methods of Cepheid analysis. Using only data from Leavitt's notebooks, we assess the quality of her light curves, measured periods, and the slope and scatter of her Period-Luminosity relations. We show that modern data and methods, for the same objects, reduce the scatter of the Period-Luminosity relation by a factor of two. We also find a bias brightward at the short period end, due to the non-linearity of the plates and environmental crowding. Overall, Leavitt's results are in excellent agreement with contemporary measurements, reinforcing the value of Cepheids in cosmology today, a testament to the enduring quality of her work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.17438v1</guid>
      <category>astro-ph.SR</category>
      <category>astro-ph.CO</category>
      <category>astro-ph.GA</category>
      <category>astro-ph.IM</category>
      <category>physics.hist-ph</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Louise Breuval, Caroline D. Huang, Adam G. Riess</dc:creator>
    </item>
    <item>
      <title>Deep Learning and LLM-based Methods Applied to Stellar Lightcurve Classification</title>
      <link>https://arxiv.org/abs/2404.10757</link>
      <description>arXiv:2404.10757v2 Announce Type: replace 
Abstract: Light curves serve as a valuable source of information on stellar formation and evolution. With the rapid advancement of machine learning techniques, it can be effectively processed to extract astronomical patterns and information. In this study, we present a comprehensive evaluation of deep-learning and large language model (LLM) based models for the automatic classification of variable star light curves, based on large datasets from the Kepler and K2 missions. Special emphasis is placed on Cepheids, RR Lyrae, and eclipsing binaries, examining the influence of observational cadence and phase distribution on classification precision. Employing AutoDL optimization, we achieve striking performance with the 1D-Convolution+BiLSTM architecture and the Swin Transformer, hitting accuracies of 94\% and 99\% correspondingly, with the latter demonstrating a notable 83\% accuracy in discerning the elusive Type II Cepheids-comprising merely 0.02\% of the total dataset.We unveil StarWhisper LightCurve (LC), an innovative Series comprising three LLM-based models: LLM, multimodal large language model (MLLM), and Large Audio Language Model (LALM). Each model is fine-tuned with strategic prompt engineering and customized training methods to explore the emergent abilities of these models for astronomical data. Remarkably, StarWhisper LC Series exhibit high accuracies around 90\%, significantly reducing the need for explicit feature engineering, thereby paving the way for streamlined parallel data processing and the progression of multifaceted multimodal models in astronomical applications. The study furnishes two detailed catalogs illustrating the impacts of phase and sampling intervals on deep learning classification accuracy, showing that a substantial decrease of up to 14\% in observation duration and 21\% in sampling points can be realized without compromising accuracy by more than 10\%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10757v2</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.SR</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yu-Yang Li, Yu Bai, Cunshi Wang, Mengwei Qu, Ziteng Lu, Roberto Soria, Jifeng Liu</dc:creator>
    </item>
    <item>
      <title>Hybrid radiation hydrodynamics scheme with adaptive gravity-tree-based pseudo-particles</title>
      <link>https://arxiv.org/abs/2410.15227</link>
      <description>arXiv:2410.15227v2 Announce Type: replace 
Abstract: HII regions powered by ionizing radiation from massive stars drive the dynamical evolution of the interstellar medium. Fast radiative transfer methods for incorporating photoionization effects are thus essential in astrophysical simulations. Previous work by Petkova et al. established a hybrid radiation hydrodynamics (RHD) scheme that couples Smoothed Particle Hydrodynamics (SPH) to grid-based Monte Carlo Radiative Transfer (MCRT) code. This particle-mesh scheme employs the Exact mapping method for transferring fluid properties between SPH particles and Voronoi grids on which the MCRT simulation is carried out. The mapping, however, can become computationally infeasible with large numbers of particles or grid cells. We present a novel optimization method that adaptively converts gravity tree nodes into pseudo-SPH particles. These pseudo-particles act in place of the SPH particles when being passed to the MCRT code, allowing fluid resolutions to be temporarily reduced in regions which are less dynamically affected by radiation. A smoothing length solver and a neighbour-finding scheme dedicated to tree nodes have been developed. We also describe the new heating and cooling routines implemented for improved thermodynamic treatment. We show that this tree-based RHD scheme produces results in strong agreement with benchmarks, and achieves a speed-up that scales with the reduction in the number of particle-cell pairs being mapped.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15227v2</guid>
      <category>astro-ph.IM</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Cheryl S. C. Lau, Maya A. Petkova, Ian A. Bonnell</dc:creator>
    </item>
    <item>
      <title>Readout Optimization of Multi-Amplifier Sensing Charge-Coupled Devices for Single-Quantum Measurement</title>
      <link>https://arxiv.org/abs/2502.10508</link>
      <description>arXiv:2502.10508v2 Announce Type: replace 
Abstract: The non-destructive readout capability of the Skipper Charge Coupled Device (CCD) has been demonstrated to reduce the noise limitation of conventional silicon devices to levels that allow single-photon or single-electron counting. The noise reduction is achieved by taking multiple measurements of the charge in each pixel. These multiple measurements come at the cost of extra readout time, which has been a limitation for the broader adoption of this technology in particle physics, quantum imaging, and astronomy applications. This work presents recent results of a novel sensor architecture that uses multiple non-destructive floating-gate amplifiers in series to achieve sub-electron readout noise in a thick, fully-depleted silicon detector to overcome the readout time overhead of the Skipper-CCD. This sensor is called the Multiple-Amplifier Sensing Charge-Coupled Device (MAS-CCD) can perform multiple independent charge measurements with each amplifier, and the measurements from multiple amplifiers can be combined to further reduce the readout noise. We will show results obtained for sensors with 8 and 16 amplifiers per readout stage in new readout operations modes to optimize its readout speed. The noise reduction capability of the new techniques will be demonstrated in terms of its ability to reduce the noise by combining the information from the different amplifiers, and to resolve signals in the order of a single photon per pixel. The first readout operation explored here avoids the extra readout time needed in the MAS-CCD to read a line of the sensor associated with the extra extent of the serial register. The second technique explore the capability of the MAS-CCD device to perform a region of interest readout increasing the number of multiple samples per amplifier in a targeted region of the active area of the device.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.10508v2</guid>
      <category>astro-ph.IM</category>
      <category>physics.ins-det</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1117/12.3019411</arxiv:DOI>
      <arxiv:journal_reference>Proceedings Volume 13103, X-Ray, Optical, and Infrared Detectors for Astronomy XI; 1310311 (2024). Event: SPIE Astronomical Telescopes + Instrumentation, 2024, Yokohama, Japan</arxiv:journal_reference>
      <dc:creator>Ana M. Botti, Brenda A. Cervantes-Vergara, Claudio R. Chavez, Fernando Chierchie, Alex Drlica-Wagner, Juan Estrada, Guillermo Fernandez Moroni, Stephen E. Holland, Blas J. Irigoyen Gimenez, Agustin J. Lapi, Edgar Marrufo Villalpando, Miguel Sofo Haro, Javier Tiffenberg, Sho Uemura, Kenneth Lin, Armin Karcher, Julien Guy, Peter E. Nugent</dc:creator>
    </item>
    <item>
      <title>Comparative Analysis of Black Hole Mass Estimation in Type-2 AGNs: Classical vs. Quantum Machine Learning and Deep Learning Approaches</title>
      <link>https://arxiv.org/abs/2502.15297</link>
      <description>arXiv:2502.15297v2 Announce Type: replace 
Abstract: In the case of Type-2 AGNs, estimating the mass of the black hole is challenging. Understanding how galaxies form and evolve requires considerable insight into the mass of black holes. This work compared different classical and quantum machine learning (QML) algorithms for black hole mass estimation, wherein the classical algorithms are Linear Regression, XGBoost Regression, Random Forest Regressor, Support Vector Regressor (SVR), Lasso Regression, Ridge Regression, Elastic Net Regression, Bayesian Regression, Decision Tree Regressor, Gradient Booster Regressor, Classical Neural Networks, Gated Recurrent Unit (GRU), LSTM, Deep Residual Networks (ResNets) and Transformer-Based Regression. On the other hand, quantum algorithms including Hybrid Quantum Neural Networks (QNN), Quantum Long Short-Term Memory (Q-LSTM), Sampler-QNN, Estimator-QNN, Variational Quantum Regressor (VQR), Quantum Linear Regression(Q-LR), QML with JAX optimization were also tested. The results revealed that classical algorithms gave better R^2, MAE, MSE, and RMSE results than the quantum models. Among the classical models, LSTM has the best result with an accuracy of 99.77%. Estimator-QNN has the highest accuracy for quantum algorithms with an MSE of 0.0124 and an accuracy of 99.75%. This study ascertains both the strengths and weaknesses of the classical and the quantum approaches. As far as our knowledge goes, this work could pave the way for the future application of quantum algorithms in astrophysical data analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.15297v2</guid>
      <category>astro-ph.IM</category>
      <category>cs.LG</category>
      <category>quant-ph</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sathwik Narkedimilli, Venkata Sriram Amballa, N V Saran Kumar, R Arun Kumar, R Praneeth Reddy, Satvik Raghav, Manish M, Aswath Babu H</dc:creator>
    </item>
    <item>
      <title>Potential impact of noise correlation in next-generation gravitational wave detectors</title>
      <link>https://arxiv.org/abs/2407.08728</link>
      <description>arXiv:2407.08728v2 Announce Type: replace-cross 
Abstract: Building upon the statistical formulation for parameter estimation (PE) in the presence of correlated noise proposed by Cireddu et al., we present the initial study to incorporate the effects of correlated noise into the analyses of various detector designs' performance. We consider a two-L-shaped-detector configuration in Europe and compare the expectation of PE of gravitational wave (GW) transients between noncollocated and hypothetical collocated configurations. In our study, we posit the existence of low-frequency correlated noise within the 5-10 Hz range for the collocated detector configuration, with a varying correlation. In this specific detector setup, our observations indicate an enhancement in the precision of intrinsic parameter measurements as the correlation increases. This trend suggests that noise correlation may beneficially influence the accuracy of PE. In particular, when the noise is highly correlated, the uncertainty on chirp mass decreases by up to $30\%$. The absence of an inter-European baseline does hinder the estimation of the extrinsic parameters. However, given a realistic global network with the additional detector in the US, the uncertainty of extrinsic parameters is significantly reduced. This reduction is further amplified as the noise correlation increases. When the noise correlation exceeds a certain level, the collocated configuration outperforms the noncollocated configuration. For instance, when the correlation is high, the collocated configuration decreases the $90\%$ credible area of sky location by up to $10\%$ compared to the noncollocated configuration. We conclude that the impact of noise correlation is not trivial and can potentially alter both the quantitative and qualitative outcomes in detector performance. We therefore recommend the inclusion of noise correlation for a comprehensive assessment of the design of third-generation GW detectors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.08728v2</guid>
      <category>gr-qc</category>
      <category>astro-ph.IM</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1103/PhysRevD.111.044046</arxiv:DOI>
      <arxiv:journal_reference>Phys. Rev. D 111, 044046 (2025)</arxiv:journal_reference>
      <dc:creator>Isaac C. F. Wong, Peter T. H. Pang, Milan Wils, Francesco Cireddu, Walter Del Pozzo, Tjonnie G. F. Li</dc:creator>
    </item>
    <item>
      <title>Accelerated parameter estimation of supermassive black hole binaries in LISA using a meshfree approximation</title>
      <link>https://arxiv.org/abs/2409.14288</link>
      <description>arXiv:2409.14288v2 Announce Type: replace-cross 
Abstract: The Laser Interferometer Space Antenna (LISA) will be capable of detecting gravitational waves (GWs) in the milli-Hertz band. Among various sources, LISA will detect the coalescence of supermassive black hole binaries (SMBHBs). Accurate and rapid inference of parameters for such sources will be important for potential electromagnetic follow-up efforts. Rapid Bayesian inference with LISA includes additional complexities as compared to current generation terrestrial detectors in terms of time and frequency dependent antenna response functions. In this work, we extend a recently developed, computationally efficient technique that uses meshfree interpolation methods to accelerate Bayesian reconstruction of compact binaries. Originally developed for second-generation terrestrial detectors, this technique is now adapted for LISA parameter estimation. Using the full inspiral, merger, and ringdown waveform (PhenomD) and assuming rigid adiabatic antenna response function, we show faithful inference of SMBHB parameters from GW signals embedded in stationary, Gaussian instrumental noise. We discuss the computational cost and performance of the meshfree approximation method in estimating the GW source parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.14288v2</guid>
      <category>gr-qc</category>
      <category>astro-ph.IM</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1103/PhysRevD.111.042009</arxiv:DOI>
      <arxiv:journal_reference>Physical Review D (Vol. 111, pages 042009, numpages 16), 2025</arxiv:journal_reference>
      <dc:creator>Abhishek Sharma, Anand S. Sengupta, Suvodip Mukherjee</dc:creator>
    </item>
    <item>
      <title>Analyzing black-hole ringdowns II: data conditioning</title>
      <link>https://arxiv.org/abs/2410.02704</link>
      <description>arXiv:2410.02704v2 Announce Type: replace-cross 
Abstract: Time series data from observations of black hole ringdown gravitational waves are often analyzed in the time domain by using damped sinusoid models with acyclic boundary conditions. Data conditioning operations, including downsampling, filtering, and the choice of data segment duration, reduce the computational cost of such analyses and can improve numerical stability. Here we analyze simulated damped sinsuoid signals to illustrate how data conditioning operations, if not carefully applied, can undesirably alter the analysis' posterior distributions. We discuss how currently implemented downsampling and filtering methods, if applied too aggressively, can introduce systematic errors and skew tests of general relativity. These issues arise because current downsampling and filtering methods do not operate identically on the data and model. Alternative downsampling and filtering methods which identically operate on the data and model may be achievable, but we argue that the current operations can still be implemented safely. We also show that our preferred anti-alias filtering technique, which has an instantaneous frequency-domain response at its roll-off frequency, preserves the structure of posterior distributions better than other commonly used filters with transient frequency-domain responses. Lastly, we highlight that exceptionally long data segments may need to be analyzed in cases where thin lines in the noise power spectral density overlap with central signal frequencies. Our findings may be broadly applicable to any analysis of truncated time domain data with acyclic boundary conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02704v2</guid>
      <category>gr-qc</category>
      <category>astro-ph.IM</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1103/PhysRevD.111.044070</arxiv:DOI>
      <arxiv:journal_reference>Phys. Rev. D 111, 044070 (2025)</arxiv:journal_reference>
      <dc:creator>Harrison Siegel, Maximiliano Isi, Will M. Farr</dc:creator>
    </item>
    <item>
      <title>RTFAST-Spectra: Emulation of X-ray reverberation mapping for active galactic nuclei</title>
      <link>https://arxiv.org/abs/2412.10131</link>
      <description>arXiv:2412.10131v2 Announce Type: replace-cross 
Abstract: Bayesian analysis has begun to be more widely adopted in X-ray spectroscopy, but it has largely been constrained to relatively simple physical models due to limitations in X-ray modelling software and computation time. As a result, Bayesian analysis of numerical models with high physics complexity have remained out of reach. This is a challenge, for example when modelling the X-ray emission of accreting black hole X-ray binaries, where the slow model computations severely limit explorations of parameter space and may bias the inference of astrophysical parameters. Here, we present RTFAST-Spectra: a neural network emulator that acts as a drop in replacement for the spectral portion of the black hole X-ray reverberation model RTDIST. This is the first emulator for the reltrans model suite and the first emulator for a state-of-the-art x-ray reflection model incorporating relativistic effects with 17 physically meaningful model parameters. We use Principal Component Analysis to create a light-weight neural network that is able to preserve correlations between complex atomic lines and simple continuum, enabling consistent modelling of key parameters of scientific interest. We achieve a $\mathcal{O}(10^2)$ times speed up over the original model in the most conservative conditions with $\mathcal{O}(1\%)$ precision over all 17 free parameters in the original numerical model, taking full posterior fits from months to hours. We employ Markov Chain Monte Carlo sampling to show how we can better explore the posteriors of model parameters in simulated data and discuss the complexities in interpreting the model when fitting real data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10131v2</guid>
      <category>astro-ph.HE</category>
      <category>astro-ph.IM</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Benjamin Ricketts, Daniela Huppenkothen, Matteo Lucchini, Adam Ingram, Guglielmo Mastroserio, Matthew Ho, Benjamin Wandelt</dc:creator>
    </item>
    <item>
      <title>A novel q-PED method: precise physical properties of a merger-origin binary Cepheid OGLE-LMC-CEP-1347</title>
      <link>https://arxiv.org/abs/2501.09076</link>
      <description>arXiv:2501.09076v2 Announce Type: replace-cross 
Abstract: Recently, a double-lined binary (SB2) classical Cepheid, OGLE-LMC-CEP-1347, was discovered, with the orbital period (P$_{\rm orb} = 59$ days) five times shorter than of any binary Cepheid known before. The expected mass of the Cepheid was below $3.5$ M$_\odot$, which, if confirmed, would also probe the uncharted territory. The system configuration also pointed to the Cepheid as a merger. We present a novel method for determining precise physical parameters of binary Cepheids using both theory and observations. This q-PED method combines the measured mass ratio (q), pulsation (P), and evolutionary (E) models, and the known distance (D) supplemented with multi-band photometry. Applying it, we determined the mass of the Cepheid of $3.41 \pm 0.08$ M$_\odot$, its radius of $13.65 \pm 0.27$ R$_\odot$, the companion mass of $1.89 \pm 0.04$ M$_\odot$ and radius of $12.51 \pm 0.62$ R$_\odot$. With the current configuration, the apparent evolutionary age difference of almost 1 Gyr between the components strongly favors the Cepheid merger origin scenario. If so, the actual age of the Cepheid would be 1.09 Gyr, on the edge of Population II stars, indicating a significant fraction of Cepheids may be much older than typically assumed. We also applied our method to an eclipsing binary Cepheid OGLE-LMC-CEP-1812 with accurately determined physical parameters, obtaining a close agreement, which confirmed our method's reliability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09076v2</guid>
      <category>astro-ph.SR</category>
      <category>astro-ph.IM</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Felipe Espinoza-Arancibia, Bogumi{\l} Pilecki</dc:creator>
    </item>
  </channel>
</rss>
