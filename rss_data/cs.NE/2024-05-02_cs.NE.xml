<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NE</link>
    <description>cs.NE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 02 May 2024 04:00:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 02 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Steel Plate Fault Detection using the Fitness Dependent Optimizer and Neural Networks</title>
      <link>https://arxiv.org/abs/2405.00006</link>
      <description>arXiv:2405.00006v1 Announce Type: new 
Abstract: Detecting faults in steel plates is crucial for ensuring the safety and reliability of the structures and industrial equipment. Early detection of faults can prevent further damage and costly repairs. This chapter aims at diagnosing and predicting the likelihood of steel plates developing faults using experimental text data. Various machine learning methods such as GWO-based and FDO-based MLP and CMLP are tested to classify steel plates as either faulty or non-faulty. The experiments produced promising results for all models, with similar accuracy and performance. However, the FDO-based MLP and CMLP models consistently achieved the best results, with 100% accuracy in all tested datasets. The other models' outcomes varied from one experiment to another. The findings indicate that models that employed the FDO as a learning algorithm had the potential to achieve higher accuracy with a little longer runtime compared to other algorithms. In conclusion, early detection of faults in steel plates is critical for maintaining safety and reliability, and machine learning techniques can help predict and diagnose these faults accurately.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00006v1</guid>
      <category>cs.NE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Salar Farahmand-Tabar, Tarik A. Rashid</dc:creator>
    </item>
    <item>
      <title>A biased random-key genetic algorithm with variable mutants to solve a vehicle routing problem</title>
      <link>https://arxiv.org/abs/2405.00268</link>
      <description>arXiv:2405.00268v1 Announce Type: new 
Abstract: The paper explores the Biased Random-Key Genetic Algorithm (BRKGA) in the domain of logistics and vehicle routing. Specifically, the application of the algorithm is contextualized within the framework of the Vehicle Routing Problem with Occasional Drivers and Time Window (VRPODTW) that represents a critical challenge in contemporary delivery systems. Within this context, BRKGA emerges as an innovative solution approach to optimize routing plans, balancing cost-efficiency with operational constraints. This research introduces a new BRKGA, characterized by a variable mutant population which can vary from generation to generation, named BRKGA-VM. This novel variant was tested to solve a VRPODTW. For this purpose, an innovative specific decoder procedure was proposed and implemented. Furthermore, a hybridization of the algorithm with a Variable Neighborhood Descent (VND) algorithm has also been considered, showing an improvement of problem-solving capabilities. Computational results show a better performances in term of effectiveness over a previous version of BRKGA, denoted as MP. The improved performance of BRKGA-VM is evident from its ability to optimize solutions across a wide range of scenarios, with significant improvements observed for each type of instance considered. The analysis also reveals that VM achieves preset goals more quickly compared to MP, thanks to the increased variability induced in the mutant population which facilitates the exploration of new regions of the solution space. Furthermore, the integration of VND has shown an additional positive impact on the quality of the solutions found.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00268v1</guid>
      <category>cs.NE</category>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paola Festa, Francesca Guerriero, Mauricio G. C. Resende, Edoardo Scalzo</dc:creator>
    </item>
    <item>
      <title>Covariant spatio-temporal receptive fields for neuromorphic computing</title>
      <link>https://arxiv.org/abs/2405.00318</link>
      <description>arXiv:2405.00318v1 Announce Type: new 
Abstract: Biological nervous systems constitute important sources of inspiration towards computers that are faster, cheaper, and more energy efficient. Neuromorphic disciplines view the brain as a coevolved system, simultaneously optimizing the hardware and the algorithms running on it. There are clear efficiency gains when bringing the computations into a physical substrate, but we presently lack theories to guide efficient implementations. Here, we present a principled computational model for neuromorphic systems in terms of spatio-temporal receptive fields, based on affine Gaussian kernels over space and leaky-integrator and leaky integrate-and-fire models over time. Our theory is provably covariant to spatial affine and temporal scaling transformations, and with close similarities to the visual processing in mammalian brains. We use these spatio-temporal receptive fields as a prior in an event-based vision task, and show that this improves the training of spiking networks, which otherwise is known as problematic for event-based vision. This work combines efforts within scale-space theory and computational neuroscience to identify theoretically well-founded ways to process spatio-temporal signals in neuromorphic systems. Our contributions are immediately relevant for signal processing and event-based vision, and can be extended to other processing tasks over space and time, such as memory and control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00318v1</guid>
      <category>cs.NE</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jens Egholm Pedersen, J\"org Conradt, Tony Lindeberg</dc:creator>
    </item>
    <item>
      <title>Optimized Drug Design using Multi-Objective Evolutionary Algorithms with SELFIES</title>
      <link>https://arxiv.org/abs/2405.00401</link>
      <description>arXiv:2405.00401v1 Announce Type: new 
Abstract: Computer aided drug design is a promising approach to reduce the tremendous costs, i.e. time and resources, for developing new medicinal drugs. It finds application in aiding the traversal of the vast chemical space of potentially useful compounds. In this paper, we deploy multi-objective evolutionary algorithms, namely NSGA-II, NSGA-III, and MOEA/D, for this purpose. At the same time, we used the SELFIES string representation method. In addition to the QED and SA score, we optimize compounds using the GuacaMol benchmark multi-objective task sets. Our results indicate that all three algorithms show converging behavior and successfully optimize the defined criteria whilst differing mainly in the number of potential solutions found. We observe that novel and promising candidates for synthesis are discovered among obtained compounds in the Pareto-sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00401v1</guid>
      <category>cs.NE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>The final version of this paper will be presented on Proceedings of the The IEEE World Congress on Computational Intelligence2024</arxiv:journal_reference>
      <dc:creator>Tomoya H\"omberg, Sanaz Mostaghim, Satoru Hiwa, Tomoyuki Hiroyasu</dc:creator>
    </item>
    <item>
      <title>An enhanced POSTA based on Nelder-Mead simplex search and quadratic interpolation</title>
      <link>https://arxiv.org/abs/2405.00122</link>
      <description>arXiv:2405.00122v1 Announce Type: cross 
Abstract: State transition algorithm (STA) is a metaheuristic method for global optimization. Recently, a modified STA named parameter optimal state transition algorithm (POSTA) is proposed. In POSTA, the performance of expansion operator, rotation operator and axesion operator is optimized through a parameter selection mechanism. But due to the insufficient utilization of historical information, POSTA still suffers from slow convergence speed and low solution accuracy on specific problems. To make better use of the historical information, Nelder-Mead (NM) simplex search and quadratic interpolation (QI) are integrated into POSTA. The enhanced POSTA is tested against 14 benchmark functions with 20-D, 30-D and 50-D space. An experimental comparison with several competitive metaheuristic methods demonstrates the effectiveness of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00122v1</guid>
      <category>math.OC</category>
      <category>cs.NE</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Tianyu Liu</dc:creator>
    </item>
    <item>
      <title>Weight Sparsity Complements Activity Sparsity in Neuromorphic Language Models</title>
      <link>https://arxiv.org/abs/2405.00433</link>
      <description>arXiv:2405.00433v1 Announce Type: cross 
Abstract: Activity and parameter sparsity are two standard methods of making neural networks computationally more efficient. Event-based architectures such as spiking neural networks (SNNs) naturally exhibit activity sparsity, and many methods exist to sparsify their connectivity by pruning weights. While the effect of weight pruning on feed-forward SNNs has been previously studied for computer vision tasks, the effects of pruning for complex sequence tasks like language modeling are less well studied since SNNs have traditionally struggled to achieve meaningful performance on these tasks. Using a recently published SNN-like architecture that works well on small-scale language modeling, we study the effects of weight pruning when combined with activity sparsity. Specifically, we study the trade-off between the multiplicative efficiency gains the combination affords and its effect on task performance for language modeling. To dissect the effects of the two sparsities, we conduct a comparative analysis between densely activated models and sparsely activated event-based models across varying degrees of connectivity sparsity. We demonstrate that sparse activity and sparse connectivity complement each other without a proportional drop in task performance for an event-based neural network trained on the Penn Treebank and WikiText-2 language modeling datasets. Our results suggest sparsely connected event-based neural networks are promising candidates for effective and efficient sequence modeling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00433v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rishav Mukherji, Mark Sch\"one, Khaleelulla Khan Nazeer, Christian Mayr, David Kappel, Anand Subramoney</dc:creator>
    </item>
    <item>
      <title>RAG-based Explainable Prediction of Road Users Behaviors for Automated Driving using Knowledge Graphs and Large Language Models</title>
      <link>https://arxiv.org/abs/2405.00449</link>
      <description>arXiv:2405.00449v1 Announce Type: cross 
Abstract: Prediction of road users' behaviors in the context of autonomous driving has gained considerable attention by the scientific community in the last years. Most works focus on predicting behaviors based on kinematic information alone, a simplification of the reality since road users are humans, and as such they are highly influenced by their surrounding context. In addition, a large plethora of research works rely on powerful Deep Learning techniques, which exhibit high performance metrics in prediction tasks but may lack the ability to fully understand and exploit the contextual semantic information contained in the road scene, not to mention their inability to provide explainable predictions that can be understood by humans. In this work, we propose an explainable road users' behavior prediction system that integrates the reasoning abilities of Knowledge Graphs (KG) and the expressiveness capabilities of Large Language Models (LLM) by using Retrieval Augmented Generation (RAG) techniques. For that purpose, Knowledge Graph Embeddings (KGE) and Bayesian inference are combined to allow the deployment of a fully inductive reasoning system that enables the issuing of predictions that rely on legacy information contained in the graph as well as on current evidence gathered in real time by onboard sensors. Two use cases have been implemented following the proposed approach: 1) Prediction of pedestrians' crossing actions; 2) Prediction of lane change maneuvers. In both cases, the performance attained surpasses the current state of the art in terms of anticipation and F1-score, showing a promising avenue for future research in this field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00449v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.IR</category>
      <category>cs.NE</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Mohamed Manzour Hussien, Angie Nataly Melo, Augusto Luis Ballardini, Carlota Salinas Maldonado, Rub\'en Izquierdo, Miguel \'Angel Sotelo</dc:creator>
    </item>
    <item>
      <title>Evolution of Heuristics: Towards Efficient Automatic Algorithm Design Using Large Language Mode</title>
      <link>https://arxiv.org/abs/2401.02051</link>
      <description>arXiv:2401.02051v2 Announce Type: replace 
Abstract: Heuristics are indispensable for tackling complex search and optimization problems. However, manual heuristic design is tedious and demands significant human intuition and experience. This paper introduces Evolution of Heuristic (EoH), a novel paradigm that leverages the synergy between Large Language Models (LLMs) and Evolutionary Computation (EC) for Automatic Heuristic Design (AHD). EoH represents heuristic ideas through linguistic descriptions, termed thoughts, generated by LLMs, which are then translated into executable code representations. The coevolution of thoughts and codes within an evolutionary framework offers superior AHD performance while mitigating computational expenses. Comprehensive evaluations on three types of combinatorial optimization benchmarks demonstrate EoH's outperformance against existing AHD methods. Notably, EoH surpasses FunSearch, a concurrent work focus on code evolution, identifying superior heuristics with significantly fewer computational budgets (i.e., queries to LLMs) on online bin packing problem. To foster reproducibility and accessibility, the source code is https://github.com/FeiLiu36/EoH.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.02051v2</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fei Liu, Xialiang Tong, Mingxuan Yuan, Xi Lin, Fu Luo, Zhenkun Wang, Zhichao Lu, Qingfu Zhang</dc:creator>
    </item>
    <item>
      <title>Neuro-Vision to Language: Image Reconstruction and Language enabled Interaction via Brain Recordings</title>
      <link>https://arxiv.org/abs/2404.19438</link>
      <description>arXiv:2404.19438v2 Announce Type: replace 
Abstract: Decoding non-invasive brain recordings is crucial for advancing our understanding of human cognition, yet faces challenges from individual differences and complex neural signal representations. Traditional methods require custom models and extensive trials, and lack interpretability in visual reconstruction tasks. Our framework integrating integrates 3D brain structures with visual semantics by Vision Transformer 3D. The unified feature extractor aligns fMRI features with multiple levels of visual embeddings efficiently, removing the need for individual-specific models and allowing extraction from single-trial data. This extractor consolidates multi-level visual features into one network, simplifying integration with Large Language Models (LLMs). Additionally, we have enhanced the fMRI dataset with various fMRI-image related textual data to support multimodal large model development. The integration with LLMs enhances decoding capabilities, enabling tasks like brain captioning, question-answering, detailed descriptions, complex reasoning, and visual reconstruction. Our approach not only shows superior performance across these tasks but also precisely identifies and manipulates language-based concepts within brain signals, enhancing interpretability and providing deeper neural process insights. These advances significantly broaden non-invasive brain decoding applicability in neuroscience and human-computer interaction, setting the stage for advanced brain-computer interfaces and cognitive models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.19438v2</guid>
      <category>cs.NE</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guobin Shen, Dongcheng Zhao, Xiang He, Linghao Feng, Yiting Dong, Jihang Wang, Qian Zhang, Yi Zeng</dc:creator>
    </item>
    <item>
      <title>The Relational Bottleneck as an Inductive Bias for Efficient Abstraction</title>
      <link>https://arxiv.org/abs/2309.06629</link>
      <description>arXiv:2309.06629v5 Announce Type: replace-cross 
Abstract: A central challenge for cognitive science is to explain how abstract concepts are acquired from limited experience. This has often been framed in terms of a dichotomy between connectionist and symbolic cognitive models. Here, we highlight a recently emerging line of work that suggests a novel reconciliation of these approaches, by exploiting an inductive bias that we term the relational bottleneck. In that approach, neural networks are constrained via their architecture to focus on relations between perceptual inputs, rather than the attributes of individual inputs. We review a family of models that employ this approach to induce abstractions in a data-efficient manner, emphasizing their potential as candidate models for the acquisition of abstract concepts in the human mind and brain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.06629v5</guid>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Taylor W. Webb, Steven M. Frankland, Awni Altabaa, Simon Segert, Kamesh Krishnamurthy, Declan Campbell, Jacob Russin, Tyler Giallanza, Zack Dulberg, Randall O'Reilly, John Lafferty, Jonathan D. Cohen</dc:creator>
    </item>
    <item>
      <title>Expert-Adaptive Medical Image Segmentation</title>
      <link>https://arxiv.org/abs/2402.07330</link>
      <description>arXiv:2402.07330v2 Announce Type: replace-cross 
Abstract: Medical image segmentation (MIS) plays an instrumental role in medical image analysis, where considerable effort has been devoted to automating the process. Currently, mainstream MIS approaches are based on deep neural networks (DNNs), which are typically trained on a dataset with annotations produced by certain medical experts. In the medical domain, the annotations generated by different experts can be inherently distinct due to complexity of medical images and variations in expertise and post-segmentation missions. Consequently, the DNN model trained on the data annotated by some experts may hardly adapt to a new expert. In this work, we evaluate a customised expert-adaptive method, characterised by multi-expert annotation, multi-task DNN-based model training, and lightweight model fine-tuning, to investigate model's adaptivity to a new expert in the situation where the amount and mobility of training images are limited. Experiments conducted on brain MRI segmentation tasks with limited training data demonstrate its effectiveness and the impact of its key parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.07330v2</guid>
      <category>cs.CV</category>
      <category>cs.NE</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Binyan Hu, A. K. Qin</dc:creator>
    </item>
    <item>
      <title>SOFIM: Stochastic Optimization Using Regularized Fisher Information Matrix</title>
      <link>https://arxiv.org/abs/2403.02833</link>
      <description>arXiv:2403.02833v2 Announce Type: replace-cross 
Abstract: This paper introduces a new stochastic optimization method based on the regularized Fisher information matrix (FIM), named SOFIM, which can efficiently utilize the FIM to approximate the Hessian matrix for finding Newton's gradient update in large-scale stochastic optimization of machine learning models. It can be viewed as a variant of natural gradient descent, where the challenge of storing and calculating the full FIM is addressed through making use of the regularized FIM and directly finding the gradient update direction via Sherman-Morrison matrix inversion. Additionally, like the popular Adam method, SOFIM uses the first moment of the gradient to address the issue of non-stationary objectives across mini-batches due to heterogeneous data. The utilization of the regularized FIM and Sherman-Morrison matrix inversion leads to the improved convergence rate with the same space and time complexities as stochastic gradient descent (SGD) with momentum. The extensive experiments on training deep learning models using several benchmark image classification datasets demonstrate that the proposed SOFIM outperforms SGD with momentum and several state-of-the-art Newton optimization methods in term of the convergence speed for achieving the pre-specified objectives of training and test losses as well as test accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02833v2</guid>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mrinmay Sen, A. K. Qin, Gayathri C, Raghu Kishore N, Yen-Wei Chen, Balasubramanian Raman</dc:creator>
    </item>
    <item>
      <title>Sup3r: A Semi-Supervised Algorithm for increasing Sparsity, Stability, and Separability in Hierarchy Of Time-Surfaces architectures</title>
      <link>https://arxiv.org/abs/2404.12402</link>
      <description>arXiv:2404.12402v2 Announce Type: replace-cross 
Abstract: The Hierarchy Of Time-Surfaces (HOTS) algorithm, a neuromorphic approach for feature extraction from event data, presents promising capabilities but faces challenges in accuracy and compatibility with neuromorphic hardware. In this paper, we introduce Sup3r, a Semi-Supervised algorithm aimed at addressing these challenges. Sup3r enhances sparsity, stability, and separability in the HOTS networks. It enables end-to-end online training of HOTS networks replacing external classifiers, by leveraging semi-supervised learning. Sup3r learns class-informative patterns, mitigates confounding features, and reduces the number of processed events. Moreover, Sup3r facilitates continual and incremental learning, allowing adaptation to data distribution shifts and learning new tasks without forgetting. Preliminary results on N-MNIST demonstrate that Sup3r achieves comparable accuracy to similarly sized Artificial Neural Networks trained with back-propagation. This work showcases the potential of Sup3r to advance the capabilities of HOTS networks, offering a promising avenue for neuromorphic algorithms in real-world applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12402v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Marco Rasetto, Himanshu Akolkar, Ryad Benosman</dc:creator>
    </item>
  </channel>
</rss>
