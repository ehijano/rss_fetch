<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 10 Oct 2025 04:00:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 10 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Clustering in Varying Metrics</title>
      <link>https://arxiv.org/abs/2510.07860</link>
      <description>arXiv:2510.07860v1 Announce Type: new 
Abstract: We introduce the aggregated clustering problem, where one is given $T$ instances of a center-based clustering task over the same $n$ points, but under different metrics. The goal is to open $k$ centers to minimize an aggregate of the clustering costs -- e.g., the average or maximum -- where the cost is measured via $k$-center/median/means objectives. More generally, we minimize a norm $\Psi$ over the $T$ cost values.
  We show that for $T \geq 3$, the problem is inapproximable to any finite factor in polynomial time. For $T = 2$, we give constant-factor approximations. We also show W[2]-hardness when parameterized by $k$, but obtain $f(k,T)\mathrm{poly}(n)$-time 3-approximations when parameterized by both $k$ and $T$.
  When the metrics have structure, we obtain efficient parameterized approximation schemes (EPAS). If all $T$ metrics have bounded $\varepsilon$-scatter dimension, we achieve a $(1+\varepsilon)$-approximation in $f(k,T,\varepsilon)\mathrm{poly}(n)$ time. If the metrics are induced by edge weights on a common graph $G$ of bounded treewidth $\mathsf{tw}$, and $\Psi$ is the sum function, we get an EPAS in $f(T,\varepsilon,\mathsf{tw})\mathrm{poly}(n,k)$ time. Conversely, unless (randomized) ETH is false, any finite factor approximation is impossible if parametrized by only $T$, even when the treewidth is $\mathsf{tw} = \Omega(\mathrm{poly}\log n)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.07860v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 10 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Deeparnab Chakrabarty, Jonathan Conroy, Ankita Sarkar</dc:creator>
    </item>
    <item>
      <title>Timeline Problems in Temporal Graphs: Vertex Cover vs. Dominating Set</title>
      <link>https://arxiv.org/abs/2510.08124</link>
      <description>arXiv:2510.08124v1 Announce Type: new 
Abstract: A temporal graph is a finite sequence of graphs, called snapshots, over the same vertex set. Many temporal graph problems turn out to be much more difficult than their static counterparts. One such problem is \textsc{Timeline Vertex Cover} (also known as \textsc{MinTimeline$_\infty$}), a temporal analogue to the classical \textsc{Vertex Cover} problem. In this problem, one is given a temporal graph $\mathcal{G}$ and two integers $k$ and $\ell$, and the goal is to cover each edge of each snapshot by selecting for each vertex at most $k$ activity intervals of length at most $\ell$ each. Here, an edge $uv$ in the $i$th snapshot is covered, if an activity interval of $u$ or $v$ is active at time $i$. In this work, we continue the algorithmic study of \textsc{Timeline Vertex Cover} and introduce the \textsc{Timeline Dominating Set} problem where we want to dominate all vertices in each snapshot by the selected activity intervals.
  We analyze both problems from a classical and parameterized point of view and also consider partial problem versions, where the goal is to cover (dominate) at least $t$ edges (vertices) of the snapshots. With respect to the parameterized complexity, we consider the temporal graph parameters vertex-interval-membership-width $(vimw)$ and interval-membership-width $(imw)$. We show that all considered problems admit FPT-algorithms when parameterized by $vimw + k+\ell$. This provides a smaller parameter combination than the ones used for previously known FPT-algorithms for \textsc{Timeline Vertex Cover}. Surprisingly, for $imw+ k+\ell$, \textsc{Timeline Dominating Set} turns out to be easier than \textsc{Timeline Vertex Cover}, by also admitting an FPT-algorithm, whereas the vertex cover version is NP-hard even if $imw+\, k+\ell$ is constant. We also consider parameterization by combinations of $n$, the vertex set size, with $k$ or $\ell$ and parameterization by $t$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08124v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Fri, 10 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anton Herrmann, Christian Komusiewicz, Nils Morawietz, Frank Sommer</dc:creator>
    </item>
    <item>
      <title>Dynamic Connectivity with Expected Polylogarithmic Worst-Case Update Time</title>
      <link>https://arxiv.org/abs/2510.08297</link>
      <description>arXiv:2510.08297v1 Announce Type: new 
Abstract: Whether a graph $G=(V,E)$ is connected is arguably its most fundamental property. Naturally, connectivity was the first characteristic studied for dynamic graphs, i.e. graphs that undergo edge insertions and deletions. While connectivity algorithms with polylogarithmic amortized update time have been known since the 90s, achieving worst-case guarantees has proven more elusive.
  Two recent breakthroughs have made important progress on this question: (1) Kapron, King and Mountjoy [SODA'13; Best Paper] gave a Monte-Carlo algorithm with polylogarithmic worst-case update time, and (2) Nanongkai, Saranurak and Wulff-Nilsen [STOC'17, FOCS'17] obtained a Las-Vegas data structure, however, with subpolynomial worst-case update time. Their algorithm was subsequently de-randomized [FOCS'20].
  In this article, we present a new dynamic connectivity algorithm based on the popular core graph framework that maintains a hierarchy interleaving vertex and edge sparsification. Previous dynamic implementations of the core graph framework required subpolynomial update time. In contrast, we show how to implement it for dynamic connectivity with polylogarithmic expected worst-case update time.
  We further show that the algorithm can be de-randomized efficiently: a deterministic static algorithm for computing a connectivity edge-sparsifier of low congestion in time $T(m) \cdot m$ on an $m$-edge graph yields a deterministic dynamic connectivity algorithm with $\tilde{O}(T(m))$ worst-case update time. Via current state-of-the-art algorithms [STOC'24], we obtain $T(m) = m^{o(1)}$ and recover deterministic subpolynomial worst-case update time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08297v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 10 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Simon Meierhans, Maximilian Probst Gutenberg</dc:creator>
    </item>
    <item>
      <title>Quantum Filtering and Analysis of Multiplicities in Eigenvalue Spectra</title>
      <link>https://arxiv.org/abs/2510.07439</link>
      <description>arXiv:2510.07439v1 Announce Type: cross 
Abstract: Fine-grained spectral properties of quantum Hamiltonians, including both eigenvalues and their multiplicities, provide useful information for characterizing many-body quantum systems as well as for understanding phenomena such as topological order. Extracting such information with small additive error is $\#\textsf{BQP}$-complete in the worst case. In this work, we introduce QFAMES (Quantum Filtering and Analysis of Multiplicities in Eigenvalue Spectra), a quantum algorithm that efficiently identifies clusters of closely spaced dominant eigenvalues and determines their multiplicities under physically motivated assumptions, which allows us to bypass worst-case complexity barriers. QFAMES also enables the estimation of observable expectation values within targeted energy clusters, providing a powerful tool for studying quantum phase transitions and other physical properties. We validate the effectiveness of QFAMES through numerical demonstrations, including its applications to characterizing quantum phases in the transverse-field Ising model and estimating the ground-state degeneracy of a topologically ordered phase in the two-dimensional toric code model. Our approach offers rigorous theoretical guarantees and significant advantages over existing subspace-based quantum spectral analysis methods, particularly in terms of the sample complexity and the ability to resolve degeneracies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.07439v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <pubDate>Fri, 10 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhiyan Ding, Lin Lin, Yilun Yang, Ruizhe Zhang</dc:creator>
    </item>
    <item>
      <title>3-Local Hamiltonian Problem and Constant Relative Error Quantum Partition Function Approximation: $O(2^{\frac{n}{2}})$ Algorithm Is Nearly Optimal under QSETH</title>
      <link>https://arxiv.org/abs/2510.07495</link>
      <description>arXiv:2510.07495v1 Announce Type: cross 
Abstract: We investigate the computational complexity of the Local Hamiltonian (LH) problem and the approximation of the Quantum Partition Function (QPF), two central problems in quantum many-body physics and quantum complexity theory. Both problems are known to be QMA-hard, and under the widely believed assumption that $\mathsf{BQP} \neq \mathsf{QMA}$, no efficient quantum algorithm exits. The best known quantum algorithm for LH runs in $O\bigl(2^{\frac{n}{2}(1 - o(1))}\bigr)$ time, while for QPF, the state-of-the-art algorithm achieves relative error $\delta$ in $O^\ast\bigl(\frac{1}{\delta}\sqrt{\frac{2^n}{Z}}\bigr)$ time, where $Z$ denotes the value of the partition function. A nature open question is whether more efficient algorithms exist for both problems.
  In this work, we establish tight conditional lower bounds showing that these algorithms are nearly optimal. Under the plausible Quantum Strong Exponential Time Hypothesis (QSETH), we prove that no quantum algorithm can solve either LH or approximate QPF significantly faster than $O(2^{n/2})$, even for 3-local Hamiltonians. In particular, we show: 1) 3-local LH cannot be solved in time $O(2^{\frac{n}{2}(1-\varepsilon)})$ for any $\varepsilon &gt; 0$ under QSETH; 2) 3-local QPF cannot be approximated up to any constant relative error in $O(2^{\frac{n}{2}(1-\varepsilon)})$ time for any $\varepsilon &gt; 0$ under QSETH; and 3) we present a quantum algorithm that approximates QPF up to relative error $1/2 + 1/\mathrm{poly}(n)$ in $O^\ast(2^{n/2})$ time, matching our conditional lower bound.
  Notably, our results provide the first fine-grained lower bounds for both LH and QPF with fixed locality. This stands in sharp contrast to QSETH and the trivial fine-grained lower bounds for LH, where the locality of the SAT instance and the Hamiltonian depends on the parameter $\varepsilon$ in the $O(2^{\frac{n}{2}(1-\varepsilon)})$ running time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.07495v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Fri, 10 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Nai-Hui Chia, Yu-Ching Shen</dc:creator>
    </item>
    <item>
      <title>No exponential quantum speedup for $\mathrm{SIS}^\infty$ anymore</title>
      <link>https://arxiv.org/abs/2510.07515</link>
      <description>arXiv:2510.07515v1 Announce Type: cross 
Abstract: In 2021, Chen, Liu, and Zhandry presented an efficient quantum algorithm for the average-case $\ell_\infty$-Short Integer Solution ($\mathrm{SIS}^\infty$) problem, in a parameter range outside the normal range of cryptographic interest, but still with no known efficient classical algorithm. This was particularly exciting since $\mathrm{SIS}^\infty$ is a simple problem without structure, and their algorithmic techniques were different from those used in prior exponential quantum speedups.
  We present efficient classical algorithms for all of the $\mathrm{SIS}^\infty$ and (more general) Constrained Integer Solution problems studied in their paper, showing there is no exponential quantum speedup anymore.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.07515v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <pubDate>Fri, 10 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Robin Kothari, Ryan O'Donnell, Kewen Wu</dc:creator>
    </item>
    <item>
      <title>Conjugate queries can help</title>
      <link>https://arxiv.org/abs/2510.07622</link>
      <description>arXiv:2510.07622v1 Announce Type: cross 
Abstract: We give a natural problem over input quantum oracles $U$ which cannot be solved with exponentially many black-box queries to $U$ and $U^\dagger$, but which can be solved with constant many queries to $U$ and $U^*$, or $U$ and $U^{\mathrm{T}}$. We also demonstrate a quantum commitment scheme that is secure against adversaries that query only $U$ and $U^\dagger$, but is insecure if the adversary can query $U^*$. These results show that conjugate and transpose queries do give more power to quantum algorithms, lending credence to the idea put forth by Zhandry that cryptographic primitives should prove security against these forms of queries.
  Our key lemma is that any circuit using $q$ forward and inverse queries to a state preparation unitary for a state $\sigma$ can be simulated to $\varepsilon$ error with $n = \mathcal{O}(q^2/\varepsilon)$ copies of $\sigma$. Consequently, for decision tasks, algorithms using (forward and inverse) state preparation queries only ever perform quadratically better than sample access. These results follow from straightforward combinations of existing techniques; our contribution is to state their consequences in their strongest, most counter-intuitive form. In doing so, we identify a motif where generically strengthening a quantum resource can be possible if the output is allowed to be random, bypassing no-go theorems for deterministic algorithms. We call this the acorn trick.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.07622v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Fri, 10 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ewin Tang, John Wright, Mark Zhandry</dc:creator>
    </item>
    <item>
      <title>Optimal lower bounds for quantum state tomography</title>
      <link>https://arxiv.org/abs/2510.07699</link>
      <description>arXiv:2510.07699v1 Announce Type: cross 
Abstract: We show that $n = \Omega(rd/\varepsilon^2)$ copies are necessary to learn a rank $r$ mixed state $\rho \in \mathbb{C}^{d \times d}$ up to error $\varepsilon$ in trace distance. This matches the upper bound of $n = O(rd/\varepsilon^2)$ from prior work, and therefore settles the sample complexity of mixed state tomography. We prove this lower bound by studying a special case of full state tomography that we refer to as projector tomography, in which $\rho$ is promised to be of the form $\rho = P/r$, where $P \in \mathbb{C}^{d \times d}$ is a rank $r$ projector. A key technical ingredient in our proof, which may be of independent interest, is a reduction which converts any algorithm for projector tomography which learns to error $\varepsilon$ in trace distance to an algorithm which learns to error $O(\varepsilon)$ in the more stringent Bures distance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.07699v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Fri, 10 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thilo Scharnhorst, Jack Spilecki, John Wright</dc:creator>
    </item>
    <item>
      <title>Integer Factoring with Unoperations</title>
      <link>https://arxiv.org/abs/2510.08027</link>
      <description>arXiv:2510.08027v1 Announce Type: cross 
Abstract: This work introduces the notion of unoperation $\mathfrak{Un}(\hat{O})$ of some operation $\hat{O}$. Given a valid output of $\hat{O}$, the corresponding unoperation produces a set of all valid inputs to $\hat{O}$ that produce the given output. Further, the working principle of unoperations is illustrated using the example of addition. A device providing that functionality is constructed utilising a quantum circuit performing the unoperation of addition - referred to as unaddition. To highlight the potential of the approach the unaddition quantum circuit is employed to construct a device for factoring integer numbers $N$, which is then called unmultiplier. This approach requires only a number of qubits $\in \mathcal{O}((\log{N})^2)$, rivalling the best known factoring algorithms to date.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08027v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <pubDate>Fri, 10 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paul Kohl</dc:creator>
    </item>
    <item>
      <title>k-SUM Hardness Implies Treewidth-SETH</title>
      <link>https://arxiv.org/abs/2510.08185</link>
      <description>arXiv:2510.08185v1 Announce Type: cross 
Abstract: We show that if k-SUM is hard, in the sense that the standard algorithm is essentially optimal, then a variant of the SETH called the Primal Treewidth SETH is true. Formally: if there is an $\varepsilon&gt;0$ and an algorithm which solves SAT in time $(2-\varepsilon)^{tw}|\phi|^{O(1)}$, where $tw$ is the width of a given tree decomposition of the primal graph of the input, then there exists a randomized algorithm which solves k-SUM in time $n^{(1-\delta)\frac{k}{2}}$ for some $\delta&gt;0$ and all sufficiently large $k$. We also establish an analogous result for the k-XOR problem, where integer addition is replaced by component-wise addition modulo $2$.
  As an application of our reduction we are able to revisit tight lower bounds on the complexity of several fundamental problems parameterized by treewidth (Independent Set, Max Cut, $k$-Coloring). Our results imply that these bounds, which were initially shown under the SETH, also hold if one assumes the k-SUM or k-XOR Hypotheses, arguably increasing our confidence in their validity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08185v1</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Fri, 10 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Lampis</dc:creator>
    </item>
    <item>
      <title>Energy-Efficient Maximal Independent Sets in Radio Networks</title>
      <link>https://arxiv.org/abs/2510.08244</link>
      <description>arXiv:2510.08244v1 Announce Type: cross 
Abstract: The maximal independent set (MIS) is one of the most fundamental problems in distributed computing, and it has been studied intensively for over four decades. This paper focuses on the MIS problem in the Radio Network model, a standard model widely used to model wireless networks, particularly ad hoc wireless and sensor networks. Energy is a premium resource in these networks, which are typically battery-powered. Hence, designing distributed algorithms that use as little energy as possible is crucial. We use the well-established energy model where a node can be sleeping or awake in a round, and only the awake rounds (when it can send or listen) determine the energy complexity of the algorithm, which we want to minimize.
  We present new, more energy-efficient MIS algorithms in radio networks with arbitrary and unknown graph topology. We present algorithms for two popular variants of the radio model -- with collision detection (CD) and without collision detection (no-CD). Specifically, we obtain the following results:
  1. CD model: We present a randomized distributed MIS algorithm with energy complexity $O(\log n)$, round complexity $O(\log^2 n)$, and failure probability $1 / poly(n)$, where $n$ is the network size. We show that our energy complexity is optimal by showing a matching $\Omega(\log n)$ lower bound.
  2. no-CD model: In the more challenging no-CD model, we present a randomized distributed MIS algorithm with energy complexity $O(\log^2n \log \log n)$, round complexity $O(\log^3 n \log \Delta)$, and failure probability $1 / poly(n)$. The energy complexity of our algorithm is significantly lower than the round (and energy) complexity of $O(\log^3 n)$ of the best known distributed MIS algorithm of Davies [PODC 2023] for arbitrary graph topology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08244v1</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <pubDate>Fri, 10 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dominick Banasik, Varsha Dani, Fabien Dufoulon, Aayush Gupta, Thomas P. Hayes, Gopal Pandurangan</dc:creator>
    </item>
    <item>
      <title>Adaptive Sparsification for Linear Programming</title>
      <link>https://arxiv.org/abs/2510.08348</link>
      <description>arXiv:2510.08348v1 Announce Type: cross 
Abstract: We introduce a generic framework for solving linear programs (LPs) with many constraints $(n \gg d)$ via adaptive sparsification. Our approach provides a principled generalization of the techniques of [Assadi '23] from matching problems to general LPs and robustifies [Clarkson's '95] celebrated algorithm for the exact setting. The framework reduces LP solving to a sequence of calls to a ``low-violation oracle'' on small, adaptively sampled subproblems, which we analyze through the lens of the multiplicative weight update method.
  Our main results demonstrate the versatility of this paradigm. First, we present a quantum version of Clarkson's algorithm that finds an exact solution to an LP using $\tilde{O}(\sqrt{n} d^3)$ row-queries to the constraint matrix. This is achieved by accelerating the classical bottleneck (the search for violated constraints) with a generalization of Grover search, decoupling the quantum component from the classical solver. Second, our framework yields new state-of-the-art algorithms for mixed packing and covering problems when the packing constraints are ``simple''. By retaining all packing constraints while sampling only from the covering constraints, we achieve a significant width reduction, leading to faster solvers in both the classical and quantum query models. Our work provides a modular and powerful approach for accelerating LP solvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08348v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <pubDate>Fri, 10 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>\'Etienne Objois, Adrian Vladu</dc:creator>
    </item>
    <item>
      <title>A Graph Width Perspective on Partially Ordered Hamiltonian Paths and Cycles II: Vertex and Edge Deletion Numbers</title>
      <link>https://arxiv.org/abs/2510.08378</link>
      <description>arXiv:2510.08378v1 Announce Type: cross 
Abstract: We consider the problem of finding a Hamiltonian path or cycle with precedence constraints in the form of a partial order on the vertex set. We study the complexity for graph width parameters for which the ordinary problems $\mathsf{Hamiltonian\ Path}$ and $\mathsf{Hamiltonian\ Cycle}$ are in $\mathsf{FPT}$. In particular, we focus on parameters that describe how many vertices and edges have to be deleted to become a member of a certain graph class. We show that the problems are $\mathsf{W[1]}$-hard for such restricted cases as vertex distance to path and vertex distance to clique. We complement these results by showing that the problems can be solved in $\mathsf{XP}$ time for vertex distance to outerplanar and vertex distance to block. Furthermore, we present some $\mathsf{FPT}$ algorithms, e.g., for edge distance to block. Additionally, we prove para-$\mathsf{NP}$-hardness when considered with the edge clique cover number.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08378v1</guid>
      <category>cs.DM</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Fri, 10 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jesse Beisegel, Katharina Klost, Kristin Knorr, Fabienne Ratajczak, Robert Scheffler</dc:creator>
    </item>
    <item>
      <title>A convergent hierarchy of spectral gap certificates for qubit Hamiltonians</title>
      <link>https://arxiv.org/abs/2510.08427</link>
      <description>arXiv:2510.08427v1 Announce Type: cross 
Abstract: We give a convergent hierarchy of SDP certificates for bounding the spectral gap of local qubit Hamiltonians from below. Our approach is based on the NPA hierarchy applied to a polynomially-sized system of constraints defining the universal enveloping algebra of the Lie algebra $\mathfrak{su}(2^{n})$, as well as additional constraints which put restrictions on the corresponding representations of the algebra. We also use as input an upper bound on the ground state energy, either using a hierarchy introduced by Fawzi, Fawzi, and Scalet, or an analog for qubit Hamiltonians of the Lasserre hierarchy of upper bounds introduced by Klep, Magron, Mass\'{e}, and Vol\v{c}i\v{c}. The convergence of the certificates does not require that the Hamiltonian be frustration-free.
  We prove that the resulting certificates have polynomial size at fixed degree and converge asymptotically (in fact, at level $n$), by showing that all allowed representations of the algebra correspond to the second exterior power $\wedge^2(\mathbb{C}^{2^n})$, which encodes the sum of the two smallest eigenvalues of the original Hamiltonian. We also give an example showing that for a commuting 1-local Hamiltonian, the hierarchy certifies a nontrivial lower bound on the spectral gap.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08427v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <pubDate>Fri, 10 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Sujit Rao</dc:creator>
    </item>
    <item>
      <title>Quartic quantum speedups for community detection</title>
      <link>https://arxiv.org/abs/2510.08494</link>
      <description>arXiv:2510.08494v1 Announce Type: cross 
Abstract: Community detection is a foundational problem in data science. Its natural extension to hypergraphs captures higher-order correlations beyond pairwise interactions. In this work, we develop a quantum algorithm for hypergraph community detection that achieves a quartic quantum speedup over the best known classical algorithm, along with superpolynomial savings in space. Our algorithm is based on the Kikuchi method, which we extend beyond previously considered problems such as Tensor PCA and $p$XORSAT to a broad family of generalized stochastic block models. To demonstrate (near) optimality of this method, we prove matching lower bounds (up to logarithmic factors) in the low-degree framework, showing that the algorithm saturates a smooth statistical-computational tradeoff. The quantum speedup arises from a quantized version of the Kikuchi method and is based on the efficient preparation of a guiding state correlated with the underlying community structure. Our work suggests that prior quantum speedups using the Kikuchi method are sufficiently robust to encompass a broader set of problems than previously believed; we conjecture that a quantity known as marginal order characterizes the existence of these quantum speedups.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08494v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <pubDate>Fri, 10 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Schmidhuber, Alexander Zlokapa</dc:creator>
    </item>
    <item>
      <title>Quantum Probe Tomography</title>
      <link>https://arxiv.org/abs/2510.08499</link>
      <description>arXiv:2510.08499v1 Announce Type: cross 
Abstract: Characterizing quantum many-body systems is a fundamental problem across physics, chemistry, and materials science. While significant progress has been made, many existing Hamiltonian learning protocols demand digital quantum control over the entire system, creating a disconnect from many real-world settings that provide access only through small, local probes. Motivated by this, we introduce and formalize the problem of quantum probe tomography, where one seeks to learn the parameters of a many-body Hamiltonian using a single local probe access to a small subsystem of a many-body thermal state undergoing time evolution. We address the identifiability problem of determining which Hamiltonians can be distinguished from probe data through a new combination of tools from algebraic geometry and smoothed analysis. Using this approach, we prove that generic Hamiltonians in various physically natural families are identifiable up to simple, unavoidable structural symmetries. Building on these insights, we design the first efficient end-to-end algorithm for probe tomography that learns Hamiltonian parameters to accuracy $\varepsilon$, with query complexity scaling polynomially in $1/\varepsilon$ and classical post-processing time scaling polylogarithmically in $1/\varepsilon$. In particular, we demonstrate that translation- and rotation-invariant nearest-neighbor Hamiltonians on square lattices in one, two, and three dimensions can be efficiently reconstructed from single-site probes of the Gibbs state, up to inversion symmetry about the probed site. Our results demonstrate that robust Hamiltonian learning remains achievable even under severely constrained experimental access.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08499v1</guid>
      <category>quant-ph</category>
      <category>cond-mat.str-el</category>
      <category>cs.DS</category>
      <pubDate>Fri, 10 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sitan Chen, Jordan Cotler, Hsin-Yuan Huang</dc:creator>
    </item>
    <item>
      <title>Randomized and quantum approximate matrix multiplication</title>
      <link>https://arxiv.org/abs/2510.08509</link>
      <description>arXiv:2510.08509v1 Announce Type: cross 
Abstract: The complexity of matrix multiplication is a central topic in computer science. While the focus has traditionally been on exact algorithms, a long line of literature also considers randomized algorithms, which return an approximate solution in faster time. In this work, we adopt a unifying perspective that frames these randomized algorithms in terms of mean estimation. Using it, we first give refined analyses of classical algorithms based on random walks by Cohen-Lewis (`99), and based on sketching by Sarl\'os (`06) and Drineas-Kannan-Mahoney (`06). We then propose an improvement on Cohen-Lewis that yields a single classical algorithm that is faster than all the other approaches, if we assume no use of (exact) fast matrix multiplication as a subroutine. Second, we demonstrate a quantum speedup on top of these algorithms by using the recent quantum multivariate mean estimation algorithm by Cornelissen-Hamoudi-Jerbi (`22).</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08509v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <pubDate>Fri, 10 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Simon Apers, Arjan Cornelissen, Samson Wang</dc:creator>
    </item>
    <item>
      <title>Computational and statistical lower bounds for low-rank estimation under general inhomogeneous noise</title>
      <link>https://arxiv.org/abs/2510.08541</link>
      <description>arXiv:2510.08541v1 Announce Type: cross 
Abstract: Recent work has generalized several results concerning the well-understood spiked Wigner matrix model of a low-rank signal matrix corrupted by additive i.i.d. Gaussian noise to the inhomogeneous case, where the noise has a variance profile. In particular, for the special case where the variance profile has a block structure, a series of results identified an effective spectral algorithm for detecting and estimating the signal, identified the threshold signal strength required for that algorithm to succeed, and proved information-theoretic lower bounds that, for some special signal distributions, match the above threshold. We complement these results by studying the computational optimality of this spectral algorithm. Namely, we show that, for a much broader range of signal distributions, whenever the spectral algorithm cannot detect a low-rank signal, then neither can any low-degree polynomial algorithm. This gives the first evidence for a computational hardness conjecture of Guionnet, Ko, Krzakala, and Zdeborov\'a (2023). With similar techniques, we also prove sharp information-theoretic lower bounds for a class of signal distributions not treated by prior work. Unlike all of the above results on inhomogeneous models, our results do not assume that the variance profile has a block structure, and suggest that the same spectral algorithm might remain optimal for quite general profiles. We include a numerical study of this claim for an example of a smoothly-varying rather than piecewise-constant profile. Our proofs involve analyzing the graph sums of a matrix, which also appear in free and traffic probability, but we require new bounds on these quantities that are tighter than existing ones for non-negative matrices, which may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08541v1</guid>
      <category>math.ST</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Fri, 10 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Debsurya De, Dmitriy Kunisky</dc:creator>
    </item>
    <item>
      <title>A Dobrushin condition for quantum Markov chains: Rapid mixing and conditional mutual information at high temperature</title>
      <link>https://arxiv.org/abs/2510.08542</link>
      <description>arXiv:2510.08542v1 Announce Type: cross 
Abstract: A central challenge in quantum physics is to understand the structural properties of many-body systems, both in equilibrium and out of equilibrium. For classical systems, we have a unified perspective which connects structural properties of systems at thermal equilibrium to the Markov chain dynamics that mix to them. We lack such a perspective for quantum systems: there is no framework to translate the quantitative convergence of the Markovian evolution into strong structural consequences.
  We develop a general framework that brings the breadth and flexibility of the classical theory to quantum Gibbs states at high temperature. At its core is a natural quantum analog of a Dobrushin condition; whenever this condition holds, a concise path-coupling argument proves rapid mixing for the corresponding Markovian evolution. The same machinery bridges dynamic and structural properties: rapid mixing yields exponential decay of conditional mutual information (CMI) without restrictions on the size of the probed subsystems, resolving a central question in the theory of open quantum systems. Our key technical insight is an optimal transport viewpoint which couples quantum dynamics to a linear differential equation, enabling precise control over how local deviations from equilibrium propagate to distant sites.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08542v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <pubDate>Fri, 10 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ainesh Bakshi, Allen Liu, Ankur Moitra, Ewin Tang</dc:creator>
    </item>
    <item>
      <title>FLASH-TB: Integrating Arc-Flags and Trip-Based Public Transit Routing</title>
      <link>https://arxiv.org/abs/2312.13146</link>
      <description>arXiv:2312.13146v4 Announce Type: replace 
Abstract: We present FLASH-TB, a journey planning algorithm for public transit networks that combines Trip-Based Public Transit Routing (TB) with the Arc-Flags speedup technique. The basic idea is simple: The network is partitioned into a configurable number of cells. For each cell and each possible transfer between two vehicles, the algorithm precomputes a flag that indicates whether the transfer is required to reach the cell. During a query, only flagged transfers are explored. Our algorithm improves upon previous attempts to apply Arc-Flags to public transit networks, which saw limited success due to conflicting rules for pruning the search space. We show that these rules can be reconciled while still producing correct results. Because the number of cells is configurable, FLASH-TB offers a tradeoff between query time and memory consumption. It is significantly more space-efficient than existing techniques with a comparable preprocessing time, which store generalized shortest-path trees: to match their query performance, it requires up to two orders of magnitude less memory. The fastest configuration of FLASH-TB achieves a speedup of more than two orders of magnitude over TB, offering sub-millisecond query times even on large countrywide networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.13146v4</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 10 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ernestine Gro{\ss}mann, Jonas Sauer, Christian Schulz, Patrick Steil, Sascha Witt</dc:creator>
    </item>
    <item>
      <title>Optimal Padded Decomposition For Bounded Treewidth Graphs</title>
      <link>https://arxiv.org/abs/2407.12230</link>
      <description>arXiv:2407.12230v3 Announce Type: replace 
Abstract: A $(\beta,\delta,\Delta)$-padded decomposition of an edge-weighted graph $G = (V,E,w)$ is a stochastic decomposition into clusters of diameter at most $\Delta$ such that for every vertex $v\in V$, the probability that $\rm{ball}_G(v,\gamma\Delta)$ is entirely contained in the cluster containing $v$ is at least $e^{-\beta\gamma}$ for every $\gamma \in [0,\delta]$. Padded decompositions have been studied for decades and have found numerous applications, including metric embedding, multicommodity flow-cut gap, multicut, and zero extension problems, to name a few. In these applications, parameter $\beta$, called the padding parameter, is the most important parameter since it decides either the distortion or the approximation ratios. For general graphs with $n$ vertices, $\beta = \Theta(\log n)$. Klein, Plotkin, and Rao showed that $K_r$-minor-free graphs have padding parameter $\beta = O(r^3)$, which is a significant improvement over general graphs when $r$ is a constant. A long-standing conjecture is to construct a padded decomposition for $K_r$-minor-free graphs with padding parameter $\beta = O(\log r)$. Despite decades of research, the best-known result is $\beta = O(r)$, even for graphs with treewidth at most $r$. In this work, we make significant progress toward the aforementioned conjecture by showing that graphs with treewidth $\rm{tw}$ admit a padded decomposition with padding parameter $O(\log \rm{tw})$, which is tight. As corollaries, we obtain an exponential improvement in dependency on treewidth in a host of algorithmic applications: $O(\sqrt{ \log n \cdot \log(\rm{tw})})$ flow-cut gap, max flow-min multicut ratio of $O(\log(\rm{tw}))$, an $O(\log(\rm{tw}))$ approximation for the 0-extension problem, an $\ell^{O(\log n)}_\infty$ embedding with distortion $O(\log \rm{tw})$, and an $O(\log \rm{tw})$ bound for integrality gap for the uniform sparsest cut.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12230v3</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Fri, 10 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.46298/theoretics.25.22</arxiv:DOI>
      <arxiv:journal_reference>TheoretiCS, Volume 4 (2025), Article 22, 1-39</arxiv:journal_reference>
      <dc:creator>Arnold Filtser, Tobias Friedrich, Davis Issac, Nikhil Kumar, Hung Le, Nadym Mallek, Ziena Zeif</dc:creator>
    </item>
    <item>
      <title>Massively Parallel Minimum Spanning Tree in General Metric Spaces</title>
      <link>https://arxiv.org/abs/2408.06455</link>
      <description>arXiv:2408.06455v2 Announce Type: replace 
Abstract: We study the minimum spanning tree (MST) problem in the massively parallel computation (MPC) model. Our focus is particularly on the *strictly sublinear* regime of MPC where the space per machine is $O(n^\delta)$. Here $n$ is the number of vertices and constant $\delta \in (0, 1)$ can be made arbitrarily small. The MST problem admits a simple and folklore $O(\log n)$-round algorithm in the MPC model. When the weights can be arbitrary, this matches a conditional lower bound of $\Omega(\log n)$ which follows from a well-known 1vs2-Cycle conjecture. As such, much of the literature focuses on breaking the logarithmic barrier in more structured variants of the problem, such as when the vertices correspond to points in low- [ANOY14, STOC'14] or high-dimensional Euclidean spaces [JMNZ, SODA'24].
  In this work, we focus more generally on metric spaces. Namely, all pairwise weights are provided and guaranteed to satisfy the triangle inequality, but are otherwise unconstrained. We show that for any $\varepsilon &gt; 0$, a $(1+\varepsilon)$-approximate MST can be found in $O(\log \frac{1}{\varepsilon} + \log \log n)$ rounds, which is the first $o(\log n)$-round algorithm for finding any constant approximation in this setting. Other than being applicable to more general weight functions, our algorithm also slightly improves the $O(\log \log n \cdot \log \log \log n)$ round-complexity of [JMNZ24, SODA'24] and significantly improves its approximation from a large constant to $1+\varepsilon$.
  On the lower bound side, we prove that under the 1vs2-Cycle conjecture, $\Omega(\log \frac{1}{\varepsilon})$ rounds are needed for finding a $(1+\varepsilon)$-approximate MST in general metrics. It is worth noting that while many existing lower bounds in the MPC model under the 1vs2-Cycle conjecture only hold against "component stable" algorithms, our lower bound applies to *all* algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06455v2</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 10 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amir Azarmehr, Soheil Behnezhad, Rajesh Jayaram, Jakub {\L}\k{a}cki, Vahab Mirrokni, Peilin Zhong</dc:creator>
    </item>
    <item>
      <title>Realization of Temporally Connected Graphs Based on Degree Sequences</title>
      <link>https://arxiv.org/abs/2504.17743</link>
      <description>arXiv:2504.17743v2 Announce Type: replace 
Abstract: Given an undirected graph $G$, the problem of deciding whether $G$ admits a simple and proper time-labeling that makes it temporally connected is known to be NP-hard (G\"obel et al., 1991). In this article, we relax this problem and ask whether a given degree sequence can be realized as a temporally connected graph. Our main results are a complete characterization of the feasible cases, and a recognition algorithm that runs in $O(n)$ time for graphical degree sequences (realized as simple temporal graphs) and in $O(n+m)$ time for multigraphical degree sequences (realized as non-simple temporal graphs, where the number of time labels on an edge corresponds to the multiplicity of the edge in the multigraph). In fact, these algorithms can be made constructive at essentially no cost. Namely, we give a constructive $O(n+m)$ time algorithm that outputs, for a given (multi)graphical degree sequence $\mathbf{d}$, a temporally connected graph whose underlying (multi)graph is a realization of $\mathbf{d}$, if one exists.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17743v2</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 10 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arnaud Casteigts, Michelle D\"oring, Nils Morawietz</dc:creator>
    </item>
    <item>
      <title>A 13/6-Approximation for Strip Packing via the Bottom-Left Algorithm</title>
      <link>https://arxiv.org/abs/2509.04654</link>
      <description>arXiv:2509.04654v2 Announce Type: replace 
Abstract: In the Strip Packing problem, we are given a vertical strip of fixed width and unbounded height, along with a set of axis-parallel rectangles. The task is to place all rectangles within the strip, without overlaps, while minimizing the height of the packing. This problem is known to be NP-hard. The Bottom-Left Algorithm is a simple and widely used heuristic for Strip Packing. Given a fixed order of the rectangles, it places them one by one, always choosing the lowest feasible position in the strip and, in case of ties, the leftmost one. Baker, Coffman, and Rivest proved in 1980 that the Bottom-Left Algorithm has approximation ratio 3 if the rectangles are sorted by decreasing width. For the past 45 years, no alternative ordering has been found that improves this bound. We introduce a new rectangle ordering and show that with this ordering the Bottom-Left Algorithm achieves a 13/6 approximation for the Strip Packing problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.04654v2</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <pubDate>Fri, 10 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Stefan Hougardy, Bart Zondervan</dc:creator>
    </item>
    <item>
      <title>Finding a Fair Scoring Function for Top-$k$ Selection: From Hardness to Practice</title>
      <link>https://arxiv.org/abs/2503.11575</link>
      <description>arXiv:2503.11575v3 Announce Type: replace-cross 
Abstract: Selecting a subset of the $k$ "best" items from a dataset of $n$ items, based on a scoring function, is a key task in decision-making. Given the rise of automated decision-making software, it is important that the outcome of this process, called top-$k$ selection, is fair. Here we consider the problem of identifying a fair linear scoring function for top-$k$ selection. The function computes a score for each item as a weighted sum of its (numerical) attribute values, and must ensure that the selected subset includes adequate representation of a minority or historically disadvantaged group. Existing algorithms do not scale efficiently, particularly in higher dimensions. Our hardness analysis shows that in more than two dimensions, no algorithm is likely to achieve good scalability with respect to dataset size, and the computational complexity is likely to increase rapidly with dimensionality. However, the hardness results also provide key insights guiding algorithm design, leading to our two-pronged solution: (1) For small values of $k$, our hardness analysis reveals a gap in the hardness barrier. By addressing various engineering challenges, including achieving efficient parallelism, we turn this potential of efficiency into an optimized algorithm delivering substantial practical performance gains. (2) For large values of $k$, where the hardness is robust, we employ a practically efficient algorithm which, despite being theoretically worse, achieves superior real-world performance. Experimental evaluations on real-world datasets then explore scenarios where worst-case behavior does not manifest, identifying areas critical to practical performance. Our solution achieves speed-ups of up to several orders of magnitude compared to SOTA, an efficiency made possible through a tight integration of hardness analysis, algorithm design, practical engineering, and empirical evaluation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.11575v3</guid>
      <category>cs.DB</category>
      <category>cs.CC</category>
      <category>cs.CY</category>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <pubDate>Fri, 10 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Guangya Cai</dc:creator>
    </item>
    <item>
      <title>Adaptive Frontier Exploration on Graphs with Applications to Network-Based Disease Testing</title>
      <link>https://arxiv.org/abs/2505.21671</link>
      <description>arXiv:2505.21671v2 Announce Type: replace-cross 
Abstract: We study a sequential decision-making problem on a $n$-node graph $\mathcal{G}$ where each node has an unknown label from a finite set $\mathbf{\Omega}$, drawn from a joint distribution $\mathcal{P}$ that is Markov with respect to $\mathcal{G}$. At each step, selecting a node reveals its label and yields a label-dependent reward. The goal is to adaptively choose nodes to maximize expected accumulated discounted rewards. We impose a frontier exploration constraint, where actions are limited to neighbors of previously selected nodes, reflecting practical constraints in settings such as contact tracing and robotic exploration. We design a Gittins index-based policy that applies to general graphs and is provably optimal when $\mathcal{G}$ is a forest. Our implementation runs in $\mathcal{O}(n^2 \cdot |\mathbf{\Omega}|^2)$ time while using $\mathcal{O}(n \cdot |\mathbf{\Omega}|^2)$ oracle calls to $\mathcal{P}$ and $\mathcal{O}(n^2 \cdot |\mathbf{\Omega}|)$ space. Experiments on synthetic and real-world graphs show that our method consistently outperforms natural baselines, including in non-tree, budget-limited, and undiscounted settings. For example, in HIV testing simulations on real-world sexual interaction networks, our policy detects nearly all positive cases with only half the population tested, substantially outperforming other baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21671v2</guid>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 10 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Davin Choo, Yuqi Pan, Tonghan Wang, Milind Tambe, Alastair van Heerden, Cheryl Johnson</dc:creator>
    </item>
    <item>
      <title>Exact Causal Attention with 10% Fewer Operations</title>
      <link>https://arxiv.org/abs/2510.05175</link>
      <description>arXiv:2510.05175v2 Announce Type: replace-cross 
Abstract: We present Exact Causal Attention (ECA), a Strassen-style algorithm that computes exact Causal Attention using 10\% fewer operations. ECA improves a special class of matrix multiplications where either one operand or the output matrix is upper- or lower-triangular. This includes all matrix multiplication operations in the forward and backward pass of Causal Attention, such as masked product $\mathrm{Mask}(QK^{T})$. ECA is built upon algebraic identities discovered via machine learning and combinatorial search. We note that ECA cannot accelerate fused kernels such as FlashAttention on GPU. This is because ECA requires materialization of large intermediate expressions in the memory, while FlashAttention does not. However, it provides an alternative approach for compute-bound applications and can potentially be useful in scenarios with FLOPs considerations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05175v2</guid>
      <category>cs.LG</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Fri, 10 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Dmitry Rybin, Yushun Zhang, Ding Tian, Zhihang Lin, Zhi-Quan Luo</dc:creator>
    </item>
  </channel>
</rss>
