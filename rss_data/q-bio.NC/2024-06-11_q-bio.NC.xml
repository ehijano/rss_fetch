<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 12 Jun 2024 01:51:07 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 11 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Processing, evaluating and understanding FMRI data with afni_proc.py</title>
      <link>https://arxiv.org/abs/2406.05248</link>
      <description>arXiv:2406.05248v2 Announce Type: new 
Abstract: FMRI data are noisy, complicated to acquire, and typically go through many steps of processing before they are used in a study or clinical practice. Being able to visualize and understand the data from the start through the completion of processing, while being confident that each intermediate step was successful, is challenging. AFNI's "afni_proc.py" is a tool to create and run a processing pipeline for FMRI data. With its flexible features, "afni_proc.py" allows users to both control and evaluate their processing at a detailed level. It has been designed to keep users informed about all processing steps: it does not just process the data, but first outputs a fully commented processing script that the users can read, query, interpret and refer back to. Having this full provenance is important for being able to understand each step of processing; it also promotes transparency and reproducibility by keeping the record of individual-level processing and modeling specifics in a single, shareable place. Additionally, "afni_proc.py" creates pipelines that contain several automatic self-checks for potential problems during runtime. The output directory contains a dictionary of relevant quantities that can be programmatically queried for potential issues and a systematic, interactive quality control (QC) HTML. All of these features help users evaluate and understand their data and processing in detail. We describe these and other aspects of "afni_proc.py" here using a set of task-based and resting state FMRI example commands.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05248v2</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Richard C. Reynolds, Daniel R. Glen, Gang Chen, Ziad S. Saad, Robert W. Cox, Paul A. Taylor</dc:creator>
    </item>
    <item>
      <title>From First-order to Higher-order Interactions: Enhanced Representation of Homotopic Functional Connectivity through Control of Intervening Variables</title>
      <link>https://arxiv.org/abs/2406.05859</link>
      <description>arXiv:2406.05859v1 Announce Type: new 
Abstract: The brain's complex functionality emerges from network interactions that go beyond dyadic connections, with higher-order interactions significantly contributing to this complexity. One method of capturing higher-order interactions is through traversing the brain network using random walks. The efficacy of these random walks depends on the defined mutual interactions between two brain entities. More precise capture of higher-order interactions enables a better reflection of the brain's intrinsic neurophysiological characteristics. One well-established neurophysiological concept is Homotopic Functional Connectivity (HoFC), which illustrates the synchronized spontaneous activity between corresponding regions in the brain's left and right hemispheres. We employ node2vec, a random walk node embedding approach, alongside resting-state fMRI from the Human Connectome Project (HCP) to obtain higher-order feature vectors. We assess the efficacy of different functional connectivity parameterizations using HoFC. The results indicates that the quality of capturing higher-order interactions largely depends on the statistical dependency measure between brain regions. Higher-order interactions defined by partial correlation, better reflects HoFC compare to other statistical associations. In this case of first-order interactions, tangent space embedding more effectively demonstrates HoFC. The findings validate HoFC and underscore the importance of functional connectivity construction method in capturing intrinsic characteristics of the human brain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05859v1</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Behdad Khodabandehloo, Payam Jannatdoust, Babak Nadjar Araabi</dc:creator>
    </item>
    <item>
      <title>The Integrated Information Theory needs Attention</title>
      <link>https://arxiv.org/abs/2406.06143</link>
      <description>arXiv:2406.06143v1 Announce Type: new 
Abstract: The Integrated Information Theory (IIT) might be our current best bet at a scientific explanation of phenomenal consciousness. IIT focuses on the distinctively subjective and phenomenological aspects of conscious experience. Currently, it offers the fundaments of a formal account, but future developments shall explain the qualitative structures of every possible conscious experience. But this ambitious project is hindered by one fundamental limitation. IIT fails to acknowledge the crucial roles of attention in generating phenomenally conscious experience and shaping its contents. Here, we argue that IIT urgently needs an account of attention. Without this account, IIT cannot explain important informational differences between different kinds of experiences. Furthermore, though some IIT proponents celebratedly endorse a double dissociation between consciousness and attention, close analysis reveals that such as dissociation is in fact incompatible with IIT. Notably, the issues we raise for IIT will likely arise for many internalist theories of conscious contents in philosophy, especially theories with primitivist inclinations. Our arguments also extend to the recently popularized structuralist approaches. Overall, our discussion highlights how considerations about attention are indispensable for scientific as well as philosophical theorizing about conscious experience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06143v1</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Azenet Lopez, Carlos Montemayor</dc:creator>
    </item>
    <item>
      <title>Leveraging Hyperscanning EEG and VR Omnidirectional Treadmill to Explore Inter-Brain Synchrony in Collaborative Spatial Navigation</title>
      <link>https://arxiv.org/abs/2406.06327</link>
      <description>arXiv:2406.06327v1 Announce Type: new 
Abstract: Navigating through a physical environment to reach a desired location involves a complex interplay of cognitive, sensory, and motor functions. When navigating with others, experiencing a degree of behavioral and cognitive synchronization is both natural and ubiquitous. This synchronization facilitates a harmonious effort toward achieving a common goal, reflecting how individuals instinctively align their actions and thoughts in collaborative settings. Collaborative spatial tasks, which are crucial in daily and professional settings, require coordinated navigation and problem-solving skills. This study explores the neural mechanisms underlying such tasks by using hyperscanning electroencephalography (EEG) technology to examine brain dynamics in dyadic route planning within a virtual reality setting. By analyzing intra- and inter-brain couplings across delta, theta, alpha, beta, and gamma EEG bands using both functional and effective connectivity measures, we identified significant neural synchronization patterns associated with collaborative task performance in both leaders and followers. Functional intra-brain connectivity analyses revealed distinct neural engagement across EEG frequency bands, with increased delta couplings observed in both leaders and followers. Theta connectivity was particularly enhanced in followers, whereas the alpha band exhibited divergent patterns that indicate role-specific neural strategies. Inter-brain analysis revealed increased delta causality between interacting members but decreased theta and gamma couplings from followers to leaders. Additionally, inter-brain analysis indicated decreased couplings in faster-performing dyads, especially in theta bands. These insights enhance our understanding of the neural mechanisms driving collaborative spatial navigation and demonstrate the effectiveness of hyperscanning in studying complex brain-to-brain interactions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06327v1</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chun-Hsiang Chuang, Po-Hsun Peng, Yi-Chieh Chen</dc:creator>
    </item>
    <item>
      <title>Optical signal recording of cellular activity in optogenetic stimulation of human pulp dental cells using a twin-core fiber-based Mach-Zehnder interferometer biosensor</title>
      <link>https://arxiv.org/abs/2406.05787</link>
      <description>arXiv:2406.05787v2 Announce Type: cross 
Abstract: This paper introduces an innovative two-core fiber (TCF) optic sensor employing a Mach-Zehnder interferometer (MZI) to monitor the optogenetic response of light-sensitive human dental pulp stem cells (hDPSCs). The in-fiber MZI, formed using a segment of TCF optic, detects refractive index (RI) changes in the surrounding medium. The sensor utilizes the evanescent wave of one core as the sensing arm, necessitating a thin cladding achieved through one-sided chemical etching. This design allows the sensor to detect subtle alterations in the RI of the environment by observing displacements in the interference spectrum. The optogenetic stimulation of light-sensitive cells induces variations in ion concentrations, leading to a corresponding change in refractive index. The fabricated sensor, with a peak sensitivity of 675.74 nm/RIU within the RI range of 1.39-1.43, can detect these changes. A computer simulation validated the sensitivity and optimized fabrication parameters, exhibiting satisfactory agreement with experimental results. Spectrum displacements were recorded for both light-sensitive hDPSCs and regular hDPSCs (as a control test). Results from the experiment, analyzed and compared using data analysis software, revealed that 473 nm blue light effectively stimulated light-sensitive hDPSCs. Notably, the proposed sensor, a novel structure, demonstrated its capability to detect RI changes in the cell medium during optogenetic applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05787v2</guid>
      <category>physics.optics</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Faezeh Akbari, Mohammad Ismail Zibaii, Sara Chavoshi Nezhad, Azam Layeghi, Leila Dargahi, Orlando Frazao</dc:creator>
    </item>
    <item>
      <title>Input Driven Synchronization of Chaotic Neural Networks with Analyticaly Determined Conditional Lyapunov Exponents</title>
      <link>https://arxiv.org/abs/2406.06491</link>
      <description>arXiv:2406.06491v1 Announce Type: cross 
Abstract: Recurrent neural networks (RNNs) with random, but sufficiently strong and balanced coupling display a well known high-dimensional chaotic dynamics. Here, we investigate if externally applied inputs to these RNNs can stabilize globally synchronous, input-dependent solutions, in spite of the strong chaos-inducing coupling. We find that when the balance between excitation and inhibition is exact, that is when the row-sum of the weights is constant and 0, a globally applied input can readily synchronize all neurons onto a synchronous solution. The stability of the synchronous solution is analytically explored in this work with a master stability function. For any synchronous solution to the network dynamics, the conditional Lyapunov spectrum can be readily determined, with the stability of the synchronous solution critically dependent on the largest real eigenvalue component of the RNN weight matrix. We find that the smaller the maximum real component of the weight matrix eigenvalues, the more readily the network synchronizes. Further, the conditional Lyapunov exponents are easily computed numerically for any synchronization signal without simulating the RNN. Finally, for certain oscillatory synchronization signals, the conditional Lyapunov exponents can be determined analytically.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06491v1</guid>
      <category>nlin.CD</category>
      <category>math.DS</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jordan Culp, Wilten Nicola</dc:creator>
    </item>
    <item>
      <title>Learning High-Order Relationships of Brain Regions</title>
      <link>https://arxiv.org/abs/2312.02203</link>
      <description>arXiv:2312.02203v3 Announce Type: replace 
Abstract: Discovering reliable and informative relationships among brain regions from functional magnetic resonance imaging (fMRI) signals is essential in phenotypic predictions. Most of the current methods fail to accurately characterize those interactions because they only focus on pairwise connections and overlook the high-order relationships of brain regions. We propose that these high-order relationships should be maximally informative and minimally redundant (MIMR). However, identifying such high-order relationships is challenging and under-explored due to the exponential search space and the absence of a tractable objective. In response to this gap, we propose a novel method named HYBRID which aims to extract MIMR high-order relationships from fMRI data. HYBRID employs a CONSTRUCTOR to identify hyperedge structures, and a WEIGHTER to compute a weight for each hyperedge, which avoids searching in exponential space. HYBRID achieves the MIMR objective through an innovative information bottleneck framework named multi-head drop-bottleneck with theoretical guarantees. Our comprehensive experiments demonstrate the effectiveness of our model. Our model outperforms the state-of-the-art predictive model by an average of 11.2%, regarding the quality of hyperedges measured by CPM, a standard protocol for studying brain connections.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.02203v3</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weikang Qiu, Huangrui Chu, Selena Wang, Haolan Zuo, Xiaoxiao Li, Yize Zhao, Rex Ying</dc:creator>
    </item>
    <item>
      <title>Modeling of Memory Mechanisms in Cerebral Cortex and Simulation of Storage Performance</title>
      <link>https://arxiv.org/abs/2401.00381</link>
      <description>arXiv:2401.00381v2 Announce Type: replace 
Abstract: At the intersection of computation and cognitive science, graph theory is utilized as a formalized description of complex relationships and structures. Traditional graph models are often static, lacking dynamic and autonomous behavioral patterns. They rely on algorithms with a global view, significantly differing from biological neural networks, in which, to simulate information storage and retrieval processes, the limitations of centralized algorithms must be overcome. This study introduces a directed graph model that equips each node with adaptive learning and decision-making capabilities, thereby facilitating decentralized dynamic information storage and modeling and simulation of the brain's memory process. We abstract different storage instances as directed graph paths, transforming the storage of information into the assignment, discrimination, and extraction of different paths. To address writing and reading challenges, each node has a personalized adaptive learning ability. A storage algorithm without a God's eye view is developed, where each node uses its limited neighborhood information to facilitate the extension, formation, solidification, and awakening of directed graph paths, achieving competitive, reciprocal, and sustainable utilization of limited resources. Storage behavior occurs in each node, with adaptive learning behaviors of nodes concretized in a microcircuit centered around a variable resistor, simulating the electrophysiological behavior of neurons. Under the constraints of neurobiology on the anatomy and electrophysiology of biological neural networks, this model offers a plausible explanation for the mechanism of memory realization, providing a comprehensive, system-level experimental validation of the memory trace theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.00381v2</guid>
      <category>q-bio.NC</category>
      <category>cs.DC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hui Wei, Chenyue Feng, Jianning Zhang</dc:creator>
    </item>
    <item>
      <title>Simple Network Mechanism Leads to Quasi-Real Brain Activation Patterns with Drosophila Connectome</title>
      <link>https://arxiv.org/abs/2404.17128</link>
      <description>arXiv:2404.17128v2 Announce Type: replace 
Abstract: Considering the high computational demands of most methods, using network communication models to simulate the brain is a more economical way. However, there is still insufficient evidence that they can effectively replicate the brains' real activation patterns. Moreover, it remains unclear whether actual network structures are crucial in simulating intelligence. Addressing these issues, we propose a large scale network communication model based on simple rules and design criteria to assess the differences between network models and real situations. To enhance the connection with the real world, we also incorporate an improved neuron dynamic model. We conduct research on the biggest adult Drosophila connectome data set. Experimental results show significant activation in neurons that should respond to stimulus and slight activation in irrelevant ones, which we call quasi-real activation pattern. Besides, when changing the network structure, the quasi-activation patterns disappear. Interestingly, activation regions have shorter network distances to their input neurons, implying that the network structure (not spatial distance) is the core to form brain functionality. In addition, giving input neurons a unilateral stimulus, we observe a bilateral response, which is consistent with reality. Then we find that both hemispheres have extremely similar statistical indicators. We also develop real-time 3D large spatial network visualization software to observe experimental phenomena, filling the software gap. This research reveals network models' power: it can reach the quasi-activation pattern with simple rules. Besides, it proves network structure matters in brain activity pattern generation. Future research could fully simulate brain behavior through network models, paving the way for artificial intelligence by developing new propagation rules and optimizing link weights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17128v2</guid>
      <category>q-bio.NC</category>
      <category>cs.SI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaoyu Zhang, Pengcheng Yang, Jiawei Feng, Qiang Luo, Wei Lin, Xin Lu</dc:creator>
    </item>
    <item>
      <title>GET: A Generative EEG Transformer for Continuous Context-Based Neural Signals</title>
      <link>https://arxiv.org/abs/2406.03115</link>
      <description>arXiv:2406.03115v3 Announce Type: replace 
Abstract: Generating continuous electroencephalography (EEG) signals through advanced artificial neural networks presents a novel opportunity to enhance brain-computer interface (BCI) technology. This capability has the potential to significantly enhance applications ranging from simulating dynamic brain activity and data augmentation to improving real-time epilepsy detection and BCI inference. By harnessing generative transformer neural networks, specifically designed for EEG signal generation, we can revolutionize the interpretation and interaction with neural data. Generative AI has demonstrated significant success across various domains, from natural language processing (NLP) and computer vision to content creation in visual arts and music. It distinguishes itself by using large-scale datasets to construct context windows during pre-training, a technique that has proven particularly effective in NLP, where models are fine-tuned for specific downstream tasks after extensive foundational training. However, the application of generative AI in the field of BCIs, particularly through the development of continuous, context-rich neural signal generators, has been limited. To address this, we introduce the Generative EEG Transformer (GET), a model leveraging transformer architecture tailored for EEG data. The GET model is pre-trained on diverse EEG datasets, including motor imagery and alpha wave datasets, enabling it to produce high-fidelity neural signals that maintain contextual integrity. Our empirical findings indicate that GET not only faithfully reproduces the frequency spectrum of the training data and input prompts but also robustly generates continuous neural signals. By adopting the successful training strategies of the NLP domain for BCIs, the GET sets a new standard for the development and application of neural signal generation technologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03115v3</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Omair Ali, Muhammad Saif-ur-Rehman, Marita Metzler, Tobias Glasmachers, Ioannis Iossifidis, Christian Klaes</dc:creator>
    </item>
    <item>
      <title>ITCMA: A Generative Agent Based on a Computational Consciousness Structure</title>
      <link>https://arxiv.org/abs/2403.20097</link>
      <description>arXiv:2403.20097v2 Announce Type: replace-cross 
Abstract: Large Language Models (LLMs) still face challenges in tasks requiring understanding implicit instructions and applying common-sense knowledge. In such scenarios, LLMs may require multiple attempts to achieve human-level performance, potentially leading to inaccurate responses or inferences in practical environments, affecting their long-term consistency and behavior. This paper introduces the Internal Time-Consciousness Machine (ITCM), a computational consciousness structure to simulate the process of human consciousness. We further propose the ITCM-based Agent (ITCMA), which supports action generation and reasoning in open-world settings, and can independently complete tasks. ITCMA enhances LLMs' ability to understand implicit instructions and apply common-sense knowledge by considering agents' interaction and reasoning with the environment. Evaluations in the Alfworld environment show that trained ITCMA outperforms the state-of-the-art (SOTA) by 9% on the seen set. Even untrained ITCMA achieves a 96% task completion rate on the seen set, 5% higher than SOTA, indicating its superiority over traditional intelligent agents in utility and generalization. In real-world tasks with quadruped robots, the untrained ITCMA achieves an 85% task completion rate, which is close to its performance in the unseen set, demonstrating its comparable utility and universality in real-world settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.20097v2</guid>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hanzhong Zhang, Jibin Yin, Haoyang Wang, Ziwei Xiang</dc:creator>
    </item>
  </channel>
</rss>
