<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DC</link>
    <description>cs.DC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 21 Feb 2025 02:45:20 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Beeping Deterministic CONGEST Algorithms in Graphs</title>
      <link>https://arxiv.org/abs/2502.13424</link>
      <description>arXiv:2502.13424v1 Announce Type: new 
Abstract: The Beeping Network (BN) model captures important properties of biological processes. Paradoxically, the extremely limited communication capabilities of such nodes has helped BN become one of the fundamental models for networks. Since in each round, a node may transmit at most one bit, it is useful to treat the communications in the network as distributed coding and design it to overcome the interference. We study both non-adaptive and adaptive codes. Some communication and graph problems already studied in BN admit fast randomized algorithms. On the other hand, all known deterministic algorithms for non-trivial problems have time complexity at least polynomial in the maximum node-degree $\Delta$.
  We improve known results for deterministic algorithms showing that beeping out a single round of any congest algorithm in any network can be done in $O(\Delta^2 \log^{O(1)} n)$ beeping rounds, even if the nodes intend to send different messages to different neighbors. This upper bound reduces polynomially the time for a deterministic simulation of congest in a BN, comparing to the best known algorithms, and nearly matches the time obtained recently using. Our simulator allows us to implement any efficient algorithm designed for the congest networks in BN, with $O(\Delta^2 \log^{O(1)} n)$ overhead. This $O(\Delta^2 \log^{O(1)} n)$ implementation results in a polynomial improvement upon the best-to-date $\Theta(\Delta^3)$-round beeping MIS algorithm. Using a more specialized transformer and some additional machinery, we constructed various other efficient deterministic Beeping algorithms for other commonly used building blocks, such as Network Decomposition. For $h$-hop simulations, we prove a lower bound $\Omega(\Delta^{h+1})$, and we design a nearly matching algorithm that is able to ``pipeline'' the information in a faster way than working layer by layer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13424v1</guid>
      <category>cs.DC</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pawel Garncarek, Dariusz R. Kowalski, Shay Kutten, Miguel A. Mosteiro</dc:creator>
    </item>
    <item>
      <title>Astra: Efficient and Money-saving Automatic Parallel Strategies Search on Heterogeneous GPUs</title>
      <link>https://arxiv.org/abs/2502.13480</link>
      <description>arXiv:2502.13480v1 Announce Type: new 
Abstract: In this paper, we introduce an efficient and money-saving automatic parallel strategies search framework on heterogeneous GPUs: Astra. First, Astra searches for the efficiency-optimal parallel strategy in both GPU configurations search space (GPU types and GPU numbers) and parallel parameters search space. Then, Astra also provides the solution on heterogeneous GPUs by mathematically modeling the time consumption of heterogeneous training. At last, Astra is the first to propose the automatic parallel strategy search on money-saving. The experiment results demonstrate that Astra can achieve better throughput than expert-designed strategies. The search time cost for Astra can also be limited to 1.27 seconds in a single-GPU setting and less than 1.35 minutes in a heterogeneous-GPU setting on average with an accuracy of over 95%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13480v1</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peiran Wang, Haibing Li, Fu Haohan, Shiyong Li, Yanpeng Wang, Dou Shen</dc:creator>
    </item>
    <item>
      <title>GENIO: Synergizing Edge Computing with Optical Network Infrastructures</title>
      <link>https://arxiv.org/abs/2502.13657</link>
      <description>arXiv:2502.13657v1 Announce Type: new 
Abstract: Edge computing has emerged as a paradigm to bring low-latency and bandwidth-intensive applications close to end-users. However, edge computing platforms still face challenges related to resource constraints, connectivity, and security. We present GENIO, a novel platform that integrates edge computing within existing Passive Optical Network (PON) infrastructures. GENIO enhances central offices with computational and storage resources, enabling telecom operators to leverage their existing PON networks as a distributed edge computing infrastructure. Through simulations, we show the feasibility of GENIO in supporting real-world edge scenarios, and its better performance compared to a traditional edge computing architecture.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13657v1</guid>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/MCOM.002.2400382</arxiv:DOI>
      <dc:creator>Carmine Cesarano, Alessio Foggia, Gianluca Roscigno, Luca Andreani, Roberto Natella</dc:creator>
    </item>
    <item>
      <title>Performance optimization of BLAS algorithms with band matrices for RISC-V processors</title>
      <link>https://arxiv.org/abs/2502.13839</link>
      <description>arXiv:2502.13839v1 Announce Type: new 
Abstract: The rapid development of RISC-V instruction set architecture presents new opportunities and challenges for software developers. Is it sufficient to simply recompile high-performance software optimized for x86-64 onto RISC-V CPUs? Are current compilers capable of effectively optimizing C and C++ codes or is it necessary to use intrinsics or assembler? Can we analyze and improve performance without well-developed profiling tools? Do standard optimization techniques work? Are there specific RISC-V features that need to be considered? These and other questions require careful consideration. In this paper, we present our experience optimizing four BLAS algorithms for band matrix operations on RISC-V processors. We demonstrate how RISC-V-optimized implementations of OpenBLAS algorithms can be significantly accelerated through improved vectorization of computationally intensive loops. Experiments on Lichee Pi 4A and Banana Pi BPI-F3 devices using RVV 0.7.1 and RVV 1.0 vector instruction sets respectively, show speedups of 1.5x to 10x depending on the operation compared to the OpenBLAS baseline. In particular, the successful use of vector register grouping with RVV can lead to significant performance improvements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13839v1</guid>
      <category>cs.DC</category>
      <category>cs.PF</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anna Pirova, Anastasia Vodeneeva, Konstantin Kovalev, Alexander Ustinov, Evgeny Kozinov, Alexey Liniov, Valentin Volokitin, Iosif Meyerov</dc:creator>
    </item>
    <item>
      <title>Strong and Hiding Distributed Certification of $k$-Coloring</title>
      <link>https://arxiv.org/abs/2502.13854</link>
      <description>arXiv:2502.13854v1 Announce Type: new 
Abstract: A locally checkable proof (LCP) is a non-deterministic distributed algorithm designed to verify global properties of a graph $G$. It involves two key components: a prover and a distributed verifier. The prover is an all-powerful computational entity capable of performing any Turing-computable operation instantaneously. Its role is to convince the distributed verifier -- composed of the graph's nodes -- that $G$ satisfies a particular property $\Pi$.
  We study the problem of certifying whether a graph is $k$-colorable with an LCP that is able to hide the $k$-coloring from the verifier. More precisely, we say an LCP for $k$-coloring is hiding if, in a yes-instance, it is possible to assign certificates to nodes without revealing an explicit $k$-coloring. Motivated by the search for promise-free separations of extensions of the LOCAL model in the context of locally checkable labeling (LCL) problems, we also require the LCPs to satisfy what we refer to as the strong soundness property. This is a strengthening of soundness that requires that, in a no-instance (i.e., a non-$k$-colorable graph) and for every certificate assignment, the subset of accepting nodes must induce a $k$-colorable subgraph.
  We focus on the case of $2$-coloring. We show that strong and hiding LCPs for $2$-coloring exist in specific graph classes and requiring only $O(\log n)$-sized certificates. Furthermore, when the input is promised to be a cycle or contains a node of degree $1$, we show the existence of strong and hiding LCPs even in an anonymous network and with constant-size certificates.
  Despite these upper bounds, we prove that there are no strong and hiding LCPs for $2$-coloring in general, regardless of certificate size. The proof relies on a Ramsey-type result as well as an intricate argument about the realizability of subgraphs of the neighborhood graph consisting of the accepting views of an LCP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13854v1</guid>
      <category>cs.DC</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Augusto Modanese, Pedro Montealegre, Mart\'in R\'ios-Wilson</dc:creator>
    </item>
    <item>
      <title>Performance Comparison of Graph Representations Which Support Dynamic Graph Updates</title>
      <link>https://arxiv.org/abs/2502.13862</link>
      <description>arXiv:2502.13862v1 Announce Type: new 
Abstract: Research in graph-structured data has grown rapidly due to graphs' ability to represent complex real-world information and capture intricate relationships, particularly as many real-world graphs evolve dynamically through edge/vertex insertions and deletions. This has spurred interest in programming frameworks for managing, maintaining, and processing such dynamic graphs. In this report, we evaluate the performance of PetGraph (Rust), Stanford Network Analysis Platform (SNAP), SuiteSparse:GraphBLAS, cuGraph, Aspen, and our custom implementation in tasks including loading graphs from disk to memory, cloning loaded graphs, applying in-place edge deletions/insertions, and performing a simple iterative graph traversal algorithm. Our implementation demonstrates significant performance improvements: it outperforms PetGraph, SNAP, SuiteSparse:GraphBLAS, cuGraph, and Aspen by factors of 177x, 106x, 76x, 17x, and 3.3x in graph loading; 20x, 235x, 0.24x, 1.3x, and 0x in graph cloning; 141x/45x, 44x/25x, 13x/11x, 28x/34x, and 3.5x/2.2x in edge deletions/insertions; and 67x/63x, 86x/86x, 2.5x/2.6x, 0.25x/0.24x, and 1.3x/1.3x in traversal on updated graphs with deletions/insertions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13862v1</guid>
      <category>cs.DC</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Subhajit Sahu</dc:creator>
    </item>
    <item>
      <title>Smoothed Normalization for Efficient Distributed Private Optimization</title>
      <link>https://arxiv.org/abs/2502.13482</link>
      <description>arXiv:2502.13482v1 Announce Type: cross 
Abstract: Federated learning enables training machine learning models while preserving the privacy of participants. Surprisingly, there is no differentially private distributed method for smooth, non-convex optimization problems. The reason is that standard privacy techniques require bounding the participants' contributions, usually enforced via $\textit{clipping}$ of the updates. Existing literature typically ignores the effect of clipping by assuming the boundedness of gradient norms or analyzes distributed algorithms with clipping but ignores DP constraints. In this work, we study an alternative approach via $\textit{smoothed normalization}$ of the updates motivated by its favorable performance in the single-node setting. By integrating smoothed normalization with an error-feedback mechanism, we design a new distributed algorithm $\alpha$-$\sf NormEC$. We prove that our method achieves a superior convergence rate over prior works. By extending $\alpha$-$\sf NormEC$ to the DP setting, we obtain the first differentially private distributed optimization algorithm with provable convergence guarantees. Finally, our empirical results from neural network training indicate robust convergence of $\alpha$-$\sf NormEC$ across different parameter settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13482v1</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Egor Shulgin, Sarit Khirirat, Peter Richt\'arik</dc:creator>
    </item>
    <item>
      <title>Autellix: An Efficient Serving Engine for LLM Agents as General Programs</title>
      <link>https://arxiv.org/abs/2502.13965</link>
      <description>arXiv:2502.13965v1 Announce Type: cross 
Abstract: Large language model (LLM) applications are evolving beyond simple chatbots into dynamic, general-purpose agentic programs, which scale LLM calls and output tokens to help AI agents reason, explore, and solve complex tasks. However, existing LLM serving systems ignore dependencies between programs and calls, missing significant opportunities for optimization. Our analysis reveals that programs submitted to LLM serving engines experience long cumulative wait times, primarily due to head-of-line blocking at both the individual LLM request and the program. To address this, we introduce Autellix, an LLM serving system that treats programs as first-class citizens to minimize their end-to-end latencies. Autellix intercepts LLM calls submitted by programs, enriching schedulers with program-level context. We propose two scheduling algorithms-for single-threaded and distributed programs-that preempt and prioritize LLM calls based on their programs' previously completed calls. Our evaluation demonstrates that across diverse LLMs and agentic workloads, Autellix improves throughput of programs by 4-15x at the same latency compared to state-of-the-art systems, such as vLLM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13965v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Luo, Xiaoxiang Shi, Colin Cai, Tianjun Zhang, Justin Wong, Yichuan Wang, Chi Wang, Yanping Huang, Zhifeng Chen, Joseph E. Gonzalez, Ion Stoica</dc:creator>
    </item>
    <item>
      <title>Asynchronous BFT Asset Transfer: Quasi-Anonymous, Light, and Consensus-Free</title>
      <link>https://arxiv.org/abs/2405.18072</link>
      <description>arXiv:2405.18072v2 Announce Type: replace 
Abstract: This paper introduces a new asynchronous Byzantine-tolerant asset transfer system (cryptocurrency) with three noteworthy properties: quasi-anonymity, lightness, and consensus-freedom. Quasi-anonymity means no information is leaked regarding the receivers and amounts of the asset transfers. Lightness means that the underlying cryptographic schemes are \textit{succinct} (\textit{i.e.}, they produce short-sized and quickly verifiable proofs) and each process only stores its own transfers while keeping communication cost as low as possible. Consensus-freedom means the system does not rely on a total order of asset transfers. The proposed algorithm is the first asset transfer system that simultaneously fulfills all these properties in the presence of asynchrony and Byzantine processes. To obtain them, the paper adopts a modular approach combining a new distributed object called ``agreement proof'' and well-known techniques such as commitments, universal accumulators, and zero-knowledge proofs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18072v2</guid>
      <category>cs.DC</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Timoth\'e Albouy (WIDE), Emmanuelle Anceaume (PIRAT), Davide Frey (WIDE), Mathieu Gestin (WIDE), Arthur Rauch (WIDE), Michel Raynal (WIDE), Fran\c{c}ois Ta\"iani (WIDE)</dc:creator>
    </item>
    <item>
      <title>Signature-based IaaS Performance Change Detection</title>
      <link>https://arxiv.org/abs/2410.17623</link>
      <description>arXiv:2410.17623v2 Announce Type: replace 
Abstract: We propose a novel change detection framework to identify changes in the long-term performance behavior of an IaaS service. An IaaS service's long-term performance behavior is represented by an IaaS performance signature. The proposed framework leverages time series similarity measures and a sliding window technique to detect changes in IaaS performance signatures. We introduce a new IaaS performance noise model that enables the proposed framework to distinguish between performance noise and actual changes in performance. The proposed framework utilizes a novel Signal-to-Noise Ratio (SNR) based approach to detect changes when prior knowledge about performance noise is available. A set of experiments is conducted using real-world datasets to demonstrate the effectiveness of the proposed change detection framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.17623v2</guid>
      <category>cs.DC</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3702228</arxiv:DOI>
      <arxiv:journal_reference>ACM Trans. Internet Technol. 25, 1, Article 2 (February 2025), 21 pages</arxiv:journal_reference>
      <dc:creator>Sheik Mohammad Mostakim Fattah, Athman Bouguettaya</dc:creator>
    </item>
    <item>
      <title>Future Resource Bank for ISAC: Achieving Fast and Stable Win-Win Matching for Both Individuals and Coalitions</title>
      <link>https://arxiv.org/abs/2502.08118</link>
      <description>arXiv:2502.08118v4 Announce Type: replace 
Abstract: Future wireless networks must support emerging applications where environmental awareness is as critical as data transmission. Integrated Sensing and Communication (ISAC) enables this vision by allowing base stations (BSs) to allocate bandwidth and power to mobile users (MUs) for communications and cooperative sensing. However, this resource allocation is highly challenging due to: (i) dynamic resource demands from MUs and resource supply from BSs, and (ii) the selfishness of MUs and BSs. To address these challenges, existing solutions rely on either real-time (online) resource trading, which incurs high overhead and failures, or static long-term (offline) resource contracts, which lack flexibility. To overcome these limitations, we propose the Future Resource Bank for ISAC, a hybrid trading framework that integrates offline and online resource allocation through a level-wise client model, where MUs and their coalitions negotiate with BSs. We introduce two mechanisms: (i) Role-Friendly Win-Win Matching (offRFW$^2$M), leveraging overbooking to establish risk-aware, stable contracts, and (ii) Effective Backup Win-Win Matching (onEBW$^2$M), which dynamically reallocates unmet demand and surplus supply. We theoretically prove stability, individual rationality, and weak Pareto optimality of these mechanisms. Through simulations, we show that our framework improves social welfare, latency, and energy efficiency compared to existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08118v4</guid>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Houyi Qi, Minghui Liwang, Seyyedali Hosseinalipour, Liqun Fu, Sai Zou, Wei Ni</dc:creator>
    </item>
    <item>
      <title>SparkAttention: High-Performance Multi-Head Attention for Large Models on Volta GPU Architecture</title>
      <link>https://arxiv.org/abs/2502.12784</link>
      <description>arXiv:2502.12784v2 Announce Type: replace 
Abstract: Transformer are widely used in various fields such as natural language processing and computer vision. However, the training time for large Transformer models can be challenging due to the Multi-Head Attention (MHA) mechanism. Especially as models become larger, training becomes more costly. So it is crucial to utilize various resources for efficient model training. Currently, NVIDIA Volta GPU is still widely used. However, because the computational shapes supported by Tensor Core Units (TCU) of Volta GPU differ from other GPU architectures, most efforts have not focused on using them to accelerate Transformer training. To address this issue, we propose SparkAttention, an acceleration library designed to speed up MHA training on the Volta GPU. SparkAttention leverages TCU and kernel fusion to reduce the number of high bandwidth memory (HBM) accesses and overhead. Our End-to-End experimental results on an NVIDIA V100 GPU show that SparkAttention achieves on average 1.80$\times$ (up to 2.46$\times$) speedup compared to using PyTorch.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12784v2</guid>
      <category>cs.DC</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Youxuan Xu, Tong Wu, Shigang Li, Xueying Wang, Jingjing Wang</dc:creator>
    </item>
    <item>
      <title>Scalable Decentralized Algorithms for Online Personalized Mean Estimation</title>
      <link>https://arxiv.org/abs/2402.12812</link>
      <description>arXiv:2402.12812v4 Announce Type: replace-cross 
Abstract: In numerous settings, agents lack sufficient data to directly learn a model. Collaborating with other agents may help, but it introduces a bias-variance trade-off, when local data distributions differ. A key challenge is for each agent to identify clients with similar distributions while learning the model, a problem that remains largely unresolved. This study focuses on a simplified version of the overarching problem, where each agent collects samples from a real-valued distribution over time to estimate its mean. Existing algorithms face impractical space and time complexities (quadratic in the number of agents A). To address scalability challenges, we propose a framework where agents self-organize into a graph, allowing each agent to communicate with only a selected number of peers r. We introduce two collaborative mean estimation algorithms: one draws inspiration from belief propagation, while the other employs a consensus-based approach, with complexity of O( r |A| log |A|) and O(r |A|), respectively. We establish conditions under which both algorithms yield asymptotically optimal estimates and offer a theoretical characterization of their performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.12812v4</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Franco Galante, Giovanni Neglia, Emilio Leonardi</dc:creator>
    </item>
    <item>
      <title>Sampling-based Distributed Training with Message Passing Neural Network</title>
      <link>https://arxiv.org/abs/2402.15106</link>
      <description>arXiv:2402.15106v4 Announce Type: replace-cross 
Abstract: In this study, we introduce a domain-decomposition-based distributed training and inference approach for message-passing neural networks (MPNN). Our objective is to address the challenge of scaling edge-based graph neural networks as the number of nodes increases. Through our distributed training approach, coupled with Nystr\"om-approximation sampling techniques, we present a scalable graph neural network, referred to as DS-MPNN (D and S standing for distributed and sampled, respectively), capable of scaling up to $O(10^5)$ nodes. We validate our sampling and distributed training approach on two cases: (a) a Darcy flow dataset and (b) steady RANS simulations of 2-D airfoils, providing comparisons with both single-GPU implementation and node-based graph convolution networks (GCNs). The DS-MPNN model demonstrates comparable accuracy to single-GPU implementation, can accommodate a significantly larger number of nodes compared to the single-GPU variant (S-MPNN), and significantly outperforms the node-based GCN.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.15106v4</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>physics.flu-dyn</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Priyesh Kakka, Sheel Nidhan, Rishikesh Ranade, Jay Pathak, Jonathan F. MacArt</dc:creator>
    </item>
  </channel>
</rss>
