<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 15 Oct 2025 04:00:15 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 15 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Inpainting the Neural Picture: Inferring Unrecorded Brain Area Dynamics from Multi-Animal Datasets</title>
      <link>https://arxiv.org/abs/2510.11924</link>
      <description>arXiv:2510.11924v1 Announce Type: new 
Abstract: Characterizing interactions between brain areas is a fundamental goal of systems neuroscience. While such analyses are possible when areas are recorded simultaneously, it is rare to observe all combinations of areas of interest within a single animal or recording session. How can we leverage multi-animal datasets to better understand multi-area interactions? Building on recent progress in large-scale, multi-animal models, we introduce NeuroPaint, a masked autoencoding approach for inferring the dynamics of unrecorded brain areas. By training across animals with overlapping subsets of recorded areas, NeuroPaint learns to reconstruct activity in missing areas based on shared structure across individuals. We train and evaluate our approach on synthetic data and two multi-animal, multi-area Neuropixels datasets. Our results demonstrate that models trained across animals with partial observations can successfully in-paint the dynamics of unrecorded areas, enabling multi-area analyses that transcend the limitations of any single experiment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.11924v1</guid>
      <category>q-bio.NC</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <pubDate>Wed, 15 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ji Xia, Yizi Zhang, Shuqi Wang, Genevera I. Allen, Liam Paninski, Cole Lincoln Hurwitz, Kenneth D. Miller</dc:creator>
    </item>
    <item>
      <title>MAPS: Masked Attribution-based Probing of Strategies- A computational framework to align human and model explanations</title>
      <link>https://arxiv.org/abs/2510.12141</link>
      <description>arXiv:2510.12141v1 Announce Type: new 
Abstract: Human core object recognition depends on the selective use of visual information, but the strategies guiding these choices are difficult to measure directly. We present MAPS (Masked Attribution-based Probing of Strategies), a behaviorally validated computational tool that tests whether explanations derived from artificial neural networks (ANNs) can also explain human vision. MAPS converts attribution maps into explanation-masked images (EMIs) and compares image-by-image human accuracies on these minimal images with limited pixel budgets with accuracies on the full stimuli. MAPS provides a principled way to evaluate and choose among competing ANN interpretability methods. In silico, EMI-based behavioral similarity between models reliably recovers the ground-truth similarity computed from their attribution maps, establishing which explanation methods best capture the model's strategy. When applied to humans and macaques, MAPS identifies ANN-explanation combinations whose explanations align most closely with biological vision, achieving the behavioral validity of Bubble masks while requiring far fewer behavioral trials. Because it needs only access to model attributions and a modest set of behavioral data on the original images, MAPS avoids exhaustive psychophysics while offering a scalable tool for adjudicating explanations and linking human behavior, neural activity, and model decisions under a common standard.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.12141v1</guid>
      <category>q-bio.NC</category>
      <category>cs.CV</category>
      <pubDate>Wed, 15 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sabine Muzellec, Yousif Kashef Alghetaa, Simon Kornblith, Kohitij Kar</dc:creator>
    </item>
    <item>
      <title>Readout Representation: Redefining Neural Codes by Input Recovery</title>
      <link>https://arxiv.org/abs/2510.12228</link>
      <description>arXiv:2510.12228v1 Announce Type: new 
Abstract: Sensory representation is typically understood through a hierarchical-causal framework where progressively abstract features are extracted sequentially. However, this causal view fails to explain misrepresentation, a phenomenon better handled by an informational view based on decodable content. This creates a tension: how does a system that abstracts away details still preserve the fine-grained information needed for downstream functions? We propose readout representation to resolve this, defining representation by the information recoverable from features rather than their causal origin. Empirically, we show that inputs can be accurately reconstructed even from heavily perturbed mid-level features, demonstrating that a single input corresponds to a broad, redundant region of feature space, challenging the causal mapping perspective. To quantify this property, we introduce representation size, a metric linked to model robustness and representational redundancy. Our framework offers a new lens for analyzing how both biological and artificial neural systems learn complex features while maintaining robust, information-rich representations of the world.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.12228v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Wed, 15 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shunsuke Onoo, Yoshihiro Nagano, Yukiyasu Kamitani</dc:creator>
    </item>
    <item>
      <title>Non-linear associations of amyloid-$\beta$ with resting-state functional networks and their cognitive relevance in a large community-based cohort of cognitively normal older adults</title>
      <link>https://arxiv.org/abs/2510.12751</link>
      <description>arXiv:2510.12751v1 Announce Type: new 
Abstract: Background: Non-linear alterations in brain network connectivity may represent early neural signatures of Alzheimer's disease (AD) pathology in cognitively normal older adults. Understanding these changes and their cognitive relevance could provide sensitive biomarkers for early detection. Most prior studies recruited participants from memory clinics, often with subjective memory concerns, limiting generalizability.
  Methods: We examined 14 large-scale functional brain networks in 968 cognitively normal older adults recruited from the community using resting-state functional MRI, cerebrospinal fluid (CSF) biomarkers (amyloid-$\beta$ 1-42 [A$\beta$], total tau, phosphorylated tau 181), and neuropsychological assessments. Functional networks were identified using group independent component analysis.
  Results: Inverted U-shaped associations between CSF A$\beta$ and functional connectivity were observed in the precuneus network and ventral default mode network (DMN), but not in the dorsal DMN, indicating network-specific vulnerability to early amyloid pathology. Higher connectivity in A$\beta$-related networks, including dorsal and ventral DMN, precuneus, and posterior salience networks, was associated with better visual memory, visuospatial, and executive performance. No significant relationships were observed between CSF tau and functional connectivity.
  Conclusions: Using a large, community-based cohort, we demonstrate that non-linear alterations in functional connectivity occur in specific networks even during the asymptomatic phase of AD. Moreover, A$\beta$-related network connectivity is cognitively relevant, highlighting functional brain networks as promising imaging markers for early detection and prognosis of AD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.12751v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Wed, 15 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Junjie Wu, Benjamin B Risk, Taylor A James, Nicholas Seyfried, David W Loring, Felicia C Goldstein, Allan I Levey, James J Lah, Deqiang Qiu</dc:creator>
    </item>
    <item>
      <title>When Purple Perceived Only at Fixation: A Fixation and Distance-Dependent Color Illusion</title>
      <link>https://arxiv.org/abs/2509.11582</link>
      <description>arXiv:2509.11582v4 Announce Type: replace-cross 
Abstract: In this paper a novel optical illusion is described in which purple structures are perceived as purple at the point of fixation, while the surrounding structures of the same purple color are perceived toward a blue hue. As the viewing distance increases, a greater number of purple structures revert to a purple appearance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11582v4</guid>
      <category>physics.optics</category>
      <category>q-bio.NC</category>
      <pubDate>Wed, 15 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Hinnerk Schulz-Hildebrandt</dc:creator>
    </item>
    <item>
      <title>The Algorithmic Regulator</title>
      <link>https://arxiv.org/abs/2510.10300</link>
      <description>arXiv:2510.10300v2 Announce Type: replace-cross 
Abstract: The regulator theorem states that, under certain conditions, any optimal controller must embody a model of the system it regulates, grounding the idea that controllers embed, explicitly or implicitly, internal models of the controlled. This principle underpins neuroscience and predictive brain theories like the Free-Energy Principle or Kolmogorov/Algorithmic Agent theory. However, the theorem is only proven in limited settings. Here, we treat the deterministic, closed, coupled world-regulator system $(W,R)$ as a single self-delimiting program $p$ via a constant-size wrapper that produces the world output string~$x$ fed to the regulator. We analyze regulation from the viewpoint of the algorithmic complexity of the output, $K(x)$. We define $R$ to be a \emph{good algorithmic regulator} if it \emph{reduces} the algorithmic complexity of the readout relative to a null (unregulated) baseline $\varnothing$, i.e., \[ \Delta = K\big(O_{W,\varnothing}\big) - K\big(O_{W,R}\big) &gt; 0. \] We then prove that the larger $\Delta$ is, the more world-regulator pairs with high mutual algorithmic information are favored. More precisely, a complexity gap $\Delta &gt; 0$ yields \[ \Pr\big((W,R)\mid x\big) \le C\,2^{\,M(W{:}R)}\,2^{-\Delta}, \] making low $M(W{:}R)$ exponentially unlikely as $\Delta$ grows. This is an AIT version of the idea that ``the regulator contains a model of the world.'' The framework is distribution-free, applies to individual sequences, and complements the Internal Model Principle. Beyond this necessity claim, the same coding-theorem calculus singles out a \emph{canonical scalar objective} and implicates a \emph{planner}. On the realized episode, a regulator behaves \emph{as if} it minimized the conditional description length of the readout.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.10300v2</guid>
      <category>cs.CC</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <category>q-bio.NC</category>
      <pubDate>Wed, 15 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Giulio Ruffini</dc:creator>
    </item>
  </channel>
</rss>
