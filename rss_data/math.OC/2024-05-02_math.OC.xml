<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 02 May 2024 04:00:17 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 02 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Gaussianity and the Kalman Filter: A Simple Yet Complicated Relationship</title>
      <link>https://arxiv.org/abs/2405.00058</link>
      <description>arXiv:2405.00058v1 Announce Type: new 
Abstract: One of the most common misconceptions made about the Kalman filter when applied to linear systems is that it requires an assumption that all error and noise processes are Gaussian. This misconception has frequently led to the Kalman filter being dismissed in favor of complicated and/or purely heuristic approaches that are supposedly "more general" in that they can be applied to problems involving non-Gaussian noise. The fact is that the Kalman filter provides rigorous and optimal performance guarantees that do not rely on any distribution assumptions beyond mean and error covariance information. These guarantees even apply to use of the Kalman update formula when applied with nonlinear models, as long as its other required assumptions are satisfied. Here we discuss misconceptions about its generality that are often found and reinforced in the literature, especially outside the traditional fields of estimation and control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00058v1</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.46571/JCI.2022.1.2</arxiv:DOI>
      <arxiv:journal_reference>Journal de Ciencia e Ingenier\'ia, vol. 14, no. 1, pp. 21-26, 2022</arxiv:journal_reference>
      <dc:creator>Jeffrey Uhlmann, Simon Julier</dc:creator>
    </item>
    <item>
      <title>Successive Convexification for Nonlinear Model Predictive Control with Continuous-Time Constraint Satisfaction</title>
      <link>https://arxiv.org/abs/2405.00061</link>
      <description>arXiv:2405.00061v1 Announce Type: new 
Abstract: We propose a nonlinear model predictive control (NMPC) framework based on a direct optimal control method that ensures continuous-time constraint satisfaction and accurate evaluation of the running cost, without compromising computational efficiency. We leverage the recently proposed successive convexification framework for trajectory optimization, where: (1) the path constraints and running cost are equivalently reformulated by augmenting the system dynamics, (2) multiple shooting is used for exact discretization, and (3) a convergence-guaranteed sequential convex programming (SCP) algorithm, the prox-linear method, is used to solve the discretized receding-horizon optimal control problems. The resulting NMPC framework is computationally efficient, owing to its support for warm-starting and premature termination of SCP, and its reliance on first-order information only. We demonstrate the effectiveness of the proposed NMPC framework by means of a numerical example with reference-tracking and obstacle avoidance. The implementation is available at https://github.com/UW-ACL/nmpc-ctcs</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00061v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Samet Uzun, Purnanand Elango, Abhinav G. Kamath, Taewan Kim, Behcet Acikmese</dc:creator>
    </item>
    <item>
      <title>From Linear to Linearizable Optimization: A Novel Framework with Applications to Stationary and Non-stationary DR-submodular Optimization</title>
      <link>https://arxiv.org/abs/2405.00065</link>
      <description>arXiv:2405.00065v1 Announce Type: new 
Abstract: This paper introduces the notion of upper linearizable/quadratizable functions, a class that extends concavity and DR-submodularity in various settings, including monotone and non-monotone cases over different convex sets. A general meta-algorithm is devised to convert algorithms for linear/quadratic maximization into ones that optimize upper quadratizable functions, offering a unified approach to tackling concave and DR-submodular optimization problems. The paper extends these results to multiple feedback settings, facilitating conversions between semi-bandit/first-order feedback and bandit/zeroth-order feedback, as well as between first/zeroth-order feedback and semi-bandit/bandit feedback. Leveraging this framework, new projection-free algorithms are derived using Follow The Perturbed Leader (FTPL) and other algorithms as base algorithms for linear/convex optimization, improving upon state-of-the-art results in various cases. Dynamic and adaptive regret guarantees are obtained for DR-submodular maximization, marking the first algorithms to achieve such guarantees in these settings. Notably, the paper achieves these advancements with fewer assumptions compared to existing state-of-the-art results, underscoring its broad applicability and theoretical contributions to non-convex optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00065v1</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammad Pedramfar, Vaneet Aggarwal</dc:creator>
    </item>
    <item>
      <title>Small noise perturbations of stochastic ergodic control problems</title>
      <link>https://arxiv.org/abs/2405.00067</link>
      <description>arXiv:2405.00067v1 Announce Type: new 
Abstract: Using small noise limit approach, we study degenerate stochastic ergodic control problems and as a byproduct obtain error bounds for the $\varepsilon$-optimal controls. We also establish tunneling for a special ergodic control problem and give a representation of the ergodic value using the tunneled Markov chain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00067v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>K. Suresh Kumar, Vikrant Desai</dc:creator>
    </item>
    <item>
      <title>Bi-objective optimization of a VRP problem applied to urban solid waste collection through a model that includes the visual attraction of routes</title>
      <link>https://arxiv.org/abs/2405.00068</link>
      <description>arXiv:2405.00068v1 Announce Type: new 
Abstract: The compactness of routes in distribution plans is a criterion that has not been sufficiently explored in the literature related to logistics distribution but has shown to have a significant impact on the practical implementation of routing plans, for example in solid waste collection problems. In this regard, this article presents a bi-objective model to optimize the vehicle routing problem with time constraints, considering the minimization of travel times and the compactness of routes. Experimental tests were conducted on small-scale instances using two exact solution methods for multi-objective problems: weighted sum and augmented {\epsilon}-constraint methods. The results obtained allowed us to explore the trade-off relationship between both objectives while evaluating the computational efficiency of both multi-objective solution methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00068v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Diego Rossit, Adri\'an Toncovich</dc:creator>
    </item>
    <item>
      <title>An enhanced POSTA based on Nelder-Mead simplex search and quadratic interpolation</title>
      <link>https://arxiv.org/abs/2405.00122</link>
      <description>arXiv:2405.00122v1 Announce Type: new 
Abstract: State transition algorithm (STA) is a metaheuristic method for global optimization. Recently, a modified STA named parameter optimal state transition algorithm (POSTA) is proposed. In POSTA, the performance of expansion operator, rotation operator and axesion operator is optimized through a parameter selection mechanism. But due to the insufficient utilization of historical information, POSTA still suffers from slow convergence speed and low solution accuracy on specific problems. To make better use of the historical information, Nelder-Mead (NM) simplex search and quadratic interpolation (QI) are integrated into POSTA. The enhanced POSTA is tested against 14 benchmark functions with 20-D, 30-D and 50-D space. An experimental comparison with several competitive metaheuristic methods demonstrates the effectiveness of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00122v1</guid>
      <category>math.OC</category>
      <category>cs.NE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Tianyu Liu</dc:creator>
    </item>
    <item>
      <title>A variational approach to sampling in diffusion processes</title>
      <link>https://arxiv.org/abs/2405.00126</link>
      <description>arXiv:2405.00126v1 Announce Type: new 
Abstract: We revisit the work of Mitter and Newton on an information-theoretic interpretation of Bayes' formula through the Gibbs variational principle. This formulation allowed them to pose nonlinear estimation for diffusion processes as a problem in stochastic optimal control, so that the posterior density of the signal given the observation path could be sampled by adding a drift to the signal process. We show that this control-theoretic approach to sampling provides a common mechanism underlying several distinct problems involving diffusion processes, specifically importance sampling using Feynman-Kac averages, time reversal, and Schr\"odinger bridges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00126v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maxim Raginsky</dc:creator>
    </item>
    <item>
      <title>A Robust Optimization Approach to Network Control Using Local Information Exchange</title>
      <link>https://arxiv.org/abs/2405.00148</link>
      <description>arXiv:2405.00148v1 Announce Type: new 
Abstract: Designing policies for a network of agents is typically done by formulating an optimization problem where each agent has access to state measurements of all the other agents in the network. Such policy designs with centralized information exchange result in optimization problems that are typically hard to solve, require establishing substantial communication links, and do not promote privacy since all information is shared among the agents. Designing policies based on arbitrary communication structures can lead to non-convex optimization problems which are typically NP-hard. In this work, we propose an optimization framework for decentralized policy designs. In contrast to the centralized information exchange, our approach requires only local communication exchange among the neighboring agents matching the physical coupling of the network. Thus, each agent only requires information from its direct neighbors, minimizing the need for excessive communication and promoting privacy amongst the agents. Using robust optimization techniques, we formulate a convex optimization problem with a loosely coupled structure that can be solved efficiently. We numerically demonstrate the efficacy of the proposed approach in energy management and supply chain applications. We show that the proposed approach leads to solutions that closely approximate those obtained by the centralized formulation only at a fraction of the computational effort.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00148v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Georgios Darivianakis, Angelos Georghiou, Soroosh Shafiee, John Lygeros</dc:creator>
    </item>
    <item>
      <title>Real Stability and Log Concavity are coNP-Complete</title>
      <link>https://arxiv.org/abs/2405.00162</link>
      <description>arXiv:2405.00162v1 Announce Type: new 
Abstract: Real-stable, Lorentzian, and log-concave polynomials are well-studied classes of polynomials, and have been powerful tools in resolving several conjectures. We show that the problems of deciding whether a polynomial of fixed degree is real stable or log concave are coNP-complete. On the other hand, while all homogeneous real-stable polynomials are Lorentzian and all Lorentzian polynomials are log concave on the positive orthant, the problem of deciding whether a polynomial of fixed degree is Lorentzian can be solved in polynomial time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00162v1</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <category>math.CO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tracy Chin</dc:creator>
    </item>
    <item>
      <title>Rockafellian Relaxation for PDE-Constrained Optimization with Distributional Uncertainty</title>
      <link>https://arxiv.org/abs/2405.00176</link>
      <description>arXiv:2405.00176v1 Announce Type: new 
Abstract: Stochastic optimization problems are generally known to be ill-conditioned to the form of the underlying uncertainty. A framework is introduced for optimal control problems with partial differential equations as constraints that is robust to inaccuracies in the precise form of the problem uncertainty. The framework is based on problem relaxation and involves optimizing a bivariate, "Rockafellian" objective functional that features both a standard control variable and an additional perturbation variable that handles the distributional ambiguity. In the presence of distributional corruption, the Rockafellian objective functionals are shown in the appropriate settings to $\Gamma$-converge to uncorrupted objective functionals in the limit of vanishing corruption. Numerical examples illustrate the framework's utility for outlier detection and removal and for variance reduction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00176v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Harbir Antil, Sean P. Carney, Hugo D\'iaz, Johannes O. Royset</dc:creator>
    </item>
    <item>
      <title>Prescribed-Time Stability Properties of Interconnected Systems</title>
      <link>https://arxiv.org/abs/2405.00224</link>
      <description>arXiv:2405.00224v1 Announce Type: new 
Abstract: Achieving control objectives (e.g., stabilization or convergence of tracking error to zero, input-to-state stabilization) in "prescribed time" has attracted significant research interest in recent years. The key property of prescribed-time results unlike traditional "asymptotic" results is that the convergence or other control objectives are achieved within an arbitrary designer-specified time interval instead of asymptotically as time goes to infinity. In this paper, we consider cascade and feedback interconnections of prescribed-time input-to-state stable (ISS) systems and study conditions under which the overall states of such interconnected systems also converge to the origin in the prescribed time interval. We show that these conditions are intrinsically related to properties of the time-varying "blow-up" functions that are central to prescribed-time control designs. We also generalize the results to interconnections of an arbitrary number of systems. As an illustrative example, we consider an interconnection of two uncertain systems that are prescribed-time stabilized using two different control design methods and show that the two separate controllers can be put together to achieve prescribed-time stability of the interconnected system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00224v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Prashanth Krishnamurthy, Farshad Khorrami, Anthony Tzes</dc:creator>
    </item>
    <item>
      <title>A decomposition-based approach for large-scale pickup and delivery problems</title>
      <link>https://arxiv.org/abs/2405.00230</link>
      <description>arXiv:2405.00230v1 Announce Type: new 
Abstract: With the advent of self-driving cars, experts envision autonomous mobility-on-demand services in the near future to cope with overloaded transportation systems in cities worldwide. Efficient operations are imperative to unlock such a system's maximum improvement potential. Existing approaches either consider a narrow planning horizon or ignore essential characteristics of the underlying problem. In this paper, we develop an algorithmic framework that allows the study of very large-scale pickup and delivery routing problems with more than 20 thousand requests, which arise in the context of integrated request pooling and vehicle-to-request dispatching. We conduct a computational study and present comparative results showing the characteristics of the developed approaches. Furthermore, we apply our algorithm to related benchmark instances from the literature to show the efficacy. Finally, we solve very large-scale instances and derive insights on upper-bound improvements regarding fleet sizing and customer delay acceptance from a practical perspective.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00230v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>G. Hiermann, M. Schiffer</dc:creator>
    </item>
    <item>
      <title>MF-OML: Online Mean-Field Reinforcement Learning with Occupation Measures for Large Population Games</title>
      <link>https://arxiv.org/abs/2405.00282</link>
      <description>arXiv:2405.00282v1 Announce Type: new 
Abstract: Reinforcement learning for multi-agent games has attracted lots of attention recently. However, given the challenge of solving Nash equilibria for large population games, existing works with guaranteed polynomial complexities either focus on variants of zero-sum and potential games, or aim at solving (coarse) correlated equilibria, or require access to simulators, or rely on certain assumptions that are hard to verify. This work proposes MF-OML (Mean-Field Occupation-Measure Learning), an online mean-field reinforcement learning algorithm for computing approximate Nash equilibria of large population sequential symmetric games. MF-OML is the first fully polynomial multi-agent reinforcement learning algorithm for provably solving Nash equilibria (up to mean-field approximation gaps that vanish as the number of players $N$ goes to infinity) beyond variants of zero-sum and potential games. When evaluated by the cumulative deviation from Nash equilibria, the algorithm is shown to achieve a high probability regret bound of $\tilde{O}(M^{3/4}+N^{-1/2}M)$ for games with the strong Lasry-Lions monotonicity condition, and a regret bound of $\tilde{O}(M^{11/12}+N^{- 1/6}M)$ for games with only the Lasry-Lions monotonicity condition, where $M$ is the total number of episodes and $N$ is the number of agents of the game. As a byproduct, we also obtain the first tractable globally convergent computational algorithm for computing approximate Nash equilibria of monotone mean-field games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00282v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anran Hu, Junzi Zhang</dc:creator>
    </item>
    <item>
      <title>A Zero-Sum Differential Game with Exit Time</title>
      <link>https://arxiv.org/abs/2405.00371</link>
      <description>arXiv:2405.00371v1 Announce Type: new 
Abstract: The paper is concerned with a zero-sum differential game in the case where a payoff is determined by the exit time, that is, the first time when the system leaves the game domain. Additionally, we assume that a part of domain's boundary is a lifeline where the payoff is infinite. Hereby, the examined problem generalizes the well-known time-optimal problem as well as time-optimal problem with lifeline. The main result of the paper relies on the solution to the Direchlet problem for the Hamilton-Jacobi equation associated with the game with exit time. We prove the existence of the value function for examined problem and construct suboptimal feedback strategies under assumption that the associated Dirichlet problem for the Hamilton-Jacobi equation admits a viscosity/minimax solution. Additionally, we derive a sufficient condition of existence result to this Dirichlet problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00371v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ekaterina Kolpakova</dc:creator>
    </item>
    <item>
      <title>Employing Federated Learning for Training Autonomous HVAC Systems</title>
      <link>https://arxiv.org/abs/2405.00389</link>
      <description>arXiv:2405.00389v1 Announce Type: new 
Abstract: Buildings account for 40 % of global energy consumption. A considerable portion of building energy consumption stems from heating, ventilation, and air conditioning (HVAC), and thus implementing smart, energy-efficient HVAC systems has the potential to significantly impact the course of climate change. In recent years, model-free reinforcement learning algorithms have been increasingly assessed for this purpose due to their ability to learn and adapt purely from experience. They have been shown to outperform classical controllers in terms of energy cost and consumption, as well as thermal comfort. However, their weakness lies in their relatively poor data efficiency, requiring long periods of training to reach acceptable policies, making them inapplicable to real-world controllers directly. Hence, common research goals are to improve the learning speed, as well as to improve their ability to generalize, in order to facilitate transfer learning to unseen building environments. In this paper, we take a federated learning approach to training the reinforcement learning controller of an HVAC system. A global control policy is learned by aggregating local policies trained on multiple data centers located in different climate zones. The goal of the policy is to simultaneously minimize energy consumption and maximize thermal comfort. The federated optimization strategy indirectly increases both the rate at which experience data is collected and the variation in the data. We demonstrate through experimental evaluation that these effects lead to a faster learning speed, as well as greater generalization capabilities in the federated policy compared to any individually trained policy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00389v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fredrik Hagstr\"om, Vikas Garg, Fabricio Oliveira</dc:creator>
    </item>
    <item>
      <title>A Modelling Framework for Energy-Management and Eco-Driving Problems using Convex Relaxations</title>
      <link>https://arxiv.org/abs/2405.00447</link>
      <description>arXiv:2405.00447v1 Announce Type: new 
Abstract: This paper presents a convex optimization framework for eco-driving and vehicle energy management problems. We will first show that several types of eco-driving and vehicle energy management problems can be modelled using the same notions of energy storage buffers and energy storage converters that are connected to a power network. It will be shown that these problems can be formulated as optimization problems with linear cost functions and linear dynamics, and nonlinear constraints representing the power converters. We will show that under some mild conditions, the (non-convex) optimization problem has the same (globally) optimal solution as a convex relaxation. This means that the problems can be solved efficiently and that the solution is guaranteed to be globally optimal. Finally, a numerical example of the eco-driving problem is used to illustrate this claim.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00447v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Y. J. J. Heuts, M. C. F. Donkers</dc:creator>
    </item>
    <item>
      <title>Time and frequency domain low order, low frequency approximation of mechanical systems</title>
      <link>https://arxiv.org/abs/2405.00486</link>
      <description>arXiv:2405.00486v1 Announce Type: new 
Abstract: Control design for linear, time-invariant mechanical systems typically requires an accurate low-order approximation in the low frequency range. For example a series expansion of the transfer function around zero consisting of a mass, velocity, and compliance term. Because computing such a series expansion of the transfer function can be cumbersome, a new method to compute low-order approximations of mechanical systems is developed in this paper. The method does not require an explicit expression for the transfer function, which is not always available for infinite-dimensional systems. The advantages of the proposed method is demonstrated in three examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00486v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hans Zwart, Dani\"el W. M. Veldman, Sahar F. Sharifi</dc:creator>
    </item>
    <item>
      <title>Shape optimization of slip-driven axisymmetric microswimmers</title>
      <link>https://arxiv.org/abs/2405.00656</link>
      <description>arXiv:2405.00656v1 Announce Type: new 
Abstract: In this work, we develop a computational framework that aims at simultaneously optimizing the shape and the slip velocity of an axisymmetric microswimmer suspended in a viscous fluid. We consider shapes of a given reduced volume that maximize the swimming efficiency, i.e., the (size-independent) ratio of the power loss arising from towing the rigid body of the same shape and size at the same translation velocity to the actual power loss incurred by swimming via the slip velocity. The optimal slip and efficiency (with shape fixed) are here given in terms of two Stokes flow solutions, and we then establish shape sensitivity formulas of adjoint-solution that provide objective function derivatives with respect to any set of shape parameters on the sole basis of the above two flow solutions. Our computational treatment relies on a fast and accurate boundary integral solver for solving all Stokes flow problems. We validate our analytic shape derivative formulas via comparisons against finite-difference gradient evaluations, and present several shape optimization examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00656v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruowen Liu, Hai Zhu, Hanliang Guo, Marc Bonnet, Shravan Veerapaneni</dc:creator>
    </item>
    <item>
      <title>A biased random-key genetic algorithm with variable mutants to solve a vehicle routing problem</title>
      <link>https://arxiv.org/abs/2405.00268</link>
      <description>arXiv:2405.00268v1 Announce Type: cross 
Abstract: The paper explores the Biased Random-Key Genetic Algorithm (BRKGA) in the domain of logistics and vehicle routing. Specifically, the application of the algorithm is contextualized within the framework of the Vehicle Routing Problem with Occasional Drivers and Time Window (VRPODTW) that represents a critical challenge in contemporary delivery systems. Within this context, BRKGA emerges as an innovative solution approach to optimize routing plans, balancing cost-efficiency with operational constraints. This research introduces a new BRKGA, characterized by a variable mutant population which can vary from generation to generation, named BRKGA-VM. This novel variant was tested to solve a VRPODTW. For this purpose, an innovative specific decoder procedure was proposed and implemented. Furthermore, a hybridization of the algorithm with a Variable Neighborhood Descent (VND) algorithm has also been considered, showing an improvement of problem-solving capabilities. Computational results show a better performances in term of effectiveness over a previous version of BRKGA, denoted as MP. The improved performance of BRKGA-VM is evident from its ability to optimize solutions across a wide range of scenarios, with significant improvements observed for each type of instance considered. The analysis also reveals that VM achieves preset goals more quickly compared to MP, thanks to the increased variability induced in the mutant population which facilitates the exploration of new regions of the solution space. Furthermore, the integration of VND has shown an additional positive impact on the quality of the solutions found.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00268v1</guid>
      <category>cs.NE</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paola Festa, Francesca Guerriero, Mauricio G. C. Resende, Edoardo Scalzo</dc:creator>
    </item>
    <item>
      <title>Quantum Global Minimum Finder based on Variational Quantum Search</title>
      <link>https://arxiv.org/abs/2405.00450</link>
      <description>arXiv:2405.00450v1 Announce Type: cross 
Abstract: The search for global minima is a critical challenge across multiple fields including engineering, finance, and artificial intelligence, particularly with non-convex functions that feature multiple local optima, complicating optimization efforts. We introduce the Quantum Global Minimum Finder (QGMF), an innovative quantum computing approach that efficiently identifies global minima. QGMF combines binary search techniques to shift the objective function to a suitable position and then employs Variational Quantum Search to precisely locate the global minimum within this targeted subspace. Designed with a low-depth circuit architecture, QGMF is optimized for Noisy Intermediate-Scale Quantum (NISQ) devices, utilizing the logarithmic benefits of binary search to enhance scalability and efficiency. This work demonstrates the impact of QGMF in advancing the capabilities of quantum computing to overcome complex non-convex optimization challenges effectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00450v1</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <category>math.QA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammadreza Soltaninia, Junpeng Zhan</dc:creator>
    </item>
    <item>
      <title>Multi-Iteration Stochastic Optimizers</title>
      <link>https://arxiv.org/abs/2011.01718</link>
      <description>arXiv:2011.01718v3 Announce Type: replace 
Abstract: We here introduce Multi-Iteration Stochastic Optimizers, a novel class of first-order stochastic optimizers where the relative $L^2$ error is estimated and controlled using successive control variates along the path of iterations. By exploiting the correlation between iterates, control variates may reduce the estimator's variance so that an accurate estimation of the mean gradient becomes computationally affordable. We name the estimator of the mean gradient Multi-Iteration stochastiC Estimator (MICE). In principle, MICE can be flexibly coupled with any first-order stochastic optimizer, given its non-intrusive nature. Our generic algorithm adaptively decides which iterates to keep in its index set. We present an error analysis of MICE and a convergence analysis of Multi-Iteration Stochastic Optimizers for different classes of problems, including some non-convex cases. Within the smooth, strongly convex setting, we show that to approximate a minimizer with accuracy $tol$, SGD-MICE requires, on average, $O(tol^{-1})$ stochastic gradient evaluations, while SGD with adaptive batch sizes requires $O(tol^{-1} \log(tol^{-1}))$, correspondingly. Moreover, in a numerical evaluation, SGD-MICE achieved tol with less than 3% the number of gradient evaluations than adaptive batch SGD. The MICE estimator provides a straightforward stopping criterion based on the gradient norm that is validated in consistency tests. To assess the efficiency of MICE, we present several examples in which we use SGD-MICE and Adam-MICE. We include one example based on a stochastic adaptation of the Rosenbrock function and logistic regression training for various datasets. When compared to SGD, SAG, SAGA, SVRG, and SARAH, the Multi-Iteration Stochastic Optimizers reduced, without the need to tune parameters for each example, the gradient sampling cost in all cases tested, also being competitive in runtime in some cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2011.01718v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andre Carlon, Luis Espath, Rafael Lopez, Raul Tempone</dc:creator>
    </item>
    <item>
      <title>Inverse Unscented Kalman Filter</title>
      <link>https://arxiv.org/abs/2304.01698</link>
      <description>arXiv:2304.01698v2 Announce Type: replace 
Abstract: Rapid advances in designing cognitive and counter-adversarial systems have motivated the development of inverse Bayesian filters. In this setting, a cognitive 'adversary' tracks its target of interest via a stochastic framework such as a Kalman filter (KF). The target or 'defender' then employs another inverse stochastic filter to infer the forward filter estimates of the defender computed by the adversary. For linear systems, the inverse Kalman filter (I-KF) has been recently shown to be effective in these counter-adversarial applications. In the paper, contrary to prior works, we focus on non-linear system dynamics and formulate the inverse unscented KF (I-UKF) to estimate the defender's state based on the unscented transform, or equivalently, statistical linearization technique. We then generalize this framework to unknown systems by proposing reproducing kernel Hilbert space-based UKF (RKHS-UKF) to learn the system dynamics and estimate the state based on its observations. Our theoretical analyses to guarantee the stochastic stability of I-UKF and RKHS-UKF in the mean-squared sense show that, provided the forward filters are stable, the inverse filters are also stable under mild system-level conditions. We show that, despite being a suboptimal filter, our proposed I-UKF is a conservative estimator, i.e., I-UKF's estimated error covariance upper-bounds its true value. Our numerical experiments for several different applications demonstrate the estimation performance of the proposed filters using recursive Cram\'{e}r-Rao lower bound and non-credibility index (NCI).</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.01698v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Himali Singh, Kumar Vijay Mishra, Arpan Chattopadhyay</dc:creator>
    </item>
    <item>
      <title>Multi-objective optimisation via the R2 utilities</title>
      <link>https://arxiv.org/abs/2305.11774</link>
      <description>arXiv:2305.11774v3 Announce Type: replace 
Abstract: The goal of multi-objective optimisation is to identify a collection of points which describe the best possible trade-offs between the multiple objectives. In order to solve this vector-valued optimisation problem, practitioners often appeal to the use of scalarisation functions in order to transform the multi-objective problem into a collection of single-objective problems. This set of scalarised problems can then be solved using traditional single-objective optimisation techniques. In this work, we formalise this convention into a general mathematical framework. We show how this strategy effectively recasts the original multi-objective optimisation problem into a single-objective optimisation problem defined over sets. An appropriate class of objective functions for this new problem are the R2 utilities, which are utility functions that are defined as a weighted integral over the scalarised optimisation problems. As part of our work, we show that these utilities are monotone and submodular set functions which can be optimised effectively using greedy optimisation algorithms. We then analyse the performance of these greedy algorithms both theoretically and empirically. Our analysis largely focusses on Bayesian optimisation, which is a popular probabilistic framework for black-box optimisation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.11774v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ben Tu, Nikolas Kantas, Robert M. Lee, Behrang Shafei</dc:creator>
    </item>
    <item>
      <title>Differentially Private and Communication-Efficient Distributed Nonconvex Optimization Algorithms</title>
      <link>https://arxiv.org/abs/2307.16656</link>
      <description>arXiv:2307.16656v2 Announce Type: replace 
Abstract: This paper studies the privacy-preserving distributed optimization problem under limited communication, where each agent aims to keep its cost function private while minimizing the sum of all agents' cost functions. To this end, we propose two differentially private distributed algorithms under compressed communication. We show that the proposed algorithms achieve sublinear convergence for smooth (possibly nonconvex) cost functions and linear convergence when the global cost function additionally satisfies the Polyak-{\L}ojasiewicz condition, even for a general class of compressors with bounded relative compression error. Furthermore, we rigorously prove that the proposed algorithms ensure $\epsilon$-differential privacy. Unlike methods in the literature, the analysis of privacy under the proposed algorithms do not rely on the specific forms of compressors. Simulations are presented to demonstrate the effectiveness of our proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.16656v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Antai Xie, Xinlei Yi, Xiaofan Wang, Ming Cao, Xiaoqiang Ren</dc:creator>
    </item>
    <item>
      <title>How Can Energy Communities Provide Grid Services? A Dynamic Pricing Mechanism with Budget Balance, Individual Rationality, and Fair Allocation</title>
      <link>https://arxiv.org/abs/2309.05363</link>
      <description>arXiv:2309.05363v2 Announce Type: replace 
Abstract: Following recent Danish legislation promoting energy communities, we explore how to enable these communities to provide grid services to distribution system operators. In particular, we focus on "capacity limitation services", where we propose a bilateral agreement in which an energy community is given reduced grid import tariffs by setting a cap to its consumption level in certain hours. This requires a coordination mechanism between the community manager and the prosumers within the community. We enable this coordination by developing a bilevel optimization model to be solved by the community manager, aiming to set dynamic, i.e., time- and prosumer-differentiated, prices. This coordination mechanism enabled by dynamic pricing ensures desirable market properties including budget balance for the community manager and individual rationality for prosumers, while encouraging (but not guaranteeing) a fair allocation of collected benefits among prosumers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.05363v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bennevis Crowley, Jalal Kazempour, Lesia Mitridati</dc:creator>
    </item>
    <item>
      <title>Collaborative Safety-Critical Control for Networked Dynamic Systems</title>
      <link>https://arxiv.org/abs/2310.03289</link>
      <description>arXiv:2310.03289v2 Announce Type: replace 
Abstract: As modern systems become ever more connected with complex dynamic coupling relationships, the development of safe control methods for such networked systems becomes paramount. In this paper, we define a general networked model with coupled dynamics and local control and discuss the relationship of node-level safety definitions for individual agents with local neighborhood dynamics. We define a node-level barrier function (NBF), node-level control barrier function (NCBF), and collaborative node-level barrier function (cNCBF) and provide conditions under which sets defined by these functions will be forward invariant. We use collaborative node-level barrier functions to construct a novel distributed algorithm for the safe control of collaborating network agents and provide conditions under which the algorithm is guaranteed to converge to a viable set of safe control actions for all agents or a terminally infeasible state for at least one agent. We introduce the notion of non-compliance of network neighbors as a metric of robustness for collaborative safety for a given network state and chosen barrier function hyper-parameters. We illustrate these results on a networked susceptible-infected-susceptible (SIS) model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.03289v2</guid>
      <category>math.OC</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Brooks A. Butler, Philip E. Par\'e</dc:creator>
    </item>
    <item>
      <title>Probabilistic Roadmaps for Aerial Relay Path Planning</title>
      <link>https://arxiv.org/abs/2310.11752</link>
      <description>arXiv:2310.11752v2 Announce Type: replace 
Abstract: Autonomous unmanned aerial vehicles (UAVs) can be utilized as aerial relays to serve users far from terrestrial infrastructure. Existing algorithms for planning the paths of multiple aerial relays cannot generally accommodate flight constraints. These are imposed by the presence of obstacles, such as buildings, and by regulations, which include altitude limits, minimum distance to people, and no-fly zones to name a few. Existing schemes for UAV path planning typically handle these constraints via shortest-path algorithms. However, in the context of aerial relays, the large number of degrees of freedom renders such an approach unaffordable. To bypass this difficulty, this work develops a framework built upon the notion of probabilistic roadmaps that allows the optimization of different communication performance metrics while preserving connectivity between the relays and the base station throughout the trajectory. To counteract the large number of configuration points required by conventional probabilistic roadmaps, a novel node generation scheme is developed based on two heuristics with theoretical guarantees, one for static users and another for moving users. Numerical experiments demonstrate that the proposed scheme can effectively serve the user by means of just two aerial relays.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.11752v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pham Q. Viet, Daniel Romero</dc:creator>
    </item>
    <item>
      <title>A mathematical model of the visual MacKay effect</title>
      <link>https://arxiv.org/abs/2311.07338</link>
      <description>arXiv:2311.07338v4 Announce Type: replace 
Abstract: This paper investigates the intricate connection between visual perception and the mathematical modelling of neural activity in the primary visual cortex (V1). The focus is on modelling the visual MacKay effect [Mackay, Nature 1957]. While bifurcation theory has been a prominent mathematical approach for addressing issues in neuroscience, especially in describing spontaneous pattern formations in V1 due to parameter changes, it faces challenges in scenarios with localized sensory inputs. This is evident, for instance, in Mackay's psychophysical experiments, where the redundancy of visual stimuli information results in irregular shapes, making bifurcation theory and multi-scale analysis less effective. To address this, we follow a mathematical viewpoint based on the input-output controllability of an Amari-type neural fields model. In this framework, we consider sensory input as a control function, a cortical representation via the retino-cortical map of the visual stimulus that captures its distinct features. This includes highly localized information in the center of MacKay's funnel pattern "MacKay rays". From a control theory point of view, the Amari-type equation's exact controllability property is discussed for linear and nonlinear response functions. For the visual MacKay effect modelling, we adjust the parameter representing intra-neuron connectivity to ensure that cortical activity exponentially stabilizes to the stationary state in the absence of sensory input. Then, we perform quantitative and qualitative studies to demonstrate that they capture all the essential features of the induced after-image reported by MacKay.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.07338v4</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.NA</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cyprien Tamekue, Dario Prandi, Yacine Chitour</dc:creator>
    </item>
    <item>
      <title>Convergence of Multi-Scale Reinforcement Q-Learning Algorithms for Mean Field Game and Control Problems</title>
      <link>https://arxiv.org/abs/2312.06659</link>
      <description>arXiv:2312.06659v2 Announce Type: replace 
Abstract: We establish the convergence of the unified two-timescale Reinforcement Learning (RL) algorithm presented in a previous work by Angiuli et al. This algorithm provides solutions to Mean Field Game (MFG) or Mean Field Control (MFC) problems depending on the ratio of two learning rates, one for the value function and the other for the mean field term. Our proof of convergence highlights the fact that in the case of MFC several mean field distributions need to be updated and for this reason we present two separate algorithms, one for MFG and one for MFC. We focus on a setting with finite state and action spaces, discrete time and infinite horizon. The proofs of convergence rely on a generalization of the two-timescale approach of Borkar. The accuracy of approximation to the true solutions depends on the smoothing of the policies. We provide a numerical example illustrating the convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.06659v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrea Angiuli, Jean-Pierre Fouque, Mathieu Lauri\`ere, Mengrui Zhang</dc:creator>
    </item>
    <item>
      <title>The Duality Theory of Fractional Calculus and a New Fractional Calculus of Variations Involving Left Operators Only</title>
      <link>https://arxiv.org/abs/2404.14458</link>
      <description>arXiv:2404.14458v2 Announce Type: replace 
Abstract: Through duality it is possible to transform left fractional operators into right fractional operators and vice versa. In contrast to existing literature, we establish integration by parts formulas that exclusively involve either left or right operators. The emergence of these novel fractional integration by parts formulas inspires the introduction of a new calculus of variations, where only one type of fractional derivative (left or right) is present. This applies to both the problem formulation and the corresponding necessary optimality conditions. As a practical application, we present a new Lagrangian that relies solely on left-hand side fractional derivatives. The fractional variational principle derived from this Lagrangian leads us to the equation of motion for a dissipative/damped system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14458v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s00009-024-02652-x</arxiv:DOI>
      <arxiv:journal_reference>Mediterr. J. Math. 21 (2024), no. 3, Paper No. 106, 16pp</arxiv:journal_reference>
      <dc:creator>Delfim F. M. Torres</dc:creator>
    </item>
    <item>
      <title>A phase-field version of the Faber--Krahn theorem</title>
      <link>https://arxiv.org/abs/2207.10946</link>
      <description>arXiv:2207.10946v4 Announce Type: replace-cross 
Abstract: We investigate a phase-field version of the Faber--Krahn theorem based on a phase-field optimization problem introduced in Garcke et al. [ESAIM Control Optim. Calc. Var. 29 (2023), Paper No. 10] formulated for the principal eigenvalue of the Dirichlet--Laplacian. The shape, that is to be optimized, is represented by a phase-field function mapping into the interval $[0,1]$. We show that any minimizer of our problem is a radially symmetric-decreasing phase-field attaining values close to $0$ and $1$ except for a thin transition layer whose thickness is of order $\varepsilon&gt;0$. Our proof relies on radially symmetric-decreasing rearrangements and corresponding functional inequalities. Moreover, we provide a $\Gamma$-convergence result which allows us to recover a variant of the Faber--Krahn theorem for sets of finite perimeter in the sharp interface limit.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.10946v4</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <category>math.SP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paul H\"uttl, Patrik Knopf, Tim Laux</dc:creator>
    </item>
    <item>
      <title>Learning zeros of Fokker-Planck operators</title>
      <link>https://arxiv.org/abs/2306.07068</link>
      <description>arXiv:2306.07068v4 Announce Type: replace-cross 
Abstract: In this paper we devise a deep learning algorithm to find non-trivial zeros of Fokker-Planck operators when the drift is non-solenoidal. We demonstrate the efficacy of our algorithm for problem dimensions ranging from 2 to 10. This method scales linearly with dimension in memory usage. In the problems we studied, overall computational time seems to scale approximately quadratically with dimension. We present results that indicate the potential of this method to produce better approximations compared to Monte Carlo methods, for the same overall sample sizes, even in low dimensions. Unlike the Monte Carlo methods, the deep network method gives a functional form of the solution. We also demonstrate that the associated loss function is strongly correlated with the distance from the true solution, thus providing a strong numerical justification for the algorithm. Moreover, this relation seems to be linear asymptotically for small values of the loss function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.07068v4</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Pinak Mandal, Amit Apte</dc:creator>
    </item>
    <item>
      <title>Null controllability of n-dimensional parabolic equations degenerated on partial boundary</title>
      <link>https://arxiv.org/abs/2307.00287</link>
      <description>arXiv:2307.00287v2 Announce Type: replace-cross 
Abstract: This paper extends the Carleman estimates to high dimensional parabolic equations with highly degenerate symmetric coefficients on a bounded domain of Lipschitz boundary and use these estimates to study the controlla?bility the corresponding equations. Due to the nonsmoothness and degeneracy of boundary, the partial integration by parts in Carleman estimates have no meaning on the degenerate and nonsmooth parts of the boundary. To get around of this difficulty, we construct special weight function, and transform some integral terms in degenerate regions into a non-degenerate ones carefully so that the obtained Carleman estimates can still be used to the controllability problem. Our results includes some well-known works as some special cases as well as some interesting new examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.00287v2</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weijia Wu, Yaozhong Hu, Hongli Sun, Donghui Yang</dc:creator>
    </item>
    <item>
      <title>On Unified Adaptive Portfolio Management</title>
      <link>https://arxiv.org/abs/2307.03391</link>
      <description>arXiv:2307.03391v3 Announce Type: replace-cross 
Abstract: This paper introduces a unified framework for adaptive portfolio management, integrating dynamic Black-Litterman (BL) optimization with the general factor model, Elastic Net regression, and mean-variance portfolio optimization, which allows us to generate investors views and mitigate potential estimation errors systematically. Specifically, we propose an innovative dynamic sliding window algorithm to respond to the constantly changing market conditions. This algorithm allows for the flexible window size adjustment based on market volatility, generating robust estimates for factor modeling, time-varying BL estimations, and optimal portfolio weights. Through extensive ten-year empirical studies using the top 100 capitalized assets in the S&amp;P 500 index, accounting for turnover transaction costs, we demonstrate that this combined approach leads to computational advantages and promising trading performances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.03391v3</guid>
      <category>q-fin.PM</category>
      <category>math.OC</category>
      <category>q-fin.CP</category>
      <category>q-fin.RM</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chi-Lin Li, Chung-Han Hsieh</dc:creator>
    </item>
    <item>
      <title>Federated Learning with Convex Global and Local Constraints</title>
      <link>https://arxiv.org/abs/2310.10117</link>
      <description>arXiv:2310.10117v3 Announce Type: replace-cross 
Abstract: In practice, many machine learning (ML) problems come with constraints, and their applied domains involve distributed sensitive data that cannot be shared with others, e.g., in healthcare. Collaborative learning in such practical scenarios entails federated learning (FL) for ML problems with constraints, or FL with constraints for short. Despite the extensive developments of FL techniques in recent years, these techniques only deal with unconstrained FL problems or FL problems with simple constraints that are amenable to easy projections. There is little work dealing with FL problems with general constraints. To fill this gap, we take the first step toward building an algorithmic framework for solving FL problems with general constraints. In particular, we propose a new FL algorithm for constrained ML problems based on the proximal augmented Lagrangian (AL) method. Assuming convex objective and convex constraints plus other mild conditions, we establish the worst-case complexity of the proposed algorithm. Our numerical experiments show the effectiveness of our algorithm in performing Neyman-Pearson classification and fairness-aware learning with nonconvex constraints, in an FL setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.10117v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chuan He, Le Peng, Ju Sun</dc:creator>
    </item>
    <item>
      <title>$\texttt{immrax}$: A Parallelizable and Differentiable Toolbox for Interval Analysis and Mixed Monotone Reachability in JAX</title>
      <link>https://arxiv.org/abs/2401.11608</link>
      <description>arXiv:2401.11608v2 Announce Type: replace-cross 
Abstract: We present an implementation of interval analysis and mixed monotone interval reachability analysis as function transforms in Python, fully composable with the computational framework JAX. The resulting toolbox inherits several key features from JAX, including computational efficiency through Just-In-Time Compilation, GPU acceleration for quick parallelized computations, and Automatic Differentiability. We demonstrate the toolbox's performance on several case studies, including a reachability problem on a vehicle model controlled by a neural network, and a robust closed-loop optimal control problem for a swinging pendulum.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.11608v2</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Akash Harapanahalli, Saber Jafarpour, Samuel Coogan</dc:creator>
    </item>
    <item>
      <title>Exploring the Robustness of In-Context Learning with Noisy Labels</title>
      <link>https://arxiv.org/abs/2404.18191</link>
      <description>arXiv:2404.18191v2 Announce Type: replace-cross 
Abstract: Recently, the mysterious In-Context Learning (ICL) ability exhibited by Transformer architectures, especially in large language models (LLMs), has sparked significant research interest. However, the resilience of Transformers' in-context learning capabilities in the presence of noisy samples, prevalent in both training corpora and prompt demonstrations, remains underexplored. In this paper, inspired by prior research that studies ICL ability using simple function classes, we take a closer look at this problem by investigating the robustness of Transformers against noisy labels. Specifically, we first conduct a thorough evaluation and analysis of the robustness of Transformers against noisy labels during in-context learning and show that they exhibit notable resilience against diverse types of noise in demonstration labels. Furthermore, we delve deeper into this problem by exploring whether introducing noise into the training set, akin to a form of data augmentation, enhances such robustness during inference, and find that such noise can indeed improve the robustness of ICL. Overall, our fruitful analysis and findings provide a comprehensive understanding of the resilience of Transformer models against label noises during ICL and provide valuable insights into the research on Transformers in natural language processing. Our code is available at https://github.com/InezYu0928/in-context-learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18191v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chen Cheng, Xinzhi Yu, Haodong Wen, Jingsong Sun, Guanzhang Yue, Yihao Zhang, Zeming Wei</dc:creator>
    </item>
  </channel>
</rss>
