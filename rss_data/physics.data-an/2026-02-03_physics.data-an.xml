<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.data-an updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.data-an</link>
    <description>physics.data-an updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.data-an" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 03 Feb 2026 05:00:55 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Comparison of Image Processing Models in Quark Gluon Jet Classification</title>
      <link>https://arxiv.org/abs/2602.00141</link>
      <description>arXiv:2602.00141v1 Announce Type: new 
Abstract: We present a comprehensive comparison of convolutional and transformer-based models for distinguishing quark and gluon jets using simulated jet images from Pythia 8. By encoding jet substructure into a three-channel representation of particle kinematics, we evaluate the performance of convolutional neural networks (CNNs), Vision Transformers (ViTs), and Swin Transformers (Swin-Tiny) under both supervised and self-supervised learning setups. Our results show that fine-tuning only the final two transformer blocks of the Swin-Tiny model achieves the best trade-off between efficiency and accuracy, reaching 81.4% accuracy and an AUC (area under the ROC curve) of 88.9%. Self-supervised pretraining with Momentum Contrast (MoCo) further enhances feature robustness and reduces the number of trainable parameters. These findings highlight the potential of hierarchical attention-based models for jet substructure studies and for domain transfer to real collision data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00141v1</guid>
      <category>physics.data-an</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>hep-ex</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daeun Kim, Jiwon Lee, Wonjun Jeong, Hyeongwoo Noh, Giyeong Kim, Jaeyoon Cho, Geonhee Kwak, Seunghwan Yang, MinJung Kweon</dc:creator>
    </item>
    <item>
      <title>Multimodal Machine Learning for Integrating Heterogeneous Analytical Systems</title>
      <link>https://arxiv.org/abs/2602.00590</link>
      <description>arXiv:2602.00590v1 Announce Type: cross 
Abstract: Understanding structure-property relationships in complex materials requires integrating complementary measurements across multiple length scales. Here we propose an interpretable "multimodal" machine learning framework that unifies heterogeneous analytical systems for end-to-end characterization, demonstrated on carbon nanotube (CNT) films whose properties are highly sensitive to microstructural variations. Quantitative morphology descriptors are extracted from SEM images via binarization, skeletonization, and network analysis, capturing curvature, orientation, intersection density, and void geometry. These SEM-derived features are fused with Raman indicators of crystallinity/defect states, specific surface area from gas adsorption, and electrical surface resistivity. Multi-dimensional visualization using radar plots and UMAP reveals clear clustering of CNT films according to crystallinity and entanglements. Regression models trained on the multimodal feature set show that nonlinear approaches, particularly XGBoost, achieve the best predictive accuracy under leave-one-out cross-validation. Feature-importance analysis further provides physically meaningful interpretations: surface resistivity is primarily governed by junction-to-junction transport length scales, crystallinity/defect-related metrics, and network connectivity, whereas specific surface area is dominated by intersection density and void size. The proposed multimodal machine learning framework offers a general strategy for data-driven, explainable characterization of complex materials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00590v1</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>cond-mat.soft</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shun Muroga, Hideaki Nakajima, Taiyo Shimizu, Kazufumi Kobashi, Kenji Hata</dc:creator>
    </item>
    <item>
      <title>Phase Transitions in Unsupervised Feature Selection</title>
      <link>https://arxiv.org/abs/2602.00660</link>
      <description>arXiv:2602.00660v1 Announce Type: cross 
Abstract: Identifying minimal and informative feature sets is a central challenge in data analysis, particularly when few data points are available. Here we present a theoretical analysis of an unsupervised feature selection pipeline based on the Differentiable Information Imbalance (DII). We consider the specific case of structural and physico-chemical features describing a set of proteins. We show that if one considers the features as coordinates of a (hypothetical) statistical physics model, this model undergoes a phase transition as a function of the number of retained features. For physico-chemical descriptors, this transition is between a glass-like phase when the features are few and a liquid-like phase. The glass-like phase exhibits bimodal order-parameter distributions and Binder cumulant minima. In contrast, for structural descriptors the transition is less sharp. Remarkably, for physico-chemical descriptors the critical number of features identified from the DII coincides with the saturation of downstream binary classification performance. These results provide a principled, unsupervised criterion for minimal feature sets in protein classification and reveal distinct mechanisms of criticality across different feature types.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00660v1</guid>
      <category>q-bio.BM</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Jonathan Fiorentino, Michele Monti, Dimitrios Miltiadis-Vrachnos, Vittorio Del Tatto, Alessandro Laio, Gian Gaetano Tartaglia</dc:creator>
    </item>
    <item>
      <title>Superposition unifies power-law training dynamics</title>
      <link>https://arxiv.org/abs/2602.01045</link>
      <description>arXiv:2602.01045v1 Announce Type: cross 
Abstract: We investigate the role of feature superposition in the emergence of power-law training dynamics using a teacher-student framework. We first derive an analytic theory for training without superposition, establishing that the power-law training exponent depends on both the input data statistics and channel importance. Remarkably, we discover that a superposition bottleneck induces a transition to a universal power-law exponent of $\sim 1$, independent of data and channel statistics. This one over time training with superposition represents an up to tenfold acceleration compared to the purely sequential learning that takes place in the absence of superposition. Our finding that superposition leads to rapid training with a data-independent power law exponent may have important implications for a wide range of neural networks that employ superposition, including production-scale large language models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01045v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>physics.data-an</category>
      <category>stat.ML</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zixin Jessie Chen, Hao Chen, Yizhou Liu, Jeff Gore</dc:creator>
    </item>
    <item>
      <title>Exploring the Limitations of kNN Noisy Feature Detection and Recovery for Self-Driving Labs</title>
      <link>https://arxiv.org/abs/2507.16833</link>
      <description>arXiv:2507.16833v2 Announce Type: replace-cross 
Abstract: Self-driving laboratories (SDLs) have shown promise to accelerate materials discovery by integrating machine learning with automated experimental platforms. However, errors in the capture of input parameters may corrupt the features used to model system performance, compromising current and future campaigns. This study develops an automated workflow to systematically detect noisy features, determine sample-feature pairings that can be corrected, and finally recover the correct feature values. A systematic study is then performed to examine how dataset size, noise intensity, noise type, and feature value distribution affect both the detectability and recoverability of noisy features on both Density Functional Theory (DFT) and SDL datasets. In general, high-intensity noise and large training datasets are conducive to the detection and correction of noisy features. Low-intensity noise reduces detection and recovery but can be compensated for by larger clean training data sets. Detection and correction results vary between features, with continuous and dispersed feature distributions showing greater recoverability compared to features with discrete or narrow distributions. This systematic study not only demonstrates a model agnostic framework for rational data recovery in the presence of noise, limited data, and differing feature distributions but also provides a tangible benchmark of kNN imputation in materials datasets. Ultimately, it aims to enhance data quality and experimental precision in automated materials discovery.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.16833v2</guid>
      <category>cs.LG</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Qiuyu Shi, Kangming Li, Yao Fehlis, Runze Zhang, Daniel Persaud, Robert Black, Jason Hattrick-Simpers</dc:creator>
    </item>
    <item>
      <title>Functional Information in Quantum Darwinism: An Operational Measure of Objectivity</title>
      <link>https://arxiv.org/abs/2509.17775</link>
      <description>arXiv:2509.17775v3 Announce Type: replace-cross 
Abstract: Quantum Darwinism explains the emergence of classical objectivity through the redundant encoding of pointer information in environmental fragments. However, existing diagnostics rely on arbitrary thresholds or structural assumptions that limit their operational applicability. We develop a framework based on \emph{functional information}, $\FI(\delta) = \log_2 R_\delta$, which quantifies objectivity as the abundance of environment fragments that individually carry at least $(1-\delta)H_S$ bits of classically accessible pointer information, as bounded by the Holevo quantity. Using onset statistics rather than parametric fits, we extract redundancy $R_\delta$ from the fragment size at which adequacy becomes typical. Simulations of a heterogeneous pure-dephasing model reveal three robust features: rapid early-time growth of $\ln R_\delta$, smooth crossover to saturation, and capacity-limited plateaus at $\FI^{\mathrm{plateau}} \lesssim \log_2 N$. We establish thermodynamic constraints showing that each additional bit of $\FI$ doubles the minimal heat dissipation required for record stabilization. These results frame classical objectivity as a quantifiable, resource-limited phenomenon.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.17775v3</guid>
      <category>quant-ph</category>
      <category>physics.comp-ph</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arda Batin Tank</dc:creator>
    </item>
    <item>
      <title>Quantitative mobile gamma-ray spectrometry through Bayesian inference</title>
      <link>https://arxiv.org/abs/2512.18769</link>
      <description>arXiv:2512.18769v3 Announce Type: replace-cross 
Abstract: Accurate quantitative mapping of gamma-ray sources is critical for applications ranging from radiological emergency response and environmental monitoring to nuclear security and deep space exploration. Here, we show that integrating high-fidelity, platform-dynamic Monte Carlo simulations and Bayesian inference with mobile gamma-ray spectrometry enables rapid and accurate quantification of distributed and point-like gamma-ray sources. Validated against laboratory and field assays, our framework quantifies natural and anthropogenic gamma-ray sources that conventional methods cannot resolve in $1\,$s with $\sim\!\!1\,\%$ error. The developed method marks a critical advance in quantitative gamma-ray sensing, enabling improved radiological situational awareness, enhanced terrestrial geophysical and geochemical mapping, as well as more robust constraints on radionuclide abundances on extraterrestrial bodies across the Solar System.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.18769v3</guid>
      <category>physics.ins-det</category>
      <category>physics.app-ph</category>
      <category>physics.comp-ph</category>
      <category>physics.data-an</category>
      <category>physics.geo-ph</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David Breitenmoser, Alberto Stabilini, Malgorzata Magdalena Kasprzak, Sabine Mayer</dc:creator>
    </item>
  </channel>
</rss>
