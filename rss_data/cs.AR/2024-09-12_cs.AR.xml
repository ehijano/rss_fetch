<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.AR updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.AR</link>
    <description>cs.AR updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.AR" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 13 Sep 2024 04:00:09 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Efficient and Reliable Vector Similarity Search Using Asymmetric Encoding with NAND-Flash for Many-Class Few-Shot Learning</title>
      <link>https://arxiv.org/abs/2409.07832</link>
      <description>arXiv:2409.07832v1 Announce Type: new 
Abstract: While memory-augmented neural networks (MANNs) offer an effective solution for few-shot learning (FSL) by integrating deep neural networks with external memory, the capacity requirements and energy overhead of data movement become enormous due to the large number of support vectors in many-class FSL scenarios. Various in-memory search solutions have emerged to improve the energy efficiency of MANNs. NAND-based multi-bit content addressable memory (MCAM) is a promising option due to its high density and large capacity. Despite its potential, MCAM faces limitations such as a restricted number of word lines, limited quantization levels, and non-ideal effects like varying string currents and bottleneck effects, which lead to significant accuracy drops. To address these issues, we propose several innovative methods. First, the Multi-bit Thermometer Code (MTMC) leverages the extensive capacity of MCAM to enhance vector precision using cumulative encoding rules, thereby mitigating the bottleneck effect. Second, the Asymmetric vector similarity search (AVSS) reduces the precision of the query vector while maintaining that of the support vectors, thereby minimizing the search iterations and improving efficiency in many-class scenarios. Finally, the Hardware-Aware Training (HAT) method optimizes controller training by modeling the hardware characteristics of MCAM, thus enhancing the reliability of the system. Our integrated framework reduces search iterations by up to 32 times, and increases overall accuracy by 1.58% to 6.94%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07832v1</guid>
      <category>cs.AR</category>
      <category>cs.LG</category>
      <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao-Wei Chiang (Andy), Chi-Tse Huang (Andy), Hsiang-Yun Cheng (Andy), Po-Hao Tseng (Andy), Ming-Hsiu Lee (Andy),  An-Yeu (Andy),  Wu</dc:creator>
    </item>
    <item>
      <title>Dynamic Simultaneous Multithreaded Arch</title>
      <link>https://arxiv.org/abs/2409.07903</link>
      <description>arXiv:2409.07903v1 Announce Type: new 
Abstract: This paper presents the Dynamic Simultaneous Multi-threaded Architecture (DSMT). DSMT efficiently exe-cutes multiple threads from a single program on a SMT processor core. To accomplish this, threads are generated dynamically from a predictable flow of control and then executed speculatively. Data obtained during the single context non-speculative execution phase of DSMT is used as a hint to speculate the posterior behavior of multiple threads. DSMT employs simple mechanisms based on state bits that keep track of inter-thread dependencies in registers and memory, synchronize thread execution, and control recovery from misspeculation. Moreover, DSMT utilizes a novel greedy policy for choosing those sections of code which provide the highest performance based on their past execution history. The DSMT architecture was simulated with a new cycle-accurate, execution-driven simulator. Our simulation results show that DSMT has very good potential to improve SMT performance, even when only a single program is available. However, we found that dynamic thread behavior together with fre-quent misspeculation may also produce diminishing re-turns in performance. Therefore, the challenge is to max-imize the amount of thread-level parallelism that DSMT is capable of exploiting and at the same time reduce the fre-quency of misspeculations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07903v1</guid>
      <category>cs.AR</category>
      <category>cs.DC</category>
      <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:journal_reference>PDCS: Parallel and Distributed Computing Systems (ISCA) 2003</arxiv:journal_reference>
      <dc:creator>Daniel Ortiz-Arroyo, Ben Lee</dc:creator>
    </item>
    <item>
      <title>Rethinking Programmed I/O for Fast Devices, Cheap Cores, and Coherent Interconnects</title>
      <link>https://arxiv.org/abs/2409.08141</link>
      <description>arXiv:2409.08141v1 Announce Type: new 
Abstract: Conventional wisdom holds that an efficient interface between an OS running on a CPU and a high-bandwidth I/O device should be based on Direct Memory Access (DMA), descriptor rings, and interrupts: DMA offloads transfers from the CPU, descriptor rings provide buffering and queuing, and interrupts facilitate asynchronous interaction between cores and device with a lightweight notification mechanism. In this paper we question this wisdom in the light of modern hardware and workloads, particularly in cloud servers. We argue that the assumptions that led to this model are obsolete, and in many use-cases use of programmed I/O, where the CPU explicitly transfers data and control information to and from a device via loads and stores, actually results in a more efficient system. We quantitatively demonstrate these advantages using three use-cases: fine-grained RPC-style invocation of functions on an accelerator, offloading of operators in a streaming dataflow engine, and a network interface targeting for serverless functions. Moreover, we show that while these advantages are significant over a modern PCIe peripheral bus, a truly cache-coherent interconnect offers significant additional efficiency gains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08141v1</guid>
      <category>cs.AR</category>
      <category>cs.OS</category>
      <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anastasiia Ruzhanskaia, Pengcheng Xu, David Cock, Timothy Roscoe</dc:creator>
    </item>
    <item>
      <title>C3-VQA: Cryogenic Counter-based Co-processor for Variational Quantum Algorithms</title>
      <link>https://arxiv.org/abs/2409.07847</link>
      <description>arXiv:2409.07847v1 Announce Type: cross 
Abstract: Cryogenic quantum computers play a leading role in demonstrating quantum advantage. Given the severe constraints on the cooling capacity in cryogenic environments, thermal design is crucial for the scalability of these computers. The sources of heat dissipation include passive inflow via inter-temperature wires and the power consumption of components located in the cryostat, such as wire amplifiers and quantum-classical interfaces. Thus, a critical challenge is to reduce the number of wires by reducing the required inter-temperature bandwidth while maintaining minimal additional power consumption in the cryostat. One solution to address this challenge is near-data processing using ultra-low-power computational logic within the cryostat. Based on the workload analysis and domain-specific system design focused on Variational Quantum Algorithms (VQAs), we propose the Cryogenic Counter-based Co-processor for VQAs (C3-VQA) to enhance the design scalability of cryogenic quantum computers under the thermal constraint. The C3-VQA utilizes single-flux-quantum logic, which is an ultra-low-power superconducting digital circuit that operates at the 4 K environment. The C3-VQA precomputes a part of the expectation value calculations for VQAs and buffers intermediate values using simple bit operation units and counters in the cryostat, thereby reducing the required inter-temperature bandwidth with small additional power consumption. Consequently, the C3-VQA reduces the number of wires, leading to a reduction in the total heat dissipation in the cryostat. Our evaluation shows that the C3-VQA reduces the total heat dissipation at the 4 K stage by 30% and 81% under sequential-shot and parallel-shot execution scenarios, respectively. Furthermore, a case study in quantum chemistry shows that the C3-VQA reduces total heat dissipation by 87% with a 10,000-qubit system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07847v1</guid>
      <category>quant-ph</category>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yosuke Ueno, Satoshi Imamura, Yuna Tomida, Teruo Tanimoto, Masamitsu Tanaka, Yutaka Tabuchi, Koji Inoue, Hiroshi Nakamura</dc:creator>
    </item>
    <item>
      <title>Photonic Quantum Computers</title>
      <link>https://arxiv.org/abs/2409.08229</link>
      <description>arXiv:2409.08229v1 Announce Type: cross 
Abstract: In the pursuit of scalable and fault-tolerant quantum computing architectures, photonic-based quantum computers have emerged as a leading frontier. This article provides a comprehensive overview of advancements in photonic quantum computing, developed by leading industry players, examining current performance, architectural designs, and strategies for developing large-scale, fault-tolerant photonic quantum computers. It also highlights recent groundbreaking experiments that leverage the unique advantages of photonic technologies, underscoring their transformative potential. This review captures a pivotal moment of photonic quantum computing in the noisy intermediate-scale quantum (NISQ) era, offering insights into how photonic quantum computers might reshape the future of quantum computing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08229v1</guid>
      <category>quant-ph</category>
      <category>cs.AI</category>
      <category>cs.AR</category>
      <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>M. AbuGhanem</dc:creator>
    </item>
    <item>
      <title>Beehive: A Flexible Network Stack for Direct-Attached Accelerators</title>
      <link>https://arxiv.org/abs/2403.14770</link>
      <description>arXiv:2403.14770v5 Announce Type: replace 
Abstract: Direct-attached accelerators, where application accelerators are directly connected to the datacenter network via a hardware network stack, offer substantial benefits in terms of reduced latency, CPU overhead, and energy use. However, a key challenge is that modern datacenter network stacks are complex, with interleaved protocol layers, network management functions, and virtualization support. To operators, network feature agility, diagnostics, and manageability are often considered just as important as raw performance. By contrast, existing hardware network stacks only support basic protocols and are often difficult to extend since they use fixed processing pipelines.
  We propose Beehive, a new, open-source FPGA network stack for direct-attached accelerators designed to enable flexible and adaptive construction of complex network functionality in hardware. Application and network protocol elements are modularized as tiles over a network-on-chip substrate. Elements can be added or scaled up/down to match workload characteristics with minimal effort or changes to other elements. Flexible diagnostics and control are integral, with tooling to ensure deadlock safety. Our implementation interoperates with standard Linux TCP and UDP clients, with a 4x improvement in end-to-end RPC tail latency for Linux UDP clients versus a CPU-attached accelerator. Beehive is available at https://github.com/beehive-fpga/beehive</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.14770v5</guid>
      <category>cs.AR</category>
      <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Katie Lim, Matthew Giordano, Theano Stavrinos, Irene Zhang, Jacob Nelson, Baris Kasikci, Tom Anderson</dc:creator>
    </item>
    <item>
      <title>Q-Pilot: Field Programmable Qubit Array Compilation with Flying Ancillas</title>
      <link>https://arxiv.org/abs/2311.16190</link>
      <description>arXiv:2311.16190v3 Announce Type: replace-cross 
Abstract: Neutral atom arrays have become a promising platform for quantum computing, especially the field programmable qubit array (FPQA) endowed with the unique capability of atom movement. This feature allows dynamic alterations in qubit connectivity during runtime, which can reduce the cost of executing long-range gates and improve parallelism. However, this added flexibility introduces new challenges in circuit compilation. Inspired by the placement and routing strategies for FPGAs, we propose to map all data qubits to fixed atoms while utilizing movable atoms to route for 2-qubit gates between data qubits. Coined flying ancillas, these mobile atoms function as ancilla qubits, dynamically generated and recycled during execution. We present Q-Pilot, a scalable compiler for FPQA employing flying ancillas to maximize circuit parallelism. For two important quantum applications, quantum simulation and the Quantum Approximate Optimization Algorithm (QAOA), we devise domain-specific routing strategies. In comparison to alternative technologies such as superconducting devices or fixed atom arrays, Q-Pilot effectively harnesses the flexibility of FPQA, achieving reductions of 1.4x, 27.7x, and 6.3x in circuit depth for 100-qubit random, quantum simulation, and QAOA circuits, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.16190v3</guid>
      <category>quant-ph</category>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hanrui Wang, Daniel Bochen Tan, Pengyu Liu, Yilian Liu, Jiaqi Gu, Jason Cong, Song Han</dc:creator>
    </item>
  </channel>
</rss>
