<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.ST updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.ST</link>
    <description>math.ST updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.ST" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 25 Apr 2025 04:00:30 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Graph Quasirandomness for Hypothesis Testing of Stochastic Block Models</title>
      <link>https://arxiv.org/abs/2504.17202</link>
      <description>arXiv:2504.17202v1 Announce Type: new 
Abstract: The celebrated theorem of Chung, Graham, and Wilson on quasirandom graphs implies that if the 4-cycle and edge counts in a graph $G$ are both close to their typical number in $\mathbb{G}(n,1/2),$ then this also holds for the counts of subgraphs isomorphic to $H$ for any $H$ of constant size. We aim to prove a similar statement where the notion of close is whether the given (signed) subgraph count can be used as a test between $\mathbb{G}(n,1/2)$ and a stochastic block model $\mathbb{SBM}.$
  Quantitatively, this is related to approximately maximizing $H \longrightarrow |\Phi(H)|^{\frac{1}{|\mathsf{V}(H)|}},$ where $\Phi(H)$ is the Fourier coefficient of $\mathbb{SBM}$, indexed by subgraph $H.$ This formulation turns out to be equivalent to approximately maximizing the partition function of a spin model over alphabet equal to the community labels in $\mathbb{SBM}.$
  We resolve the approximate maximization when $\mathbb{SBM}$ satisfies one of four conditions: 1) the probability of an edge between any two vertices in different communities is exactly $1/2$; 2) the probability of an edge between two vertices from any two communities is at least $1/2$ (this case is also covered in a recent work of Yu, Zadik, and Zhang); 3) the probability of belonging to any given community is at least $c$ for some universal constant $c&gt;0$; 4) $\mathbb{SBM}$ has two communities. In each of these cases, we show that there is an approximate maximizer of $|\Phi(H)|^{\frac{1}{|\mathsf{V}(H)|}}$ in the set $\mathsf{A} = \{\text{stars, 4-cycle}\}.$ This implies that if there exists a constant-degree polynomial test distinguishing $\mathbb{G}(n,1/2)$ and $\mathbb{SBM},$ then the two distributions can also be distinguished via the signed count of some graph in $\mathsf{A}.$ We conjecture that the same holds true for distinguishing $\mathbb{G}(n,1/2)$ and any graphon if we also add triangles to $\mathsf{A}.$</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17202v1</guid>
      <category>math.ST</category>
      <category>math.CO</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kiril Bangachev, Guy Bresler</dc:creator>
    </item>
    <item>
      <title>Functional $K$ Sample Problem via Multivariate Optimal Measure Transport-Based Permutation Test</title>
      <link>https://arxiv.org/abs/2504.17451</link>
      <description>arXiv:2504.17451v1 Announce Type: new 
Abstract: The null hypothesis of equality of distributions of functional data coming from $K$ samples is considered. The proposed test statistic is multivariate and its components are based on pairwise Cram\'{e}r von Mises comparisons of empirical characteristic functionals. The significance of the test statistic is evaluated via the novel multivariate permutation test, where the final single $p$-value is computed using the discrete optimal measure transport. The methodology is illustrated by real data on cumulative intraday returns of Bitcoin.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17451v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>\v{S}\'arka Hudecov\'a, Daniel Hlubinka, Zden\v{e}k Hl\'avka</dc:creator>
    </item>
    <item>
      <title>Concentration inequalities and cut-off phenomena for penalized model selection within a basic Rademacher framework</title>
      <link>https://arxiv.org/abs/2504.17559</link>
      <description>arXiv:2504.17559v1 Announce Type: new 
Abstract: This article exists first and foremost to contribute to a tribute to Patrick Cattiaux. One of the two authors has known Patrick Cattiaux for a very long time, and owes him a great deal. If we are to illustrate the adage that life is made up of chance, then what could be better than the meeting of two young people in the 80s, both of whom fell in love with the mathematics of randomness, and one of whom changed the other's life by letting him in on a secret: if you really believe in it, you can turn this passion into a profession. By another happy coincidence, this tribute comes at just the right time, as Michel Talagrand has been awarded the Abel prize. The temptation was therefore great to do a double. Following one of the many galleries opened up by mathematics, we shall first draw a link between the mathematics of Patrick Cattiaux and that of Michel Talagrand. Then we shall show how the abstract probabilistic material on the concentration of product measures thus revisited can be used to shed light on cut-off phenomena in our field of expertise, mathematical statistics. Nothing revolutionary here, as everyone knows the impact that Talagrand's work has had on the development of mathematical statistics since the late 90s, but we've chosen a very simple framework in which everything can be explained with minimal technicality, leaving the main ideas to the fore.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17559v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pascal Massart, Vincent Rivoirard</dc:creator>
    </item>
    <item>
      <title>Some Results on Generalized Familywise Error Rate Controlling Procedures under Dependence</title>
      <link>https://arxiv.org/abs/2504.17611</link>
      <description>arXiv:2504.17611v1 Announce Type: new 
Abstract: The topic of multiple hypotheses testing now has a potpourri of novel theories and ubiquitous applications in diverse scientific fields. However, the universal utility of this field often hinders the possibility of having a generalized theory that accommodates every scenario. This tradeoff is better reflected through the lens of dependence, a central piece behind the theoretical and applied developments of multiple testing. Although omnipresent in many scientific avenues, the nature and extent of dependence vary substantially with the context and complexity of the particular scenario. Positive dependence is the norm in testing many treatments versus a single control or in spatial statistics. On the contrary, negative dependence arises naturally in tests based on split samples and in cyclical, ordered comparisons. In GWAS, the SNP markers are generally considered to be weakly dependent. Generalized familywise error rate (k-FWER) control has been one of the prominent frequentist approaches in simultaneous inference. However, the performances of k-FWER controlling procedures are yet unexplored under different dependencies. This paper revisits the classical testing problem of normal means in different correlated frameworks. We establish upper bounds on the generalized familywise error rates under each dependence, consequently giving rise to improved testing procedures. Towards this, we present improved probability inequalities, which are of independent theoretical interest</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17611v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Monitirtha Dey, Subir Kumar Bhandari</dc:creator>
    </item>
    <item>
      <title>Relationship between H\"{o}lder Divergence and Functional Density Power Divergence: Intersection and Generalization</title>
      <link>https://arxiv.org/abs/2504.17008</link>
      <description>arXiv:2504.17008v1 Announce Type: cross 
Abstract: In this study, we discuss the relationship between two families of density-power-based divergences with functional degrees of freedom -- the H\"{o}lder divergence and the functional density power divergence (FDPD) -- based on their intersection and generalization. These divergence families include the density power divergence and the $\gamma$-divergence as special cases. First, we prove that the intersection of the H\"{o}lder divergence and the FDPD is limited to a general divergence family introduced by Jones et al. (Biometrika, 2001). Subsequently, motivated by the fact that H\"{o}lder's inequality is used in the proofs of nonnegativity for both the H\"{o}lder divergence and the FDPD, we define a generalized divergence family, referred to as the $\xi$-H\"{o}lder divergence. The nonnegativity of the $\xi$-H\"{o}lder divergence is established through a combination of the inequalities used to prove the nonnegativity of the H\"{o}lder divergence and the FDPD. Furthermore, we derive an inequality between the composite scoring rules corresponding to different FDPDs based on the $\xi$-H\"{o}lder divergence. Finally, we prove that imposing the mathematical structure of the H\"{o}lder score on a composite scoring rule results in the $\xi$-H\"{o}lder divergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17008v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Masahiro Kobayashi</dc:creator>
    </item>
    <item>
      <title>Estimation and Inference for the Average Treatment Effect in a Score-Explained Heterogeneous Treatment Effect Model</title>
      <link>https://arxiv.org/abs/2504.17126</link>
      <description>arXiv:2504.17126v1 Announce Type: cross 
Abstract: In many practical situations, randomly assigning treatments to subjects is uncommon due to feasibility constraints. For example, economic aid programs and merit-based scholarships are often restricted to those meeting specific income or exam score thresholds. In these scenarios, traditional approaches to estimating treatment effects typically focus solely on observations near the cutoff point, thereby excluding a significant portion of the sample and potentially leading to information loss. Moreover, these methods generally achieve a non-parametric convergence rate. While some approaches, e.g., Mukherjee et al. (2021), attempt to tackle these issues, they commonly assume that treatment effects are constant across individuals, an assumption that is often unrealistic in practice. In this study, we propose a differencing and matching-based estimator of the average treatment effect on the treated (ATT) in the presence of heterogeneous treatment effects, utilizing all available observations. We establish the asymptotic normality of our estimator and illustrate its effectiveness through various synthetic and real data analyses. Additionally, we demonstrate that our method yields non-parametric estimates of the conditional average treatment effect (CATE) and individual treatment effect (ITE) as a byproduct.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17126v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kevin Christian Wibisono, Debarghya Mukherjee, Moulinath Banerjee, Ya'acov Ritov</dc:creator>
    </item>
    <item>
      <title>Asymptotics of Yule's nonsense correlation for Ornstein-Uhlenbeck paths: The correlated case</title>
      <link>https://arxiv.org/abs/2504.17175</link>
      <description>arXiv:2504.17175v1 Announce Type: cross 
Abstract: We study the continuous-time version of the empirical correlation coefficient between the paths of two possibly correlated Ornstein-Uhlenbeck processes, known as Yule's nonsense correlation for these paths. Using sharp tools from the analysis on Wiener chaos, we establish the asymptotic normality of the fluctuations of this correlation coefficient around its long-time limit, which is the mathematical correlation coefficient between the two processes. This asymptotic normality is quantified in Kolmogorov distance, which allows us to establish speeds of convergence in the Type-II error for two simple tests of independence of the paths, based on the empirical correlation, and based on its numerator. An application to independence of two observations of solutions to the stochastic heat equation is given, with excellent asymptotic power properties using merely a small number of the solutions' Fourier modes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17175v1</guid>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Soukaina Douissi, Philip Ernst, Frederi Viens</dc:creator>
    </item>
    <item>
      <title>Signal Recovery from Random Dot-Product Graphs Under Local Differential Privacy</title>
      <link>https://arxiv.org/abs/2504.17274</link>
      <description>arXiv:2504.17274v1 Announce Type: cross 
Abstract: We consider the problem of recovering latent information from graphs under $\varepsilon$-edge local differential privacy where the presence of relationships/edges between two users/vertices remains confidential, even from the data curator. For the class of generalized random dot-product graphs, we show that a standard local differential privacy mechanism induces a specific geometric distortion in the latent positions. Leveraging this insight, we show that consistent recovery of the latent positions is achievable by appropriately adjusting the statistical inference procedure for the privatized graph. Furthermore, we prove that our procedure is nearly minimax-optimal under local edge differential privacy constraints. Lastly, we show that this framework allows for consistent recovery of geometric and topological information underlying the latent positions, as encoded in their persistence diagrams. Our results extend previous work from the private community detection literature to a substantially richer class of models and inferential tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17274v1</guid>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siddharth Vishwanath, Jonathan Hehir</dc:creator>
    </item>
    <item>
      <title>Linear Functions to the Extended Reals</title>
      <link>https://arxiv.org/abs/2102.09552</link>
      <description>arXiv:2102.09552v2 Announce Type: replace 
Abstract: This paper investigates functions from $\mathbb{R}^d$ to $\mathbb{R} \cup \{\pm \infty\}$ that satisfy axioms of linearity wherever allowed by extended-value arithmetic. They have a nontrivial structure defined inductively on $d$, and unlike finite linear functions, they require $\Omega(d^2)$ parameters to uniquely identify. In particular they can capture vertical tangent planes to epigraphs: a function (never $-\infty$) is convex if and only if it has an extended-valued subgradient at every point in its effective domain, if and only if it is the supremum of a family of "affine extended" functions. These results are applied to the well-known characterization of proper scoring rules, for the finite-dimensional case: it is carefully and rigorously extended here to a more constructive form. In particular it is investigated when proper scoring rules can be constructed from a given convex function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2102.09552v2</guid>
      <category>math.ST</category>
      <category>cs.GT</category>
      <category>stat.TH</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Bo Waggoner</dc:creator>
    </item>
    <item>
      <title>Survival Analysis with Graph-Based Regularization for Predictors</title>
      <link>https://arxiv.org/abs/2108.12827</link>
      <description>arXiv:2108.12827v3 Announce Type: replace 
Abstract: We study the variable selection problem in survival analysis to identify the most important factors affecting survival time. Our method incorporates prior knowledge of mutual correlations among variables, represented through a graph. We utilize the Cox proportional hazard model with a graph-based regularizer for variable selection. We present a computationally efficient algorithm developed to solve the graph regularized maximum likelihood problem by establishing connections with the group lasso, and provide theoretical guarantees about the recovery error and asymptotic distribution of the proposed estimators. The improved performance of the proposed approach compared with existing methods are demonstrated in both synthetic and real organ transplantation datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2108.12827v3</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liyan Xie, Xi He, Pinar Keskinocak, Yao Xie</dc:creator>
    </item>
    <item>
      <title>Bayesian Mixtures Models with Repulsive and Attractive Atoms</title>
      <link>https://arxiv.org/abs/2302.09034</link>
      <description>arXiv:2302.09034v4 Announce Type: replace 
Abstract: The study of almost surely discrete random probability measures is an active line of research in Bayesian nonparametrics. The idea of assuming interaction across the atoms of the random probability measure has recently spurred significant interest in the context of Bayesian mixture models. This allows the definition of priors that encourage well-separated and interpretable clusters. In this work, we provide a unified framework for the construction and the Bayesian analysis of random probability measures with interacting atoms, encompassing both repulsive and attractive behaviours. Specifically, we derive closed-form expressions for the posterior distribution, the marginal and predictive distributions, which were not previously available except for the case of measures with i.i.d. atoms. We show how these quantities are fundamental both for prior elicitation and to develop new posterior simulation algorithms for hierarchical mixture models. Our results are obtained without any assumption on the finite point process that governs the atoms of the random measure. Their proofs rely on analytical tools borrowed from the Palm calculus theory, which might be of independent interest. We specialise our treatment to the classes of Poisson, Gibbs, and determinantal point processes, as well as in the case of shot-noise Cox processes. Finally, we illustrate the performance of different modelling strategies on simulated and real datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.09034v4</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mario Beraha, Raffaele Argiento, Federico Camerlenghi, Alessandra Guglielmi</dc:creator>
    </item>
    <item>
      <title>An Optimal Design Framework for Lasso Sign Recovery</title>
      <link>https://arxiv.org/abs/2303.16843</link>
      <description>arXiv:2303.16843v3 Announce Type: replace 
Abstract: Supersaturated designs investigate more factors than there are runs, and are often constructed under a criterion measuring a design's proximity to an unattainable orthogonal design. The most popular analysis identifies active factors by inspecting the solution path of a penalized estimator, such as the lasso. Recent criteria encouraging positive correlations between factors have been shown to produce designs with more definitive solution paths so long as the active factors have positive effects. Two open problems affecting the understanding and practicality of supersaturated designs are: (1) do optimal designs under existing criteria maximize support recovery probability across an estimator's solution path, and (2) why do designs with positively correlated columns produce more definitive solution paths when the active factors have positive sign effects? To answer these questions, we develop criteria maximizing the lasso's sign recovery probability. We prove that an orthogonal design is an ideal structure when the signs of the active factors are unknown, and a design constant small, positive correlations is ideal when the signs are assumed known. A computationally-efficient design search algorithm is proposed that first filters through optimal designs under new heuristic criteria to select the one that maximizes the lasso sign recovery probability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.16843v3</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonathan W. Stallrich, Kade Young, Maria L. Weese, Byran J. Smucker, David J. Edwards</dc:creator>
    </item>
    <item>
      <title>Precise Error Rates for Computationally Efficient Testing</title>
      <link>https://arxiv.org/abs/2311.00289</link>
      <description>arXiv:2311.00289v3 Announce Type: replace 
Abstract: We revisit the fundamental question of simple-versus-simple hypothesis testing with an eye towards computational complexity, as the statistically optimal likelihood ratio test is often computationally intractable in high-dimensional settings. In the classical spiked Wigner model with a general i.i.d. spike prior we show (conditional on a conjecture) that an existing test based on linear spectral statistics achieves the best possible tradeoff curve between type I and type II error rates among all computationally efficient tests, even though there are exponential-time tests that do better. This result is conditional on an appropriate complexity-theoretic conjecture, namely a natural strengthening of the well-established low-degree conjecture. Our result shows that the spectrum is a sufficient statistic for computationally bounded tests (but not for all tests).
  To our knowledge, our approach gives the first tool for reasoning about the precise asymptotic testing error achievable with efficient computation. The main ingredients required for our hardness result are a sharp bound on the norm of the low-degree likelihood ratio along with (counterintuitively) a positive result on achievability of testing. This strategy appears to be new even in the setting of unbounded computation, in which case it gives an alternate way to analyze the fundamental statistical limits of testing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.00289v3</guid>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ankur Moitra, Alexander S. Wein</dc:creator>
    </item>
    <item>
      <title>Minimax Sequential Testing for Poisson Processes</title>
      <link>https://arxiv.org/abs/2311.04084</link>
      <description>arXiv:2311.04084v2 Announce Type: replace 
Abstract: Suppose we observe a Poisson process in real time for which the intensity may take on two possible values $\lambda_0$ and $\lambda_1$. Suppose further that the priori probability of the true intensity is not given. We solve a minimax version of Bayesian problem of sequential testing of two simple hypotheses to minimize a linear combination of the probability of wrong detection and the expected waiting time in the worst scenario of all possible priori distributions. An equivalent characterization for the least favorable distributions is derived and a sufficient condition for the existence is concluded.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.04084v2</guid>
      <category>math.ST</category>
      <category>math.OC</category>
      <category>stat.TH</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hongwei Mei</dc:creator>
    </item>
    <item>
      <title>A sliced Wasserstein and diffusion approach to random coefficient models</title>
      <link>https://arxiv.org/abs/2502.04654</link>
      <description>arXiv:2502.04654v2 Announce Type: replace 
Abstract: We propose a new minimum-distance estimator for linear random coefficient models. This estimator integrates the recently advanced sliced Wasserstein distance with the nearest neighbor methods, both of which enhance computational efficiency. We demonstrate that the proposed method is consistent in approximating the true distribution. Moreover, our formulation naturally leads to a diffusion process-based algorithm and is closely connected to treatment effect distribution estimation -- both of which are of independent interest and hold promise for broader applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04654v2</guid>
      <category>math.ST</category>
      <category>econ.EM</category>
      <category>stat.TH</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Keunwoo Lim, Ting Ye, Fang Han</dc:creator>
    </item>
    <item>
      <title>Attainability of Two-Point Testing Rates for Finite-Sample Location Estimation</title>
      <link>https://arxiv.org/abs/2502.05730</link>
      <description>arXiv:2502.05730v2 Announce Type: replace 
Abstract: LeCam's two-point testing method yields perhaps the simplest lower bound for estimating the mean of a distribution: roughly, if it is impossible to well-distinguish a distribution centered at $\mu$ from the same distribution centered at $\mu+\Delta$, then it is impossible to estimate the mean by better than $\Delta/2$. It is setting-dependent whether or not a nearly matching upper bound is attainable. We study the conditions under which the two-point testing lower bound can be attained for univariate mean estimation; both in the setting of location estimation (where the distribution is known up to translation) and adaptive location estimation (unknown distribution). Roughly, we will say an estimate nearly attains the two-point testing lower bound if it incurs error that is at most polylogarithmically larger than the Hellinger modulus of continuity for $\tilde{\Omega}(n)$ samples.
  Adaptive location estimation is particularly interesting as some distributions admit much better guarantees than sub-Gaussian rates (e.g. $\operatorname{Unif}(\mu-1,\mu+1)$ permits error $\Theta(\frac{1}{n})$, while the sub-Gaussian rate is $\Theta(\frac{1}{\sqrt{n}})$), yet it is not obvious whether these rates may be adaptively attained by one unified approach. Our main result designs an algorithm that nearly attains the two-point testing rate for mixtures of symmetric, log-concave distributions with a common mean. Moreover, this algorithm runs in near-linear time and is parameter-free. In contrast, we show the two-point testing rate is not nearly attainable even for symmetric, unimodal distributions.
  We complement this with results for location estimation, showing the two-point testing rate is nearly attainable for unimodal distributions, but unattainable for symmetric distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05730v2</guid>
      <category>math.ST</category>
      <category>cs.DS</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Spencer Compton, Gregory Valiant</dc:creator>
    </item>
    <item>
      <title>Nonparametric Estimation in Uniform Deconvolution and Interval Censoring</title>
      <link>https://arxiv.org/abs/2504.14555</link>
      <description>arXiv:2504.14555v2 Announce Type: replace 
Abstract: In the uniform deconvolution problem one is interested in estimating the distribution function $F_0$ of a nonnegative random variable, based on a sample with additive uniform noise. A peculiar and not well understood phenomenon of the nonparametric maximum likelihood estimator in this setting is the dichotomy between the situations where $F_0(1)=1$ and $F_0(1)&lt;1$. If $F_0(1)=1$, the MLE can be computed in a straightforward way and its asymptotic pointwise behavior can be derived using the connection to the so-called current status problem. However, if $F_0(1)&lt;1$, one needs an iterative procedure to compute it and the asymptotic pointwise behavior of the nonparametric maximum likelihood estimator is not known. In this paper we describe the problem, connect it to interval censoring problems and a more general model studied in Groeneboom (2024) to state two competing naturally occurring conjectures for the case $F_0(1)&lt;1$. Asymptotic arguments related to smooth functional theory and extensive simulations lead us to to bet on one of these two conjectures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14555v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Piet Groeneboom, Geurt Jongbloed</dc:creator>
    </item>
    <item>
      <title>Convergence of Diffusion Models Under the Manifold Hypothesis in High-Dimensions</title>
      <link>https://arxiv.org/abs/2409.18804</link>
      <description>arXiv:2409.18804v2 Announce Type: replace-cross 
Abstract: Denoising Diffusion Probabilistic Models (DDPM) are powerful state-of-the-art methods used to generate synthetic data from high-dimensional data distributions and are widely used for image, audio, and video generation as well as many more applications in science and beyond. The \textit{manifold hypothesis} states that high-dimensional data often lie on lower-dimensional manifolds within the ambient space, and is widely believed to hold in provided examples. While recent results have provided invaluable insight into how diffusion models adapt to the manifold hypothesis, they do not capture the great empirical success of these models, making this a very fruitful research direction.
  In this work, we study DDPMs under the manifold hypothesis and prove that they achieve rates independent of the ambient dimension in terms of score learning. In terms of sampling complexity, we obtain rates independent of the ambient dimension w.r.t. the Kullback-Leibler divergence, and $O(\sqrt{D})$ w.r.t. the Wasserstein distance. We do this by developing a new framework connecting diffusion models to the well-studied theory of extrema of Gaussian Processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.18804v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Iskander Azangulov, George Deligiannidis, Judith Rousseau</dc:creator>
    </item>
    <item>
      <title>Linear Convergence of Diffusion Models Under the Manifold Hypothesis</title>
      <link>https://arxiv.org/abs/2410.09046</link>
      <description>arXiv:2410.09046v2 Announce Type: replace-cross 
Abstract: Score-matching generative models have proven successful at sampling from complex high-dimensional data distributions. In many applications, this distribution is believed to concentrate on a much lower $d$-dimensional manifold embedded into $D$-dimensional space; this is known as the manifold hypothesis. The current best-known convergence guarantees are either linear in $D$ or polynomial (superlinear) in $d$. The latter exploits a novel integration scheme for the backward SDE. We take the best of both worlds and show that the number of steps diffusion models require in order to converge in Kullback-Leibler~(KL) divergence is linear (up to logarithmic terms) in the intrinsic dimension $d$. Moreover, we show that this linear dependency is sharp.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09046v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Peter Potaptchik, Iskander Azangulov, George Deligiannidis</dc:creator>
    </item>
    <item>
      <title>Proofs for Folklore Theorems on the Radon-Nikodym Derivative</title>
      <link>https://arxiv.org/abs/2501.18374</link>
      <description>arXiv:2501.18374v2 Announce Type: replace-cross 
Abstract: In this paper, rigorous statements and formal proofs are presented for both foundational and advanced folklore theorems on the Radon-Nikodym derivative. The cases of conditional and marginal probability measures are carefully considered, which leads to an identity involving the sum of mutual and lautum information suggesting a new interpretation for such a sum.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18374v2</guid>
      <category>cs.IT</category>
      <category>math.HO</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yaiza Bermudez, Gaetan Bisson, I\~naki Esnaola, Samir M. Perlaza</dc:creator>
    </item>
  </channel>
</rss>
