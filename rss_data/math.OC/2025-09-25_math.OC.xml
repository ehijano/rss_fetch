<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 26 Sep 2025 04:00:14 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 26 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Automated algorithm design for convex optimization problems with linear equality constraints</title>
      <link>https://arxiv.org/abs/2509.20746</link>
      <description>arXiv:2509.20746v1 Announce Type: new 
Abstract: Synthesis of optimization algorithms typically follows a {\em design-then-analyze\/} approach, which can obscure fundamental performance limits and hinder the systematic development of algorithms that operate near these limits. Recently, a framework grounded in robust control theory has emerged as a powerful tool for automating algorithm synthesis. By integrating design and analysis stages, fundamental performance bounds are revealed and synthesis of algorithms that achieve them is enabled. In this paper, we apply this framework to design algorithms for solving strongly convex optimization problems with linear equality constraints. Our approach yields a single-loop, gradient-based algorithm whose convergence rate is independent of the condition number of the constraint matrix. This improves upon the best known rate within the same algorithm class, which depends on the product of the condition numbers of the objective function and the constraint matrix.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.20746v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <pubDate>Fri, 26 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ibrahim K. Ozaslan, Wuwei Wu, Jie Chen, Tryphon T. Georgiou, Mihailo R. Jovanovic</dc:creator>
    </item>
    <item>
      <title>Complexity of Error Bounds for Systems of Linear Inequalities</title>
      <link>https://arxiv.org/abs/2509.20814</link>
      <description>arXiv:2509.20814v1 Announce Type: new 
Abstract: Error bounds have been studied for over seventy years, beginning with Hoffman's 1952 result [ J. Res. Natl. Bur. Standards, 49(1952), 263-65], which provided a bound on the distance from any point to the solution set of a linear system. However, little is known about the inherent intractability of error bounds. This paper focuses on the complexity of error bounds and stbaility of error bounds for systems of linear inequalities. For the complexity of error bounds for linear inequalities, we reformulate this problem as the task of solving finitely many min-max problems-defined by certain rows of the given matrix over the sphere and then prove that this problem is not in the class P, but it is in the clathat there exist pseudo-polynomial time algorithms to solve both the error bounds problem and its complement. In particular, the complement is a number problem, but not NP-complete in the strong sense (unless P = NP). For the complexity of stability of error bounds, it is proved that this problem is not in the class P. However, such problem becomes polynomially solvable when the dimension is fixed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.20814v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 26 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Zhou Wei, Michel Thera, Jen-Chih Yao</dc:creator>
    </item>
    <item>
      <title>Universal Complexity Bounds for Universal Gradient Methods in Nonlinear Optimization</title>
      <link>https://arxiv.org/abs/2509.20902</link>
      <description>arXiv:2509.20902v1 Announce Type: new 
Abstract: In this paper, we provide the universal first-order methods of Composite Optimization with new complexity analysis. It delivers some universal convergence guarantees, which are not linked directly to any parametric problem class. However, they can be easily transformed into the rates of convergence for the particular problem classes by substituting the corresponding upper estimates for the Global Curvature Bound of the objective function. We analyze in this way the simple gradient method for nonconvex minimization, gradient methods for convex composite optimization, and their accelerated variant. For them, the only input parameter is the required accuracy of the approximate solution. The accelerated variant of our scheme automatically ensures the best possible rate of convergence simultaneously for all parametric problem classes containing the smooth part of the objective function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.20902v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 26 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yurii Nesterov</dc:creator>
    </item>
    <item>
      <title>$H^\infty$-control problem for a singular parabolic system with convection</title>
      <link>https://arxiv.org/abs/2509.20984</link>
      <description>arXiv:2509.20984v1 Announce Type: new 
Abstract: We study the $H^\infty-$control problem for an infinite dimensional parabolic system, with a convection term, perturbed by a singular inverse-square potential with control distributed in the interior of a domain, extending part of the results by G. Marinoschi (ESAIM: COCV, 2023).</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.20984v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 26 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cristian Cazacu, Gabriela Marinoschi, Teodor Rugin\u{a}</dc:creator>
    </item>
    <item>
      <title>Smoothing Binary Optimization: A Primal-Dual Perspective</title>
      <link>https://arxiv.org/abs/2509.21064</link>
      <description>arXiv:2509.21064v1 Announce Type: new 
Abstract: Binary optimization is a powerful tool for modeling combinatorial problems, yet scalable and theoretically sound solution methods remain elusive. Conventional solvers often rely on heuristic strategies with weak guarantees or struggle with large-scale instances. In this work, we introduce a novel primal-dual framework that reformulates unconstrained binary optimization as a continuous minimax problem, satisfying a strong max-min property. This reformulation effectively smooths the discrete problem, enabling the application of efficient gradient-based methods. We propose a simultaneous gradient descent-ascent algorithm that is highly parallelizable on GPUs and provably converges to a near-optimal solution in linear time. Extensive experiments on large-scale problems--including Max-Cut, MaxSAT, and Maximum Independent Set with up to 50,000 variables--demonstrate that our method identifies high-quality solutions within seconds, significantly outperforming state-of-the-art alternatives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21064v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 26 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wenbo Liu, Akang Wang, Dun Ma, Hongyi Jiang, Jianghua Wu, Wenguo Yang</dc:creator>
    </item>
    <item>
      <title>A Riemannian Variational and Spectral Framework for High-Dimensional Sphere Packing: Barrier-Dynamics Reconciliation, Periodic Rigidity, and Discrete-Time Guarantees</title>
      <link>https://arxiv.org/abs/2509.21066</link>
      <description>arXiv:2509.21066v1 Announce Type: new 
Abstract: We develop a unified framework that reconciles a barrier based geometric model of periodic sphere packings with a provably convergent discrete time dynamics. First, we introduce a C2 interior barrier U_nu that is compatible with a strict feasibility safeguard and has a Lipschitz gradient on the iterates domain. Second, we correct and formalize the discrete update and give explicit step size and damping rules. Third, we prove barrier to KKT consistency and state an interior variant clarifying the role of the quadratic term. Fourth, we show that strict prestress stability implies periodic infinitesimal rigidity of the contact framework. Fifth, we establish a Lyapunov energy descent principle, an energy nonexpansive feasibility projection (including a joint x and lattice basis B variant), and local linear convergence for the Spectral Projected Interior Trajectory (Spit) method. We also provide practical Hessian vector formulas to estimate smoothness and curvature, minimal schematic illustrations, and a short reproducibility stub. The emphasis is on rigorous assumptions and proofs; empirical evaluation is deferred.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21066v1</guid>
      <category>math.OC</category>
      <category>math.MG</category>
      <pubDate>Fri, 26 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Faruk Alpay, Hamdi Alakkad</dc:creator>
    </item>
    <item>
      <title>Machine Learning Powered Feasible Path Framework with Adaptive Sampling for Black-box Optimization</title>
      <link>https://arxiv.org/abs/2509.21077</link>
      <description>arXiv:2509.21077v1 Announce Type: new 
Abstract: Black-box optimization (BBO) involves functions that are unknown, inexact and/or expensive-to-evaluate. Existing BBO algorithms face several challenges, including high computational cost from extensive evaluations, difficulty in handling complex constraints, lacking theoretical convergence guarantees and/or instability due to large solution quality variation. In this work, a machine learning-powered feasible path optimization framework (MLFP) is proposed for general BBO problems including complex constraints. An adaptive sampling strategy is first proposed to explore optimal regions and pre-filter potentially infeasible points to reduce evaluations. Machine learning algorithms are leveraged to develop surrogates of black-boxes. The feasible path algorithm is employed to accelerate theoretical convergence by updating independent variables rather than all. Computational studies demonstrate MLFP can rapidly and robustly converge around the KKT point, even training surrogates with small datasets. MLFP is superior to the state-of-the-art BBO algorithms, as it stably obtains the same or better solutions with fewer evaluations for benchmark examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21077v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 26 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zixuan Zhang, Xiaowei Song, Jiaming Li, Yujiao Zeng, Yaling Nie, Min Zhu, Dongyun Lu, Yibo Zhang, Xin Xiao, Jie Li</dc:creator>
    </item>
    <item>
      <title>On structured condition number of rational matrix functions</title>
      <link>https://arxiv.org/abs/2509.21101</link>
      <description>arXiv:2509.21101v1 Announce Type: new 
Abstract: We derive the necessary and sufficient conditions for the simple eigenvalues of rational matrix functions with symmetry structure to have the same normwise condition number with respect to arbitrary and structure-preserving perturbations. We obtain an exact expression for the structured condition number of simple eigenvalues of symmetric, skew-symmetric and even/odd rational matrix functions, and tight bounds are obtained for simple eigenvalues of Hermitian, skew-Hermitian, even/odd, and palindromic rational matrix functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21101v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 26 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ritwik Prabin Kalita, Anshul Prajapati, Punit Sharma</dc:creator>
    </item>
    <item>
      <title>A Recovery Theory for Diffusion Priors: Deterministic Analysis of the Implicit Prior Algorithm</title>
      <link>https://arxiv.org/abs/2509.20511</link>
      <description>arXiv:2509.20511v1 Announce Type: cross 
Abstract: Recovering high-dimensional signals from corrupted measurements is a central challenge in inverse problems. Recent advances in generative diffusion models have shown remarkable empirical success in providing strong data-driven priors, but rigorous recovery guarantees remain limited. In this work, we develop a theoretical framework for analyzing deterministic diffusion-based algorithms for inverse problems, focusing on a deterministic version of the algorithm proposed by Kadkhodaie \&amp; Simoncelli \cite{kadkhodaie2021stochastic}. First, we show that when the underlying data distribution concentrates on a low-dimensional model set, the associated noise-convolved scores can be interpreted as time-varying projections onto such a set. This leads to interpreting previous algorithms using diffusion priors for inverse problems as generalized projected gradient descent methods with varying projections. When the sensing matrix satisfies a restricted isometry property over the model set, we can derive quantitative convergence rates that depend explicitly on the noise schedule. We apply our framework to two instructive data distributions: uniform distributions over low-dimensional compact, convex sets and low-rank Gaussian mixture models. In the latter setting, we can establish global convergence guarantees despite the nonconvexity of the underlying model set.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.20511v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Fri, 26 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Oscar Leong, Yann Traonmilin</dc:creator>
    </item>
    <item>
      <title>Optimal phase change for a generalized Grover's algorithm</title>
      <link>https://arxiv.org/abs/2509.20610</link>
      <description>arXiv:2509.20610v1 Announce Type: cross 
Abstract: We study the generalized Grover's algorithm with an arbitrary amplitude vector to find the optimal phase change for maximizing the gain in probability for the target of each iteration. In the classic setting of Grover's algorithm with a real initial amplitude vector, we find that a phase change of $\pi$ stays optimal until the probability of observing the target is quite close to 1. We provide a formula for identifying this cut-off point based on the size of the data set. When the amplitude is truly complex, we find that the optimal phase change depends non-trivially on the complexity of the amplitude vector. We provide an optimization formula to identify the required optimal phase change.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.20610v1</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <pubDate>Fri, 26 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christopher Cardullo, Min Kang</dc:creator>
    </item>
    <item>
      <title>State-Constrained Chemical Reactions: Discrete-to-Continuous Hamilton--Jacobi Equations and Large Deviations</title>
      <link>https://arxiv.org/abs/2509.20747</link>
      <description>arXiv:2509.20747v1 Announce Type: cross 
Abstract: We study the macroscopic behavior of chemical reactions modeled as random time-changed Poisson processes on discrete state spaces. Using the WKB reformulation, the backward equation of the rescaled process leads to a discrete Hamilton--Jacobi equation with state constraints. As the grid size tends to zero, the limiting solution and its associated variational representation are closely connected to the good rate function of the large deviation principle for state-constrained chemical reactions in the thermodynamic limit. In this work, we focus on the limiting behavior of discrete Hamilton--Jacobi equations defined on bounded domains with state-constraint boundary conditions. For a single chemical reaction, we show that, under a suitable reparametrization, the solution of the discrete Hamilton--Jacobi equation converges to the solution of a continuous Hamilton--Jacobi equation with a Neumann boundary condition. Building on this convergence result and the associated variational representation, we establish the large deviation principle for the rescaled chemical reaction process in bounded domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.20747v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Fri, 26 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuan Gao, Yuxi Han</dc:creator>
    </item>
    <item>
      <title>Gaussian splatting holography</title>
      <link>https://arxiv.org/abs/2509.20774</link>
      <description>arXiv:2509.20774v1 Announce Type: cross 
Abstract: In-line holography offers high space-bandwidth product imaging with a simplified lens-free optical system. However, in-line holographic reconstruction is troubled by twin images arising from the Hermitian symmetry of complex fields. Twin images disrupt the reconstruction in solving the ill-posed phase retrieval problem. The known parameters are less than the unknown parameters, causing phase ambiguities. State-of-the-art deep-learning or non-learning methods face challenges in balancing data fidelity with twin-image disturbance. We propose the Gaussian splatting holography (GSH) for twin-image-suppressed holographic reconstruction. GSH uses Gaussian splatting for optical field representation and compresses the number of unknown parameters by a maximum of 15 folds, transforming the original ill-posed phase retrieval into a well-posed one with reduced phase ambiguities. Additionally, the Gaussian splatting tends to form sharp patterns rather than those with noisy twin-image backgrounds as each Gaussian has a spatially slow-varying profile. Experiments show that GSH achieves constraint-free recovery for in-line holography with accuracy comparable to state-of-the-art constraint-based methods, with an average peak signal-to-noise ratio equal to 26 dB, and structure similarity equal to 0.8. Combined with total variation, GSH can be further improved, obtaining a peak signal-to-noise ratio of 31 dB, and a high compression ability of up to 15 folds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.20774v1</guid>
      <category>physics.optics</category>
      <category>math.OC</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 26 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Shuhe Zhang, Liangcai Cao</dc:creator>
    </item>
    <item>
      <title>Feature Augmentation of GNNs for ILPs: Local Uniqueness Suffices</title>
      <link>https://arxiv.org/abs/2509.21000</link>
      <description>arXiv:2509.21000v1 Announce Type: cross 
Abstract: Integer Linear Programs (ILPs) are central to real-world optimizations but notoriously difficult to solve. Learning to Optimize (L2O) has emerged as a promising paradigm, with Graph Neural Networks (GNNs) serving as the standard backbone. However, standard anonymous GNNs are limited in expressiveness for ILPs, and the common enhancement of augmenting nodes with globally unique identifiers (UIDs) typically introduces spurious correlations that severely harm generalization. To address this tradeoff, we propose a parsimonious Local-UID scheme based on d-hop uniqueness coloring, which ensures identifiers are unique only within each node's d-hop neighborhood. Building on this scheme, we introduce ColorGNN, which incorporates color information via color-conditioned embeddings, and ColorUID, a lightweight feature-level variant. We prove that for d-layer networks, Local-UIDs achieve the expressive power of Global-UIDs while offering stronger generalization. Extensive experiments show that our approach (i) yields substantial gains on three ILP benchmarks, (ii) exhibits strong OOD generalization on linear programming datasets, and (iii) further improves a general graph-level task when paired with a state-of-the-art method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21000v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 26 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Qingyu Han, Qian Li, Linxin Yang, Qian Chen, Qingjiang Shi, Ruoyu Sun</dc:creator>
    </item>
    <item>
      <title>Inverse Reinforcement Learning Using Just Classification and a Few Regressions</title>
      <link>https://arxiv.org/abs/2509.21172</link>
      <description>arXiv:2509.21172v1 Announce Type: cross 
Abstract: Inverse reinforcement learning (IRL) aims to explain observed behavior by uncovering an underlying reward. In the maximum-entropy or Gumbel-shocks-to-reward frameworks, this amounts to fitting a reward function and a soft value function that together satisfy the soft Bellman consistency condition and maximize the likelihood of observed actions. While this perspective has had enormous impact in imitation learning for robotics and understanding dynamic choices in economics, practical learning algorithms often involve delicate inner-loop optimization, repeated dynamic programming, or adversarial training, all of which complicate the use of modern, highly expressive function approximators like neural nets and boosting. We revisit softmax IRL and show that the population maximum-likelihood solution is characterized by a linear fixed-point equation involving the behavior policy. This observation reduces IRL to two off-the-shelf supervised learning problems: probabilistic classification to estimate the behavior policy, and iterative regression to solve the fixed point. The resulting method is simple and modular across function approximation classes and algorithms. We provide a precise characterization of the optimal solution, a generic oracle-based algorithm, finite-sample error bounds, and empirical results showing competitive or superior performance to MaxEnt IRL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21172v1</guid>
      <category>cs.LG</category>
      <category>econ.EM</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 26 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lars van der Laan, Nathan Kallus, Aur\'elien Bibaut</dc:creator>
    </item>
    <item>
      <title>Data-driven Neural Networks for Windkessel Parameter Calibration</title>
      <link>https://arxiv.org/abs/2509.21206</link>
      <description>arXiv:2509.21206v1 Announce Type: cross 
Abstract: In this work, we propose a novel method for calibrating Windkessel (WK) parameters in a dimensionally reduced 1D-0D coupled blood flow model. To this end, we design a data-driven neural network (NN)trained on simulated blood pressures in the left brachial artery. Once trained, the NN emulates the pressure pulse waves across the entire simulated domain, i.e., over time, space and varying WK parameters, with negligible error and computational effort. To calibrate the WK parameters on a measured pulse wave, the NN is extended by dummy neurons and retrained only on these. The main objective of this work is to assess the effectiveness of the method in various scenarios -- particularly, when the exact measurement location is unknown or the data are affected by noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21206v1</guid>
      <category>q-bio.TO</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>q-bio.QM</category>
      <pubDate>Fri, 26 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Benedikt Hoock, Tobias K\"oppl</dc:creator>
    </item>
    <item>
      <title>humancompatible.train: Implementing Optimization Algorithms for Stochastically-Constrained Stochastic Optimization Problems</title>
      <link>https://arxiv.org/abs/2509.21254</link>
      <description>arXiv:2509.21254v1 Announce Type: cross 
Abstract: There has been a considerable interest in constrained training of deep neural networks (DNNs) recently for applications such as fairness and safety. Several toolkits have been proposed for this task, yet there is still no industry standard. We present humancompatible.train (https://github.com/humancompatible/train), an easily-extendable PyTorch-based Python package for training DNNs with stochastic constraints. We implement multiple previously unimplemented algorithms for stochastically constrained stochastic optimization. We demonstrate the toolkit use by comparing two algorithms on a deep learning task with fairness constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21254v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 26 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrii Kliachkin, Jana Lep\v{s}ov\'a, Gilles Bareilles, Jakub Mare\v{c}ek</dc:creator>
    </item>
    <item>
      <title>A Linear-Quadratic Stackelberg Differential Game with Mixed Deterministic and Stochastic Controls</title>
      <link>https://arxiv.org/abs/2004.00653</link>
      <description>arXiv:2004.00653v2 Announce Type: replace 
Abstract: This paper is concerned with a linear-quadratic (LQ) leader-follower differential game with mixed deterministic and stochastic controls. In the game, the follower is a random controller which means that the follower can choose adapted stochastic processes, while the leader is a deterministic controller which means that the leader can choose only deterministic time functions. Such problem is motivated by a pension fund insurance problem, with government, supervisory or employer being a deterministic leader and individual producer or retail investor being a random follower. An open-loop Stackelberg equilibrium solution is considered. First, an optimal control process of the follower is characterized by a stationary condition of forward-backward stochastic differential equation (FBSDE) and a convexity condition of SDE. Then it is represented as a linear functional of optimal state variable of the follower and the leader's control variable, via a classical Riccati equation. Then an optimal control function of the leader is first characterized by a convexity condition of FBSDE and a stationary condition of mean-field type FBSDE. And it is represented as a functional of expectation of optimal state variable of the leader, with the help of a system consisting of two cross-coupled Riccati equations and a two-point boundary value problem of ordinary differential equations (ODEs). The solvabilities of this new system of Riccati equations and two-point boundary value problem and investigated.</description>
      <guid isPermaLink="false">oai:arXiv.org:2004.00653v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 26 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jingtao Shi, Guangchen Wang</dc:creator>
    </item>
    <item>
      <title>Data-driven h2 model reduction for linear discrete-time systems</title>
      <link>https://arxiv.org/abs/2401.05774</link>
      <description>arXiv:2401.05774v3 Announce Type: replace 
Abstract: We present a data-driven framework for $h^{2}$-optimal model reduction for linear discrete-time systems. Our main contribution is to create optimal reduced-order models in the $h^{2}$-norm sense directly from the measurement data alone, without using the information about the original system. In particular, we focus on the fact that the gradients of the $h^{2}$ model reduction problem are expressed using the discrete-time Lyapunov equation and the discrete-time Sylvester equation, and derive the data-driven gradients. The proposed algorithm uses the output of an existing MOR as the initial point, and convergence to a stationary point is guaranteed under certain assumptions. In numerical experiments, we demonstrate that, for a modeling task in neuroscience, our method constructs a reduced-order model that outperforms DMDc in terms of the $h^{2}$-norm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.05774v3</guid>
      <category>math.OC</category>
      <pubDate>Fri, 26 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hiroki Sakamoto, Kazuhiro Sato</dc:creator>
    </item>
    <item>
      <title>Monotone Lipschitz-Gradient Denoiser: Explainability of Operator Regularization Approaches Free From Lipschitz Constant Control</title>
      <link>https://arxiv.org/abs/2406.04676</link>
      <description>arXiv:2406.04676v3 Announce Type: replace 
Abstract: This paper addresses explainability of the operator-regularization approach under the use of monotone Lipschitz-gradient (MoL-Grad) denoiser -- an operator that can be expressed as the Lipschitz continuous gradient of a differentiable convex function. We prove that an operator is a MoL-Grad denoiser if and only if it is the ``single-valued'' proximity operator of a weakly convex function. An extension of Moreau's decomposition is also shown with respect to a weakly convex function and the conjugate of its convexified function. Under these arguments, two specific algorithms, the forward-backward splitting algorithm and the primal-dual splitting algorithm, are considered, both employing MoL-Grad denoisers. These algorithms generate a sequence of vectors converging weakly, under conditions, to a minimizer of a certain cost function which involves an ``implicit regularizer'' induced by the denoiser. Unlike the previous studies of operator regularization, our framework requires no control of the Lipschitz constant in learning the denoiser. The theoretical findings are supported by simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04676v3</guid>
      <category>math.OC</category>
      <category>eess.SP</category>
      <pubDate>Fri, 26 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TSP.2025.3580667</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Signal Processing, vol. 73, pp. 3378 - 3393, 2025</arxiv:journal_reference>
      <dc:creator>Masahiro Yukawa, Isao Yamada</dc:creator>
    </item>
    <item>
      <title>Primal-dual proximal bundle and conditional gradient methods for convex problems</title>
      <link>https://arxiv.org/abs/2412.00585</link>
      <description>arXiv:2412.00585v4 Announce Type: replace 
Abstract: This paper studies the primal-dual convergence and iteration-complexity of proximal bundle methods for solving nonsmooth problems with convex structures. More specifically, we develop a family of primal-dual proximal bundle methods for solving convex nonsmooth composite optimization problems and establish the iteration-complexity in terms of a primal-dual gap. We also propose a class of proximal bundle methods for solving convex-concave nonsmooth composite saddle-point problems and establish the iteration-complexity to find an approximate saddle-point. This paper places special emphasis on the primal-dual perspective of the proximal bundle method. In particular, we discover an interesting duality between the conditional gradient method and the cutting-plane scheme used within the proximal bundle method. Leveraging this duality, we further develop novel variants of both the conditional gradient method and the cutting-plane scheme. Additionally, we report numerical experiments to demonstrate the effectiveness and efficiency of the proposed proximal bundle methods in comparison with the subgradient method for solving a regularized matrix game.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00585v4</guid>
      <category>math.OC</category>
      <pubDate>Fri, 26 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiaming Liang</dc:creator>
    </item>
    <item>
      <title>Data-driven stabilization of polynomial systems using density functions</title>
      <link>https://arxiv.org/abs/2503.07092</link>
      <description>arXiv:2503.07092v2 Announce Type: replace 
Abstract: This paper studies data-driven stabilization of a class of unknown polynomial systems using data corrupted by bounded noise. Existing work addressing this problem has focused on designing a controller and a Lyapunov function so that a certain state-dependent matrix is negative definite, which ensures asymptotic stability of all closed-loop systems compatible with the data. However, as we demonstrate in this paper, considering the negative definiteness of this matrix introduces conservatism, which limits the applicability of current approaches. To tackle this issue, we develop a new method for the data-driven stabilization of polynomial systems using the concept of density functions. The control design consists of two steps. Firstly, a dual Lyapunov theorem is used to formulate a sum of squares program that allows us to compute a rational state feedback controller for all systems compatible with the data. By the dual Lyapunov theorem, this controller ensures that the trajectories of the closed-loop system converge to zero for almost all initial states. Secondly, we propose a method to verify whether the designed controller achieves asymptotic stability of all closed-loop systems compatible with the data. Apart from reducing conservatism of existing methods, the proposed approach can also readily take into account prior knowledge on the system parameters. A key technical result developed in this paper is a new type of S-lemma for a specific class of matrices that, in contrast to the classical S-lemma, avoids the use of multipliers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.07092v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 26 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huayuan Huang, M. Kanat Camlibel, Raffaella Carloni, Henk J. van Waarde</dc:creator>
    </item>
    <item>
      <title>FEM-based A-optimal sensor placement for heat source inversion from final time measurement</title>
      <link>https://arxiv.org/abs/2509.19679</link>
      <description>arXiv:2509.19679v2 Announce Type: replace 
Abstract: Within the field of optimal experimental design, \emph{sensor placement} refers to the act of finding the optimal locations of data collecting sensors, with the aim to optimise reconstruction of an unknown parameter from finite data. In this work, we investigate sensor placement for the inverse problem of reconstructing a heat source given final time measurements. Employing forward and adjoint analysis of this PDE-driven model, we show how one can leverage the first author's recently invented \emph{redundant-dominant $p$-continuation} algorithm to obtain binary A-optimal sensor placements also for this time-dependent model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.19679v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 26 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christian Aarset, Tram Thi Ngoc Nguyen</dc:creator>
    </item>
    <item>
      <title>The Stochastic Steepest Descent Method for Robust Optimization in Banach Spaces</title>
      <link>https://arxiv.org/abs/2308.06116</link>
      <description>arXiv:2308.06116v2 Announce Type: replace-cross 
Abstract: Stochastic gradient methods have been a popular and powerful choice of optimization methods, aimed at minimizing functions. Their advantage lies in the fact that that one approximates the gradient as opposed to using the full Jacobian matrix. One research direction, related to this, has been on the application to infinite-dimensional problems, where one may naturally have a Hilbert space framework. However, there has been limited work done on considering this in a more general setup, such as where the natural framework is that of a Banach space. This article aims to address this by the introduction of a novel stochastic method, the stochastic steepest descent method (SSD). The SSD will follow the spirit of stochastic gradient descent, which utilizes Riesz representation to identify gradients and derivatives. Our choice for using such a method is that it naturally allows one to adopt a Banach space setting, for which recent applications have exploited the benefit of this, such as in PDE-constrained shape optimization. We provide a convergence theory related to this under mild assumptions. Furthermore, we demonstrate the performance of this method on a couple of numerical applications, namely a $p$-Laplacian and an optimal control problem. Our assumptions are verified in these applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.06116v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 26 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Neil K. Chada, Philip J. Herbert</dc:creator>
    </item>
    <item>
      <title>Geometry and factorization of multivariate Markov chains with applications to MCMC acceleration</title>
      <link>https://arxiv.org/abs/2404.12589</link>
      <description>arXiv:2404.12589v5 Announce Type: replace-cross 
Abstract: This paper analyzes the factorizability and geometry of transition matrices of multivariate Markov chains. Specifically, we demonstrate that the induced chains on factors of a product space can be regarded as information projections with respect to the Kullback-Leibler divergence. This perspective yields Han-Shearer type inequalities and submodularity of the entropy rate of Markov chains, as well as applications in the context of large deviations and mixing time comparison. As concrete algorithmic applications in Markov chain Monte Carlo (MCMC), we provide two illustrations based on lifted MCMC and swapping algorithm respectively to demonstrate projection samplers improve mixing over the original samplers. The projection sampler based on the swapping algorithm resamples the highest-temperature coordinate at stationarity at each step, and we prove that such practice accelerates the mixing time by multiplicative factors related to the number of temperatures and the dimension of the underlying state space when compared with the original swapping algorithm. Through simple numerical experiments on a bimodal target distribution, we show that the projection samplers mix effectively, in contrast to lifted MCMC and the swapping algorithm, which mix less well.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12589v5</guid>
      <category>math.PR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>stat.CO</category>
      <pubDate>Fri, 26 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael C. H. Choi, Youjia Wang, Geoffrey Wolfer</dc:creator>
    </item>
    <item>
      <title>Two-level overlapping additive Schwarz preconditioner for training scientific machine learning applications</title>
      <link>https://arxiv.org/abs/2406.10997</link>
      <description>arXiv:2406.10997v2 Announce Type: replace-cross 
Abstract: We introduce a novel two-level overlapping additive Schwarz preconditioner for accelerating the training of scientific machine learning applications. The design of the proposed preconditioner is motivated by the nonlinear two-level overlapping additive Schwarz preconditioner. The neural network parameters are decomposed into groups (subdomains) with overlapping regions. In addition, the network's feed-forward structure is indirectly imposed through a novel subdomain-wise synchronization strategy and a coarse-level training step. Through a series of numerical experiments, which consider physics-informed neural networks and operator learning approaches, we demonstrate that the proposed two-level preconditioner significantly speeds up the convergence of the standard (LBFGS) optimizer while also yielding more accurate machine learning models. Moreover, the devised preconditioner is designed to take advantage of model-parallel computations, which can further reduce the training time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10997v2</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 26 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.cma.2025.118400</arxiv:DOI>
      <arxiv:journal_reference>Computer Methods in Applied Mechanics and Engineering. 448 (2026) 118400</arxiv:journal_reference>
      <dc:creator>Youngkyu Lee, Alena Kopani\v{c}\'akov\'a, George Em Karniadakis</dc:creator>
    </item>
    <item>
      <title>Understanding Optimization in Deep Learning with Central Flows</title>
      <link>https://arxiv.org/abs/2410.24206</link>
      <description>arXiv:2410.24206v2 Announce Type: replace-cross 
Abstract: Traditional theories of optimization cannot describe the dynamics of optimization in deep learning, even in the simple setting of deterministic training. The challenge is that optimizers typically operate in a complex, oscillatory regime called the "edge of stability." In this paper, we develop theory that can describe the dynamics of optimization in this regime. Our key insight is that while the *exact* trajectory of an oscillatory optimizer may be challenging to analyze, the *time-averaged* (i.e. smoothed) trajectory is often much more tractable. To analyze an optimizer, we derive a differential equation called a "central flow" that characterizes this time-averaged trajectory. We empirically show that these central flows can predict long-term optimization trajectories for generic neural networks with a high degree of numerical accuracy. By interpreting these central flows, we are able to understand how gradient descent makes progress even as the loss sometimes goes up; how adaptive optimizers "adapt" to the local loss landscape; and how adaptive optimizers implicitly navigate towards regions where they can take larger steps. Our results suggest that central flows can be a valuable theoretical tool for reasoning about optimization in deep learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.24206v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 26 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jeremy M. Cohen, Alex Damian, Ameet Talwalkar, J. Zico Kolter, Jason D. Lee</dc:creator>
    </item>
    <item>
      <title>The Asymptotic Behavior of Attention in Transformers</title>
      <link>https://arxiv.org/abs/2412.02682</link>
      <description>arXiv:2412.02682v2 Announce Type: replace-cross 
Abstract: The transformer architecture has become the foundation of modern Large Language Models (LLMs), yet its theoretical properties are still not well understood. As with classic neural networks, a common approach to improve these models is to increase their size and depth. However, such strategies may be suboptimal, as several works have shown that adding more layers yields increasingly diminishing returns. More importantly, prior studies have shown that increasing depth may lead to model collapse, i.e., all the tokens converge to a single cluster, undermining the ability of LLMs to generate diverse outputs. Building on differential equation models for the transformer dynamics, we prove that all the tokens in a transformer asymptotically converge to a cluster as depth increases. At the technical level we leverage tools from control theory, including consensus dynamics on manifolds and input-to-state stability (ISS). We then extend our analysis to autoregressive models, exploiting their structure to further generalize the theoretical guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02682v2</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Fri, 26 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>\'Alvaro Rodr\'iguez Abella, Jo\~ao Pedro Silvestre, Paulo Tabuada</dc:creator>
    </item>
    <item>
      <title>Bayesian Optimization with Preference Exploration using a Monotonic Neural Network Ensemble</title>
      <link>https://arxiv.org/abs/2501.18792</link>
      <description>arXiv:2501.18792v2 Announce Type: replace-cross 
Abstract: Many real-world black-box optimization problems have multiple conflicting objectives. Rather than attempting to approximate the entire set of Pareto-optimal solutions, interactive preference learning allows to focus the search on the most relevant subset. However, few previous studies have exploited the fact that utility functions are usually monotonic. In this paper, we address the Bayesian Optimization with Preference Exploration (BOPE) problem and propose using a neural network ensemble as a utility surrogate model. This approach naturally integrates monotonicity and supports pairwise comparison data. Our experiments demonstrate that the proposed method outperforms state-of-the-art approaches and exhibits robustness to noise in utility evaluations. An ablation study highlights the critical role of monotonicity in enhancing performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18792v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 26 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hanyang Wang, Juergen Branke, Matthias Poloczek</dc:creator>
    </item>
    <item>
      <title>Application of Battery Storage to Switching Predictive Control of Power Distribution Systems Including Road Heating</title>
      <link>https://arxiv.org/abs/2503.24104</link>
      <description>arXiv:2503.24104v3 Announce Type: replace-cross 
Abstract: In regions with heavy snowfall, the living environment is becoming a serious problem due to heavy snow accumulation. A road heating is an electrical device which promotes snow melting by burying a heating cable as a thermal source underground in such regions. When integrating the road heating into power distribution systems, we need to optimize the flow of electric power by appropriately integrating distributed power sources and conventional power distribution equipment. In this paper, we introduce a battery storage to the power distribution system including road heating, and extend the predictive switching control of the systems due to the authors' previous study to the case where battery storage is installed. As a main result, we propose a predictive switching control that utilizes photovoltaic (PV) power generation and surplus power stored in the battery storage effectively, and achieves the reduction of distribution loss, attenuation of voltage fluctuation, and efficient snow melting, simultaneously. We verify the effectiveness of the application of battery storage through numerical simulation using actual time series data of weather conditions and active power of the PV power generation and load.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.24104v3</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 26 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chiaki Kojima, Yuya Muto, Hikaru Akutsu, Rinnosuke Shima, Yoshihiko Susuki</dc:creator>
    </item>
    <item>
      <title>A Finite-Time Analysis of TD Learning with Linear Function Approximation without Projections or Strong Convexity</title>
      <link>https://arxiv.org/abs/2506.01052</link>
      <description>arXiv:2506.01052v2 Announce Type: replace-cross 
Abstract: We investigate the finite-time convergence properties of Temporal Difference (TD) learning with linear function approximation, a cornerstone algorithm in the field of reinforcement learning.
  We are interested in the so-called ``robust'' setting, where the convergence guarantee does not depend on the minimal curvature of the potential function.
  While prior work has established convergence guarantees in this setting, these results typically rely on the assumption that each iterate is projected onto a bounded set, a condition that is both artificial and does not match the current practice.
  In this paper, we challenge the necessity of such an assumption and present a refined analysis of TD learning. For the first time, we show that the simple projection-free variant converges with a rate of $\widetilde{\mathcal{O}}(\frac{||\theta^*||^2_2}{\sqrt{T}})$, even in the presence of Markovian noise. Our analysis reveals a novel self-bounding property of the TD updates and exploits it to guarantee bounded iterates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01052v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 26 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wei-Cheng Lee, Francesco Orabona</dc:creator>
    </item>
    <item>
      <title>Systematic Constraint Formulation and Collision-Free Trajectory Planning Using Space-Time Graphs of Convex Sets</title>
      <link>https://arxiv.org/abs/2508.10203</link>
      <description>arXiv:2508.10203v2 Announce Type: replace-cross 
Abstract: In this paper, we create optimal, collision-free, time-dependent trajectories through cluttered dynamic environments. The many spatial and temporal constraints make finding an initial guess for a numerical solver difficult. Graphs of Convex Sets (GCS) and the recently developed Space-Time Graphs of Convex Sets (ST-GCS) enable us to generate minimum distance collision-free trajectories without providing an initial guess to the solver. We also explore the derivation of general GCS-compatible constraints and document an intuitive strategy for adapting general constraints to the framework. We show that ST-GCS produces equivalent trajectories to the standard GCS formulation when the environment is static, as well as globally optimal trajectories in cluttered dynamic environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10203v2</guid>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 26 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Matthew D. Osburn, Cameron K. Peterson, John L. Salmon</dc:creator>
    </item>
    <item>
      <title>Isogeometric Topology Optimization Based on Topological Derivatives</title>
      <link>https://arxiv.org/abs/2509.09236</link>
      <description>arXiv:2509.09236v2 Announce Type: replace-cross 
Abstract: Topology optimization is a valuable tool in engineering, facilitating the design of optimized structures. However, topological changes often require a remeshing step, which can become challenging. In this work, we propose an isogeometric approach to topology optimization driven by topological derivatives. The combination of a level-set method together with an immersed isogeometric framework allows seamless geometry updates without the necessity of remeshing. At the same time, topological derivatives provide topological modifications without the need to define initial holes [7]. We investigate the influence of higher-degree basis functions in both the level-set representation and the approximation of the solution. Two numerical examples demonstrate the proposed approach, showing that employing higher-degree basis functions for approximating the solution improves accuracy, while linear basis functions remain sufficient for the level-set function representation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.09236v2</guid>
      <category>math.NA</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 26 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guilherme Henrique Teixeira, Nepomuk Krenn, Peter Gangl, Benjamin Marussig</dc:creator>
    </item>
  </channel>
</rss>
