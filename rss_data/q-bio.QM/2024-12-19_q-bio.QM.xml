<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.QM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.QM</link>
    <description>q-bio.QM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.QM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 20 Dec 2024 02:56:03 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Solving the Inverse Problem of Magnetic Induction Tomography Using Gauss-Newton Iterative Method and Zoning Technique to Reduce Unknown Coefficients</title>
      <link>https://arxiv.org/abs/2412.13199</link>
      <description>arXiv:2412.13199v1 Announce Type: new 
Abstract: Magnetic Induction Tomography (MIT) is a promising modality for noninvasive imaging due to its contactless and nonionizing technology. In this imaging method, a primary magnetic field is applied by excitation coils to induce eddy currents in the material to be studied, and a secondary magnetic field is detected from these eddy currents using sensing coils. The image (spatial distribution of electrical conductivity) is then reconstructed using measurement data, the initial estimation of electrical conductivity, and the iterative solution of forward and inverse problems. The inverse problem can be solved using one-step linear, iterative nonlinear, and special methods. In general, the MIT inverse problem can be solved by Gauss- Newton iterative method with acceptable accuracy. In this paper, this algorithm is extended and the zoning technique is employed for the reduction of unknown coefficients. The simulation results obtained by the proposed method are compared with the real conductivity coefficients and the mean relative error rate is reduced to 24.22%. On the other hand, Gauss-Newton iterative method is extended for solving the inverse problem of the MIT, and sensitivity measurement matrices are extracted in different experimental and normalization conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13199v1</guid>
      <category>q-bio.QM</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <arxiv:DOI>10.22108/ISEE.2022.131265.1523</arxiv:DOI>
      <dc:creator>Mohammad Reza Yousefi, Amin Dehghani, Ali Asghar Amini, S. M. Mehdi Mirtalaei</dc:creator>
    </item>
    <item>
      <title>Generative modeling of protein ensembles guided by crystallographic electron densities</title>
      <link>https://arxiv.org/abs/2412.13223</link>
      <description>arXiv:2412.13223v1 Announce Type: new 
Abstract: Proteins are dynamic, adopting ensembles of conformations. The nature of this conformational heterogenity is imprinted in the raw electron density measurements obtained from X-ray crystallography experiments. Fitting an ensemble of protein structures to these measurements is a challenging, ill-posed inverse problem. We propose a non-i.i.d. ensemble guidance approach to solve this problem using existing protein structure generative models and demonstrate that it accurately recovers complicated multi-modal alternate protein backbone conformations observed in certain single crystal measurements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13223v1</guid>
      <category>q-bio.QM</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sai Advaith Maddipatla, Nadav Bojan Sellam, Sanketh Vedula, Ailie Marx, Alex Bronstein</dc:creator>
    </item>
    <item>
      <title>TSEML: A task-specific embedding-based method for few-shot classification of cancer molecular subtypes</title>
      <link>https://arxiv.org/abs/2412.13228</link>
      <description>arXiv:2412.13228v1 Announce Type: new 
Abstract: Molecular subtyping of cancer is recognized as a critical and challenging upstream task for personalized therapy. Existing deep learning methods have achieved significant performance in this domain when abundant data samples are available. However, the acquisition of densely labeled samples for cancer molecular subtypes remains a significant challenge for conventional data-intensive deep learning approaches. In this work, we focus on the few-shot molecular subtype prediction problem in heterogeneous and small cancer datasets, aiming to enhance precise diagnosis and personalized treatment. We first construct a new few-shot dataset for cancer molecular subtype classification and auxiliary cancer classification, named TCGA Few-Shot, from existing publicly available datasets. To effectively leverage the relevant knowledge from both tasks, we introduce a task-specific embedding-based meta-learning framework (TSEML). TSEML leverages the synergistic strengths of a model-agnostic meta-learning (MAML) approach and a prototypical network (ProtoNet) to capture diverse and fine-grained features. Comparative experiments conducted on the TCGA Few-Shot dataset demonstrate that our TSEML framework achieves superior performance in addressing the problem of few-shot molecular subtype classification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13228v1</guid>
      <category>q-bio.QM</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>BIBM 2024</arxiv:journal_reference>
      <dc:creator>Ran Sua, Rui Shi, Hui Cui, Ping Xuan, Chengyan Fang, Xikang Feng, Qiangguo Jin</dc:creator>
    </item>
    <item>
      <title>Modeling therapy sequence for advanced cancer: A microsimulation approach leveraging Electronic Health Record data</title>
      <link>https://arxiv.org/abs/2412.13234</link>
      <description>arXiv:2412.13234v2 Announce Type: new 
Abstract: Many patients with advanced cancers undergo multiple lines of treatment. We develop methods for estimating quality-adjusted outcomes and cost-effectiveness of therapy sequences, informed by patient-level longitudinal data from Electronic Health Records (EHRs). We develop microsimulation models with a discrete-time health-state transition framework and propose two methods: one using multi-state models to estimate transition probabilities, and one using observed patient trajectories through the health states. We use bootstrap resampling to estimate standard errors. We create synthetic EHR-like datasets to evaluate these methods where within-patient transition times depend on covariates and a copula generator, and compare with Markov cohort models. We demonstrate these methods in two treatment sequences for advanced bladder cancer (cisplatin or carboplatin-based therapy followed by immunotherapy), incorporating external information on costs, utilities, and expected adverse event. Both methods produced well-calibrated overall survivals, although the trajectory approach was often superior. The multi-state model approach generated lower standard errors but was biased when compared to known results from the synthetic datasets. The observed trajectory approach mostly produced confidence intervals that covered known values. In the bladder cancer example, both methods result in a Net Monetary Benefit (NMB)&gt;0 for the cisplatin-based treatment sequence with a willingness to pay of $100,000 per quality-adjusted life year. Both microsimulation methods produce well-calibrated results and offer superior performance to a homogeneous Markov cohort approach when studying therapy sequence. Where available, patient level EHR-based data should be considered to inform cost-effectiveness models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13234v2</guid>
      <category>q-bio.QM</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elizabeth A. Handorf, J. Robert Beck, Daniel M. Geynisman</dc:creator>
    </item>
    <item>
      <title>Soft Modes as a Predictive Framework for Low Dimensional Biological Systems across Scales</title>
      <link>https://arxiv.org/abs/2412.13637</link>
      <description>arXiv:2412.13637v1 Announce Type: new 
Abstract: All biological systems are subject to perturbations: due to thermal fluctuations, external environments, or mutations. Yet, while biological systems are composed of thousands of interacting components, recent high-throughput experiments show that their response to perturbations is surprisingly low-dimensional: confined to only a few stereotyped changes out of the many possible. Here, we explore a unifying dynamical systems framework - soft modes - to explain and analyze low-dimensionality in biology, from molecules to eco-systems. We argue that this one framework of soft modes makes non-trivial predictions that generalize classic ideas from developmental biology to disparate systems, namely: phenocopying, dual buffering, and global epistasis. While some of these predictions have been borne out in experiments, we discuss how soft modes allow for a surprisingly far-reaching and unifying framework in which to analyze data from protein biophysics to microbial ecology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13637v1</guid>
      <category>q-bio.QM</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1146/annurev-biophys-081624-030543</arxiv:DOI>
      <dc:creator>Christopher Joel Russo, Kabir Husain, Arvind Murugan</dc:creator>
    </item>
    <item>
      <title>Spatio-Temporal SIR Model of Pandemic Spread During Warfare with Optimal Dual-use Healthcare System Administration using Deep Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2412.14039</link>
      <description>arXiv:2412.14039v1 Announce Type: new 
Abstract: Large-scale crises, including wars and pandemics, have repeatedly shaped human history, and their simultaneous occurrence presents profound challenges to societies. Understanding the dynamics of epidemic spread during warfare is essential for developing effective containment strategies in complex conflict zones. While research has explored epidemic models in various settings, the impact of warfare on epidemic dynamics remains underexplored. In this study, we proposed a novel mathematical model that integrates the epidemiological SIR (susceptible-infected-recovered) model with the war dynamics Lanchester model to explore the dual influence of war and pandemic on a population's mortality. Moreover, we consider a dual-use military and civil healthcare system that aims to reduce the overall mortality rate which can use different administration policies. Using an agent-based simulation to generate in silico data, we trained a deep reinforcement learning model for healthcare administration policy and conducted an intensive investigation on its performance. Our results show that a pandemic during war conduces chaotic dynamics where the healthcare system should either prioritize war-injured soldiers or pandemic-infected civilians based on the immediate amount of mortality from each option, ignoring long-term objectives. Our findings highlight the importance of integrating conflict-related factors into epidemic modeling to enhance preparedness and response strategies in conflict-affected areas.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.14039v1</guid>
      <category>q-bio.QM</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <category>physics.soc-ph</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Adi Shuchami, Teddy Lazebnik</dc:creator>
    </item>
    <item>
      <title>Efficient Fine-Tuning of Single-Cell Foundation Models Enables Zero-Shot Molecular Perturbation Prediction</title>
      <link>https://arxiv.org/abs/2412.13478</link>
      <description>arXiv:2412.13478v1 Announce Type: cross 
Abstract: Predicting transcriptional responses to novel drugs provides a unique opportunity to accelerate biomedical research and advance drug discovery efforts. However, the inherent complexity and high dimensionality of cellular responses, combined with the extremely limited available experimental data, makes the task challenging. In this study, we leverage single-cell foundation models (FMs) pre-trained on tens of millions of single cells, encompassing multiple cell types, states, and disease annotations, to address molecular perturbation prediction. We introduce a drug-conditional adapter that allows efficient fine-tuning by training less than 1% of the original foundation model, thus enabling molecular conditioning while preserving the rich biological representation learned during pre-training. The proposed strategy allows not only the prediction of cellular responses to novel drugs, but also the zero-shot generalization to unseen cell lines. We establish a robust evaluation framework to assess model performance across different generalization tasks, demonstrating state-of-the-art results across all settings, with significant improvements in the few-shot and zero-shot generalization to new cell lines compared to existing baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13478v1</guid>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sepideh Maleki, Jan-Christian Huetter, Kangway V. Chuang, Gabriele Scalia, Tommaso Biancalani</dc:creator>
    </item>
    <item>
      <title>Disease Progression Modelling and Stratification for detecting sub-trajectories in the natural history of pathologies: application to Parkinson's Disease trajectory modelling</title>
      <link>https://arxiv.org/abs/2412.13608</link>
      <description>arXiv:2412.13608v1 Announce Type: cross 
Abstract: Modelling the progression of Degenerative Diseases (DD) is essential for detection, prevention, and treatment, yet it remains challenging due to the heterogeneity in disease trajectories among individuals. Factors such as demographics, genetic conditions, and lifestyle contribute to diverse phenotypical manifestations, necessitating patient stratification based on these variations. Recent methods like Subtype and Stage Inference (SuStaIn) have advanced unsupervised stratification of disease trajectories, but they face potential limitations in robustness, interpretability, and temporal granularity. To address these challenges, we introduce Disease Progression Modelling and Stratification (DP-MoSt), a novel probabilistic method that optimises clusters of continuous trajectories over a long-term disease time-axis while estimating the confidence of trajectory sub-types for each biomarker. We validate DP-MoSt using both synthetic and real-world data from the Parkinson's Progression Markers Initiative (PPMI). Our results demonstrate that DP-MoSt effectively identifies both sub-trajectories and subpopulations, and is a promising alternative to current state-of-the-art models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13608v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>q-bio.QM</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alessandro Viani (CRISAM), Boris A Gutman (IIT), Emile d'Angremont (Amsterdam UMC), Marco Lorenzi (CRISAM)</dc:creator>
    </item>
    <item>
      <title>Let Curves Speak: A Continuous Glucose Monitor based Large Sensor Foundation Model for Diabetes Management</title>
      <link>https://arxiv.org/abs/2412.09727</link>
      <description>arXiv:2412.09727v2 Announce Type: replace 
Abstract: While previous studies of AI in diabetes management focus on long-term risk, research on near-future glucose prediction remains limited but important as it enables timely diabetes self-management. Integrating AI with continuous glucose monitoring (CGM) holds promise for near-future glucose prediction. However, existing models have limitations in capturing patterns of blood glucose fluctuations and demonstrate poor generalizability. A robust approach is needed to leverage massive CGM data for near-future glucose prediction. We propose large sensor models (LSMs) to capture knowledge in CGM data by modeling patients as sequences of glucose. CGM-LSM is pretrained on 15.96 million glucose records from 592 diabetes patients for near-future glucose prediction. We evaluated CGM-LSM against state-of-the-art methods using the OhioT1DM dataset across various metrics, prediction horizons, and unseen patients. Additionally, we assessed its generalizability across factors like diabetes type, age, gender, and hour of day. CGM-LSM achieved exceptional performance, with an rMSE of 29.81 mg/dL for type 1 diabetes patients and 23.49 mg/dL for type 2 diabetes patients in a two-hour prediction horizon. For the OhioT1DM dataset, CGM-LSM achieved a one-hour rMSE of 15.64 mg/dL, halving the previous best of 31.97 mg/dL. Robustness analyses revealed consistent performance not only for unseen patients and future periods, but also across diabetes type, age, and gender. The model demonstrated adaptability to different hours of day, maintaining accuracy across periods of various activity intensity levels. CGM-LSM represents a transformative step in diabetes management by leveraging pretraining to uncover latent glucose generation patterns in sensor data. Our findings also underscore the broader potential of LSMs to drive innovation across domains involving complex sensor data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09727v2</guid>
      <category>q-bio.QM</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Junjie Luo, Abhimanyu Kumbara, Mansur Shomali, Rui Han, Anand Iyer, Ritu Agarwal, Gordon Gao</dc:creator>
    </item>
    <item>
      <title>A study of animal action segmentation algorithms across supervised, unsupervised, and semi-supervised learning paradigms</title>
      <link>https://arxiv.org/abs/2407.16727</link>
      <description>arXiv:2407.16727v2 Announce Type: replace-cross 
Abstract: Action segmentation of behavioral videos is the process of labeling each frame as belonging to one or more discrete classes, and is a crucial component of many studies that investigate animal behavior. A wide range of algorithms exist to automatically parse discrete animal behavior, encompassing supervised, unsupervised, and semi-supervised learning paradigms. These algorithms -- which include tree-based models, deep neural networks, and graphical models -- differ widely in their structure and assumptions on the data. Using four datasets spanning multiple species -- fly, mouse, and human -- we systematically study how the outputs of these various algorithms align with manually annotated behaviors of interest. Along the way, we introduce a semi-supervised action segmentation model that bridges the gap between supervised deep neural networks and unsupervised graphical models. We find that fully supervised temporal convolutional networks with the addition of temporal information in the observations perform the best on our supervised metrics across all datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16727v2</guid>
      <category>cs.CV</category>
      <category>q-bio.QM</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ari Blau, Evan S Schaffer, Neeli Mishra, Nathaniel J Miska, The International Brain Laboratory, Liam Paninski, Matthew R Whiteway</dc:creator>
    </item>
    <item>
      <title>KA-GNN: Kolmogorov-Arnold Graph Neural Networks for Molecular Property Prediction</title>
      <link>https://arxiv.org/abs/2410.11323</link>
      <description>arXiv:2410.11323v2 Announce Type: replace-cross 
Abstract: As key models in geometric deep learning, graph neural networks have demonstrated enormous power in molecular data analysis. Recently, a specially-designed learning scheme, known as Kolmogorov-Arnold Network (KAN), shows unique potential for the improvement of model accuracy, efficiency, and explainability. Here we propose the first non-trivial Kolmogorov-Arnold Network-based Graph Neural Networks (KA-GNNs), including KAN-based graph convolutional networks(KA-GCN) and KAN-based graph attention network (KA-GAT). The essential idea is to utilizes KAN's unique power to optimize GNN architectures at three major levels, including node embedding, message passing, and readout. Further, with the strong approximation capability of Fourier series, we develop Fourier series-based KAN model and provide a rigorous mathematical prove of the robust approximation capability of this Fourier KAN architecture. To validate our KA-GNNs, we consider seven most-widely-used benchmark datasets for molecular property prediction and extensively compare with existing state-of-the-art models. It has been found that our KA-GNNs can outperform traditional GNN models. More importantly, our Fourier KAN module can not only increase the model accuracy but also reduce the computational time. This work not only highlights the great power of KA-GNNs in molecular property prediction but also provides a novel geometric deep learning framework for the general non-Euclidean data analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11323v2</guid>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Longlong Li, Yipeng Zhang, Guanghui Wang, Kelin Xia</dc:creator>
    </item>
  </channel>
</rss>
