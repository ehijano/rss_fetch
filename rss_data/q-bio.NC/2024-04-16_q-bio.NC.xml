<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 16 Apr 2024 04:00:22 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 16 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A simple mathematical theory for Simple Volatile Memristors and their spiking circuits</title>
      <link>https://arxiv.org/abs/2404.08647</link>
      <description>arXiv:2404.08647v1 Announce Type: cross 
Abstract: In pursuit of neuromorphic (brain-inspired) devices, memristors (memory-resistors) have emerged as promising candidates for emulating neuronal circuitry. Here we mathematically define a class of Simple Volatile Memristors (SVMs), which notably includes various fluidic iontronic devices that have recently garnered significant interest due to their unique quality of operating within the same medium as the brain. We show that symmetric SVMs produce non self-crossing current-voltage hysteresis loops, while simple asymmetric SVMs produce self-crossing loops. Additionally, we derive a general expression for the enclosed area in a loop, providing a relation between the voltage frequency and the SVM memory timescale. These general results are shown to materialise in physical finite-element calculations of microfluidic memristors. An SVM-based circuit has been proposed that exhibits all-or-none and tonic neuronal spiking. We generalise and analyse this spiking circuit, characterising it as a two-dimensional dynamical system. Additionally, we demonstrate that stochastic effects can induce novel neuronal firing modes absent in the deterministic case. Through our analysis, the circuit dynamics are well understood, while retaining its explicit link with the physically plausible underlying system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08647v1</guid>
      <category>cond-mat.soft</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>T. M. Kamsma, R. van Roij, C. Spitoni</dc:creator>
    </item>
    <item>
      <title>Synthetic Brain Images: Bridging the Gap in Brain Mapping With Generative Adversarial Model</title>
      <link>https://arxiv.org/abs/2404.08703</link>
      <description>arXiv:2404.08703v1 Announce Type: cross 
Abstract: Magnetic Resonance Imaging (MRI) is a vital modality for gaining precise anatomical information, and it plays a significant role in medical imaging for diagnosis and therapy planning. Image synthesis problems have seen a revolution in recent years due to the introduction of deep learning techniques, specifically Generative Adversarial Networks (GANs). This work investigates the use of Deep Convolutional Generative Adversarial Networks (DCGAN) for producing high-fidelity and realistic MRI image slices. The suggested approach uses a dataset with a variety of brain MRI scans to train a DCGAN architecture. While the discriminator network discerns between created and real slices, the generator network learns to synthesise realistic MRI image slices. The generator refines its capacity to generate slices that closely mimic real MRI data through an adversarial training approach. The outcomes demonstrate that the DCGAN promise for a range of uses in medical imaging research, since they show that it can effectively produce MRI image slices if we train them for a consequent number of epochs. This work adds to the expanding corpus of research on the application of deep learning techniques for medical image synthesis. The slices that are could be produced possess the capability to enhance datasets, provide data augmentation in the training of deep learning models, as well as a number of functions are made available to make MRI data cleaning easier, and a three ready to use and clean dataset on the major anatomical plans.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08703v1</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Drici Mourad, Kazeem Oluwakemi Oseni</dc:creator>
    </item>
    <item>
      <title>Listen to the Waves: Using a Neuronal Model of the Human Auditory System to Predict Ocean Waves</title>
      <link>https://arxiv.org/abs/2404.09510</link>
      <description>arXiv:2404.09510v1 Announce Type: cross 
Abstract: Artificial neural networks (ANNs) have evolved from the 1940s primitive models of brain function to become tools for artificial intelligence. They comprise many units, artificial neurons, interlinked through weighted connections. ANNs are trained to perform tasks through learning rules that modify the connection weights. With these rules being in the focus of research, ANNs have become a branch of machine learning developing independently from neuroscience. Although likely required for the development of truly intelligent machines, the integration of neuroscience into ANNs has remained a neglected proposition.
  Here, we demonstrate that designing an ANN along biological principles results in drastically improved task performance. As a challenging real-world problem, we choose real-time ocean-wave prediction which is essential for various maritime operations. Motivated by the similarity of ocean waves measured at a single location to sound waves arriving at the eardrum, we redesign an echo state network to resemble the brain's auditory system. This yields a powerful predictive tool which is computationally lean, robust with respect to network parameters, and works efficiently across a wide range of sea states. Our results demonstrate the advantages of integrating neuroscience with machine learning and offer a tool for use in the production of green energy from ocean waves.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.09510v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Artur Matysiak, Volker Roeber, Henrik Kalisch, Reinhard K\"onig, Patrick J. C. May</dc:creator>
    </item>
    <item>
      <title>Orientation selectivity properties for the affine Gaussian derivative and the affine Gabor models for visual receptive fields</title>
      <link>https://arxiv.org/abs/2304.11920</link>
      <description>arXiv:2304.11920v5 Announce Type: replace 
Abstract: This paper presents a theoretical analysis of the orientation selectivity of simple and complex cells that can be well modelled by the generalized Gaussian derivative model for visual receptive fields, with the purely spatial component of the receptive fields determined by oriented affine Gaussian derivatives for different orders of spatial differentiation.
  A detailed mathematical analysis is presented for the three different cases of either: (i) purely spatial receptive fields, (ii) space-time separable spatio-temporal receptive fields and (iii) velocity-adapted spatio-temporal receptive fields. Closed-form theoretical expressions for the orientation selectivity curves for idealized models of simple and complex cells are derived for all these main cases, and it is shown that the orientation selectivity of the receptive fields becomes more narrow, as a scale parameter ratio $\kappa$, defined as the ratio between the scale parameters in the directions perpendicular to vs. parallel with the preferred orientation of the receptive field, increases. It is also shown that the orientation selectivity becomes more narrow with increasing order of spatial differentiation in the underlying affine Gaussian derivative operators over the spatial domain.
  For comparison, we also present a corresponding theoretical orientation selectivity analysis for purely spatial receptive fields according to an affine Gabor model. The results from that analysis are consistent with the results obtained from the affine Gaussian derivative model,in the respect that the orientation selectivity becomes more narrow when making the receptive fields wider in the direction perpendicular to the preferred orientation of the receptive field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.11920v5</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tony Lindeberg</dc:creator>
    </item>
    <item>
      <title>Mind-to-Image: Projecting Visual Mental Imagination of the Brain from fMRI</title>
      <link>https://arxiv.org/abs/2404.05468</link>
      <description>arXiv:2404.05468v2 Announce Type: replace 
Abstract: The reconstruction of images observed by subjects from fMRI data collected during visual stimuli has made significant strides in the past decade, thanks to the availability of extensive fMRI datasets and advancements in generative models for image generation. However, the application of visual reconstruction has remained limited. Reconstructing visual imagination presents a greater challenge, with potentially revolutionary applications ranging from aiding individuals with disabilities to verifying witness accounts in court. The primary hurdles in this field are the absence of data collection protocols for visual imagery and the lack of datasets on the subject. Traditionally, fMRI-to-image relies on data collected from subjects exposed to visual stimuli, which poses issues for generating visual imagery based on the difference of brain activity between visual stimulation and visual imagery. For the first time, we have compiled a substantial dataset (around 6h of scans) on visual imagery along with a proposed data collection protocol. We then train a modified version of an fMRI-to-image model and demonstrate the feasibility of reconstructing images from two modes of imagination: from memory and from pure imagination. This marks an important step towards creating a technology that allow direct reconstruction of visual imagery.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05468v2</guid>
      <category>q-bio.NC</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hugo Caselles-Dupr\'e, Charles Mellerio, Paul H\'erent, Aliz\'ee Lopez-Persem, Benoit B\'eranger, Mathieu Soularue, Pierre Fautrel, Gauthier Vernier, Matthieu Cord</dc:creator>
    </item>
    <item>
      <title>Exploration of the search space of Gaussian graphical models for paired data</title>
      <link>https://arxiv.org/abs/2303.05561</link>
      <description>arXiv:2303.05561v2 Announce Type: replace-cross 
Abstract: We consider the problem of learning a Gaussian graphical model in the case where the observations come from two dependent groups sharing the same variables. We focus on a family of coloured Gaussian graphical models specifically suited for the paired data problem. Commonly, graphical models are ordered by the submodel relationship so that the search space is a lattice, called the model inclusion lattice. We introduce a novel order between models, named the twin order. We show that, embedded with this order, the model space is a lattice that, unlike the model inclusion lattice, is distributive. Furthermore, we provide the relevant rules for the computation of the neighbours of a model. The latter are more efficient than the same operations in the model inclusion lattice, and are then exploited to achieve a more efficient exploration of the search space. These results can be applied to improve the efficiency of both greedy and Bayesian model search procedures. Here we implement a stepwise backward elimination procedure and evaluate its performance by means of simulations. Finally, the procedure is applied to learn a brain network from fMRI data where the two groups correspond to the left and right hemispheres, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.05561v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <category>stat.ME</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Journal of Machine Learning Research (2024)</arxiv:journal_reference>
      <dc:creator>Alberto Roverato, Dung Ngoc Nguyen</dc:creator>
    </item>
  </channel>
</rss>
