<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NA</link>
    <description>cs.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 09 Dec 2024 05:01:21 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A fast spectral sum-of-Gaussians method for electrostatic summation in quasi-2D systems</title>
      <link>https://arxiv.org/abs/2412.04595</link>
      <description>arXiv:2412.04595v1 Announce Type: new 
Abstract: The quasi-2D electrostatic systems, characterized by periodicity in two dimensions with a free third dimension, have garnered significant interest in many fields. We apply the sum-of-Gaussians (SOG) approximation to the Laplace kernel, dividing the interactions into near-field, mid-range, and long-range components. The near-field component, singular but compactly supported in a local domain, is directly calculated. The mid-range component is managed using a procedure similar to nonuniform fast Fourier transforms in three dimensions. The long-range component, which includes Gaussians of large variance, is treated with polynomial interpolation/anterpolation in the free dimension and Fourier spectral solver in the other two dimensions on proxy points. Unlike the fast Ewald summation, which requires extensive zero padding in the case of high aspect ratios, the separability of Gaussians allows us to handle such case without any zero padding in the free direction. Furthermore, while NUFFTs typically rely on certain upsampling in each dimension, and the truncated kernel method introduces an additional factor of upsampling due to kernel oscillation, our scheme eliminates the need for upsampling in any direction due to the smoothness of Gaussians, significantly reducing computational cost for large-scale problems. Finally, whereas all periodic fast multipole methods require dividing the periodic tiling into a smooth far part and a near part containing its nearest neighboring cells, our scheme operates directly on the fundamental cell, resulting in better performance with simpler implementation. We provide a rigorous error analysis showing that upsampling is not required in NUFFT-like steps, achieving $O(N\log N)$ complexity with a small prefactor. The performance of the scheme is demonstrated via extensive numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.04595v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xuanzhao Gao, Shidong Jiang, Jiuyang Liang, Zhenli Xu, Qi Zhou</dc:creator>
    </item>
    <item>
      <title>Quasi-interpolation for the Helmholtz-Hodge decomposition</title>
      <link>https://arxiv.org/abs/2412.04600</link>
      <description>arXiv:2412.04600v1 Announce Type: new 
Abstract: The paper aims at proposing an efficient and stable quasi-interpolation based method for numerically computing the Helmholtz-Hodge decomposition of a vector field. To this end, we first explicitly construct a matrix kernel in a general form from polyharmonic splines such that it includes divergence-free/curl-free/harmonic matrix kernels as special cases. Then we apply the matrix kernel to vector decomposition via the convolution technique together with the Helmholtz-Hodge decomposition. More precisely, we show that if we convolve a vector field with a scaled divergence-free (curl-free) matrix kernel, then the resulting divergence-free (curl-free) convolution sequence converges to the corresponding divergence-free (curl-free) part of the Helmholtz-Hodge decomposition of the field. Finally, by discretizing the convolution sequence via certain quadrature rule, we construct a family of (divergence-free/curl-free) quasi-interpolants for the Helmholtz-Hodge decomposition (defined both in the whole space and over a bounded domain). Corresponding error estimates derived in the paper show that our quasi-interpolation based method yields convergent approximants to both the vector field and its Helmholtz-Hodge decomposition</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.04600v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicholas Fisher, Gregory Fasshauer, Wenwu Gao</dc:creator>
    </item>
    <item>
      <title>Aubin--Nitsche-type estimates for space-time FOSLS for parabolic PDEs</title>
      <link>https://arxiv.org/abs/2412.04651</link>
      <description>arXiv:2412.04651v1 Announce Type: new 
Abstract: We develop Aubin--Nitsche-type estimates for recently proposed first-order system least-squares finite element methods (FOSLS) for the heat equation. Under certain assumptions, which are satisfied if the spatial domain is convex and the heat source and initial datum are sufficiently smooth, we prove that the $L^2$ error of approximations of the scalar field variable converges at a higher rate than the overall error. Furthermore, a higher-order conservation property is shown. In addition, we discuss quasi-optimality in weaker norms. Numerical experiments confirm our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.04651v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas F\"uhrer, Gregor Gantner</dc:creator>
    </item>
    <item>
      <title>Matrix-Free Parallel Scalable Multilevel Deflation Preconditioning for Heterogeneous Time-Harmonic Wave Problems</title>
      <link>https://arxiv.org/abs/2412.04980</link>
      <description>arXiv:2412.04980v1 Announce Type: new 
Abstract: We present a matrix-free parallel scalable multilevel deflation preconditioned method for heterogeneous time-harmonic wave problems. Building on the higher-order deflation preconditioning proposed by Dwarka and Vuik (SIAM J. Sci. Comput. 42(2):A901-A928, 2020; J. Comput. Phys. 469:111327, 2022) for highly indefinite time-harmonic waves, we adapt these techniques for parallel implementation in the context of solving large-scale heterogeneous problems with minimal pollution error. Our proposed method integrates the Complex Shifted Laplacian preconditioner with deflation approaches. We employ higher-order deflation vectors and re-discretization schemes derived from the Galerkin coarsening approach for a matrix-free parallel implementation. We suggest a robust and efficient configuration of the matrix-free multilevel deflation method, which yields a close to wavenumber-independent convergence and good time efficiency. Numerical experiments demonstrate the effectiveness of our approach for increasingly complex model problems. The matrix-free implementation of the preconditioned Krylov subspace methods reduces memory consumption, and the parallel framework exhibits satisfactory parallel performance and weak parallel scalability. This work represents a significant step towards developing efficient, scalable, and parallel multilevel deflation preconditioning methods for large-scale real-world applications in wave propagation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.04980v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinqiang Chen, Vandana Dwarka, Cornelis Vuik</dc:creator>
    </item>
    <item>
      <title>Tensor-product vertex patch smoothers for biharmonic problems</title>
      <link>https://arxiv.org/abs/2412.05082</link>
      <description>arXiv:2412.05082v1 Announce Type: new 
Abstract: We discuss vertex patch smoothers as overlapping domain decomposition methods for fourth order elliptic partial differential equations. We show that they are numerically very efficient and yield high convergence rates. Furthermore, we discuss low rank tensor approximations for their efficient implementation. Our experiments demonstrate that the inexact local solver yields a method which converges fast and uniformly with respect to mesh refinement. The multiplicative smoother shows superior performance in terms of solution efficiency, requiring fewer iterations. However, in three-dimensional cases, the additive smoother outperforms its multiplicative counterpart due to the latter's lower potential for parallelism. Additionally, the solver infrastructure supports a mixed-precision approach, executing the multigrid preconditioner in single precision while performing the outer iteration in double precision, thereby increasing throughput by up to 70 percent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05082v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julius Witte, Cu Cui, Francesca Bonizzoni, Guido Kanschat</dc:creator>
    </item>
    <item>
      <title>Physics-informed reduced order model with conditional neural fields</title>
      <link>https://arxiv.org/abs/2412.05233</link>
      <description>arXiv:2412.05233v1 Announce Type: new 
Abstract: This study presents the conditional neural fields for reduced-order modeling (CNF-ROM) framework to approximate solutions of parametrized partial differential equations (PDEs). The approach combines a parametric neural ODE (PNODE) for modeling latent dynamics over time with a decoder that reconstructs PDE solutions from the corresponding latent states. We introduce a physics-informed learning objective for CNF-ROM, which includes two key components. First, the framework uses coordinate-based neural networks to calculate and minimize PDE residuals by computing spatial derivatives via automatic differentiation and applying the chain rule for time derivatives. Second, exact initial and boundary conditions (IC/BC) are imposed using approximate distance functions (ADFs) [Sukumar and Srivastava, CMAME, 2022]. However, ADFs introduce a trade-off as their second- or higher-order derivatives become unstable at the joining points of boundaries. To address this, we introduce an auxiliary network inspired by [Gladstone et al., NeurIPS ML4PS workshop, 2022]. Our method is validated through parameter extrapolation and interpolation, temporal extrapolation, and comparisons with analytical solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05233v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Minji Kim, Tianshu Wen, Kookjin Lee, Youngsoo Choi</dc:creator>
    </item>
    <item>
      <title>Simultaneous identification of the parameters in the plasticity function for power hardening materials : A Bayesian approach</title>
      <link>https://arxiv.org/abs/2412.05241</link>
      <description>arXiv:2412.05241v1 Announce Type: new 
Abstract: In this paper, we study simultaneous determination of the strain hardening exponent, the shear modulus and the yield stress in an inverse problem. First, we analyze the direct and the inverse problems. Then we formulate the inverse problem in the Bayesian framework. After solving the direct problem by an iterative approach, we propose a numerical method based on a Bayesian approach for the numerical solution of the inverse problem. Numerical examples with noisy data illustrate applicability and accuracy of the proposed method to some extent.\</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05241v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Salih Tatar, Mohamed BenSalah</dc:creator>
    </item>
    <item>
      <title>Nonlinear Operator Learning Using Energy Minimization and MLPs</title>
      <link>https://arxiv.org/abs/2412.04596</link>
      <description>arXiv:2412.04596v1 Announce Type: cross 
Abstract: We develop and evaluate a method for learning solution operators to nonlinear problems governed by partial differential equations. The approach is based on a finite element discretization and aims at representing the solution operator by an MLP that takes latent variables as input. The latent variables will typically correspond to parameters in a parametrization of input data such as boundary conditions, coefficients, and right-hand sides. The loss function is most often an energy functional and we formulate efficient parallelizable training algorithms based on assembling the energy locally on each element. For large problems, the learning process can be made more efficient by using only a small fraction of randomly chosen elements in the mesh in each iteration. The approach is evaluated on several relevant test cases, where learning the solution operator turns out to be beneficial compared to classical numerical methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.04596v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mats G. Larson, Carl Lundholm, Anna Persson</dc:creator>
    </item>
    <item>
      <title>Asymptotic compatibility of parametrized optimal design problems</title>
      <link>https://arxiv.org/abs/2412.04630</link>
      <description>arXiv:2412.04630v1 Announce Type: cross 
Abstract: We study optimal design problems where the design corresponds to a coefficient in the principal part of the state equation. The state equation, in addition, is parameter dependent, and we allow it to change type in the limit of this (modeling) parameter. We develop a framework that guarantees asymptotic compatibility, that is unconditional convergence with respect to modeling and discretization parameters to the solution of the corresponding limiting problems. This framework is then applied to two distinct classes of problems where the modeling parameter represents the degree of nonlocality. Specifically, we show unconditional convergence of optimal design problems when the state equation is either a scalar-valued fractional equation, or a strongly coupled system of nonlocal equations derived from the bond-based model of peridynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.04630v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.NA</category>
      <pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tadele Mengesha, Abner J. Salgado, Joshua M. Siktar</dc:creator>
    </item>
    <item>
      <title>Solving 1D Poisson problem with a Variational Quantum Linear Solver</title>
      <link>https://arxiv.org/abs/2412.04938</link>
      <description>arXiv:2412.04938v1 Announce Type: cross 
Abstract: Different hybrid quantum-classical algorithms have recently been developed as a near-term way to solve linear systems of equations on quantum devices. However, the focus has so far been mostly on the methods, rather than the problems that they need to tackle. In fact, these algorithms have been run on real hardware only for problems in quantum physics, such as Hamiltonians of a few qubits systems. These problems are particularly favorable for quantum hardware, since their matrices are the sum of just a few unitary terms and since only shallow quantum circuits are required to estimate the cost function. However, for many interesting problems in linear algebra, it appears far less trivial to find an efficient decomposition and to trade it off with the depth of the cost quantum circuits. A first simple yet interesting instance to consider are tridiagonal systems of equations. These arise, for instance, in the discretization of one-dimensional finite element analyses.
  This work presents a method to solve a class of tridiagonal systems of equations with the variational quantum linear solver (VQLS), a recently proposed variational hybrid algorithm for solving linear systems. In particular, we present a new decomposition for this class of matrices based on both Pauli strings and multi--qubit gates, resulting in less terms than those obtained by just using Pauli gates. Based on this decomposition, we discuss the tradeoff between the number of terms and the near-term implementability of the quantum circuits. Furthermore, we present the first simulated and real-hardware results obtained by solving tridiagonal linear systems with VQLS, using the decomposition proposed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.04938v1</guid>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giorgio Tosti Balducci, Boyang Chen, Matthias M\"oller, Roeland De Breuker</dc:creator>
    </item>
    <item>
      <title>Optimal control under uncertainty with joint chance state constraints: almost-everywhere bounds, variance reduction, and application to (bi-)linear elliptic PDEs</title>
      <link>https://arxiv.org/abs/2412.05125</link>
      <description>arXiv:2412.05125v1 Announce Type: cross 
Abstract: We study optimal control of PDEs under uncertainty with the state variable subject to joint chance constraints. The controls are deterministic, but the states are probabilistic due to random variables in the governing equation. Joint chance constraints ensure that the random state variable meets pointwise bounds with high probability. For linear governing PDEs and elliptically distributed random parameters, we prove existence and uniqueness results for almost-everywhere state bounds. Using the spherical-radial decomposition (SRD) of the uncertain variable, we prove that when the probability is very large or small, the resulting Monte Carlo estimator for the chance constraint probability exhibits substantially reduced variance compared to the standard Monte Carlo estimator. We further illustrate how the SRD can be leveraged to efficiently compute derivatives of the probability function, and discuss different expansions of the uncertain variable in the governing equation. Numerical examples for linear and bilinear PDEs compare the performance of Monte Carlo and quasi-Monte Carlo sampling methods, examining probability estimation convergence as the number of samples increases. We also study how the accuracy of the probabilities depends on the truncation of the random variable expansion, and numerically illustrate the variance reduction of the SRD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05125v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.CO</category>
      <pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rene Henrion, Georg Stadler, Florian Wechsung</dc:creator>
    </item>
    <item>
      <title>Strong convergence of the Euler scheme for singular kinetic SDEs driven by $\alpha$-stable processes</title>
      <link>https://arxiv.org/abs/2412.05142</link>
      <description>arXiv:2412.05142v1 Announce Type: cross 
Abstract: We study the strong approximation of the solutions to singular stochastic kinetic equations (also referred to as second-order SDEs) driven by $\alpha$-stable processes, using an Euler-type scheme inspired by [11]. For these equations, the stability index $\alpha$ lies in the range $(1,2)$, and the drift term exhibits anisotropic $\beta$-H\"older continuity with $\beta &gt;1 - \frac{\alpha}{2}$. We establish a convergence rate of $(\frac{1}{2} + \frac{\beta}{\alpha(1+\alpha)} \wedge \frac{1}{2})$, which aligns with the results in [4] concerning first-order SDEs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05142v1</guid>
      <category>math.PR</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chengcheng Ling</dc:creator>
    </item>
    <item>
      <title>Effective Rank and the Staircase Phenomenon: New Insights into Neural Network Training Dynamics</title>
      <link>https://arxiv.org/abs/2412.05144</link>
      <description>arXiv:2412.05144v1 Announce Type: cross 
Abstract: In recent years, deep learning, powered by neural networks, has achieved widespread success in solving high-dimensional problems, particularly those with low-dimensional feature structures. This success stems from their ability to identify and learn low dimensional features tailored to the problems. Understanding how neural networks extract such features during training dynamics remains a fundamental question in deep learning theory. In this work, we propose a novel perspective by interpreting the neurons in the last hidden layer of a neural network as basis functions that represent essential features. To explore the linear independence of these basis functions throughout the deep learning dynamics, we introduce the concept of 'effective rank'. Our extensive numerical experiments reveal a notable phenomenon: the effective rank increases progressively during the learning process, exhibiting a staircase-like pattern, while the loss function concurrently decreases as the effective rank rises. We refer to this observation as the 'staircase phenomenon'. Specifically, for deep neural networks, we rigorously prove the negative correlation between the loss function and effective rank, demonstrating that the lower bound of the loss function decreases with increasing effective rank. Therefore, to achieve a rapid descent of the loss function, it is critical to promote the swift growth of effective rank. Ultimately, we evaluate existing advanced learning methodologies and find that these approaches can quickly achieve a higher effective rank, thereby avoiding redundant staircase processes and accelerating the rapid decline of the loss function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05144v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yang Jiang, Yuxiang Zhao, Quanhui Zhu</dc:creator>
    </item>
    <item>
      <title>Exponentially Convergent Numerical Method for Abstract Cauchy Problem with Fractional Derivative of Caputo Type</title>
      <link>https://arxiv.org/abs/2304.13099</link>
      <description>arXiv:2304.13099v4 Announce Type: replace 
Abstract: We present an exponentially convergent numerical method to approximate the solution of the Cauchy problem for the inhomogeneous fractional differential equation with an unbounded operator coefficient and Caputo fractional derivative in time. The numerical method is based on the newly obtained solution formula that consolidates the mild solution representations of sub-parabolic, parabolic and sub-hyperbolic equations with sectorial operator coefficient $A$ and non-zero initial data. The involved integral operators are approximated using the sinc-quadrature formulas that are tailored to the spectral parameters of $A$, fractional order $\alpha$ and the smoothness of the first initial condition, as well as to the properties of the equation's right-hand side $f(t)$. The resulting method possesses exponential convergence for positive sectorial $A$, any finite $t$, including $t = 0$ and the whole range $\alpha \in (0,2)$. It is suitable for a practically important case, when no knowledge of $f(t)$ is available outside the considered interval $t \in [0, T]$. The algorithm of the method is capable of multi-level parallelism. We provide numerical examples that confirm the theoretical error estimates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.13099v4</guid>
      <category>math.NA</category>
      <category>cs.MS</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.CA</category>
      <pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.3390/math11102312</arxiv:DOI>
      <arxiv:journal_reference>Mathematics 11, no. 10: 2312 (2023)</arxiv:journal_reference>
      <dc:creator>Dmytro Sytnyk, Barbara Wohlmuth</dc:creator>
    </item>
    <item>
      <title>Exploring Well-Posedness and Asymptotic Behavior in an Advection-Diffusion-Reaction (ADR) Model</title>
      <link>https://arxiv.org/abs/2403.02339</link>
      <description>arXiv:2403.02339v2 Announce Type: replace-cross 
Abstract: In this paper, the existence, uniqueness, and positivity of solutions, as well as the asymptotic behavior through a finite fractal dimensional global attractor for a general Advection-Diffusion-Reaction (ADR) equation, are investigated. Our findings are innovative, as we employ semigroups and global attractors theories to achieve these results. Also, an analytical solution of a two-dimensional Advection-Diffusion Equation is presented. And finally, two Explicit Finite Difference schemes are used to simulate solutions in the two- and three-dimensional cases. The numerical simulations are conducted with predefined initial and Dirichlet boundary conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02339v2</guid>
      <category>math.AP</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <category>math.NA</category>
      <pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammed Elghandouri, Khalil Ezzinbi, Lamiae Saidi</dc:creator>
    </item>
    <item>
      <title>The stability of the multivariate geometric Brownian motion as a bilinear matrix inequality problem</title>
      <link>https://arxiv.org/abs/2403.16765</link>
      <description>arXiv:2403.16765v2 Announce Type: replace-cross 
Abstract: In this manuscript, we study the stability of the origin for the multivariate geometric Brownian motion. More precisely, under suitable sufficient conditions, we construct a Lyapunov function such that the origin of the multivariate geometric Brownian motion is globally asymptotically stable in probability. Moreover, we show that such conditions can be rewritten as a Bilinear Matrix Inequality (BMI) feasibility problem. We stress that no commutativity relations between the drift matrix and the noise dispersion matrices are assumed and therefore the so-called Magnus representation of the solution of the multivariate geometric Brownian motion is complicated. In addition, we exemplify our method in numerous specific models from the literature such as random linear oscillators, satellite dynamics, inertia systems, diagonal and non-diagonal noise systems, cancer self-remission and smoking.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16765v2</guid>
      <category>math.PR</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gerardo Barrera, Eyleifur Bjarkason, Sigurdur Hafstein</dc:creator>
    </item>
    <item>
      <title>Learning Partial Differential Equations with Deep Parallel Neural Operator</title>
      <link>https://arxiv.org/abs/2409.19976</link>
      <description>arXiv:2409.19976v3 Announce Type: replace-cross 
Abstract: In recent years, Solving partial differential equations has shifted the focus of traditional neural network studies from finite-dimensional Euclidean spaces to generalized functional spaces in research. A novel methodology is to learn an operator as a means of approximating the mapping between outputs. Currently, researchers have proposed a variety of operator architectures. Nevertheless, the majority of these architectures adopt an iterative update architecture, whereby a single operator is learned from the same function space. In practical physical science problems, the numerical solutions of partial differential equations are complex, and a serial single operator is unable to accurately approximate the intricate mapping between input and output. So, We propose a deep parallel operator model (DPNO) for efficiently and accurately solving partial differential equations. DPNO employs convolutional neural networks to extract local features and map data into distinct latent spaces. Designing a parallel block of double Fourier neural operators to solve the iterative error problem. DPNO approximates complex mappings between inputs and outputs by learning multiple operators in different potential spaces in parallel blocks. DPNO achieved the best performance on five of them, with an average improvement of 10.5\%, and ranked second on one dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19976v3</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Qinglong Ma, Peizhi Zhao, Sen Wang, Tao Song</dc:creator>
    </item>
  </channel>
</rss>
