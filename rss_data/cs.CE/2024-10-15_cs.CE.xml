<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 15 Oct 2024 04:01:36 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>BAKUP: Automated, Flexible, and Capital-Efficient Insurance Protocol for Decentralized Finance</title>
      <link>https://arxiv.org/abs/2410.09341</link>
      <description>arXiv:2410.09341v1 Announce Type: new 
Abstract: This paper introduces BAKUP, a smart contract insurance design for decentralized finance users to mitigate risks arising from platform vulnerabilities. While providing automated claim payout, BAKUP utilizes a modular structure to harmonize three key features: the platform's resilience against vulnerabilities, the flexibility of underwritten policies, and capital efficiency. An immutable core module performs capital accounting while ensuring robustness against external vulnerabilities, a customizable oracle module enables the underwriting of novel policies, and an optional and peripheral yield module allows users to independently manage additional yield. The implementation incorporates binary conditional tokens that are tradable on automated market maker (AMM)-based exchanges. Finally, the paper examines specific liquidity provision strategies for the conditional tokens, demonstrating that a conservative strategy and parameterization can effectively reduce the divergence loss of liquidity providers by more than 47 % compared to a naive strategy in the worst-case scenario.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09341v1</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/ICBC59979.2024.10634418</arxiv:DOI>
      <dc:creator>Srisht Fateh Singh, Panagiotis Michalopoulos, Andreas Veneris</dc:creator>
    </item>
    <item>
      <title>Benchmarking Time Series Foundation Models for Short-Term Household Electricity Load Forecasting</title>
      <link>https://arxiv.org/abs/2410.09487</link>
      <description>arXiv:2410.09487v1 Announce Type: new 
Abstract: Accurate household electricity short-term load forecasting (STLF) is key to future and sustainable energy systems. While various studies have analyzed statistical, machine learning, or deep learning approaches for household electricity STLF, recently proposed time series foundation models such as Chronos, TimesFM, or LagLlama have not yet been considered for household electricity STLF. These models are trained on a vast amount of time series data and are able to forecast time series without explicit task-specific training (zero-shot learning). In this study, we benchmark the forecasting capabilities of time series foundation models compared to Trained-from-Scratch (TFS) Transformer-based approaches. Our results suggest that foundation models perform comparably to TFS Transformer models, while the TimesFM foundation model outperforms all TFS models when the input size increases. At the same time, they require less effort, as they need no domain-specific training and only limited contextual data for inference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09487v1</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marcel Meyer, David Zapata, Sascha Kaltenpoth, Oliver M\"uller</dc:creator>
    </item>
    <item>
      <title>Combining Causal Discovery and Machine Learning for Modeling Data Center Operations</title>
      <link>https://arxiv.org/abs/2410.09516</link>
      <description>arXiv:2410.09516v1 Announce Type: new 
Abstract: Data centers consume large amounts of energy, and their electricity demand is predicted to multiply in the coming years. To mitigate the growing environmental challenges associated with data center energy consumption, optimizing the operation of IT equipment (ITE) and Heating, Ventilation, and Air Conditioning (HVAC) systems is crucial. Yet, modeling such systems is challenging due to the complex and non-linear interactions between many factors, including server load, indoor climate, weather, and data center configurations. While physical simulations are capable of representing this complexity, they are often time-consuming to set up and run. Machine Learning (ML), in contrast, allows efficient data-driven modeling but typically does not consider a system's causal dynamics, lacks interpretability, and suffers from overfitting. This study addresses the limitations of ML-driven predictive modeling by employing Causal Discovery to select features that are causally related to the response variable. We use a simulated data center to generate time series of its operation and conduct experiments to compare ML models trained with all features, traditional feature selection methods, and causal feature selection. Our results show that causal feature selection leads to models with substantially fewer features and similar or better performance, especially when predicting the effects of interventions. In addition, our proposed methodology allows the interpretation of the causal mechanism and the integration of expert knowledge into the modeling process. Overall, our findings suggest that combining Causal Discovery with ML can be a promising alternative for feature selection methods and prediction of interactions in complex physical systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09516v1</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David Zapata, Marcel Meyer, Oliver M\"uller</dc:creator>
    </item>
    <item>
      <title>Boltzmann-Aligned Inverse Folding Model as a Predictor of Mutational Effects on Protein-Protein Interactions</title>
      <link>https://arxiv.org/abs/2410.09543</link>
      <description>arXiv:2410.09543v1 Announce Type: new 
Abstract: Predicting the change in binding free energy ($\Delta \Delta G$) is crucial for understanding and modulating protein-protein interactions, which are critical in drug design. Due to the scarcity of experimental $\Delta \Delta G$ data, existing methods focus on pre-training, while neglecting the importance of alignment. In this work, we propose the Boltzmann Alignment technique to transfer knowledge from pre-trained inverse folding models to $\Delta \Delta G$ prediction. We begin by analyzing the thermodynamic definition of $\Delta \Delta G$ and introducing the Boltzmann distribution to connect energy with protein conformational distribution. However, the protein conformational distribution is intractable; therefore, we employ Bayes' theorem to circumvent direct estimation and instead utilize the log-likelihood provided by protein inverse folding models for $\Delta \Delta G$ estimation. Compared to previous inverse folding-based methods, our method explicitly accounts for the unbound state of protein complex in the $\Delta \Delta G$ thermodynamic cycle, introducing a physical inductive bias and achieving both supervised and unsupervised state-of-the-art (SoTA) performance. Experimental results on SKEMPI v2 indicate that our method achieves Spearman coefficients of 0.3201 (unsupervised) and 0.5134 (supervised), significantly surpassing the previously reported SoTA values of 0.2632 and 0.4324, respectively. Futhermore, we demonstrate the capability of our method on binding energy prediction, protein-protein docking and antibody optimization tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09543v1</guid>
      <category>cs.CE</category>
      <category>cs.AI</category>
      <category>q-bio.BM</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaoran Jiao, Weian Mao, Wengong Jin, Peiyuan Yang, Hao Chen, Chunhua Shen</dc:creator>
    </item>
    <item>
      <title>From x*y=k to Uniswap Hooks; A Comparative Review of Decentralized Exchanges (DEX)</title>
      <link>https://arxiv.org/abs/2410.10162</link>
      <description>arXiv:2410.10162v1 Announce Type: new 
Abstract: Decentralized exchanges (DEXs) are pivotal applications in the Decentralized finance (DeFi) landscape, aiming to facilitate trustless cryptocurrency trading by relying on smart contracts and blockchain networks. The developments in the DEXs sector began with the implementation of an automated market maker (AMM) system using a simple math formula by Uniswap V1 in 2018. Absorbing significant funding and the attention of web3 enthusiasts, DEXs have seen numerous advancements in their evolution. A notable recent advancement is the introduction of hooks in Uniswap v4, which allows users to take advantage of a wide range of plugin-like features with liquidity pools. This paper provides a comprehensive classification and comparative analyses of prominent DEX protocols, namely Uniswap, Curve, and Balancer, in addition to investigating other protocols' noteworthy aspects. The evaluation framework encompasses mechanisms, components, mathematical formulations, and the performance of liquidity pools. The goals are to elucidate the strengths and limitations of different AMM models, highlight emerging concepts in DEX development, outline current challenges, and differentiate optimal models for specific applications. The results and comparative insights can be a reference for web3 developers, blockchain researchers, traders, and regulatory parties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10162v1</guid>
      <category>cs.CE</category>
      <category>cs.CR</category>
      <category>cs.ET</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammad Ali Asef, Seyed Mojtaba Hosseini Bamakan</dc:creator>
    </item>
    <item>
      <title>A Geometric Model with Stochastic Error for Abnormal Motion Detection of Portal Crane Bucket Grab</title>
      <link>https://arxiv.org/abs/2410.10246</link>
      <description>arXiv:2410.10246v1 Announce Type: new 
Abstract: Abnormal swing angle detection of bucket grabs is crucial for efficient harbor operations. In this study, we develop a practically convenient swing angle detection method for crane operation, requiring only a single standard surveillance camera at the fly-jib head, without the need for sophisticated sensors or markers on the payload. Specifically, our algorithm takes the video images from the camera as input. Next, a fine-tuned 'the fifth version of the You Only Look Once algorithm' (YOLOv5) model is used to automatically detect the position of the bucket grab on the image plane. Subsequently, a novel geometric model is constructed, which takes the pixel position of the bucket grab, the steel rope length provided by the Programmable Logic Controller system, and the optical lens information of the camera into consideration. The key parameters of this geometric model are statistically estimated by a novel iterative algorithm. Once the key parameters are estimated, the algorithm can automatically detect swing angles from video streams. Being analytically simple, the computation of our algorithm is fast, as it takes about 0.01 seconds to process one single image generated by the surveillance camera. Therefore, we are able to obtain an accurate and fast estimation of the swing angle of an operating crane in real-time applications. Simulation studies are conducted to validate the model and algorithm. Real video examples from Qingdao Seaport under various weather conditions are analyzed to demonstrate its practical performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10246v1</guid>
      <category>cs.CE</category>
      <category>stat.AP</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Baichen Yu, Xiao Wang, Hansheng Wang</dc:creator>
    </item>
    <item>
      <title>Harvesting Layer-2 Yield: Suboptimality in Automated Market Makers</title>
      <link>https://arxiv.org/abs/2410.10324</link>
      <description>arXiv:2410.10324v1 Announce Type: new 
Abstract: Layer-2 (L2) blockchains offer security guarantees for Ethereum while reducing transaction (gas) fees, and consequentially are gaining popularity among traders at Automated Market Makers (AMMs). However, Liquidity Providers (LPs) are lagging behind. Our empirical results show that AMM liquidity pools on Ethereum are oversubscribed compared to their counterparties on L2s and often deliver lower returns than staking ETH. LPs would receive higher rewards by reallocating part of the liquidity to AMMs on L2s, or staking. By employing Lagrangian optimization, we find the optimal liquidity allocation strategy that maximizes LPs rewards. Moreover, we show that the returns from liquidity provisions converge to the staking rate, and in a perfect equilibrium, liquidity provisions to any AMM should provide returns equal to staking rewards.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10324v1</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Krzysztof Gogol, Manvir Schneider, Benjamin Livshits</dc:creator>
    </item>
    <item>
      <title>FairMindSim: Alignment of Behavior, Emotion, and Belief in Humans and LLM Agents Amid Ethical Dilemmas</title>
      <link>https://arxiv.org/abs/2410.10398</link>
      <description>arXiv:2410.10398v1 Announce Type: new 
Abstract: AI alignment is a pivotal issue concerning AI control and safety. It should consider not only value-neutral human preferences but also moral and ethical considerations. In this study, we introduced FairMindSim, which simulates the moral dilemma through a series of unfair scenarios. We used LLM agents to simulate human behavior, ensuring alignment across various stages. To explore the various socioeconomic motivations, which we refer to as beliefs, that drive both humans and LLM agents as bystanders to intervene in unjust situations involving others, and how these beliefs interact to influence individual behavior, we incorporated knowledge from relevant sociological fields and proposed the Belief-Reward Alignment Behavior Evolution Model (BREM) based on the recursive reward model (RRM). Our findings indicate that, behaviorally, GPT-4o exhibits a stronger sense of social justice, while humans display a richer range of emotions. Additionally, we discussed the potential impact of emotions on behavior. This study provides a theoretical foundation for applications in aligning LLMs with altruistic values.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10398v1</guid>
      <category>cs.CE</category>
      <category>cs.AI</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu Lei, Hao Liu, Chengxing Xie, Songjia Liu, Zhiyu Yin, Canyu chen, Guohao Li, Philip Torr, Zhen Wu</dc:creator>
    </item>
    <item>
      <title>Naturalness Indicators of Forests in Southern Sweden derived from the Canopy Height Model</title>
      <link>https://arxiv.org/abs/2410.10465</link>
      <description>arXiv:2410.10465v1 Announce Type: new 
Abstract: Forest canopies embody a dynamic set of ecological factors, acting as a pivotal interface between the Earth and its atmosphere. They are not only the result of an ecosystem's ability to maintain its inherent ecological processes, structures, and functions but also a reflection of human disturbance. This study introduces a methodology for extracting a comprehensive and human-interpretable set of features from the Canopy Height Model (CHM), which are then analyzed to identify reliable indicators for the degree of naturalness of forests in Southern Sweden. Utilizing these features, machine learning models - specifically, the perceptron, logistic regression, and decision trees - are applied to predict forest naturalness with an accuracy spanning from 89% to 95%, depending on the area of the region of interest. The predictions of the proposed method are easy to interpret, something that various stakeholders may find valuable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10465v1</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marco L. Della Vedova, Mattias Wahde</dc:creator>
    </item>
    <item>
      <title>Modeling News Interactions and Influence for Financial Market Prediction</title>
      <link>https://arxiv.org/abs/2410.10614</link>
      <description>arXiv:2410.10614v1 Announce Type: new 
Abstract: The diffusion of financial news into market prices is a complex process, making it challenging to evaluate the connections between news events and market movements. This paper introduces FININ (Financial Interconnected News Influence Network), a novel market prediction model that captures not only the links between news and prices but also the interactions among news items themselves. FININ effectively integrates multi-modal information from both market data and news articles. We conduct extensive experiments on two datasets, encompassing the S&amp;P 500 and NASDAQ 100 indices over a 15-year period and over 2.7 million news articles. The results demonstrate FININ's effectiveness, outperforming advanced market prediction models with an improvement of 0.429 and 0.341 in the daily Sharpe ratio for the two markets respectively. Moreover, our results reveal insights into the financial news, including the delayed market pricing of news, the long memory effect of news, and the limitations of financial sentiment analysis in fully extracting predictive power from news data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10614v1</guid>
      <category>cs.CE</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>q-fin.CP</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mengyu Wang, Shay B. Cohen, Tiejun Ma</dc:creator>
    </item>
    <item>
      <title>Fokker-Planck Central Moment Lattice Boltzmann Method for Effective Simulations of Fluid Dynamics</title>
      <link>https://arxiv.org/abs/2410.09739</link>
      <description>arXiv:2410.09739v1 Announce Type: cross 
Abstract: We present a new formulation of the central moment lattice Boltzmann (LB) method based on a continuous Fokker-Planck (FP) kinetic model, originally proposed for stochastic diffusive-drift processes (e.g., Brownian dynamics), by adapting it as a collision model for the continuous Boltzmann equation (CBE) for fluid dynamics. The FP collision model has several desirable properties, including its ability to preserve the quadratic nonlinearity of the CBE, unlike that based on the common Bhatnagar-Gross-Krook model. Rather than using an equivalent Langevin equation as a proxy, we construct our approach by directly matching the changes in different discrete central moments independently supported by the lattice under collision to those given by the CBE under the FP-guided collision model. This can be interpreted as a new path for the collision process in terms of the relaxation of the various central moments to 'equilibria', which we term as the Markovian central moment attractors that depend on a diffusion coefficient tensor. The construction of the method using central moments rather than via distribution functions facilitates its numerical implementation and analysis. We show its consistency to the Navier-Stokes equations via a Chapman-Enskog analysis and elucidate the choice of the diffusion coefficient based on the second order moments in accurately representing flows at relatively low viscosities. We will demonstrate the accuracy and robustness of our new central moment FP-LB formulation, termed as the FPC-LBM, using the D3Q27 lattice for simulations of a variety of flows, including wall-bounded turbulent flows. We show that the FPC-LBM is more stable than other existing LB schemes based on central moments, while avoiding numerical hyperviscosity effects in flow simulations at relatively very low physical fluid viscosities through a refinement to a model founded on kinetic theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09739v1</guid>
      <category>physics.flu-dyn</category>
      <category>cs.CE</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>William Schupbach, Kannan Premnath</dc:creator>
    </item>
    <item>
      <title>LoLI-Street: Benchmarking Low-Light Image Enhancement and Beyond</title>
      <link>https://arxiv.org/abs/2410.09831</link>
      <description>arXiv:2410.09831v1 Announce Type: cross 
Abstract: Low-light image enhancement (LLIE) is essential for numerous computer vision tasks, including object detection, tracking, segmentation, and scene understanding. Despite substantial research on improving low-quality images captured in underexposed conditions, clear vision remains critical for autonomous vehicles, which often struggle with low-light scenarios, signifying the need for continuous research. However, paired datasets for LLIE are scarce, particularly for street scenes, limiting the development of robust LLIE methods. Despite using advanced transformers and/or diffusion-based models, current LLIE methods struggle in real-world low-light conditions and lack training on street-scene datasets, limiting their effectiveness for autonomous vehicles. To bridge these gaps, we introduce a new dataset LoLI-Street (Low-Light Images of Streets) with 33k paired low-light and well-exposed images from street scenes in developed cities, covering 19k object classes for object detection. LoLI-Street dataset also features 1,000 real low-light test images for testing LLIE models under real-life conditions. Furthermore, we propose a transformer and diffusion-based LLIE model named "TriFuse". Leveraging the LoLI-Street dataset, we train and evaluate our TriFuse and SOTA models to benchmark on our dataset. Comparing various models, our dataset's generalization feasibility is evident in testing across different mainstream datasets by significantly enhancing images and object detection for practical applications in autonomous driving and surveillance systems. The complete code and dataset is available on https://github.com/tanvirnwu/TriFuse.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09831v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Md Tanvir Islam, Inzamamul Alam, Simon S. Woo, Saeed Anwar, IK Hyun Lee, Khan Muhammad</dc:creator>
    </item>
    <item>
      <title>A Simple Baseline for Predicting Events with Auto-Regressive Tabular Transformers</title>
      <link>https://arxiv.org/abs/2410.10648</link>
      <description>arXiv:2410.10648v1 Announce Type: cross 
Abstract: Many real-world applications of tabular data involve using historic events to predict properties of new ones, for example whether a credit card transaction is fraudulent or what rating a customer will assign a product on a retail platform. Existing approaches to event prediction include costly, brittle, and application-dependent techniques such as time-aware positional embeddings, learned row and field encodings, and oversampling methods for addressing class imbalance. Moreover, these approaches often assume specific use-cases, for example that we know the labels of all historic events or that we only predict a pre-specified label and not the data's features themselves. In this work, we propose a simple but flexible baseline using standard autoregressive LLM-style transformers with elementary positional embeddings and a causal language modeling objective. Our baseline outperforms existing approaches across popular datasets and can be employed for various use-cases. We demonstrate that the same model can predict labels, impute missing values, or model event sequences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10648v1</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <category>stat.ML</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alex Stein, Samuel Sharpe, Doron Bergman, Senthil Kumar, Bayan Bruss, John Dickerson, Tom Goldstein, Micah Goldblum</dc:creator>
    </item>
    <item>
      <title>Multimodal Language and Graph Learning of Adsorption Configuration in Catalysis</title>
      <link>https://arxiv.org/abs/2401.07408</link>
      <description>arXiv:2401.07408v4 Announce Type: replace 
Abstract: Adsorption energy is a reactivity descriptor that must be accurately predicted for effective machine learning (ML) application in catalyst screening. This process involves determining the lowest energy across various adsorption configurations on a catalytic surface, which can exhibit very similar energy values. While graph neural networks (GNNs) have shown great success in computing the energy of catalyst systems, they rely heavily on atomic spatial coordinates. In contrast, transformer-based language models can directly use human-readable text inputs, potentially bypassing the need for detailed atomic positions. However, these language models often struggle with accurately predicting the energy of adsorption configurations. Our study addresses this limitation by introducing a self-supervised multi-modal learning approach called graph-assisted pretraining, which connects well-established GNNs with emerging language model applications. This method reduces the MAE of energy prediction for adsorption configurations by about 10%. Furthermore, our findings demonstrate that graph-assisted pretraining enhances fine-tuning with different datasets, indicating the transferability of this approach. This method also redirects the model's attention toward adsorption configuration, rather than individual adsorbate and catalyst information, similar to common domain knowledge. Building on this, we propose using generative large language models to create text inputs for the predictive model, based solely on chemical composition and surface orientation, without relying on exact atomic positions. This demonstrates a potential use case of language models in energy prediction without geometric information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.07408v4</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Janghoon Ock, Srivathsan Badrinarayanan, Rishikesh Magar, Akshay Antony, Amir Barati Farimani</dc:creator>
    </item>
    <item>
      <title>A Diffusion MRI model for axonal damage quantification based on axial diffusivity reduction in axons: a Monte Carlo simulation study</title>
      <link>https://arxiv.org/abs/2403.06140</link>
      <description>arXiv:2403.06140v3 Announce Type: replace 
Abstract: Axonal damage is the primary pathological correlate of long-term impairment in multiple sclerosis (MS). Previous work has demonstrated a strong, quantitative relationship between decrease in axial diffusivity and axonal damage. In the present work, we develop an extension of diffusion basis spectrum imaging (DBSI) which can be used to quantify the fraction of diseased and healthy axons based on reduction in axial diffusivity in axons. In this novel method, we model the MRI signal with the axial diffusion (AD) spectrum for each fiber orientation and use two component restricted anisotropic diffusion spectrum (RADS) to model the anisotropic component of the diffusion-weighted MRI signal. Diffusion coefficients and signal fractions are computed for the optimal model with the lowest Bayesian information criterion (BIC) score. This gives us the fractions of diseased and healthy axons. We test our method using Monte-Carlo (MC) simulations with the MC simulation package developed as part of this work. The simulation geometry for the voxel includes uniformly spaced cylinders to model axons, and uniformly spaced spheres to model extra-axonal cells. First we test and validate our MC simulations for the basic RADS model. It accurately recovers the fiber and cell fractions simulated, as well as the simulated diffusivities. For testing and validating RADS to quantify axonal damage, we simulate different fractions of diseased and healthy axons. Our method produces highly accurate quantification of diseased and healthy axons with Pearson's correlation (predicted vs true proportion) of r = 0.98 (p-value = 0.001); the one Sample t-test for proportion error gives the mean error of 2% (p-value = 0.034). Furthermore, the method recovers the axial diffusivities of the diseased and healthy axons very accurately with mean error of 4% (p-value = 0.001).</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06140v3</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nand Sharma</dc:creator>
    </item>
    <item>
      <title>No-Regret Learning for Stackelberg Equilibrium Computation in Newsvendor Pricing Games</title>
      <link>https://arxiv.org/abs/2404.00203</link>
      <description>arXiv:2404.00203v3 Announce Type: replace 
Abstract: We introduce the application of online learning in a Stackelberg game pertaining to a system with two learning agents in a dyadic exchange network, consisting of a supplier and retailer, specifically where the parameters of the demand function are unknown. In this game, the supplier is the first-moving leader, and must determine the optimal wholesale price of the product. Subsequently, the retailer who is the follower, must determine both the optimal procurement amount and selling price of the product. In the perfect information setting, this is known as the classical price-setting Newsvendor problem, and we prove the existence of a unique Stackelberg equilibrium when extending this to a two-player pricing game. In the framework of online learning, the parameters of the reward function for both the follower and leader must be learned, under the assumption that the follower will best respond with optimism under uncertainty. A novel algorithm based on contextual linear bandits with a measurable uncertainty set is used to provide a confidence bound on the parameters of the stochastic demand. Consequently, optimal finite time regret bounds on the Stackelberg regret, along with convergence guarantees to an approximate Stackelberg equilibrium, are provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00203v3</guid>
      <category>cs.CE</category>
      <category>cs.MA</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Larkin Liu, Yuming Rong</dc:creator>
    </item>
    <item>
      <title>Interpretable Machine Learning Models for Predicting the Next Targets of Activist Funds</title>
      <link>https://arxiv.org/abs/2404.16169</link>
      <description>arXiv:2404.16169v2 Announce Type: replace 
Abstract: This work develops a predictive model to identify potential targets of activist investment funds, which strategically acquire significant corporate stakes to drive operational and strategic improvements and enhance shareholder value. Predicting these targets is crucial for companies to mitigate intervention risks, for activists to select optimal targets, and for investors to capitalize on associated stock price gains. Our analysis utilizes data from the Russell 3000 index from 2016 to 2022. We tested 123 variations of models using different data imputation, oversampling, and machine learning methods, achieving a top AUC-ROC of 0.782. This demonstrates the model's effectiveness in identifying likely targets of activist funds. We applied the Shapley value method to determine the most influential factors in a company's susceptibility to activist investment. This interpretative approach provides clear insights into the driving forces behind activist targeting. Our model offers stakeholders a strategic tool for proactive corporate governance and investment strategy, enhancing understanding of the dynamics of activist investing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16169v2</guid>
      <category>cs.CE</category>
      <category>q-fin.ST</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Minwu Kim, Sidahmed Benabderrahmane, Talal Rahwan</dc:creator>
    </item>
    <item>
      <title>Illustrating the benefits of efficient creation and adaption of behavior models in intelligent Digital Twins over the machine life cycle</title>
      <link>https://arxiv.org/abs/2406.08323</link>
      <description>arXiv:2406.08323v2 Announce Type: replace 
Abstract: The concept of the Digital Twin, which in the context of this paper is the virtual representation of a production system or its components, can be used as a "digital playground" to master the increasing complexity of these assets. One of the central subcomponents of the Digital Twin are behavior models that can enable benefits over the entire machine life cycle. However, the creation, adaption and use of behavior models throughout the machine life cycle is very time-consuming, which is why approaches to improve the cost-benefit ratio are needed. Furthermore, there is a lack of specific use cases that illustrate the application and added benefit of behavior models over the machine life cycle, which is why the universal application of behavior models in industry is still lacking compared to research. This paper first presents the fundamentals, challenges and related work on Digital Twins and behavior models in the context of the machine life cycle. Then, concepts for low-effort creation and automatic adaption of Digital Twins are presented, with a focus on behavior models. Finally, the aforementioned gap between research and industry is addressed by demonstrating various realized use cases over the machine life cycle, in which the advantages as well as the application of behavior models in the different life cycle phases are shown.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.08323v2</guid>
      <category>cs.CE</category>
      <category>cs.NE</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.jmsy.2024.08.016</arxiv:DOI>
      <arxiv:journal_reference>Journal of Manufacturing Systems 76 (2024) 520-539</arxiv:journal_reference>
      <dc:creator>Daniel Dittler, Valentin Stegmaier, Nasser Jazdi, Michael Weyrich</dc:creator>
    </item>
    <item>
      <title>MLP, XGBoost, KAN, TDNN, and LSTM-GRU Hybrid RNN with Attention for SPX and NDX European Call Option Pricing</title>
      <link>https://arxiv.org/abs/2409.06724</link>
      <description>arXiv:2409.06724v3 Announce Type: replace-cross 
Abstract: We explore the performance of various artificial neural network architectures, including a multilayer perceptron (MLP), Kolmogorov-Arnold network (KAN), LSTM-GRU hybrid recursive neural network (RNN) models, and a time-delay neural network (TDNN) for pricing European call options. In this study, we attempt to leverage the ability of supervised learning methods, such as ANNs, KANs, and gradient-boosted decision trees, to approximate complex multivariate functions in order to calibrate option prices based on past market data. The motivation for using ANNs and KANs is the Universal Approximation Theorem and Kolmogorov-Arnold Representation Theorem, respectively. Specifically, we use S\&amp;P 500 (SPX) and NASDAQ 100 (NDX) index options traded during 2015-2023 with times to maturity ranging from 15 days to over 4 years (OptionMetrics IvyDB US dataset). Black \&amp; Scholes's (BS) PDE \cite{Black1973} model's performance in pricing the same options compared to real data is used as a benchmark. This model relies on strong assumptions, and it has been observed and discussed in the literature that real data does not match its predictions. Supervised learning methods are widely used as an alternative for calibrating option prices due to some of the limitations of this model. In our experiments, the BS model underperforms compared to all of the others. Also, the best TDNN model outperforms the best MLP model on all error metrics. We implement a simple self-attention mechanism to enhance the RNN models, significantly improving their performance. The best-performing model overall is the LSTM-GRU hybrid RNN model with attention. Also, the KAN model outperforms the TDNN and MLP models. We analyze the performance of all models by ticker, moneyness category, and over/under/correctly-priced percentage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06724v3</guid>
      <category>q-fin.CP</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.13140/RG.2.2.32372.56963</arxiv:DOI>
      <dc:creator>Boris Ter-Avanesov, Homayoon Beigi</dc:creator>
    </item>
  </channel>
</rss>
