<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 03 Jul 2025 04:00:07 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Hardware-software co-exploration with racetrack memory based in-memory computing for CNN inference in embedded systems</title>
      <link>https://arxiv.org/abs/2507.01429</link>
      <description>arXiv:2507.01429v1 Announce Type: new 
Abstract: Deep neural networks generate and process large volumes of data, posing challenges for low-resource embedded systems. In-memory computing has been demonstrated as an efficient computing infrastructure and shows promise for embedded AI applications. Among newly-researched memory technologies, racetrack memory is a non-volatile technology that allows high data density fabrication, making it a good fit for in-memory computing. However, integrating in-memory arithmetic circuits with memory cells affects both the memory density and power efficiency. It remains challenging to build efficient in-memory arithmetic circuits on racetrack memory within area and energy constraints. To this end, we present an efficient in-memory convolutional neural network (CNN) accelerator optimized for use with racetrack memory. We design a series of fundamental arithmetic circuits as in-memory computing cells suited for multiply-and-accumulate operations. Moreover, we explore the design space of racetrack memory based systems and CNN model architectures, employing co-design to improve the efficiency and performance of performing CNN inference in racetrack memory while maintaining model accuracy. Our designed circuits and model-system co-optimization strategies achieve a small memory bank area with significant improvements in energy and performance for racetrack memory based embedded systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.01429v1</guid>
      <category>cs.ET</category>
      <category>cs.AI</category>
      <category>cs.AR</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.sysarc.2022.102507</arxiv:DOI>
      <dc:creator>Benjamin Chen Ming Choong, Tao Luo, Cheng Liu, Bingsheng He, Wei Zhang, Joey Tianyi Zhou</dc:creator>
    </item>
    <item>
      <title>Revisiting Noise-adaptive Transpilation in Quantum Computing: How Much Impact Does it Have?</title>
      <link>https://arxiv.org/abs/2507.01195</link>
      <description>arXiv:2507.01195v1 Announce Type: cross 
Abstract: Transpilation, particularly noise-aware optimization, is widely regarded as essential for maximizing the performance of quantum circuits on superconducting quantum computers. The common wisdom is that each circuit should be transpiled using up-to-date noise calibration data to optimize fidelity. In this work, we revisit the necessity of frequent noise-adaptive transpilation, conducting an in-depth empirical study across five IBM 127-qubit quantum computers and 16 diverse quantum algorithms. Our findings reveal novel and interesting insights: (1) noise-aware transpilation leads to a heavy concentration of workloads on a small subset of qubits, which increases output error variability; (2) using random mapping can mitigate this effect while maintaining comparable average fidelity; and (3) circuits compiled once with calibration data can be reliably reused across multiple calibration cycles and time periods without significant loss in fidelity. These results suggest that the classical overhead associated with daily, per-circuit noise-aware transpilation may not be justified. We propose lightweight alternatives that reduce this overhead without sacrificing fidelity -- offering a path to more efficient and scalable quantum workflows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.01195v1</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuqian Huo, Jinbiao Wei, Christopher Kverne, Mayur Akewar, Janki Bhimani, Tirthak Patel</dc:creator>
    </item>
    <item>
      <title>VLAD: A VLM-Augmented Autonomous Driving Framework with Hierarchical Planning and Interpretable Decision Process</title>
      <link>https://arxiv.org/abs/2507.01284</link>
      <description>arXiv:2507.01284v1 Announce Type: cross 
Abstract: Recent advancements in open-source Visual Language Models (VLMs) such as LLaVA, Qwen-VL, and Llama have catalyzed extensive research on their integration with diverse systems. The internet-scale general knowledge encapsulated within these models presents significant opportunities for enhancing autonomous driving perception, prediction, and planning capabilities. In this paper we propose VLAD, a vision-language autonomous driving model, which integrates a fine-tuned VLM with VAD, a state-of-the-art end-to-end system. We implement a specialized fine-tuning approach using custom question-answer datasets designed specifically to improve the spatial reasoning capabilities of the model. The enhanced VLM generates high-level navigational commands that VAD subsequently processes to guide vehicle operation. Additionally, our system produces interpretable natural language explanations of driving decisions, thereby increasing transparency and trustworthiness of the traditionally black-box end-to-end architecture. Comprehensive evaluation on the real-world nuScenes dataset demonstrates that our integrated system reduces average collision rates by 31.82% compared to baseline methodologies, establishing a new benchmark for VLM-augmented autonomous driving systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.01284v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cristian Gariboldi, Hayato Tokida, Ken Kinjo, Yuki Asada, Alexander Carballo</dc:creator>
    </item>
    <item>
      <title>Quantum-Assisted Automatic Path-Planning for Robotic Quality Inspection in Industry 4.0</title>
      <link>https://arxiv.org/abs/2507.01462</link>
      <description>arXiv:2507.01462v1 Announce Type: cross 
Abstract: This work explores the application of hybrid quantum-classical algorithms to optimize robotic inspection trajectories derived from Computer-Aided Design (CAD) models in industrial settings. By modeling the task as a 3D variant of the Traveling Salesman Problem, incorporating incomplete graphs and open-route constraints, this study evaluates the performance of two D-Wave-based solvers against classical methods such as GUROBI and Google OR-Tools. Results across five real-world cases demonstrate competitive solution quality with significantly reduced computation times, highlighting the potential of quantum approaches in automation under Industry 4.0.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.01462v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eneko Osaba, Estibaliz Garrote, Pablo Miranda-Rodriguez, Alessia Ciacco, Itziar Cabanes, Aitziber Mancisidor</dc:creator>
    </item>
    <item>
      <title>Empowering Manufacturers with Privacy-Preserving AI Tools: A Case Study in Privacy-Preserving Machine Learning to Solve Real-World Problems</title>
      <link>https://arxiv.org/abs/2507.01808</link>
      <description>arXiv:2507.01808v1 Announce Type: cross 
Abstract: Small- and medium-sized manufacturers need innovative data tools but, because of competition and privacy concerns, often do not want to share their proprietary data with researchers who might be interested in helping. This paper introduces a privacy-preserving platform by which manufacturers may safely share their data with researchers through secure methods, so that those researchers then create innovative tools to solve the manufacturers' real-world problems, and then provide tools that execute solutions back onto the platform for others to use with privacy and confidentiality guarantees. We illustrate this problem through a particular use case which addresses an important problem in the large-scale manufacturing of food crystals, which is that quality control relies on image analysis tools. Previous to our research, food crystals in the images were manually counted, which required substantial and time-consuming human efforts, but we have developed and deployed a crystal analysis tool which makes this process both more rapid and accurate. The tool enables automatic characterization of the crystal size distribution and numbers from microscope images while the natural imperfections from the sample preparation are automatically removed; a machine learning model to count high resolution translucent crystals and agglomeration of crystals was also developed to aid in these efforts. The resulting algorithm was then packaged for real-world use on the factory floor via a web-based app secured through the originating privacy-preserving platform, allowing manufacturers to use it while keeping their proprietary data secure. After demonstrating this full process, future directions are also explored.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.01808v1</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.ET</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaoyu Ji, Jessica Shorland, Joshua Shank, Pascal Delpe-Brice, Latanya Sweeney, Jan Allebach, Ali Shakouri</dc:creator>
    </item>
    <item>
      <title>Self-heating electrochemical memory for high-precision analog computing</title>
      <link>https://arxiv.org/abs/2505.15936</link>
      <description>arXiv:2505.15936v2 Announce Type: replace 
Abstract: Analog computers hold promise to significantly reduce the energy consumption of artificial intelligence algorithms, but commercialization has been hampered by a fundamental scientific challenge - how to reliably store and process analog information with high precision. We present an approach based upon metal oxide memory cells that undergo controlled self-heating during programming with a newly developed, electro-thermo-chemical gate. The gate uniformly spreads heat and electrochemical reactions to enable wide, bulk-vacancy modulation which yields nine orders of magnitude in tunable analog resistance - three orders greater than other devices reported, with thousands of states. The gating profoundly reduces noise and drift to enable precision programming to targeted states within a few operations, lowering conductance errors by two orders of magnitude relative to other devices reported. Simulations show improvement in computational energy efficiency by at least 10x over other devices due to far greater scalability at higher precision. The results overturn long-held assumptions about the poor reliability and precision of analog resistance devices and opens the door to manufacturable, bulk metal-oxide devices and new applications that leverage high precision.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.15936v2</guid>
      <category>cs.ET</category>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.app-ph</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adam L. Gross, Sangheon Oh, Fran\c{c}ois L\'eonard, Wyatt Hodges, T. Patrick Xiao, Joshua D. Sugar, Jacklyn Zhu, Sritharini Radhakrishnan, Sangyong Lee, Jolie Wang, Adam Christensen, Sam Lilak, Patrick S. Finnegan, Patrick Crandall, Christopher H. Bennett, William Wahby, Robin Jacobs-Gedrim, Matthew J. Marinella, Suhas Kumar, Sapan Agarwal, Yiyang Li, A. Alec Talin, Elliot J. Fuller</dc:creator>
    </item>
    <item>
      <title>Resilient-By-Design: A Resiliency Framework for Future Wireless Networks</title>
      <link>https://arxiv.org/abs/2410.23203</link>
      <description>arXiv:2410.23203v2 Announce Type: replace-cross 
Abstract: Our future society will be increasingly digitalized, hyper-connected and globally data driven. The sixth generation (6G) and beyond 6G wireless networks are expected to bridge the digital and physical worlds by providing wireless connectivity as a service to different vertical sectors, making the society increasingly dependent on wireless networks. Thus, any disruption to these networks would have a significant impact with far-reaching consequences. Disruptions can occur for a variety of reasons, including planned outages, natural disasters, and deliberate cybersecurity attacks. Resilience against such disruptions is expected to be one of the most important defining features of future wireless networks. This paper first discusses a generic framework for designing future resilient wireless networks. A novel resilient-by-design framework consisting of four building blocks, namely predict, preempt, protect and progress, is then proposed as a specific example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23203v2</guid>
      <category>cs.NI</category>
      <category>cs.ET</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nurul Huda Mahmood, Sumudu Samarakoon, Pawani Porambage, Mehdi Bennis, Matti Latva-aho</dc:creator>
    </item>
    <item>
      <title>FAMES: Fast Approximate Multiplier Substitution for Mixed-Precision Quantized DNNs--Down to 2 Bits!</title>
      <link>https://arxiv.org/abs/2411.18055</link>
      <description>arXiv:2411.18055v3 Announce Type: replace-cross 
Abstract: A widely-used technique in designing energy-efficient deep neural network (DNN) accelerators is quantization. Recent progress in this direction has reduced the bitwidths used in DNN down to 2. Meanwhile, many prior works apply approximate multipliers (AppMuls) in designing DNN accelerators to lower their energy consumption. Unfortunately, these works still assume a bitwidth much larger than 2, which falls far behind the state-of-the-art in quantization area and even challenges the meaningfulness of applying AppMuls in DNN accelerators, since a high-bitwidth AppMul consumes much more energy than a low-bitwidth exact multiplier! Thus, an important problem to study is: Can approximate multipliers be effectively applied to quantized DNN models with very low bitwidths? In this work, we give an affirmative answer to this question and present a systematic solution that achieves the answer: FAMES, a fast approximate multiplier substitution method for mixed-precision DNNs. Our experiments demonstrate an average 28.67% energy reduction on state-of-the-art mixed-precision quantized models with bitwidths as low as 2 bits and accuracy losses kept under 1%. Additionally, our approach is up to 300x faster than previous genetic algorithm-based methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18055v3</guid>
      <category>cs.LG</category>
      <category>cs.ET</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yi Ren, Ruge Xu, Xinfei Guo, Weikang Qian</dc:creator>
    </item>
    <item>
      <title>Enhancing Expressivity of Quantum Neural Networks Based on the SWAP test</title>
      <link>https://arxiv.org/abs/2506.16938</link>
      <description>arXiv:2506.16938v2 Announce Type: replace-cross 
Abstract: Parameterized quantum circuits represent promising architectures for machine learning applications, yet many lack clear connections to classical models, potentially limiting their ability to translate the wide success of classical neural networks to the quantum realm. We examine a specific type of quantum neural network (QNN) built exclusively from SWAP test circuits, and discuss its mathematical equivalence to a classical two-layer feedforward network with quadratic activation functions under amplitude encoding. Our analysis across classical real-world and synthetic datasets reveals that while this architecture can successfully learn many practical tasks, it exhibits fundamental expressivity limitations due to violating the universal approximation theorem, particularly failing on harder problems like the parity check function. To address this limitation, we introduce a circuit modification using generalized SWAP test circuits that effectively implements classical neural networks with product layers. This enhancement enables successful learning of parity check functions in arbitrary dimensions which we analytically argue to be impossible for the original architecture beyond two dimensions regardless of network size. Our results establish a framework for enhancing QNN expressivity through classical task analysis and demonstrate that our SWAP test-based architecture offers broad representational capacity, suggesting potential promise also for quantum learning tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16938v2</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sebastian Nagies, Emiliano Tolotti, Davide Pastorello, Enrico Blanzieri</dc:creator>
    </item>
  </channel>
</rss>
