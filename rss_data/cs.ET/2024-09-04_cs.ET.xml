<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 05 Sep 2024 01:47:49 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Comprehensive Analysis of the Future of Atomically Precise Manufacturing</title>
      <link>https://arxiv.org/abs/2409.00955</link>
      <description>arXiv:2409.00955v1 Announce Type: new 
Abstract: Atomically Precise Manufacturing (APM) refers to the assembly of materials with atomic precision, representing a highly advanced technology with significant potential. However, the development of APM remains in its early stages, with applications largely confined to specialized fields and lacking cohesion within a unified discipline. The current literature on APM is often dominated by older, speculative papers that discuss its immense potential risks and benefits without sufficient grounding in the latest advancements or practical limitations that exist today. This paper aims to bridge this gap by providing a comprehensive assessment of current APM and near-APM technologies, as well as using the barriers to further progress to predict future developments. Through this analysis, we seek to establish a clearer understanding of the present state of the technology and then use these insights to predict the future trajectory of APM. By doing so, we aim to create a more grounded discourse on APM and its potential risks and benefits, while also guiding future research on the necessary regulations and safety considerations for this emerging field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00955v1</guid>
      <category>cs.ET</category>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.app-ph</category>
      <category>physics.soc-ph</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vadym Shvydun, Justin Sato, Gabriel Bristot</dc:creator>
    </item>
    <item>
      <title>Annealing-inspired training of an optical neural network with ternary weights</title>
      <link>https://arxiv.org/abs/2409.01042</link>
      <description>arXiv:2409.01042v1 Announce Type: new 
Abstract: Artificial neural networks (ANNs) represent a fundamentally connectionnist and distributed approach to computing, and as such they differ from classical computers that utilize the von Neumann architecture. This has revived research interest in new unconventional hardware to enable more efficient implementations of ANNs rather than emulating them on traditional machines. In order to fully leverage the capabilities of this new generation of ANNs, optimization algorithms that take into account hardware limitations and imperfections are necessary. Photonics represents a particularly promising platform, offering scalability, high speed, energy efficiency, and the capability for parallel information processing. Yet, fully fledged implementations of autonomous optical neural networks (ONNs) with in-situ learning remain scarce. In this work, we propose a ternary weight architecture high-dimensional semiconductor laser-based ONN. We introduce a simple method for achieving ternary weights with Boolean hardware, significantly increasing the ONN's information processing capabilities. Furthermore, we design a novel in-situ optimization algorithm that is compatible with, both, Boolean and ternary weights, and provide a detailed hyperparameter study of said algorithm for two different tasks. Our novel algorithm results in benefits, both in terms of convergence speed and performance. Finally, we experimentally characterize the long-term inference stability of our ONN and find that it is extremely stable with a consistency above 99\% over a period of more than 10 hours, addressing one of the main concerns in the field. Our work is of particular relevance in the context of in-situ learning under restricted hardware resources, especially since minimizing the power consumption of auxiliary hardware is crucial to preserving efficiency gains achieved by non-von Neumann ANN implementations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.01042v1</guid>
      <category>cs.ET</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anas Skalli, Mirko Goldmann, Nasibeh Haghighi, Stephan Reitzenstein, James A. Lott, Daniel Brunner</dc:creator>
    </item>
    <item>
      <title>Two-Timescale Synchronization and Migration for Digital Twin Networks: A Multi-Agent Deep Reinforcement Learning Approach</title>
      <link>https://arxiv.org/abs/2409.01092</link>
      <description>arXiv:2409.01092v1 Announce Type: new 
Abstract: Digital twins (DTs) have emerged as a promising enabler for representing the real-time states of physical worlds and realizing self-sustaining systems. In practice, DTs of physical devices, such as mobile users (MUs), are commonly deployed in multi-access edge computing (MEC) networks for the sake of reducing latency. To ensure the accuracy and fidelity of DTs, it is essential for MUs to regularly synchronize their status with their DTs. However, MU mobility introduces significant challenges to DT synchronization. Firstly, MU mobility triggers DT migration which could cause synchronization failures. Secondly, MUs require frequent synchronization with their DTs to ensure DT fidelity. Nonetheless, DT migration among MEC servers, caused by MU mobility, may occur infrequently. Accordingly, we propose a two-timescale DT synchronization and migration framework with reliability consideration by establishing a non-convex stochastic problem to minimize the long-term average energy consumption of MUs. We use Lyapunov theory to convert the reliability constraints and reformulate the new problem as a partially observable Markov decision-making process (POMDP). Furthermore, we develop a heterogeneous agent proximal policy optimization with Beta distribution (Beta-HAPPO) method to solve it. Numerical results show that our proposed Beta-HAPPO method achieves significant improvements in energy savings when compared with other benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.01092v1</guid>
      <category>cs.ET</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenshuai Liu, Yaru Fu, Yongna Guo, Fu Lee Wang, Wen Sun, Yan Zhang</dc:creator>
    </item>
    <item>
      <title>Acoustic Levitation for Environmental Remediation: An Effective Approach for Containment and Forecasting of Oil Spills</title>
      <link>https://arxiv.org/abs/2409.01642</link>
      <description>arXiv:2409.01642v1 Announce Type: new 
Abstract: The ocean ecology is badly impacted by large-scale oil spills, plastic waste, and chemical pollution, which destroy ecosystems and endanger marine life. Acknowledging the detrimental effects of oil spills on ecosystems, our research aims to establish the foundation for creative methods to lessen their impact. With an emphasis on the containment and prediction of oil spills, this research investigates the potential of acoustic levitation as a cutting-edge technique for environmental cleanup. Effectively separating and eliminating pollutants without causing additional ecological harm is a major issue for traditional oil spill cleanup techniques. Acoustic levitation provides a non-invasive, accurate, and effective alternative by using sound waves to precisely and subtly separate oil droplets from water in controlled environments. This proposed approach can reduce the negative effects on the environment and increase the efficacy of cleanup efforts. The findings have been examined and assessed by proof of concept experiments with oil droplets, identifying the relationship between the intensity of ultrasonic pressure and the proportion of oil droplets collected.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.01642v1</guid>
      <category>cs.ET</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>L Rochit, Nithish Kumar N, Devi Priya V S, Sibi Chakkaravarthy Sethuraman, Anitha Subramanian</dc:creator>
    </item>
    <item>
      <title>Toward Large Language Models as a Therapeutic Tool: Comparing Prompting Techniques to Improve GPT-Delivered Problem-Solving Therapy</title>
      <link>https://arxiv.org/abs/2409.00112</link>
      <description>arXiv:2409.00112v1 Announce Type: cross 
Abstract: While Large Language Models (LLMs) are being quickly adapted to many domains, including healthcare, their strengths and pitfalls remain under-explored. In our study, we examine the effects of prompt engineering to guide Large Language Models (LLMs) in delivering parts of a Problem-Solving Therapy (PST) session via text, particularly during the symptom identification and assessment phase for personalized goal setting. We present evaluation results of the models' performances by automatic metrics and experienced medical professionals. We demonstrate that the models' capability to deliver protocolized therapy can be improved with the proper use of prompt engineering methods, albeit with limitations. To our knowledge, this study is among the first to assess the effects of various prompting techniques in enhancing a generalist model's ability to deliver psychotherapy, focusing on overall quality, consistency, and empathy. Exploring LLMs' potential in delivering psychotherapy holds promise with the current shortage of mental health professionals amid significant needs, enhancing the potential utility of AI-based and AI-enhanced care services.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00112v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Daniil Filienko, Yinzhou Wang, Caroline El Jazmi, Serena Xie, Trevor Cohen, Martine De Cock, Weichao Yuwen</dc:creator>
    </item>
    <item>
      <title>Quantum Kernel Principal Components Analysis for Compact Readout of Chemiresistive Sensor Arrays</title>
      <link>https://arxiv.org/abs/2409.00115</link>
      <description>arXiv:2409.00115v1 Announce Type: cross 
Abstract: The rapid growth of Internet of Things (IoT) devices necessitates efficient data compression techniques to handle the vast amounts of data generated by these devices. In this context, chemiresistive sensor arrays (CSAs), a simple-to-fabricate but crucial component in IoT systems, generate large volumes of data due to their simultaneous multi-sensor operations. Classical principal component analysis (cPCA) methods, a common solution to the data compression challenge, face limitations in preserving critical information during dimensionality reduction. In this study, we present quantum principal component analysis (qPCA) as a superior alternative to enhance information retention. Our findings demonstrate that qPCA outperforms cPCA in various back-end machine-learning modeling tasks, particularly in low-dimensional scenarios when limited Quantum bits (qubits) can be accessed. These results underscore the potential of noisy intermediate-scale quantum (NISQ) computers, despite current qubit limitations, to revolutionize data processing in real-world IoT applications, particularly in enhancing the efficiency and reliability of CSA data compression and readout.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00115v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zeheng Wang, Timothy van der Laan, Muhammad Usman</dc:creator>
    </item>
    <item>
      <title>Hyper-Compression: Model Compression via Hyperfunction</title>
      <link>https://arxiv.org/abs/2409.00592</link>
      <description>arXiv:2409.00592v1 Announce Type: cross 
Abstract: The rapid growth of large models' size has far outpaced that of GPU memory. To bridge this gap, inspired by the succinct relationship between genotype and phenotype, we turn the model compression problem into the issue of parameter representation to propose the so-called hyper-compression. The hyper-compression uses a hyperfunction to represent the parameters of the target network, and notably, here the hyperfunction is designed per ergodic theory that relates to a problem: if a low-dimensional dynamic system can fill the high-dimensional space eventually. Empirically, the proposed hyper-compression enjoys the following merits: 1) \textbf{P}referable compression ratio; 2) \textbf{N}o post-hoc retraining; 3) \textbf{A}ffordable inference time; and 4) \textbf{S}hort compression time. It compresses LLaMA2-7B in an hour and achieves close-to-int4-quantization performance, without retraining and with a performance drop of less than 1\%. Our work has the potential to invigorate the field of model compression, towards a harmony between the scaling law and the stagnation of hardware upgradation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00592v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fenglei Fan, Juntong Fan, Dayang Wang, Jingbo Zhang, Zelin Dong, Shijun Zhang, Ge Wang, Tieyong Zeng</dc:creator>
    </item>
    <item>
      <title>AirCompSim: A Discrete Event Simulator for Air Computing</title>
      <link>https://arxiv.org/abs/2409.00689</link>
      <description>arXiv:2409.00689v1 Announce Type: cross 
Abstract: Air components, including UAVs, planes, balloons, and satellites have been widely utilized since the fixed capacity of ground infrastructure cannot meet the dynamic load of the users. However, since those air components should be coordinated in order to achieve the desired quality of service, several next-generation paradigms have been defined including air computing. Nevertheless, even though many studies and open research issues exist for air computing, there are limited test environments that cannot satisfy the performance evaluation requirements of the dynamic environment. Therefore, in this study, we introduce our discrete event simulator, AirCompSim, which fulfills an air computing environment considering dynamically changing requirements, loads, and capacities through its modular structure. To show its capabilities, a dynamic capacity enhancement scenario is used for investigating the effect of the number of users, UAVs, and requirements of different application types on the average task success rate, service time, and server utilization. The results demonstrate that AirCompSim can be used for experiments in air computing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00689v1</guid>
      <category>cs.NI</category>
      <category>cs.ET</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Baris Yamansavascilar, Atay Ozgovde, Cem Ersoy</dc:creator>
    </item>
    <item>
      <title>Infiltrating the Sky: Data Delay and Overflow Attacks in Earth Observation Constellations</title>
      <link>https://arxiv.org/abs/2409.00897</link>
      <description>arXiv:2409.00897v1 Announce Type: cross 
Abstract: Low Earth Orbit (LEO) Earth Observation (EO) satellites have changed the way we monitor Earth. Acting like moving cameras, EO satellites are formed in constellations with different missions and priorities, and capture vast data that needs to be transmitted to the ground for processing. However, EO satellites have very limited downlink communication capability, limited by transmission bandwidth, number and location of ground stations, and small transmission windows due to high velocity satellite movement. To optimize resource utilization, EO constellations are expected to share communication spectrum and ground stations for maximum communication efficiency.
  In this paper, we investigate a new attack surface exposed by resource competition in EO constellations, targeting the delay or drop of Earth monitoring data using legitimate EO services. Specifically, an attacker can inject high-priority requests to temporarily preempt low-priority data transmission windows. Furthermore, we show that by utilizing predictable satellite dynamics, an attacker can intelligently target critical data from low-priority satellites, either delaying its delivery or irreversibly dropping the data. We formulate two attacks, the data delay attack and the data overflow attack, design algorithms to assist attackers in devising attack strategies, and analyze their feasibility or optimality in typical scenarios. We then conduct trace-driven simulations using real-world satellite images and orbit data to evaluate the success probability of launching these attacks under realistic satellite communication settings. We also discuss possible defenses against these attacks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00897v1</guid>
      <category>cs.NI</category>
      <category>cs.CR</category>
      <category>cs.ET</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaojian Wang, Ruozhou Yu, Dejun Yang, Guoliang Xue</dc:creator>
    </item>
    <item>
      <title>DTRAN: A Special Use Case of RAN Optimization using Digital Twin</title>
      <link>https://arxiv.org/abs/2409.01136</link>
      <description>arXiv:2409.01136v1 Announce Type: cross 
Abstract: The emergence of beyond 5G (B5G) and 6G networks underscores the critical role of advanced computer-aided tools, such as network digital twins (DTs), in fostering autonomous networks and ubiquitous intelligence. Existing solutions in the DT domain primarily aim to model and automate specific tasks within the network lifecycle, which lack flexibility and adaptability for fully autonomous design and management. Unlike the existing DT approaches, we propose RAN optimization using the Digital Twin (DTRAN) framework that follows a holistic approach from core to edge networks. The proposed DTRAN framework enables real-time data management and communication with the physical network, which provides a more accurate and detailed digital replica than the existing approaches. We outline the main building blocks of the DTRAN and describe the details of our specific use case, which is RAN configuration optimization, to demonstrate the applicability of the proposed framework for a real-world scenario.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.01136v1</guid>
      <category>cs.NI</category>
      <category>cs.ET</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Caglar Tunc, Kubra Duran, Buse Bilgin, Gokhan Kalem, Berk Canberk</dc:creator>
    </item>
    <item>
      <title>SafeEmbodAI: a Safety Framework for Mobile Robots in Embodied AI Systems</title>
      <link>https://arxiv.org/abs/2409.01630</link>
      <description>arXiv:2409.01630v1 Announce Type: cross 
Abstract: Embodied AI systems, including AI-powered robots that autonomously interact with the physical world, stand to be significantly advanced by Large Language Models (LLMs), which enable robots to better understand complex language commands and perform advanced tasks with enhanced comprehension and adaptability, highlighting their potential to improve embodied AI capabilities. However, this advancement also introduces safety challenges, particularly in robotic navigation tasks. Improper safety management can lead to failures in complex environments and make the system vulnerable to malicious command injections, resulting in unsafe behaviours such as detours or collisions. To address these issues, we propose \textit{SafeEmbodAI}, a safety framework for integrating mobile robots into embodied AI systems. \textit{SafeEmbodAI} incorporates secure prompting, state management, and safety validation mechanisms to secure and assist LLMs in reasoning through multi-modal data and validating responses. We designed a metric to evaluate mission-oriented exploration, and evaluations in simulated environments demonstrate that our framework effectively mitigates threats from malicious commands and improves performance in various environment settings, ensuring the safety of embodied AI systems. Notably, In complex environments with mixed obstacles, our method demonstrates a significant performance increase of 267\% compared to the baseline in attack scenarios, highlighting its robustness in challenging conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.01630v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wenxiao Zhang, Xiangrui Kong, Thomas Braunl, Jin B. Hong</dc:creator>
    </item>
    <item>
      <title>DAOs of Collective Intelligence? Unraveling the Complexity of Blockchain Governance in Decentralized Autonomous Organizations</title>
      <link>https://arxiv.org/abs/2409.01823</link>
      <description>arXiv:2409.01823v1 Announce Type: cross 
Abstract: Decentralized autonomous organizations (DAOs) have transformed organizational structures by shifting from traditional hierarchical control to decentralized approaches, leveraging blockchain and cryptoeconomics. Despite managing significant funds and building global networks, DAOs face challenges like declining participation, increasing centralization, and inabilities to adapt to changing environments, which stifle innovation. This paper explores DAOs as complex systems and applies complexity science to explain their inefficiencies. In particular, we discuss DAO challenges, their complex nature, and introduce the self-organization mechanisms of collective intelligence, digital democracy, and adaptation. By applying these mechansims to improve DAO design and construction, a practical design framework for DAOs is created. This contribution lays a foundation for future research at the intersection of complexity science and DAOs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.01823v1</guid>
      <category>cs.CY</category>
      <category>cs.ET</category>
      <category>physics.app-ph</category>
      <category>physics.soc-ph</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mark C. Ballandies, Dino Carpentras, Evangelos Pournaras</dc:creator>
    </item>
    <item>
      <title>Ternary Tree Fermion-to-Qubit Mapping with Hamiltonian Aware Optimization</title>
      <link>https://arxiv.org/abs/2409.02010</link>
      <description>arXiv:2409.02010v1 Announce Type: cross 
Abstract: This paper introduces the Hamiltonian-Aware Ternary Tree (HATT) framework to compile optimized Fermion-to-qubit mapping for specific Fermionic Hamiltonians. In the simulation of Fermionic quantum systems, efficient Fermion-to-qubit mapping plays a critical role in transforming the Fermionic system into a qubit system. HATT utilizes ternary tree mapping and a bottom-up construction procedure to generate Hamiltonian aware Fermion-to-qubit mapping to reduce the Pauli weight of the qubit Hamiltonian, resulting in lower quantum simulation circuit overhead. Additionally, our optimizations retain the important vacuum state preservation property in our Fermion-to-qubit mapping and reduce the complexity of our algorithm from $O(N^4)$ to $O(N^3)$. Evaluations and simulations of various Fermionic systems demonstrate a significant reduction in both Pauli weight and circuit complexity, alongside excellent scalability to larger systems. Experiments on the Ionq quantum computer also show the advantages of our approach in noise resistance in quantum simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02010v1</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuhao Liu, Kevin Yao, Jonathan Hong, Julien Froustey, Yunong Shi, Ermal Rrapaj, Costin Iancu, Gushu Li</dc:creator>
    </item>
    <item>
      <title>SELCC: Coherent Caching over Compute-Limited Disaggregated Memory</title>
      <link>https://arxiv.org/abs/2409.02088</link>
      <description>arXiv:2409.02088v1 Announce Type: cross 
Abstract: Disaggregating memory from compute offers the opportunity to better utilize stranded memory in data centers. It is important to cache data in the compute nodes and maintain cache coherence across multiple compute nodes to save on round-trip communication cost between the disaggregated memory and the compute nodes. However, the limited computing power on the disaggregated memory servers makes it challenging to maintain cache coherence among multiple compute-side caches over disaggregated shared memory. This paper introduces SELCC; a Shared-Exclusive Latch Cache Coherence protocol that maintains cache coherence without imposing any computational burden on the remote memory side. SELCC builds on a one-sided shared-exclusive latch protocol by introducing lazy latch release and invalidation messages among the compute nodes so that it can guarantee both data access atomicity and cache coherence. SELCC minimizes communication round-trips by embedding the current cache copy holder IDs into RDMA latch words and prioritizes local concurrency control over global concurrency control. We instantiate the SELCC protocol onto compute-sided cache, forming an abstraction layer over disaggregated memory. This abstraction layer provides main-memory-like APIs to upper-level applications, and thus enabling existing data structures and algorithms to function over disaggregated memory with minimal code change. To demonstrate the usability of SELCC, we implement a B-tree and three transaction concurrency control algorithms over SELCC's APIs. Micro-benchmark results show that the SELCC protocol achieves better performance compared to RPC-based cache-coherence protocols. Additionally, YCSB and TPC-C benchmarks indicate that applications over SELCC can achieve comparable or superior performance against competitors over disaggregated memory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02088v1</guid>
      <category>cs.DB</category>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruihong Wang, Jianguo Wang, Walid G. Aref</dc:creator>
    </item>
    <item>
      <title>Reduction of Joule Losses in Memristive Switching Using Optimal Control</title>
      <link>https://arxiv.org/abs/2404.01507</link>
      <description>arXiv:2404.01507v3 Announce Type: replace 
Abstract: This study investigates strategies for minimizing Joule losses in resistive random access memory (ReRAM) cells, which are also referred to as memristive devices. Typically, the structure of ReRAM cells involves a nanoscale layer of resistance-switching material sandwiched between two metal electrodes. The basic question that we ask is what is the optimal driving protocol to switch a memristive device from one state to another. In the case of ideal memristors, in the most basic scenario, the optimal protocol is determined by solving a variational problem without constraints with the help of the Euler-Lagrange equation. In the case of memristive systems, for the same situation, the optimal protocol is found using the method of Lagrange multipliers. We demonstrate the advantages of our approaches through specific examples and compare our results with those of switching with constant voltage or current. Our findings suggest that voltage or current control can be used to reduce Joule losses in emerging memory devices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01507v3</guid>
      <category>cs.ET</category>
      <category>cond-mat.mes-hall</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Valeriy A. Slipko, Yuriy V. Pershin</dc:creator>
    </item>
    <item>
      <title>Sustainable Volunteer Engagement: Ensuring Potential Retention and Skill Diversity for Balanced Workforce Composition in Crowdsourcing Paradigm</title>
      <link>https://arxiv.org/abs/2408.11498</link>
      <description>arXiv:2408.11498v2 Announce Type: replace 
Abstract: Crowdsourcing (CS) faces the challenge of managing complex, skill-demanding tasks, which requires effective task assignment and retention strategies to sustain a balanced workforce. This challenge has become more significant in Volunteer Crowdsourcing Services (VCS). This study introduces Workforce Composition Balance (WCB), a novel framework designed to maintain workforce diversity in VCS by dynamically adjusting retention decisions. The WCB framework integrates the Volunteer Retention and Value Enhancement (VRAVE) algorithm with advanced skill-based task assignment methods. It ensures efficient remuneration policy for both assigned and unassigned potential volunteers by incorporating their potential levels, participation dividends, and satisfaction scores. Comparative analysis with three state-of-the-art baselines on real dataset shows that our WCB framework achieves 1.4 times better volunteer satisfaction and a 20% higher task retention rate, with only a 12% increase in remuneration. The effectiveness of the proposed WCB approach is to enhance the volunteer engagement and their long-term retention, thus making it suitable for functioning of social good applications where a potential and skilled volunteer workforce is crucial for sustainable community services.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.11498v2</guid>
      <category>cs.ET</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Riya Samanta, Soumya K Ghosh</dc:creator>
    </item>
    <item>
      <title>Fast Numerical Solver of Ising Optimization Problems via Pruning and Domain Selection</title>
      <link>https://arxiv.org/abs/2312.05837</link>
      <description>arXiv:2312.05837v2 Announce Type: replace-cross 
Abstract: Quantum annealers, coherent Ising machines and digital Ising machines for solving quantum-inspired optimization problems have been developing rapidly due to their near-term applications. The numerical solvers of the digital Ising machines are based on traditional computing devices. In this work, we propose a fast and efficient solver for the Ising optimization problems. The algorithm consists of a pruning method that exploits the graph information of the Ising model to reduce the computational complexity, and a domain selection method which introduces significant acceleration by relaxing the discrete feasible domain into a continuous one to incorporate the efficient gradient descent method. The experiment results show that our solver can be an order of magnitude faster than the classical solver, and at least two times faster than the quantum-inspired annealers including the simulated quantum annealing on the benchmark problems. With more relaxed requirements on hardware and lower cost than quantum annealing, the proposed solver has the potential for near-term application in solving challenging optimization problems as well as serving as a benchmark for evaluating the advantage of quantum devices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.05837v2</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Langyu Li, Daoyi Dong, Yu Pan</dc:creator>
    </item>
    <item>
      <title>A SAT Scalpel for Lattice Surgery: Representation and Synthesis of Subroutines for Surface-Code Fault-Tolerant Quantum Computing</title>
      <link>https://arxiv.org/abs/2404.18369</link>
      <description>arXiv:2404.18369v3 Announce Type: replace-cross 
Abstract: Quantum error correction is necessary for large-scale quantum computing. A promising quantum error correcting code is the surface code. For this code, fault-tolerant quantum computing (FTQC) can be performed via lattice surgery, i.e., splitting and merging patches of code. Given the frequent use of certain lattice-surgery subroutines (LaS), it becomes crucial to optimize their design in order to minimize the overall spacetime volume of FTQC. In this study, we define the variables to represent LaS and the constraints on these variables. Leveraging this formulation, we develop a synthesizer for LaS, LaSsynth, that encodes a LaS construction problem into a SAT instance, subsequently querying SAT solvers for a solution. Starting from a baseline design, we can gradually invoke the solver with shrinking spacetime volume to derive more compact designs. Due to our foundational formulation and the use of SAT solvers, LaSsynth can exhaustively explore the design space, yielding optimal designs in volume. For example, it achieves 8% and 18% volume reduction respectively over two states-of-the-art human designs for the 15-to-1 T-factory, a bottleneck in FTQC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18369v3</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/ISCA59077.2024.00032</arxiv:DOI>
      <dc:creator>Daniel Bochen Tan, Murphy Yuezhen Niu, Craig Gidney</dc:creator>
    </item>
    <item>
      <title>Compressive Beam Alignment for Indoor Millimeter-Wave Systems</title>
      <link>https://arxiv.org/abs/2406.07965</link>
      <description>arXiv:2406.07965v2 Announce Type: replace-cross 
Abstract: The dynamic nature of indoor environments poses unique challenges for next-generation millimeter-wave (mmwave) connectivity. These challenges arise from blockages due to mobile obstacles, mm-wave signal scattering caused by indoor surfaces, and user phased antenna array imperfections. Traditional compressed sensing (CS) based beam alignment techniques enable swift mm-wave connectivity with a limited number of measurements. These techniques, however, rely on prior knowledge of the communication channel model and the user's array manifold to design the sensing matrix and minimize angle quantization errors. This limits their effectiveness in dynamic environments. This paper proposes a novel CS-based beam alignment technique for mm-wave systems operating in indoor environments. Unlike prior work that rely on knowledge of the user's antenna architecture, communication codebook, and channel, the proposed technique is agnostic to these factors. The proposed formulation eliminates angle quantization errors by mapping the recovered angular directions onto the user's specific codebook. This is achieved by exploiting the energy compaction property of the Discrete Cosine Transform (DCT) to compress and identify the strongest cluster locations in the transform domain for robust beamforming. Experimental results at 60 GHz demonstrate successful recovery of the mm-wave power distribution in the angular domain, facilitating accurate beam alignment with limited measurements compared to exhaustive search solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.07965v2</guid>
      <category>eess.SP</category>
      <category>cs.ET</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>April Junio, Rafaela Lomboy, Raj Sai Sohel Bandari, Mohammed E. Eltayeb</dc:creator>
    </item>
    <item>
      <title>Towards Less Greedy Quantum Coalition Structure Generation in Induced Subgraph Games</title>
      <link>https://arxiv.org/abs/2408.04366</link>
      <description>arXiv:2408.04366v2 Announce Type: replace-cross 
Abstract: The transition to 100% renewable energy requires new techniques for managing energy networks, such as dividing them into sensible subsets of prosumers called micro-grids. Doing so in an optimal manner is a difficult optimization problem, as it can be abstracted to the Coalition Structure Generation problem in Induced Subgraph Games, a NP-complete problem which requires dividing an undirected, complete, weighted graph into subgraphs in a way that maximizes the sum of their internal weights. Recently, Venkatesh et al. (arXiv:2212.11372) published a Quantum Annealing (QA)-based iterative algorithm called GCS-Q, which they claim to be the best currently existing solver for the problem in terms of runtime complexity. As this algorithm makes the application of QA to the problem seem promising, but is a greedy one, this work proposes several less greedy QA-based approaches and investigates whether any of them can outperform GCS-Q in terms of solution quality. While we find that this is not the case yet on D-Wave hardware, most of them do when using the classical QBSolv software as a solver. Especially an algorithm we call 4-split iterative R-QUBO shows potential here, finding all optima in our dataset while scaling favorably with the problem size in terms of runtime. Thus, it appears to be interesting for future research on quantum approaches to the problem, assuming QA hardware will become more noise-resilient over time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04366v2</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jonas N\"u{\ss}lein, Dani\"elle Schuman, David Bucher, Naeimeh Mohseni, Kumar Ghosh, Corey O'Meara, Giorgio Cortiana, Claudia Linnhoff-Popien</dc:creator>
    </item>
    <item>
      <title>Enhanced Quantum Energy Teleportation using a 3-Qubit System</title>
      <link>https://arxiv.org/abs/2408.07997</link>
      <description>arXiv:2408.07997v3 Announce Type: replace-cross 
Abstract: Quantum Energy Teleportation (QET) is a novel method that leverages quantum entanglement to transfer energy between two distant locations without any physical movement of the energy. The first realization of QET on superconducting hardware, utilizing a 2-qubit system, demonstrated an average energy retrieval efficiency of 35.4% (observing only V ) by the receiver, Bob. In this paper, we present a new approach using a 3-qubit system to enhance the energy efficiency of QET. We have incorporated a novel 3-qubit ground state hamiltonian H to achieve this, that conforms the constraints of Zero mean energy and anti-commutative properties of the operations on the observable of the senders and receiver. Our experimental results show a significant improvement in energy retrieval, achieving an average efficiency of 65.5% (observing only V ), which is significantly higher than that of the 2-qubit system regarding practical usage. This advancement not only marks a step forward in practical quantum energy applications but also provides a new framework for future research in quantum energy teleportation and related quantum technologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07997v3</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Md Shoyib Hassan, Syed Emad Uddin Shubha, M. R. C Mahdy</dc:creator>
    </item>
    <item>
      <title>Automated Synthesis of Fault-Tolerant State Preparation Circuits for Quantum Error Correction Codes</title>
      <link>https://arxiv.org/abs/2408.11894</link>
      <description>arXiv:2408.11894v2 Announce Type: replace-cross 
Abstract: A central ingredient in fault-tolerant quantum algorithms is the initialization of a logical state for a given quantum error-correcting code from a set of noisy qubits. A scheme that has demonstrated promising results for small code instances that are realizable on currently available hardware composes a non-fault-tolerant state preparation step with a verification step that checks for spreading errors. Known circuit constructions of this scheme are mostly obtained manually, and no algorithmic techniques for constructing depth- or gate-optimal circuits exist. As a consequence, the current state of the art exploits this scheme only for specific code instances and mostly for the special case of distance 3 codes. In this work, we propose an automated approach for synthesizing fault-tolerant state preparation circuits for arbitrary CSS codes. We utilize methods based on satisfiability solving (SAT) techniques to construct fault-tolerant state preparation circuits consisting of depth- and gate-optimal preparation and verification circuits. We also provide heuristics that can synthesize fault-tolerant state preparation circuits for code instances where no optimal solution can be obtained in an adequate timeframe. Moreover, we give a general construction for non-deterministic state preparation circuits beyond distance 3. Numerical evaluations using $d=3$ and $d=5$ codes confirm that the generated circuits exhibit the desired scaling of the logical error rates. The resulting methods are publicly available as part of the Munich Quantum Toolkit (MQT) at https://github.com/cda-tum/mqt-qecc. Such methods are an important step in providing fault-tolerant circuit constructions that can aid in near-term demonstration of fault-tolerant quantum computing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.11894v2</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tom Peham, Ludwig Schmid, Lucas Berent, Markus M\"uller, Robert Wille</dc:creator>
    </item>
  </channel>
</rss>
