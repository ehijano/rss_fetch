<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.IT</link>
    <description>math.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 21 Oct 2024 04:02:22 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Optimal Communication and Key Rate Region for Hierarchical Secure Aggregation with User Collusion</title>
      <link>https://arxiv.org/abs/2410.14035</link>
      <description>arXiv:2410.14035v1 Announce Type: new 
Abstract: Secure aggregation is concerned with the task of securely uploading the inputs of multiple users to an aggregation server without letting the server know the inputs beyond their summation. It finds broad applications in distributed machine learning paradigms such as federated learning (FL) where multiple clients, each having access to a proprietary dataset, periodically upload their locally trained models (abstracted as inputs) to a parameter server which then generates an aggregate (e.g., averaged) model that is sent back to the clients as an initializing point for a new round of local training. To enhance the data privacy of the clients, secure aggregation protocols are developed using techniques from cryptography to ensure that the server infers no more information of the users' inputs beyond the desired aggregated input, even if the server can collude with some users. Although laying the ground for understanding the fundamental utility-security trade-off in secure aggregation, the simple star client-server architecture cannot capture more complex network architectures used in practical systems. Motivated by hierarchical federated learning, we investigate the secure aggregation problem in a $3$-layer hierarchical network consisting of clustered users connecting to an aggregation server through an intermediate layer of relays. Besides the conventional server security which requires that the server learns nothing beyond the desired sum of inputs, relay security is also imposed so that the relays infer nothing about the users' inputs and remain oblivious. For such a hierarchical secure aggregation (HSA) problem, we characterize the optimal multifaceted trade-off between communication (in terms of user-to-relay and relay-to-server communication rates) and secret key generation efficiency (in terms of individual key and source key rates).</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14035v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiang Zhang, Kai Wan, Hua Sun, Shiqiang Wang, Mingyue Ji, Giuseppe Caire</dc:creator>
    </item>
    <item>
      <title>Coded Water-Filling for Multi-User Interference Cancellation</title>
      <link>https://arxiv.org/abs/2410.14136</link>
      <description>arXiv:2410.14136v1 Announce Type: new 
Abstract: In this paper, we study the system-level advantages provided by rateless coding, early termination and power allocation strategy for multiple users distributed across multiple cells. In a multi-cell scenario, the early termination of coded transmission not only reduces finite-length loss akin to the single-user scenario but also yields capacity enhancements due to the cancellation of interference across cells. We term this technique \emph{coded water-filling}, a concept that diverges from traditional water-filling by incorporating variable-length rateless coding and interference cancellation.
  We formulate a series of analytical models to quantify the gains associated with coded water-filling in multi-user scenarios. First, we analyze the capacity gains from interference cancellation in Additive White Gaussian Noise (AWGN) channels, which arises from the disparity in the number of bits transmitted by distinct users. Building upon this, we broaden our analysis to encompass fading channels to show the robustness of the interference cancellation algorithms. Finally, we address the power allocation problem analogous to the water-filling problem under a multi-user framework, proving that an elevation in the water-filling threshold facilitates overall system capacity enhancement. Our analysis reveals the capacity gains achievable through early termination and power allocation techniques in multi-user settings. These results show that coded water-filling is instrumental for further improving spectral efficiency in crowded spectrums.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14136v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuan Li, Zicheng Ye, Huazi Zhang, Jun Wang, Jianglei Ma, Wen Tong</dc:creator>
    </item>
    <item>
      <title>Secure Collaborative Computation Offloading and Resource Allocation in Cache-Assisted Ultra-Dense MEC Networks With Multi-Slope Channels</title>
      <link>https://arxiv.org/abs/2410.14142</link>
      <description>arXiv:2410.14142v1 Announce Type: new 
Abstract: Cache-assisted ultra-dense mobile edge computing (MEC) networks have been extensively seen as a promising solution to meeting the rapidly growing requirements of massive mobile devices (MDs). To properly tackle the complicated, severe, and average interferences caused by small base stations (SBSs) ultra-densely deployed in such networks, the orthogonal frequency division multiple access (OFDMA), non-orthogonal multiple access (NOMA) and base station (BS) clustering are jointly considered in this paper. To protect the tasks of MDs offloaded to BSs for computing, which are exposed to multiple MDs, and vulnerable to eavesdropping and malicious attacks, some security measures are further introduced. After that, we develop a computation offloading scheme to minimize the energy consumed by MDs under the constraints of delay, power, computing resources, and security costs, which jointly optimizes the task execution decision, device association, channel selection, security service assignment, power control, and computing resource allocation. To solve the finally formulated problem, we develop a high-performance algorithm by improving the existing hierarchical adaptive search algorithm. Then, the convergence, computation complexity, and parallel implementation analyses are made for the proposed algorithms. Simulation results show that such algorithms may generally achieve lower total energy consumption and delay than other algorithms under strict latency and cost constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14142v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianqing Zhou, Bobo Wang, Dong Qin, Xuefang Nie, Nan Jiang, Chunguo Li</dc:creator>
    </item>
    <item>
      <title>Wireless Human-Machine Collaboration in Industry 5.0</title>
      <link>https://arxiv.org/abs/2410.14153</link>
      <description>arXiv:2410.14153v1 Announce Type: new 
Abstract: Wireless Human-Machine Collaboration (WHMC) represents a critical advancement for Industry 5.0, enabling seamless interaction between humans and machines across geographically distributed systems. As the WHMC systems become increasingly important for achieving complex collaborative control tasks, ensuring their stability is essential for practical deployment and long-term operation. Stability analysis certifies how the closed-loop system will behave under model randomness, which is essential for systems operating with wireless communications. However, the fundamental stability analysis of the WHMC systems remains an unexplored challenge due to the intricate interplay between the stochastic nature of wireless communications, dynamic human operations, and the inherent complexities of control system dynamics. This paper establishes a fundamental WHMC model incorporating dual wireless loops for machine and human control. Our framework accounts for practical factors such as short-packet transmissions, fading channels, and advanced HARQ schemes. We model human control lag as a Markov process, which is crucial for capturing the stochastic nature of human interactions. Building on this model, we propose a stochastic cycle-cost-based approach to derive a stability condition for the WHMC system, expressed in terms of wireless channel statistics, human dynamics, and control parameters. Our findings are validated through extensive numerical simulations and a proof-of-concept experiment, where we developed and tested a novel wireless collaborative cart-pole control system. The results confirm the effectiveness of our approach and provide a robust framework for future research on WHMC systems in more complex environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14153v1</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gaoyang Pang, Wanchun Liu, Dusit Niyato, Daniel Quevedo, Branka Vucetic, Yonghui Li</dc:creator>
    </item>
    <item>
      <title>Fast proxy centers for Jeffreys centroids: The Jeffreys-Fisher-Rao and the inductive Gauss-Bregman centers</title>
      <link>https://arxiv.org/abs/2410.14326</link>
      <description>arXiv:2410.14326v1 Announce Type: new 
Abstract: The symmetric Kullback-Leibler centroid also called the Jeffreys centroid of a set of mutually absolutely continuous probability distributions on a measure space provides a notion of centrality which has proven useful in many tasks including information retrieval, information fusion, and clustering in image, video and sound processing. However, the Jeffreys centroid is not available in closed-form for sets of categorical or normal distributions, two widely used statistical models, and thus need to be approximated numerically in practice. In this paper, we first propose the new Jeffreys-Fisher-Rao center defined as the Fisher-Rao midpoint of the sided Kullback-Leibler centroids as a plug-in replacement of the Jeffreys centroid. This Jeffreys-Fisher-Rao center admits a generic formula for uni-parameter exponential family distributions, and closed-form formula for categorical and normal distributions, matches exactly the Jeffreys centroid for same-mean normal distributions, and is experimentally observed in practice to be close to the Jeffreys centroid. Second, we define a new type of inductive centers generalizing the principle of Gauss arithmetic-geometric double sequence mean for pairs of densities of any given exponential family. This center is shown experimentally to approximate very well the Jeffreys centroid and is suggested to use when the Jeffreys-Fisher-Rao center is not available in closed form. Moreover, this Gauss-Bregman inductive center always converges and matches the Jeffreys centroid for sets of same-mean normal distributions. We report on our experiments demonstrating the use of the Jeffreys-Fisher-Rao and Gauss-Bregman centers instead of the Jeffreys centroid. Finally, we conclude this work by reinterpreting these fast proxy centers of Jeffreys centroids under the lens of dually flat spaces in information geometry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14326v1</guid>
      <category>cs.IT</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Frank Nielsen</dc:creator>
    </item>
    <item>
      <title>Nonadaptive Noisy Group Testing with Optimal Tests and Decoding</title>
      <link>https://arxiv.org/abs/2410.14566</link>
      <description>arXiv:2410.14566v1 Announce Type: new 
Abstract: In Group Testing, the objective is to identify K defective items out of N, K&lt;&lt;N, by testing pools of items together and using the least amount of tests possible. In this paper, we propose a non-adaptive probabilistic group testing scheme in the presence of both false positives and false negatives in test outcomes. Our scheme simultaneously achieves the optimal asymptotic bound of O(KlogN) for both the number of tests and the decoding complexity of recovery with high probability, where O hides a constant that depends on the noisy channel. This result generalizes Price and Scarlett's group testing algorithm from the noiseless setting to the Binary Asymmetric Channel (BAC) and Binary Symmetric Channel (BSC) settings, achieving both the optimal number of tests and decoding complexity, which was one of the main open problems of this line of research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14566v1</guid>
      <category>cs.IT</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.IT</category>
      <pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaxin Li, Arya Mazumdar</dc:creator>
    </item>
    <item>
      <title>Site-Specific Outdoor Propagation Assessment and Ray-Tracing Analysis for Wireless Digital Twins</title>
      <link>https://arxiv.org/abs/2410.14620</link>
      <description>arXiv:2410.14620v1 Announce Type: new 
Abstract: Digital twinning is becoming increasingly vital in the design and real-time control of future wireless networks by providing precise cost-effective simulations, predictive insights, and real-time data integration. This paper explores the application of digital twinning in optimizing wireless communication systems within urban environments, where building arrangements can critically impact network performances. We develop a digital twin platform to simulate and analyze how factors such as building positioning, base station placement, and antenna design influence wireless propagation. The ray-tracing software package of Matlab is compared with Remcom Wireless InSite. Using a realistic radiation pattern of a base transceiver station (BTS) antenna, ray tracing simulations for signal propagation and interactions in urban landscapes are then extensively examined. By analyzing radio heat maps alongside antenna patterns, we gain valuable insights into optimizing wireless deployment strategies. This study highlights the potential of digital twinning as a critical tool for urban planners and network engineers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14620v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Morteza Ghaderi Aram, Hao Guo, Mingsheng Yin, Tommy Svensson</dc:creator>
    </item>
    <item>
      <title>Elements of disinformation theory: cyber engagement via increasing adversary information consumption</title>
      <link>https://arxiv.org/abs/2410.14168</link>
      <description>arXiv:2410.14168v1 Announce Type: cross 
Abstract: We consider the case where an adversary is conducting a surveillance campaign against a networked control system (NCS), and take the perspective of a defender/control system operator who has successfully isolated the cyber intruder. To better understand the adversary's intentions and to drive up their operating costs, the defender directs the adversary towards a ``honeypot" that emulates a real control system and without actual connections to a physical plant. We propose a strategy for adversary engagement within the ``honey" control system to increase the adversary's costs of information processing. We assume that, based on an understanding of the adversary's control theoretic goals, cyber threat intelligence (CTI) provides the defender knowledge of the adversary's preferences for information acquisition. We use this knowledge to spoof sensor readings to maximize the amount of information the adversary consumes while making it (information theoretically) difficult for the adversary to detect that they are being spoofed. We discuss the case of imperfect versus perfect threat intelligence and perform a numerical comparison.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14168v1</guid>
      <category>eess.SY</category>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>cs.SY</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Travis Cuvelier, Sean Ha, Maretta Morovitz</dc:creator>
    </item>
    <item>
      <title>Jamming Detection and Channel Estimation for Spatially Correlated Beamspace Massive MIMO</title>
      <link>https://arxiv.org/abs/2410.14215</link>
      <description>arXiv:2410.14215v1 Announce Type: cross 
Abstract: In this paper, we investigate the problem of jamming detection and channel estimation during multi-user uplink beam training under random pilot jamming attacks in beamspace massive multi-input-multi-output (MIMO) systems. For jamming detection, we distinguish the signals from the jammer and the user by projecting the observation signals onto the pilot space. By using the multiple projected observation vectors corresponding to the unused pilots, we propose a jamming detection scheme based on the locally most powerful test (LMPT) for systems with general channel conditions. Analytical expressions for the probability of detection and false alarms are derived using the second-order statistics and likelihood functions of the projected observation vectors. For the detected jammer along with users, we propose a two-step minimum mean square error (MMSE) channel estimation using the projected observation vectors. As a part of the channel estimation, we develop schemes to estimate the norm and the phase of the inner-product of the legitimate pilot vector and the random jamming pilot vector, which can be obtained using linear MMSE estimation and a bilinear form of the multiple projected observation vectors. From simulations under different system parameters, we observe that the proposed technique improves the detection probability by 32.22% compared to the baseline at medium channel correlation level, and the channel estimation achieves a mean square error of -15.93dB.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14215v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pengguang Du, Cheng Zhang, Yindi Jing, Chao Fang, Zhilei Zhang, Yongming Huang</dc:creator>
    </item>
    <item>
      <title>Surpassing the fundamental limits of distillation with catalysts</title>
      <link>https://arxiv.org/abs/2410.14547</link>
      <description>arXiv:2410.14547v1 Announce Type: cross 
Abstract: Quantum resource distillation is a fundamental task in quantum information science. Minimizing the distillation overhead, i.e., the amount of noisy source states required to produce some desired output state within some target error, is crucial for the scalability of quantum computation and communication. Here, we show that quantum catalysts -- an additional resource that facilitates the transformation but remains unchanged before and after the process -- can help surpass previously known fundamental limitations on distillation overhead. Specifically, we show that multi-shot distillation protocols can be converted into one-shot catalytic protocols, which hold significant practical benefits, while maintaining the distillation overhead. In particular, in the context of magic state distillation, our result indicates that the code-based low-overhead distillation protocols that rely on divergingly large batches can be promoted to the one-shot setting where the batch volume can be arbitrarily small for any accuracy. Combining with very recent results on asymptotically good quantum codes with transversal non-Clifford gates, we demonstrate that magic state distillation with constant overhead can be achieved with controllable output size using catalytic protocols. Furthermore, we demonstrate that catalysis enables a spacetime trade-off between overhead and success probability. Notably, we show that the optimal constant for constant-overhead catalytic magic state distillation can be reduced to $1$ at the price of compromising the success probability by a constant factor. Finally, we present an illustrative example that extends the catalysis techniques to the study of dynamic quantum resources. This provides the channel mutual information with a one-shot operational interpretation, thereby addressing an open question posed by Wilming.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14547v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kun Fang, Zi-Wen Liu</dc:creator>
    </item>
    <item>
      <title>Bayesian Multi-wavelength Imaging of the LMC SN1987A with SRG/eROSITA</title>
      <link>https://arxiv.org/abs/2410.14599</link>
      <description>arXiv:2410.14599v1 Announce Type: cross 
Abstract: The EDR and eRASS1 data have already revealed a remarkable number of undiscovered X-ray sources. Using Bayesian inference and generative modeling techniques for X-ray imaging, we aim to increase the sensitivity and scientific value of these observations by denoising, deconvolving, and decomposing the X-ray sky. Leveraging information field theory, we can exploit the spatial and spectral correlation structures of the different physical components of the sky with non-parametric priors to enhance the image reconstruction. By incorporating instrumental effects into the forward model, we develop a comprehensive Bayesian imaging algorithm for eROSITA pointing observations. Finally, we apply the developed algorithm to EDR data of the LMC SN1987A, fusing data sets from observations made by five different telescope modules. The final result is a denoised, deconvolved, and decomposed view of the LMC, which enables the analysis of its fine-scale structures, the creation of point source catalogues of this region, and enhanced calibration for future work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14599v1</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.HE</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>physics.data-an</category>
      <pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vincent Eberle, Matteo Guardiani, Margret Westerkamp, Philipp Frank, Michael Freyberg, Mara Salvato, Torsten En{\ss}lin</dc:creator>
    </item>
    <item>
      <title>Asymptotically Optimal Change Detection for Unnormalized Pre- and Post-Change Distributions</title>
      <link>https://arxiv.org/abs/2410.14615</link>
      <description>arXiv:2410.14615v1 Announce Type: cross 
Abstract: This paper addresses the problem of detecting changes when only unnormalized pre- and post-change distributions are accessible. This situation happens in many scenarios in physics such as in ferromagnetism, crystallography, magneto-hydrodynamics, and thermodynamics, where the energy models are difficult to normalize.
  Our approach is based on the estimation of the Cumulative Sum (CUSUM) statistics, which is known to produce optimal performance. We first present an intuitively appealing approximation method. Unfortunately, this produces a biased estimator of the CUSUM statistics and may cause performance degradation. We then propose the Log-Partition Approximation Cumulative Sum (LPA-CUSUM) algorithm based on thermodynamic integration (TI) in order to estimate the log-ratio of normalizing constants of pre- and post-change distributions. It is proved that this approach gives an unbiased estimate of the log-partition function and the CUSUM statistics, and leads to an asymptotically optimal performance. Moreover, we derive a relationship between the required sample size for thermodynamic integration and the desired detection delay performance, offering guidelines for practical parameter selection. Numerical studies are provided demonstrating the efficacy of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14615v1</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arman Adibi, Sanjeev Kulkarni, H. Vincent Poor, Taposh Banerjee, Vahid Tarokh</dc:creator>
    </item>
    <item>
      <title>Transversal non-Clifford gates for quantum LDPC codes on sheaves</title>
      <link>https://arxiv.org/abs/2410.14631</link>
      <description>arXiv:2410.14631v1 Announce Type: cross 
Abstract: A major goal in quantum computing is to build a fault-tolerant quantum computer. One approach involves quantum low-density parity-check (qLDPC) codes that support transversal non-Clifford gates. In this work, we provide a large family of such codes. The key insight is to interpret the logical operators of qLDPC codes as geometric surfaces and use the intersection number of these surfaces to define the non-Clifford operation. At a more abstract level, this construction is based on defining the cup product on the chain complex induced from a sheaf.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14631v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ting-Chun Lin</dc:creator>
    </item>
    <item>
      <title>Quantum LDPC Codes with Transversal Non-Clifford Gates via Products of Algebraic Codes</title>
      <link>https://arxiv.org/abs/2410.14662</link>
      <description>arXiv:2410.14662v1 Announce Type: cross 
Abstract: For every integer $r\geq 2$ and every $\epsilon&gt;0$, we construct an explicit infinite family of quantum LDPC codes supporting a transversal $C^{r-1}Z$ gate with length $N$, dimension $K\geq N^{1-\epsilon}$, distance $D\geq N^{1/r}/\operatorname{poly}(\log N)$, and stabilizer weight $w\leq\operatorname{poly}(\log N)$. The previous state of the art construction (in most parameter regimes) was the $r$-dimensional color code, which has only constant dimension $K=O(1)$, and otherwise has the same parameters up to polylogarithmic factors. Our construction provides the first known codes with low-weight stabilizers that are capable of magic state distillation with arbitrarily small yield parameter $\gamma=\log(N/K)/\log(D)&gt;0$.
  A classical analogue of transversal $C^{r-1}Z$ gates is given by the multiplication property, which requires component-wise products of classical codewords to belong to another similar code. As a byproduct of our techniques, we also obtain a new construction of classical locally testable codes with such a multiplication property.
  We construct our codes as products of chain complexes associated to classical LDPC codes, which in turn we obtain by imposing local Reed-Solomon codes on a specific spectral expander that we construct. We prove that our codes support the desired transversal $C^{r-1}Z$ gates by using the multiplication property to combine local circuits based on the topological structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14662v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Louis Golowich, Ting-Chun Lin</dc:creator>
    </item>
    <item>
      <title>A simplicity bubble problem and zemblanity in digitally intermediated societies</title>
      <link>https://arxiv.org/abs/2304.10681</link>
      <description>arXiv:2304.10681v3 Announce Type: replace 
Abstract: In this article, we discuss the ubiquity of Big Data and machine learning in society and propose that it evinces the need of further investigation of their fundamental limitations. We extend the ``too much information tends to behave like very little information'' phenomenon to formal knowledge about lawlike universes and arbitrary collections of computably generated datasets. This gives rise to the simplicity bubble problem, which refers to a learning algorithm equipped with a formal theory that can be deceived by a dataset to find a locally optimal model which it deems to be the global one. In the context of lawlike (computable) universes and formal learning systems, we show that there is a ceiling above which formal knowledge cannot further decrease the probability of zemblanitous findings, should the randomly generated data made available to the formal learning system be sufficiently large in comparison to their joint complexity. Zemblanity, the opposite of serendipity, is defined by an undesirable but expected finding that reveals an underlying problem or negative consequence in a given model or theory, which is in principle predictable in case the formal theory contains sufficient information. We also argue that this is an epistemological limitation that may generate unpredictable problems in digitally intermediated societies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.10681v3</guid>
      <category>cs.IT</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <category>cs.SI</category>
      <category>math.IT</category>
      <pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Felipe S. Abrah\~ao, Ricardo P. Cavassane, Michael Winter, Mariana Vitti Rodrigues, Itala M. L. D'Ottaviano</dc:creator>
    </item>
    <item>
      <title>Pre-Chirp-Domain Index Modulation for Full-Diversity Affine Frequency Division Multiplexing towards 6G</title>
      <link>https://arxiv.org/abs/2410.00313</link>
      <description>arXiv:2410.00313v2 Announce Type: replace 
Abstract: Affine frequency division multiplexing (AFDM), tailored as a superior multicarrier technique utilizing chirp signals for high-mobility communications, is envisioned as a promising candidate for the sixth-generation (6G) wireless network. AFDM is based on the discrete affine Fourier transform (DAFT) with two adjustable parameters of the chirp signals, termed as the pre-chirp and post-chirp parameters, respectively. We show that the pre-chirp counterpart can be flexibly manipulated for additional degree-of-freedom (DoF). Therefore, this paper proposes a novel AFDM scheme with the pre-chirp index modulation (PIM) philosophy (AFDM-PIM), which can implicitly convey extra information bits through dynamic pre-chirp parameter assignment, thus enhancing both spectral and energy efficiency. Specifically, we first demonstrate that the subcarrier orthogonality is still maintained by applying distinct pre-chirp parameters to various subcarriers in the AFDM modulation process. Inspired by this property, each AFDM subcarrier is constituted with a unique pre-chirp signal according to the incoming bits. By such arrangement, extra binary bits can be embedded into the index patterns of pre-chirp parameter assignment without additional energy consumption. For performance analysis, we derive the asymptotically tight upper bounds on the average bit error rates (BERs) of the proposed schemes with maximum-likelihood (ML) detection, and validate that the proposed AFDM-PIM can achieve the optimal diversity order under doubly dispersive channels. Based on the derivations, we further propose an optimal pre-chirp alphabet design to enhance the BER performance via intelligent optimization algorithms. Simulations demonstrate that the proposed AFDM-PIM outperforms the classical benchmarks under doubly dispersive channel.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00313v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guangyao Liu, Tianqi Mao, Zhenyu Xiao, Ruiqi Liu, Miaowen Wen</dc:creator>
    </item>
    <item>
      <title>Tight bounds on Pauli channel learning without entanglement</title>
      <link>https://arxiv.org/abs/2309.13461</link>
      <description>arXiv:2309.13461v3 Announce Type: replace-cross 
Abstract: Quantum entanglement is a crucial resource for learning properties from nature, but a precise characterization of its advantage can be challenging. In this work, we consider learning algorithms without entanglement to be those that only utilize states, measurements, and operations that are separable between the main system of interest and an ancillary system. Interestingly, we show that these algorithms are equivalent to those that apply quantum circuits on the main system interleaved with mid-circuit measurements and classical feedforward. Within this setting, we prove a tight lower bound for Pauli channel learning without entanglement that closes the gap between the best-known upper and lower bound. In particular, we show that $\Theta(2^n\varepsilon^{-2})$ rounds of measurements are required to estimate each eigenvalue of an $n$-qubit Pauli channel to $\varepsilon$ error with high probability when learning without entanglement. In contrast, a learning algorithm with entanglement only needs $\Theta(\varepsilon^{-2})$ copies of the Pauli channel. The tight lower bound strengthens the foundation for an experimental demonstration of entanglement-enhanced advantages for Pauli noise characterization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.13461v3</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1103/PhysRevLett.132.180805</arxiv:DOI>
      <arxiv:journal_reference>Phys. Rev. Lett. 132, 180805 (2024)</arxiv:journal_reference>
      <dc:creator>Senrui Chen, Changhun Oh, Sisi Zhou, Hsin-Yuan Huang, Liang Jiang</dc:creator>
    </item>
    <item>
      <title>Discrete Messages Improve Communication Efficiency among Isolated Intelligent Agents</title>
      <link>https://arxiv.org/abs/2312.15985</link>
      <description>arXiv:2312.15985v3 Announce Type: replace-cross 
Abstract: Individuals, despite having varied life experiences and learning processes, can communicate effectively through languages. This study aims to explore the efficiency of language as a communication medium. We put forth two specific hypotheses: First, discrete messages are more effective than continuous ones when agents have diverse personal experiences. Second, communications using multiple discrete tokens are more advantageous than those using a single token. To valdate these hypotheses, we designed multi-agent machine learning experiments to assess communication efficiency using various information transmission methods between speakers and listeners. Our empirical findings indicate that, in scenarios where agents are exposed to different data, communicating through sentences composed of discrete tokens offers the best inter-agent communication efficiency. The limitations of our finding include lack of systematic advantages over other more sophisticated encoder-decoder model such as variational autoencoder and lack of evluation on non-image dataset, which we will leave for future studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.15985v3</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hang Chen, Yuchuan Jang, Weijie Zhou, Cristian Meo, Ziwei Chen, Dianbo Liu</dc:creator>
    </item>
    <item>
      <title>Residual-INR: Communication Efficient On-Device Learning Using Implicit Neural Representation</title>
      <link>https://arxiv.org/abs/2408.05617</link>
      <description>arXiv:2408.05617v2 Announce Type: replace-cross 
Abstract: Edge computing is a distributed computing paradigm that collects and processes data at or near the source of data generation. The on-device learning at edge relies on device-to-device wireless communication to facilitate real-time data sharing and collaborative decision-making among multiple devices. This significantly improves the adaptability of the edge computing system to the changing environments. However, as the scale of the edge computing system is getting larger, communication among devices is becoming the bottleneck because of the limited bandwidth of wireless communication leads to large data transfer latency. To reduce the amount of device-to-device data transmission and accelerate on-device learning, in this paper, we propose Residual-INR, a fog computing-based communication-efficient on-device learning framework by utilizing implicit neural representation (INR) to compress images/videos into neural network weights. Residual-INR enhances data transfer efficiency by collecting JPEG images from edge devices, compressing them into INR format at the fog node, and redistributing them for on-device learning. By using a smaller INR for full image encoding and a separate object INR for high-quality object region reconstruction through residual encoding, our technique can reduce the encoding redundancy while maintaining the object quality. Residual-INR is a promising solution for edge on-device learning because it reduces data transmission by up to 5.16 x across a network of 10 edge devices. It also facilitates CPU-free accelerated on-device learning, achieving up to 2.9 x speedup without sacrificing accuracy. Our code is available at: https://github.com/sharclab/Residual-INR.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05617v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.DC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hanqiu Chen, Xuebin Yao, Pradeep Subedi, Cong Hao</dc:creator>
    </item>
  </channel>
</rss>
