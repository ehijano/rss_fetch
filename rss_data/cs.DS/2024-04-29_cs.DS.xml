<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 30 Apr 2024 04:00:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 30 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Approximation Algorithms for $\ell_p$-Shortest Path and $\ell_p$-Group Steiner Tree</title>
      <link>https://arxiv.org/abs/2404.17669</link>
      <description>arXiv:2404.17669v1 Announce Type: new 
Abstract: We present polylogarithmic approximation algorithms for variants of the Shortest Path, Group Steiner Tree, and Group ATSP problems with vector costs. In these problems, each edge e has a non-negative vector cost $c_e \in \mathbb{R}^{\ell}_{\ge 0}$. For a feasible solution - a path, subtree, or tour (respectively) - we find the total vector cost of all the edges in the solution and then compute the $\ell_p$-norm of the obtained cost vector (we assume that $p \ge 1$ is an integer). Our algorithms for series-parallel graphs run in polynomial time and those for arbitrary graphs run in quasi-polynomial time. To obtain our results, we introduce and use new flow-based Sum-of-Squares relaxations. We also obtain a number of hardness results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17669v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yury Makarychev, Max Ovsiankin, Erasmo Tani</dc:creator>
    </item>
    <item>
      <title>Lower Bounds for Private Estimation of Gaussian Covariance Matrices under All Reasonable Parameter Regimes</title>
      <link>https://arxiv.org/abs/2404.17714</link>
      <description>arXiv:2404.17714v1 Announce Type: new 
Abstract: We prove lower bounds on the number of samples needed to privately estimate the covariance matrix of a Gaussian distribution. Our bounds match existing upper bounds in the widest known setting of parameters. Our analysis relies on the Stein-Haff identity, an extension of the classical Stein's identity used in previous fingerprinting lemma arguments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17714v1</guid>
      <category>cs.DS</category>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Victor S. Portella, Nick Harvey</dc:creator>
    </item>
    <item>
      <title>Directed Isoperimetry and Monotonicity Testing: A Dynamical Approach</title>
      <link>https://arxiv.org/abs/2404.17882</link>
      <description>arXiv:2404.17882v1 Announce Type: new 
Abstract: This paper explores the connection between classical isoperimetric inequalities, their directed analogues, and monotonicity testing. We study the setting of real-valued functions $f : [0,1]^d \to \mathbb{R}$ on the solid unit cube, where the goal is to test with respect to the $L^p$ distance. Our goals are twofold: to further understand the relationship between classical and directed isoperimetry, and to give a monotonicity tester with sublinear query complexity in this setting.
  Our main results are 1) an $L^2$ monotonicity tester for $M$-Lipschitz functions with query complexity $\widetilde O(\sqrt{d} M^2 / \epsilon^2)$ and, behind this result, 2) the directed Poincar\'e inequality $\mathsf{dist}^{\mathsf{mono}}_2(f)^2 \le C \mathbb{E}[|\nabla^- f|^2]$, where the "directed gradient" operator $\nabla^-$ measures the local violations of monotonicity of $f$.
  To prove the second result, we introduce a partial differential equation (PDE), the directed heat equation, which takes a one-dimensional function $f$ into a monotone function $f^*$ over time and enjoys many desirable analytic properties. We obtain the directed Poincar\'e inequality by combining convergence aspects of this PDE with the theory of optimal transport. Crucially for our conceptual motivation, this proof is in complete analogy with the mathematical physics perspective on the classical Poincar\'e inequality, namely as characterizing the convergence of the standard heat equation toward equilibrium.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17882v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Renato Ferreira Pinto Jr</dc:creator>
    </item>
    <item>
      <title>Approximation and FPT Algorithms for Finding DM-Irreducible Spanning Subgraphs</title>
      <link>https://arxiv.org/abs/2404.17927</link>
      <description>arXiv:2404.17927v1 Announce Type: new 
Abstract: Finding a minimum strongly connected spanning subgraph of a given directed graph generalizes the well-known strong connectivity augmentation problem, and it is NP-hard. For the weighted problem, a simple $2$-approximation algorithm was proposed by Frederickson and J\'{a}j\'{a} (1981); surprisingly, it still achieves the best known approximation ratio in general. Also, the unweighted problem was shown to be FPT by Bang-Jensen and Yeo (2008), where the parameter is the difference from the trivial upper bound of the optimal value. In this paper, we consider a generalized problem related to the Dulmage--Mendelsohn decompositions of bipartite graphs instead of the strong connectivity of directed graphs, and extend the above approximation and FPT results to this setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17927v1</guid>
      <category>cs.DS</category>
      <category>math.CO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ryoma Norose, Yutaro Yamaguchi</dc:creator>
    </item>
    <item>
      <title>Parameterized Linear Time Transitive Closure</title>
      <link>https://arxiv.org/abs/2404.17954</link>
      <description>arXiv:2404.17954v1 Announce Type: new 
Abstract: Inquiries such as whether a task A depends on a task B, whether an author A has been influenced by a paper B, whether a certain protein is associated with a specific biological process or molecular function, or whether class A inherits from class B, are just a few examples of inquiries that can be modeled as reachability queries on a network (Directed Graph). Digital systems answer myriad such inquiries every day.
  In this paper, we discuss the transitive closure problem. We focus on applicable solutions that enable us to answer queries fast, in constant time, and can serve in real-world applications. In contrast to the majority of research on this topic that revolves around the construction of a two-dimensional adjacency matrix, we present an approach that builds a reachability indexing scheme. This scheme enables us to answer queries in constant time and can be built in parameterized linear time. In addition, it captures a compressed data structure. Our approach and algorithms are validated by extensive experiments that shed light on the factors that play a key role in this problem. To stress the efficiency of this solution and demonstrate the potential to apply our approach to important problems, we use it algorithm to speed up Fulkerson's method for finding the width of a DAG. Our results challenge the prevailing belief, reiterated over the last thirty years, regarding the efficiency of this method.
  Our approach is based on the concept of chain decomposition. Before we delve into its description, we introduce, analyze, and utilize a chain decomposition algorithm. Furthermore, we explore how chain decomposition can facilitate transitive closure solutions introducing a general purpose linear time reduction technique that removes a large subset of transitive edges given any chain decomposition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17954v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giorgos Kritikakis, Ioannis G Tollis</dc:creator>
    </item>
    <item>
      <title>Varia\c{c}\~oes do Problema de Dist\^ancia de Rearranjos</title>
      <link>https://arxiv.org/abs/2404.17996</link>
      <description>arXiv:2404.17996v1 Announce Type: new 
Abstract: Considering a pair of genomes, the goal of rearrangement distance problems is to estimate how distant these genomes are from each other based on genome rearrangements. Seminal works in genome rearrangements assumed that both genomes being compared have the same set of genes (balanced genomes) and, furthermore, only the relative order of genes and their orientations, when they are known, are used in the mathematical representation of the genomes. In this case, the genomes are represented as permutations, originating the Sorting Permutations by Rearrangements problems. The main problems of Sorting Permutations by Rearrangements considered DCJs, reversals, transpositions, or the combination of both reversals and transpositions, and these problems have their complexity known. Besides these problems, other ones were studied involving the combination of transpositions with one or more of the following rearrangements: transreversals, revrevs, and reversals. Although there are approximation results for these problems, their complexity remained open. Some of the results of this thesis are the complexity proofs for these problems. Furthermore, we present a new 1.375-approximation algorithm, which has better time complexity, for the Sorting Permutations by Transpositions. When considering unbalanced genomes, it is necessary to use insertions and deletions to transform one genome into another. In this thesis, we studied Rearrangement Distance problems on unbalanced genomes considering only gene order and their orientations (when they are known), as well as Intergenic Rearrangement Distance problems, which incorporate the information regarding the size distribution of intergenic regions, besides the use of gene order and their orientations (when they are known). We present complexity proofs and approximation algorithms for problems that include reversals and transpositions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17996v1</guid>
      <category>cs.DS</category>
      <category>q-bio.QM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexsandro Oliveira Alexandrino</dc:creator>
    </item>
    <item>
      <title>Testing $C_k$-freeness in bounded-arboricity graphs</title>
      <link>https://arxiv.org/abs/2404.18126</link>
      <description>arXiv:2404.18126v1 Announce Type: new 
Abstract: We study the problem of testing $C_k$-freeness ($k$-cycle-freeness) for fixed constant $k &gt; 3$ in graphs with bounded arboricity (but unbounded degrees). In particular, we are interested in one-sided error algorithms, so that they must detect a copy of $C_k$ with high constant probability when the graph is $\epsilon$-far from $C_k$-free. We next state our results for constant arboricity and constant $\epsilon$ with a focus on the dependence on the number of graph vertices, $n$. The query complexity of all our algorithms grows polynomially with $1/\epsilon$. (1) As opposed to the case of $k=3$, where the complexity of testing $C_3$-freeness grows with the arboricity of the graph but not with the size of the graph (Levi, ICALP 2021) this is no longer the case already for $k=4$. We show that $\Omega(n^{1/4})$ queries are necessary for testing $C_4$-freeness, and that $\widetilde{O}(n^{1/4})$ are sufficient. The same bounds hold for $C_5$. (2) For every fixed $k \geq 6$, any one-sided error algorithm for testing $C_k$-freeness must perform $\Omega(n^{1/3})$ queries. (3) For $k=6$ we give a testing algorithm whose query complexity is $\widetilde{O}(n^{1/2})$. (4) For any fixed $k$, the query complexity of testing $C_k$-freeness is upper bounded by ${O}(n^{1-1/\lfloor k/2\rfloor})$.
  Our $\Omega(n^{1/4})$ lower bound for testing $C_4$-freeness in constant arboricity graphs provides a negative answer to an open problem posed by (Goldreich, 2021).</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18126v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Talya Eden, Reut Levi, Dana Ron</dc:creator>
    </item>
    <item>
      <title>Additive Spanner Lower Bounds with Optimal Inner Graph Structure</title>
      <link>https://arxiv.org/abs/2404.18337</link>
      <description>arXiv:2404.18337v1 Announce Type: new 
Abstract: We construct $n$-node graphs on which any $O(n)$-size spanner has additive error at least $+\Omega(n^{3/17})$, improving on the previous best lower bound of $\Omega(n^{1/7})$ [Bodwin-Hoppenworth FOCS '22]. Our construction completes the first two steps of a particular three-step research program, introduced in prior work and overviewed here, aimed at producing tight bounds for the problem by aligning aspects of the upper and lower bound constructions. More specifically, we develop techniques that enable the use of inner graphs in the lower bound framework whose technical properties are provably tight with the corresponding assumptions made in the upper bounds. As an additional application of our techniques, we improve the corresponding lower bound for $O(n)$-size additive emulators to $+\Omega(n^{1/14})$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18337v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Greg Bodwin, Gary Hoppenworth, Virginia Vassilevska Williams, Nicole Wein, Zixuan Xu</dc:creator>
    </item>
    <item>
      <title>PHOBIC: Perfect Hashing with Optimized Bucket Sizes and Interleaved Coding</title>
      <link>https://arxiv.org/abs/2404.18497</link>
      <description>arXiv:2404.18497v1 Announce Type: new 
Abstract: A minimal perfect hash function (MPHF) maps a set of n keys to {1, ..., n} without collisions. Such functions find widespread application e.g. in bioinformatics and databases. In this paper we revisit PTHash - a construction technique particularly designed for fast queries. PTHash distributes the input keys into small buckets and, for each bucket, it searches for a hash function seed that places its keys in the output domain without collisions. The collection of all seeds is then stored in a compressed way. Since the first buckets are easier to place, buckets are considered in non-increasing order of size. Additionally, PTHash heuristically produces an imbalanced distribution of bucket sizes by distributing 60% of the keys into 30% of the buckets. Our main contribution is to characterize, up to lower order terms, an optimal distribution of expected bucket sizes. We arrive at a simple, closed form solution which improves construction throughput for space efficient configurations in practice. Our second contribution is a novel encoding scheme for the seeds. We split the keys into partitions. Within each partition, we run the bucket distribution and search step. We then store the seeds in an interleaved way by consecutively placing the seeds for the i-th buckets from all partitions. The seeds for the i-th bucket of each partition follow the same statistical distribution. This allows us to tune a compressor for each bucket. Hence, we call our technique PHOBIC - Perfect Hashing with Optimized Bucket sizes and Interleaved Coding. Compared to PTHash, PHOBIC is 0.17 bits/key more space efficient for same query time and construction throughput. We also contribute a GPU implementation to further accelerate MPHF construction. For a configuration with fast queries, PHOBIC-GPU can construct a perfect hash function at 2.17 bits/key in 28 ns per key, which can be queried in 37 ns on the CPU.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18497v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefan Hermann, Hans-Peter Lehmann, Giulio Ermanno Pibiri, Peter Sanders, Stefan Walzer</dc:creator>
    </item>
    <item>
      <title>Did Fourier Really Meet M\"obius? Fast Subset Convolution via FFT</title>
      <link>https://arxiv.org/abs/2404.18522</link>
      <description>arXiv:2404.18522v1 Announce Type: new 
Abstract: In their seminal work on subset convolution, Bj\"orklund, Husfeldt, Kaski and Koivisto introduced the now well-known $O(2^n n^2)$-time evaluation of the subset convolution in the sum-product ring. This sparked a wave of remarkable results for fundamental problems, such as the minimum Steiner tree and the chromatic number. However, in spite of its theoretical improvement, large intermediate outputs and floating-point precision errors due to alternating addition and subtraction in its set function transforms make the algorithm unusable in practice.
  We provide a simple FFT-based algorithm that completely eliminates the need for set function transforms and maintains the running time of the original algorithm. This makes it possible to take advantage of nearly sixty years of research on efficient FFT implementations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18522v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mihail Stoian</dc:creator>
    </item>
    <item>
      <title>Private graph colouring with limited defectiveness</title>
      <link>https://arxiv.org/abs/2404.18692</link>
      <description>arXiv:2404.18692v1 Announce Type: new 
Abstract: Differential privacy is the gold standard in the problem of privacy preserving data analysis, which is crucial in a wide range of disciplines. Vertex colouring is one of the most fundamental questions about a graph. In this paper, we study the vertex colouring problem in the differentially private setting.
  To be edge-differentially private, a colouring algorithm needs to be defective: a colouring is d-defective if a vertex can share a colour with at most d of its neighbours. Without defectiveness, the only differentially private colouring algorithm needs to assign n different colours to the n different vertices. We show the following lower bound for the defectiveness: a differentially private c-edge colouring algorithm of a graph of maximum degree {\Delta} &gt; 0 has defectiveness at least d = {\Omega} (log n / (log c+log {\Delta})).
  We also present an {\epsilon}-differentially private algorithm to {\Theta} ( {\Delta} / log n + 1 / {\epsilon})-colour a graph with defectiveness at most {\Theta}(log n).</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18692v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aleksander B. G. Christiansen, Eva Rotenberg, Teresa Anna Steiner, Juliette Vlieghe</dc:creator>
    </item>
    <item>
      <title>Improved bounds for group testing in arbitrary hypergraphs</title>
      <link>https://arxiv.org/abs/2404.18783</link>
      <description>arXiv:2404.18783v1 Announce Type: new 
Abstract: Recent papers initiated the study of a generalization of group testing where the potentially contaminated sets are the members of a given hypergraph F=(V,E). This generalization finds application in contexts where contaminations can be conditioned by some kinds of social and geographical clusterings. The paper focuses on few-stage group testing algorithms, i.e., slightly adaptive algorithms where tests are performed in stages and all tests performed in the same stage should be decided at the very beginning of the stage. In particular, the paper presents the first two-stage algorithm that uses o(dlog|E|) tests for general hypergraphs with hyperedges of size at most d, and a three-stage algorithm that improves by a d^{1/6} factor on the number of tests of the best known three-stage algorithm. These algorithms are special cases of an s-stage algorithm designed for an arbitrary positive integer s&lt;= d. The design of this algorithm resort to a new non-adaptive algorithm (one-stage algorithm), i.e., an algorithm where all tests must be decided beforehand. Further, we derive a lower bound for non-adaptive group testing. For E sufficiently large, the lower bound is very close to the upper bound on the number of tests of the best non-adaptive group testing algorithm known in the literature, and it is the first lower bound that improves on the information theoretic lower bound Omega(log |E|).</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18783v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Annalisa De Bonis</dc:creator>
    </item>
    <item>
      <title>Learning general Gaussian mixtures with efficient score matching</title>
      <link>https://arxiv.org/abs/2404.18893</link>
      <description>arXiv:2404.18893v1 Announce Type: new 
Abstract: We study the problem of learning mixtures of $k$ Gaussians in $d$ dimensions. We make no separation assumptions on the underlying mixture components: we only require that the covariance matrices have bounded condition number and that the means and covariances lie in a ball of bounded radius. We give an algorithm that draws $d^{\mathrm{poly}(k/\varepsilon)}$ samples from the target mixture, runs in sample-polynomial time, and constructs a sampler whose output distribution is $\varepsilon$-far from the unknown mixture in total variation. Prior works for this problem either (i) required exponential runtime in the dimension $d$, (ii) placed strong assumptions on the instance (e.g., spherical covariances or clusterability), or (iii) had doubly exponential dependence on the number of components $k$.
  Our approach departs from commonly used techniques for this problem like the method of moments. Instead, we leverage a recently developed reduction, based on diffusion models, from distribution learning to a supervised learning task called score matching. We give an algorithm for the latter by proving a structural result showing that the score function of a Gaussian mixture can be approximated by a piecewise-polynomial function, and there is an efficient algorithm for finding it. To our knowledge, this is the first example of diffusion models achieving a state-of-the-art theoretical guarantee for an unsupervised learning task.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18893v1</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sitan Chen, Vasilis Kontonis, Kulin Shah</dc:creator>
    </item>
    <item>
      <title>Recent Increments in Incremental View Maintenance</title>
      <link>https://arxiv.org/abs/2404.17679</link>
      <description>arXiv:2404.17679v1 Announce Type: cross 
Abstract: We overview recent progress on the longstanding problem of incremental view maintenance (IVM), with a focus on the fine-grained complexity and optimality of IVM for classes of conjunctive queries. This theoretical progress guided the development of IVM engines that reported practical benefits in academic papers and industrial settings. When taken in isolation, each of the reported advancements is but a small increment. Yet when taken together, they may well pave the way to a deeper understanding of the IVM problem.
  This paper accompanies the invited Gems of PODS 2024 talk with the same title. Some of the works highlighted in this paper are based on prior or on-going collaborations with: Ahmet Kara, Milos Nikolic, and Haozhe Zhang in the F-IVM project; and Mahmoud Abo Khamis, Niko G\"obel, Hung Ngo, and Dan Suciu at RelationalAI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17679v1</guid>
      <category>cs.DB</category>
      <category>cs.DS</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dan Olteanu</dc:creator>
    </item>
    <item>
      <title>Generalizing Roberts' characterization of unit interval graphs</title>
      <link>https://arxiv.org/abs/2404.17872</link>
      <description>arXiv:2404.17872v1 Announce Type: cross 
Abstract: For any natural number $d$, a graph $G$ is a (disjoint) $d$-interval graph if it is the intersection graph of (disjoint) $d$-intervals, the union of $d$ (disjoint) intervals on the real line. Two important subclasses of $d$-interval graphs are unit and balanced $d$-interval graphs (where every interval has unit length or all the intervals associated to a same vertex have the same length, respectively). A celebrated result by Roberts gives a simple characterization of unit interval graphs being exactly claw-free interval graphs. Here, we study the generalization of this characterization for $d$-interval graphs. In particular, we prove that for any $d \geq 2$, if $G$ is a $K_{1,2d+1}$-free interval graph, then $G$ is a unit $d$-interval graph. However, somehow surprisingly, under the same assumptions, $G$ is not always a \emph{disjoint} unit $d$-interval graph. This implies that the class of disjoint unit $d$-interval graphs is strictly included in the class of unit $d$-interval graphs. Finally, we study the relationships between the classes obtained under disjoint and non-disjoint $d$-intervals in the balanced case and show that the classes of disjoint balanced 2-intervals and balanced 2-intervals coincide, but this is no longer true for $d&gt;2$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17872v1</guid>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Virginia Ard\'evol Mart\'inez, Romeo Rizzi, Abdallah Saffidine, Florian Sikora, St\'ephane Vialette</dc:creator>
    </item>
    <item>
      <title>Revisiting Majumdar-Ghosh spin chain model and Max-cut problem using variational quantum algorithms</title>
      <link>https://arxiv.org/abs/2404.18142</link>
      <description>arXiv:2404.18142v1 Announce Type: cross 
Abstract: In this work, energy levels of the Majumdar-Ghosh model (MGM) are analyzed up to 15 spins chain in the noisy intermediate-scale quantum framework using noisy simulations. This is a useful model whose exact solution is known for a particular choice of interaction coefficients. We have solved this model for interaction coefficients other than that required for the exactly solvable conditions as this solution can be of help in understanding the quantum phase transitions in complex spin chain models. The solutions are obtained using quantum approximate optimization algorithms (QAOA), and variational quantum eigensolver (VQE). To obtain the solutions, the one-dimensional lattice network is mapped to a Hamiltonian that corresponds to the required interaction coefficients among spins. Then, the ground states energy eigenvalue of this Hamiltonian is found using QAOA and VQE. Further, the validity of the Lieb-Schultz-Mattis theorem in the context of MGM is established by employing variational quantum deflation to find the first excited energy of MGM. Solution for an unweighted Max-cut graph for 17 nodes is also obtained using QAOA and VQE to know which one of these two techniques performs better in a combinatorial optimization problem. Since the variational quantum algorithms used here to revisit the Max-cut problem and MGM are hybrid algorithms, they require classical optimization. Consequently, the results obtained using different types of classical optimizers are compared to reveal that the QNSPSA optimizer improves the convergence of QAOA in comparison to the SPSA optimizer. However, VQE with EfficientSU2 ansatz using the SPSA optimizer yields the best results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18142v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator> Britant, Anirban Pathak</dc:creator>
    </item>
    <item>
      <title>The PRODSAT phase of random quantum satisfiability</title>
      <link>https://arxiv.org/abs/2404.18447</link>
      <description>arXiv:2404.18447v1 Announce Type: cross 
Abstract: The $k$-QSAT problem is a quantum analog of the famous $k$-SAT constraint satisfaction problem. We must determine the zero energy ground states of a Hamiltonian of $N$ qubits consisting of a sum of $M$ random $k$-local rank-one projectors. It is known that product states of zero energy exist with high probability if and only if the underlying factor graph has a clause-covering dimer configuration. This means that the threshold of the PRODSAT phase is a purely geometric quantity equal to the dimer covering threshold. We revisit and fully prove this result through a combination of complex analysis and algebraic methods based on Buchberger's algorithm for complex polynomial equations with random coefficients. We also discuss numerical experiments investigating the presence of entanglement in the PRODSAT phase in the sense that product states do not span the whole zero energy ground state space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18447v1</guid>
      <category>cs.IT</category>
      <category>cs.DS</category>
      <category>math.IT</category>
      <category>quant-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joon Lee, Nicolas Macris, Jean Bernoulli Ravelomanana, Perrine Vantalon</dc:creator>
    </item>
    <item>
      <title>Beating Posits at Their Own Game: Takum Arithmetic</title>
      <link>https://arxiv.org/abs/2404.18603</link>
      <description>arXiv:2404.18603v1 Announce Type: cross 
Abstract: Recent evaluations have highlighted the tapered posit number format as a promising alternative to the uniform precision IEEE 754 floating-point numbers, which suffer from various deficiencies. Although the posit encoding scheme offers superior coding efficiency at values close to unity, its efficiency markedly diminishes with deviation from unity. This reduction in efficiency leads to suboptimal encodings and a consequent diminution in dynamic range, thereby rendering posits suboptimal for general-purpose computer arithmetic.
  This paper introduces and formally proves 'takum' as a novel general-purpose logarithmic tapered-precision number format, synthesising the advantages of posits in low-bit applications with high encoding efficiency for numbers distant from unity. Takums exhibit an asymptotically constant dynamic range in terms of bit string length, which is delineated in the paper to be suitable for a general-purpose number format. It is demonstrated that takums either match or surpass existing alternatives. Moreover, takums address several issues previously identified in posits while unveiling novel and beneficial arithmetic properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18603v1</guid>
      <category>math.NA</category>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Laslo Hunhold</dc:creator>
    </item>
    <item>
      <title>Graph Search Trees and the Intermezzo Problem</title>
      <link>https://arxiv.org/abs/2404.18645</link>
      <description>arXiv:2404.18645v1 Announce Type: cross 
Abstract: The last in-tree recognition problem asks whether a given spanning tree can be derived by connecting each vertex with its rightmost left neighbor of some search ordering. In this study, we demonstrate that the last-in-tree recognition problem for Generic Search is $\mathsf{NP}$-complete. We utilize this finding to strengthen a complexity result from order theory. Given partial order $\pi$ and a set of triples, the $\mathsf{NP}$-complete intermezzo problem asks for a linear extension of $\pi$ where each first element of a triple is not between the other two. We show that this problem remains $\mathsf{NP}$-complete even when the Hasse diagram of the partial order forms a tree of bounded height. In contrast, we give an $\mathsf{XP}$ algorithm for the problem when parameterized by the width of the partial order. Furthermore, we show that $\unicode{x2013}$ under the assumption of the Exponential Time Hypothesis $\unicode{x2013}$ the running time of this algorithm is asymptotically optimal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18645v1</guid>
      <category>cs.DM</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jesse Beisegel, Ekkehard K\"ohler, Fabienne Ratajczak, Robert Scheffler, Martin Strehler</dc:creator>
    </item>
    <item>
      <title>Tensor cumulants for statistical inference on invariant distributions</title>
      <link>https://arxiv.org/abs/2404.18735</link>
      <description>arXiv:2404.18735v1 Announce Type: cross 
Abstract: Many problems in high-dimensional statistics appear to have a statistical-computational gap: a range of values of the signal-to-noise ratio where inference is information-theoretically possible, but (conjecturally) computationally intractable. A canonical such problem is Tensor PCA, where we observe a tensor $Y$ consisting of a rank-one signal plus Gaussian noise. Multiple lines of work suggest that Tensor PCA becomes computationally hard at a critical value of the signal's magnitude. In particular, below this transition, no low-degree polynomial algorithm can detect the signal with high probability; conversely, various spectral algorithms are known to succeed above this transition. We unify and extend this work by considering tensor networks, orthogonally invariant polynomials where multiple copies of $Y$ are "contracted" to produce scalars, vectors, matrices, or other tensors. We define a new set of objects, tensor cumulants, which provide an explicit, near-orthogonal basis for invariant polynomials of a given degree. This basis lets us unify and strengthen previous results on low-degree hardness, giving a combinatorial explanation of the hardness transition and of a continuum of subexponential-time algorithms that work below it, and proving tight lower bounds against low-degree polynomials for recovering rather than just detecting the signal. It also lets us analyze a new problem of distinguishing between different tensor ensembles, such as Wigner and Wishart tensors, establishing a sharp computational threshold and giving evidence of a new statistical-computational gap in the Central Limit Theorem for random tensors. Finally, we believe these cumulants are valuable mathematical objects in their own right: they generalize the free cumulants of free probability theory from matrices to tensors, and share many of their properties, including additivity under additive free convolution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18735v1</guid>
      <category>math.ST</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dmitriy Kunisky, Cristopher Moore, Alexander S. Wein</dc:creator>
    </item>
    <item>
      <title>Learning Mixtures of Gaussians Using Diffusion Models</title>
      <link>https://arxiv.org/abs/2404.18869</link>
      <description>arXiv:2404.18869v1 Announce Type: cross 
Abstract: We give a new algorithm for learning mixtures of $k$ Gaussians (with identity covariance in $\mathbb{R}^n$) to TV error $\varepsilon$, with quasi-polynomial ($O(n^{\text{poly log}\left(\frac{n+k}{\varepsilon}\right)})$) time and sample complexity, under a minimum weight assumption. Unlike previous approaches, most of which are algebraic in nature, our approach is analytic and relies on the framework of diffusion models. Diffusion models are a modern paradigm for generative modeling, which typically rely on learning the score function (gradient log-pdf) along a process transforming a pure noise distribution, in our case a Gaussian, to the data distribution. Despite their dazzling performance in tasks such as image generation, there are few end-to-end theoretical guarantees that they can efficiently learn nontrivial families of distributions; we give some of the first such guarantees. We proceed by deriving higher-order Gaussian noise sensitivity bounds for the score functions for a Gaussian mixture to show that that they can be inductively learned using piecewise polynomial regression (up to poly-logarithmic degree), and combine this with known convergence results for diffusion models. Our results extend to continuous mixtures of Gaussians where the mixing distribution is supported on a union of $k$ balls of constant radius. In particular, this applies to the case of Gaussian convolutions of distributions on low-dimensional manifolds, or more generally sets with small covering number.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18869v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Khashayar Gatmiry, Jonathan Kelner, Holden Lee</dc:creator>
    </item>
    <item>
      <title>On classes of bounded tree rank, their interpretations, and efficient sparsification</title>
      <link>https://arxiv.org/abs/2404.18904</link>
      <description>arXiv:2404.18904v1 Announce Type: cross 
Abstract: Graph classes of bounded tree rank were introduced recently in the context of the model checking problem for first-order logic of graphs. These graph classes are a common generalization of graph classes of bounded degree and bounded treedepth, and they are a special case of graph classes of bounded expansion. We introduce a notion of decomposition for these classes and show that these decompositions can be efficiently computed. Also, a natural extension of our decomposition leads to a new characterization and decomposition for graph classes of bounded expansion (and an efficient algorithm computing this decomposition).
  We then focus on interpretations of graph classes of bounded tree rank. We give a characterization of graph classes interpretable in graph classes of tree rank $2$. Importantly, our characterization leads to an efficient sparsification procedure: For any graph class $C$ interpretable in a efficiently bounded graph class of tree rank at most $2$, there is a polynomial time algorithm that to any $G \in C$ computes a (sparse) graph $H$ from a fixed graph class of tree rank at most $2$ such that $G = I(H)$ for a fixed interpretation $I$. To the best of our knowledge, this is the first efficient "interpretation reversal" result that generalizes the result of Gajarsk\'y et al. [LICS 2016], who showed an analogous result for graph classes interpretable in classes of graphs of bounded degree.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18904v1</guid>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>cs.LO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jakub Gajarsk\'y, Rose McCarty</dc:creator>
    </item>
    <item>
      <title>New Tradeoffs for Decremental Approximate All-Pairs Shortest Paths</title>
      <link>https://arxiv.org/abs/2211.01152</link>
      <description>arXiv:2211.01152v4 Announce Type: replace 
Abstract: We provide new tradeoffs between approximation and running time for the decremental all-pairs shortest paths (APSP) problem. For undirected graphs with $m$ edges and $n$ nodes undergoing edge deletions, we provide four new approximate decremental APSP algorithms, two for weighted and two for unweighted graphs. Our first result is $(2+ \epsilon)$-APSP with total update time $\tilde{O}(m^{1/2}n^{3/2})$ (when $m= n^{1+c}$ for any constant $0&lt;c&lt;1$). Prior to our work the fastest algorithm for weighted graphs with approximation at most $3$ had total $\tilde O(mn)$ update time for $(1+\epsilon)$-APSP [Bernstein, SICOMP 2016]. Our second result is $(2+\epsilon, W_{u,v})$-APSP with total update time $\tilde{O}(nm^{3/4})$, where the second term is an additive stretch with respect to $W_{u,v}$, the maximum weight on the shortest path from $u$ to $v$.
  Our third result is $(2+ \epsilon)$-APSP for unweighted graphs in $\tilde O(m^{7/4})$ update time, which for sparse graphs ($m=o(n^{8/7})$) is the first subquadratic $(2+\epsilon)$-approximation. Our last result for unweighted graphs is $(1+\epsilon, 2(k-1))$-APSP, for $k \geq 2 $, with $\tilde{O}(n^{2-1/k}m^{1/k})$ total update time (when $m=n^{1+c}$ for any constant $c &gt;0$). For comparison, in the special case of $(1+\epsilon, 2)$-approximation, this improves over the state-of-the-art algorithm by [Henzinger, Krinninger, Nanongkai, SICOMP 2016] with total update time of $\tilde{O}(n^{2.5})$. All of our results are randomized, work against an oblivious adversary, and have constant query time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.01152v4</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michal Dory, Sebastian Forster, Yasamin Nazari, Tijn de Vos</dc:creator>
    </item>
    <item>
      <title>Sublinear Algorithms for TSP via Path Covers</title>
      <link>https://arxiv.org/abs/2301.05350</link>
      <description>arXiv:2301.05350v2 Announce Type: replace 
Abstract: We study sublinear time algorithms for the traveling salesman problem (TSP). First, we focus on the closely related {\em maximum path cover} problem, which asks for a collection of vertex disjoint paths that include the maximum number of edges. We show that for any fixed $\epsilon &gt; 0$, there is an algorithm that $(1/2 - \epsilon)$-approximates the maximum path cover size of an $n$-vertex graph in $\widetilde{O}(n)$ time. This improves upon a $(3/8-\epsilon)$-approximate $\widetilde{O}(n \sqrt{n})$-time algorithm of Chen, Kannan, and Khanna [ICALP'20].
  Equipped with our path cover algorithm, we give an $\widetilde{O}(n)$ time algorithm that estimates the cost of $(1,2)$-TSP within a factor of $(1.5+\epsilon)$ which is an improvement over a folklore $(1.75 + \epsilon)$-approximate $\widetilde{O}(n)$-time algorithm, as well as a $(1.625+\epsilon)$-approximate $\widetilde{O}(n\sqrt{n})$-time algorithm of [CHK ICALP'20]. For graphic TSP, we present an $\widetilde{O}(n)$ algorithm that estimates the cost of graphic TSP within a factor of $1.83$ which is an improvement over a $1.92$-approximate $\widetilde{O}(n)$ time algorithm due to [CHK ICALP'20, Behnezhad FOCS'21]. We show that the approximation can be further improved to $1.66$ using $n^{2-\Omega(1)}$ time.
  All of our $\widetilde{O}(n)$ time algorithms are information-theoretically time-optimal up to poly log n factors. Additionally, we show that our approximation guarantees for path cover and $(1,2)$-TSP hit a natural barrier: We show better approximations require better sublinear time algorithms for the well-studied maximum matching problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.05350v2</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Soheil Behnezhad, Mohammad Roghani, Aviad Rubinstein, Amin Saberi</dc:creator>
    </item>
    <item>
      <title>Dynamic $(1+\epsilon)$-Approximate Matching Size in Truly Sublinear Update Time</title>
      <link>https://arxiv.org/abs/2302.05030</link>
      <description>arXiv:2302.05030v3 Announce Type: replace 
Abstract: We show a fully dynamic algorithm for maintaining $(1+\epsilon)$-approximate \emph{size} of maximum matching of the graph with $n$ vertices and $m$ edges using $m^{0.5-\Omega_{\epsilon}(1)}$ update time. This is the first polynomial improvement over the long-standing $O(n)$ update time, which can be trivially obtained by periodic recomputation. Thus, we resolve the value version of a major open question of the dynamic graph algorithms literature (see, e.g., [Gupta and Peng FOCS'13], [Bernstein and Stein SODA'16],[Behnezhad and Khanna SODA'22]).
  Our key technical component is the first sublinear algorithm for $(1,\epsilon n)$-approximate maximum matching with sublinear running time on dense graphs. All previous algorithms suffered a multiplicative approximation factor of at least $1.499$ or assumed that the graph has a very small maximum degree.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.05030v3</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sayan Bhattacharya, Peter Kiss, Thatchaphol Saranurak</dc:creator>
    </item>
    <item>
      <title>List Update with Delays or Time Windows</title>
      <link>https://arxiv.org/abs/2304.06565</link>
      <description>arXiv:2304.06565v2 Announce Type: replace 
Abstract: We consider the problem of List Update, one of the most fundamental problems in online algorithms. We are given a list of elements and requests for these elements that arrive over time. Our goal is to serve these requests, at a cost equivalent to their position in the list, with the option of moving them towards the head of the list. Sleator and Tarjan introduced the famous "Move to Front" algorithm (wherein any requested element is immediately moved to the head of the list) and showed that it is 2-competitive. While this bound is excellent, the absolute cost of the algorithm's solution may be very large (e.g., requesting the last half elements of the list would result in a solution cost that is quadratic in the length of the list). Thus, we consider the more general problem wherein every request arrives with a deadline and must be served, not immediately, but rather before the deadline. We further allow the algorithm to serve multiple requests simultaneously. We denote this problem as List Update with Time Windows. While this generalization benefits from lower solution costs, it requires new types of algorithms. In particular, for the simple example of requesting the last half elements of the list with overlapping time windows, Move-to-Front fails. We show an O(1) competitive algorithm. The algorithm is natural but the analysis is a bit complicated and a novel potential function is required. Thereafter we consider the more general problem of List Update with Delays in which the deadlines are replaced with arbitrary delay functions. This problem includes as a special case the prize collecting version in which a request might not be served (up to some deadline) and instead suffers an arbitrary given penalty. Here we also establish an O(1) competitive algorithm for general delays. The algorithm for the delay version is more complex and its analysis is significantly more involved.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.06565v2</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yossi Azar, Shahar Lewkowicz, Danny Vainstein</dc:creator>
    </item>
    <item>
      <title>Enumeration Kernels of Polynomial Size for Cuts of Bounded Degree</title>
      <link>https://arxiv.org/abs/2308.01286</link>
      <description>arXiv:2308.01286v5 Announce Type: replace 
Abstract: Enumeration kernelization was first proposed by Creignou et al. [TOCS 2017] and was later refined by Golovach et al. [JCSS 2022] into two different variants: fully-polynomial enumeration kernelization and polynomial-delay enumeration kernelization. In this paper, we consider the DEGREE-d-CUT problem from the perspective of (polynomial-delay) enumeration kenrelization. Given an undirected graph G = (V, E), a cut F = (A, B) is a degree-d-cut of G if every $u \in A$ has at most d neighbors in B and every $v \in B$ has at most d neighbors in A. Checking the existence of a degree-d-cut in a graph is a well-known NP-hard problem and is well-studied in parameterized complexity [Algorithmica 2021, IWOCA 2021]. This problem also generalizes a well-studied problem MATCHING CUT (set d = 1) that has been a central problem in the literature of polynomial-delay enumeration kernelization. In this paper, we study three different enumeration variants of this problem, ENUM DEGREE-d-CUT, ENUM MIN-DEGREE-d-CUT and ENUM MAX-DEGREE-d-CUT that intends to enumerate all the d-cuts, all the minimal d-cuts and all the maximal degree-d-cuts respectively. We consider various structural parameters of the input and for every fixed $d \geq 1$, we provide polynomial-delay enumeration kernelizations of polynomial size for ENUM DEGREE-d-CUT and ENUM MAX-DEGREE-d-CUT and fully-polynomial enumeration kernels of polynomial size for ENUM MIN-DEGREE-d-CUT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.01286v5</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Diptapriyo Majumdar</dc:creator>
    </item>
    <item>
      <title>A Nearly Quadratic-Time FPTAS for Knapsack</title>
      <link>https://arxiv.org/abs/2308.07821</link>
      <description>arXiv:2308.07821v2 Announce Type: replace 
Abstract: We investigate polynomial-time approximation schemes for the classic 0-1 knapsack problem. The previous algorithm by Deng, Jin, and Mao (SODA'23) has approximation factor $1 + \eps$ with running time $\widetilde{O}(n + \frac{1}{\eps^{2.2}})$. There is a lower Bound of $(n + \frac{1}{\eps})^{2-o(1)}$ conditioned on the hypothesis that $(\min, +)$ has no truly subquadratic algorithm. We close the gap by proposing an approximation scheme that runs in $\widetilde{O}(n + \frac{1}{\eps^2})$ time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.07821v2</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lin Chen, Jiayi Lian, Yuchen Mao, Guochuan Zhang</dc:creator>
    </item>
    <item>
      <title>Computing Minimal Absent Words and Extended Bispecial Factors with CDAWG Space</title>
      <link>https://arxiv.org/abs/2402.18090</link>
      <description>arXiv:2402.18090v2 Announce Type: replace 
Abstract: A string $w$ is said to be a minimal absent word (MAW) for a string $S$ if $w$ does not occur in $S$ and any proper substring of $w$ occurs in $S$. We focus on non-trivial MAWs which are of length at least 2. Finding such non-trivial MAWs for a given string is motivated for applications in bioinformatics and data compression. Fujishige et al. [TCS 2023] proposed a data structure of size $\Theta(n)$ that can output the set $\mathsf{MAW}(S)$ of all MAWs for a given string $S$ of length $n$ in $O(n + |\mathsf{MAW}(S)|)$ time, based on the directed acyclic word graph (DAWG). In this paper, we present a more space efficient data structure based on the compact DAWG (CDAWG), which can output $\mathsf{MAW}(S)$ in $O(|\mathsf{MAW}(S)|)$ time with $O(\mathsf{e}_\min)$ space, where $\mathsf{e}_\min$ denotes the minimum of the sizes of the CDAWGs for $S$ and for its reversal $S^R$. For any strings of length $n$, it holds that $\mathsf{e}_\min &lt; 2n$, and for highly repetitive strings $\mathsf{e}_\min$ can be sublinear (up to logarithmic) in $n$. We also show that MAWs and their generalization minimal rare words have close relationships with extended bispecial factors, via the CDAWG.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.18090v2</guid>
      <category>cs.DS</category>
      <category>cs.FL</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shunsuke Inenaga, Takuya Mieno, Hiroki Arimura, Mitsuru Funakoshi, Yuta Fujishige</dc:creator>
    </item>
    <item>
      <title>Computing the $D$-base and $D$-relation in finite closure systems</title>
      <link>https://arxiv.org/abs/2404.07037</link>
      <description>arXiv:2404.07037v2 Announce Type: replace 
Abstract: Implicational bases (IBs) are a common representation of finite closure systems and lattices, along with meet-irreducible elements. They appear in a wide variety of fields ranging from logic and databases to Knowledge Space Theory. Different IBs can represent the same closure system. Therefore, several IBs have been studied, such as the canonical and canonical direct bases. In this paper, we investigate the $D$-base, a refinement of the canonical direct base. It is connected with the $D$-relation, an essential tool in the study of free lattices. The $D$-base demonstrates desirable algorithmic properties, and together with the $D$-relation, it conveys essential properties of the underlying closure system. Hence, computing the $D$-base and the $D$-relation of a closure system from another representation is crucial to enjoy its benefits. However, complexity results for this task are lacking. In this paper, we give algorithms and hardness results for the computation of the $D$-base and $D$-relation. Specifically, we establish the $NP$-completeness of finding the $D$-relation from an arbitrary IB; we give an output-quasi-polynomial time algorithm to compute the $D$-base from meet-irreducible elements; and we obtain a polynomial-delay algorithm computing the $D$-base from an arbitrary IB. These results complete the picture regarding the complexity of identifying the $D$-base and $D$-relation of a closure system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07037v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>math.CO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kira Adaricheva, Lhouari Nourine, Simon Vilmin</dc:creator>
    </item>
    <item>
      <title>Efficient and Near-Optimal Noise Generation for Streaming Differential Privacy</title>
      <link>https://arxiv.org/abs/2404.16706</link>
      <description>arXiv:2404.16706v2 Announce Type: replace 
Abstract: In the task of differentially private (DP) continual counting, we receive a stream of increments and our goal is to output an approximate running total of these increments, without revealing too much about any specific increment. Despite its simplicity, differentially private continual counting has attracted significant attention both in theory and in practice. Existing algorithms for differentially private continual counting are either inefficient in terms of their space usage or add an excessive amount of noise, inducing suboptimal utility.
  The most practical DP continual counting algorithms add carefully correlated Gaussian noise to the values. The task of choosing the covariance for this noise can be expressed in terms of factoring the lower-triangular matrix of ones (which computes prefix sums). We present two approaches from this class (for different parameter regimes) that achieve near-optimal utility for DP continual counting and only require logarithmic or polylogarithmic space (and time).
  Our first approach is based on a space-efficient streaming matrix multiplication algorithm for a class of Toeplitz matrices. We show that to instantiate this algorithm for DP continual counting, it is sufficient to find a low-degree rational function that approximates the square root on a circle in the complex plane. We then apply and extend tools from approximation theory to achieve this. We also derive efficient closed-forms for the objective function for arbitrarily many steps, and show direct numerical optimization yields a highly practical solution to the problem. Our second approach combines our first approach with a recursive construction similar to the binary tree mechanism.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16706v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Krishnamurthy Dvijotham, H. Brendan McMahan, Krishna Pillutla, Thomas Steinke, Abhradeep Thakurta</dc:creator>
    </item>
    <item>
      <title>$t$-sails and sparse hereditary classes of unbounded tree-width</title>
      <link>https://arxiv.org/abs/2302.04783</link>
      <description>arXiv:2302.04783v4 Announce Type: replace-cross 
Abstract: It has long been known that the following basic objects are obstructions to bounded tree-width: for arbitrarily large $t$, $(1)$ the complete graph $K_t$, $(2)$ the complete bipartite graph $K_{t,t}$, $(3)$ a subdivision of the $(t \times t)$-wall and $(4)$ the line graph of a subdivision of the $(t \times t)$-wall. We now add a further \emph{boundary object} to this list, a \emph{$t$-sail}.
  These results have been obtained by studying sparse hereditary \emph{path-star} graph classes, each of which consists of the finite induced subgraphs of a single infinite graph whose edges can be partitioned into a path (or forest of paths) with a forest of stars, characterised by an infinite word over a possibly infinite alphabet. We show that a path-star class whose infinite graph has an unbounded number of stars, each of which connects an unbounded number of times to the path, has unbounded tree-width. In addition, we show that such a class is not a subclass of the hereditary class of circle graphs.
  We identify a collection of \emph{nested} words with a recursive structure that exhibit interesting characteristics when used to define a path-star graph class. These graph classes do not contain any of the four basic obstructions but instead contain graphs that have large tree-width if and only if they contain arbitrarily large $t$-sails. We show that these classes are infinitely defined and, like classes of bounded degree or classes excluding a fixed minor, do not contain a minimal class of unbounded tree-width.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.04783v4</guid>
      <category>math.CO</category>
      <category>cs.DS</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Cocks</dc:creator>
    </item>
    <item>
      <title>Block-Diagonal Guided DBSCAN Clustering</title>
      <link>https://arxiv.org/abs/2404.01341</link>
      <description>arXiv:2404.01341v2 Announce Type: replace-cross 
Abstract: Cluster analysis plays a crucial role in database mining, and one of the most widely used algorithms in this field is DBSCAN. However, DBSCAN has several limitations, such as difficulty in handling high-dimensional large-scale data, sensitivity to input parameters, and lack of robustness in producing clustering results. This paper introduces an improved version of DBSCAN that leverages the block-diagonal property of the similarity graph to guide the clustering procedure of DBSCAN. The key idea is to construct a graph that measures the similarity between high-dimensional large-scale data points and has the potential to be transformed into a block-diagonal form through an unknown permutation, followed by a cluster-ordering procedure to generate the desired permutation. The clustering structure can be easily determined by identifying the diagonal blocks in the permuted graph. We propose a gradient descent-based method to solve the proposed problem. Additionally, we develop a DBSCAN-based points traversal algorithm that identifies clusters with high densities in the graph and generates an augmented ordering of clusters. The block-diagonal structure of the graph is then achieved through permutation based on the traversal order, providing a flexible foundation for both automatic and interactive cluster analysis. We introduce a split-and-refine algorithm to automatically search for all diagonal blocks in the permuted graph with theoretically optimal guarantees under specific cases. We extensively evaluate our proposed approach on twelve challenging real-world benchmark clustering datasets and demonstrate its superior performance compared to the state-of-the-art clustering method on every dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01341v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Weibing Zhao</dc:creator>
    </item>
  </channel>
</rss>
