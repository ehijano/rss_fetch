<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SI</link>
    <description>cs.SI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 08 Apr 2025 03:06:35 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Mapping Technological Futures: Anticipatory Discourse Through Text Mining</title>
      <link>https://arxiv.org/abs/2504.02853</link>
      <description>arXiv:2504.02853v1 Announce Type: new 
Abstract: The volatility and unpredictability of emerging technologies, such as artificial intelligence (AI), generate significant uncertainty, which is widely discussed on social media. This study examines anticipatory discourse surrounding technological futures by analysing 1.5 million posts from 400 key opinion leaders (KOLs) published on the X platform (from 2021 to 2023). Using advanced text mining techniques, including BERTopic modelling, sentiment, emotion, and attitude analyses, the research identifies 100 distinct topics reflecting anticipated tech-driven futures. Our findings emphasize the dual role of KOLs in framing \textit{present futures} -- optimistic visions of transformative technologies like AI and IoT -- and influencing \textit{future presents}, where these projections shape contemporary societal and geopolitical debates. Positive emotions such as Hope dominate, outweighing Anxiety, particularly in topics like ``Machine Learning, Data Science, and Deep Learning,'' while discussions around ``Climate Change'' and ``War, Ukraine, and Trump People'' elicit \textit{Anxiety}. By framing technologies as solutions to societal challenges, KOLs act as mediators of societal narratives, bridging imagined futures and current realities. These insights underscore their pivotal role in directing public attention with emerging technologies during periods of heightened uncertainty, advancing our understanding of anticipatory discourse in technology-mediated contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02853v1</guid>
      <category>cs.SI</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maciej Skorski, Alina Landowska, Krzysztof Rajda</dc:creator>
    </item>
    <item>
      <title>A Dataset of the Representatives Elected in France During the Fifth Republic</title>
      <link>https://arxiv.org/abs/2504.02869</link>
      <description>arXiv:2504.02869v1 Announce Type: new 
Abstract: The electoral system is a cornerstone of democracy, shaping the structure of political competition, representation, and accountability. In the case of France, it is difficult to access data describing elected representatives, though, as they are scattered across a number of sources, including public institutions, but also academic and individual efforts. This article presents a unified relational database that aims at tackling this issue by gathering information regarding representatives elected in France over the whole Fifth Republic (1958-present). This database constitutes an unprecedented resource for analyzing the evolution of political representation in France, exploring trends in party system dynamics, gender equality, and the professionalization of politics. By providing a longitudinal view of French elected representatives, the database facilitates research on the institutional stability of the Fifth Republic, offering insights into the factors of political change.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02869v1</guid>
      <category>cs.SI</category>
      <category>cs.CY</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>No\'emie F\'evrat (FR 3621, JPEG), Vincent Labatut (LIA), \'Emilie Volpi (FR 3621), Guillaume Marrel (JPEG)</dc:creator>
    </item>
    <item>
      <title>Embedding Method for Knowledge Graph with Densely Defined Ontology</title>
      <link>https://arxiv.org/abs/2504.02889</link>
      <description>arXiv:2504.02889v1 Announce Type: new 
Abstract: Knowledge graph embedding (KGE) is a technique that enhances knowledge graphs by addressing incompleteness and improving knowledge retrieval. A limitation of the existing KGE models is their underutilization of ontologies, specifically the relationships between properties. This study proposes a KGE model, TransU, designed for knowledge graphs with well-defined ontologies that incorporate relationships between properties. The model treats properties as a subset of entities, enabling a unified representation. We present experimental results using a standard dataset and a practical dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02889v1</guid>
      <category>cs.SI</category>
      <category>cs.AI</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Takanori Ugai</dc:creator>
    </item>
    <item>
      <title>Graph Network Modeling Techniques for Visualizing Human Mobility Patterns</title>
      <link>https://arxiv.org/abs/2504.03119</link>
      <description>arXiv:2504.03119v1 Announce Type: new 
Abstract: Human mobility analysis at urban-scale requires models to represent the complex nature of human movements, which in turn are affected by accessibility to nearby points of interest, underlying socioeconomic factors of a place, and local transport choices for people living in a geographic region. In this work, we represent human mobility and the associated flow of movements as a grapyh. Graph-based approaches for mobility analysis are still in their early stages of adoption and are actively being researched. The challenges of graph-based mobility analysis are multifaceted - the lack of sufficiently high-quality data to represent flows at high spatial and teporal resolution whereas, limited computational resources to translate large voluments of mobility data into a network structure, and scaling issues inherent in graph models etc. The current study develops a methodology by embedding graphs into a continuous space, which alleviates issues related to fast graph matching, graph time-series modeling, and visualization of mobility dynamics. Through experiments, we demonstrate how mobility data collected from taxicab trajectories could be transformed into network structures and patterns of mobility flow changes, and can be used for downstream tasks reporting approx 40% decrease in error on average in matched graphs vs unmatched ones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03119v1</guid>
      <category>cs.SI</category>
      <category>cs.AI</category>
      <category>stat.ML</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sinjini Mitra, Anuj Srivastava, Avipsa Roy, Pavan Turaga</dc:creator>
    </item>
    <item>
      <title>The epistemic dimension of algorithmic fairness: assessing its impact in innovation diffusion and fair policy making</title>
      <link>https://arxiv.org/abs/2504.02856</link>
      <description>arXiv:2504.02856v1 Announce Type: cross 
Abstract: Algorithmic fairness is an expanding field that addresses a range of discrimination issues associated with algorithmic processes. However, most works in the literature focus on analyzing it only from an ethical perspective, focusing on moral principles and values that should be considered in the design and evaluation of algorithms, while disregarding the epistemic dimension related to knowledge transmission and validation. However, this aspect of algorithmic fairness should also be included in the debate, as it is crucial to introduce a specific type of harm: an individual may be systematically excluded from the dissemination of knowledge due to the attribution of a credibility deficit/excess. In this work, we specifically focus on characterizing and analyzing the impact of this credibility deficit or excess on the diffusion of innovations on a societal scale, a phenomenon driven by individual attitudes and social interactions, and also by the strength of mutual connections. Indeed, discrimination might shape the latter, ultimately modifying how innovations spread within the network. In this light, to incorporate, also from a formal point of view, the epistemic dimension in innovation diffusion models becomes paramount, especially if these models are intended to support fair policy design. For these reasons, we formalize the epistemic properties of a social environment, by extending the well-established Linear Threshold Model (LTM) in an epistemic direction to show the impact of epistemic biases in innovation diffusion. Focusing on the impact of epistemic bias in both open-loop and closed-loop scenarios featuring optimal fostering policies, our results shed light on the pivotal role the epistemic dimension might have in the debate of algorithmic fairness in decision-making.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02856v1</guid>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eugenia Villa, Camilla Quaresmini, Valentina Breschi, Viola Schiaffonati, Mara Tanelli</dc:creator>
    </item>
    <item>
      <title>GS_DravidianLangTech@2025: Women Targeted Abusive Texts Detection on Social Media</title>
      <link>https://arxiv.org/abs/2504.02863</link>
      <description>arXiv:2504.02863v1 Announce Type: cross 
Abstract: The increasing misuse of social media has become a concern; however, technological solutions are being developed to moderate its content effectively. This paper focuses on detecting abusive texts targeting women on social media platforms. Abusive speech refers to communication intended to harm or incite hatred against vulnerable individuals or groups. Specifically, this study aims to identify abusive language directed toward women. To achieve this, we utilized logistic regression and BERT as base models to train datasets sourced from DravidianLangTech@2025 for Tamil and Malayalam languages. The models were evaluated on test datasets, resulting in a 0.729 macro F1 score for BERT and 0.6279 for logistic regression in Tamil and Malayalam, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02863v1</guid>
      <category>cs.CL</category>
      <category>cs.SI</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Girma Yohannis Bade, Zahra Ahani, Olga Kolesnikova, Jos\'e Luis Oropeza, Grigori Sidorov</dc:creator>
    </item>
    <item>
      <title>On Word-of-Mouth and Private-Prior Sequential Social Learning</title>
      <link>https://arxiv.org/abs/2504.02913</link>
      <description>arXiv:2504.02913v2 Announce Type: cross 
Abstract: Social learning provides a fundamental framework in economics and social sciences for studying interactions among rational agents who observe each other's actions but lack direct access to individual beliefs. This paper investigates a specific social learning paradigm known as Word-of-Mouth (WoM), where a series of agents seeks to estimate the state of a dynamical system. The first agent receives noisy measurements of the state, while each subsequent agent relies solely on a degraded version of her predecessor's estimate. A defining feature of WoM is that the final agent's belief is publicly broadcast and adopted by all agents, in place of their own. We analyze this setting both theoretically and through numerical simulations, showing that some agents benefit from using the public belief broadcast by the last agent, while others suffer from performance deterioration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02913v2</guid>
      <category>cs.MA</category>
      <category>cs.SI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrea Da Col, Cristian R. Rojas, Vikram Krishnamurthy</dc:creator>
    </item>
    <item>
      <title>TikTok StitchGraph: Characterizing communication patterns on TikTok through a collection of interaction networks</title>
      <link>https://arxiv.org/abs/2502.18661</link>
      <description>arXiv:2502.18661v3 Announce Type: replace 
Abstract: We present TikTok StitchGraph: a collection of 36 graphs based on TikTok stitches. With its rapid growth and widespread popularity, TikTok presents a compelling platform for study, yet given its video-first nature the network structure of the conversations that it hosts remains largely unexplored. Leveraging its recently released APIs, in combination with web scraping, we construct graphs detailing stitch relations from both a video- and user-centric perspective. Specifically, we focus on user multi-digraphs, with vertices representing users and edges representing directed stitch relations. From the user graphs, we characterize common communication patterns of the stitch using frequent subgraph mining, finding a preference for stars and star-like structures, an aversion towards cyclic structures, and directional disposition favoring in- and out-stars over mixed-direction structures. These structures are augmented with sentiment labels in the form of edge attributes. We then use these subgraphs for graph-level embeddings together with Graph2Vec, we show no clear distinction between topologies for different hashtag topic categories. Lastly, we compare our StitchGraphs to Twitter reply networks and show that a remakable similarity between the conversation networks on the two platforms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.18661v3</guid>
      <category>cs.SI</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mads H{\o}genhaug, Marcus Friis, Morten Pedersen, Luca Rossi</dc:creator>
    </item>
    <item>
      <title>Generalizing Hate Speech Detection Using Multi-Task Learning: A Case Study of Political Public Figures</title>
      <link>https://arxiv.org/abs/2208.10598</link>
      <description>arXiv:2208.10598v2 Announce Type: replace-cross 
Abstract: Automatic identification of hateful and abusive content is vital in combating the spread of harmful online content and its damaging effects. Most existing works evaluate models by examining the generalization error on train-test splits on hate speech datasets. These datasets often differ in their definitions and labeling criteria, leading to poor generalization performance when predicting across new domains and datasets. This work proposes a new Multi-task Learning (MTL) pipeline that trains simultaneously across multiple hate speech datasets to construct a more encompassing classification model. Using a dataset-level leave-one-out evaluation (designating a dataset for testing and jointly training on all others), we trial the MTL detection on new, previously unseen datasets. Our results consistently outperform a large sample of existing work. We show strong results when examining the generalization error in train-test splits and substantial improvements when predicting on previously unseen datasets. Furthermore, we assemble a novel dataset, dubbed PubFigs, focusing on the problematic speech of American Public Political Figures. We crowdsource-label using Amazon MTurk more than $20,000$ tweets and machine-label problematic speech in all the $305,235$ tweets in PubFigs. We find that the abusive and hate tweeting mainly originates from right-leaning figures and relates to six topics, including Islam, women, ethnicity, and immigrants. We show that MTL builds embeddings that can simultaneously separate abusive from hate speech, and identify its topics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.10598v2</guid>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.csl.2024.101690</arxiv:DOI>
      <arxiv:journal_reference>Computer Speech &amp; Language 89 (2025) 101690</arxiv:journal_reference>
      <dc:creator>Lanqin Yuan, Marian-Andrei Rizoiu</dc:creator>
    </item>
    <item>
      <title>LLMs Prompted for Graphs: Hallucinations and Generative Capabilities</title>
      <link>https://arxiv.org/abs/2409.00159</link>
      <description>arXiv:2409.00159v3 Announce Type: replace-cross 
Abstract: Large Language Models (LLMs) are nowadays prompted for a wide variety of tasks. In this article, we investigate their ability in reciting and generating graphs. We first study the ability of LLMs to regurgitate well known graphs from the literature (e.g. Karate club or the graph atlas)4. Secondly, we question the generative capabilities of LLMs by asking for Erdos-Renyi random graphs. As opposed to the possibility that they could memorize some Erdos-Renyi graphs included in their scraped training set, this second investigation aims at studying a possible emergent property of LLMs. For both tasks, we propose a metric to assess their errors with the lens of hallucination (i.e. incorrect information returned as facts). We most notably find that the amplitude of graph hallucinations can characterize the superiority of some LLMs. Indeed, for the recitation task, we observe that graph hallucinations correlate with the Hallucination Leaderboard, a hallucination rank that leverages 10, 000 times more prompts to obtain its ranking. For the generation task, we find surprisingly good and reproducible results in most of LLMs. We believe this to constitute a starting point for more in-depth studies of this emergent capability and a challenging benchmark for their improvements. Altogether, these two aspects of LLMs capabilities bridge a gap between the network science and machine learning communities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00159v3</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.SI</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Gurvan Richardeau, Samy Chali, Erwan Le Merrer, Camilla Penzo, Gilles Tredan</dc:creator>
    </item>
    <item>
      <title>A Large-Scale Simulation on Large Language Models for Decision-Making in Political Science</title>
      <link>https://arxiv.org/abs/2412.15291</link>
      <description>arXiv:2412.15291v3 Announce Type: replace-cross 
Abstract: While LLMs have demonstrated remarkable capabilities in text generation and reasoning, their ability to simulate human decision-making -- particularly in political contexts -- remains an open question. However, modeling voter behavior presents unique challenges due to limited voter-level data, evolving political landscapes, and the complexity of human reasoning. In this study, we develop a theory-driven, multi-step reasoning framework that integrates demographic, temporal and ideological factors to simulate voter decision-making at scale. Using synthetic personas calibrated to real-world voter data, we conduct large-scale simulations of recent U.S. presidential elections. Our method significantly improves simulation accuracy while mitigating model biases. We examine its robustness by comparing performance across different LLMs. We further investigate the challenges and constraints that arise from LLM-based political simulations. Our work provides both a scalable framework for modeling political decision-making behavior and insights into the promise and limitations of using LLMs in political science research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.15291v3</guid>
      <category>cs.CL</category>
      <category>cs.SI</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chenxiao Yu, Jinyi Ye, Yuangang Li, Zhaotian Weng, Zheng Li, Emilio Ferrara, Xiyang Hu, Yue Zhao</dc:creator>
    </item>
    <item>
      <title>Controlled Social Learning: Altruism vs. Bias</title>
      <link>https://arxiv.org/abs/2504.02648</link>
      <description>arXiv:2504.02648v2 Announce Type: replace-cross 
Abstract: We introduce a model of controlled sequential social learning in which a planner may pay a cost to adjust the private information structure of agents. The planner may seek to induce correct actions that are consistent with an unknown true state of the world (altruistic planner) or to induce a specific action the planner prefers (biased planner). Our framework presents a new optimization problem for social learning that combines dynamic programming with decentralized action choices and Bayesian belief updates. This sheds light on practical policy questions, such as how the socially optimal level of ad personalization changes according to current beliefs or how a political campaign may selectively illuminate or obfuscate the winning potential of its candidate among voters. We then prove the convexity of the value function and characterize the optimal policies of altruistic and biased planners, which attain desired tradeoffs between the costs they incur and the payoffs they earn from the choices they induce in the agents. Even for a planner who has equivalent knowledge to an individual, cannot lie or cherry-pick information, and is fully observable, we demonstrate that it is possible to dramatically influence social welfare in both positive and negative directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02648v2</guid>
      <category>eess.SY</category>
      <category>cs.GT</category>
      <category>cs.SI</category>
      <category>cs.SY</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Raghu Arghal, Kevin He, Shirin Saeedi Bidokhti, Saswati Sarkar</dc:creator>
    </item>
  </channel>
</rss>
