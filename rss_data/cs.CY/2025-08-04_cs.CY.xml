<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CY updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CY</link>
    <description>cs.CY updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CY" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 05 Aug 2025 02:30:21 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Data Bias in Human Mobility is a Universal Phenomenon but is Highly Location-specific</title>
      <link>https://arxiv.org/abs/2508.00149</link>
      <description>arXiv:2508.00149v1 Announce Type: new 
Abstract: Large-scale human mobility datasets play increasingly critical roles in many algorithmic systems, business processes and policy decisions. Unfortunately there has been little focus on understanding bias and other fundamental shortcomings of the datasets and how they impact downstream analyses and prediction tasks. In this work, we study `data production', quantifying not only whether individuals are represented in big digital datasets, but also how they are represented in terms of how much data they produce. We study GPS mobility data collected from anonymized smartphones for ten major US cities and find that data points can be more unequally distributed between users than wealth. We build models to predict the number of data points we can expect to be produced by the composition of demographic groups living in census tracts, and find strong effects of wealth, ethnicity, and education on data production. While we find that bias is a universal phenomenon, occurring in all cities, we further find that each city suffers from its own manifestation of it, and that location-specific models are required to model bias for each city. This work raises serious questions about general approaches to debias human mobility data and urges further research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00149v1</guid>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <category>physics.soc-ph</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Katinka den Nijs, Elisa Omodei, Vedran Sekara</dc:creator>
    </item>
    <item>
      <title>Green Computing: The Ultimate Carbon Destroyer for a Sustainable Future</title>
      <link>https://arxiv.org/abs/2508.00153</link>
      <description>arXiv:2508.00153v2 Announce Type: new 
Abstract: Green computing represents a critical pathway to decarbonize the digital economy while maintaining technological progress. This article examines how sustainable IT strategies including energy-efficient hardware, AI-optimized data centres, and circular e-waste systems can transform computing into a net carbon sink. Through analysis of industry best practices and emerging technologies like quantum computing and biodegradable electronics, we demonstrate achievable reductions of 40-60% in energy consumption without compromising performance. The study highlights three key findings: (1) current solutions already deliver both environmental and economic benefits, with typical payback periods of 3-5 years; (2) systemic barriers including cost premiums and policy fragmentation require coordinated action; and (3) next-generation innovations promise order-of-magnitude improvements in efficiency. We present a practical framework for stakeholders from corporations adopting renewable-powered cloud services to individuals extending device lifespans to accelerate the transition. The research underscores computing's unique potential as a climate solution through its rapid innovation cycles and measurable impacts, concluding that strategic investments in green IT today can yield disproportionate sustainability dividends across all sectors tomorrow. This work provides both a compelling case for urgent action and a clear roadmap to realize computing's potential as a powerful carbon destruction tool in the climate crisis era.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00153v2</guid>
      <category>cs.CY</category>
      <category>cs.SC</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Sayed Mahbub Hasan Amiri, Prasun Goswami, Md. Mainul Islam, Mohammad Shakhawat Hossen, Marzana Mithila, Naznin Akter</dc:creator>
    </item>
    <item>
      <title>J4CC, A Frame for Communication Control</title>
      <link>https://arxiv.org/abs/2508.00485</link>
      <description>arXiv:2508.00485v1 Announce Type: new 
Abstract: Politics increasingly faces conflicts that appear irreconcilable, where one party's requirements directly contradict those of another. We propose J4CC, a frame for mapping how four forces (Power, Capital, Morality, and Knowledge) influence rule-making. J4CC provides a jargon for analyzing rule-making conversations. Beyond ideas about framing (Lakoff 2004; Rein &amp; Sch\"on, 1996), it draws on ideas from legal theory (Fuller 1967), institutional economics (Coase 1937), anthropology (Douglas 1992), and AI (Lewis et al. 2020). While our ultimate goal is to develop a working and usable AI language model (actually a 'jargon model'), this article focuses for now on its conceptual foundation. We demonstrate J4CC's analytical power through three case studies that profile seemingly incompatible positions. First, of influential thinkers (Confucius, Friedman, Montesquieu, Popper, Goodfellow) and their environments. Then, of governance dynamics (in the US during the first 5 months of 2025). Finally, of two contrasting interpretations thereof (Klein-Taylor's (2025) "end of time fascism" versus Bobbitt's (2025) "constitutional degradation"). The studies confirm that J4CC can profile positions from incompatible governance philosophies without clogging communication channels, sometimes also by providing translation mechanisms. Rather than eliminating disagreements, the framework enables productive engagement by making explicit the underlying tensions that lead to institutional conflicts. Our case studies lead to the conclusion that J4CC in its current form is a usable instrument for analyzing failing political debate. We add in the appendix our position on the feasibility that the J4CC framework can develop its intended jargon through application in an AI language model trained on large numbers of negotiation records.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00485v1</guid>
      <category>cs.CY</category>
      <category>econ.TH</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aernout Schmidt, Kunbei Zhang</dc:creator>
    </item>
    <item>
      <title>Futures with Digital Minds: Expert Forecasts in 2025</title>
      <link>https://arxiv.org/abs/2508.00536</link>
      <description>arXiv:2508.00536v1 Announce Type: new 
Abstract: This report presents findings from an expert survey on digital minds takeoff scenarios. The survey was conducted in early 2025 with 67 experts in digital minds research, AI research, philosophy, forecasting, and related fields. Participants provided probabilistic forecasts and qualitative reasoning on the development, characteristics, and societal impact of digital minds, that is, computer systems capable of subjective experience. Experts assigned high probability to digital minds being possible in principle (median 90%) and being created this century (65% by 2100), with a non-negligible probability of emergence by 2030 (20%). Many anticipated rapid growth in digital mind welfare capacity, with collective welfare capacity potentially matching that of billions of humans within a decade after the creation of the first digital mind. Participants also expected widespread claims from digital minds regarding their consciousness and rights, and predicted substantial societal disagreement over their existence and moral interests. Views diverged on whether digital mind welfare will be net positive or negative. These findings provide evidence that bears on the extent to which preparing the world for the potential arrival of digital minds should be a priority across domains such as research and governance. However, these findings should be interpreted cautiously in light of the potential for systematic overrepresentation of experts who deem digital minds particularly likely or important.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00536v1</guid>
      <category>cs.CY</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lucius Caviola, Bradford Saad</dc:creator>
    </item>
    <item>
      <title>Towards Efficient Certification of Maritime Remote Operation Centers</title>
      <link>https://arxiv.org/abs/2508.00543</link>
      <description>arXiv:2508.00543v1 Announce Type: new 
Abstract: Additional automation being build into ships implies a shift of crew from ship to shore. However, automated ships still have to be monitored and, in some situations, controlled remotely. These tasks are carried out by human operators located in shore-based remote operation centers. In this work, we present a concept for a hazard database that supports the safeguarding and certification of such remote operation centers. The concept is based on a categorization of hazard sources which we derive from a generic functional architecture. A subsequent preliminary suitability analysis unveils which methods for hazard analysis and risk assessment can adequately fill this hazard database.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00543v1</guid>
      <category>cs.CY</category>
      <category>cs.RO</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christian Neurohr, Marcel Saager, Lina Putze, Jan-Patrick Osterloh, Karina Rothemann, Hilko Wiards, Eckard B\"ode, Axel Hahn</dc:creator>
    </item>
    <item>
      <title>Semiotic Complexity and Its Epistemological Implications for Modeling Culture</title>
      <link>https://arxiv.org/abs/2508.00095</link>
      <description>arXiv:2508.00095v1 Announce Type: cross 
Abstract: Greater theorizing of methods in the computational humanities is needed for epistemological and interpretive clarity, and therefore the maturation of the field. In this paper, we frame such modeling work as engaging in translation work from a cultural, linguistic domain into a computational, mathematical domain, and back again. Translators benefit from articulating the theory of their translation process, and so do computational humanists in their work -- to ensure internal consistency, avoid subtle yet consequential translation errors, and facilitate interpretive transparency. Our contribution in this paper is to lay out a particularly consequential dimension of the lack of theorizing and the sorts of translation errors that emerge in our modeling practices as a result. Along these lines we introduce the idea of semiotic complexity as the degree to which the meaning of some text may vary across interpretive lenses, and make the case that dominant modeling practices -- especially around evaluation -- commit a translation error by treating semiotically complex data as semiotically simple when it seems epistemologically convenient by conferring superficial clarity. We then lay out several recommendations for researchers to better account for these epistemological issues in their own work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00095v1</guid>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zachary K. Stine, James E. Deitrick</dc:creator>
    </item>
    <item>
      <title>Beyond Agreement: Rethinking Ground Truth in Educational AI Annotation</title>
      <link>https://arxiv.org/abs/2508.00143</link>
      <description>arXiv:2508.00143v1 Announce Type: cross 
Abstract: Humans can be notoriously imperfect evaluators. They are often biased, unreliable, and unfit to define "ground truth." Yet, given the surging need to produce large amounts of training data in educational applications using AI, traditional inter-rater reliability (IRR) metrics like Cohen's kappa remain central to validating labeled data. IRR remains a cornerstone of many machine learning pipelines for educational data. Take, for example, the classification of tutors' moves in dialogues or labeling open responses in machine-graded assessments. This position paper argues that overreliance on human IRR as a gatekeeper for annotation quality hampers progress in classifying data in ways that are valid and predictive in relation to improving learning. To address this issue, we highlight five examples of complementary evaluation methods, such as multi-label annotation schemes, expert-based approaches, and close-the-loop validity. We argue that these approaches are in a better position to produce training data and subsequent models that produce improved student learning and more actionable insights than IRR approaches alone. We also emphasize the importance of external validity, for example, by establishing a procedure of validating tutor moves and demonstrating that it works across many categories of tutor actions (e.g., providing hints). We call on the field to rethink annotation quality and ground truth--prioritizing validity and educational impact over consensus alone.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00143v1</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Danielle R. Thomas, Conrad Borchers, Kenneth R. Koedinger</dc:creator>
    </item>
    <item>
      <title>Model-Based Soft Maximization of Suitable Metrics of Long-Term Human Power</title>
      <link>https://arxiv.org/abs/2508.00159</link>
      <description>arXiv:2508.00159v1 Announce Type: cross 
Abstract: Power is a key concept in AI safety: power-seeking as an instrumental goal, sudden or gradual disempowerment of humans, power balance in human-AI interaction and international AI governance. At the same time, power as the ability to pursue diverse goals is essential for wellbeing.
  This paper explores the idea of promoting both safety and wellbeing by forcing AI agents explicitly to empower humans and to manage the power balance between humans and AI agents in a desirable way. Using a principled, partially axiomatic approach, we design a parametrizable and decomposable objective function that represents an inequality- and risk-averse long-term aggregate of human power. It takes into account humans' bounded rationality and social norms, and, crucially, considers a wide variety of possible human goals.
  We derive algorithms for computing that metric by backward induction or approximating it via a form of multi-agent reinforcement learning from a given world model. We exemplify the consequences of (softly) maximizing this metric in a variety of paradigmatic situations and describe what instrumental sub-goals it will likely imply. Our cautious assessment is that softly maximizing suitable aggregate metrics of human power might constitute a beneficial objective for agentic AI systems that is safer than direct utility-based objectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00159v1</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <category>econ.TH</category>
      <category>math.OC</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jobst Heitzig, Ram Potham</dc:creator>
    </item>
    <item>
      <title>Advancing Quantum Information Science Pre-College Education: The Case for Learning Sciences Collaboration</title>
      <link>https://arxiv.org/abs/2508.00668</link>
      <description>arXiv:2508.00668v1 Announce Type: cross 
Abstract: As quantum information science advances and the need for pre-college engagement grows, a critical question remains: How can young learners be prepared to participate in a field so radically different from what they have encountered before? This paper argues that meeting this challenge will require strong interdisciplinary collaboration with the Learning Sciences (LS), a field dedicated to understanding how people learn and designing theory-guided environments to support learning. Drawing on lessons from previous STEM education efforts, we discuss two key contributions of the learning sciences to quantum information science (QIS) education. The first is design-based research, the signature methodology of learning sciences, which can inform the development, refinement, and scaling of effective QIS learning experiences. The second is a framework for reshaping how learners reason about, learn and participate in QIS practices through shifts in knowledge representations that provide new forms of engagement and associated learning. We call for a two-way partnership between quantum information science and the learning sciences, one that not only supports learning in quantum concepts and practices but also improves our understanding of how to teach and support learning in highly complex domains. We also consider potential questions involved in bridging these disciplinary communities and argue that the theoretical and practical benefits justify the effort.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00668v1</guid>
      <category>physics.ed-ph</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>quant-ph</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Raquel Coelho, Roy Pea, Christian Schunn, Jinglei Cheng, Junyu Liu</dc:creator>
    </item>
    <item>
      <title>The Urban Impact of AI: Modeling Feedback Loops in Next-Venue Recommendation</title>
      <link>https://arxiv.org/abs/2504.07911</link>
      <description>arXiv:2504.07911v2 Announce Type: replace-cross 
Abstract: Next-venue recommender systems are increasingly embedded in location-based services, shaping individual mobility decisions in urban environments. While their predictive accuracy has been extensively studied, less attention has been paid to their systemic impact on urban dynamics. In this work, we introduce a simulation framework to model the human-AI feedback loop underpinning next-venue recommendation, capturing how algorithmic suggestions influence individual behavior, which in turn reshapes the data used to retrain the models. Our simulations, grounded in real-world mobility data, systematically explore the effects of algorithmic adoption across a range of recommendation strategies. We find that while recommender systems consistently increase individual-level diversity in visited venues, they may simultaneously amplify collective inequality by concentrating visits on a limited subset of popular places. This divergence extends to the structure of social co-location networks, revealing broader implications for urban accessibility and spatial segregation. Our framework operationalizes the feedback loop in next-venue recommendation and offers a novel lens through which to assess the societal impact of AI-assisted mobility-providing a computational tool to anticipate future risks, evaluate regulatory interventions, and inform the design of ethic algorithmic systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.07911v2</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Giovanni Mauro, Marco Minici, Luca Pappalardo</dc:creator>
    </item>
    <item>
      <title>Mitigating Gender Bias via Fostering Exploratory Thinking in LLMs</title>
      <link>https://arxiv.org/abs/2505.17217</link>
      <description>arXiv:2505.17217v2 Announce Type: replace-cross 
Abstract: Large Language Models (LLMs) often exhibit gender bias, resulting in unequal treatment of male and female subjects across different contexts. To address this issue, we propose a novel data generation framework that fosters exploratory thinking in LLMs. Our approach prompts models to generate story pairs featuring male and female protagonists in structurally identical, morally ambiguous scenarios, then elicits and compares their moral judgments. When inconsistencies arise, the model is guided to produce balanced, gender-neutral judgments. These story-judgment pairs are used to fine-tune or optimize the models via Direct Preference Optimization (DPO). Experimental results show that our method significantly reduces gender bias while preserving or even enhancing general model capabilities. We will release the code and generated data. We release the code and generated data at: https://github.com/WeiKangda/LLMs-Exploratory-Bias-Mitigation/tree/main.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.17217v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Kangda Wei, Hasnat Md Abdullah, Ruihong Huang</dc:creator>
    </item>
    <item>
      <title>Verification Cost Asymmetry in Cognitive Warfare: A Complexity-Theoretic Framework</title>
      <link>https://arxiv.org/abs/2507.21258</link>
      <description>arXiv:2507.21258v2 Announce Type: replace-cross 
Abstract: Human verification under adversarial information flow operates as a cost-bounded decision procedure constrained by working memory limits and cognitive biases. We introduce the Verification Cost Asymmetry (VCA) coefficient, formalizing it as the ratio of expected verification work between populations under identical claim distributions. Drawing on probabilistically checkable proofs (PCP) and parameterized complexity theory, we construct dissemination protocols that reduce verification for trusted audiences to constant human effort while imposing superlinear costs on adversarial populations lacking cryptographic infrastructure. We prove theoretical guarantees for this asymmetry, validate the framework through controlled user studies measuring verification effort with and without spot-checkable provenance, and demonstrate practical encoding of real-world information campaigns. The results establish complexity-theoretic foundations for engineering democratic advantage in cognitive warfare, with immediate applications to content authentication, platform governance, and information operations doctrine.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.21258v2</guid>
      <category>cs.CR</category>
      <category>cs.CC</category>
      <category>cs.CY</category>
      <category>cs.GT</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Joshua Luberisse</dc:creator>
    </item>
    <item>
      <title>Breaking the mould of Social Mixed Reality - State-of-the-Art and Glossary</title>
      <link>https://arxiv.org/abs/2507.23454</link>
      <description>arXiv:2507.23454v2 Announce Type: replace-cross 
Abstract: This article explores a critical gap in Mixed Reality (MR) technology: while advances have been made, MR still struggles to authentically replicate human embodiment and socio-motor interaction. For MR to enable truly meaningful social experiences, it needs to incorporate multi-modal data streams and multi-agent interaction capabilities. To address this challenge, we present a comprehensive glossary covering key topics such as Virtual Characters and Autonomisation, Responsible AI, Ethics by Design, and the Scientific Challenges of Social MR within Neuroscience, Embodiment, and Technology. Our aim is to drive the transformative evolution of MR technologies that prioritize human-centric innovation, fostering richer digital connections. We advocate for MR systems that enhance social interaction and collaboration between humans and virtual autonomous agents, ensuring inclusivity, ethical design and psychological safety in the process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.23454v2</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <category>cs.ET</category>
      <category>cs.GR</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Marta Bie\'nkiewicz, Julia Ayache, Panayiotis Charalambous, Cristina Becchio, Marco Corragio, Bertram Taetz, Francesco De Lellis, Antonio Grotta, Anna Server, Daniel Rammer, Richard Kulpa, Franck Multon, Azucena Garcia-Palacios, Jessica Sutherland, Kathleen Bryson, St\'ephane Donikian, Didier Stricker, Beno\^it Bardy</dc:creator>
    </item>
  </channel>
</rss>
