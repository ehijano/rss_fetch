<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NE</link>
    <description>cs.NE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 17 Oct 2024 04:00:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Learned Neural Physics Simulation for Articulated 3D Human Pose Reconstruction</title>
      <link>https://arxiv.org/abs/2410.12023</link>
      <description>arXiv:2410.12023v1 Announce Type: new 
Abstract: We propose a novel neural network approach, LARP (Learned Articulated Rigid body Physics), to model the dynamics of articulated human motion with contact. Our goal is to develop a faster and more convenient methodological alternative to traditional physics simulators for use in computer vision tasks such as human motion reconstruction from video. To that end we introduce a training procedure and model components that support the construction of a recurrent neural architecture to accurately simulate articulated rigid body dynamics. Our neural architecture supports features typically found in traditional physics simulators, such as modeling of joint motors, variable dimensions of body parts, contact between body parts and objects, and is an order of magnitude faster than traditional systems when multiple simulations are run in parallel. To demonstrate the value of LARP we use it as a drop-in replacement for a state of the art classical non-differentiable simulator in an existing video-based reconstruction framework and show comparative or better 3D human pose reconstruction accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12023v1</guid>
      <category>cs.NE</category>
      <category>cs.CV</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mykhaylo Andriluka, Baruch Tabanpour, C. Daniel Freeman, Cristian Sminchisescu</dc:creator>
    </item>
    <item>
      <title>A Lattice-based Method for Optimization in Continuous Spaces with Genetic Algorithms</title>
      <link>https://arxiv.org/abs/2410.12188</link>
      <description>arXiv:2410.12188v1 Announce Type: new 
Abstract: This work presents a novel lattice-based methodology for incorporating multidimensional constraints into continuous decision variables within a genetic algorithm (GA) framework. The proposed approach consolidates established transcription techniques for crossover of continuous decision variables, aiming to leverage domain knowledge and guide the search process towards feasible regions of the design space. This work offers a robust and general purpose lattice-based GA that is applicable to a broad range of optimization problems. Monte Carlo analysis demonstrates that lattice-based methods find solutions two orders of magnitude closer to optima in fewer generations. The effectiveness of the lattice-based approach is showcased through two illustrative multi-objective design problems: (1) optimal telescope placement for astrophotography and (2) optimal design of a satellite constellation for maximizing ground station access. The optimal telescope placement example shows that lattice-based methods converge to the Pareto front in 15% fewer generations than traditional methods. The orbit design example shows that lattice-based methods discover an order of magnitude more Pareto-optimal solutions than traditional methods in a highly constrained design space. Overall, the results show that the lattice-based method exhibits enhanced exploration capabilities, traversing the solution space more comprehensively and achieving faster convergence compared to conventional GAs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12188v1</guid>
      <category>cs.NE</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cameron D. Harris, Kevin B. Schroeder, Jonathan Black</dc:creator>
    </item>
    <item>
      <title>Are Grid Cells Hexagonal for Performance or by Convenience?</title>
      <link>https://arxiv.org/abs/2410.11886</link>
      <description>arXiv:2410.11886v1 Announce Type: cross 
Abstract: This paper investigates whether the hexagonal structure of grid cells provides any performance benefits or if it merely represents a biologically convenient configuration. Utilizing the Vector-HaSH content addressable memory model as a model of the grid cell -- place cell network of the mammalian brain, we compare the performance of square and hexagonal grid cells in tasks of storing and retrieving spatial memories. Our experiments across different path types, path lengths and grid configurations, reveal that hexagonal grid cells perform similarly to square grid cells with respect to spatial representation and memory recall. Our results show comparable accuracy and robustness across different datasets and noise levels on images to recall. These findings suggest that the brain's use of hexagonal grids may be more a matter of biological convenience and ease of implementation rather than because they provide superior performance over square grid cells (which are easier to implement in silico).</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11886v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Taahaa Mir, Peipei Yao, Kateri Duranceau, Isabeau Pr\'emont-Schwarz</dc:creator>
    </item>
    <item>
      <title>Spatial-Temporal Bearing Fault Detection Using Graph Attention Networks and LSTM</title>
      <link>https://arxiv.org/abs/2410.11923</link>
      <description>arXiv:2410.11923v1 Announce Type: cross 
Abstract: Purpose: This paper aims to enhance bearing fault diagnosis in industrial machinery by introducing a novel method that combines Graph Attention Network (GAT) and Long Short-Term Memory (LSTM) networks. This approach captures both spatial and temporal dependencies within sensor data, improving the accuracy of bearing fault detection under various conditions. Methodology: The proposed method converts time series sensor data into graph representations. GAT captures spatial relationships between components, while LSTM models temporal patterns. The model is validated using the Case Western Reserve University (CWRU) Bearing Dataset, which includes data under different horsepower levels and both normal and faulty conditions. Its performance is compared with methods such as K-Nearest Neighbors (KNN), Local Outlier Factor (LOF), Isolation Forest (IForest) and GNN-based method for bearing fault detection (GNNBFD). Findings: The model achieved outstanding results, with precision, recall, and F1-scores reaching 100\% across various testing conditions. It not only identifies faults accurately but also generalizes effectively across different operational scenarios, outperforming traditional methods. Originality: This research presents a unique combination of GAT and LSTM for fault detection, overcoming the limitations of traditional time series methods by capturing complex spatial-temporal dependencies. Its superior performance demonstrates significant potential for predictive maintenance in industrial applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11923v1</guid>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Moirangthem Tiken Singh, Rabinder Kumar Prasad, Gurumayum Robert Michael, N. Hemarjit Singh, N. K. Kaphungkui</dc:creator>
    </item>
    <item>
      <title>Increasing the clock speed of a thermodynamic computer by adding noise</title>
      <link>https://arxiv.org/abs/2410.12211</link>
      <description>arXiv:2410.12211v1 Announce Type: cross 
Abstract: We describe a proposal for increasing the effective clock speed of a thermodynamic computer, by altering the interaction scale of the units within the computer and introducing to the computer an additional source of noise. The resulting thermodynamic computer program is equivalent to the original computer program, but runs at a higher clock speed. This approach offers a way of increasing the speed of thermodynamic computing while preserving the fidelity of computation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12211v1</guid>
      <category>cond-mat.stat-mech</category>
      <category>cs.NE</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stephen Whitelam</dc:creator>
    </item>
    <item>
      <title>Deep Learning and genetic algorithms for cosmological Bayesian inference speed-up</title>
      <link>https://arxiv.org/abs/2405.03293</link>
      <description>arXiv:2405.03293v2 Announce Type: replace-cross 
Abstract: In this paper, we present a novel approach to accelerate the Bayesian inference process, focusing specifically on the nested sampling algorithms. Bayesian inference plays a crucial role in cosmological parameter estimation, providing a robust framework for extracting theoretical insights from observational data. However, its computational demands can be substantial, primarily due to the need for numerous likelihood function evaluations. Our proposed method utilizes the power of deep learning, employing feedforward neural networks to approximate the likelihood function dynamically during the Bayesian inference process. Unlike traditional approaches, our method trains neural networks on-the-fly using the current set of live points as training data, without the need for pre-training. This flexibility enables adaptation to various theoretical models and datasets. We perform simple hyperparameter optimization using genetic algorithms to suggest initial neural network architectures for learning each likelihood function. Once sufficient accuracy is achieved, the neural network replaces the original likelihood function. The implementation integrates with nested sampling algorithms and has been thoroughly evaluated using both simple cosmological dark energy models and diverse observational datasets. Additionally, we explore the potential of genetic algorithms for generating initial live points within nested sampling inference, opening up new avenues for enhancing the efficiency and effectiveness of Bayesian inference methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03293v2</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.CO</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <category>stat.ML</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1103/PhysRevD.110.083518</arxiv:DOI>
      <arxiv:journal_reference>Phys. Rev. D 110, 083518 (2024)</arxiv:journal_reference>
      <dc:creator>Isidro G\'omez-Vargas, J. Alberto V\'azquez</dc:creator>
    </item>
  </channel>
</rss>
