<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.QM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.QM</link>
    <description>q-bio.QM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.QM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 08 Aug 2025 04:01:24 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Understanding protein function with a multimodal retrieval-augmented foundation model</title>
      <link>https://arxiv.org/abs/2508.04724</link>
      <description>arXiv:2508.04724v1 Announce Type: new 
Abstract: Protein language models (PLMs) learn probability distributions over natural protein sequences. By learning from hundreds of millions of natural protein sequences, protein understanding and design capabilities emerge. Recent works have shown that scaling these models improves structure prediction, but does not seem to improve mutation understanding and representation quality for protein function prediction. We introduce PoET-2, a multimodal, retrieval-augmented protein foundation model that incorporates in-context learning of family-specific evolutionary constraints with optional structure conditioning to learn generative distributions over protein sequences. PoET-2 uses a hierarchical transformer encoder that is equivariant to sequence context ordering and a dual decoder architecture with both causal and masked language modeling objectives, allowing PoET-2 to operate in both fully generative and bidirectional representation learning modes. PoET-2 achieves state-of-the-art performance on zero-shot variant effect prediction, excelling at scoring variants with multiple mutations and challenging indel mutations. In supervised settings, PoET-2 embeddings outperform previous methods for learning sequence-function relationships, especially with small datasets. This work highlights the benefits of combining retrieval augmentation with multimodal, family-centric modeling for advancing protein foundation models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04724v1</guid>
      <category>q-bio.QM</category>
      <category>cs.LG</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Timothy Fei Truong Jr, Tristan Bepler</dc:creator>
    </item>
    <item>
      <title>Cross-Domain Image Synthesis: Generating H&amp;E from Multiplex Biomarker Imaging</title>
      <link>https://arxiv.org/abs/2508.04734</link>
      <description>arXiv:2508.04734v1 Announce Type: new 
Abstract: While multiplex immunofluorescence (mIF) imaging provides deep, spatially-resolved molecular data, integrating this information with the morphological standard of Hematoxylin &amp; Eosin (H&amp;E) can be very important for obtaining complementary information about the underlying tissue. Generating a virtual H&amp;E stain from mIF data offers a powerful solution, providing immediate morphological context. Crucially, this approach enables the application of the vast ecosystem of H&amp;E-based computer-aided diagnosis (CAD) tools to analyze rich molecular data, bridging the gap between molecular and morphological analysis. In this work, we investigate the use of a multi-level Vector-Quantized Generative Adversarial Network (VQGAN) to create high-fidelity virtual H&amp;E stains from mIF images. We rigorously evaluated our VQGAN against a standard conditional GAN (cGAN) baseline on two publicly available colorectal cancer datasets, assessing performance on both image similarity and functional utility for downstream analysis. Our results show that while both architectures produce visually plausible images, the virtual stains generated by our VQGAN provide a more effective substrate for computer-aided diagnosis. Specifically, downstream nuclei segmentation and semantic preservation in tissue classification tasks performed on VQGAN-generated images demonstrate superior performance and agreement with ground-truth analysis compared to those from the cGAN. This work establishes that a multi-level VQGAN is a robust and superior architecture for generating scientifically useful virtual stains, offering a viable pathway to integrate the rich molecular data of mIF into established and powerful H&amp;E-based analytical workflows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04734v1</guid>
      <category>q-bio.QM</category>
      <category>cs.AI</category>
      <category>eess.IV</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jillur Rahman Saurav, Mohammad Sadegh Nasr, Jacob M. Luber</dc:creator>
    </item>
    <item>
      <title>ERDES: A Benchmark Video Dataset for Retinal Detachment and Macular Status Classification in Ocular Ultrasound</title>
      <link>https://arxiv.org/abs/2508.04735</link>
      <description>arXiv:2508.04735v1 Announce Type: new 
Abstract: Retinal detachment (RD) is a vision-threatening condition that requires timely intervention to preserve vision. Macular involvement -- whether the macula is still intact (macula-intact) or detached (macula-detached) -- is the key determinant of visual outcomes and treatment urgency. Point-of-care ultrasound (POCUS) offers a fast, non-invasive, cost-effective, and accessible imaging modality widely used in diverse clinical settings to detect RD. However, ultrasound image interpretation is limited by a lack of expertise among healthcare providers, especially in resource-limited settings. Deep learning offers the potential to automate ultrasound-based assessment of RD. However, there are no ML ultrasound algorithms currently available for clinical use to detect RD and no prior research has been done on assessing macular status using ultrasound in RD cases -- an essential distinction for surgical prioritization. Moreover, no public dataset currently supports macular-based RD classification using ultrasound video clips. We introduce Eye Retinal DEtachment ultraSound, ERDES, the first open-access dataset of ocular ultrasound clips labeled for (i) presence of retinal detachment and (ii) macula-intact versus macula-detached status. The dataset is intended to facilitate the development and evaluation of machine learning models for detecting retinal detachment. We also provide baseline benchmarks using multiple spatiotemporal convolutional neural network (CNN) architectures. All clips, labels, and training code are publicly available at https://osupcvlab.github.io/ERDES/.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04735v1</guid>
      <category>q-bio.QM</category>
      <category>cs.AI</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pouyan Navard, Yasemin Ozkut, Srikar Adhikari, Elaine Situ-LaCasse, Josie Acu\~na, Adrienne Yarnish, Alper Yilmaz</dc:creator>
    </item>
    <item>
      <title>PhysiBoSS-Models: A database for multiscale models</title>
      <link>https://arxiv.org/abs/2508.05550</link>
      <description>arXiv:2508.05550v1 Announce Type: new 
Abstract: PhysiBoSS is an open-source platform that integrates agent-based modeling of cell populations with intracellular stochastic Boolean networks, enabling multiscale simulations of complex biological behaviors. To promote model sharing and versioning, we present the PhysiBoSS-Models database: a curated repository for multiscale models built with PhysiBoSS. By providing a simple Python API, PhysiBoSS-Models provides an easy way to download and simulate preexisting models through tools such as PhysiCell Studio. By providing standardized access to validated models, PhysiBoSS-Models facilitates reuse, validation, and benchmarking, supporting research in biology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05550v1</guid>
      <category>q-bio.QM</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vincent Noel, Marco Ruscone, Randy Heiland, Arnau Montagud, Alfonso Valencia, Emmanuel Barillot, Paul Macklin, Laurence Calzone</dc:creator>
    </item>
    <item>
      <title>Data Analysis and Modeling for Transitioning Between Laboratory Methods for Detecting SARS-CoV-2 in Wastewater</title>
      <link>https://arxiv.org/abs/2508.05594</link>
      <description>arXiv:2508.05594v1 Announce Type: new 
Abstract: Wastewater surveillance has proven to be a useful tool to monitor pathogens such as SARS-CoV-2 as it is a nonintrusive way to survey the potential disease burden of the population contributing to a sewershed. With the expansion of this field since the beginning of the COVID-19 pandemic, laboratory methods to process wastewater and quantify pathogen nucleic acid levels have improved as technologies changed, efforts expanded in size and scope, and supply chain issues were resolved. Maintaining data continuity is crucial for labs undergoing method transitions to accurately assess infectious disease levels over time and compare measured RNA concentrations to public health data. Despite the dynamic nature of laboratory methods and the necessity to ensure uninterrupted data, to our knowledge there has not been a study that unites two datasets from different lab methods for pathogen quantification from environmental samples. Here, we describe a lab transition from SARS-CoV-2 RNA quantification using a low-throughput, manual filtration-based wastewater concentration and RNA extraction followed by qPCR to a high-throughput, automated magnetic bead-based concentration and extraction followed by dPCR. During the two-month transition period, wastewater samples from across the Chicago metropolitan area were processed with both methods in parallel. We evaluated a variety of regression models to relate the RNA measurements from both methods and found a log-log model was most appropriate after removing outliers and discrepancy points to improve model performance. We also evaluated the consequences of assigning values to samples that were below the detection limit. Our study demonstrates that data continuity can be maintained throughout a transition of laboratory methods if there is a sufficient period of overlap between the methods for an appropriate model to be constructed to relate the datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05594v1</guid>
      <category>q-bio.QM</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maria M. Warns, Leah Mrowiec, Christopher Owen, Adam Horton, Chi-Yu Lin, Modou Lamin Jarju, Niall M. Mangan, Aaron Packman, Katelyn Plaisier Leisman, Abhilasha Shrestha, Rachel Poretsky</dc:creator>
    </item>
    <item>
      <title>Adaptive k-space Radial Sampling for Cardiac MRI with Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2508.04727</link>
      <description>arXiv:2508.04727v1 Announce Type: cross 
Abstract: Accelerated Magnetic Resonance Imaging (MRI) requires careful optimization of k-space sampling patterns to balance acquisition speed and image quality. While recent advances in deep learning have shown promise in optimizing Cartesian sampling, the potential of reinforcement learning (RL) for non-Cartesian trajectory optimization remains largely unexplored. In this work, we present a novel RL framework for optimizing radial sampling trajectories in cardiac MRI. Our approach features a dual-branch architecture that jointly processes k-space and image-domain information, incorporating a cross-attention fusion mechanism to facilitate effective information exchange between domains. The framework employs an anatomically-aware reward design and a golden-ratio sampling strategy to ensure uniform k-space coverage while preserving cardiac structural details. Experimental results demonstrate that our method effectively learns optimal radial sampling strategies across multiple acceleration factors, achieving improved reconstruction quality compared to conventional approaches. Code available: https://github.com/Ruru-Xu/RL-kspace-Radial-Sampling</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04727v1</guid>
      <category>q-bio.TO</category>
      <category>eess.IV</category>
      <category>q-bio.QM</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ruru Xu, Ilkay Oksuz</dc:creator>
    </item>
    <item>
      <title>Data Leakage and Redundancy in the LIT-PCBA Benchmark</title>
      <link>https://arxiv.org/abs/2507.21404</link>
      <description>arXiv:2507.21404v2 Announce Type: replace-cross 
Abstract: LIT-PCBA is widely used to benchmark virtual screening models, but our audit reveals that it is fundamentally compromised. We find extensive data leakage and molecular redundancy across its splits, including 2D-identical ligands within and across partitions, pervasive analog overlap, and low-diversity query sets. In ALDH1 alone, for instance, 323 active training -- validation analog pairs occur at ECFP4 Tanimoto similarity $\geq 0.6$; across all targets, 2,491 2D-identical inactives appear in both training and validation, with very few corresponding actives. These overlaps allow models to succeed through scaffold memorization rather than generalization, inflating enrichment factors and AUROC scores. These flaws are not incidental -- they are so severe that a trivial memorization-based baseline with no learnable parameters can exploit them to match or exceed the reported performance of state-of-the-art deep learning and 3D-similarity models. As a result, nearly all published results on LIT-PCBA are undermined. Even models evaluated in "zero-shot" mode are affected by analog leakage into the query set, weakening claims of generalization. In its current form, the benchmark does not measure a model's ability to recover novel chemotypes and should not be taken as evidence of methodological progress.
  All code, data, and baseline implementations are available at: https://github.com/sievestack/LIT-PCBA-audit</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.21404v2</guid>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amber Huang, Ian Scott Knight, Slava Naprienko</dc:creator>
    </item>
  </channel>
</rss>
