<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.GN updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.GN</link>
    <description>econ.GN updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.GN" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 21 Aug 2025 01:23:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Category Theory Framework for Macroeconomic Modeling: The Case of Argentina's Bimonetary Economy</title>
      <link>https://arxiv.org/abs/2508.13233</link>
      <description>arXiv:2508.13233v1 Announce Type: new 
Abstract: Traditional macroeconomic models, based on static algebraic systems, fail to capture the dynamics of a bimonetary economy like Argentina's. This paper proposes a framework based on category theory to develop a more flexible and structured model that represents the evolving relationships between key variables such as inflation expectations, interest rates, and currency demand. Using concepts like objects, morphisms, learning/forgetful functors, limits, and colimits, the model is applied to empirical data from 2018-2023. The findings reveal a significant structural misalignment between the equilibrium and observed exchange rates and propose a new aggregate indicator to measure devaluation risk. The framework demonstrates a strong synergy with modern computational tools like machine learning, offering a more robust approach to policy analysis and forecasting in complex economies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13233v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luciano Pollicino</dc:creator>
    </item>
    <item>
      <title>Interpreting the Interpreter: Can We Model post-ECB Conferences Volatility with LLM Agents?</title>
      <link>https://arxiv.org/abs/2508.13635</link>
      <description>arXiv:2508.13635v1 Announce Type: new 
Abstract: This paper develops a novel method to simulate financial market reactions to European Central Bank (ECB) press conferences using a Large Language Model (LLM). We create a behavioral, agent-based simulation of 30 synthetic traders, each with distinct risk preferences, cognitive biases, and interpretive styles. These agents forecast Euro interest rate swap levels at 3-month, 2-year, and 10-year maturities, with the variation across forecasts serving as a measure of market uncertainty or disagreement. We evaluate three prompting strategies, naive, few-shot (enriched with historical data), and an advanced iterative 'LLM-as-a-Judge' framework, to assess the effect of prompt design on predictive performance. Even the naive approach generates a strong correlation (roughly 0.5) between synthetic disagreement and actual market outcomes, particularly for longer-term maturities. The LLM-as-a-Judge framework further improves accuracy at the first iteration. These results demonstrate that LLM-driven simulations can capture interpretive uncertainty beyond traditional measures, providing central banks with a practical tool to anticipate market reactions, refine communication strategies, and enhance financial stability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13635v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Umberto Collodel</dc:creator>
    </item>
    <item>
      <title>Monotonic Path-Specific Effects: Application to Estimating Educational Returns</title>
      <link>https://arxiv.org/abs/2508.13366</link>
      <description>arXiv:2508.13366v1 Announce Type: cross 
Abstract: Conventional research on educational effects typically either employs a "years of schooling" measure of education, or dichotomizes attainment as a point-in-time treatment. Yet, such a conceptualization of education is misaligned with the sequential process by which individuals make educational transitions. In this paper, I propose a causal mediation framework for the study of educational effects on outcomes such as earnings. The framework considers the effect of a given educational transition as operating indirectly, via progression through subsequent transitions, as well as directly, net of these transitions. I demonstrate that the average treatment effect (ATE) of education can be additively decomposed into mutually exclusive components that capture these direct and indirect effects. The decomposition has several special properties which distinguish it from conventional mediation decompositions of the ATE, properties which facilitate less restrictive identification assumptions as well as identification of all causal paths in the decomposition. An analysis of the returns to high school completion in the NLSY97 cohort suggests that the payoff to a high school degree stems overwhelmingly from its direct labor market returns. Mediation via college attendance, completion and graduate school attendance is small because of individuals' low counterfactual progression rates through these subsequent transitions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13366v1</guid>
      <category>stat.AP</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <category>stat.ME</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aleksei Opacic</dc:creator>
    </item>
    <item>
      <title>Trust, but verify</title>
      <link>https://arxiv.org/abs/2504.13443</link>
      <description>arXiv:2504.13443v2 Announce Type: replace-cross 
Abstract: Decentralized AI agent networks, such as Gaia, allows individuals to run customized LLMs on their own computers and then provide services to the public. However, in order to maintain service quality, the network must verify that individual nodes are running their designated LLMs. In this paper, we demonstrate that in a cluster of mostly honest nodes, we can detect nodes that run unauthorized or incorrect LLM through social consensus of its peers. We will discuss the algorithm and experimental data from the Gaia network. We will also discuss the intersubjective validation system, implemented as an EigenLayer AVS to introduce financial incentives and penalties to encourage honest behavior from LLM nodes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.13443v2</guid>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>cs.MA</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael J. Yuan, Carlos Lospoy, Sydney Lai, James Snewin, Ju Long</dc:creator>
    </item>
  </channel>
</rss>
