<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 18 Apr 2025 01:43:35 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Delayed Acceptance Markov Chain Monte Carlo for Robust Bayesian Analysis</title>
      <link>https://arxiv.org/abs/2504.11761</link>
      <description>arXiv:2504.11761v1 Announce Type: new 
Abstract: This study introduces a computationally efficient algorithm, delayed acceptance Markov chain Monte Carlo (DA-MCMC), designed to improve posterior simulation in quasi-Bayesian inference. Quasi-Bayesian methods, which do not require fully specifying a probabilistic model, are often computationally expensive owing to the need to evaluate the inverse and determinant of large covariance matrices. DA-MCMC addresses this challenge by employing a two-stage process: In the first stage, proposals are screened using an approximate posterior, whereas a final acceptance or rejection decision is made in the second stage based on the exact target posterior. This reduces the need for costly matrix computations, thereby improving efficiency without sacrificing accuracy. We demonstrate the effectiveness of DA-MCMC through applications to both synthetic and real data. The results demonstrate that, although DA-MCMC slightly reduces the effective sample size per iteration compared with the standard MCMC, it achieves substantial improvement in terms of effective sample size per second, approximately doubling the efficiency. This makes DA-MCMC particularly useful for cases where posterior simulation is computationally intensive. Thus, the DA-MCMC algorithm offers a significant advancement in computational efficiency for quasi-Bayesian inference, making it a valuable tool for robust Bayesian analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11761v1</guid>
      <category>stat.CO</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Masahiro Tanaka</dc:creator>
    </item>
    <item>
      <title>Particle Data Cloning for Complex Ordinary Differential Equations</title>
      <link>https://arxiv.org/abs/2504.11835</link>
      <description>arXiv:2504.11835v1 Announce Type: new 
Abstract: Ordinary differential equations (ODEs) are fundamental tools for modeling complex dynamic systems across scientific disciplines. However, parameter estimation in ODE models is challenging due to the multimodal nature of the likelihood function, which can lead to local optima and unstable inference. In this paper, we propose particle data cloning (PDC), a novel approach that enhances global optimization by leveraging data cloning and annealed sequential Monte Carlo (ASMC). PDC mitigates multimodality by refining the likelihood through data clones and progressively extracting information from the sharpened posterior. Compared to standard data cloning, PDC provides more reliable frequentist inference and demonstrates superior global optimization performance. We offer practical guidelines for efficient implementation and illustrate the method through simulation studies and an application to a prey-predator ODE model. Our implementation is available at https://github.com/SONDONGHUI/PDC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11835v1</guid>
      <category>stat.CO</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Donghui Son, Liangliang Wang</dc:creator>
    </item>
    <item>
      <title>Reducing Calls to the Simulator in Simulation Based Inference (SBI)</title>
      <link>https://arxiv.org/abs/2504.11925</link>
      <description>arXiv:2504.11925v1 Announce Type: new 
Abstract: Simulation-Based Inference (SBI) deals with statistical inference in problems where the data are generated from a system that is described by a complex stochastic simulator. The challenge for inference in these problems is that the likelihood is intractable; SBI proceeds by using the simulator to sample from the likelihood. In many real world applications, simulator calls are expensive, limiting the associated sample size. Our goal in this work is to extend SBI to exploit two proposals for reducing simulator calls: to draw likelihood samples from a Neural Density Estimator (NDE) surrogate rather than from the stochastic simulator; and use of Support Points rather than simple random sampling to generate evaluation sites. We embed these methods in the Sequential Neural Posterior Estimator (SNPE) algorithm. Across a suite of test cases, we find that the NDE surrogate improves the quality of the inference; support points worked well in some examples, but not in others.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11925v1</guid>
      <category>stat.CO</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>David Refaeli, Mira Marcus-Kalish, David M. Steinberg</dc:creator>
    </item>
    <item>
      <title>Creating non-reversible rejection-free samplers by rebalancing skew-balanced Markov jump processes</title>
      <link>https://arxiv.org/abs/2504.12190</link>
      <description>arXiv:2504.12190v1 Announce Type: cross 
Abstract: Markov chain sampling methods form the backbone of modern computational statistics. However, many popular methods are prone to random walk behavior, i.e., diffusion-like exploration of the sample space, leading to slow mixing that requires intricate tuning to alleviate. Non-reversible samplers can resolve some of these issues. We introduce a device that turns jump processes that satisfy a skew-detailed balance condition for a reference measure into a process that samples a target measure that is absolutely continuous with respect to the reference measure. The resulting sampler is rejection-free, non-reversible, and continuous-time. As an example, we apply the device to Hamiltonian dynamics discretized by the leapfrog integrator, resulting in a rejection-free non-reversible continuous-time version of Hamiltonian Monte Carlo (HMC). We prove the geometric ergodicity of the resulting sampler under certain convexity conditions, and demonstrate its qualitatively different behavior to HMC through numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.12190v1</guid>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erik Jansson, Moritz Schauer, Ruben Seyer, Akash Sharma</dc:creator>
    </item>
    <item>
      <title>Data Assimilation for Robust UQ Within Agent-Based Simulation on HPC Systems</title>
      <link>https://arxiv.org/abs/2504.12228</link>
      <description>arXiv:2504.12228v1 Announce Type: cross 
Abstract: Agent-based simulation provides a powerful tool for in silico system modeling. However, these simulations do not provide built-in methods for uncertainty quantification (UQ). Within these types of models a typical approach to UQ is to run multiple realizations of the model then compute aggregate statistics. This approach is limited due to the compute time required for a solution. When faced with an emerging biothreat, public health decisions need to be made quickly and solutions for integrating near real-time data with analytic tools are needed.
  We propose an integrated Bayesian UQ framework for agent-based models based on sequential Monte Carlo sampling. Given streaming or static data about the evolution of an emerging pathogen, this Bayesian framework provides a distribution over the parameters governing the spread of a disease through a population. These estimates of the spread of a disease may be provided to public health agencies seeking to abate the spread.
  By coupling agent-based simulations with Bayesian modeling in a data assimilation, our proposed framework provides a powerful tool for modeling dynamical systems in silico. We propose a method which reduces model error and provides a range of realistic possible outcomes. Moreover, our method addresses two primary limitations of ABMs: the lack of UQ and an inability to assimilate data. Our proposed framework combines the flexibility of an agent-based model with UQ provided by the Bayesian paradigm in a workflow which scales well to HPC systems. We provide algorithmic details and results on a simulated outbreak with both static and streaming data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.12228v1</guid>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adam Spannaus, Sifat Afroj Moon, John Gounley, Heidi A. Hanson</dc:creator>
    </item>
    <item>
      <title>A Stability Framework for Parameter Selection in the Minimum Covariance Determinant Problem</title>
      <link>https://arxiv.org/abs/2401.14359</link>
      <description>arXiv:2401.14359v4 Announce Type: replace-cross 
Abstract: The Minimum Covariance Determinant (MCD) method is a widely adopted tool for robust estimation and outlier detection. In this paper, we introduce MCD model selection based on the notion of stability. Our best subset method leverages prior best practices such as statistical depths for initialization and concentration steps for subset refinement. Our contribution lies in constructing a bootstrap procedure to estimate the instability of the best subset algorithm. The instability path offers insights into a dataset's inlier/outlier structure and facilitates suitable choice of the subset size. We rigorously benchmark the proposed framework against existing MCD variants and illustrate its practical utility on several real-world datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.14359v4</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qiang Heng, Hui Shen, Kenneth Lange</dc:creator>
    </item>
    <item>
      <title>Efficient Rare-Event Simulation for Random Geometric Graphs via Importance Sampling</title>
      <link>https://arxiv.org/abs/2504.10530</link>
      <description>arXiv:2504.10530v2 Announce Type: replace-cross 
Abstract: Random geometric graphs defined on Euclidean subspaces, also called Gilbert graphs, are widely used to model spatially embedded networks across various domains. In such graphs, nodes are located at random in Euclidean space, and any two nodes are connected by an edge if they lie within a certain distance threshold. Accurately estimating rare-event probabilities related to key properties of these graphs, such as the number of edges and the size of the largest connected component, is important in the assessment of risk associated with catastrophic incidents, for example. However, this task is computationally challenging, especially for large networks. Importance sampling offers a viable solution by concentrating computational efforts on significant regions of the graph. This paper explores the application of an importance sampling method to estimate rare-event probabilities, highlighting its advantages in reducing variance and enhancing accuracy. Through asymptotic analysis and experiments, we demonstrate the effectiveness of our methodology, contributing to improved analysis of Gilbert graphs and showcasing the broader applicability of importance sampling in complex network analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10530v2</guid>
      <category>math.PR</category>
      <category>stat.CO</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sarat Moka, Christian Hirsch, Volker Schmidt, Dirk Kroese</dc:creator>
    </item>
  </channel>
</rss>
