<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 14 Jul 2025 04:02:26 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Estimating Marginal Likelihoods in Likelihood-Free Inference via Neural Density Estimation</title>
      <link>https://arxiv.org/abs/2507.08734</link>
      <description>arXiv:2507.08734v1 Announce Type: new 
Abstract: The marginal likelihood, or evidence, plays a central role in Bayesian model selection, yet remains notoriously challenging to compute in likelihood-free settings. While Simulation-Based Inference (SBI) techniques such as Sequential Neural Likelihood Estimation (SNLE) offer powerful tools to approximate posteriors using neural density estimators, they typically do not provide estimates of the evidence. In this technical report presented at BayesComp 2025, we present a simple and general methodology to estimate the marginal likelihood using the output of SNLE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.08734v1</guid>
      <category>stat.CO</category>
      <pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paul Bastide, Arnaud Estoup, Jean-Michel Marin, Julien Stoehr</dc:creator>
    </item>
    <item>
      <title>Addressing overlapping communities in multiple-source detection: An edge clustering approach for complex networks</title>
      <link>https://arxiv.org/abs/2507.08265</link>
      <description>arXiv:2507.08265v1 Announce Type: cross 
Abstract: The source detection problem in network analysis involves identifying the origins of diffusion processes, such as disease outbreaks or misinformation propagation. Traditional methods often focus on single sources, whereas real-world scenarios frequently involve multiple sources, complicating detection efforts. This study addresses the multiple-source detection (MSD) problem by integrating edge clustering algorithms into the community-based label propagation framework, effectively handling mixed-membership issues where nodes belong to multiple communities.
  The proposed approach applies the automated latent space edge clustering model to a network, partitioning infected networks into edge-based clusters to identify multiple sources. Simulation studies on ADD HEALTH social network datasets demonstrate that this method achieves superior accuracy, as measured by the F1-Measure, compared to state-of-the-art clustering algorithms. The results highlight the robustness of edge clustering in accurately detecting sources, particularly in networks with complex and overlapping source regions. This work advances the applicability of clustering-based methods to MSD problems, offering improved accuracy and adaptability for real-world network analyses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.08265v1</guid>
      <category>cs.SI</category>
      <category>stat.CO</category>
      <pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haomin Li, Daniel K. Sewell</dc:creator>
    </item>
    <item>
      <title>Detecting Evolutionary Change-Points with Branch-Specific Substitution Models and Shrinkage Priors</title>
      <link>https://arxiv.org/abs/2507.08386</link>
      <description>arXiv:2507.08386v1 Announce Type: cross 
Abstract: Branch-specific substitution models are popular for detecting evolutionary change-points, such as shifts in selective pressure. However, applying such models typically requires prior knowledge of change-point locations on the phylogeny or faces scalability issues with large data sets. To address both limitations, we integrate branch-specific substitution models with shrinkage priors to automatically identify change-points without prior knowledge, while simultaneously estimating distinct substitution parameters for each branch. To enable tractable inference under this high-dimensional model, we develop an analytical gradient algorithm for the branch-specific substitution parameters where the computation time is linear in the number of parameters. We apply this gradient algorithm to infer selection pressure dynamics in the evolution of the BRCA1 gene in primates and mutational dynamics in viral sequences from the recent mpox epidemic. Our novel algorithm enhances inference efficiency, achieving up to a 90-fold speedup per iteration in maximum-likelihood optimization when compared to central difference numerical gradient method and up to a 360-fold improvement in computational performance within a Bayesian framework using Hamiltonian Monte Carlo sampler compared to conventional univariate random walk sampler.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.08386v1</guid>
      <category>q-bio.PE</category>
      <category>stat.CO</category>
      <pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Xiang Ji, Benjamin Redelings, Shuo Su, Hongcun Bao, Wu-Min Deng, Samuel L. Hong, Guy Baele, Philippe Lemey, Marc A. Suchard</dc:creator>
    </item>
    <item>
      <title>Splitting Regularized Wasserstein Proximal Algorithms for Nonsmooth Sampling Problems</title>
      <link>https://arxiv.org/abs/2502.16773</link>
      <description>arXiv:2502.16773v2 Announce Type: replace 
Abstract: Sampling from nonsmooth target probability distributions is essential in various applications, including the Bayesian Lasso. We propose a splitting-based sampling algorithm for the time-implicit discretization of the probability flow for the Fokker-Planck equation, where the score function, defined as the gradient logarithm of the current probability density function, is approximated by the regularized Wasserstein proximal. When the prior distribution is the Laplace prior, our algorithm is explicitly formulated as a deterministic interacting particle system, incorporating softmax operators and shrinkage operations to efficiently compute the gradient drift vector field and the score function. We verify the convergence towards target distributions regarding R\'enyi divergences and Wasserstein-2 distance under suitable conditions. Numerical experiments in high-dimensional nonsmooth sampling problems, such as sampling from mixed Gaussian and Laplace distributions, logistic regressions, image restoration with $L_1$-TV regularization, and Bayesian neural networks, demonstrate the efficiency and robust performance of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16773v2</guid>
      <category>stat.CO</category>
      <pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fuqun Han, Stanley Osher, Wuchen Li</dc:creator>
    </item>
    <item>
      <title>DUST: A Duality-Based Pruning Method For Exact Multiple Change-Point Detection</title>
      <link>https://arxiv.org/abs/2507.02467</link>
      <description>arXiv:2507.02467v2 Announce Type: replace-cross 
Abstract: We tackle the challenge of detecting multiple change points in large time series by optimising a penalised likelihood derived from exponential family models. Dynamic programming algorithms can solve this task exactly with at most quadratic time complexity. In recent years, the development of pruning strategies has drastically improved their computational efficiency. However, the two existing approaches have notable limitations: PELT struggles with pruning efficiency in sparse-change scenarios, while FPOP's structure is not adapted to multi-parametric settings. To address these issues, we introduce the DUal Simple Test (DUST) framework, which prunes candidate changes by evaluating a dual function against a threshold. This approach is highly flexible and broadly applicable to parametric models of any dimension. Under mild assumptions, we establish strong duality for the underlying non-convex pruning problem. We demonstrate DUST's effectiveness across various change-point regimes and models. In particular, for one-parametric models, DUST matches the simplicity of PELT with the efficiency of FPOP. Its use is especially advantageous for non-Gaussian models. Finally, we apply DUST to mouse monitoring time series under a change-in-variance model, illustrating its ability to recover the optimal change-point structure efficiently.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.02467v2</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vincent Runge, Charles Truong, Simon Quern\'e</dc:creator>
    </item>
  </channel>
</rss>
