<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 07 Mar 2025 05:00:40 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>On Optimal Control of Hybrid Dynamical Systems using Complementarity Constraints</title>
      <link>https://arxiv.org/abs/2503.03879</link>
      <description>arXiv:2503.03879v1 Announce Type: new 
Abstract: Optimal control for switch-based dynamical systems is a challenging problem in the process control literature. In this study, we model these systems as hybrid dynamical systems with finite number of unknown switching points and reformulate them using non-smooth and non-convex complementarity constraints as a mathematical program with complementarity constraints (MPCC). We utilize a moving finite element based strategy to discretize the differential equation system to accurately locate the unknown switching points at the finite element boundary and achieve high-order accuracy at intermediate non-collocation points. We propose a globalization approach to solve the discretized MPCC problem using a mixed NLP/MILP-based strategy to converge to a non-spurious first-order optimal solution. The method is tested on three dynamic optimization examples, including a gas-liquid tank model and an optimal control problem with a sliding mode solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03879v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Saif R. Kazi, Kexin Wang, Lorenz T. Biegler</dc:creator>
    </item>
    <item>
      <title>Endpoint-Explicit Differential Dynamic Programming via Exact Resolution</title>
      <link>https://arxiv.org/abs/2503.03897</link>
      <description>arXiv:2503.03897v1 Announce Type: new 
Abstract: We introduce a novel method for handling endpoint constraints in constrained differential dynamic programming (DDP). Unlike existing approaches, our method guarantees quadratic convergence and is exact, effectively managing rank deficiencies in both endpoint and stagewise equality constraints. It is applicable to both forward and inverse dynamics formulations, making it particularly well-suited for model predictive control (MPC) applications and for accelerating optimal control (OC) solvers. We demonstrate the efficacy of our approach across a broad range of robotics problems and provide a user-friendly open-source implementation within CROCODDYL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03897v1</guid>
      <category>math.OC</category>
      <category>cs.MS</category>
      <category>cs.RO</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>IEEE International Conference on Robotics and Automation, 2025</arxiv:journal_reference>
      <dc:creator>Maria Parilli, Sergi Martinez, Carlos Mastalli</dc:creator>
    </item>
    <item>
      <title>Asymptotic behavior of penalty dynamics for constrained variational inequalities</title>
      <link>https://arxiv.org/abs/2503.03902</link>
      <description>arXiv:2503.03902v1 Announce Type: new 
Abstract: We propose a comprehensive framework for solving constrained variational inequalities via various classes of evolution equations displaying multi-scale aspects. In a Hilbertian framework, the class of dynamical systems we propose combine Tikhonov regularization and exterior penalization terms in order to yield simultaneously strong convergence of trajectories to least norm solutions in the constrained domain. Our construction thus unifies the literature on regularization methods and penalty-term based dynamical systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03902v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Siqi Qu, Mathias Staudigl, Juan Peypouquet</dc:creator>
    </item>
    <item>
      <title>The Small-Gain Condition for Infinite Networks</title>
      <link>https://arxiv.org/abs/2503.03925</link>
      <description>arXiv:2503.03925v1 Announce Type: new 
Abstract: In recent years, attempts have been made to extend ISS small-gain theorems from finite networks to countably infinite, locally finite networks. Under specific assumptions about the subsystems and the ISS formulation, corresponding infinite-dimensional small-gain results have been proven. However, concerning the assumptions about the interconnection gains and the way they influence the subsystems, these results are still too narrow to be considered a full extension of the state-of-the-art for finite networks. We take a step to closing this gap by a thorough investigation of certain classes of monotone operators associated with an infinite network. Our results shed more light on the theory of finite networks, yield complete characterizations of the small-gain condition for specific ISS formulations and show very clearly which obstacles still have to be overcome to obtain a complete theory for the most general case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03925v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christoph Kawan</dc:creator>
    </item>
    <item>
      <title>Kantorovich duality for optimal transport on completely regular Hausdorff spaces</title>
      <link>https://arxiv.org/abs/2503.03929</link>
      <description>arXiv:2503.03929v1 Announce Type: new 
Abstract: Given two completely regular Hausdorff spaces $X$ and $Y$, two tight Baire measures $\mu$ and $\nu$ on $X$ and $Y$ respectively and a cost $c: X\times Y\to \R$ bounded continuous such that the family $\{c(\cdot,y): y\in Y\}$ (resp. $\{c(x,\cdot): x\in X\}$) is equicontinuous, it is shown that the Kantorovich primal and dual problems, both have solutions and realize the same value. This extends results known on Polish spaces to the more general class of completely regular Hausdorff spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03929v1</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammed Bachir</dc:creator>
    </item>
    <item>
      <title>Efficient, Fast, and Fair Voting Through Dynamic Resource Allocation in a Secure Election Physical Intranet</title>
      <link>https://arxiv.org/abs/2503.04053</link>
      <description>arXiv:2503.04053v1 Announce Type: new 
Abstract: Resource allocations in an election system, often with hundreds of polling locations over a territory such as a county, with the aim that voters receive fair and efficient services, is a challenging problem, as election resources are limited and the number of expected voters can be highly volatile through the voting period. This paper develops two propositions to ensure efficiency, fairness, resilience, and security. The first is to leverage Physical Internet (PI) principles, notably setting up a "secure election physical intranet" (SEPI) based on open resource sharing and flow consolidation between election facilities in the territory. The second is to adopt a smart dynamic resource allocation methodology within the SEPI based on queueing networks and lexicographic optimization. A queueing model is developed to provide feasible combinations of resources and individual performances for each polling location by considering layout and utilization constraints. A two-stage lexicographic optimizer receives the queueing model's outputs and finds an optimal solution that is less expensive, fast, and fair. A scenario-based case study validates the proposed methodology based on data from the 2020 US Presidential Election in Fulton County, Georgia, USA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.04053v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tiankuo Zhang, Benoit Montreuil, Ali V Barenji, Praveen Muthukrishnan</dc:creator>
    </item>
    <item>
      <title>Quantitative Flow Approximation Properties of Narrow Neural ODEs</title>
      <link>https://arxiv.org/abs/2503.04068</link>
      <description>arXiv:2503.04068v1 Announce Type: new 
Abstract: In this note, we revisit the problem of flow approximation properties of neural ordinary differential equations (NODEs). The approximation properties have been considered as a flow controllability problem in recent literature. The neural ODE is considered {\it narrow} when the parameters have dimension equal to the input of the neural network, and hence have limited width. We derive the relation of narrow NODEs in approximating flows of shallow but wide NODEs. Due to existing results on approximation properties of shallow neural networks, this facilitates understanding which kind of flows of dynamical systems can be approximated using narrow neural ODEs. While approximation properties of narrow NODEs have been established in literature, the proofs often involve extensive constructions or require invoking deep controllability theorems from control theory. In this paper, we provide a simpler proof technique that involves only ideas from ODEs and Gr{\"o}nwall's lemma. Moreover, we provide an estimate on the number of switches needed for the time dependent weights of the narrow NODE to mimic the behavior of a NODE with a single layer wide neural network as the velocity field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.04068v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Karthik Elamvazhuthi</dc:creator>
    </item>
    <item>
      <title>Admissibility of control operators for positive semigroups and robustness of input-to-state stability</title>
      <link>https://arxiv.org/abs/2503.04097</link>
      <description>arXiv:2503.04097v1 Announce Type: new 
Abstract: In this paper, we establish the well-posedness and stability of distributed parameter systems, focusing on linear positive control systems in a Banach lattice setting. We characterize well-posedness and derive a sufficient condition for admissibility based on a lower norm estimate of the resolvent operator on the positive cone. Furthermore, we analyze input-to-state stability (ISS) under boundary perturbations within the domain of the semigroup generator. Notably, we provide necessary and sufficient conditions for the robustness of ISS under Desch-Schappacher perturbations. Our theoretical results are demonstrated through a boundary value-controlled transport equation with non-local boundary conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.04097v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yassine El Gantouh, Yang Liu, Jianquan Lu, Jinde Cao</dc:creator>
    </item>
    <item>
      <title>Primal and Dual Characterizations for Farkas type Lemmas in Terms of Closedness Criteria</title>
      <link>https://arxiv.org/abs/2503.04226</link>
      <description>arXiv:2503.04226v1 Announce Type: new 
Abstract: This paper deals with the characterization, in terms of closedness of certain sets regarding other sets, of Farkas lemmas determining when the upperlevel set of a given convex function contains the intersection, say F, of a convex set of a locally convex space X with the inverse image by a continuous linear operator from X to another locally convex space Y of certain convex subset of Y. More in detail, each of the mentioned characterizations of Farkas type lemmas consists in the closedness of certain subset of either one of the "primal" spaces XxYxR and YxR, or of the "dual" space X'xR, regarding some singleton set of the corresponding space. Moreover, the paper also provides an existence theorem for the feasible set F in terms of the closedness of certain subset of the dual space X'xR regarding the singleton set formed by the null element. These results are illustrated with significant applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.04226v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nguyen Dinh, Miguel A. Goberna, Michel Volle</dc:creator>
    </item>
    <item>
      <title>Mean field optimal stopping with uncontrolled state</title>
      <link>https://arxiv.org/abs/2503.04269</link>
      <description>arXiv:2503.04269v1 Announce Type: new 
Abstract: We study a specific class of finite-horizon mean field optimal stopping problems by means of the dynamic programming approach. In particular, we consider problems where the state process is not affected by the stopping time. Such problems arise, for instance, in the pricing of American options when the underlying asset follows a McKean-Vlasov dynamics. Due to the time inconsistency of these problems, we provide a suitable reformulation of the original problem for which a dynamic programming principle can be established. To accomplish this, we first enlarge the state space and then introduce the so-called extended value function. We prove that the Snell envelope of the original problem can be written in terms of the extended value function, from which we can derive a characterization of the smallest optimal stopping time. On the enlarged space, we restore time-consistency and in particular establish a dynamic programming principle for the extended value function. Finally, by employing the notion of Lions measure derivative, we derive the associated Hamilton-Jacobi-Bellman equation, which turns out to be a second-order variational inequality on the product space $[0, T ] \times \mathbb{R}^d \times \mathcal{P}_2(\mathbb{R}^d)$; under suitable assumptions, we prove that the extended value function is a viscosity solution to this equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.04269v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrea Cosso, Laura Perelli</dc:creator>
    </item>
    <item>
      <title>A Graph-Partitioning Based Continuous Optimization Approach to Semi-supervised Clustering Problems</title>
      <link>https://arxiv.org/abs/2503.04447</link>
      <description>arXiv:2503.04447v1 Announce Type: new 
Abstract: Semi-supervised clustering is a basic problem in various applications. Most existing methods require knowledge of the ideal cluster number, which is often difficult to obtain in practice. Besides, satisfying the must-link constraints is another major challenge for these methods. In this work, we view the semi-supervised clustering task as a partitioning problem on a graph associated with the given dataset, where the similarity matrix includes a scaling parameter to reflect the must-link constraints. Utilizing a relaxation technique, we formulate the graph partitioning problem into a continuous optimization model that does not require the exact cluster number, but only an overestimate of it. We then propose a block coordinate descent algorithm to efficiently solve this model, and establish its convergence result. Based on the obtained solution, we can construct the clusters that theoretically meet the must-link constraints under mild assumptions. Furthermore, we verify the effectiveness and efficiency of our proposed method through comprehensive numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.04447v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wei Liu, Xin Liu, Michael K. Ng, Zaikun Zhang</dc:creator>
    </item>
    <item>
      <title>Averaged Controllability of the Random Schr\"odinger Equation with Diffusivity Following Absolutely Continuous Distributions</title>
      <link>https://arxiv.org/abs/2503.04465</link>
      <description>arXiv:2503.04465v1 Announce Type: new 
Abstract: This paper is devoted to the averaged controllability of the random Schr\"odinger equation, with diffusivity as a random variable drawn from a general probability distribution. First, we show that the solutions to these random Schr\"odinger equations are null averaged controllable with an open-loop control independent of randomness from any arbitrary open set of the domain and in any time. This is done for an interesting class of random variables, including certain stable distributions, specifically recovering the known result when the random diffusivity follows a normal or Cauchy distribution. Second, by the Riemann-Lebesgue lemma, we prove for any time the lack of averaged exact controllability in a $L^2$ setting for all absolutely continuous random variables. Notably, this implies that this property is not inherited from the exact controllability of the Schr\"odinger equation. Third, we show that simultaneous null controllability is not possible except for a finite number of scenarios. Finally, we perform numerical simulations that robustly validate the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.04465v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jon Asier B\'arcena-Petisco, Fouad Et-Tahri</dc:creator>
    </item>
    <item>
      <title>A new Lagrangian approach to optimal control of second-order systems</title>
      <link>https://arxiv.org/abs/2503.04466</link>
      <description>arXiv:2503.04466v1 Announce Type: new 
Abstract: In this work, we propose and study a new approach to formulate the optimal control problem of second-order differential equations, with a particular interest in those derived from force-controlled Lagrangian systems. The formulation results in a new hyperregular control Langrangian and, thus, a new control Hamiltonian whose equations of motion provide necessary optimality conditions. We compare this approach to Pontryagin's maximum principle (PMP) in this setting, providing geometric insight into their relation. This leads us to define an extended Tulczyjew's triple with controls. Moreover, we study the relationship between Noether symmetries of this new formulation and those of the PMP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.04466v1</guid>
      <category>math.OC</category>
      <category>math-ph</category>
      <category>math.DG</category>
      <category>math.DS</category>
      <category>math.MP</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Konopik, Sigrid Leyendecker, Sofya Maslovskaya, Sina Ober-Bl\"obaum, Rodrigo T. Sato Mart\'in de Almagro</dc:creator>
    </item>
    <item>
      <title>Tight Analysis of Difference-of-Convex Algorithm (DCA) Improves Convergence Rates for Proximal Gradient Descent</title>
      <link>https://arxiv.org/abs/2503.04486</link>
      <description>arXiv:2503.04486v1 Announce Type: new 
Abstract: We investigate a difference-of-convex (DC) formulation where the second term is allowed to be weakly convex. We examine the precise behavior of a single iteration of the difference-of-convex algorithm (DCA), providing a tight characterization of the objective function decrease, distinguishing between six distinct parameter regimes.
  Our proofs, inspired by the performance estimation framework, are notably simplified compared to related prior research. We subsequently derive sublinear convergence rates for the DCA towards critical points, assuming at least one of the functions is smooth.
  Additionally, we explore the underexamined equivalence between proximal gradient descent (PGD) and DCA iterations, demonstrating how DCA, a parameter-free algorithm, without the need for a stepsize, serves as a tool for studying the exact convergence rates of PGD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.04486v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Teodor Rotaru, Panagiotis Patrinos, Fran\c{c}ois Glineur</dc:creator>
    </item>
    <item>
      <title>First-order methods on bounded-rank tensors converging to stationary points</title>
      <link>https://arxiv.org/abs/2503.04523</link>
      <description>arXiv:2503.04523v1 Announce Type: new 
Abstract: Provably finding stationary points on bounded-rank tensors turns out to be an open problem [E. Levin, J. Kileel, and N. Boumal, Math. Program., 199 (2023), pp. 831--864] due to the inherent non-smoothness of the set of bounded-rank tensors. We resolve this problem by proposing two first-order methods with guaranteed convergence to stationary points. Specifically, we revisit the variational geometry of bounded-rank tensors and explicitly characterize its normal cones. Moreover, we propose gradient-related approximate projection methods that are provable to find stationary points, where the decisive ingredients are gradient-related vectors from tangent cones, line search along approximate projections, and rank-decreasing mechanisms near rank-deficient points. Numerical experiments on tensor completion validate that the proposed methods converge to stationary points across various rank parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.04523v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.AG</category>
      <category>math.NA</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bin Gao, Renfeng Peng, Ya-xiang Yuan</dc:creator>
    </item>
    <item>
      <title>Moreau envelope and proximal-point methods under the lens of high-order regularization</title>
      <link>https://arxiv.org/abs/2503.04577</link>
      <description>arXiv:2503.04577v1 Announce Type: new 
Abstract: This paper is devoted to investigating the fundamental properties of high-order proximal operator (HOPE) and high-order Moreau envelope (HOME) in the nonconvex setting, meaning that the quadratic regularization ($p=2$) is replaced with a regularization with $p&gt;1$. After studying several basic properties of HOPE and HOME, we investigate the differentiability and weak smoothness of HOME under $q$-prox-regularity $q\geq 2$ and $p$-calmness for $p \in (1,2]$ and $2 \leq p \leq q$. Further, we design of a high-order proximal-point algorithm (HiPPA) for which the convergence of the generated sequence to proximal fixed points is studied. Our results pave the way toward the high-order smoothing theory with $p&gt;1$ that can lead to algorithmic developments in the nonconvex setting, where our numerical experiments of HiPPA on Nesterov-Chebyshev-Rosenbrock functions show the potential of this development for nonsmooth and nonconvex optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.04577v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alireza Kabgani, Masoud Ahookhosh</dc:creator>
    </item>
    <item>
      <title>Globally Finite time and Globally Fixed-time stable Dynamical Systems for solving Inverse Quasi-variational inequality problems</title>
      <link>https://arxiv.org/abs/2503.04590</link>
      <description>arXiv:2503.04590v1 Announce Type: new 
Abstract: In this paper, we propose two projection dynamical systems for solving inverse quasi-variational inequality problems in finite-dimensional Hilbert spaces-one ensuring finite-time stability and the other guaranteeing fixed-time stability. We first establish the connection between these dynamical systems and the solutions of inverse quasi-variational problems. Then, under mild conditions on the operators and parameters, we analyze the global finite-time and global fixed-time stability of the proposed systems. Both approaches offer accelerated convergence, however, while the settling time of a finite-time stable dynamical system depends on initial conditions, the fixed-time stable system achieves convergence within a predefined time, independent of initial conditions. To demonstrate their effectiveness, we provide numerical experiments, including an application to the traffic assignment problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.04590v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nam Van Tran, Le Thi Thanh Hai</dc:creator>
    </item>
    <item>
      <title>Perturbation-Aware Distributionally Robust Optimization for Inverse Problems</title>
      <link>https://arxiv.org/abs/2503.04646</link>
      <description>arXiv:2503.04646v1 Announce Type: new 
Abstract: This paper builds on classical distributionally robust optimization techniques to construct a comprehensive framework that can be used for solving inverse problems. Given an estimated distribution of inputs in $X$ and outputs in $Y$, an ambiguity set is constructed by collecting all the perturbations that belong to a prescribed set $K$ and are inside an entropy-regularized Wasserstein ball. By finding the worst-case reconstruction within $K$ one can produce reconstructions that are robust with respect to various types of perturbations: $X$-robustness, $Y|X$-robustness and, more general, targeted robustness depending on noise type, imperfect forward operators and noise anisotropies. After defining the general robust optimization problem, we derive its (weak) dual formulation and we use it to design an efficient algorithm. Finally, we demonstrate the effectiveness of our general framework to solve matrix inversion and deconvolution problems defining $K$ as the set of multivariate Gaussian perturbations in $Y|X$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.04646v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Floor van Maarschalkerwaart, Subhadip Mukherjee, Malena Sabat\'e Landman, Christoph Brune, Marcello Carioni</dc:creator>
    </item>
    <item>
      <title>Data-Driven Distributed Optimization via Aggregative Tracking and Deep-Learning</title>
      <link>https://arxiv.org/abs/2503.04668</link>
      <description>arXiv:2503.04668v1 Announce Type: new 
Abstract: In this paper, we propose a novel distributed data-driven optimization scheme. In particular, we focus on the so-called aggregative framework, namely, the scenario in which a set of agents aim to cooperatively minimize the sum of local costs, each depending on both local decision variables and an aggregation of all of them. We consider a data-driven setup in which each objective function is unknown and can be only sampled at a single point per iteration (thanks to, e.g., feedback from human users or physical sensors). We address this scenario through a distributed algorithm that combines three key components: (i) a learning part that leverages neural networks to learn the local cost functions descent direction, (ii) an optimization routine that steers the estimates according to the learned direction to minimize the global cost, and (iii) a tracking mechanism that locally reconstructs the unavailable global quantities. By using tools from system theory, i.e., timescale separation and averaging theory, we formally prove that, in strongly convex setups, the overall distributed strategy linearly converges in a neighborhood of the optimal solution whose radius depends on the given accuracy capabilities of the neural networks. Finally, we corroborate the theoretical results with numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.04668v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Riccardo Brumali, Guido Carnevale, Giuseppe Notarstefano</dc:creator>
    </item>
    <item>
      <title>Efficiently Escaping Saddle Points under Generalized Smoothness via Self-Bounding Regularity</title>
      <link>https://arxiv.org/abs/2503.04712</link>
      <description>arXiv:2503.04712v1 Announce Type: new 
Abstract: In this paper, we study the problem of non-convex optimization on functions that are not necessarily smooth using first order methods. Smoothness (functions whose gradient and/or Hessian are Lipschitz) is not satisfied by many machine learning problems in both theory and practice, motivating a recent line of work studying the convergence of first order methods to first order stationary points under appropriate generalizations of smoothness.
  We develop a novel framework to study convergence of first order methods to first and \textit{second} order stationary points under generalized smoothness, under more general smoothness assumptions than the literature. Using our framework, we show appropriate variants of GD and SGD (e.g. with appropriate perturbations) can converge not just to first order but also \textit{second order stationary points} in runtime polylogarithmic in the dimension. To our knowledge, our work contains the first such result, as well as the first 'non-textbook' rate for non-convex optimization under generalized smoothness. We demonstrate that several canonical non-convex optimization problems fall under our setting and framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.04712v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Yiming Cao, August Y. Chen, Karthik Sridharan, Benjamin Tang</dc:creator>
    </item>
    <item>
      <title>Reheated Gradient-based Discrete Sampling for Combinatorial Optimization</title>
      <link>https://arxiv.org/abs/2503.04047</link>
      <description>arXiv:2503.04047v1 Announce Type: cross 
Abstract: Recently, gradient-based discrete sampling has emerged as a highly efficient, general-purpose solver for various combinatorial optimization (CO) problems, achieving performance comparable to or surpassing the popular data-driven approaches. However, we identify a critical issue in these methods, which we term ''wandering in contours''. This behavior refers to sampling new different solutions that share very similar objective values for a long time, leading to computational inefficiency and suboptimal exploration of potential solutions. In this paper, we introduce a novel reheating mechanism inspired by the concept of critical temperature and specific heat in physics, aimed at overcoming this limitation. Empirically, our method demonstrates superiority over existing sampling-based and data-driven algorithms across a diverse array of CO problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.04047v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Muheng Li, Ruqi Zhang</dc:creator>
    </item>
    <item>
      <title>Fredholm Approach to Nonlinear Propagator Models</title>
      <link>https://arxiv.org/abs/2503.04323</link>
      <description>arXiv:2503.04323v1 Announce Type: cross 
Abstract: We formulate and solve an optimal trading problem with alpha signals, where transactions induce a nonlinear transient price impact described by a general propagator model, including power-law decay. Using a variational approach, we demonstrate that the optimal trading strategy satisfies a nonlinear stochastic Fredholm equation with both forward and backward coefficients. We prove the existence and uniqueness of the solution under a monotonicity condition reflecting the nonlinearity of the price impact. Moreover, we derive an existence result for the optimal strategy beyond this condition when the underlying probability space is countable. In addition, we introduce a novel iterative scheme and establish its convergence to the optimal trading strategy. Finally, we provide a numerical implementation of the scheme that illustrates its convergence, stability, and the effects of concavity on optimal execution strategies under exponential and power-law decay.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.04323v1</guid>
      <category>q-fin.MF</category>
      <category>math.OC</category>
      <category>q-fin.TR</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eduardo Abi Jaber, Alessandro Bondi, Nathan De Carvalho, Eyal Neuman, Sturmius Tuschmann</dc:creator>
    </item>
    <item>
      <title>Optimal interpolation-based coordinate descent method for parameterized quantum circuits</title>
      <link>https://arxiv.org/abs/2503.04620</link>
      <description>arXiv:2503.04620v1 Announce Type: cross 
Abstract: Parameterized quantum circuits appear ubiquitously in the design of many quantum algorithms, such as variational quantum algorithms, where the optimization of parameters is crucial for algorithmic efficiency. In this work, we propose an Optimal Interpolation-based Coordinate Descent (OICD) method to solve the parameter optimization problem that arises in parameterized quantum circuits. Our OICD method employs an interpolation technique to approximate the cost function of a parameterized quantum circuit, effectively recovering its trigonometric characteristics, then performs an argmin update on a single parameter per iteration on a classical computer. We determine the optimal interpolation nodes in our OICD method to mitigate the impact of statistical errors from quantum measurements. Additionally, for the case of equidistant frequencies -- commonly encountered when the Hermitian generators are Pauli operators -- we show that the optimal interpolation nodes are equidistant nodes, and our OICD method can simultaneously minimize the mean squared error, the condition number of the interpolation matrix, and the average variance of derivatives of the cost function. We perform numerical simulations of our OICD method using Qiskit Aer and test its performance on the maxcut problem, the transverse field Ising model, and the XXZ model. Numerical results imply that our OICD method is more efficient than the commonly used stochastic gradient descent method and the existing random coordinate descent method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.04620v1</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhijian Lai, Jiang Hu, Taehee Ko, Jiayuan Wu, Dong An</dc:creator>
    </item>
    <item>
      <title>A Method for Establishing Asymptotically Accurate Bounds for Extremal Roots of Eulerian Polynomials Using Polynomial Stability Preservers</title>
      <link>https://arxiv.org/abs/2503.04628</link>
      <description>arXiv:2503.04628v1 Announce Type: cross 
Abstract: We develop the tools to bound extreme roots of multivariate real zero polynomials globally. This is done through the use of a relaxation that approximates their rigidly convex sets. This relaxation can easily be constructed using the degree $3$ truncation of the polynomial and it produces in this way a spectrahedron whose computation is relatively easy and whose size is relatively small and depending solely on the number of variables of the polynomial. As we know that, in order to be able to produce in general spectrahedral representations of rigidly convex sets it is necessary to build matrices of very big size, we try, analyze and experiment with several constructions that could increase the size of these matrices. These constructions are based principally in two main approaches: adding information about higher degree monomials or non-trivially increasing the number of variables of the original polynomial. We explore these two construction first in a general setting and see that it is necessary to particularize to certain families of polynomials in order to make them work. In particular, we are able to prove that increasing the number of variables improves the behavior of the relaxation along the diagonal in the case of Eulerian polynomials. We see that applying the relaxation to multivariate Eulerian polynomials and then looking at the univariate polynomials injected in their diagonals produces an exponential asymptotic improvement in the bounds provided. We compare these bounds with other bounds that have appeared previously in the literature and refine these previous bounds in order to study how close do the bounds provided by the relaxation are to the actual roots of the univariate Eulerian polynomials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.04628v1</guid>
      <category>math.CO</category>
      <category>cs.NA</category>
      <category>math.AG</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Alejandro Gonz\'alez Nevado</dc:creator>
    </item>
    <item>
      <title>Transferable Foundation Models for Geometric Tasks on Point Cloud Representations: Geometric Neural Operators</title>
      <link>https://arxiv.org/abs/2503.04649</link>
      <description>arXiv:2503.04649v1 Announce Type: cross 
Abstract: We introduce methods for obtaining pretrained Geometric Neural Operators (GNPs) that can serve as basal foundation models for use in obtaining geometric features. These can be used within data processing pipelines for machine learning tasks and numerical methods. We show how our GNPs can be trained to learn robust latent representations for the differential geometry of point-clouds to provide estimates of metric, curvature, and other shape-related features. We demonstrate how our pre-trained GNPs can be used (i) to estimate the geometric properties of surfaces of arbitrary shape and topologies with robustness in the presence of noise, (ii) to approximate solutions of geometric partial differential equations (PDEs) on manifolds, and (iii) to solve equations for shape deformations such as curvature driven flows. We also release a package of the codes and weights for using our pre-trained GNPs for processing point cloud representations. This allows for incorporating our pre-trained GNPs as components for reuse within existing and new data processing pipelines. The GNPs also can be used as part of numerical solvers involving geometry or as part of methods for performing inference and other geometric tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.04649v1</guid>
      <category>cs.LG</category>
      <category>cs.CV</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Blaine Quackenbush, Paul J. Atzberger</dc:creator>
    </item>
    <item>
      <title>Posted Price versus Hybrid Mechanisms in Freight Transportation Marketplaces</title>
      <link>https://arxiv.org/abs/2106.00923</link>
      <description>arXiv:2106.00923v3 Announce Type: replace 
Abstract: We consider a freight platform that serves as an intermediary between shippers and carriers in a truckload transportation network. The platform's objective is to design a policy that determines prices for shippers and payments to carriers, as well as how carriers are matched to loads to be transported, to maximize its long-run average profit. We propose a two-stage decision framework to model carriers' load choice behavior, where carriers choose a lane according to the multinomial logit (MNL) model based on the platform's posted price in the first stage and book a load in the second stage. We analyze two types of carrier-side mechanisms commonly used by freight platforms: a posted price mechanism and a hybrid mechanism where carriers can either book loads at posted price or submit their bids in an auction. The proposed mechanisms are constructed using a fluid approximation model to incorporate carrier interactions in the freight network. We show that the hybrid mechanism has higher profits than the posted price mechanism. We prove tight bounds between these mechanisms for varying market sizes. The findings are validated through a numerical simulation using industry data from the U.S. freight market.</description>
      <guid isPermaLink="false">oai:arXiv.org:2106.00923v3</guid>
      <category>math.OC</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruoran Chen, Sungwoo Kim, He Wang, Xuan Wang</dc:creator>
    </item>
    <item>
      <title>Probable Event Constrained Optimization and A Data-embedded Solution Paradigm</title>
      <link>https://arxiv.org/abs/2209.01119</link>
      <description>arXiv:2209.01119v3 Announce Type: replace 
Abstract: This paper solves a new class of optimization problems under uncertainty, called Probable Event Constrained Optimization (PECO), which optimizes an objective function of decision variables and subjects to a set of Probable Event Constraints (PEC). This new type of constraint guarantees that optimal solutions are feasible for all uncertain events whose joint probabilities are greater than a user-defined threshold. The PEC can be used as an alternative to the conventional chance constraint, while the latter cannot guarantee the solution's feasibility to high-probability uncertain events. Given that the existing solution methods of optimization problems under uncertainty are not suitable for solving PECO problems, we develop a novel data-embedded solution paradigm that uses historical measurements/data of the uncertain parameters as input samples. This solution paradigm is conceptually simple and allows us to develop effective data-reduction schemes which reduce computational burden while preserving high accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.01119v3</guid>
      <category>math.OC</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qifeng Li</dc:creator>
    </item>
    <item>
      <title>Goh and Legendre-Clebsh conditions for nonsmooth control systems</title>
      <link>https://arxiv.org/abs/2308.06867</link>
      <description>arXiv:2308.06867v3 Announce Type: replace 
Abstract: Higher order necessary conditions for a minimizer of an optimal control problem are generally obtained for systems whose dynamics is at least continuously differentiable in the state variable. Here, by making use of the notion of set-valued Lie bracket introduced in "Set-valued differentials and a nonsmooth version of Chow-Rashevski's theorem" by F. Rampazzo and H.J.Sussmann and extended in "Iterated Lie brackets for nonsmooth vector fields" by E. Feleqi and F.Rampazzo , we obtain Goh and Legendre-Clebsh type conditions for a control affine system with Lipschitz continuous dynamics. In order to manage the simultaneous lack of smoothness of the adjoint equation and of the Lie bracket-like variations, we will exploit the notion of Quasi Differential Quotient, introduced in "A geometrically based criterion to avoid infimum-gaps in Optimal Control" by M. Palladino and F.Rampazzo. We finally exhibit an example where the established higher order condition is capable to rule out the optimality of a control verifying a first order Maximum Principle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.06867v3</guid>
      <category>math.OC</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Francesca Angrisani, Franco Rampazzo</dc:creator>
    </item>
    <item>
      <title>Deep Reinforcement Learning for Infinite Horizon Mean Field Problems in Continuous Spaces</title>
      <link>https://arxiv.org/abs/2309.10953</link>
      <description>arXiv:2309.10953v3 Announce Type: replace 
Abstract: We present the development and analysis of a reinforcement learning (RL) algorithm designed to solve continuous-space mean field game (MFG) and mean field control (MFC) problems in a unified manner. The proposed approach pairs the actor-critic (AC) paradigm with a representation of the mean field distribution via a parameterized score function, which can be efficiently updated in an online fashion, and uses Langevin dynamics to obtain samples from the resulting distribution. The AC agent and the score function are updated iteratively to converge, either to the MFG equilibrium or the MFC optimum for a given mean field problem, depending on the choice of learning rates. A straightforward modification of the algorithm allows us to solve mixed mean field control games (MFCGs). The performance of our algorithm is evaluated using linear-quadratic benchmarks in the asymptotic infinite horizon framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.10953v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4208/jml.230919</arxiv:DOI>
      <dc:creator>Andrea Angiuli, Jean-Pierre Fouque, Ruimeng Hu, Alan Raydan</dc:creator>
    </item>
    <item>
      <title>On Discrete Subproblems in Integer Optimal Control with Total Variation Regularization in Two Dimensions</title>
      <link>https://arxiv.org/abs/2403.09213</link>
      <description>arXiv:2403.09213v3 Announce Type: replace 
Abstract: We analyze integer linear programs which we obtain after discretizing two-dimensional subproblems arising from a trust-region algorithm for mixed integer optimal control problems with total variation regularization. We discuss NP-hardness of the discretized problems and the connection to graph-based problems. We show that the underlying polyhedron exhibits structural restrictions in its vertices with regards to which variables can attain fractional values at the same time. Based on this property, we derive cutting planes by employing a relation to shortest-path and minimum bisection problems. We propose a branching rule and a primal heuristic which improves previously found feasible points. We validate the proposed tools with a numerical benchmark in a standard integer programming solver. We observe a significant speedup for medium-sized problems. Our results give hints for scaling towards larger instances in the future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09213v3</guid>
      <category>math.OC</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paul Manns, Marvin Severitt</dc:creator>
    </item>
    <item>
      <title>Learning truly monotone operators with applications to nonlinear inverse problems</title>
      <link>https://arxiv.org/abs/2404.00390</link>
      <description>arXiv:2404.00390v2 Announce Type: replace 
Abstract: This article introduces a novel approach to learning monotone neural networks through a newly defined penalization loss. The proposed method is particularly effective in solving classes of variational problems, specifically monotone inclusion problems, commonly encountered in image processing tasks. The Forward-Backward-Forward (FBF) algorithm is employed to address these problems, offering a solution even when the Lipschitz constant of the neural network is unknown. Notably, the FBF algorithm provides convergence guarantees under the condition that the learned operator is monotone. Building on plug-and-play methodologies, our objective is to apply these newly learned operators to solving non-linear inverse problems. To achieve this, we initially formulate the problem as a variational inclusion problem. Subsequently, we train a monotone neural network to approximate an operator that may not inherently be monotone. Leveraging the FBF algorithm, we then show simulation examples where the non-linear inverse problem is successfully solved.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00390v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Younes Belkouchi, Jean-Christophe Pesquet, Audrey Repetti, Hugues Talbot</dc:creator>
    </item>
    <item>
      <title>Flows of vector fields and the Kalman Theorem</title>
      <link>https://arxiv.org/abs/2412.07438</link>
      <description>arXiv:2412.07438v2 Announce Type: replace 
Abstract: We give two proofs of the Kalman Theorem, alternative to the most common ones, which infer such a classical result of Control Theory using just very basic facts on flows of vector fields. These proofs are apt to be generalised in diverse directions -- in fact one of them has been already generalised, yielding new criteria for local controllability of non-linear real analytic controlled systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.07438v2</guid>
      <category>math.OC</category>
      <category>math.DG</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fabio Bagagiolo, Cristina Giannotti, Andrea Spiro, Marta Zoppello</dc:creator>
    </item>
    <item>
      <title>A learning-based approach to stochastic optimal control under reach-avoid constraint</title>
      <link>https://arxiv.org/abs/2412.16561</link>
      <description>arXiv:2412.16561v2 Announce Type: replace 
Abstract: We develop a model-free approach to optimally control stochastic, Markovian systems subject to a reach-avoid constraint. Specifically, the state trajectory must remain within a safe set while reaching a target set within a finite time horizon. Due to the time-dependent nature of these constraints, we show that, in general, the optimal policy for this constrained stochastic control problem is non-Markovian, which increases the computational complexity. To address this challenge, we apply the state-augmentation technique from arXiv:2402.19360, reformulating the problem as a constrained Markov decision process (CMDP) on an extended state space. This transformation allows us to search for a Markovian policy, avoiding the complexity of non-Markovian policies. To learn the optimal policy without a system model, and using only trajectory data, we develop a log-barrier policy gradient approach. We prove that under suitable assumptions, the policy parameters converge to the optimal parameters, while ensuring that the system trajectories satisfy the stochastic reach-avoid constraint with high probability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16561v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3716863.3718055</arxiv:DOI>
      <arxiv:journal_reference>28th ACM International Conference on Hybrid Systems: Computation and Control (HSCC '25), May 6-9, 2025</arxiv:journal_reference>
      <dc:creator>Tingting Ni, Maryam Kamgarpour</dc:creator>
    </item>
    <item>
      <title>A Laplace duality for integration</title>
      <link>https://arxiv.org/abs/2502.20842</link>
      <description>arXiv:2502.20842v2 Announce Type: replace 
Abstract: We consider the integral v(y) = Ky f (x)dx on a domain Ky = {x $\in$ R d : g(x) $\le$ y}, where g is nonnegative and Ky is compact for all y $\in$ [0, +$\infty$). Under some assumptions, we show that for every y $\in$ (0, $\infty$) there exists a distinguished scalar $\lambda$y $\in$ (0, +$\infty$) such that which is the counterpart analogue for integration of Lagrangian duality for optimization. A crucial ingredient is the Laplace transform, the analogue for integration of Legendre-Fenchel transform in optimization. In particular, if both f and g are positively homogeneous then $\lambda$y is a simple explicitly rational function of y. In addition if g is quadratic form then computing v(y) reduces to computing the integral of f with respect to a specific Gaussian measure for which exact and approximate numerical methods (e.g. cubatures) are available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20842v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jean B Lasserre (LAAS-POP, TSE-R)</dc:creator>
    </item>
    <item>
      <title>Tutorial on amortized optimization</title>
      <link>https://arxiv.org/abs/2202.00665</link>
      <description>arXiv:2202.00665v4 Announce Type: replace-cross 
Abstract: Optimization is a ubiquitous modeling tool and is often deployed in settings which repeatedly solve similar instances of the same problem. Amortized optimization methods use learning to predict the solutions to problems in these settings, exploiting the shared structure between similar problem instances. These methods have been crucial in variational inference and reinforcement learning and are capable of solving optimization problems many orders of magnitudes times faster than traditional optimization methods that do not use amortization. This tutorial presents an introduction to the amortized optimization foundations behind these advancements and overviews their applications in variational inference, sparse coding, gradient-based meta-learning, control, reinforcement learning, convex optimization, optimal transport, and deep equilibrium networks. The source code for this tutorial is available at https://github.com/facebookresearch/amortized-optimization-tutorial.</description>
      <guid isPermaLink="false">oai:arXiv.org:2202.00665v4</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Brandon Amos</dc:creator>
    </item>
    <item>
      <title>Introduction to Online Control</title>
      <link>https://arxiv.org/abs/2211.09619</link>
      <description>arXiv:2211.09619v4 Announce Type: replace-cross 
Abstract: This text presents an introduction to an emerging paradigm in control of dynamical systems and differentiable reinforcement learning called online nonstochastic control. The new approach applies techniques from online convex optimization and convex relaxations to obtain new methods with provable guarantees for classical settings in optimal and robust control.
  The primary distinction between online nonstochastic control and other frameworks is the objective. In optimal control, robust control, and other control methodologies that assume stochastic noise, the goal is to perform comparably to an offline optimal strategy. In online nonstochastic control, both the cost functions as well as the perturbations from the assumed dynamical model are chosen by an adversary. Thus the optimal policy is not defined a priori. Rather, the target is to attain low regret against the best policy in hindsight from a benchmark class of policies.
  This objective suggests the use of the decision making framework of online convex optimization as an algorithmic methodology. The resulting methods are based on iterative mathematical optimization algorithms, and are accompanied by finite-time regret and computational complexity guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.09619v4</guid>
      <category>cs.LG</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Elad Hazan, Karan Singh</dc:creator>
    </item>
    <item>
      <title>Dynamic Scheduling of a Multiclass Queue in the Halfin-Whitt Regime: A Computational Approach for High-Dimensional Problems</title>
      <link>https://arxiv.org/abs/2311.18128</link>
      <description>arXiv:2311.18128v2 Announce Type: replace-cross 
Abstract: We consider a multi-class queueing model of a telephone call center, in which a system manager dynamically allocates available servers to customer calls. Calls can terminate through either service completion or customer abandonment, and the manager strives to minimize the expected total of holding costs plus abandonment costs over a finite horizon. Focusing on the Halfin-Whitt heavy traffic regime, we derive an approximating diffusion control problem, and building on earlier work by Beck et al. (2021), develop a simulation-based computational method for solution of such problems, one that relies heavily on deep neural network technology. Using this computational method, we propose a policy for the original (pre-limit) call center scheduling problem. Finally, the performance of this policy is assessed using test problems based on publicly available call center data. For the test problems considered so far, our policy does as well as or better than the best benchmark we could find. Moreover, our method is computationally feasible at least up to dimension 500, that is, for call centers with 500 or more distinct customer classes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.18128v2</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Baris Ata, Ebru Kasikaralar</dc:creator>
    </item>
    <item>
      <title>CONGO: Compressive Online Gradient Optimization</title>
      <link>https://arxiv.org/abs/2407.06325</link>
      <description>arXiv:2407.06325v3 Announce Type: replace-cross 
Abstract: We address the challenge of zeroth-order online convex optimization where the objective function's gradient exhibits sparsity, indicating that only a small number of dimensions possess non-zero gradients. Our aim is to leverage this sparsity to obtain useful estimates of the objective function's gradient even when the only information available is a limited number of function samples. Our motivation stems from the optimization of large-scale queueing networks that process time-sensitive jobs. Here, a job must be processed by potentially many queues in sequence to produce an output, and the service time at any queue is a function of the resources allocated to that queue. Since resources are costly, the end-to-end latency for jobs must be balanced with the overall cost of the resources used. While the number of queues is substantial, the latency function primarily reacts to resource changes in only a few, rendering the gradient sparse. We tackle this problem by introducing the Compressive Online Gradient Optimization framework which allows compressive sensing methods previously applied to stochastic optimization to achieve regret bounds with an optimal dependence on the time horizon without the full problem dimension appearing in the bound. For specific algorithms, we reduce the samples required per gradient estimate to scale with the gradient's sparsity factor rather than its full dimensionality. Numerical simulations and real-world microservices benchmarks demonstrate CONGO's superiority over gradient descent approaches that do not account for sparsity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06325v3</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>math.OC</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jeremy Carleton, Prathik Vijaykumar, Divyanshu Saxena, Dheeraj Narasimha, Srinivas Shakkottai, Aditya Akella</dc:creator>
    </item>
    <item>
      <title>From Data to Predictive Control: A Framework for Stochastic Linear Systems with Output Measurements</title>
      <link>https://arxiv.org/abs/2407.17277</link>
      <description>arXiv:2407.17277v2 Announce Type: replace-cross 
Abstract: We introduce data to predictive control, D2PC, a framework to facilitate the design of robust and predictive controllers from data. The proposed framework is designed for discrete-time stochastic linear systems with output measurements and provides a principled design of a predictive controller based on data. The framework starts with a parameter identification method based on the Expectation-Maximization algorithm, which incorporates pre-defined structural constraints. Additionally, we provide an asymptotically correct method to quantify uncertainty in parameter estimates. Next, we develop a strategy to synthesize robust dynamic output-feedback controllers tailored to the derived uncertainty characterization. Finally, we introduce a predictive control scheme that guarantees recursive feasibility and satisfaction of chance constraints. This framework marks a significant advancement in integrating data into robust and predictive control schemes. We demonstrate the efficacy of D2PC through a numerical example involving a 10-dimensional spring-mass-damper system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17277v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haldun Balim, Andrea Carron, Melanie N. Zeilinger, Johannes K\"ohler</dc:creator>
    </item>
    <item>
      <title>Fractional Sobolev paths on Wasserstein spaces and their energy-minimizing particle representations</title>
      <link>https://arxiv.org/abs/2502.12068</link>
      <description>arXiv:2502.12068v2 Announce Type: replace-cross 
Abstract: We study a generalization of Kantorovich's optimal transportation problem. Given a prescribed family of time-dependent probability measures $(\mu_t)$, we aim to find, among all path-continuous stochastic processes whose one-dimensional time marginals coincide with $(\mu_t)$ (if there is any), a process that minimizes a given energy. After discussing a sufficient condition for the energy to ensure the existence of a minimizer, we investigate fractional Sobolev energies. Given a deterministic path $(\mu_t)$ on a $p$-Wasserstein space with fractional Sobolev regularity $W^{\alpha,p}$, where $1/p &lt; \alpha &lt; 1$, we provide conditions under which we prove the existence of a process that minimizes the energy and construct a process that realizes the regularity of $(\mu_t)$. While continuous paths of low regularity on Wasserstein spaces naturally appear in stochastic analysis, they can also arise deterministically as solutions to the continuity equation. This paper is devoted to the deterministic setting to gain some understanding of the required conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12068v2</guid>
      <category>math.MG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ehsan Abedi</dc:creator>
    </item>
    <item>
      <title>Deep unrolling for learning optimal spatially varying regularisation parameters for Total Generalised Variation</title>
      <link>https://arxiv.org/abs/2502.16532</link>
      <description>arXiv:2502.16532v2 Announce Type: replace-cross 
Abstract: We extend a recently introduced deep unrolling framework for learning spatially varying regularisation parameters in inverse imaging problems to the case of Total Generalised Variation (TGV). The framework combines a deep convolutional neural network (CNN) inferring the two spatially varying TGV parameters with an unrolled algorithmic scheme that solves the corresponding variational problem. The two subnetworks are jointly trained end-to-end in a supervised fashion and as such the CNN learns to compute those parameters that drive the reconstructed images as close to the ground truth as possible. Numerical results in image denoising and MRI reconstruction show a significant qualitative and quantitative improvement compared to the best TGV scalar parameter case as well as to other approaches employing spatially varying parameters computed by unsupervised methods. We also observe that the inferred spatially varying parameter maps have a consistent structure near the image edges, asking for further theoretical investigations. In particular, the parameter that weighs the first-order TGV term has a triple-edge structure with alternating high-low-high values whereas the one that weighs the second-order term attains small values in a large neighbourhood around the edges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16532v2</guid>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Thanh Trung Vu, Andreas Kofler, Kostas Papafitsoros</dc:creator>
    </item>
    <item>
      <title>Local minimizers in $3$d of vector Allen-Cahn with a quadruple junction</title>
      <link>https://arxiv.org/abs/2502.17687</link>
      <description>arXiv:2502.17687v2 Announce Type: replace-cross 
Abstract: For $\Omega$ a perturbation of the unit ball in $\mathbb{R}^3$, we establish the existence of a sequence of local minimizers for the vector Allen-Cahn energy. The sequence converges in $L^1$ to a partition of $\Omega$ whose skeleton is given by a tetrahedral cone and thus contains a quadruple point. This is accomplished by proving that the partition is an isolated local minimizer of a weighted perimeter problem arising as the associated $\Gamma$-limit of the sequence of Allen-Cahn functionals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.17687v2</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Abhishek Adimurthi, Peter Sternberg</dc:creator>
    </item>
    <item>
      <title>Tracking Control of Euler-Lagrangian Systems with Prescribed State, Input, and Temporal Constraints</title>
      <link>https://arxiv.org/abs/2503.01866</link>
      <description>arXiv:2503.01866v2 Announce Type: replace-cross 
Abstract: The synthesis of a smooth tracking control policy for Euler-Lagrangian (EL) systems with stringent regions of operation induced by state, input and temporal (SIT) constraints is a very challenging task. In contrast with existing methods that utilize prior knowledge of EL model parameters and uncertainty bounds, this study proposes an approximation-free adaptive barrier function-based control policy to ensure local prescribed time convergence of tracking error under state and input constraints. The proposed control policy accomplishes this by utilizing smooth time-based generator functions embedded in the filtered tracking error, which is combined with a saturation function that limits control action and confines states within the prescribed limits by enforcing the time-varying bounds on the filtered tracking error. Importantly, corresponding feasibility conditions pertaining to the minimum control authority, maximum disturbance rejection capability of the control policy, and the viable set of initial conditions are derived, illuminating the narrow operating domain of the EL systems arising from the interplay of SIT constraints. Numerical validation studies with three different robotic manipulators are employed to demonstrate the efficacy of the proposed scheme. A detailed performance comparison study with leading alternative designs is also undertaken to illustrate the superior performance of the proposed scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01866v2</guid>
      <category>eess.SY</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Chidre Shravista Kashyap, Pushpak Jagtap, Jishnu Keshavan</dc:creator>
    </item>
    <item>
      <title>Is Bellman Equation Enough for Learning Control?</title>
      <link>https://arxiv.org/abs/2503.02171</link>
      <description>arXiv:2503.02171v2 Announce Type: replace-cross 
Abstract: The Bellman equation and its continuous-time counterpart, the Hamilton-Jacobi-Bellman (HJB) equation, serve as necessary conditions for optimality in reinforcement learning and optimal control. While the value function is known to be the unique solution to the Bellman equation in tabular settings, we demonstrate that this uniqueness fails to hold in continuous state spaces. Specifically, for linear dynamical systems, we prove the Bellman equation admits at least $\binom{2n}{n}$ solutions, where $n$ is the state dimension. Crucially, only one of these solutions yields both an optimal policy and a stable closed-loop system. We then demonstrate a common failure mode in value-based methods: convergence to unstable solutions due to the exponential imbalance between admissible and inadmissible solutions. Finally, we introduce a positive-definite neural architecture that guarantees convergence to the stable solution by construction to address this issue.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02171v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haoxiang You, Lekan Molu, Ian Abraham</dc:creator>
    </item>
  </channel>
</rss>
