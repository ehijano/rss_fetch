<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DL</link>
    <description>cs.DL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 15 Apr 2025 04:01:32 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Lowering the Cost of Diamond Open Access Journals</title>
      <link>https://arxiv.org/abs/2504.10424</link>
      <description>arXiv:2504.10424v1 Announce Type: new 
Abstract: Many scholarly societies face challenges in adapting their publishing to an open access model where neither authors nor readers pay any fees. Some have argued that one of the main barriers is the actual cost of publishing. The goal of this paper is to show that the actual costs can be extremely low while still maintaining scholarly quality. We accomplish this by building a journal publishing workflow that minimizes the amount of required human labor. We recently built a software system for this and launched a journal using the system, and we estimate estimate our cost to publish this journal is approximately \$705 per year, plus \$1 per article and about 10 minutes of volunteer labor per article. We benefited from two factors, namely the fact that authors in our discipline use LaTeX to prepare their manuscripts, and we had volunteer labor to develop software and run the journal. We have made most of this software open source in the hopes that it can help others.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10424v1</guid>
      <category>cs.DL</category>
      <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joppe Bos, Kevin S. McCurley</dc:creator>
    </item>
    <item>
      <title>A Quantitative Approach to Evaluating Open-Source EHR Systems for Indian Healthcare</title>
      <link>https://arxiv.org/abs/2504.08750</link>
      <description>arXiv:2504.08750v1 Announce Type: cross 
Abstract: The increasing use of Electronic Health Records (EHR) has emphasized the need for standardization and interoperability in healthcare data management. The Ministry of Health and Family Welfare, Government of India, has introduced the Electronic Health Record Minimum Data Set (EHRMDS) to facilitate uniformity in clinical documentation. However, the compatibility of Open-Source Electronic Health Record Systems (OS-EHRS) with EHRMDS remains largely unexplored. This study conducts a systematic assessment of the alignment between EHRMDS and commonly utilized OS-EHRS to determine the most appropriate system for healthcare environments in India. A quantitative closeness analysis was performed by comparing the metadata elements of EHRMDS with those of 10 selected OS-EHRS. Using crosswalk methodologies based on syntactic and semantic similarity, the study measured the extent of metadata alignment. Results indicate that OpenEMR exhibits the highest compatibility with EHRMDS, covering 73.81% of its metadata elements, while OpenClinic shows the least alignment at 33.33%. Additionally, the analysis identified 47 metadata elements present in OS-EHRS but absent in EHRMDS, suggesting the need for an extended metadata schema. By bridging gaps in clinical metadata, this study contributes to enhancing the interoperability of EHR systems in India. The findings provide valuable insights for healthcare policymakers and organizations seeking to adopt OS-EHRS aligned with national standards. Keywords. EHR metadata, electronic health record systems, EHRMDS, meta data, structured vocabularies, metadata crosswalk, methodologies and tools, SNOMED-CT, UMLS terms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.08750v1</guid>
      <category>cs.IR</category>
      <category>cs.DL</category>
      <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Biswanath Dutta, Debanjali Bain</dc:creator>
    </item>
    <item>
      <title>Knowledge Independence Breeds Disruption but Limits Recognition</title>
      <link>https://arxiv.org/abs/2504.09589</link>
      <description>arXiv:2504.09589v1 Announce Type: cross 
Abstract: Recombinant growth theory highlights the pivotal role of cumulative knowledge in driving innovation. Although interconnected knowledge facilitates smoother dissemination, its connection to scientific disruption remains poorly understood. Here, we quantify knowledge dependence based on the degree to which references within a given paper's bibliography cite one another. Analyzing 53.8 million papers spanning six decades, we observe that papers built on independent knowledge have decreased over time. However, propensity score matching and regression analyses reveal that such papers are associated with greater scientific disruption, as those who cite them are less likely to cite their references. Moreover, a team's preference for independent knowledge amplifies its disruptive potential, regardless of team size, geographic distance, or collaboration freshness. Despite the disruptive nature, papers built on independent knowledge receive fewer citations and delayed recognition. Taken together, these findings fill a critical gap in our fundamental understanding of scientific innovation, revealing a universal law in peer recognition: Knowledge independence breeds disruption at the cost of impact.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.09589v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.DL</category>
      <category>cs.SI</category>
      <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaoyao Yu, Talal Rahwan, Tao Jia</dc:creator>
    </item>
    <item>
      <title>Analyzing 16,193 LLM Papers for Fun and Profits</title>
      <link>https://arxiv.org/abs/2504.08619</link>
      <description>arXiv:2504.08619v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) are reshaping the landscape of computer science research, driving significant shifts in research priorities across diverse conferences and fields. This study provides a comprehensive analysis of the publication trend of LLM-related papers in 77 top-tier computer science conferences over the past six years (2019-2024). We approach this analysis from four distinct perspectives: (1) We investigate how LLM research is driving topic shifts within major conferences. (2) We adopt a topic modeling approach to identify various areas of LLM-related topic growth and reveal the topics of concern at different conferences. (3) We explore distinct contribution patterns of academic and industrial institutions. (4) We study the influence of national origins on LLM development trajectories. Synthesizing the findings from these diverse analytical angles, we derive ten key insights that illuminate the dynamics and evolution of the LLM research ecosystem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.08619v2</guid>
      <category>cs.DL</category>
      <category>cs.CL</category>
      <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhiqiu Xia, Lang Zhu, Bingzhe Li, Feng Chen, Qiannan Li, Hang Liu</dc:creator>
    </item>
  </channel>
</rss>
