<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SI</link>
    <description>cs.SI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 24 Oct 2024 01:59:16 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Efficient and Effective Algorithms for A Family of Influence Maximization Problems with A Matroid Constraint</title>
      <link>https://arxiv.org/abs/2410.16603</link>
      <description>arXiv:2410.16603v1 Announce Type: new 
Abstract: Influence maximization (IM) is a classic problem that aims to identify a small group of critical individuals, known as seeds, who can influence the largest number of users in a social network through word-of-mouth. This problem finds important applications including viral marketing, infection detection, and misinformation containment. The conventional IM problem is typically studied with the oversimplified goal of selecting a single seed set. Many real-world scenarios call for multiple sets of seeds, particularly on social media platforms where various viral marketing campaigns need different sets of seeds to propagate effectively. To this end, previous works have formulated various IM variants, central to which is the requirement of multiple seed sets, naturally modeled as a matroid constraint. However, the current best-known solutions for these variants either offer a weak $(1/2-\epsilon)$-approximation, or offer a $(1-1/e-\epsilon)$-approximation algorithm that is very expensive. We propose an efficient seed selection method called AMP, an algorithm with a $(1-1/e-\epsilon)$-approximation guarantee for this family of IM variants. To further improve efficiency, we also devise a fast implementation, called RAMP. We extensively evaluate the performance of our proposal against 6 competitors across 4 IM variants and on 7 real-world networks, demonstrating that our proposal outperforms all competitors in terms of result quality, running time, and memory usage. We have also deployed RAMP in a real industry strength application involving online gaming, where we show that our deployed solution significantly improves upon the baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16603v1</guid>
      <category>cs.SI</category>
      <category>cs.DB</category>
      <pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yiqian Huang, Shiqi Zhang, Laks V. S. Lakshmanan, Wenqing Lin, Xiaokui Xiao, Bo Tang</dc:creator>
    </item>
    <item>
      <title>FastGEMF: Scalable High-Speed Simulation of Stochastic Spreading Processes over Complex Multilayer Networks</title>
      <link>https://arxiv.org/abs/2410.16625</link>
      <description>arXiv:2410.16625v1 Announce Type: new 
Abstract: Predicting the spread of processes across complex multi-layered networks has long challenged researchers due to the intricate interplay between network structure and propagation dynamics. Each layer of these networks possesses unique characteristics, further complicating analysis. To authors' knowledge, a comprehensive framework capable of simulating various spreading processes across different layers, particularly in networks with millions of nodes and connections, has been notably absent. This study introduces a novel framework that efficiently predicts Markov Chain processes over large-scale networks, while significantly reducing time and space complexity. This approach enables exact simulation of spreading processes across extensive real-world multi-layer networks, accounting for diverse influencers on each layer. FastGEMF provides a baseline framework for exact simulating stochastic spread processes, facilitating comparative analysis of models across diverse domains, from epidemiology to social media dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16625v1</guid>
      <category>cs.SI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammad Hossein Samaei, Faryad Darabi Sahneh, Caterina Scoglio</dc:creator>
    </item>
    <item>
      <title>LEGO-Learn: Label-Efficient Graph Open-Set Learning</title>
      <link>https://arxiv.org/abs/2410.16386</link>
      <description>arXiv:2410.16386v1 Announce Type: cross 
Abstract: How can we train graph-based models to recognize unseen classes while keeping labeling costs low? Graph open-set learning (GOL) and out-of-distribution (OOD) detection aim to address this challenge by training models that can accurately classify known, in-distribution (ID) classes while identifying and handling previously unseen classes during inference. It is critical for high-stakes, real-world applications where models frequently encounter unexpected data, including finance, security, and healthcare. However, current GOL methods assume access to many labeled ID samples, which is unrealistic for large-scale graphs due to high annotation costs.
  In this paper, we propose LEGO-Learn (Label-Efficient Graph Open-set Learning), a novel framework that tackles open-set node classification on graphs within a given label budget by selecting the most informative ID nodes. LEGO-Learn employs a GNN-based filter to identify and exclude potential OOD nodes and then select highly informative ID nodes for labeling using the K-Medoids algorithm. To prevent the filter from discarding valuable ID examples, we introduce a classifier that differentiates between the C known ID classes and an additional class representing OOD nodes (hence, a C+1 classifier). This classifier uses a weighted cross-entropy loss to balance the removal of OOD nodes while retaining informative ID nodes. Experimental results on four real-world datasets demonstrate that LEGO-Learn significantly outperforms leading methods, with up to a 6.62% improvement in ID classification accuracy and a 7.49% increase in AUROC for OOD detection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16386v1</guid>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haoyan Xu, Kay Liu, Zhengtao Yao, Philip S. Yu, Kaize Ding, Yue Zhao</dc:creator>
    </item>
    <item>
      <title>Large Language Model-based Augmentation for Imbalanced Node Classification on Text-Attributed Graphs</title>
      <link>https://arxiv.org/abs/2410.16882</link>
      <description>arXiv:2410.16882v1 Announce Type: cross 
Abstract: Node classification on graphs frequently encounters the challenge of class imbalance, leading to biased performance and posing significant risks in real-world applications. Although several data-centric solutions have been proposed, none of them focus on Text-Attributed Graphs (TAGs), and therefore overlook the potential of leveraging the rich semantics encoded in textual features for boosting the classification of minority nodes. Given this crucial gap, we investigate the possibility of augmenting graph data in the text space, leveraging the textual generation power of Large Language Models (LLMs) to handle imbalanced node classification on TAGs. Specifically, we propose a novel approach called LA-TAG (LLM-based Augmentation on Text-Attributed Graphs), which prompts LLMs to generate synthetic texts based on existing node texts in the graph. Furthermore, to integrate these synthetic text-attributed nodes into the graph, we introduce a text-based link predictor to connect the synthesized nodes with the existing nodes. Our experiments across multiple datasets and evaluation metrics show that our framework significantly outperforms traditional non-textual-based data augmentation strategies and specific node imbalance solutions. This highlights the promise of using LLMs to resolve imbalance issues on TAGs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16882v1</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Leyao Wang, Yu Wang, Bo Ni, Yuying Zhao, Tyler Derr</dc:creator>
    </item>
    <item>
      <title>A Fast Parallel Approach for Neighborhood-based Link Prediction by Disregarding Large Hubs</title>
      <link>https://arxiv.org/abs/2401.11415</link>
      <description>arXiv:2401.11415v4 Announce Type: replace 
Abstract: Link prediction can help rectify inaccuracies in various graph algorithms, stemming from unaccounted-for or overlooked links within networks. However, many existing works use a baseline approach, which incurs unnecessary computational costs due to its high time complexity. Further, many studies focus on smaller graphs, which can lead to misleading conclusions. Here, we study the prediction of links using neighborhood-based similarity measures on large graphs. In particular, we improve upon the baseline approach (IBase), and propose a heuristic approach that additionally disregards large hubs (DLH), based on the idea that high-degree nodes contribute little similarity among their neighbors. On a server equipped with dual 16-core Intel Xeon Gold 6226R processors, DLH is on average 1019x faster than IBase, especially on web graphs and social networks, while maintaining similar prediction accuracy. Notably, DLH achieves a link prediction rate of 38.1M edges/s and improves performance by 1.6x for every doubling of threads.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.11415v4</guid>
      <category>cs.SI</category>
      <category>cs.DC</category>
      <pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Subhajit Sahu</dc:creator>
    </item>
    <item>
      <title>Interest Maximization in Social Networks</title>
      <link>https://arxiv.org/abs/2404.08236</link>
      <description>arXiv:2404.08236v2 Announce Type: replace 
Abstract: Nowadays, organizations use viral marketing strategies to promote their products through social networks. It is expensive to directly send the product promotional information to all the users in the network. In this context, Kempe et al. \cite{kempe2003maximizing} introduced the Influence Maximization (IM) problem, which identifies $k$ most influential nodes (spreader nodes), such that the maximum number of people in the network adopts the promotional message.
  Many variants of the IM problem have been studied in the literature, namely, Perfect Evangelising Set (PES), Perfect Awareness Problem (PAP), etc. In this work, we propose a maximization version of PAP called the \IM{} problem. Different people have different levels of interest in a particular product. This is modeled by assigning an interest value to each node in the network. Then, the problem is to select $k$ initial spreaders such that the sum of the interest values of the people (nodes) who become aware of the message is maximized.
  We study the \IM{} problem under two popular diffusion models: the Linear Threshold Model (LTM) and the Independent Cascade Model (ICM). We show that the \IM{} problem is NP-Hard under LTM. We give linear programming formulation for the problem under LTM. We propose four heuristic algorithms for the \IM{} problem: \LBE{} (\LB{}), Maximum Degree First Heuristic (\MD{}), \PBE{} (\PB{}), and Maximum Profit Based Greedy Heuristic (\MP{}). Extensive experimentation has been carried out on many real-world benchmark data sets for both diffusion models. The results show that among the proposed heuristics, \MP{} performs better in maximizing the interest value.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08236v2</guid>
      <category>cs.SI</category>
      <pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rahul Kumar Gautam, Anjeneya Swami Kare, S. Durga Bhavani</dc:creator>
    </item>
    <item>
      <title>Towards Fair Graph Representation Learning in Social Networks</title>
      <link>https://arxiv.org/abs/2410.11493</link>
      <description>arXiv:2410.11493v2 Announce Type: replace 
Abstract: With the widespread use of Graph Neural Networks (GNNs) for representation learning from network data, the fairness of GNN models has raised great attention lately. Fair GNNs aim to ensure that node representations can be accurately classified, but not easily associated with a specific group. Existing advanced approaches essentially enhance the generalisation of node representation in combination with data augmentation strategy, and do not directly impose constraints on the fairness of GNNs. In this work, we identify that a fundamental reason for the unfairness of GNNs in social network learning is the phenomenon of social homophily, i.e., users in the same group are more inclined to congregate. The message-passing mechanism of GNNs can cause users in the same group to have similar representations due to social homophily, leading model predictions to establish spurious correlations with sensitive attributes. Inspired by this reason, we propose a method called Equity-Aware GNN (EAGNN) towards fair graph representation learning. Specifically, to ensure that model predictions are independent of sensitive attributes while maintaining prediction performance, we introduce constraints for fair representation learning based on three principles: sufficiency, independence, and separation. We theoretically demonstrate that our EAGNN method can effectively achieve group fairness. Extensive experiments on three datasets with varying levels of social homophily illustrate that our EAGNN method achieves the state-of-the-art performance across two fairness metrics and offers competitive effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11493v2</guid>
      <category>cs.SI</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Guixian Zhang, Guan Yuan, Debo Cheng, Lin Liu, Jiuyong Li, Shichao Zhang</dc:creator>
    </item>
    <item>
      <title>Community Detection Guarantees Using Embeddings Learned by Node2Vec</title>
      <link>https://arxiv.org/abs/2310.17712</link>
      <description>arXiv:2310.17712v3 Announce Type: replace-cross 
Abstract: Embedding the nodes of a large network into an Euclidean space is a common objective in modern machine learning, with a variety of tools available. These embeddings can then be used as features for tasks such as community detection/node clustering or link prediction, where they achieve state of the art performance. With the exception of spectral clustering methods, there is little theoretical understanding for commonly used approaches to learning embeddings. In this work we examine the theoretical properties of the embeddings learned by node2vec. Our main result shows that the use of $k$-means clustering on the embedding vectors produced by node2vec gives weakly consistent community recovery for the nodes in (degree corrected) stochastic block models. We also discuss the use of these embeddings for node and link prediction tasks. We demonstrate this result empirically, and examine how this relates to other embedding tools for network data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.17712v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <category>stat.ME</category>
      <pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrew Davison, S. Carlyle Morgan, Owen G. Ward</dc:creator>
    </item>
    <item>
      <title>Temporal Graph Rewiring with Expander Graphs</title>
      <link>https://arxiv.org/abs/2406.02362</link>
      <description>arXiv:2406.02362v3 Announce Type: replace-cross 
Abstract: Evolving relations in real-world networks are often modelled by temporal graphs. Temporal Graph Neural Networks (TGNNs) emerged to model evolutionary behaviour of such graphs by leveraging the message passing primitive at the core of Graph Neural Networks (GNNs). It is well-known that GNNs are vulnerable to several issues directly related to the input graph topology, such as under-reaching and over-squashing - we argue that these issues can often get exacerbated in temporal graphs, particularly as the result of stale nodes and edges. While graph rewiring techniques have seen frequent usage in GNNs to make the graph topology more favourable for message passing, they have not seen any mainstream usage on TGNNs. In this work, we propose Temporal Graph Rewiring (TGR), the first approach for graph rewiring on temporal graphs, to the best of our knowledge. TGR constructs message passing highways between temporally distant nodes in a continuous-time dynamic graph by utilizing expander graph propagation, a prominent framework used for graph rewiring on static graphs which makes minimal assumptions on the underlying graph structure. On the challenging TGB benchmark, TGR achieves state-of-the-art results on tgbl-review, tgbl-coin, tgbl-comment and tgbl-flight datasets at the time of writing. For tgbl-review, TGR has 50.5% improvement in MRR over the base TGN model and 22.2% improvement over the base TNCN model. The significant improvement over base models demonstrates clear benefits of temporal graph rewiring.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.02362v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.SI</category>
      <category>stat.ML</category>
      <pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Katarina Petrovi\'c, Shenyang Huang, Farimah Poursafaei, Petar Veli\v{c}kovi\'c</dc:creator>
    </item>
    <item>
      <title>Boardwalk Empire: How Generative AI is Revolutionizing Economic Paradigms</title>
      <link>https://arxiv.org/abs/2410.15212</link>
      <description>arXiv:2410.15212v2 Announce Type: replace-cross 
Abstract: The relentless pursuit of technological advancements has ushered in a new era where artificial intelligence (AI) is not only a powerful tool but also a critical economic driver. At the forefront of this transformation is Generative AI, which is catalyzing a paradigm shift across industries. Deep generative models, an integration of generative and deep learning techniques, excel in creating new data beyond analyzing existing ones, revolutionizing sectors from production and manufacturing to finance. By automating design, optimization, and innovation cycles, Generative AI is reshaping core industrial processes. In the financial sector, it is transforming risk assessment, trading strategies, and forecasting, demonstrating its profound impact. This paper explores the sweeping changes driven by deep learning models like Large Language Models (LLMs), highlighting their potential to foster innovative business models, disruptive technologies, and novel economic landscapes. As we stand at the threshold of an AI-driven economic era, Generative AI is emerging as a pivotal force, driving innovation, disruption, and economic evolution on a global scale.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15212v2</guid>
      <category>cs.CE</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Subramanyam Sahoo, Kamlesh Dutta</dc:creator>
    </item>
  </channel>
</rss>
