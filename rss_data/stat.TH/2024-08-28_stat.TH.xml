<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.TH</link>
    <description>stat.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 28 Aug 2024 04:00:44 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>High-dimensional Gaussian linear processes: Marchenko-Pastur beyond simultaneous diagonalizability</title>
      <link>https://arxiv.org/abs/2408.14618</link>
      <description>arXiv:2408.14618v1 Announce Type: new 
Abstract: Except for trivial cases, the eigenvectors of spectral density matrices $f(\theta)$ corresponding to stationary Gaussian process depend explicitly on the frequency $\theta \in [0,2\pi]$. The most commonly used estimator of the spectral density matrix is the smoothed periodogram, which takes the form of sample covariance matrices $YY^T$ for data-matrices $Y$ with iid columns that each have differing underlying covariance structure. However, the covariance matrices of the columns need not be simultaneously diagonalizable and therefore, such sample covariance matrices are out of reach for the current state of random matrix theory. In this paper, we derive a Marchenko-Pastur law in this non-simultaneously diagonalizable case. On the technical level, we make the following two major contributions:
  - Except for negligible approximations we construct a matrix with the same eigenvalue distribution as the smoothed periodogram, but which is much more accessible. To this aim, we introduce a generalization of graph-theoretical methods specific to Gaussian random matrices, which allow for the exploitation of independence properties in-between either columns or rows.
  - By means of the Lagrange inversion formula, we draw a novel connection between trace moment expansions and the Marchen\-ko-Pastur equation, which enables us to formulate deviation inequalities for the corresponding $l$-th moments for all $l \in \mathbb{N}$.
  The Marchenko-Pastur law emerges when the dimension $d$ of the process and the smoothing span $m$ of the smoothed periodogram grow at the same rate, which is slower than the number of observations $n$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.14618v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ben Deitmar</dc:creator>
    </item>
    <item>
      <title>Unveiling the Statistical Foundations of Chain-of-Thought Prompting Methods</title>
      <link>https://arxiv.org/abs/2408.14511</link>
      <description>arXiv:2408.14511v1 Announce Type: cross 
Abstract: Chain-of-Thought (CoT) prompting and its variants have gained popularity as effective methods for solving multi-step reasoning problems using pretrained large language models (LLMs). In this work, we analyze CoT prompting from a statistical estimation perspective, providing a comprehensive characterization of its sample complexity. To this end, we introduce a multi-step latent variable model that encapsulates the reasoning process, where the latent variable encodes the task information. Under this framework, we demonstrate that when the pretraining dataset is sufficiently large, the estimator formed by CoT prompting is equivalent to a Bayesian estimator. This estimator effectively solves the multi-step reasoning problem by aggregating a posterior distribution inferred from the demonstration examples in the prompt. Moreover, we prove that the statistical error of the CoT estimator can be decomposed into two main components: (i) a prompting error, which arises from inferring the true task using CoT prompts, and (ii) the statistical error of the pretrained LLM. We establish that, under appropriate assumptions, the prompting error decays exponentially to zero as the number of demonstrations increases. Additionally, we explicitly characterize the approximation and generalization errors of the pretrained LLM. Notably, we construct a transformer model that approximates the target distribution of the multi-step reasoning problem with an error that decreases exponentially in the number of transformer blocks. Our analysis extends to other variants of CoT, including Self-Consistent CoT, Tree-of-Thought, and Selection-Inference, offering a broad perspective on the efficacy of these methods. We also provide numerical experiments to validate the theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.14511v1</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinyang Hu, Fengzhuo Zhang, Siyu Chen, Zhuoran Yang</dc:creator>
    </item>
    <item>
      <title>A generalization of Gr\"unbaum's inequality in RCD$(0,N)$-spaces</title>
      <link>https://arxiv.org/abs/2408.15030</link>
      <description>arXiv:2408.15030v1 Announce Type: cross 
Abstract: We generalize Gr\"unbaum's classical inequality in convex geometry to curved spaces with nonnegative Ricci curvature, precisely, to $\mathrm{RCD}(0,N)$-spaces with $N \in (1,\infty)$ as well as weighted Riemannian manifolds of $\mathrm{Ric}_N \ge 0$ for $N \in (-\infty,-1) \cup \{\infty\}$. Our formulation makes use of the isometric splitting theorem; given a convex set $\Omega$ and the Busemann function associated with any straight line, the volume of the intersection of $\Omega$ and any sublevel set of the Busemann function that contains a barycenter of $\Omega$ is bounded from below in terms of $N$. We also extend this inequality beyond uniform distributions on convex sets. Moreover, we establish some rigidity results by using the localization method, and the stability problem is also studied.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.15030v1</guid>
      <category>math.MG</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Victor-Emmanuel Brunel, Shin-ichi Ohta, Jordan Serres</dc:creator>
    </item>
    <item>
      <title>The Benefits of Balance: From Information Projections to Variance Reduction</title>
      <link>https://arxiv.org/abs/2408.15065</link>
      <description>arXiv:2408.15065v1 Announce Type: cross 
Abstract: Data balancing across multiple modalities/sources appears in various forms in several foundation models (e.g., CLIP and DINO) achieving universal representation learning. We show that this iterative algorithm, usually used to avoid representation collapse, enjoys an unsuspected benefit: reducing the variance of estimators that are functionals of the empirical distribution over these sources. We provide non-asymptotic bounds quantifying this variance reduction effect and relate them to the eigendecays of appropriately defined Markov operators. We explain how various forms of data balancing in contrastive multimodal learning and self-supervised clustering can be interpreted as instances of this variance reduction scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.15065v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lang Liu, Ronak Mehta, Soumik Pal, Zaid Harchaoui</dc:creator>
    </item>
    <item>
      <title>Inference with Mondrian Random Forests</title>
      <link>https://arxiv.org/abs/2310.09702</link>
      <description>arXiv:2310.09702v2 Announce Type: replace 
Abstract: Random forests are popular methods for regression and classification analysis, and many different variants have been proposed in recent years. One interesting example is the Mondrian random forest, in which the underlying constituent trees are constructed via a Mondrian process. We give precise bias and variance characterizations, along with a Berry-Esseen-type central limit theorem, for the Mondrian random forest regression estimator. By combining these results with a carefully crafted debiasing approach and an accurate variance estimator, we present valid statistical inference methods for the unknown regression function. These methods come with explicitly characterized error bounds in terms of the sample size, tree complexity parameter, and number of trees in the forest, and include coverage error rates for feasible confidence interval estimators. Our novel debiasing procedure for the Mondrian random forest also allows it to achieve the minimax-optimal point estimation convergence rate in mean squared error for multivariate $\beta$-H\"older regression functions, for all $\beta &gt; 0$, provided that the underlying tuning parameters are chosen appropriately. Efficient and implementable algorithms are devised for both batch and online learning settings, and we carefully study the computational complexity of different Mondrian random forest implementations. Finally, simulations with synthetic data validate our theory and methodology, demonstrating their excellent finite-sample properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.09702v2</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matias D. Cattaneo, Jason M. Klusowski, William G. Underwood</dc:creator>
    </item>
    <item>
      <title>On the Estimation of bivariate Conditional Transition Rates</title>
      <link>https://arxiv.org/abs/2404.02736</link>
      <description>arXiv:2404.02736v2 Announce Type: replace 
Abstract: Recent literature has found conditional transition rates to be a useful tool for avoiding Markov assumptions in multi-state models. While the estimation of univariate conditional transition rates has been extensively studied, the intertemporal dependencies captured in the bivariate conditional transition rates still require a consistent estimator. We provide an estimator that is suitable for censored data and emphasize the connection to the rich theory of the estimation of bivariate survival functions. Bivariate conditional transition rates are necessary for various applications in the survival context but especially in the calculation of moments in life insurance mathematics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02736v2</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Theis Bathke</dc:creator>
    </item>
    <item>
      <title>Persistence Diagram Estimation : Beyond Plug-in Approaches</title>
      <link>https://arxiv.org/abs/2405.18005</link>
      <description>arXiv:2405.18005v3 Announce Type: replace 
Abstract: Persistent homology is a tool from Topological Data Analysis (TDA) used to summarize the topology underlying data. It can be conveniently represented through persistence diagrams. Observing a noisy signal, common strategies to infer its persistence diagram involve plug-in estimators, and convergence properties are then derived from sup-norm stability. This dependence on the sup-norm convergence of the preliminary estimator is restrictive, as it essentially imposes to consider regular classes of signals. Departing from these approaches, we design an estimator based on image persistence. In the context of the Gaussian white noise model, and for large classes of piecewise-constant signals, we prove that the proposed estimator is consistent and achieves parametric rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18005v3</guid>
      <category>math.ST</category>
      <category>math.AT</category>
      <category>stat.TH</category>
      <pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hugo Henneuse</dc:creator>
    </item>
    <item>
      <title>Persistence-based Modes Inference</title>
      <link>https://arxiv.org/abs/2407.15449</link>
      <description>arXiv:2407.15449v2 Announce Type: replace 
Abstract: We address the problem of estimating multiple modes of a multivariate density, using persistent homology, a key tool from Topological Data Analysis. We propose a procedure, based on a preliminary estimation of the $H_{0}-$persistence diagram, to estimate the number of modes, their locations, and the associated local maxima. For large classes of piecewise-continuous functions, we show that these estimators are consistent and achieve nearly minimax rates. These classes involve geometric control over the set of discontinuities of the density, and differ from commonly considered function classes in mode(s) inference. Interestingly, we do not suppose regularity or even continuity in any neighborhood of the modes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15449v2</guid>
      <category>math.ST</category>
      <category>math.AT</category>
      <category>stat.TH</category>
      <pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hugo Henneuse</dc:creator>
    </item>
    <item>
      <title>Bayesian Inference of Minimally Complex Models with Interactions of Arbitrary Order</title>
      <link>https://arxiv.org/abs/2008.00520</link>
      <description>arXiv:2008.00520v3 Announce Type: replace-cross 
Abstract: Finding the model that best describes a high-dimensional dataset is a daunting task, even more so if one aims to consider all possible high-order patterns of the data, going beyond pairwise models. For binary data, we show that this task becomes feasible when restricting the search to a family of simple models, that we call Minimally Complex Models (MCMs). MCMs are maximum entropy models that have interactions of arbitrarily high order grouped into independent components of minimal complexity. They are simple in information-theoretic terms, which means they can only fit well certain types of data patterns and are therefore easy to falsify. We show that Bayesian model selection restricted to these models is computationally feasible and has many advantages. First, the model evidence, which balances goodness-of-fit against complexity, can be computed efficiently without any parameter fitting, enabling very fast explorations of the space of MCMs. Second, the family of MCMs is invariant under gauge transformations, which can be used to develop a representation-independent approach to statistical modeling. For small systems (up to 15 variables), combining these two results allows us to select the best MCM among all, even though the number of models is already extremely large. For larger systems, we propose simple heuristics to find optimal MCMs in reasonable times. Besides, inference and sampling can be performed without any computational effort. Finally, because MCMs have interactions of any order, they can reveal the presence of important high-order dependencies in the data, providing a new approach to explore high-order dependencies in complex systems. We apply our method to synthetic data and real-world examples, illustrating how MCMs portray the structure of dependencies among variables in a simple manner, extracting falsifiable predictions on symmetries and invariance from the data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2008.00520v3</guid>
      <category>cs.AI</category>
      <category>math.ST</category>
      <category>physics.data-an</category>
      <category>q-bio.QM</category>
      <category>stat.TH</category>
      <pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cl\'elia de Mulatier, Matteo Marsili</dc:creator>
    </item>
    <item>
      <title>Channel State Acquisition in Uplink NOMA for Cellular-Connected UAV: Exploitation of Doppler and Modulation Diversities</title>
      <link>https://arxiv.org/abs/2108.06713</link>
      <description>arXiv:2108.06713v4 Announce Type: replace-cross 
Abstract: Integration of unmanned aerial vehicles (UAVs) for surveillance or monitoring applications into fifth generation (5G) New Radio (NR) cellular networks is an intriguing problem that has recently tackled a lot of interest in both academia and industry. For an efficient spectrum usage, we consider a recently-proposed sky-ground nonorthogonal multiple access (NOMA) scheme, where a cellular-connected UAV acting as aerial user (AU) and a static terrestrial user (TU) are paired to simultaneously transmit their uplink signals to a base station (BS) in the same time-frequency resource blocks. In such a case, due to the highly dynamic nature of the UAV, the signal transmitted by the AU experiences both time dispersion due to multipath propagation effects and frequency dispersion caused by Doppler shifts. On the other hand, for a static ground network, frequency dispersion of the signal transmitted by the TU is negligible and only multipath effects have to be taken into account. To decode the superposed signals at the BS through successive interference cancellation, accurate estimates of both the AU and TU channels are needed. In this paper, we propose channel estimation procedures that suitably exploit the different circular/noncircular modulation formats (modulation diversity) and the different almost-cyclostationarity features (Doppler diversity) of the AU and TU by means of widely-linear time-varying processing. Our estimation approach is semi-blind since Doppler shifts and time delays of the AU are estimated based on the received data only, whereas the remaining relevant parameters of the AU and TU channels are acquired relying also on the available training symbols, which are transmitted by the AU and TU in a nonorthogonal manner.</description>
      <guid isPermaLink="false">oai:arXiv.org:2108.06713v4</guid>
      <category>eess.SP</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/OJCOMS.2024.3451308</arxiv:DOI>
      <dc:creator>Donatella Darsena, Ivan Iudice, Francesco Verde</dc:creator>
    </item>
    <item>
      <title>Adjusting for Incomplete Baseline Covariates in Randomized Controlled Trials: A Cross-World Imputation Framework</title>
      <link>https://arxiv.org/abs/2302.01269</link>
      <description>arXiv:2302.01269v2 Announce Type: replace-cross 
Abstract: In randomized controlled trials, adjusting for baseline covariates is often applied to improve the precision of treatment effect estimation. However, missingness in covariates is common. Recently, Zhao &amp; Ding (2022) studied two simple strategies, the single imputation method and missingness indicator method (MIM), to deal with missing covariates, and showed that both methods can provide efficiency gain. To better understand and compare these two strategies, we propose and investigate a novel imputation framework termed cross-world imputation (CWI), which includes single imputation and MIM as special cases. Through the lens of CWI, we show that MIM implicitly searches for the optimal CWI values and thus achieves optimal efficiency. We also derive conditions under which the single imputation method, by searching for the optimal single imputation values, can achieve the same efficiency as the MIM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.01269v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yilin Song, James P. Hughes, Ting Ye</dc:creator>
    </item>
    <item>
      <title>Mesoscopic Bayesian Inference by Solvable Models</title>
      <link>https://arxiv.org/abs/2406.02869</link>
      <description>arXiv:2406.02869v2 Announce Type: replace-cross 
Abstract: The rapid advancement of data science and artificial intelligence has affected physics in numerous ways, including the application of Bayesian inference, setting the stage for a revolution in research methodology. Our group has proposed Bayesian measurement, a framework that applies Bayesian inference to measurement science with broad applicability across various natural sciences. This framework enables the determination of posterior probability distributions of system parameters, model selection, and the integration of multiple measurement datasets. However, applying Bayesian measurement to real data analysis requires a more sophisticated approach than traditional statistical methods like Akaike information criterion (AIC) and Bayesian information criterion (BIC), which are designed for an infinite number of measurements $N$. Therefore, in this paper, we propose an analytical theory that explicitly addresses the case where $N$ is finite in the linear regression model. We introduce $O(1)$ mesoscopic variables for $N$ observation noises. Using this mesoscopic theory, we analyze the three core principles of Bayesian measurement: parameter estimation, model selection, and measurement integration. Furthermore, by introducing these mesoscopic variables, we demonstrate that the difference in free energies, critical for both model selection and measurement integration, can be analytically reduced by two mesoscopic variables of $N$ observation noises. This provides a deeper qualitative understanding of model selection and measurement integration and further provides deeper insights into actual measurements for nonlinear models. Our framework presents a novel approach to understanding Bayesian measurement results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.02869v2</guid>
      <category>physics.data-an</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shun Katakami, Shuhei Kashiwamura, Kenji Nagata, Masaichiro Mizumaki, Masato Okada</dc:creator>
    </item>
  </channel>
</rss>
