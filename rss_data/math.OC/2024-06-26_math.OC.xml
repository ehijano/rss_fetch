<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 27 Jun 2024 01:33:54 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 26 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A Page-Rank-like Approach to Optimal Placement of Charging Stations in a Warehouse</title>
      <link>https://arxiv.org/abs/2406.17003</link>
      <description>arXiv:2406.17003v1 Announce Type: new 
Abstract: In this paper we describe an approach to the problem of finding optimal positions for charging stations (CS) in a warehouse, where a fleet of electrical industrial trucks/forklifts is employed. Our procedure is motivated by Googles Page-Ranking. The graph model underlying our method is easily extensible from simple distance based criteria, relevant for choosing optimal CS-positions, to more complex criteria taking into account, e.g., the ''state of charge'' (SOC) of the individual trucks battery.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17003v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Hans-Georg Stark, Mustafa Jelibaghu, Katrin Tschirpke, Michael Eley</dc:creator>
    </item>
    <item>
      <title>Mean-Field Langevin Dynamics for Signed Measures via a Bilevel Approach</title>
      <link>https://arxiv.org/abs/2406.17054</link>
      <description>arXiv:2406.17054v2 Announce Type: new 
Abstract: Mean-field Langevin dynamics (MLFD) is a class of interacting particle methods that tackle convex optimization over probability measures on a manifold, which are scalable, versatile, and enjoy computational guarantees. However, some important problems -- such as risk minimization for infinite width two-layer neural networks, or sparse deconvolution -- are originally defined over the set of signed, rather than probability, measures. In this paper, we investigate how to extend the MFLD framework to convex optimization problems over signed measures. Among two known reductions from signed to probability measures -- the lifting and the bilevel approaches -- we show that the bilevel reduction leads to stronger guarantees and faster rates (at the price of a higher per-iteration complexity). In particular, we investigate the convergence rate of MFLD applied to the bilevel reduction in the low-noise regime and obtain two results. First, this dynamics is amenable to an annealing schedule, adapted from Suzuki et al. (2023), that results in improved convergence rates to a fixed multiplicative accuracy. Second, we investigate the problem of learning a single neuron with the bilevel approach and obtain local exponential convergence rates that depend polynomially on the dimension and noise level (to compare with the exponential dependence that would result from prior analyses).</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17054v2</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guillaume Wang, Alireza Mousavi-Hosseini, L\'ena\"ic Chizat</dc:creator>
    </item>
    <item>
      <title>A Fast Single-Loop Primal-Dual Algorithm for Non-Convex Functional Constrained Optimization</title>
      <link>https://arxiv.org/abs/2406.17107</link>
      <description>arXiv:2406.17107v1 Announce Type: new 
Abstract: Non-convex functional constrained optimization problems have gained substantial attention in machine learning and signal processing. This paper develops a new primal-dual algorithm for solving this class of problems. The algorithm is based on a novel form of the Lagrangian function, termed {\em Proximal-Perturbed Augmented Lagrangian}, which enables us to develop an efficient and simple first-order algorithm that converges to a stationary solution under mild conditions. Our method has several key features of differentiation over existing augmented Lagrangian-based methods: (i) it is a single-loop algorithm that does not require the continuous adjustment of the penalty parameter to infinity; (ii) it can achieves an improved iteration complexity of $\widetilde{\mathcal{O}}(1/\epsilon^2)$ or at least ${\mathcal{O}}(1/\epsilon^{2/q})$ with $q \in (2/3,1)$ for computing an $\epsilon$-approximate stationary solution, compared to the best-known complexity of $\mathcal{O}(1/\epsilon^3)$; and (iii) it effectively handles functional constraints for feasibility guarantees with fixed parameters, without imposing boundedness assumptions on the dual iterates and the penalty parameters. We validate the effectiveness of our method through numerical experiments on popular non-convex problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17107v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jong Gwang Kim, Ashish Chandra, Abolfazl Hashemi, Christopher Brinton</dc:creator>
    </item>
    <item>
      <title>Exponential turnpike property for particle systems and mean-field limit</title>
      <link>https://arxiv.org/abs/2406.17127</link>
      <description>arXiv:2406.17127v1 Announce Type: new 
Abstract: This work is concerned with the exponential turnpike property for optimal control problems of particle systems and their mean-field limit. Under the assumption of the strict dissipativity of the cost function, exponential estimates for both optimal states and optimal control are proven. Moreover, we show that all the results for particle systems can be preserved under the limit in the case of infinitely many particles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17127v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Herty, Yizhou Zhou</dc:creator>
    </item>
    <item>
      <title>A Decentralized Shotgun Approach for Team Deception</title>
      <link>https://arxiv.org/abs/2406.17160</link>
      <description>arXiv:2406.17160v1 Announce Type: new 
Abstract: Deception is helpful for agents masking their intentions from an observer. We consider a team of agents deceiving their supervisor. The supervisor defines nominal behavior for the agents through reference policies, but the agents share an alternate task that they can only achieve by deviating from these references. Consequently, the agents use deceptive policies to complete the task while ensuring that their behaviors remain plausible to the supervisor. We propose a setting with centralized deceptive policy synthesis and decentralized execution. We model each agent with a Markov decision process and constrain the agents' deceptive policies so that, with high probability, at least one agent achieves the task. We then provide an algorithm to synthesize deceptive policies that ensure the deviations of all agents are small by minimizing the worst Kullback-Leibler divergence between any agent's deceptive and reference policies. Thanks to decentralization, this algorithm scales linearly with the number of agents and also facilitates the efficient synthesis of reference policies. We then explore a more general version of the deceptive policy synthesis problem. In particular, we consider a supervisor who selects a subset of agents to eliminate based on the agents' behaviors. We give algorithms to synthesize deceptive policies such that, after the supervisor eliminates some agents, the remaining agents complete the task with high probability. We also demonstrate the developed methods in a package delivery example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17160v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Caleb Probine, Mustafa O. Karabag, Ufuk Topcu</dc:creator>
    </item>
    <item>
      <title>Extended alternating structure-adapted proximal gradient algorithm for nonconvex nonsmooth problems</title>
      <link>https://arxiv.org/abs/2406.17226</link>
      <description>arXiv:2406.17226v1 Announce Type: new 
Abstract: Alternating structure-adapted proximal (ASAP) gradient algorithm (M. Nikolova and P. Tan, SIAM J Optim, 29:2053-2078, 2019) has drawn much attention due to its efficiency in solving nonconvex nonsmooth optimization problems. However, the multiblock nonseparable structure confines the performance of ASAP to far-reaching practical problems, e.g., coupled tensor decomposition. In this paper, we propose an extended ASAP (eASAP) algorithm for nonconvex nonsmooth optimization whose objective is the sum of two nonseperable functions and a coupling one. By exploiting the blockwise restricted prox-regularity, eASAP is capable of minimizing the objective whose coupling function is multiblock nonseparable. Moreover, we analyze the global convergence of eASAP by virtue of the Aubin property on partial subdifferential mapping and the Kurdyka-{\L}ojasiewicz property on the objective. Furthermore, the sublinear convergence rate of eASAP is built upon the proximal point algorithmic framework under some mild conditions. Numerical simulations on multimodal data fusion demonstrate the compelling performance of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17226v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ying Gao, Chunfeng Cui, Wenxing Zhang, Deren Han</dc:creator>
    </item>
    <item>
      <title>Exponentially E-preinvex and E-invex functions in mathematical programming</title>
      <link>https://arxiv.org/abs/2406.17273</link>
      <description>arXiv:2406.17273v1 Announce Type: new 
Abstract: In this paper, we introduce a new concept of generalized convexity for E-differentiable vector optimization problems. Namely, the notion of exponentially E-invexity is defined. Further, some properties and results of exponentially E-invex functions are studied. The sufficient optimality conditions are derived under appropriate (generalized) exponentially E-invexity hypotheses. To exemplify the application of our proposed concept, we have included an appropriate example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17273v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Najeeb Abdulaleem</dc:creator>
    </item>
    <item>
      <title>Continuous-time optimal control for trajectory planning under uncertainty</title>
      <link>https://arxiv.org/abs/2406.17317</link>
      <description>arXiv:2406.17317v1 Announce Type: new 
Abstract: This paper presents a continuous-time optimal control framework for the generation of reference trajectories in driving scenarios with uncertainty. A previous work presented a discrete-time stochastic generator for autonomous vehicles; those results are extended to continuous time to ensure the robustness of the generator in a real-time setting. We show that the stochastic model in continuous time can capture the uncertainty of information by producing better results, limiting the risk of violating the problem's constraints compared to a discrete approach. Dynamic solvers provide faster computation and the continuous-time model is more robust to a wider variety of driving scenarios than the discrete-time model, as it can handle further time horizons, which allows trajectory planning outside the framework of urban driving scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17317v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ange Valli (L2S), Shangyuan Zhang (L2S), Abdel Lisser (L2S)</dc:creator>
    </item>
    <item>
      <title>Hiring and firing -- a signaling game</title>
      <link>https://arxiv.org/abs/2406.17380</link>
      <description>arXiv:2406.17380v1 Announce Type: new 
Abstract: We study a signaling game between an employer and a potential employee, where the employee has private information regarding their production capacity. At the initial stage, the employee communicates a salary claim, after which the true production capacity is gradually revealed to the employer as the unknown drift of a Brownian motion representing the revenues generated by the employee. Subsequently, the employer has the possibility to choose a time to fire the employee in case the estimated production capacity falls short of the salary. In this set-up, we use filtering and optimal stopping theory to derive an equilibrium in which the employee provides a randomized salary claim and the employer uses a threshold strategy in terms of the conditional probability for the high production capacity. The analysis is robust in the sense that various extensions of the basic model can be solved using the same methodology, including cases with positive firing costs, incomplete information about one's own type, as well as an additional interview phase.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17380v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erik Ekstr\"om, Topias Tolonen-Weckstr\"om</dc:creator>
    </item>
    <item>
      <title>Double Momentum Method for Lower-Level Constrained Bilevel Optimization</title>
      <link>https://arxiv.org/abs/2406.17386</link>
      <description>arXiv:2406.17386v1 Announce Type: new 
Abstract: Bilevel optimization (BO) has recently gained prominence in many machine learning applications due to its ability to capture the nested structure inherent in these problems. Recently, many hypergradient methods have been proposed as effective solutions for solving large-scale problems. However, current hypergradient methods for the lower-level constrained bilevel optimization (LCBO) problems need very restrictive assumptions, namely, where optimality conditions satisfy the differentiability and invertibility conditions and lack a solid analysis of the convergence rate. What's worse, existing methods require either double-loop updates, which are sometimes less efficient. To solve this problem, in this paper, we propose a new hypergradient of LCBO leveraging the theory of nonsmooth implicit function theorem instead of using the restrive assumptions. In addition, we propose a \textit{single-loop single-timescale} algorithm based on the double-momentum method and adaptive step size method and prove it can return a $(\delta, \epsilon)$-stationary point with $\tilde{\mathcal{O}}(d_2^2\epsilon^{-4})$ iterations. Experiments on two applications demonstrate the effectiveness of our proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17386v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wanli Shi, Yi Chang, Bin Gu</dc:creator>
    </item>
    <item>
      <title>Operating envelopes for the grid-constrained use of distributed flexibility in balancing markets</title>
      <link>https://arxiv.org/abs/2406.17398</link>
      <description>arXiv:2406.17398v1 Announce Type: new 
Abstract: The increasing share of distributed energy sources enhances the participation potential of distributed flexibility in the provision of system services. However, this participation can endanger the grid-safety of the distribution networks (DNs) from which this flexibility originates. In this paper, the use of operating envelopes (OE) to enable the grid-safe procurement of distributed flexibility in centralized balancing markets is proposed. Two classes of approaches for calculating OEs (one-step and two-step methods) are compared in terms of the level of distribution grid safety they can provide, the impact they can have on the market efficiency, and the volume of discarded flexibility they can yield. A case study considering different system scenarios, based on Monte Carlo simulations, highlights a trade-off between the market efficiency, DN flexibility resource utilization, and the grid safety delivered by the different OE methods. The results showcase that the use of the two-step OE approach results in a more grid-secure albeit less-efficient use of distributed flexibility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17398v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abhimanyu Kaushal, Wicak Ananduta, Luciana Marques, Tom Cuypers, Anibal Sanjab</dc:creator>
    </item>
    <item>
      <title>Optimal Design of Broadband, Low-Directivity Graded Index Acoustic Lenses for Underwater Applications</title>
      <link>https://arxiv.org/abs/2406.17400</link>
      <description>arXiv:2406.17400v1 Announce Type: new 
Abstract: Manipulating underwater pressure waves is crucial for marine exploration, as electromagnetic signals are strongly absorbed in water. However, the multi-path phenomenon complicates the accurate capture of acoustic waves by receivers. Although graded index lenses, based on metamaterials with smoothly varying properties, successfully focus pressure waves, they tend to have high directivity, which hinders practical application.
  This work introduces three 2D acoustic lenses made from a metamaterial composed of solid inclusions in water. We propose an optimization scheme where the pressure dynamics is governed by Helmholtz's equation, with control parameters affecting each lens cell's density and bulk modulus. Through an appropriate cost function, the optimization encourages a broadband, low-directivity lens. The large-scale optimization is solved using the Lagrangian approach, which provides an analytical expression for the cost gradient. This scheme avoids the need for a separate discretization step, allowing the design to transition directly from the desired smooth refractive index to a practical lattice structure. As a result, the optimized lens closely aligns with real-world behavior.
  The homogenized numerical model is validated against finite elements, which considers acoustic-elastic coupling at the microstructure level. When homogenization holds, this approach proves to be an effective design tool for achieving broadband, low-directivity acoustic lenses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17400v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sebastiano Cominelli, Francesco Braghin</dc:creator>
    </item>
    <item>
      <title>A comparison of formulations for aircraft deconfliction</title>
      <link>https://arxiv.org/abs/2406.17403</link>
      <description>arXiv:2406.17403v1 Announce Type: new 
Abstract: In this work, we aim to compare different methods and formulations to solve a problem in air traffic management to global optimality. In particular, we focus on the aircraft deconfliction problem, where we are given n aircraft, their position at time 0, and their (straight) trajectories. We wish to identify and solve potential pairwise conflict by temporarily modifying the aircraft's trajectory. A pair of aircraft is in conflict when they do not respect a minimum, predefined safety distance. In general, conflicts could be solved both varying the aircraft's speed or trajectory, but in this paper we only consider the latter, more precisely heading-angle deviations. The problem has been formulated as a mixed integer nonlinear program (MINLP). We compare this formulation, solved by open-source MINLP solvers for global optimization, against a reformulation that shows a larger number of variables and constraints but only separable nonconvexities. We solve such a separable formulation with the same MINLP solvers or the Sequential Convex Mixed Integer Nonlinear Programming method. The separable formulation, despite being larger, facilitates some solvers in finding good-quality solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17403v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Renan Spencer Trindade, Claudia D'Ambrosio</dc:creator>
    </item>
    <item>
      <title>Optimal Reflection Coefficients for ASK Modulated Backscattering from Passive Tags</title>
      <link>https://arxiv.org/abs/2406.17448</link>
      <description>arXiv:2406.17448v1 Announce Type: new 
Abstract: A passive backscatter tag is an energy-efficient wireless communication device that is ideal for low-power and low-bandwidth applications, such as sensing and identification. Despite their usefulness, the effectiveness of these tags is limited by the amount of energy they can harness from the incident radio signals used to backscatter their information through the modulation of reflections. This paper aims to maximize this harvested power at a passive tag by optimally designing the underlying M-ary amplitude-shift keying (ASK) modulator in a monostatic backscatter communication (BackCom) system. Specifically, we derive the closed-form expression for the global optimal reflection coefficients that maximize the tag's harvested power while satisfying the minimum symbol error rate (SER) requirement, tag sensitivity, and reader sensitivity constraints. We also proposed optimal binary-ASK modulation design to gain novel design insights on practical BackCom systems with readers having superior sensitivity. We have validated these nontrivial analytical claims via extensive simulations. The numerical results provide insight into the impact of the transmit symbol probability, tag sensitivity constraint, and SER on the maximum average harvested power. Remarkably, our design achieves an overall gain of around 13% over the benchmark, signifying its utility in improving the efficiency of BackCom systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17448v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Amus Chee Yuen Goay, Deepak Mishra, Aruna Seneviratne</dc:creator>
    </item>
    <item>
      <title>A Novel Deflation Approach for Topology Optimization and Application for Optimization of Bipolar Plates of Electrolysis Cells</title>
      <link>https://arxiv.org/abs/2406.17491</link>
      <description>arXiv:2406.17491v1 Announce Type: new 
Abstract: Topology optimization problems usually feature multiple local minimizers. To guarantee convergence to local minimizers that perform best globally or to find local solutions that are desirable for practical applications due to easy manufacturability or aesthetic designs, it is important to compute multiple local minimizers of topology optimization problems. Existing methods typically rely on Newton-type solvers during the optimization process, which makes them unsuitable for sensitivity-based topology optimization. In this paper, we introduce a novel deflation approach to systematically find multiple local minimizers of general topology optimization problems. The approach is based on a penalization of previously found local solutions in the objective. We validate our approach on the so-called two-pipes five-holes example. Finally, we introduce a model for the topology optimization of bipolar plates of hydrogen electrolysis cells and demonstrate that our deflation approach enables the discovery of novel designs for such plates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17491v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Leon Baeck, Sebastian Blauth, Christian Leith\"auser, Ren\'e Pinnau, Kevin Sturm</dc:creator>
    </item>
    <item>
      <title>Exact worst-case convergence rates of gradient descent: a complete analysis for all constant stepsizes over nonconvex and convex functions</title>
      <link>https://arxiv.org/abs/2406.17506</link>
      <description>arXiv:2406.17506v1 Announce Type: new 
Abstract: We consider gradient descent with constant stepsizes and derive exact worst-case convergence rates on the minimum gradient norm of the iterates. Our analysis covers all possible stepsizes and arbitrary upper/lower bounds on the curvature of the objective function, thus including convex, strongly convex and weakly convex (hypoconvex) objective functions. Unlike prior approaches, which rely solely on inequalities connecting consecutive iterations, our analysis employs inequalities involving an iterate and its two predecessors. While this complicates the proofs to some extent, it enables us to achieve, for the first time, an exact full-range analysis of gradient descent for any constant stepsizes (covering, in particular, normalized stepsizes greater than one), whereas the literature contained only conjectured rates of this type. In the nonconvex case, allowing arbitrary bounds on upper and lower curvatures extends existing partial results that are valid only for gradient Lipschitz functions (i.e., where lower and upper bounds on curvature are equal), leading to improved rates for weakly convex functions. From our exact rates, we deduce the optimal constant stepsize for gradient descent. Leveraging our analysis, we also introduce a new variant of gradient descent based on a unique, fixed sequence of variable stepsizes, demonstrating its superiority over any constant stepsize schedule.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17506v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Teodor Rotaru, Fran\c{c}ois Glineur, Panagiotis Patrinos</dc:creator>
    </item>
    <item>
      <title>Joint spectral radius and forbidden products</title>
      <link>https://arxiv.org/abs/2406.17524</link>
      <description>arXiv:2406.17524v1 Announce Type: new 
Abstract: We address the problem of finite products that attain the joint spectral radius of a finite number of square matrices. Up to date the problem of existence of "forbidden products" remained open. We prove that the product $AABABABB$ (together with its circular shifts and their mirror images) never delivers the strict maximum to the joint spectral radius if we restrict consideration to pairs $\{A,B\}$ of real $2\by 2$ matrices. Under this restriction circular shifts and their mirror images constitute the class of isospectral products and hence they all have the same spectral radius for any pair $\{A,B\}$ of $2\by 2$ matrices, even complex. For pairs of complex matrices we have numerical evidence that $AABABABB$ is still a fobidden product. A couple of binary words that encode products from this isospectral class also happen to be the shortest forbidden patterns in the parametric family of double rotations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17524v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Vladimirov</dc:creator>
    </item>
    <item>
      <title>Computing User Equilibria for Schedule-Based Transit Networks with Hard Vehicle Capacities</title>
      <link>https://arxiv.org/abs/2406.17153</link>
      <description>arXiv:2406.17153v1 Announce Type: cross 
Abstract: Modelling passenger assignments in public transport networks is a fundamental task for city planners, especially when deliberating network infrastructure decisions. A key aspect of a realistic model for passenger assignments is to integrate selfish routing behaviour of passengers on the one hand, and the limited vehicle capacities on the other hand. We formulate a side-constrained user equilibrium model in a schedule-based time-expanded transit network, where passengers are modelled via a continuum of non-atomic agents that want to travel with a fixed start time from a user-specific origin to a destination. An agent's route may comprise several rides along given lines, each using vehicles with hard loading capacities. We give a characterization of (side-constrained) user equilibria via a quasi-variational inequality and prove their existence by generalizing a well-known existence result of Bernstein and Smith (Transp. Sci., 1994). We further derive a polynomial time algorithm for single-commodity instances and an exact finite time algorithm for the multi-commodity case. Based on our quasi-variational characterization, we finally devise a fast heuristic computing user equilibria, which is tested on real-world instances based on data gained from the Hamburg S-Bahn system and the Swiss long-distance train network. It turns out that w.r.t. the total travel time, the computed user-equilibria are quite efficient compared to a system optimum, which neglects equilibrium constraints and only minimizes total travel time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17153v1</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tobias Harks, Sven J\"ager, Michael Markl, Philine Schiewe</dc:creator>
    </item>
    <item>
      <title>Optimizing Sparse Mean-Reverting Portfolio</title>
      <link>https://arxiv.org/abs/2406.17155</link>
      <description>arXiv:2406.17155v1 Announce Type: cross 
Abstract: Mean-reverting behavior of individuals assets is widely known in financial markets. In fact, we can construct a portfolio that has mean-reverting behavior and use it in trading strategies to extract profits. In this paper, we show that we are able to find the optimal weights of stocks to construct portfolio that has the fastest mean-reverting behavior. We further add minimum variance and sparsity constraints to the optimization problem and transform into Semidefinite Programming (SDP) problem to find the optimal weights. Using the optimal weights, we empirically compare the performance of contrarian strategies between non-sparse mean-reverting portfolio and sparse mean-reverting portfolio to argue that the latter provides higher returns when we take into account of transaction costs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17155v1</guid>
      <category>q-fin.PM</category>
      <category>math.OC</category>
      <category>q-fin.MF</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sung Min Yoon</dc:creator>
    </item>
    <item>
      <title>Exact controllability to eigensolutions of the heat equation via bilinear controls on two-dimensional domains</title>
      <link>https://arxiv.org/abs/2406.17348</link>
      <description>arXiv:2406.17348v1 Announce Type: cross 
Abstract: The exact controllability of heat type equations in the presence of bilinear controls have been successfully studied in the recent works [1,3,14] motivated by the numerous application to engineering, neurobiology, chemistry, and life science. Nevertheless, the result has been only achieved for one-dimensional domains due to limit of the existing techniques. In this work, we develop a new strategy to ensure the so-called exact controllability to the eigensolutions of heat-type equations via bilinear control on the two-dimensional domains. The result is implied by the null-controllability of a suitable linearized equation, and the main novelty of the work is the strategy of its proof. First, the null-controllability in a finite dimensional subspace has to be ensured via the solvability of a suitable moment problem. Explicit bounds on the control cost w.r.t. to the dimension of the controlled space are also required. Second, the controllability can be extended to the whole Hilbert space, thanks to the Lebeau-Robbiano-Miller method, when the control cost does not growth too fast w.r.t to the dimension of the finite dimensional subspace. We firstly develop our techniques in the general case when suitable hypotheses on the problem are verified. Afterwards, we apply our procedure to the bilinear heat equation on rectangular domains, and we ensure its exact controllability to the eigensolutions. Finally, we study the controllability issue on the square and we use perturbation theory techniques to deal with the presence of multiple eigenvalues for the spectrum of the Dirichlet Laplacian.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17348v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>R\'emi Buffe, Alessandro Duca</dc:creator>
    </item>
    <item>
      <title>Moment-based parameter inference with error guarantees for stochastic reaction networks</title>
      <link>https://arxiv.org/abs/2406.17434</link>
      <description>arXiv:2406.17434v1 Announce Type: cross 
Abstract: Inferring parameters of models of biochemical kinetics from single-cell data remains challenging because of the uncertainty arising from the intractability of the likelihood function of stochastic reaction networks. Such uncertainty falls beyond current error quantification measures, which focus on the effects of finite sample size and identifiability but lack theoretical guarantees when likelihood approximations are needed. Here, we propose an inference method for stochastic reaction networks with nonlinear and rational propensities at steady state that provides bounds on the parameters via convex optimisation over sets constrained by moment equations and moment matrices. Our approach takes observations from the stochastic reaction network and forms moment intervals, which are then used to constrain parameters through convex sets. The bounds on the parameters contain the true parameters under the condition that the moment intervals contain the true stationary moments, thus providing uncertainty quantification and error guarantees. Our approach does not need to predict moments and distributions for given parameters (i.e., it avoids solving or simulating the forward problem), and hence circumvents intractable likelihood computations or computationally expensive simulations. We demonstrate its use for uncertainty quantification, data integration and prediction of latent species statistics through synthetic data from common nonlinear biochemical models including the Schl\"ogl model, the toggle switch and post-transcriptional regulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17434v1</guid>
      <category>q-bio.QM</category>
      <category>math.OC</category>
      <category>physics.bio-ph</category>
      <category>physics.data-an</category>
      <category>q-bio.MN</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zekai Li, Mauricio Barahona, Philipp Thomas</dc:creator>
    </item>
    <item>
      <title>A New Perspective on Shampoo's Preconditioner</title>
      <link>https://arxiv.org/abs/2406.17748</link>
      <description>arXiv:2406.17748v1 Announce Type: cross 
Abstract: Shampoo, a second-order optimization algorithm which uses a Kronecker product preconditioner, has recently garnered increasing attention from the machine learning community. The preconditioner used by Shampoo can be viewed either as an approximation of the Gauss--Newton component of the Hessian or the covariance matrix of the gradients maintained by Adagrad. We provide an explicit and novel connection between the $\textit{optimal}$ Kronecker product approximation of these matrices and the approximation made by Shampoo. Our connection highlights a subtle but common misconception about Shampoo's approximation. In particular, the $\textit{square}$ of the approximation used by the Shampoo optimizer is equivalent to a single step of the power iteration algorithm for computing the aforementioned optimal Kronecker product approximation. Across a variety of datasets and architectures we empirically demonstrate that this is close to the optimal Kronecker product approximation. Additionally, for the Hessian approximation viewpoint, we empirically study the impact of various practical tricks to make Shampoo more computationally efficient (such as using the batch gradient and the empirical Fisher) on the quality of Hessian approximation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17748v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Depen Morwani, Itai Shapira, Nikhil Vyas, Eran Malach, Sham Kakade, Lucas Janson</dc:creator>
    </item>
    <item>
      <title>Splitting Guarantees for Prophet Inequalities via Nonlinear Systems</title>
      <link>https://arxiv.org/abs/2406.17767</link>
      <description>arXiv:2406.17767v1 Announce Type: cross 
Abstract: The prophet inequality is one of the cornerstone problems in optimal stopping theory and has become a crucial tool for designing sequential algorithms in Bayesian settings. In the i.i.d. $k$-selection prophet inequality problem, we sequentially observe $n$ non-negative random values sampled from a known distribution. Each time, a decision is made to accept or reject the value, and under the constraint of accepting at most $k$. For $k=1$, Hill and Kertz [Ann. Probab. 1982] provided an upper bound on the worst-case approximation ratio that was later matched by an algorithm of Correa et al. [Math. Oper. Res. 2021]. The worst-case tight approximation ratio for $k=1$ is computed by studying a differential equation that naturally appears when analyzing the optimal dynamic programming policy. A similar result for $k&gt;1$ has remained elusive.
  In this work, we introduce a nonlinear system of differential equations for the i.i.d. $k$-selection prophet inequality that generalizes Hill and Kertz's equation when $k=1$. Our nonlinear system is defined by $k$ constants that determine its functional structure, and their summation provides a lower bound on the optimal policy's asymptotic approximation ratio for the i.i.d. $k$-selection prophet inequality. To obtain this result, we introduce for every $k$ an infinite-dimensional linear programming formulation that fully characterizes the worst-case tight approximation ratio of the $k$-selection prophet inequality problem for every $n$, and then we follow a dual-fitting approach to link with our nonlinear system for sufficiently large values of $n$. As a corollary, we use our provable lower bounds to establish a tight approximation ratio for the stochastic sequential assignment problem in the i.i.d. non-negative regime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17767v1</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Johannes Brustle, Sebastian Perez-Salazar, Victor Verdugo</dc:creator>
    </item>
    <item>
      <title>The role of individual compensation and acceptance decisions in crowdsourced delivery</title>
      <link>https://arxiv.org/abs/2305.01317</link>
      <description>arXiv:2305.01317v4 Announce Type: replace 
Abstract: One of the recent innovations in urban distribution is crowdsourced delivery, where deliveries are made by occasional drivers who wish to utilize their surplus resources (unused transport capacity) by making deliveries in exchange for some compensation. The potential benefits of crowdsourced delivery include reduced delivery costs and increased flexibility (by scaling delivery capacity up and down as needed). The use of occasional drivers poses new challenges because (unlike traditional couriers) neither their availability nor their behavior in accepting delivery offers is certain. The relationship between the compensation offered to occasional drivers and the probability that they will accept a task has been largely neglected in the scientific literature. Therefore, we consider a setting in which compensation-dependent acceptance probabilities are explicitly considered in the process of assigning delivery tasks to occasional drivers. We propose a mixed-integer nonlinear model that minimizes the expected delivery costs while identifying optimal assignments of tasks to a mix of professional and occasional drivers and their compensation. We propose an exact two-stage solution algorithm that allows to decompose compensation and assignment decisions for generic acceptance probability functions and show that the runtime of this algorithm is polynomial under mild conditions. Finally, we also study a more general case of the considered problem setting, show that it is NP-hard and propose an approximate linearization scheme of our mixed-integer nonlinear model. The results of our computational study show clear advantages of our new approach over existing ones. They also indicate that these advantages remain in dynamic settings when tasks and drivers are revealed over time and in which case our method constitutes a fast, yet powerful heuristic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.01317v4</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alim Bu\u{g}ra \c{C}{\i}nar, Wout Dullaert, Markus Leitner, Rosario Paradiso, Stefan Waldherr</dc:creator>
    </item>
    <item>
      <title>Safe Adaptive Control of Hyperbolic PDE-ODE Cascades</title>
      <link>https://arxiv.org/abs/2309.05596</link>
      <description>arXiv:2309.05596v2 Announce Type: replace 
Abstract: Adaptive safe control employing conventional continuous infinite-time adaptation requires that the initial conditions be restricted to a subset of the safe set due to parametric uncertainty, where the safe set is shrunk in inverse proportion to the adaptation gain. The recent regulation-triggered adaptive control approach with batch least-squares identification (BaLSI, pronounced "ballsy") completes perfect parameter identification in finite time and offers a previously unforeseen advantage in adaptive safe control, which we elucidate in this paper. Since the true challenge of safe control is exhibited for CBF of a high relative degree, we undertake a safe BaLSI design in this paper for a class of systems that possess a particularly extreme relative degree: ODE-PDE-ODE sandwich systems. Such sandwich systems arise in various applications, including delivery UAVs (Unmanned Aerial Vehicles) with a cable-suspended load. Collision avoidance of the payload with the surrounding environment is required. The considered class of plants is $2\times2$ hyperbolic PDEs sandwiched by a strict-feedback nonlinear ODE and a linear ODE, where the unknown coefficients, whose bounds are known and arbitrary, are associated with the PDE in-domain coupling terms that can cause instability and with the input signal of the distal ODE. This is the first safe adaptive control design for PDEs, where we introduce the concept of PDE CBF whose non-negativity, as well as the ODE CBF's non-negativity, are ensured with a backstepping-based safety filter. Our safe adaptive controller is explicit and operates in the entire original safe set.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.05596v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ji Wang, Miroslav Krstic</dc:creator>
    </item>
    <item>
      <title>On symmetry adapted bases in trigonometric optimization</title>
      <link>https://arxiv.org/abs/2310.05519</link>
      <description>arXiv:2310.05519v2 Announce Type: replace 
Abstract: The problem of computing the global minimum of a trigonometric polynomial is computationally hard. We address this problem for the case, where the polynomial is invariant under the exponential action of a finite group. The strategy is to follow an established relaxation strategy in order to obtain a converging hierarchy of lower bounds. Those bounds are obtained by numerically solving semi-definite programs (SDPs) on the cone of positive semi-definite Hermitian Toeplitz matrices, which is outlined in the book of Dumitrescu [Dum07]. To exploit the invariance, we show that the group has an induced action on the Toeplitz matrices and prove that the feasible region of the SDP can be restricted to the invariant matrices, whilst retaining the same solution. Then we construct a symmetry adapted basis tailored to this group action, which allows us to block-diagonalize invariant matrices and thus reduce the computational complexity to solve the SDP.
  The approach is in its generality novel for trigonometric optimization and complements the one that was proposed as a poster at the ISSAC 2022 conference [HMMR22] and later extended to [HMMR24]. In the previous work, we first used the invariance of the trigonometric polynomial to obtain a classical polynomial optimization problem on the orbit space and subsequently relaxed the problem to an SDP. Now, we first make the relaxation and then exploit invariance.
  Partial results of this article have been presented as a poster at the ISSAC 2023 conference [Met23].</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.05519v2</guid>
      <category>math.OC</category>
      <category>math.AG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tobias Metzlaff</dc:creator>
    </item>
    <item>
      <title>Low-rank approximated Kalman-Bucy filters using Oja's principal component flow for linear time-invariant systems</title>
      <link>https://arxiv.org/abs/2403.03104</link>
      <description>arXiv:2403.03104v3 Announce Type: replace 
Abstract: The Kalman-Bucy filter is extensively utilized across various applications. However, its computational complexity increases significantly in large-scale systems. To mitigate this challenge, a low-rank approximated Kalman--Bucy filter was proposed, comprising Oja's principal component flow and a low-dimensional Riccati differential equation. Previously, the estimation error was confirmed solely for linear time-invariant systems with a symmetric system matrix. This study extends the application by eliminating the constraint on the symmetricity of the system matrix and describes the equilibrium points of the Oja flow along with their stability for general matrices. In addition, the domain of attraction for a set of stable equilibrium points is estimated. Based on these findings, we demonstrate that the low-rank approximated Kalman--Bucy filter with a suitable rank maintains a bounded estimation error covariance matrix if the system is controllable and observable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.03104v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/LCSYS.2024.3412150</arxiv:DOI>
      <arxiv:journal_reference>IEEE Control Systems Letters (Early Access) 2024</arxiv:journal_reference>
      <dc:creator>Daiki Tsuzuki, Kentaro Ohki</dc:creator>
    </item>
    <item>
      <title>On the Convergence of the Sinkhorn-Knopp Algorithm with Sparse Cost Matrices</title>
      <link>https://arxiv.org/abs/2405.20528</link>
      <description>arXiv:2405.20528v4 Announce Type: replace 
Abstract: Matrix scaling problems with sparse cost matrices arise frequently in various domains, such as optimal transport, image processing, and machine learning. The Sinkhorn-Knopp algorithm is a popular iterative method for solving these problems, but its convergence properties in the presence of sparsity have not been thoroughly analyzed. This paper presents a theoretical analysis of the convergence rate of the Sinkhorn-Knopp algorithm specifically for sparse cost matrices. We derive novel bounds on the convergence rate that explicitly depend on the sparsity pattern and the degree of nonsparsity of the cost matrix. These bounds provide new insights into the behavior of the algorithm and highlight the potential for exploiting sparsity to develop more efficient solvers. We also explore connections between our sparse convergence results and existing convergence results for dense matrices, showing that our bounds generalize the dense case. Our analysis reveals that the convergence rate improves as the matrix becomes less sparse and as the minimum entry of the cost matrix increases relative to its maximum entry. These findings have important practical implications, suggesting that the Sinkhorn-Knopp algorithm may be particularly well-suited for large-scale matrix scaling problems with sparse cost matrices arising in real-world applications. Future research directions include investigating tighter bounds based on more sophisticated sparsity patterns, developing algorithm variants that actively exploit sparsity, and empirically validating the benefits of our theoretical results on real-world datasets. This work advances our understanding of the Sinkhorn-Knopp algorithm for an important class of matrix scaling problems and lays the foundation for designing more efficient and scalable solutions in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20528v4</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jose Rafael Espinosa Mena</dc:creator>
    </item>
    <item>
      <title>Essentially Sharp Estimates on the Entropy Regularization Error in Discrete Discounted Markov Decision Processes</title>
      <link>https://arxiv.org/abs/2406.04163</link>
      <description>arXiv:2406.04163v2 Announce Type: replace 
Abstract: We study the error introduced by entropy regularization of infinite-horizon discrete discounted Markov decision processes. We show that this error decreases exponentially in the inverse regularization strength both in a weighted KL-divergence and in value with a problem-specific exponent. We provide a lower bound matching our upper bound up to a polynomial factor. Our proof relies on the correspondence of the solutions of entropy-regularized Markov decision processes with gradient flows of the unregularized reward with respect to a Riemannian metric common in natural policy gradient methods. Further, this correspondence allows us to identify the limit of the gradient flow as the generalized maximum entropy optimal policy, thereby characterizing the implicit bias of the Kakade gradient flow which corresponds to a time-continuous version of the natural policy gradient method. We use this to show that for entropy-regularized natural policy gradient methods the overall error decays exponentially in the square root of the number of iterations improving existing sublinear guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04163v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Johannes M\"uller, Semih Cayci</dc:creator>
    </item>
    <item>
      <title>Straight-Through meets Sparse Recovery: the Support Exploration Algorithm</title>
      <link>https://arxiv.org/abs/2301.13584</link>
      <description>arXiv:2301.13584v3 Announce Type: replace-cross 
Abstract: The {\it straight-through estimator} (STE) is commonly used to optimize quantized neural networks, yet its contexts of effective performance are still unclear despite empirical successes.To make a step forward in this comprehension, we apply STE to a well-understood problem: {\it sparse support recovery}. We introduce the {\it Support Exploration Algorithm} (SEA), a novel algorithm promoting sparsity, and we analyze its performance in support recovery (a.k.a. model selection) problems. SEA explores more supports than the state-of-the-art, leading to superior performance in experiments, especially when the columns of $A$ are strongly coherent.The theoretical analysis considers recovery guarantees when the linear measurements matrix $A$ satisfies the {\it Restricted Isometry Property} (RIP).The sufficient conditions of recovery are comparable but more stringent than those of the state-of-the-art in sparse support recovery. Their significance lies mainly in their applicability to an instance of the STE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.13584v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>ICML 2024, the 41st International Conference on Machine Learning, Jul 2024, Vienna, Austria</arxiv:journal_reference>
      <dc:creator>Mimoun Mohamed (QARMA, I2M), Fran\c{c}ois Malgouyres (IMT), Valentin Emiya (QARMA), Caroline Chaux (IPAL)</dc:creator>
    </item>
    <item>
      <title>Time-Consistent Asset Allocation for Risk Measures in a L\'evy Market</title>
      <link>https://arxiv.org/abs/2305.09471</link>
      <description>arXiv:2305.09471v5 Announce Type: replace-cross 
Abstract: Focusing on gains &amp; losses relative to a risk-free benchmark instead of terminal wealth, we consider an asset allocation problem to maximize time-consistently a mean-risk reward function with a general risk measure which is i) law-invariant, ii) cash- or shift-invariant, and iii) positively homogeneous, and possibly plugged into a general function. Examples include (relative) Value at Risk, coherent risk measures, variance, and generalized deviation risk measures. We model the market via a generalized version of the multi-dimensional Black-Scholes model using $\alpha$-stable L\'evy processes and give supplementary results for the classical Black-Scholes model. The optimal solution to this problem is a Nash subgame equilibrium given by the solution of an extended Hamilton-Jacobi-Bellman equation. Moreover, we show that the optimal solution is deterministic under appropriate assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.09471v5</guid>
      <category>q-fin.MF</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Felix Fie{\ss}inger, Mitja Stadje</dc:creator>
    </item>
    <item>
      <title>Interpolatory $\mathcal{H}_2$-optimality Conditions for Structured Linear Time-invariant Systems</title>
      <link>https://arxiv.org/abs/2310.10618</link>
      <description>arXiv:2310.10618v3 Announce Type: replace-cross 
Abstract: Interpolatory necessary optimality conditions for $\mathcal{H}_2$-optimal reduced-order modeling of unstructured linear time-invariant (LTI) systems are well-known. Based on previous work on $\mathcal{L}_2$-optimal reduced-order modeling of stationary parametric problems, in this paper we develop and investigate optimality conditions for $\mathcal{H}_2$-optimal reduced-order modeling of structured LTI systems, in particular, for second-order, port-Hamiltonian, and time-delay systems. Under certain diagonalizability assumptions, we show that across all these different structured settings, bitangential Hermite interpolation is the common form for optimality, thus proving a unifying optimality framework for structured reduced-order modeling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.10618v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Petar Mlinari\'c, Peter Benner, Serkan Gugercin</dc:creator>
    </item>
    <item>
      <title>Mean-Square Exponential Stabilization of Mixed-Autonomy Traffic PDE System</title>
      <link>https://arxiv.org/abs/2310.15547</link>
      <description>arXiv:2310.15547v2 Announce Type: replace-cross 
Abstract: Control of mixed-autonomy traffic where Human-driven Vehicles (HVs) and Autonomous Vehicles (AVs) coexist on the road has gained increasing attention over the recent decades. This paper addresses the boundary stabilization problem for mixed traffic on freeways. The traffic dynamics are described by uncertain coupled hyperbolic partial differential equations (PDEs) with Markov jumping parameters, which aim to address the distinctive driving strategies between AVs and HVs. Considering that the spacing policies of AVs vary in mixed traffic, the stochastic impact area of AVs is governed by a continuous Markov chain. The interactions between HVs and AVs such as overtaking or lane changing are mainly induced by impact areas. Using backstepping design, we develop a full-state feedback boundary control law to stabilize the deterministic system (nominal system). Applying Lyapunov analysis, we demonstrate that the nominal backstepping control law is able to stabilize the traffic system with Markov jumping parameters, provided the nominal parameters are sufficiently close to the stochastic ones on average. The mean-square exponential stability conditions are derived, and the results are validated by numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.15547v2</guid>
      <category>math.AP</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yihuai Zhang, Huan Yu, Jean Auriol, Mike Pereira</dc:creator>
    </item>
    <item>
      <title>High-Performance Hybrid Algorithm for Minimum Sum-of-Squares Clustering of Infinitely Tall Data</title>
      <link>https://arxiv.org/abs/2311.04517</link>
      <description>arXiv:2311.04517v5 Announce Type: replace-cross 
Abstract: This paper introduces a novel formulation of the clustering problem, namely the Minimum Sum-of-Squares Clustering of Infinitely Tall Data (MSSC-ITD), and presents HPClust, an innovative set of hybrid parallel approaches for its effective solution. By utilizing modern high-performance computing techniques, HPClust enhances key clustering metrics: effectiveness, computational efficiency, and scalability. In contrast to vanilla data parallelism, which only accelerates processing time through the MapReduce framework, our approach unlocks superior performance by leveraging the multi-strategy competitive-cooperative parallelism and intricate properties of the objective function landscape. Unlike other available algorithms that struggle to scale, our algorithm is inherently parallel in nature, improving solution quality through increased scalability and parallelism, and outperforming even advanced algorithms designed for small and medium-sized datasets. Our evaluation of HPClust, featuring four parallel strategies, demonstrates its superiority over traditional and cutting-edge methods by offering better performance in the key metrics. These results also show that parallel processing not only enhances the clustering efficiency, but the accuracy as well. Additionally, we explore the balance between computational efficiency and clustering quality, providing insights into optimal parallel strategies based on dataset specifics and resource availability. This research advances our understanding of parallelism in clustering algorithms, demonstrating that a judicious hybridization of advanced parallel approaches yields optimal results for MSSC-ITD. Experiments on synthetic data further confirm HPClust's exceptional scalability and robustness to noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.04517v5</guid>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:DOI>10.3390/math12131930</arxiv:DOI>
      <arxiv:journal_reference>Mathematics 2024, 12, 1930</arxiv:journal_reference>
      <dc:creator>Ravil Mussabayev, Rustam Mussabayev</dc:creator>
    </item>
    <item>
      <title>On the numerical reliability of nonsmooth autodiff: a MaxPool case study</title>
      <link>https://arxiv.org/abs/2401.02736</link>
      <description>arXiv:2401.02736v2 Announce Type: replace-cross 
Abstract: This paper considers the reliability of automatic differentiation (AD) for neural networks involving the nonsmooth MaxPool operation. We investigate the behavior of AD across different precision levels (16, 32, 64 bits) and convolutional architectures (LeNet, VGG, and ResNet) on various datasets (MNIST, CIFAR10, SVHN, and ImageNet). Although AD can be incorrect, recent research has shown that it coincides with the derivative almost everywhere, even in the presence of nonsmooth operations (such as MaxPool and ReLU). On the other hand, in practice, AD operates with floating-point numbers  (not real numbers), and there is, therefore, a need to explore subsets on which AD can be numerically incorrect. These subsets include a bifurcation zone (where AD is incorrect over reals) and a compensation zone (where AD is incorrect over floating-point numbers but correct over reals). Using SGD for the training process, we study the impact of different choices of the nonsmooth Jacobian for the MaxPool function on the precision of 16 and 32 bits. These findings suggest that nonsmooth MaxPool Jacobians with lower norms help maintain stable and efficient test accuracy, whereas those with higher norms can result in instability and decreased performance. We also observe that the influence of MaxPool's nonsmooth Jacobians on learning can be reduced by using batch normalization, Adam-like optimizers, or increasing the precision level.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.02736v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Transactions on Machine Learning Research Journal, 2024, 23 p</arxiv:journal_reference>
      <dc:creator>Ryan Boustany (TSE-R)</dc:creator>
    </item>
    <item>
      <title>Accelerating Look-ahead in Bayesian Optimization: Multilevel Monte Carlo is All you Need</title>
      <link>https://arxiv.org/abs/2402.02111</link>
      <description>arXiv:2402.02111v2 Announce Type: replace-cross 
Abstract: We leverage multilevel Monte Carlo (MLMC) to improve the performance of multi-step look-ahead Bayesian optimization (BO) methods that involve nested expectations and maximizations. Often these expectations must be computed by Monte Carlo (MC). The complexity rate of naive MC degrades for nested operations, whereas MLMC is capable of achieving the canonical MC convergence rate for this type of problem, independently of dimension and without any smoothness assumptions. Our theoretical study focuses on the approximation improvements for twoand three-step look-ahead acquisition functions, but, as we discuss, the approach is generalizable in various ways, including beyond the context of BO. Our findings are verified numerically and the benefits of MLMC for BO are illustrated on several benchmark examples. Code is available at https://github.com/Shangda-Yang/MLMCBO .</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.02111v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shangda Yang, Vitaly Zankin, Maximilian Balandat, Stefan Scherer, Kevin Carlberg, Neil Walton, Kody J. H. Law</dc:creator>
    </item>
    <item>
      <title>Who Plays First? Optimizing the Order of Play in Stackelberg Games with Many Robots</title>
      <link>https://arxiv.org/abs/2402.09246</link>
      <description>arXiv:2402.09246v4 Announce Type: replace-cross 
Abstract: We consider the multi-agent spatial navigation problem of computing the socially optimal order of play, i.e., the sequence in which the agents commit to their decisions, and its associated equilibrium in an N-player Stackelberg trajectory game. We model this problem as a mixed-integer optimization problem over the space of all possible Stackelberg games associated with the order of play's permutations. To solve the problem, we introduce Branch and Play (B&amp;P), an efficient and exact algorithm that provably converges to a socially optimal order of play and its Stackelberg equilibrium. As a subroutine for B&amp;P, we employ and extend sequential trajectory planning, i.e., a popular multi-agent control approach, to scalably compute valid local Stackelberg equilibria for any given order of play. We demonstrate the practical utility of B&amp;P to coordinate air traffic control, swarm formation, and delivery vehicle fleets. We find that B&amp;P consistently outperforms various baselines, and computes the socially optimal equilibrium.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.09246v4</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haimin Hu, Gabriele Dragotto, Zixu Zhang, Kaiqu Liang, Bartolomeo Stellato, Jaime F. Fisac</dc:creator>
    </item>
    <item>
      <title>Breaking Consensus in Kinetic Opinion Formation Models on Graphons</title>
      <link>https://arxiv.org/abs/2403.14431</link>
      <description>arXiv:2403.14431v2 Announce Type: replace-cross 
Abstract: In this work we propose and investigate a strategy to prevent consensus in kinetic models for opinion formation. We consider a large interacting agent system, and assume that agent interactions are driven by compromise as well as self-thinking dynamics and also modulated by an underlying static social network. This network structure is included using so-called graphons, which modulate the interaction frequency in the corresponding kinetic formulation. We then derive the corresponding limiting Fokker Planck equation, and analyze its large time behavior. This microscopic setting serves as a starting point for the proposed control strategy, which steers agents away from mean opinion and is characterised by a suitable penalization depending on the properties of the graphon. We show that this minimalist approach is very effective by analyzing the quasi-stationary solutions mean-field model in a plurality of graphon structures. Several numerical experiments are also provided to show the effectiveness of the approach in preventing the formation of consensus steering the system towards a declustered state.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.14431v2</guid>
      <category>math-ph</category>
      <category>math.AP</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <category>physics.soc-ph</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Bertram D\"uring, Jonathan Franceschi, Marie-Therese Wolfram, Mattia Zanella</dc:creator>
    </item>
    <item>
      <title>Convex Optimization of Initial Perturbations toward Quantitative Weather Control</title>
      <link>https://arxiv.org/abs/2405.19546</link>
      <description>arXiv:2405.19546v2 Announce Type: replace-cross 
Abstract: This study proposes introducing convex optimization to find initial perturbations of atmospheric models for realizing specified changes in subsequent forecasts. In the proposed method, we formulate and solve an inverse problem to find effective perturbations in atmospheric variables so that controlled variables satisfy specified changes at a specified time. The proposed method first constructs a sensitivity matrix of controlled variables, such as accumulated precipitation, to the initial atmospheric variables, such as temperature and humidity, through sensitivity analysis using numerical weather prediction (NWP) models. The sensitivity matrix is used to solve the inverse problem as convex optimization, in which a global optimal solution can be found computationally efficiently. The proposed method was validated through a benchmark warm bubble experiment using an NWP model. The experiments showed that identified perturbation successfully realized specified spatial distributions of accumulated precipitation. These results demonstrated the possibility of controlling the real atmosphere by solving inverse problems and adding small perturbations to atmospheric states.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19546v2</guid>
      <category>physics.ao-ph</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Toshiyuki Ohtsuka, Atsushi Okazaki, Masaki Ogura, Shunji Kotsuki</dc:creator>
    </item>
  </channel>
</rss>
