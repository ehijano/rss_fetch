<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DB updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DB</link>
    <description>cs.DB updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DB" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 20 Aug 2024 04:00:32 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 20 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Leveraging Large Language Models for Enhanced Process Model Comprehension</title>
      <link>https://arxiv.org/abs/2408.08892</link>
      <description>arXiv:2408.08892v1 Announce Type: new 
Abstract: In Business Process Management (BPM), effectively comprehending process models is crucial yet poses significant challenges, particularly as organizations scale and processes become more complex. This paper introduces a novel framework utilizing the advanced capabilities of Large Language Models (LLMs) to enhance the interpretability of complex process models. We present different methods for abstracting business process models into a format accessible to LLMs, and we implement advanced prompting strategies specifically designed to optimize LLM performance within our framework. Additionally, we present a tool, AIPA, that implements our proposed framework and allows for conversational process querying. We evaluate our framework and tool by i) an automatic evaluation comparing different LLMs, model abstractions, and prompting strategies and ii) a user study designed to assess AIPA's effectiveness comprehensively. Results demonstrate our framework's ability to improve the accessibility and interpretability of process models, pioneering new pathways for integrating AI technologies into the BPM field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08892v1</guid>
      <category>cs.DB</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Humam Kourani, Alessandro Berti, Jasmin Henrich, Wolfgang Kratsch, Robin Weidlich, Chiao-Yun Li, Ahmad Arslan, Daniel Schuster, Wil M. P. van der Aalst</dc:creator>
    </item>
    <item>
      <title>The temporal conceptual data modelling language TREND</title>
      <link>https://arxiv.org/abs/2408.09427</link>
      <description>arXiv:2408.09427v1 Announce Type: new 
Abstract: Temporal conceptual data modelling, as an extension to regular conceptual data modelling languages such as EER and UML class diagrams, has received intermittent attention across the decades. It is receiving renewed interest in the context of, among others, business process modelling that needs robust expressive data models to complement them. None of the proposed temporal conceptual data modelling languages have been tested on understandability and usability by modellers, however, nor is it clear which temporal constraints would be used by modellers or whether the ones included are the relevant temporal constraints. We therefore sought to investigate temporal representations in temporal conceptual data modelling languages, design a, to date, most expressive language, TREND, through small-scale qualitative experiments, and finalise the graphical notation and modelling and understanding in large scale experiments. This involved a series of 11 experiments with over a thousand participants in total, having created 246 temporal conceptual data models. Key outcomes are that choice of label for transition constraints had limited impact, as did extending explanations of the modelling language, but expressing what needs to be modelled in controlled natural language did improve model quality. The experiments also indicate that more training may be needed, in particular guidance for domain experts, to achieve adoption of temporal conceptual data modelling by the community.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09427v1</guid>
      <category>cs.DB</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sonia Berman, C. Maria Keet, Tamindran Shunmugam</dc:creator>
    </item>
    <item>
      <title>The Story Behind the Lines: Line Charts as a Gateway to Dataset Discovery</title>
      <link>https://arxiv.org/abs/2408.09506</link>
      <description>arXiv:2408.09506v1 Announce Type: new 
Abstract: Line charts are a valuable tool for data analysis and exploration, distilling essential insights from a dataset. However, access to the underlying dataset behind a line chart is rarely readily available. In this paper, we explore a novel dataset discovery problem, dataset discovery via line charts, focusing on the use of line charts as queries to discover datasets within a large data repository that are capable of generating similar line charts. To solve this problem, we propose a novel approach called Fine-grained Cross-modal Relevance Learning Model (FCM), which aims to estimate the relevance between a line chart and a candidate dataset. To achieve this goal, FCM first employs a visual element extractor to extract informative visual elements, i.e., lines and y-ticks, from a line chart. Then, two novel segment-level encoders are adopted to learn representations for a line chart and a dataset, preserving fine-grained information, followed by a cross-modal matcher to match the learned representations in a fine-grained way. Furthermore, we extend FCM to support line chart queries generated based on data aggregation. Last, we propose a benchmark tailored for this problem since no such dataset exists. Extensive evaluation on the new benchmark verifies the effectiveness of our proposed method. Specifically, our proposed approach surpasses the best baseline by 30.1% and 41.0% in terms of prec@50 and ndcg@50, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09506v1</guid>
      <category>cs.DB</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daomin Ji, Hui Luo, Zhifeng Bao, J. Shane Culpper</dc:creator>
    </item>
    <item>
      <title>Can we measure the impact of a database?</title>
      <link>https://arxiv.org/abs/2408.09842</link>
      <description>arXiv:2408.09842v1 Announce Type: new 
Abstract: In disseminating scientific and statistical data, on-line databases have almost completely replaced traditional paper-based media such as journals and reference works. Given this, can we measure the impact of a database in the same way that we measure an author's or journal's impact? To do this, we need somehow to represent a database as a set of publications, and databases typically allow a large number of possible decompositions into parts, any of which could be treated as a publication.
  We show that the definition of the h-index naturally extends to hierarchies, so that if a database admits some kind of hierarchical interpretation we can use this as one measure of the importance of a database; moreover, this can be computed as efficiently as one can compute the normal h-index. This also gives us a decomposition of the database that might be used for other purposes such as giving credit to the curators or contributors to the database. We illustrate the process by analyzing three widely used databases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09842v1</guid>
      <category>cs.DB</category>
      <category>cs.DL</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Peter Buneman, Dennis Dosso, Matteo Lissandrini, Gianmaria Silvello, He Sun</dc:creator>
    </item>
    <item>
      <title>RoarGraph: A Projected Bipartite Graph for Efficient Cross-Modal Approximate Nearest Neighbor Search</title>
      <link>https://arxiv.org/abs/2408.08933</link>
      <description>arXiv:2408.08933v1 Announce Type: cross 
Abstract: Approximate Nearest Neighbor Search (ANNS) is a fundamental and critical component in many applications, including recommendation systems and large language model-based applications. With the advancement of multimodal neural models, which transform data from different modalities into a shared high-dimensional space as feature vectors, cross-modal ANNS aims to use the data vector from one modality (e.g., texts) as the query to retrieve the most similar items from another (e.g., images or videos). However, there is an inherent distribution gap between embeddings from different modalities, and cross-modal queries become Out-of-Distribution (OOD) to the base data. Consequently, state-of-the-art ANNS approaches suffer poor performance for OOD workloads. In this paper, we quantitatively analyze the properties of the OOD workloads to gain an understanding of their ANNS efficiency. Unlike single-modal workloads, we reveal OOD queries spatially deviate from base data, and the k-nearest neighbors of an OOD query are distant from each other in the embedding space. The property breaks the assumptions of existing ANNS approaches and mismatches their design for efficient search. With insights from the OOD workloads, we propose pRojected bipartite Graph (RoarGraph), an efficient ANNS graph index built under the guidance of query distribution. Extensive experiments show that RoarGraph significantly outperforms state-of-the-art approaches on modern cross-modal datasets, achieving up to 3.56x faster search speed at a 90% recall rate for OOD queries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08933v1</guid>
      <category>cs.IR</category>
      <category>cs.AI</category>
      <category>cs.DB</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.14778/3681954.3681959</arxiv:DOI>
      <dc:creator>Meng Chen, Kai Zhang, Zhenying He, Yinan Jing, X. Sean Wang</dc:creator>
    </item>
    <item>
      <title>BOD: Blindly Optimal Data Discovery</title>
      <link>https://arxiv.org/abs/2401.05712</link>
      <description>arXiv:2401.05712v3 Announce Type: replace 
Abstract: Combining discovery and augmentation is important in the era of data usage when it comes to predicting the outcome of tasks. However, having to ask the user the utility function to discover the goal to achieve the optimal small rightful dataset is not an optimal solution. The existing solutions do not make good use of this combination, hence underutilizing the data. In this paper, we introduce a novel goal-oriented framework, called BOD: Blindly Optimal Data Discovery, that involves humans in the loop and comparing utility scores every time querying in the process without knowing the utility function. This establishes the promise of using BOD: Blindly Optimal Data Discovery for modern data science solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.05712v3</guid>
      <category>cs.DB</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thomas Hoang</dc:creator>
    </item>
    <item>
      <title>UniTS: A Universal Time Series Analysis Framework Powered by Self-Supervised Representation Learning</title>
      <link>https://arxiv.org/abs/2303.13804</link>
      <description>arXiv:2303.13804v2 Announce Type: replace-cross 
Abstract: Machine learning has emerged as a powerful tool for time series analysis. Existing methods are usually customized for different analysis tasks and face challenges in tackling practical problems such as partial labeling and domain shift. To improve the performance and address the practical problems universally, we develop UniTS, a novel framework that incorporates self-supervised representation learning (or pre-training). The components of UniTS are designed using sklearn-like APIs to allow flexible extensions. We demonstrate how users can easily perform an analysis task using the user-friendly GUIs, and show the superior performance of UniTS over the traditional task-specific methods without self-supervised pre-training on five mainstream tasks and two practical settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.13804v2</guid>
      <category>cs.LG</category>
      <category>cs.DB</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3626246.3654733</arxiv:DOI>
      <arxiv:journal_reference>SIGMOD/PODS '24: International Conference on Management of Data, Santiago AA, Chile, June 9 - 15, 2024</arxiv:journal_reference>
      <dc:creator>Zhiyu Liang, Chen Liang, Zheng Liang, Hongzhi Wang, Bo Zheng</dc:creator>
    </item>
    <item>
      <title>LLMs for Knowledge Graph Construction and Reasoning: Recent Capabilities and Future Opportunities</title>
      <link>https://arxiv.org/abs/2305.13168</link>
      <description>arXiv:2305.13168v3 Announce Type: replace-cross 
Abstract: This paper presents an exhaustive quantitative and qualitative evaluation of Large Language Models (LLMs) for Knowledge Graph (KG) construction and reasoning. We engage in experiments across eight diverse datasets, focusing on four representative tasks encompassing entity and relation extraction, event extraction, link prediction, and question-answering, thereby thoroughly exploring LLMs' performance in the domain of construction and inference. Empirically, our findings suggest that LLMs, represented by GPT-4, are more suited as inference assistants rather than few-shot information extractors. Specifically, while GPT-4 exhibits good performance in tasks related to KG construction, it excels further in reasoning tasks, surpassing fine-tuned models in certain cases. Moreover, our investigation extends to the potential generalization ability of LLMs for information extraction, leading to the proposition of a Virtual Knowledge Extraction task and the development of the corresponding VINE dataset. Based on these empirical findings, we further propose AutoKG, a multi-agent-based approach employing LLMs and external sources for KG construction and reasoning. We anticipate that this research can provide invaluable insights for future undertakings in the field of knowledge graphs. The code and datasets are in https://github.com/zjunlp/AutoKG.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.13168v3</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.DB</category>
      <category>cs.IR</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuqi Zhu, Xiaohan Wang, Jing Chen, Shuofei Qiao, Yixin Ou, Yunzhi Yao, Shumin Deng, Huajun Chen, Ningyu Zhang</dc:creator>
    </item>
    <item>
      <title>Multi-Meta-RAG: Improving RAG for Multi-Hop Queries using Database Filtering with LLM-Extracted Metadata</title>
      <link>https://arxiv.org/abs/2406.13213</link>
      <description>arXiv:2406.13213v2 Announce Type: replace-cross 
Abstract: The retrieval-augmented generation (RAG) enables retrieval of relevant information from an external knowledge source and allows large language models (LLMs) to answer queries over previously unseen document collections. However, it was demonstrated that traditional RAG applications perform poorly in answering multi-hop questions, which require retrieving and reasoning over multiple elements of supporting evidence. We introduce a new method called Multi-Meta-RAG, which uses database filtering with LLM-extracted metadata to improve the RAG selection of the relevant documents from various sources, relevant to the question. While database filtering is specific to a set of questions from a particular domain and format, we found out that Multi-Meta-RAG greatly improves the results on the MultiHop-RAG benchmark. The code is available at https://github.com/mxpoliakov/Multi-Meta-RAG.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13213v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.DB</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mykhailo Poliakov, Nadiya Shvai</dc:creator>
    </item>
  </channel>
</rss>
