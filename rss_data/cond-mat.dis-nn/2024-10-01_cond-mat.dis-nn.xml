<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cond-mat.dis-nn updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cond-mat.dis-nn</link>
    <description>cond-mat.dis-nn updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cond-mat.dis-nn" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 02 Oct 2024 04:01:31 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Rigidity condition for gluing two bar-joint rigid graphs embedded in $\mathbb{R}^d$</title>
      <link>https://arxiv.org/abs/2410.00317</link>
      <description>arXiv:2410.00317v1 Announce Type: new 
Abstract: How does one determine if a collection of bars joined by freely rotating hinges cannot be deformed without changing the length of any of the bars? In other words, how does one determine if a bar-joint graph is rigid? This question has been definitively answered using combinatorial rigidity theory in two dimensions via the Geiringer-Laman Theorem. However, it has not yet been answered using combinatorial rigidity theory in higher dimensions, given known counterexamples to the trivial dimensional extension of the Geiringer-Laman Theorem. To work towards a combinatorial approach in dimensions beyond two, we present a theorem for gluing two rigid bar-joint graphs together that remain rigid. When there are no overlapping vertices between the two graphs, the theorem reduces to Tay's theorem used to identify rigidity in body-bar graphs. When there are overlapping vertices, we rely on the notion of pinned rigid graphs to identify and constrain rigid motions. This theorem provides a basis for an algorithm for recursively constructing rigid clusters that can be readily adapted for computational purposes. By leveraging Henneberg-type operations to grow a rigid (or minimally rigid) graph and treating simplices-where every vertex connects to every other vertex-as fundamental units, our approach offers a scalable solution with computational complexity comparable to traditional methods. Thus, we provide a combinatorial blueprint for algorithms in multi-dimensional rigidity theory as applied to bar-joint graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00317v1</guid>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.soft</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Kyungeun Kim, J. M. Schwarz</dc:creator>
    </item>
    <item>
      <title>Hammerstein equations for sparse random matrices</title>
      <link>https://arxiv.org/abs/2410.00355</link>
      <description>arXiv:2410.00355v1 Announce Type: new 
Abstract: Finding eigenvalue distributions for a number of sparse random matrix ensembles can be reduced to solving nonlinear integral equations of the Hammerstein type. While a systematic mathematical theory of such equations exists, it has not been previously applied to sparse matrix problems. We close this gap in the literature by showing how one can employ numerical solutions of Hammerstein equations to accurately recover the spectra of adjacency matrices and Laplacians of random graphs. While our treatment focuses on random graphs for concreteness, the methodology has broad applications to more general sparse random matrices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00355v1</guid>
      <category>cond-mat.dis-nn</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pawat Akara-pipattana, Oleg Evnin</dc:creator>
    </item>
    <item>
      <title>Generalization vs. Specialization under Concept Shift</title>
      <link>https://arxiv.org/abs/2409.15582</link>
      <description>arXiv:2409.15582v1 Announce Type: cross 
Abstract: Machine learning models are often brittle under distribution shift, i.e., when data distributions at test time differ from those during training. Understanding this failure mode is central to identifying and mitigating safety risks of mass adoption of machine learning. Here we analyze ridge regression under concept shift -- a form of distribution shift in which the input-label relationship changes at test time. We derive an exact expression for prediction risk in the high-dimensional limit. Our results reveal nontrivial effects of concept shift on generalization performance, depending on the properties of robust and nonrobust features of the input. We show that test performance can exhibit a nonmonotonic data dependence, even when double descent is absent. Finally, our experiments on MNIST and FashionMNIST suggest that this intriguing behavior is present also in classification problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.15582v1</guid>
      <category>stat.ML</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.LG</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alex Nguyen, David J. Schwab, Vudtiwat Ngampruetikorn</dc:creator>
    </item>
    <item>
      <title>Dynamic neurons: A statistical physics approach for analyzing deep neural networks</title>
      <link>https://arxiv.org/abs/2410.00396</link>
      <description>arXiv:2410.00396v1 Announce Type: cross 
Abstract: Deep neural network architectures often consist of repetitive structural elements. We introduce a new approach that reveals these patterns and can be broadly applied to the study of deep learning. Similar to how a power strip helps untangle and organize complex cable connections, this approach treats neurons as additional degrees of freedom in interactions, simplifying the structure and enhancing the intuitive understanding of interactions within deep neural networks. Furthermore, it reveals the translational symmetry of deep neural networks, which simplifies the application of the renormalization group transformation - a method that effectively analyzes the scaling behavior of the system. By utilizing translational symmetry and renormalization group transformations, we can analyze critical phenomena. This approach may open new avenues for studying deep neural networks using statistical physics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00396v1</guid>
      <category>cond-mat.stat-mech</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.LG</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Donghee Lee, Hye-Sung Lee, Jaeok Yi</dc:creator>
    </item>
    <item>
      <title>Exploring entanglement in finite-size quantum systems with degenerate ground state</title>
      <link>https://arxiv.org/abs/2410.00515</link>
      <description>arXiv:2410.00515v1 Announce Type: cross 
Abstract: We develop an approach for characterizing non-local quantum correlations in spin systems with exactly or nearly degenerate ground states. Starting with linearly independent degenerate eigenfunctions calculated with exact diagonalization we generate a finite set of their random linear combinations with Haar measure, which guarantees that these combinations are uniformly distributed in the space spanned by the initial eigenstates. Estimating the von Neumann entropy of the random wave functions helps to reveal previously unknown features of the quantum correlations in the phases with degeneracy of the ground state. For instance, spin spiral phase of the quantum magnet with Dzyaloshinskii-Moriya interaction is characterized by the enhancement of the entanglement entropy, which can be qualitatively explained by the changes in behaviour of two- and three-spin correlation functions. To establish the connection between our theoretical findings and real experiments we elaborate on the problem of estimating observables on the basis of the single-shot measurements of numerous degenerate eigenstates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00515v1</guid>
      <category>quant-ph</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.str-el</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>V. S. Okatev, O. M. Sotnikov, V. V. Mazurenko</dc:creator>
    </item>
    <item>
      <title>About the AT line in Replica Symmetry Breaking assumption for spin glasses</title>
      <link>https://arxiv.org/abs/2407.06701</link>
      <description>arXiv:2407.06701v2 Announce Type: replace 
Abstract: Replica Symmetry Breaking is a fascinating phenomenon of spin glasses model which could have consequences also in other field of studies. Although there are several studies regarding the stability between the Replica Symmetric and first step of Replica Symmetry Breaking approximations, we have very few results for the following steps (apart from that one by Gardner for P-spin glasses in 1985 and Chen in 2017 and 2021). This is link to the fact that the classic method, based from the work by De Almeida and Thoules (from which the critical stability line takes its name), is cumbersome to generalise for the next assumptions. In this paper we devise a new straightforward method inspired to the work by Toninelli in 2002 to recover the critical line in order to inspect the stability first between the second and the first steps of Replica Symmetry Breaking and then, we generalise to Kth step, with K finite.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06701v2</guid>
      <category>cond-mat.dis-nn</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Linda Albanese</dc:creator>
    </item>
    <item>
      <title>Revisiting the Lee-Yang singularities in the four-dimensional Ising model: a tribute to the memory of Ralph Kenna</title>
      <link>https://arxiv.org/abs/2402.03932</link>
      <description>arXiv:2402.03932v2 Announce Type: replace-cross 
Abstract: We have studied numerically the Lee-Yang singularities of the four dimensional Ising model at criticality, which is believed to be in the same universality class as the $\phi_4^4$ scalar field theory. We have focused in the numerical characterization of the logarithmic corrections to the scaling of the zeros of the partition function and its cumulative probability distribution, finding a very good agreement with the predictions of the renormalization group computation on the $\phi_4^4$ scalar field theory. To obtain these results, we have extended a previous study [R. Kenna, C. B. Lang, Nucl. Phys., 1993, B393, 461] in which there were computed numerically the first two zeros for $L\leqslant 24$ lattices, to the computation of the first four zeros for $L\leqslant 64$ lattices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.03932v2</guid>
      <category>cond-mat.stat-mech</category>
      <category>cond-mat.dis-nn</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.5488/CMP.27.33604</arxiv:DOI>
      <arxiv:journal_reference>Condensed Matter Physics, 2024, Vol. 27, No. 3, 33604</arxiv:journal_reference>
      <dc:creator>J. J. Ruiz-Lorenzo</dc:creator>
    </item>
    <item>
      <title>Statistical signatures of abstraction in deep neural networks</title>
      <link>https://arxiv.org/abs/2407.01656</link>
      <description>arXiv:2407.01656v2 Announce Type: replace-cross 
Abstract: We study how abstract representations emerge in a Deep Belief Network (DBN) trained on benchmark datasets. Our analysis targets the principles of learning in the early stages of information processing, starting from the "primordial soup" of the under-sampling regime. As the data is processed by deeper and deeper layers, features are detected and removed, transferring more and more "context-invariant" information to deeper layers. We show that the representation approaches an universal model -- the Hierarchical Feature Model (HFM) -- determined by the principle of maximal relevance. Relevance quantifies the uncertainty on the model of the data, thus suggesting that "meaning" -- i.e. syntactic information -- is that part of the data which is not yet captured by a model. Our analysis shows that shallow layers are well described by pairwise Ising models, which provide a representation of the data in terms of generic, low order features. We also show that plasticity increases with depth, in a similar way as it does in the brain. These findings suggest that DBNs are capable of extracting a hierarchy of features from the data which is consistent with the principle of maximal relevance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.01656v2</guid>
      <category>cs.LG</category>
      <category>cond-mat.dis-nn</category>
      <category>physics.data-an</category>
      <category>stat.ML</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Carlo Orientale Caputo, Matteo Marsili</dc:creator>
    </item>
  </channel>
</rss>
