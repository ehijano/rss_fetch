<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 03 Dec 2025 02:41:57 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Low-Cost Reliable Racetrack Cache Based on Data Compression</title>
      <link>https://arxiv.org/abs/2512.01915</link>
      <description>arXiv:2512.01915v1 Announce Type: new 
Abstract: SRAM-based cache memory faces several scalability limitations in deep nanoscale technologies, e.g., high leakage current, low cell stability, and low density. Emerging Non-Volatile Memory (NVM) technologies have received lots of attention in recent years, where Racetrack Memory (RTM) is among the most promising ones. RTM has the highest density among all NVMs and its access performance is comparable to SRAM technology. Therefore, RTM is a suitable alternative for SRAM in the Last-Level Caches (LLCs). Despite all its benefits, RTM confronts different reliability challenges due to the stochastic behavior of its storage element and highly error-prone data shifting, leading to a high probability of multiple-bit errors. Conventional Error-Correcting Codes (ECCs) are either incapable of tolerating multiple-bit errors or require a large amount of extra storage for check bits. This paper proposes taking advantage of value locality for compressing data blocks and freeing up a large fraction of cache blocks for storing data redundancy of strong ECCs. Utilizing the proposed scheme, a large majority of cache blocks are protected by strong ECCs to tolerate multiple-bit errors without any storage overhead. The evaluation using gem5 full-system simulator demonstrates that the proposed scheme enhances the mean-time-to-failure of the cache by an average of 11.3x with less than 1% hardware and performance overhead.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.01915v1</guid>
      <category>cs.ET</category>
      <category>cs.AR</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Elham Cheshmikhani, Fateme Shokouhinia, Hamed Farbeh</dc:creator>
    </item>
    <item>
      <title>Towards a future space-based, highly scalable AI infrastructure system design</title>
      <link>https://arxiv.org/abs/2511.19468</link>
      <description>arXiv:2511.19468v1 Announce Type: cross 
Abstract: If AI is a foundational general-purpose technology, we should anticipate that demand for AI compute -- and energy -- will continue to grow. The Sun is by far the largest energy source in our solar system, and thus it warrants consideration how future AI infrastructure could most efficiently tap into that power. This work explores a scalable compute system for machine learning in space, using fleets of satellites equipped with solar arrays, inter-satellite links using free-space optics, and Google tensor processing unit (TPU) accelerator chips. To facilitate high-bandwidth, low-latency inter-satellite communication, the satellites would be flown in close proximity. We illustrate the basic approach to formation flight via a 81-satellite cluster of 1 km radius, and describe an approach for using high-precision ML-based models to control large-scale constellations. Trillium TPUs are radiation tested. They survive a total ionizing dose equivalent to a 5 year mission life without permanent failures, and are characterized for bit-flip errors. Launch costs are a critical part of overall system cost; a learning curve analysis suggests launch to low-Earth orbit (LEO) may reach $\lesssim$\$200/kg by the mid-2030s.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.19468v1</guid>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <category>physics.space-ph</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Blaise Ag\"uera y Arcas, Travis Beals, Maria Biggs, Jessica V. Bloom, Thomas Fischbacher, Konstantin Gromov, Urs K\"oster, Rishiraj Pravahan, James Manyika</dc:creator>
    </item>
    <item>
      <title>Modeling and Simulation Frameworks for Processing-in-Memory Architectures</title>
      <link>https://arxiv.org/abs/2512.00096</link>
      <description>arXiv:2512.00096v1 Announce Type: cross 
Abstract: Processing-in-Memory (PIM) has emerged as a promising computing paradigm to address the memory wall and the fundamental bottleneck of the von Neumann architecture by reducing costly data movement between memory and processing units. As with any engineering challenge, identifying the most effective solutions requires thorough exploration of diverse architectural proposals, device technologies, and application domains. In this context, simulation plays a critical role in enabling researchers to evaluate, compare, and refine PIM designs prior to fabrication. Over the past decade, a variety of PIM simulators have been introduced, spanning low-level device models, architectural frameworks, and application-oriented environments. These tools differ significantly in fidelity, scalability, supported memory/compute technologies, and benchmark compatibility. Understanding these trade-offs is essential for researchers to select appropriate simulators that accurately map and validate their research efforts. This chapter provides a comprehensive overview of PIM simulation methodologies and tools. We categorize simulators according to abstraction levels, design objectives, and evaluation metrics, highlighting representative examples. To improve accessibility, some content may appear in multiple contexts to guide readers with different backgrounds. We also survey benchmark suites commonly employed in PIM studies and discuss open challenges in simulation methodology, paving the way for more reliable, scalable, and efficient PIM modeling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00096v1</guid>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mahdi Aghaei, Saba Ebrahimi, Mohammad Saleh Arafati, Elham Cheshmikhani, Dara Rahmati, Saeid Gorgin, Jungrae Kim</dc:creator>
    </item>
    <item>
      <title>Polynomial Neural Sheaf Diffusion: A Spectral Filtering Approach on Cellular Sheaves</title>
      <link>https://arxiv.org/abs/2512.00242</link>
      <description>arXiv:2512.00242v1 Announce Type: cross 
Abstract: Sheaf Neural Networks equip graph structures with a cellular sheaf: a geometric structure which assigns local vector spaces (stalks) and a linear learnable restriction/transport maps to nodes and edges, yielding an edge-aware inductive bias that handles heterophily and limits oversmoothing. However, common Neural Sheaf Diffusion implementations rely on SVD-based sheaf normalization and dense per-edge restriction maps, which scale with stalk dimension, require frequent Laplacian rebuilds, and yield brittle gradients. To address these limitations, we introduce Polynomial Neural Sheaf Diffusion (PolyNSD), a new sheaf diffusion approach whose propagation operator is a degree-K polynomial in a normalised sheaf Laplacian, evaluated via a stable three-term recurrence on a spectrally rescaled operator. This provides an explicit K-hop receptive field in a single layer (independently of the stalk dimension), with a trainable spectral response obtained as a convex mixture of K+1 orthogonal polynomial basis responses. PolyNSD enforces stability via convex mixtures, spectral rescaling, and residual/gated paths, reaching new state-of-the-art results on both homophilic and heterophilic benchmarks, inverting the Neural Sheaf Diffusion trend by obtaining these results with just diagonal restriction maps, decoupling performance from large stalk dimension, while reducing runtime and memory requirements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00242v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>stat.ML</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alessio Borgi, Fabrizio Silvestri, Pietro Li\`o</dc:creator>
    </item>
    <item>
      <title>A Novel 8T SRAM-Based In-Memory Computing Architecture for MAC-Derived Logical Functions</title>
      <link>https://arxiv.org/abs/2512.00441</link>
      <description>arXiv:2512.00441v1 Announce Type: cross 
Abstract: This paper presents an in-memory computing (IMC) architecture developed on an 8x8 array of 8T SRAM cells. This architecture enables both multi-bit parallel Multiply-Accumulate (MAC) operations and standard memory processing through charge-sharing on dedicated read bit-lines. By leveraging the maturity of SRAM technology, this work introduces an 8T SRAM-based IMC architecture that decouples read and write paths, thereby overcoming the reliability limitations of prior 6T SRAM designs. A novel analog-to-digital decoding scheme converts the MAC voltage output into digital counts, which are subsequently interpreted to realize fundamental logic functions including AND/NAND, NOR/OR, XOR/XNOR, and 1-bit addition within the same array. Simulated in a 90 nm CMOS process at 1.8 V supply voltage, the proposed design achieves 8-bit MAC and logical operations at a frequency of 142.85 MHz, with a latency of 0.7 ns and energy consumption of 56.56 fJ/bit per MAC operation and throughput of 15.8 M operations/s.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00441v1</guid>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amogh K M, Sunita M S</dc:creator>
    </item>
    <item>
      <title>Speculating on the Role of Media Architecture in Post-disaster Rebuilding and Recovery: Insights from Architects and Interaction Designers</title>
      <link>https://arxiv.org/abs/2512.00537</link>
      <description>arXiv:2512.00537v1 Announce Type: cross 
Abstract: In post-disaster contexts, design is not only about rebuilding structures but also about reimagining how architecture can become a communicative medium that supports recovery, resilience, and collective memory. While recent studies have expanded the understanding of media architecture from aesthetic urban screens to participatory civic infrastructures, there remains limited empirical research on its potential role in post-disaster contexts. In particular, opportunities exist to explore how architecture and interaction design might speculate on media architecture's role in rebuilding and recovery efforts for post-disaster permanent housing, especially when conceptualizing disasters as active agents that reshape design processes. Following to Kahramanmaras earthquake on February 6, 2023, we conducted two focus groups with architects and interaction designers in the case of Antakya, Turkey, building on affected residents' expectations for post-earthquake permanent housing. Our analysis revealed three critical dimensions of how future media architecture may support post-disaster housing: (1) as a facilitator of individuals' social connections to their community, (2) as an enabler of multispecies participation and collective efforts, and (3) as a mediator of heritage preservation and revival. With novel perspectives, we contribute a three-dimension lens for media architecture in permanent homes; a co-speculative, card-based process bridging residents' insights and expert design; and ten situated speculative design ideas with implications for design of post-disaster permanent homes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00537v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <category>cs.ET</category>
      <category>cs.MM</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Berk Goksenin Tan, Oguzhan Ozcan</dc:creator>
    </item>
    <item>
      <title>Sensing-Aided Near-Field Beam Tracking</title>
      <link>https://arxiv.org/abs/2512.00655</link>
      <description>arXiv:2512.00655v1 Announce Type: cross 
Abstract: The interplay between large antenna apertures and high carrier frequencies in future wireless systems gives rise to near-field communications, where the curvature of spherical wavefronts renders traditional far-field beamforming models inadequate. This chapter addresses the following fundamental questions on near-field operation: (i) What is the maximum distance where far-field approximations remain effective for path gain prediction and beam design? (ii) What level of position resolution is needed for accurate near-field beam focusing? (iii) How frequently must channel state information be updated to maintain highly directive bweamforming in dynamic scenarios? We develop an analytical framework for assessing near-field beamforming gain degradation due to mismatches between the focusing point and the coordinates of a user. Closed-form expressions for beam correlation, beam sensitivity to user movement, and the direction of fastest beamforming gain degradation are derived. A dynamic polar coordinate grid is also proposed for low complexity and adaptive near-field beam search. Furthermore, we introduce the novel concept of beam coherence time, quantifying the temporal robustness of focused beams and enabling proactive sensing-aided beam tracking strategies. The effect of microstrip losses on the preceding derivations is also analyzed. Finally, extensive simulation results validate the presented theoretical analysis and beam tracking method over randomly generated user trajectories.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00655v1</guid>
      <category>eess.SP</category>
      <category>cs.ET</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Panagiotis Gavriilidis, George C. Alexandropoulos</dc:creator>
    </item>
    <item>
      <title>Non-Negative Matrix Factorization Using Non-Von Neumann Computers</title>
      <link>https://arxiv.org/abs/2512.00675</link>
      <description>arXiv:2512.00675v1 Announce Type: cross 
Abstract: Non-negative matrix factorization (NMF) is a matrix decomposition problem with applications in unsupervised learning. The general form of this problem (along with many of its variants) is NP-hard in nature. In our work, we explore how this problem could be solved with an energy-based optimization method suitable for certain machines with non-von Neumann architectures. We used the Dirac-3, a device based on the entropy computing paradigm and made by Quantum Computing Inc., to evaluate our approach. Our formulations consist of (i) a quadratic unconstrained binary optimization model (QUBO, suitable for Ising machines) and a quartic formulation that allows for real-valued and integer variables (suitable for machines like the Dirac-3). Although current devices cannot solve large NMF problems, the results of our preliminary experiments are promising enough to warrant further research. For non-negative real matrices, we observed that a fusion approach of first using Dirac-3 and then feeding its results as the initial factor matrices to Scikit-learn's NMF procedure outperforms Scikit-learn's NMF procedure on its own, with default parameters in terms of the error in the reconstructed matrices. For our experiments on non-negative integer matrices, we compared the Dirac-3 device to Google's CP-SAT solver (inside the Or-Tools package) and found that for serial processing, Dirac-3 outperforms CP-SAT in a majority of the cases. We believe that future work in this area might be able to identify domains and variants of the problem where entropy computing (and other non-von Neumann architectures) could offer a clear advantage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00675v1</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ajinkya Borle, Charles Nicholas, Uchenna Chukwu, Mohammad-Ali Miri, Nicholas Chancellor</dc:creator>
    </item>
    <item>
      <title>Hierarchical Molecular Language Models (HMLMs)</title>
      <link>https://arxiv.org/abs/2512.00696</link>
      <description>arXiv:2512.00696v1 Announce Type: cross 
Abstract: Cellular signaling networks represent complex information processing systems that have been modeled via traditional mathematical or statistical approaches. However, these methods often struggle to capture context-dependent signaling, pathway cross-talk, and temporal dynamics across multiple biological scales. Here, we introduce hierarchical molecular language models (HMLMs), a novel architecture that proposes a molecular network-specific large language model (LLM) to use in intracellular communication as a specialized molecular language, which includes molecules as tokens, protein interactions, post-translational modifications, and regulatory events modeled as semantic relationships within an adapted transformer architecture. HMLMs employ graph-structured attention mechanisms to accommodate signaling network topology while integrating information across the molecular, pathway, and cellular scales through hierarchical attention patterns. We demonstrate HMLM superiority using a cardiac fibroblast signaling network comprising over 100 molecular species across functional modules connected by regulatory edges. HMLM achieved a mean squared error (MSE) of 0.058 for temporal signaling predictions, representing 30% improvement over graph neural networks (GNNs: 0.083) and 52% improvement over ordinary differential equation models (ODEs: 0.121), with particular advantages under sparse temporal sampling conditions where HMLM maintained MSE = 0.041 with only 4 time-points. The HMLMs offer a foundation for AI-driven biology and medicine with predictable scaling characteristics suitable for interactive applications. By bridging molecular mechanisms with cellular phenotypes through AI-driven molecular language representation, HMLMs provide a powerful paradigm for systems biology that advances precision medicine applications and therapeutic discovery in the era of AI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00696v1</guid>
      <category>q-bio.MN</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hasi Hays, Yue Yu, William Richardson</dc:creator>
    </item>
    <item>
      <title>Cross-Domain Federated Semantic Communication with Global Representation Alignment and Domain-Aware Aggregation</title>
      <link>https://arxiv.org/abs/2512.00711</link>
      <description>arXiv:2512.00711v1 Announce Type: cross 
Abstract: Semantic communication can significantly improve bandwidth utilization in wireless systems by exploiting the meaning behind raw data. However, the advancements achieved through semantic communication are closely dependent on the development of deep learning (DL) models for joint source-channel coding (JSCC) encoder/decoder techniques, which require a large amount of data for training. To address this data-intensive nature of DL models, federated learning (FL) has been proposed to train a model in a distributed manner, where the server broadcasts the DL model to clients in the network for training with their local data. However, the conventional FL approaches suffer from catastrophic degradation when client data are from different domains. In contrast, in this paper, a novel FL framework is proposed to address this domain shift by constructing the global representation, which aligns with the local features of the clients to preserve the semantics of different data domains. In addition, the dominance problem of client domains with a large number of samples is identified and, then, addressed with a domain-aware aggregation approach. This work is the first to consider the domain shift in training the semantic communication system for the image reconstruction task. Finally, simulation results demonstrate that the proposed approach outperforms the model-contrastive FL (MOON) framework by 0.5 for PSNR values under three domains at an SNR of 1 dB, and this gap continues to widen as the channel quality improves.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00711v1</guid>
      <category>cs.IT</category>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <category>cs.IR</category>
      <category>math.IT</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Loc X. Nguyen, Ji Su Yoon, Huy Q. Le, Yu Qiao, Avi Deb Raha, Eui-Nam Huh, Walid Saad, Dusit Niyato, Zhu Han, Choong Seon Hong</dc:creator>
    </item>
    <item>
      <title>A WASM-Subset Stack Architecture for Low-cost FPGAs using Open-Source EDA Flows</title>
      <link>https://arxiv.org/abs/2512.00974</link>
      <description>arXiv:2512.00974v1 Announce Type: cross 
Abstract: Soft-core processors on resource-constrained FPGAs often suffer from low code density and reliance on proprietary toolchains. This paper details the design, implementation, and evaluation of a 32-bit dual-stack microprocessor architecture optimized for low-cost, resource-constrained Field-Programmable Gate Arrays (FPGAs). Implemented on the Gowin GW1NR-9 (Tang Nano 9K), the processor utilizes an instruction set architecture (ISA) inspired from a subset of the WebAssembly (WASM) specification to achieve high code density. Unlike traditional soft-cores that often rely on proprietary vendor toolchains and opaque IP blocks, this design is synthesized and routed utilizing an open-source flow, providing transparency and portability. The architecture features a dual-stack model (Data and Return), executing directly from SPI Flash via an Execute-in-Place (XIP) mechanism to conserve scarce Block RAM on the intended target device. An analysis of the trade-offs involved in stack depth parametrization is presented, demonstrating that an 8-entry distributed RAM implementation provides a balance between logic resource utilization ($\sim 80\%$) and routing congestion. Furthermore, timing hazards in single-cycle stack operations are identified and resolved through a refined Finite State Machine (FSM) design. The system achieves a stable operating frequency of 27 MHz, limited by Flash latency, and successfully executes simple applications including a single and multi-digit infix calculator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00974v1</guid>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aradhya Chakrabarti (School of Computer Engineering, KIIT Deemed to be University)</dc:creator>
    </item>
    <item>
      <title>Internet of Intelligent Reflecting Surfaces (IoIRS)</title>
      <link>https://arxiv.org/abs/2512.01083</link>
      <description>arXiv:2512.01083v1 Announce Type: cross 
Abstract: Intelligent Reflecting Surfaces (IRS) are anticipated to serve as a key cornerstone of future wireless networks, providing an unmatched capability to deterministically shape electromagnetic wave propagation. Despite this potential, most existing research still considers the IRS merely as a standalone physical-layer component, controlled by transmitters. However, as networks grow to encompass a massive number of these surfaces and a massive number of transmitters wishing to use them, this transmitter-centric design encounters substantial challenges. To overcome this challenge, we propose the Internet of IRS (IoIRS), an architecture that reconceives the IRS not just as a passive reflecting surface, but as a connected, hybrid entity functioning across both the physical layer and upper network layers. We present the conceptual framework and a preliminary protocol suite necessary to integrate these surfaces into the higher network layers. We conclude by examining how IoIRS architectures could be applied in practice, as their deployment will be essential for fully realizing the capabilities of future wireless networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.01083v1</guid>
      <category>cs.NI</category>
      <category>cs.ET</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fatih E. Bilgen, A. Sila Okcu, O. Tansel Baydas, Ozgur B. Akan</dc:creator>
    </item>
    <item>
      <title>Social Media Data Mining of Human Behaviour during Bushfire Evacuation</title>
      <link>https://arxiv.org/abs/2512.01262</link>
      <description>arXiv:2512.01262v1 Announce Type: cross 
Abstract: Traditional data sources on bushfire evacuation behaviour, such as quantitative surveys and manual observations have severe limitations. Mining social media data related to bushfire evacuations promises to close this gap by allowing the collection and processing of a large amount of behavioural data, which are low-cost, accurate, possibly including location information and rich contextual information. However, social media data have many limitations, such as being scattered, incomplete, informal, etc. Together, these limitations represent several challenges to their usefulness to better understand bushfire evacuation. To overcome these challenges and provide guidance on which and how social media data can be used, this scoping review of the literature reports on recent advances in relevant data mining techniques. In addition, future applications and open problems are discussed. We envision future applications such as evacuation model calibration and validation, emergency communication, personalised evacuation training, and resource allocation for evacuation preparedness. We identify open problems such as data quality, bias and representativeness, geolocation accuracy, contextual understanding, crisis-specific lexicon and semantics, and multimodal data interpretation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.01262v1</guid>
      <category>cs.SI</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Junfeng Wu, Xiangmin Zhou, Erica Kuligowski, Dhirendra Singh, Enrico Ronchi, Max Kinateder</dc:creator>
    </item>
    <item>
      <title>BHRAM-IL: A Benchmark for Hallucination Recognition and Assessment in Multiple Indian Languages</title>
      <link>https://arxiv.org/abs/2512.01852</link>
      <description>arXiv:2512.01852v1 Announce Type: cross 
Abstract: Large language models (LLMs) are increasingly deployed in multilingual applications but often generate plausible yet incorrect or misleading outputs, known as hallucinations. While hallucination detection has been studied extensively in English, under-resourced Indian languages remain largely unexplored. We present BHRAM-IL, a benchmark for hallucination recognition and assessment in multiple Indian languages, covering Hindi, Gujarati, Marathi, Odia, along with English. The benchmark comprises 36,047 curated questions across nine categories spanning factual, numerical, reasoning, and linguistic tasks. We evaluate 14 state-of-the-art multilingual LLMs on a benchmark subset of 10,265 questions, analyzing cross-lingual and factual hallucinations across languages, models, scales, categories, and domains using category-specific metrics normalized to (0,1) range. Aggregation over all categories and models yields a primary score of 0.23 and a language-corrected fuzzy score of 0.385, demonstrating the usefulness of BHRAM-IL for hallucination-focused evaluation. The dataset, and the code for generation and evaluation are available on GitHub (https://github.com/sambhashana/BHRAM-IL/) and HuggingFace (https://huggingface.co/datasets/sambhashana/BHRAM-IL/) to support future research in multilingual hallucination detection and mitigation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.01852v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Hrishikesh Terdalkar, Kirtan Bhojani, Aryan Dongare, Omm Aditya Behera</dc:creator>
    </item>
    <item>
      <title>Event-Based Simulation of Stochastic Memristive Devices for Neuromorphic Computing</title>
      <link>https://arxiv.org/abs/2407.04718</link>
      <description>arXiv:2407.04718v3 Announce Type: replace 
Abstract: In this paper, we build a general modelling framework for memristors, suitable for the simulation of event-based systems such as hardware spiking neural networks, and more generally, neuromorphic computing systems composed of three independent components: i) an event-based modelling approach, extending and generalising an existing general model of memristors - the Generalised Metastable Switch Model (GMSM) - eliminating errors associated with discrete time approximation, as well as offering potential improvements in terms of suitability for neuromorphic memristive system simulations; ii) a volatility state variable to allow for the unified understanding of disparate non-linear and volatile phenomena, including state relaxation, structural disruption, Joule heating, and non-linear drift in different memristive devices; and iii) a readout equation that separates the latent state variable evolution from explicit variables of interest such as an instantaneous resistance. We exhibit an illustrative implementation of this framework, fit to a resistive drift dataset for titanium dioxide memristors, based on a proposed linear conductance model for resistive drift in the devices. Finally, we highlight the application of the model to neuromorphic computing, through demonstrating the contribution of the volatility state variable to switching dynamics, resulting in frequency-dependent switching (for stable memristors acting as programmable synaptic weights) and the generation of action potentials (for unstable memristors, acting as spike-generators).</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04718v3</guid>
      <category>cs.ET</category>
      <category>cs.NE</category>
      <category>physics.app-ph</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/MLSP62443.2025.11204291</arxiv:DOI>
      <dc:creator>Waleed El-Geresy, Christos Papavassiliou, Deniz G\"und\"uz</dc:creator>
    </item>
    <item>
      <title>LuGo: an Enhanced Quantum Phase Estimation Implementation</title>
      <link>https://arxiv.org/abs/2503.15439</link>
      <description>arXiv:2503.15439v2 Announce Type: replace-cross 
Abstract: Quantum Phase Estimation (QPE) is a cardinal algorithm in quantum computing that plays a crucial role in various applications, including cryptography, molecular simulation, and solving systems of linear equations. However, the standard implementation of QPE faces challenges related to time complexity and circuit depth, which limit its practicality for large-scale computations. We introduce LuGo, a novel framework designed to enhance the performance of QPE by reducing circuit duplication, as well as using parallelization techniques to achieve faster generation of the QPE circuit and gate reduction. We validate the effectiveness of our framework by generating quantum linear solver circuits, which require both QPE and inverse QPE, to solve linear systems of equations. LuGo achieves significant improvements in both computational efficiency and hardware requirements without compromising on accuracy. Compared to a standard QPE implementation, LuGo reduces time consumption to generate a circuit that solves a $2^6\times 2^6$ system matrix by a factor of $50.68$ and over $31\times$ reduction of quantum gates and circuit depth, with no fidelity loss on an ideal quantum simulator. We demonstrated the versatility and scalability of LuGo enabled HHL algorithm by simulating a canonical Hele-Shaw fluid problem using a quantum simulator. With these advantages, LuGo paves the way for more efficient implementations of QPE, enabling broader applications across several quantum computing domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15439v2</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <category>cs.SE</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Chao Lu, Muralikrishnan Gopalakrishanan Meena, Kalyana Chakravarthi Gottiparthi</dc:creator>
    </item>
  </channel>
</rss>
