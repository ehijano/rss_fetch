<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 26 Aug 2025 04:00:35 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Risk-Averse and Optimistic Advertiser Incentive Compatibility in Auto-bidding</title>
      <link>https://arxiv.org/abs/2508.16823</link>
      <description>arXiv:2508.16823v1 Announce Type: new 
Abstract: The rise of auto-bidding has created challenges for ensuring advertiser incentive compatibility, particularly when advertisers delegate bidding to agents with high-level constraints. One challenge in defining incentive compatibility is the multiplicity of equilibria. After advertisers submit reports, it is unclear what the result will be and one only has knowledge of a range of possible results. Nevertheless, Alimohammadi et al. proposed a notion of Auto-bidding Incentive Compatibility (AIC) which serves to highlight that auctions may not incentivize truthful reporting of constraints. However, their definition of AIC is very stringent as it requires that the worst-case outcome of an advertiser's truthful report is at least as good as the best-case outcome of any of the advertiser's possible deviations. Indeed, they show both First-Price Auction and Second-Price Auction are not AIC. Moreover, the AIC definition precludes having ordinal preferences on the possible constraints that the advertiser can report.
  In this paper, we introduce two refined and relaxed concepts: Risk-Averse Auto-bidding Incentive Compatibility (RAIC) and Optimistic Auto-bidding Incentive Compatibility (OAIC). RAIC (OAIC) stipulates that truthful reporting is preferred if its least (most) favorable equilibrium outcome is no worse than the least (most) favorable equilibrium outcome from any misreport. This distinction allows for a clearer modeling of ordinal preferences for advertisers with differing attitudes towards equilibrium uncertainty. We demonstrate that SPA satisfies both RAIC and OAIC. Furthermore, we show that SPA also meets these conditions for two advertisers when they are assumed to employ uniform bidding. These findings provide new insights into the incentive properties of SPA in auto-bidding environments, particularly when considering advertisers' perspectives on equilibrium selection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16823v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christopher Liaw, Wennan Zhu</dc:creator>
    </item>
    <item>
      <title>Personalized Pricing Through Strategic User Profiling in Social Networks</title>
      <link>https://arxiv.org/abs/2508.17111</link>
      <description>arXiv:2508.17111v1 Announce Type: new 
Abstract: Traditional user profiling techniques rely on browsing history or purchase records to identify users' willingness to pay. This enables sellers to offer personalized prices to profiled users while charging only a uniform price to non-profiled users. However, the emergence of privacy-enhancing technologies has caused users to actively avoid on-site data tracking. Today, major online sellers have turned to public platforms such as online social networks to better track users' profiles from their product-related discussions. This paper presents the first analytical study on how users should best manage their social activities against potential personalized pricing, and how a seller should strategically adjust her pricing scheme to facilitate user profiling in social networks. We formulate a dynamic Bayesian game played between the seller and users under asymmetric information. The key challenge of analyzing this game comes from the double couplings between the seller and the users as well as among the users. Furthermore, the equilibrium analysis needs to ensure consistency between users' revealed information and the seller's belief under random user profiling. We address these challenges by alternately applying backward and forward induction, and successfully characterize the unique perfect Bayesian equilibrium (PBE) in closed form. Our analysis reveals that as the accuracy of profiling technology improves, the seller tends to raise the equilibrium uniform price to motivate users' increased social activities and facilitate user profiling. However, this results in most users being worse off after the informed consent policy is imposed to ensure users' awareness of data access and profiling practices by potential sellers. This finding suggests that recent regulatory evolution towards enhancing users' privacy awareness may have unintended consequences of reducing users' payoffs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17111v1</guid>
      <category>cs.GT</category>
      <category>cs.SI</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TNET.2024.3410976.</arxiv:DOI>
      <arxiv:journal_reference>IEEE/ACM Transactions on Networking, vol. 32, no. 5, pp. 3977-3992, Oct. 2024</arxiv:journal_reference>
      <dc:creator>Qinqi Lin, Lingjie Duan, Jianwei Huang</dc:creator>
    </item>
    <item>
      <title>Designing Rules to Pick a Rule: Aggregation by Consistency</title>
      <link>https://arxiv.org/abs/2508.17177</link>
      <description>arXiv:2508.17177v1 Announce Type: new 
Abstract: Given a set of items and a set of evaluators who all individually rank them, how do we aggregate these evaluations into a single societal ranking? Work in social choice and statistics has produced many aggregation methods for this problem, each with its desirable properties, but also with its limitations. Further, existing impossibility results rule out designing a single method that achieves every property of interest. Faced with this trade-off between incompatible desiderata, how do we decide which aggregation rule to use, i.e., what is a good rule picking rule?
  In this paper, we formally address this question by introducing a novel framework for rule picking rules (RPRs). We then design a data-driven RPR that identifies the best aggregation method for each specific setting, without assuming any generative model. The principle behind our RPR is to pick the rule which maximizes the consistency of the output ranking if the data collection process were repeated. We introduce several consistency-related axioms for RPRs and show that our method satisfies them, including those failed by a wide class of natural RPRs. While we prove that the algorithmic problem of maximizing consistency is computationally hard, we provide a sampling-based implementation of our RPR that is efficient in practice. We run this implementation on known statistical models and find that, when possible, our method selects the maximum likelihood estimator of the data. Finally, we show that our RPR can be used in many real-world settings to gain insights about how the rule currently being used can be modified or replaced to substantially improve the consistency of the process.
  Taken together, our work bridges an important gap between the axiomatic and statistical approaches to rank aggregation, laying a robust theoretical and computational foundation for principled rule picking.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17177v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ratip Emin Berker, Ben Armstrong, Vincent Conitzer, Nihar B. Shah</dc:creator>
    </item>
    <item>
      <title>Decision-Making on Timing and Route Selection: A Game-Theoretic Approach</title>
      <link>https://arxiv.org/abs/2508.17206</link>
      <description>arXiv:2508.17206v1 Announce Type: new 
Abstract: We present a Stackelberg game model to investigate how individuals make their decisions on timing and route selection. Group formation can naturally result from these decisions, but only when individuals arrive at the same time and choose the same route. Although motivated by bird migration, our model applies to scenarios such as traffic planning, disaster evacuation, and other animal movements. Early arrivals secure better territories, while traveling together enhances navigation accuracy, foraging efficiency, and energy efficiency. Longer or more difficult migration routes reduce predation risks but increase travel costs, such as higher elevations and scarce food resources. Our analysis reveals a richer set of subgame perfect equilibria (SPEs) and heightened competition, compared to earlier models focused only on timing. By incorporating individual differences in travel costs, our model introduces a "neutrality" state in addition to "cooperation" and "competition."</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17206v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chenlan Wang, Mingyan Liu</dc:creator>
    </item>
    <item>
      <title>A Dynamic Approach to Collaborative Document Writing</title>
      <link>https://arxiv.org/abs/2508.17489</link>
      <description>arXiv:2508.17489v1 Announce Type: new 
Abstract: We introduce a model for collaborative text aggregation in which an agent community coauthors a document, modeled as an unordered collection of paragraphs, using a dynamic mechanism: agents propose paragraphs and vote on those suggested by others. We formalize the setting and explore its realizations, concentrating on voting mechanisms that aggregate votes into a single, dynamic document. We focus on two desiderata: the eventual stability of the process and its expected social welfare. Following an impossibility result, we describe several aggregation methods and report on agent-based simulations that utilize natural language processing (NLP) and large-language models (LLMs) to model agents and their contexts. Using these simulations, we demonstrate promising results regarding the possibility of rapid convergence to a high social welfare collaborative text.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17489v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Avital Finanser, Nimrod Talmon</dc:creator>
    </item>
    <item>
      <title>Price of Uncertainty for Consensus Games</title>
      <link>https://arxiv.org/abs/2508.17557</link>
      <description>arXiv:2508.17557v1 Announce Type: new 
Abstract: Many game-theoretic models assume that players have access to accurate information, but uncertainty in observed data is frequently present in real-world settings. In this paper, we consider a model of uncertainty where adversarial perturbations of relative magnitude $1+\varepsilon$ are introduced to players' observed costs. The effect of uncertainty on social cost is denoted as the price of uncertainty. We prove a tight bound on the price of uncertainty for consensus games of $\Theta(\varepsilon^2 n^2)$ for all $\varepsilon = \Omega\mathopen{}\left(n^{-1/4}\right)$. This improves a previous lower bound of $\Omega(\varepsilon^3 n^2)$ as well as a previous upper bound of $O(\varepsilon n^2)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17557v1</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>cs.SI</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yunzhe Bai, Alec Sun</dc:creator>
    </item>
    <item>
      <title>Consistent Opponent Modeling of Static Opponents in Imperfect-Information Games</title>
      <link>https://arxiv.org/abs/2508.17671</link>
      <description>arXiv:2508.17671v1 Announce Type: new 
Abstract: The goal of agents in multi-agent environments is to maximize total reward against the opposing agents that are encountered. Following a game-theoretic solution concept, such as Nash equilibrium, may obtain a strong performance in some settings; however, such approaches fail to capitalize on historical and observed data from repeated interactions against our opponents. Opponent modeling algorithms integrate machine learning techniques to exploit suboptimal opponents utilizing available data; however, the effectiveness of such approaches in imperfect-information games to date is quite limited. We show that existing opponent modeling approaches fail to satisfy a simple desirable property even against static opponents drawn from a known prior distribution; namely, they do not guarantee that the model approaches the opponent's true strategy even in the limit as the number of game iterations approaches infinity. We develop a new algorithm that is able to achieve this property and runs efficiently by solving a convex minimization problem based on the sequence-form game representation using projected gradient descent. The algorithm is guaranteed to efficiently converge to the opponent's true strategy given observations from gameplay and possibly additional historical data if it is available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17671v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <category>econ.TH</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sam Ganzfried</dc:creator>
    </item>
    <item>
      <title>WOMAC: A Mechanism For Prediction Competitions</title>
      <link>https://arxiv.org/abs/2508.17907</link>
      <description>arXiv:2508.17907v1 Announce Type: new 
Abstract: Competitions are widely used to identify top performers in judgmental forecasting and machine learning, and the standard competition design ranks competitors based on their cumulative scores against a set of realized outcomes or held-out labels. However, this standard design is neither incentive-compatible nor very statistically efficient. The main culprit is noise in outcomes/labels that experts are scored against; it allows weaker competitors to often win by chance, and the winner-take-all nature incentivizes misreporting that improves win probability even if it decreases expected score. Attempts to achieve incentive-compatibility rely on randomized mechanisms that add even more noise in winner selection, but come at the cost of determinism and practical adoption. To tackle these issues, we introduce a novel deterministic mechanism: WOMAC (Wisdom of the Most Accurate Crowd). Instead of scoring experts against noisy outcomes, as is standard, WOMAC scores experts against the best ex-post aggregate of peer experts' predictions given the noisy outcomes. WOMAC is also more efficient than the standard competition design in typical settings. While the increased complexity of WOMAC makes it challenging to analyze incentives directly, we provide a clear theoretical foundation to justify the mechanism. We also provide an efficient vectorized implementation and demonstrate empirically on real-world forecasting datasets that WOMAC is a more reliable predictor of experts' out-of-sample performance relative to the standard mechanism. WOMAC is useful in any competition where there is substantial noise in the outcomes/labels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17907v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Siddarth Srinivasan, Tao Lin, Connacher Murphy, Anish Thilagar, Yiling Chen, Ezra Karger</dc:creator>
    </item>
    <item>
      <title>Adaptive Learning for Moving Target defence: Enhancing Cybersecurity Strategies</title>
      <link>https://arxiv.org/abs/2508.17945</link>
      <description>arXiv:2508.17945v1 Announce Type: new 
Abstract: In this work, we model Moving Target Defence (MTD) as a partially observable stochastic game between an attacker and a defender. The attacker tries to compromise the system through probing actions, while the defender minimizes the risk by reimaging the system, balancing between performance cost and security level. We demonstrate that the optimal strategies for both players follow a threshold structure. Based on this insight, we propose a structure-aware policy gradient reinforcement learning algorithm that helps both players converge to the Nash equilibrium. This approach enhances the defender's ability to adapt and effectively counter evolving threats, improving the overall security of the system. Finally, we validate the proposed method through numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17945v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>International Conference on Control, Decision and Information Technologies (CoDIT 2025), Jul 2025, Croatie, Croatia</arxiv:journal_reference>
      <dc:creator>Mandar Datar (CEA-LETI), Yann Dujardin</dc:creator>
    </item>
    <item>
      <title>Axiomatizations of a simple Condorcet voting method for Final Four and Final Five elections</title>
      <link>https://arxiv.org/abs/2508.17095</link>
      <description>arXiv:2508.17095v1 Announce Type: cross 
Abstract: Proponents of Condorcet voting face the question of what to do in the rare case when no Condorcet winner exists. Recent work provides compelling arguments for the rule that should be applied in three-candidate elections, but already with four candidates, many rules appear reasonable. In this paper, we consider a recent proposal of a simple Condorcet voting method for Final Four political elections. Our question is what normative principles could support this simple form of Condorcet voting. When there is no Condorcet winner, one natural principle is to pick the candidate who is closest to being a Condorcet winner. Yet there are multiple plausible ways to define closeness, leading to different results. Here we take the following approach: identify a relatively uncontroversial sufficient condition for one candidate to be closer than another to being a Condorcet winner; then use other principles to help settle who wins in cases when that condition alone does not. We prove that our principles uniquely characterize the simple Condorcet voting method for Final Four elections. This analysis also points to a new way of extending the method to elections with five or more candidates that is simpler than an extension previously considered. The new proposal is to elect the candidate with the most head-to-head wins, and if multiple candidates tie for the most wins, then elect the one who has the smallest head-to-head loss. We provide additional principles sufficient to characterize this simple method for Final Five elections.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17095v1</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wesley H. Holliday</dc:creator>
    </item>
    <item>
      <title>Integrative Experiments Identify How Punishment Impacts Welfare in Public Goods Games</title>
      <link>https://arxiv.org/abs/2508.17151</link>
      <description>arXiv:2508.17151v1 Announce Type: cross 
Abstract: Punishment as a mechanism for promoting cooperation has been studied extensively for more than two decades, but its effectiveness remains a matter of dispute. Here, we examine how punishment's impact varies across cooperative settings through a large-scale integrative experiment. We vary 14 parameters that characterize public goods games, sampling 360 experimental conditions and collecting 147,618 decisions from 7,100 participants. Our results reveal striking heterogeneity in punishment effectiveness: while punishment consistently increases contributions, its impact on payoffs (i.e., efficiency) ranges from dramatically enhancing welfare (up to 43% improvement) to severely undermining it (up to 44% reduction) depending on the cooperative context. To characterize these patterns, we developed models that outperformed human forecasters (laypeople and domain experts) in predicting punishment outcomes in new experiments. Communication emerged as the most predictive feature, followed by contribution framing (opt-out vs. opt-in), contribution type (variable vs. all-or-nothing), game length (number of rounds), peer outcome visibility (whether participants can see others' earnings), and the availability of a reward mechanism. Interestingly, however, most of these features interact to influence punishment effectiveness rather than operating independently. For example, the extent to which longer games increase the effectiveness of punishment depends on whether groups can communicate. Together, our results refocus the debate over punishment from whether or not it "works" to the specific conditions under which it does and does not work. More broadly, our study demonstrates how integrative experiments can be combined with machine learning to uncover generalizable patterns, potentially involving interactions between multiple features, and help generate novel explanations in complex social phenomena.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17151v1</guid>
      <category>econ.GN</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammed Alsobay, David G. Rand, Duncan J. Watts, Abdullah Almaatouq</dc:creator>
    </item>
    <item>
      <title>Dynamic Reserve Price Design with Distributed Solving Algorithm</title>
      <link>https://arxiv.org/abs/2206.10295</link>
      <description>arXiv:2206.10295v2 Announce Type: replace 
Abstract: Unexpected advertising items in sponsored search may reduce users' reliance on organic search, resulting in hidden cost for the e-commerce platform. To address this problem and promote sustainable growth, we propose a dynamic reserve price design that incorporates the hidden cost into the auction mechanism to determine whether to sell the traffic, thereby ensuring a balanced relationship between revenue and user experience. Our dynamic reserve price design framework optimizes traffic sales by minimizing impacts on user experience while maintaining long-term incentives for advertisers to reveal their valuations truthfully. Furthermore, we introduce a distributed algorithm capable of computing reserve prices with billion-scale data in the production environment. Experiments involving offline evaluations and online A/B testing demonstrate that this method is simple and efficient, making it suitable for use in industrial production. This method has already been fully deployed in the production environment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.10295v2</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3746252.3760806</arxiv:DOI>
      <dc:creator>Mang Li</dc:creator>
    </item>
    <item>
      <title>Selling an Item Among a Strategic Bidder and a Profiled Agent</title>
      <link>https://arxiv.org/abs/2502.12313</link>
      <description>arXiv:2502.12313v2 Announce Type: replace 
Abstract: We consider the fundamental scenario where a single item is to be sold to one of two agents. Both agents draw their valuation for the item from the same probability distribution. However, only one of them submits a bid to the mechanism. The other agent is profiled, i.e., the mechanism receives a prediction for her valuation, which can be true or false. Our goal is to design mechanisms for selling the item that make as much revenue as possible in cases of a correct or incorrect prediction. As a benchmark for proving our revenue-approximation guarantees, we use the maximum expected revenue that can be obtained by a strategic and an honest bidder. We study two mechanisms. The first one yields optimal revenue when the prediction is guaranteed to be correct and a constant revenue approximation when the prediction is incorrect, assuming that the agent valuations are drawn from a monotone hazard rate (MHR) distribution. The second mechanism ignores the prediction for the second agent and simulates the revenue-optimal mechanism when no bid information for the bidders is available. We prove, again assuming that valuations are drawn from MHR distributions, that this mechanism achieves a constant revenue approximation guarantee compared to our revenue benchmark. The MHR assumption is necessary; we show that there are non-MHR but regular probability distributions for which no constant approximation of our revenue benchmark is possible.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12313v2</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ioannis Caragiannis, Georgios Kalantzis</dc:creator>
    </item>
    <item>
      <title>Optimistic Online Learning in Symmetric Cone Games</title>
      <link>https://arxiv.org/abs/2504.03592</link>
      <description>arXiv:2504.03592v2 Announce Type: replace-cross 
Abstract: We introduce symmetric cone games (SCGs), a broad class of multi-player games where each player's strategy lies in a generalized simplex (the trace-one slice of a symmetric cone). This framework unifies a wide spectrum of settings, including normal-form games (simplex strategies), quantum games (density matrices), and continuous games with ball-constrained strategies. It also captures several structured machine learning and optimization problems, such as distance metric learning and Fermat-Weber facility location, as two-player zero-sum SCGs. To compute approximate Nash equilibria in two-player zero-sum SCGs, we propose a single online learning algorithm: Optimistic Symmetric Cone Multiplicative Weights Updates (OSCMWU). Unlike prior methods tailored to specific geometries, OSCMWU provides closed-form, projection-free updates over any symmetric cone and achieves an optimal $\tilde{\mathcal{O}}(1/\epsilon)$ iteration complexity for computing $\epsilon$-saddle points. Our analysis builds on the Optimistic Follow-the-Regularized-Leader framework and hinges on a key technical contribution: We prove that the symmetric cone negative entropy is strongly convex with respect to the trace-one norm. This result extends known results for the simplex and spectraplex to all symmetric cones, and may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03592v2</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anas Barakat, Wayne Lin, John Lazarsfeld, Antonios Varvitsiotis</dc:creator>
    </item>
    <item>
      <title>Co-Investment with Payoff-Sharing Mechanism for Cooperative Decision-Making in Network Design Games</title>
      <link>https://arxiv.org/abs/2508.12059</link>
      <description>arXiv:2508.12059v2 Announce Type: replace-cross 
Abstract: Network-based systems are inherently interconnected, with the design and performance of subnetworks being interdependent. However, the decisions of self-interested operators may lead to suboptimal outcomes for users and the overall system. This paper explores cooperative mechanisms that can simultaneously benefit both operators and users. We address this challenge using a game-theoretical framework that integrates both non-cooperative and cooperative game theory. In the non-cooperative stage, we propose a network design game in which subnetwork decision-makers strategically design local infrastructures. In the cooperative stage, co-investment with payoff-sharing mechanism is developed to enlarge collective benefits and fairly distribute them. To demonstrate the effectiveness of our framework, we conduct case studies on the Sioux Falls network and real-world public transport networks in Zurich and Winterthur, Switzerland. Our evaluation considers impacts on environmental sustainability, social welfare, and economic efficiency. The proposed framework provides a foundation for improving interdependent networked systems by enabling strategic cooperation among self-interested operators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.12059v2</guid>
      <category>eess.SY</category>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mingjia He, Andrea Censi, Emilio Frazzoli, Gioele Zardini</dc:creator>
    </item>
  </channel>
</rss>
