<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.QM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.QM</link>
    <description>q-bio.QM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.QM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 15 Apr 2024 04:00:24 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 15 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Learning Chemotherapy Drug Action via Universal Physics-Informed Neural Networks</title>
      <link>https://arxiv.org/abs/2404.08019</link>
      <description>arXiv:2404.08019v1 Announce Type: new 
Abstract: Quantitative systems pharmacology (QSP) is widely used to assess drug effects and toxicity before the drug goes to clinical trial. However, significant manual distillation of the literature is needed in order to construct a QSP model. Parameters may need to be fit, and simplifying assumptions of the model need to be made. In this work, we apply Universal Physics-Informed Neural Networks (UPINNs) to learn unknown components of various differential equations that model chemotherapy pharmacodynamics. We learn three commonly employed chemotherapeutic drug actions (log-kill, Norton-Simon, and E_max) from synthetic data. Then, we use the UPINN method to fit the parameters for several synthetic datasets simultaneously. Finally, we learn the net proliferation rate in a model of doxorubicin (a chemotherapeutic) pharmacodynamics. As these are only toy examples, we highlight the usefulness of UPINNs in learning unknown terms in pharmacodynamic and pharmacokinetic models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08019v1</guid>
      <category>q-bio.QM</category>
      <category>cs.LG</category>
      <category>physics.chem-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lena Podina, Ali Ghodsi, Mohammad Kohandel</dc:creator>
    </item>
    <item>
      <title>Pathology-genomic fusion via biologically informed cross-modality graph learning for survival analysis</title>
      <link>https://arxiv.org/abs/2404.08023</link>
      <description>arXiv:2404.08023v1 Announce Type: new 
Abstract: The diagnosis and prognosis of cancer are typically based on multi-modal clinical data, including histology images and genomic data, due to the complex pathogenesis and high heterogeneity. Despite the advancements in digital pathology and high-throughput genome sequencing, establishing effective multi-modal fusion models for survival prediction and revealing the potential association between histopathology and transcriptomics remains challenging. In this paper, we propose Pathology-Genome Heterogeneous Graph (PGHG) that integrates whole slide images (WSI) and bulk RNA-Seq expression data with heterogeneous graph neural network for cancer survival analysis. The PGHG consists of biological knowledge-guided representation learning network and pathology-genome heterogeneous graph. The representation learning network utilizes the biological prior knowledge of intra-modal and inter-modal data associations to guide the feature extraction. The node features of each modality are updated through attention-based graph learning strategy. Unimodal features and bi-modal fused features are extracted via attention pooling module and then used for survival prediction. We evaluate the model on low-grade gliomas, glioblastoma, and kidney renal papillary cell carcinoma datasets from the Cancer Genome Atlas (TCGA) and the First Affiliated Hospital of Zhengzhou University (FAHZU). Extensive experimental results demonstrate that the proposed method outperforms both unimodal and other multi-modal fusion models. For demonstrating the model interpretability, we also visualize the attention heatmap of pathological images and utilize integrated gradient algorithm to identify important tissue structure, biological pathways and key genes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08023v1</guid>
      <category>q-bio.QM</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zeyu Zhang, Yuanshen Zhao, Jingxian Duan, Yaou Liu, Hairong Zheng, Dong Liang, Zhenyu Zhang, Zhi-Cheng Li</dc:creator>
    </item>
    <item>
      <title>Role of Noise in the Fairen-Velarde model of bacterial respiration</title>
      <link>https://arxiv.org/abs/2404.08437</link>
      <description>arXiv:2404.08437v1 Announce Type: new 
Abstract: Following our recent study (Kundu and Acharyya, Int. J. Mod. Phys. C (2024) 2450094), we have introduced stochasticity (random noise) in the Fairen-Velarde deterministic differential equations. The role of such noise on time scales is studied. The probability of reaching the domain of fixed points in a given interval is also calculated. The probability is studied as a function of the width of the noise, and a hyperbolic tangent fitting is proposed. The noise reduces the time scale for bringing the bacteria into an inactive state. The area of the fixed-point domain was found to be asympotically linear with noise. The time to reach the fixed-point domain is fitted to a Gaussian with noise intensity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08437v1</guid>
      <category>q-bio.QM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Soumyadeep Kundu, Muktish Acharyya</dc:creator>
    </item>
    <item>
      <title>SurvMamba: State Space Model with Multi-grained Multi-modal Interaction for Survival Prediction</title>
      <link>https://arxiv.org/abs/2404.08027</link>
      <description>arXiv:2404.08027v1 Announce Type: cross 
Abstract: Multi-modal learning that combines pathological images with genomic data has significantly enhanced the accuracy of survival prediction. Nevertheless, existing methods have not fully utilized the inherent hierarchical structure within both whole slide images (WSIs) and transcriptomic data, from which better intra-modal representations and inter-modal integration could be derived. Moreover, many existing studies attempt to improve multi-modal representations through attention mechanisms, which inevitably lead to high complexity when processing high-dimensional WSIs and transcriptomic data. Recently, a structured state space model named Mamba emerged as a promising approach for its superior performance in modeling long sequences with low complexity. In this study, we propose Mamba with multi-grained multi-modal interaction (SurvMamba) for survival prediction. SurvMamba is implemented with a Hierarchical Interaction Mamba (HIM) module that facilitates efficient intra-modal interactions at different granularities, thereby capturing more detailed local features as well as rich global representations. In addition, an Interaction Fusion Mamba (IFM) module is used for cascaded inter-modal interactive fusion, yielding more comprehensive features for survival prediction. Comprehensive evaluations on five TCGA datasets demonstrate that SurvMamba outperforms other existing methods in terms of performance and computational cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08027v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ying Chen, Jiajing Xie, Yuxiang Lin, Yuhang Song, Wenxian Yang, Rongshan Yu</dc:creator>
    </item>
    <item>
      <title>Combining Compositional Data Sets Introduces Error in Covariance Network Reconstruction</title>
      <link>https://arxiv.org/abs/2311.04357</link>
      <description>arXiv:2311.04357v2 Announce Type: replace 
Abstract: Microbial communities are diverse biological systems that include taxa from across multiple kingdoms of life. Notably, interactions between bacteria and fungi play a significant role in determining community structure. However, these statistical associations across kingdoms are more difficult to infer than intra-kingdom associations due to the nature of the data involved using standard network inference techniques. We quantify the challenges of cross-kingdom network inference from both a theoretical and practical viewpoint using synthetic and real-world microbiome data. We detail the theoretical issue presented by combining compositional data sets drawn from the same environment, e.g. 16S and ITS sequencing of a single set of samples, and survey common network inference techniques for their ability to handle this error. We then test these techniques for the accuracy and usefulness of their intra- and inter-kingdom associations by inferring networks from a set of simulated samples for which a ground-truth set of associations is known. We show that while two methods mitigate the error of cross-kingdom inference, there is little difference between techniques for key practical applications including identification of strong correlations and identification of possible keystone taxa (i.e. hub nodes in the network). Furthermore, we identify a signature of the error caused transkingdom network inference and demonstrate that it appears in networks constructed using real-world environmental microbiome data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.04357v2</guid>
      <category>q-bio.QM</category>
      <category>q-bio.PE</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>James D. Brunner, Aaron J. Robinson, Patrick S. G. Chain</dc:creator>
    </item>
    <item>
      <title>Structured methods for parameter inference and uncertainty quantification for mechanistic models in the life sciences</title>
      <link>https://arxiv.org/abs/2403.01678</link>
      <description>arXiv:2403.01678v2 Announce Type: replace 
Abstract: Parameter inference and uncertainty quantification are important steps when relating mathematical models to real-world observations, and when estimating uncertainty in model predictions. However, methods for doing this can be computationally expensive, particularly when the number of unknown model parameters is large. The aim of this study is to develop and test an efficient profile likelihood-based method, which takes advantage of the structure of the mathematical model being used. We do this by identifying specific parameters that affect model output in a known way, such as a linear scaling. We illustrate the method by applying it to three caricature models from different areas of the life sciences: (i) a predator-prey model from ecology; (ii) a compartment-based epidemic model from health sciences; and, (iii) an advection-diffusion-reaction model describing transport of dissolved solutes from environmental science. We show that the new method produces results of comparable accuracy to existing profile likelihood methods, but with substantially fewer evaluations of the forward model. We conclude that our method could provide a much more efficient approach to parameter inference for models where a structured approach is feasible. Code to apply the new method to user-supplied models and data is provided via a publicly accessible repository.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01678v2</guid>
      <category>q-bio.QM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Michael J. Plank, Matthew J. Simpson</dc:creator>
    </item>
  </channel>
</rss>
