<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>eess.SP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/eess.SP</link>
    <description>eess.SP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/eess.SP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 14 Aug 2025 01:28:35 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Where is the Boundary: Multimodal Sensor Fusion Test Bench for Tissue Boundary Delineation</title>
      <link>https://arxiv.org/abs/2508.08257</link>
      <description>arXiv:2508.08257v1 Announce Type: new 
Abstract: Robot-assisted neurological surgery is receiving growing interest due to the improved dexterity, precision, and control of surgical tools, which results in better patient outcomes. However, such systems often limit surgeons' natural sensory feedback, which is crucial in identifying tissues -- particularly in oncological procedures where distinguishing between healthy and tumorous tissue is vital. While imaging and force sensing have addressed the lack of sensory feedback, limited research has explored multimodal sensing options for accurate tissue boundary delineation. We present a user-friendly, modular test bench designed to evaluate and integrate complementary multimodal sensors for tissue identification. Our proposed system first uses vision-based guidance to estimate boundary locations with visual cues, which are then refined using data acquired by contact microphones and a force sensor. Real-time data acquisition and visualization are supported via an interactive graphical interface. Experimental results demonstrate that multimodal fusion significantly improves material classification accuracy. The platform provides a scalable hardware-software solution for exploring sensor fusion in surgical applications and demonstrates the potential of multimodal approaches in real-time tissue boundary delineation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08257v1</guid>
      <category>eess.SP</category>
      <category>cs.RO</category>
      <pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zacharias Chen, Alexa Cristelle Cahilig, Sarah Dias, Prithu Kolar, Ravi Prakash, Patrick J. Codd</dc:creator>
    </item>
    <item>
      <title>Hardware-friendly IR-HARQ for Polar SCL Decoders</title>
      <link>https://arxiv.org/abs/2508.08425</link>
      <description>arXiv:2508.08425v1 Announce Type: new 
Abstract: To extend the applications of polar codes within next-generation wireless communication systems, it is essential to incorporate support for Incremental Redundancy (IR) Hybrid Automatic Repeat Request (HARQ) schemes. The baseline IR-HARQ scheme's reliance on set-based operations leads to irregular memory access patterns, posing significant challenges for efficient hardware implementation. Furthermore, the introduction of new bit types increases the number of fast nodes that are decoded without traversing the sub-tree, resulting in a substantial area overhead when implemented in hardware. To address these issues and improve hardware compatibility, we propose transforming the set-based operations within the polar IR-HARQ scheme into binary vector operations. Additionally, we introduce a new fast node integration approach that avoids increasing the number of fast nodes, thereby minimizing the associated area overhead. Our proposed scheme results in a memory overhead of 25-27% compared to successive cancellation list (SCL) decoding without IR-HARQ support.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08425v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marwan Jalaleddine, Jiajie Li, Warren J. Gross</dc:creator>
    </item>
    <item>
      <title>Tensor-Structured Bayesian Channel Prediction for Upper Mid-Band XL-MIMO Systems</title>
      <link>https://arxiv.org/abs/2508.08491</link>
      <description>arXiv:2508.08491v1 Announce Type: new 
Abstract: The upper mid-band balances coverage and capacity for the future cellular systems and also embraces XL-MIMO systems, offering enhanced spectral and energy efficiency. However, these benefits are significantly degraded under mobility due to channel aging, and further exacerbated by the unique near-field (NF) and spatial non-stationarity (SnS) propagation in such systems. To address this challenge, we propose a novel channel prediction approach that incorporates dedicated channel modeling, probabilistic representations, and Bayesian inference algorithms for this emerging scenario. Specifically, we develop tensor-structured channel models in both the spatial-frequency-temporal (SFT) and beam-delay-Doppler (BDD) domains, which leverage temporal correlations among multiple pilot symbols for channel prediction. The factor matrices of multi-linear transformations are parameterized by BDD domain grids and SnS factors, where beam domain grids are jointly determined by angles and slopes under spatial-chirp based NF representations. To enable tractable inference, we replace environment-dependent BDD domain grids with uniformly sampled ones, and introduce perturbation parameters in each domain to mitigate grid mismatch. We further propose a hybrid beam domain strategy that integrates angle-only sampling with slope hyperparameterization to avoid the computational burden of explicit slope sampling. Based on the probabilistic models, we develop tensor-structured bi-layer inference (TS-BLI) algorithm under the expectation-maximization (EM) framework, which reduces computational complexity via tensor operations by leveraging the bi-layer factor graph for approximate E-step inference and an alternating strategy with closed-form updates in the M-step. Numerical simulations based on the near-practical channel simulator demonstrate the superior channel prediction performance of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08491v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongwei Hou, Yafei Wang, Xinping Yi, Wenjin Wang, Dirk T. M. Slock, Shi Jin</dc:creator>
    </item>
    <item>
      <title>An Analytical and Experimental Study of Distributed Uplink Beamforming in the Presence of Carrier Frequency Offsets</title>
      <link>https://arxiv.org/abs/2508.08506</link>
      <description>arXiv:2508.08506v1 Announce Type: new 
Abstract: Realizing distributed multi-user beamforming (D-MUBF) in time division duplex (TDD)-based multi-user MIMO (MU-MIMO) systems faces significant challenges. One of the most fundamental challenges is achieving accurate over-the-air (OTA) timing and frequency synchronization among distributed access points (APs), particularly due to residual frequency offsets caused by local oscillator (LO) drifts. Despite decades of research on synchronization for MU-MIMO, there are only a few experimental studies that evaluate D-MUBF techniques under imperfect frequency synchronization among distributed antennas. This paper presents an analytical and experimental assessment of D-MUBF methods in the presence of frequency synchronization errors. We provide closed-form expressions for signal-to-interference-plus-noise ratio (SINR) as a function of channel characteristics and statistical properties of carrier frequency offset (CFO) among AP antennas. In addition, through experimental evaluations conducted with the RENEW massive MIMO testbed, we collected comprehensive datasets across various experimental scenarios. These datasets comprise uplink pilot samples for channel and CFO estimation, in addition to uplink multi-user data intended for analyzing D-MUBF techniques. By examining these datasets, we assess the performance of D-MUBF in the presence of CFO and compare the analytical predictions with empirical measurements. Furthermore, we make the datasets publicly available and provide insights on utilizing them for future research endeavors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08506v1</guid>
      <category>eess.SP</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mehdi Zafari, Divyanshu Pandey, Rahman Doost-Mohammady</dc:creator>
    </item>
    <item>
      <title>Learning Zero Constellations for Binary MOCZ in Fading Channels</title>
      <link>https://arxiv.org/abs/2508.08571</link>
      <description>arXiv:2508.08571v1 Announce Type: new 
Abstract: In this work, we propose two methods to design zero constellations for binary modulation on conjugate-reciprocal zeros (BMOCZ). In the first approach, we treat constellation design as a multi-label binary classification problem and learn the zero locations for a direct zero-testing (DiZeT) decoder. In the second approach, we introduce a neural network (NN)-based decoder and jointly learn the decoder and zero constellation parameters. We show that the NN-based decoder can directly generalize to flat-fading channels, despite being trained under additive white Gaussian noise. Furthermore, the results of numerical simulations demonstrate that learned zero constellations outperform the canonical, Huffman BMOCZ constellation, with the proposed NN-based decoder achieving large performance gain at the expense of increased computational complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08571v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anthony Joseph Perre, Parker Huggins, Alphan Sahin</dc:creator>
    </item>
    <item>
      <title>Biomedical Signal Processing: EEG and ECG Classification with Discrete Wavelet Transforms, Energy Distribution, and Convolutional Neural Networks</title>
      <link>https://arxiv.org/abs/2508.08602</link>
      <description>arXiv:2508.08602v1 Announce Type: new 
Abstract: Biomedical signal processing extract meaningful information from physiological signals like electrocardiograms (ECGs), electroencephalograms (EEGs), and electromyograms (EMGs) to diagnose, monitor, and treat medical conditions and diseases such as seizures, cardiomyopathy, and neuromuscular disorders, respectively. Traditional manual physician analysis of electrical recordings is prone to human error as subtle anomolies may not be detected. Recently, advanced deep learning has significantly improved the accuracy of biomedical signal analysis. A multi-modal deep learning model is proposed that utilizes discrete wavelet transforms for signal pre-processing to reduce noise. A multi-modal image fusion and multimodal feature fusion framework is utilized that converts numeric biomedical signals into 2D and 3D images for image processing using Gramian angular fields, recurrency plots, and Markov transition fields. In this paper, deep learning models are applied to ECG, EEG, and human activity signals using actual medical datasets, brain, and heart recordings. The results demonstrate that using a multi-modal approach using wavelet transforms improves the accuracy of disease and disorder classification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08602v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Justin London</dc:creator>
    </item>
    <item>
      <title>Agentic Graph Neural Networks for Wireless Communications and Networking Towards Edge General Intelligence: A Survey</title>
      <link>https://arxiv.org/abs/2508.08620</link>
      <description>arXiv:2508.08620v1 Announce Type: new 
Abstract: The rapid advancement of communication technologies has driven the evolution of communication networks towards both high-dimensional resource utilization and multifunctional integration. This evolving complexity poses significant challenges in designing communication networks to satisfy the growing quality-of-service and time sensitivity of mobile applications in dynamic environments. Graph neural networks (GNNs) have emerged as fundamental deep learning (DL) models for complex communication networks. GNNs not only augment the extraction of features over network topologies but also enhance scalability and facilitate distributed computation. However, most existing GNNs follow a traditional passive learning framework, which may fail to meet the needs of increasingly diverse wireless systems. This survey proposes the employment of agentic artificial intelligence (AI) to organize and integrate GNNs, enabling scenario- and task-aware implementation towards edge general intelligence. To comprehend the full capability of GNNs, we holistically review recent applications of GNNs in wireless communications and networking. Specifically, we focus on the alignment between graph representations and network topologies, and between neural architectures and wireless tasks. We first provide an overview of GNNs based on prominent neural architectures, followed by the concept of agentic GNNs. Then, we summarize and compare GNN applications for conventional systems and emerging technologies, including physical, MAC, and network layer designs, integrated sensing and communication (ISAC), reconfigurable intelligent surface (RIS) and cell-free network architecture. We further propose a large language model (LLM) framework as an intelligent question-answering agent, leveraging this survey as a local knowledge base to enable GNN-related responses tailored to wireless communication research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08620v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yang Lu, Shengli Zhang, Chang Liu, Ruichen Zhang, Bo Ai, Dusit Niyato, Wei Ni, Xianbin Wang, Abbas Jamalipour</dc:creator>
    </item>
    <item>
      <title>Sparse Near-Field Channel Estimation for XL-MIMO via Adaptive Filtering</title>
      <link>https://arxiv.org/abs/2508.08663</link>
      <description>arXiv:2508.08663v1 Announce Type: new 
Abstract: Extremely large-scale multiple-input multiple-output (XL-MIMO) systems operating at sub-THz carrier frequencies represent a promising solution to meet the demands of next-generation wireless applications. This work focuses on sparse channel estimation for XL-MIMO systems operating in the near-field (NF) regime. Assuming a practical subarray-based architecture, we develop a NF channel estimation framework based on adaptive filtering, referred to as \textit{polar-domain zero-attracting least mean squares (PD-ZALMS)}. The proposed method achieves significantly superior channel estimation accuracy and lower computational complexity compared with the well-established polar-domain orthogonal matching pursuit. In addition, the proposed PD-ZALMS is shown to outperform the oracle least-squares channel estimator at low-to-moderate signal-to-noise ratio.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08663v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vidya Bhasker Shukla, Italo Atzeni</dc:creator>
    </item>
    <item>
      <title>VQ-VAE Based Digital Semantic Communication with Importance-Aware OFDM Transmission</title>
      <link>https://arxiv.org/abs/2508.08686</link>
      <description>arXiv:2508.08686v1 Announce Type: new 
Abstract: Semantic communication (SemCom) significantly reduces redundant data and improves transmission efficiency by extracting the latent features of information. However, most of the conventional deep learning-based SemCom systems focus on analog transmission and lack in compatibility with practical digital communications. This paper proposes a vector quantized-variational autoencoder (VQ-VAE) based digital SemCom system that directly transmits the semantic features and incorporates the importance-aware orthogonal frequency division multiplexing (OFDM) transmission to enhance the SemCom performance, where the VQ-VAE generates a discrete codebook shared between the transmitter and receiver. At transmitter, the latent semantic features are firstly extracted by VQ-VAE, and then the shared codebook is adopted to match these features, which are subsequently transformed into a discrete version to adapt the digital transmission. To protect the semantic information, an importance-aware OFDM transmission strategy is proposed to allocate the key features near the OFDM reference signals, where the feature importance is derived from the gradient-based method. At the receiver, the features are rematched with the shared codebook to further correct errors. Finally, experimental results demonstrate that our proposed scheme outperforms the conventional DeepSC and achieves better reconstruction performance under low SNR region.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08686v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ming Lyu, Hao Chen, Dan Wang, Chen Qiu, Guangyin Feng, Nan Ma, Xiaodong Xu</dc:creator>
    </item>
    <item>
      <title>Evaluating Task Execution Performance Under Energy Measurement Overhead</title>
      <link>https://arxiv.org/abs/2508.08757</link>
      <description>arXiv:2508.08757v1 Announce Type: new 
Abstract: Energy-awareness for adapting task execution behavior can bring several benefits in terms of performance improvement in energy harvesting (EH) Internet of Things (IoT) devices. However, the energy measurement cost of acquiring energy information, which is traditionally ignored, can potentially neutralize or even reverse the potential benefits. This paper highlights operational parameters, such as energy measurement frequency and task execution frequency, which can be tuned to improve the task execution performance of an EH-IoT device. To this end, we consider energy-blind (EB) and energy-aware (EA) task decision approaches and compare their task completion rate performance. We show that, for specific hardware design parameters of an EH-IoT device, there exists an optimal energy measurement/task execution frequency that can maximize the task completion rate in both approaches. Moreover, if these parameters are not chosen appropriately, then energy measurement costs can cause EA scheduling to underperform compared to EB scheduling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08757v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mateen Ashraf, Shahab Jahanbazi, Onel L. A. L\'opez</dc:creator>
    </item>
    <item>
      <title>Wideband Coplanar Waveguide MIMO Antenna for 6G Millimeter-Wave Applications with Defected Ground Structure</title>
      <link>https://arxiv.org/abs/2508.08771</link>
      <description>arXiv:2508.08771v1 Announce Type: new 
Abstract: This research study introduces a novel small antenna with wideband capacity for the higher frequency range. As a possible contender for 6G wireless networks, the proposed antenna is designed to target the 6G Millimeter-Wave (mmWave) operating bands spanning 25 GHz to 33.5 GHz. With a microstrip patch structure fed by a coplanar waveguide (CPW) with the defected ground structure (DGS), a single antenna is introduced and then a design of 2 x 2 MIMO antenna is presented. The single antenna has 2 elements, while the 2 x 2 MIMO antenna has 8 elements. It achieves remarkably well in terms of return loss of 8.5 GHz wideband, which is anticipated to be used for several applications in 6G mmWave technology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08771v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Atta Ullah, Daniyal Munir, Daniel Lindenschmitt, Hans D. Schotten</dc:creator>
    </item>
    <item>
      <title>Patient-Adaptive Focused Transmit Beamforming using Cognitive Ultrasound</title>
      <link>https://arxiv.org/abs/2508.08782</link>
      <description>arXiv:2508.08782v1 Announce Type: new 
Abstract: Focused transmit beamforming is the most commonly used acquisition scheme for echocardiograms, but suffers from relatively low frame rates, and in 3D, even lower volume rates. Fast imaging based on unfocused transmits has disadvantages such as motion decorrelation and limited harmonic imaging capabilities. This work introduces a patient-adaptive focused transmit scheme that has the ability to drastically reduce the number of transmits needed to produce a high-quality ultrasound image. The method relies on posterior sampling with a temporal diffusion model to perceive and reconstruct the anatomy based on partial observations, while subsequently taking an action to acquire the most informative transmits. This active perception modality outperforms random and equispaced subsampling on the 2D EchoNet-Dynamic dataset and a 3D Philips dataset, where we actively select focused elevation planes. Furthermore, we show it achieves better performance in terms of generalized contrast-to-noise ratio when compared to the same number of diverging waves transmits on three in-house echocardiograms. Additionally, we can estimate ejection fraction using only 2% of the total transmits and show that the method is robust to outlier patients. Finally, our method can be run in real-time on GPU accelerators from 2023. The code is publicly available at https://tue-bmd.github.io/ulsa/</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08782v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Wessel L. van Nierop, Ois\'in Nolan, Tristan S. W. Stevens, Ruud J. G. van Sloun</dc:creator>
    </item>
    <item>
      <title>ReQuestNet: A Foundational Learning model for Channel Estimation</title>
      <link>https://arxiv.org/abs/2508.08790</link>
      <description>arXiv:2508.08790v1 Announce Type: new 
Abstract: In this paper, we present a novel neural architecture for channel estimation (CE) in 5G and beyond, the Recurrent Equivariant UERS Estimation Network (ReQuestNet). It incorporates several practical considerations in wireless communication systems, such as ability to handle variable number of resource block (RB), dynamic number of transmit layers, physical resource block groups (PRGs) bundling size (BS), demodulation reference signal (DMRS) patterns with a single unified model, thereby, drastically simplifying the CE pipeline. Besides it addresses several limitations of the legacy linear MMSE solutions, for example, by being independent of other reference signals and particularly by jointly processing MIMO layers and differently precoded channels with unknown precoding at the receiver. ReQuestNet comprises of two sub-units, CoarseNet followed by RefinementNet. CoarseNet performs per PRG, per transmit-receive (Tx-Rx) stream channel estimation, while RefinementNet refines the CoarseNet channel estimate by incorporating correlations across differently precoded PRGs, and correlation across multiple input multiple output (MIMO) channel spatial dimensions (cross-MIMO). Simulation results demonstrate that ReQuestNet significantly outperforms genie minimum mean squared error (MMSE) CE across a wide range of channel conditions, delay-Doppler profiles, achieving up to 10dB gain at high SNRs. Notably, ReQuestNet generalizes effectively to unseen channel profiles, efficiently exploiting inter-PRG and cross-MIMO correlations under dynamic PRG BS and varying transmit layer allocations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08790v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>stat.ML</category>
      <pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kumar Pratik, Pouriya Sadeghi, Gabriele Cesa, Sanaz Barghi, Joseph B. Soriaga, Yuanning Yu, Supratik Bhattacharjee, Arash Behboodi</dc:creator>
    </item>
    <item>
      <title>Iterative Distortion Cancellation Algorithms for Single-Sideband Systems</title>
      <link>https://arxiv.org/abs/2508.08796</link>
      <description>arXiv:2508.08796v1 Announce Type: new 
Abstract: We propose an iterative distortion cancellation algorithm to digitally mitigate the impact of double-sideband dither signal amplitude from the automatic bias control module on Kramers-Kronig receivers without modifying physical layer structures. The algorithm utilizes the KK relation for initial signal decisions and reconstructs the distortion caused by dither signals. Experimental tests in back-to-back showed it improved tolerance to dither amplitudes up to 10% V{\pi}. For 80-km fiber transmission, the algorithm increased the receiver sensitivity by more than 1 dB, confirming the effectiveness of the proposed distortion cancellation method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08796v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jun Dong, Tianwai Bo, Zhuo Wang, Haolei Gao, Zhongwei Tan, Yi Dong</dc:creator>
    </item>
    <item>
      <title>Trajectory-adaptive Beam Shaping: Towards Beam-Management-Free Near-field Communications</title>
      <link>https://arxiv.org/abs/2508.08894</link>
      <description>arXiv:2508.08894v1 Announce Type: new 
Abstract: The quest for higher wireless carrier frequencies spanning the millimeter-wave (mmWave) and Terahertz (THz) bands heralds substantial enhancements in data throughput and spectral efficiency for next-generation wireless networks. However, these gains come at the cost of severe path loss and a heightened risk of beam misalignment due to user mobility, especially pronounced in near-field communication. Traditional solutions rely on extremely directional beamforming and frequent beam updates via beam management, but such techniques impose formidable computational and signaling overhead. In response, we propose a novel approach termed trajectory-adaptive beam shaping (TABS) that eliminates the need for real-time beam management by shaping the electromagnetic wavefront to follow the user's predefined trajectory. Drawing inspiration from self-accelerating beams in optics, TABS concentrates energy along pre-defined curved paths corresponding to the user's motion without requiring real-time beam reconfiguration. We further introduce a dedicated quantitative metric to characterize performance under the TABS framework. Comprehensive simulations substantiate the superiority of TABS in terms of link performance, overhead reduction, and implementation complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08894v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sicong Ye, Yulan Gao, Ming Xiao, Peng Wang, Marios Poulakis, Ulrik Imberg</dc:creator>
    </item>
    <item>
      <title>Scalable RIS-Aided Beamforming Strategies for Near-Field MU-MISO via Multi-Antenna Feeder</title>
      <link>https://arxiv.org/abs/2508.08993</link>
      <description>arXiv:2508.08993v1 Announce Type: new 
Abstract: This paper investigates a modular beamforming framework for reconfigurable intelligent surface (RIS)-aided multi-user (MU) communications in the near-field regime, built upon a novel antenna architecture integrating an active multi-antenna feeder (AMAF) array with a transmissive RIS (T-RIS), referred to as AT-RIS. This decoupling enables coordinated yet independently configurable designs in the AMAF and T-RIS domains, supporting flexible strategies with diverse complexity-performance trade-offs. Several implementations are analyzed, including diagonal and non-diagonal T-RIS architectures, paired with precoding schemes based on focusing, minimum mean square error, and eigenmode decomposition. Simulation results demonstrate that while non-diagonal schemes maximize sum rate in scenarios with a limited number of User Equipments (UEs) and high angular separability, they exhibit fairness and scalability limitations as UE density increases. Conversely, diagonal T-RIS configurations, particularly the proposed focusing-based scheme with uniform feeder-side power allocation, offer robust, fair, and scalable performance with minimal channel state information. The findings emphasize the critical impact of UEs' angular separability and reveal inherent trade-offs among spectral efficiency, complexity, and fairness, positioning diagonal AT-RIS architectures as practical solutions for scalable near-field MU multiple-input single-output systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08993v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giulia Torcolacci, Malte Schellmann, Davide Dardari</dc:creator>
    </item>
    <item>
      <title>Improved SINR Approximation for Downlink SDMA-based Networks with Outdated Channel State Information</title>
      <link>https://arxiv.org/abs/2508.09020</link>
      <description>arXiv:2508.09020v1 Announce Type: new 
Abstract: Understanding the performance of multi-user multiple-input multiple-output (MU-MIMO) systems under imperfect channel state information at the transmitter (CSIT) remains a critical challenge in next-generation wireless networks. In this context, accurate statistical modeling of the signal-to-interference-plus-noise ratio (SINR) is essential for enabling tractable performance analysis of multi-user systems. This paper presents an improved statistical approximation of the SINR for downlink (DL) MU-MIMO systems with imperfect CSIT. The proposed model retains the analytical simplicity of existing approaches (e.g., Gamma-based approximations) while overcoming their limitations, particularly the underestimation of SINR variance. We evaluate the proposed approximation in the context of Rate-Splitting Multiple Access (RSMA)-enabled MIMO DL systems with outdated CSIT. The results demonstrate excellent accuracy across a wide range of system configurations, including varying numbers of users, antennas, and degrees of CSIT staleness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09020v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maria Cecilia Fern\'andez Montefiore, Gustavo Gonz\'alez, F. Javier L\'opez-Mart\'inez, Fernando Gregorio</dc:creator>
    </item>
    <item>
      <title>Chartwin: a Case Study on Channel Charting-aided Localization in Dynamic Digital Network Twins</title>
      <link>https://arxiv.org/abs/2508.09055</link>
      <description>arXiv:2508.09055v1 Announce Type: new 
Abstract: Wireless communication systems can significantly benefit from the availability of spatially consistent representations of the wireless channel to efficiently perform a wide range of communication tasks. Towards this purpose, channel charting has been introduced as an effective unsupervised learning technique to achieve both locally and globally consistent radio maps. In this letter, we propose Chartwin, a case study on the integration of localization-oriented channel charting with dynamic Digital Network Twins (DNTs). Numerical results showcase the significant performance of semi-supervised channel charting in constructing a spatially consistent chart of the considered extended urban environment. The considered method results in $\approx$ 4.5 m localization error for the static DNT and $\approx$ 6 m in the dynamic DNT, fostering DNT-aided channel charting and localization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09055v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Lorenzo Cazzella, Francesco Linsalata, Mahdi Maleki, Damiano Badini, Matteo Matteucci, Umberto Spagnolini</dc:creator>
    </item>
    <item>
      <title>Spectral Efficiency Considerations for 6G</title>
      <link>https://arxiv.org/abs/2508.09117</link>
      <description>arXiv:2508.09117v1 Announce Type: new 
Abstract: As wireless connectivity continues to evolve towards 6G, there is an ever-increasing demand to not only deliver higher throughput, lower latency, and improved reliability, but also do so as efficiently as possible. To this point, the term efficiency has been quantified through applications to Spectral Efficiency (SE) and Energy Efficiency (EE). In this paper we introduce a new system metric called Radio Resource Utilization Efficiency (RUE). This metric quantifies the efficiency of the available radio resources (Spectrum, Access Method, Time Slots, Data Symbols, etc.) used to deliver future 6G demands. We compare the system performance of Typical Cellular and Cell-Free Massive MIMO deployments as a vehicle to demonstrate the need for this new metric. We begin by providing a concise treatment of items impacting SE by introducing three categories: 5G Radio Resources, Practical Limitations (such as channel matrix rank deficiency) and Implementation Losses (SINR degradation). For the example Radio Access Technology configuration analyzed, we show 5G yields an RUE of 47% (revealing significant room for improvement when defining 6G). Practical limitation assumptions are compared to 5G Multi-User MIMO (MU-MIMO) measurements conducted in a commercialized deployment. SE losses are characterized to offer guidance to advanced algorithms employing Machine Learning (ML) based techniques. We present the benefits of increasing the transmission Bandwidth (BW) from 100MHz to 1.6GHz. We describe a Next Generation RAN architecture that can support 6G and AI-RAN.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09117v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joseph Boccuzzi</dc:creator>
    </item>
    <item>
      <title>Exploring Disentangled Neural Speech Codecs from Self-Supervised Representations</title>
      <link>https://arxiv.org/abs/2508.08399</link>
      <description>arXiv:2508.08399v1 Announce Type: cross 
Abstract: Neural audio codecs (NACs), which use neural networks to generate compact audio representations, have garnered interest for their applicability to many downstream tasks -- especially quantized codecs due to their compatibility with large language models. However, unlike text, speech conveys not only linguistic content but also rich paralinguistic features. Encoding these elements in an entangled fashion may be suboptimal, as it limits flexibility. For instance, voice conversion (VC) aims to convert speaker characteristics while preserving the original linguistic content, which requires a disentangled representation. Inspired by VC methods utilizing $k$-means quantization with self-supervised features to disentangle phonetic information, we develop a discrete NAC capable of structured disentanglement. Experimental evaluations show that our approach achieves reconstruction performance on par with conventional NACs that do not explicitly perform disentanglement, while also matching the effectiveness of conventional VC techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08399v1</guid>
      <category>eess.AS</category>
      <category>eess.SP</category>
      <pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ryo Aihara, Yoshiki Masuyama, Gordon Wichern, Fran\c{c}ois G. Germain, Jonathan Le Roux</dc:creator>
    </item>
    <item>
      <title>Preprocessing Algorithm Leveraging Geometric Modeling for Scale Correction in Hyperspectral Images for Improved Unmixing Performance</title>
      <link>https://arxiv.org/abs/2508.08431</link>
      <description>arXiv:2508.08431v1 Announce Type: cross 
Abstract: Spectral variability significantly impacts the accuracy and convergence of hyperspectral unmixing algorithms. While many methods address complex spectral variability, large-scale variations in spectral signature scale caused by factors such as topography, illumination, and shadowing remain a major challenge. These variations often degrade unmixing performance and complicate model fitting. In this paper, we propose a novel preprocessing algorithm that corrects scale-induced spectral variability prior to unmixing. By isolating and compensating for these large-scale multiplicative effects, the algorithm provides a cleaner input, enabling unmixing methods to focus more effectively on modeling nonlinear spectral variability and abundance estimation. We present a rigorous mathematical framework to describe scale variability and extensive experimental validation of the proposed algorithm. Furthermore, the algorithm's impact is evaluated across a broad spectrum of state-of-the-art unmixing algorithms on two synthetic and two real hyperspectral datasets. The proposed preprocessing step consistently improves the performance of these algorithms, including those specifically designed to handle spectral variability, with error reductions close to 50% in many cases. This demonstrates that scale correction acts as a complementary step, facilitating more accurate unmixing by existing methods. The algorithm's generality and significant impact highlight its potential as a key component in practical hyperspectral unmixing pipelines. The implementation code will be made publicly available upon publication.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08431v1</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>eess.SP</category>
      <pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Praveen Sumanasekara, Athulya Ratnayake, Buddhi Wijenayake, Keshawa Ratnayake, Roshan Godaliyadda, Parakrama Ekanayake, Vijitha Herath</dc:creator>
    </item>
    <item>
      <title>Audio-Visual Speech Enhancement: Architectural Design and Deployment Strategies</title>
      <link>https://arxiv.org/abs/2508.08468</link>
      <description>arXiv:2508.08468v1 Announce Type: cross 
Abstract: This paper introduces a new AI-based Audio-Visual Speech Enhancement (AVSE) system and presents a comparative performance analysis of different deployment architectures. The proposed AVSE system employs convolutional neural networks (CNNs) for spectral feature extraction and long short-term memory (LSTM) networks for temporal modeling, enabling robust speech enhancement through multimodal fusion of audio and visual cues. Multiple deployment scenarios are investigated, including cloud-based, edge-assisted, and standalone device implementations. Their performance is evaluated in terms of speech quality improvement, latency, and computational overhead. Real-world experiments are conducted across various network conditions, including Ethernet, Wi-Fi, 4G, and 5G, to analyze the trade-offs between processing delay, communication latency, and perceptual speech quality. The results show that while cloud deployment achieves the highest enhancement quality, edge-assisted architectures offer the best balance between latency and intelligibility, meeting real-time requirements under 5G and Wi-Fi 6 conditions. These findings provide practical guidelines for selecting and optimizing AVSE deployment architectures in diverse applications, including assistive hearing devices, telepresence, and industrial communications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08468v1</guid>
      <category>cs.SD</category>
      <category>eess.SP</category>
      <pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anis Hamadouche, Haifeng Luo, Mathini Sellathurai, Tharm Ratnarajah</dc:creator>
    </item>
    <item>
      <title>MultiAiTutor: Child-Friendly Educational Multilingual Speech Generation Tutor with LLMs</title>
      <link>https://arxiv.org/abs/2508.08715</link>
      <description>arXiv:2508.08715v1 Announce Type: cross 
Abstract: Generative speech models have demonstrated significant potential in personalizing teacher-student interactions, offering valuable real-world applications for language learning in children's education. However, achieving high-quality, child-friendly speech generation remains challenging, particularly for low-resource languages across diverse languages and cultural contexts. In this paper, we propose MultiAiTutor, an educational multilingual generative AI tutor with child-friendly designs, leveraging LLM architecture for speech generation tailored for educational purposes. We propose to integrate age-appropriate multilingual speech generation using LLM architectures, facilitating young children's language learning through culturally relevant image-description tasks in three low-resource languages: Singaporean-accent Mandarin, Malay, and Tamil. Experimental results from both objective metrics and subjective evaluations demonstrate the superior performance of the proposed MultiAiTutor compared to baseline methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08715v1</guid>
      <category>eess.AS</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>eess.SP</category>
      <pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xiaoxue Gao, Huayun Zhang, Nancy F. Chen</dc:creator>
    </item>
    <item>
      <title>FetFIDS: A Feature Embedding Attention based Federated Network Intrusion Detection Algorithm</title>
      <link>https://arxiv.org/abs/2508.09056</link>
      <description>arXiv:2508.09056v1 Announce Type: cross 
Abstract: Intrusion Detection Systems (IDS) have an increasingly important role in preventing exploitation of network vulnerabilities by malicious actors. Recent deep learning based developments have resulted in significant improvements in the performance of IDS systems. In this paper, we present FetFIDS, where we explore the employment of feature embedding instead of positional embedding to improve intrusion detection performance of a transformer based deep learning system. Our model is developed with the aim of deployments in edge learning scenarios, where federated learning over multiple communication rounds can ensure both privacy and localized performance improvements. FetFIDS outperforms multiple state-of-the-art intrusion detection systems in a federated environment and demonstrates a high degree of suitability to federated learning. The code for this work can be found at https://github.com/ghosh64/fetfids.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09056v1</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shreya Ghosh, Abu Shafin Mohammad Mahdee Jameel, Aly El Gamal</dc:creator>
    </item>
    <item>
      <title>Developing a Transferable Federated Network Intrusion Detection System</title>
      <link>https://arxiv.org/abs/2508.09060</link>
      <description>arXiv:2508.09060v1 Announce Type: cross 
Abstract: Intrusion Detection Systems (IDS) are a vital part of a network-connected device. In this paper, we develop a deep learning based intrusion detection system that is deployed in a distributed setup across devices connected to a network. Our aim is to better equip deep learning models against unknown attacks using knowledge from known attacks. To this end, we develop algorithms to maximize the number of transferability relationships. We propose a Convolutional Neural Network (CNN) model, along with two algorithms that maximize the number of relationships observed. One is a two step data pre-processing stage, and the other is a Block-Based Smart Aggregation (BBSA) algorithm. The proposed system succeeds in achieving superior transferability performance while maintaining impressive local detection rates. We also show that our method is generalizable, exhibiting transferability potential across datasets and even with different backbones. The code for this work can be found at https://github.com/ghosh64/tabfidsv2.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09060v1</guid>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abu Shafin Mohammad Mahdee Jameel, Shreya Ghosh, Aly El Gamal</dc:creator>
    </item>
    <item>
      <title>A Radio Map Approach for Reduced Pilot CSI Tracking in Massive MIMO Networks</title>
      <link>https://arxiv.org/abs/2410.05803</link>
      <description>arXiv:2410.05803v5 Announce Type: replace 
Abstract: Massive multiple-input multiple-output (MIMO) systems offer significant potential to enhance wireless communication performance, yet accurate and timely channel state information (CSI) acquisition remains a key challenge. Existing works on CSI estimation and radio map applications typically rely on stationary CSI statistics and accurate location labels. However, the CSI process can be discontinuous due to user mobility and environmental variations, and inaccurate location data can degrade the performance. By contrast, this paper studies radio-map-embedded CSI tracking and radio map construction without the assumptions of stationary CSI statistics and precise location labels. Using radio maps as the prior information, this paper develops a radio-map-embedded switching Kalman filter (SKF) framework that jointly tracks the location and the CSI with adaptive beamforming for sparse CSI observations under reduced pilots. For radio map construction without precise location labels, the location sequence and the channel covariance matrices are jointly estimated based on a Hidden Markov Model (HMM). An unbiased estimator on the channel covariance matrix is found. Numerical results on ray-traced MIMO channel datasets demonstrate that using 1 pilot in every 10 milliseconds, an average of over 97% of capacity over that of perfect CSI can be achieved, while a conventional Kalman filter (KF) can only achieve 76%. Furthermore, the proposed radio-map-embedded CSI model can reduce the localization error from 30 meters from the prior to 6 meters for radio map construction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05803v5</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TSP.2025.3584229</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Signal Processing, vol. 73, pp. 2833-2847, 2025</arxiv:journal_reference>
      <dc:creator>Yuanshuai Zheng, Junting Chen</dc:creator>
    </item>
    <item>
      <title>Task-Oriented Feature Compression for Multimodal Understanding via Device-Edge Co-Inference</title>
      <link>https://arxiv.org/abs/2503.12926</link>
      <description>arXiv:2503.12926v2 Announce Type: replace 
Abstract: With the rapid development of large multimodal models (LMMs), multimodal understanding applications are emerging. As most LMM inference requests originate from edge devices with limited computational capabilities, the predominant inference pipeline involves directly forwarding the input data to an edge server which handles all computations. However, this approach introduces high transmission latency due to limited uplink bandwidth of edge devices and significant computation latency caused by the prohibitive number of visual tokens, thus hindering delay-sensitive tasks and degrading user experience. To address this challenge, we propose a task-oriented feature compression (TOFC) method for multimodal understanding in a device-edge co-inference framework, where visual features are merged by clustering and encoded by a learnable and selective entropy model before feature projection. Specifically, we employ density peaks clustering based on K nearest neighbors to reduce the number of visual features, thereby minimizing both data transmission and computational complexity. Subsequently, a learnable entropy model with hyperprior is utilized to encode and decode merged features, further reducing transmission overhead. To enhance compression efficiency, multiple entropy models are adaptively selected based on the characteristics of the visual features, enabling a more accurate estimation of the probability distribution. Comprehensive experiments on seven visual question answering benchmarks validate the effectiveness of the proposed TOFC method. Results show that TOFC achieves up to 52% reduction in data transmission overhead and 63% reduction in system latency while maintaining identical task performance, compared with neural compression ELIC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.12926v2</guid>
      <category>eess.SP</category>
      <category>cs.CV</category>
      <pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cheng Yuan, Zhening Liu, Jiashu Lv, Jiawei Shao, Yufei Jiang, Jun Zhang, Xuelong Li</dc:creator>
    </item>
    <item>
      <title>Aligning Beam with Imbalanced Multi-modality: A Generative Federated Learning Approach</title>
      <link>https://arxiv.org/abs/2504.14835</link>
      <description>arXiv:2504.14835v3 Announce Type: replace 
Abstract: As vehicle intelligence advances, multi-modal sensing-aided communication emerges as a key enabler for reliable Vehicle-to-Everything (V2X) connectivity through precise environmental characterization. As centralized learning may suffer from data privacy, model heterogeneity and communication overhead issues, federated learning (FL) has been introduced to support V2X. However, the practical deployment of FL faces critical challenges: model performance degradation from label imbalance across vehicles and training instability induced by modality disparities in sensor-equipped agents. To overcome these limitations, we propose a generative FL approach for beam selection (GFL4BS). Our solution features two core innovations: 1) An adaptive zero-shot multi-modal generator coupled with spectral-regularized loss functions to enhance the expressiveness of synthetic data compensating for both label scarcity and missing modalities; 2) A hybrid training paradigm integrating feature fusion with decentralized optimization to ensure training resilience while minimizing communication costs. Experimental evaluations demonstrate significant improvements over baselines achieving 16.2% higher accuracy than the current state-of-the-art under severe label imbalance conditions while maintaining over 70% successful rate even when two agents lack both LiDAR and RGB camera inputs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14835v3</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiahui Liang, Miaowen Wen, Shuoyao Wang, Yuxuan Liang, Shijian Gao</dc:creator>
    </item>
    <item>
      <title>Passive Multi-Target Visible Light Positioning Based on Multi-Camera Joint Optimization</title>
      <link>https://arxiv.org/abs/2506.02418</link>
      <description>arXiv:2506.02418v2 Announce Type: replace 
Abstract: Camera-based visible light positioning (VLP) has emerged as a promising indoor positioning technique. However, the need for dedicated luminaire infrastructure and on-target cameras in existing algorithms may limit their scalability and increase deployment costs. To address these limitations, this letter proposes a passive VLP algorithm based on Multi-Camera Joint Optimization (MCJO). In the considered system, multiple ceiling-mounted pre-calibrated cameras continuously capture images of targets with unmodulated point light sources, and can simultaneously localize these targets at the server. In particular, MCJO comprises two stages: It first estimates target positions via linear least squares (LLS) from multi-view projection rays; then refines these positions through nonlinear joint optimization to minimize the reprojection error. Simulation results show that MCJO can achieve millimeter-level accuracy, with an improvement of 19% over an LLS-based state-of-the-art algorithm. Experimental results further show that MCJO achieves an average position error as low as 5.63 mm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02418v2</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/LCOMM.2025.3598352</arxiv:DOI>
      <dc:creator>Wenxuan Pan, Yang Yang, Dong Wei, Meng Zhang, Zhiyu Zhu</dc:creator>
    </item>
    <item>
      <title>Zak-OTFS over CP-OFDM</title>
      <link>https://arxiv.org/abs/2508.03906</link>
      <description>arXiv:2508.03906v2 Announce Type: replace 
Abstract: Zak-Orthogonal Time Frequency Space (Zak-OTFS) modulation has been shown to achieve significantly better performance compared to the standardized Cyclic-Prefix Orthogonal Frequency Division Multiplexing (CP-OFDM), in high delay/Doppler spread scenarios envisaged in next generation communication systems. Zak-OTFS carriers are quasi-periodic pulses in the delay-Doppler (DD) domain, characterized by two parameters, (i) the pulse period along the delay axis (``delay period") (Doppler period is related to the delay period), and (ii) the pulse shaping filter. An important practical challenge is enabling support for Zak-OTFS modulation in existing CP-OFDM based modems. In this paper we show that Zak-OTFS modulation with pulse shaping constrained to sinc filtering (filter bandwidth equal to the communication bandwidth $B$) followed by time-windowing with a rectangular window of duration $(T + T_{cp})$ ($T$ is the symbol duration and $T_{cp}$ is the CP duration), can be implemented as a low-complexity precoder over standard CP-OFDM. We also show that the Zak-OTFS de-modulator with matched filtering constrained to sinc filtering (filter bandwidth $B$) followed by rectangular time windowing over duration $T$ can be implemented as a low-complexity post-processing of the CP-OFDM de-modulator output. This proposed ``Zak-OTFS over CP-OFDM" architecture enables us to harness the benefits of Zak-OTFS in existing network infrastructure. We also show that the proposed Zak-OTFS over CP-OFDM is a family of modulations, with CP-OFDM being a special case when the delay period takes its minimum possible value equal to the inverse bandwidth, i.e., Zak-OTFS over CP-OFDM with minimum delay period.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03906v2</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Saif Khan Mohammed, Saurabh Prakash, Muhammad Ubadah, Imran Ali Khan, Ronny Hadani, Shlomo Rakib, Shachar Kons, Yoav Hebron, Ananthanarayanan Chockalingam, Robert Calderbank</dc:creator>
    </item>
    <item>
      <title>RIS-Assisted NOMA with Partial CSI and Mutual Coupling: A Machine Learning Approach</title>
      <link>https://arxiv.org/abs/2508.07909</link>
      <description>arXiv:2508.07909v2 Announce Type: replace 
Abstract: Non-orthogonal multiple access (NOMA) is a promising multiple access technique. Its performance depends strongly on the wireless channel property, which can be enhanced by reconfigurable intelligent surfaces (RISs). In this paper, we jointly optimize base station (BS) precoding and RIS configuration with unsupervised machine learning (ML), which looks for the optimal solution autonomously. In particular, we propose a dedicated neural network (NN) architecture RISnet inspired by domain knowledge in communication. Compared to state-of-the-art, the proposed approach combines analytical optimal BS precoding and ML-enabled RIS, has a high scalability to control more than 1000 RIS elements, has a low requirement for channel state information (CSI) in input, and addresses the mutual coupling between RIS elements. Beyond the considered problem, this work is an early contribution to domain knowledge enabled ML, which exploit the domain expertise of communication systems to design better approaches than general ML methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07909v2</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bile Peng, Karl-Ludwig Besser, Shanpu Shen, Finn Siegismund-Poschmann, Ramprasad Raghunath, Daniel M. Mittleman, Vahid Jamali, Eduard A. Jorswieck</dc:creator>
    </item>
    <item>
      <title>Beamforming Design for Joint Target Sensing and Proactive Eavesdropping</title>
      <link>https://arxiv.org/abs/2407.06521</link>
      <description>arXiv:2407.06521v3 Announce Type: replace-cross 
Abstract: This work studies the beamforming design in the joint target sensing and proactive eavesdropping (JTSAPE) system. The JTSAPE base station (BS) receives the information transmitted by the illegal transmitter and transmits the waveform for target sensing. The shared waveform also serves as artificial noise to interfere with the illegal receiver, thereby achieving proactive eavesdropping. We firstly optimize the transmitting beam of the BS to maximize the eavesdropping signal-to-interference-plus-noise ratio or minimize the target estimation parameter Cram{\'{e}}r-Rao bound, respectively. Then, the joint optimization of proactive eavesdropping and target sensing is investigated, and the normalized weighted optimization problem is formulated. To address the complexity of the original problem, the formulated problem is decomposed into two subproblems: proactive eavesdropping and target sensing, which are solved by the semi-definite relaxation technique. Furthermore, the scenario in which the quality of the eavesdropping channel is stronger than that of the illegal channel is considered. We utilize the sequential rank-one constraint relaxation method and iteration technique to obtain the high-quality suboptimal solution of the beam transmit covariance matrix. Numerical simulation shows the effectiveness of our proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06521v3</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qian Dan, Hongjiang Lei, Ki-Hong Park, Gaofeng Pan, Mohamed-Slim Alouini</dc:creator>
    </item>
    <item>
      <title>Risk Estimate under a Time-Varying Autoregressive Model for Data-Driven Reproduction Number Estimation</title>
      <link>https://arxiv.org/abs/2409.14937</link>
      <description>arXiv:2409.14937v4 Announce Type: replace-cross 
Abstract: COVID-19 pandemic has brought to the fore epidemiological models which, though describing a wealth of behaviors, have previously received little attention in signal processing literature. In this work, a generalized time-varying autoregressive model is considered, encompassing, but not reducing to, a state-of-the-art model of viral epidemics propagation. The time-varying parameter of this model is estimated via the minimization of a penalized likelihood estimator. A major challenge is that the estimation accuracy strongly depends on hyperparameters fine-tuning. Without available ground truth, hyperparameters are selected by minimizing specifically designed data-driven oracles, used as proxy for the estimation error. Focusing on the time-varying autoregressive Poisson model, Stein's Unbiased Risk Estimate formalism is generalized to construct asymptotically unbiased risk estimators based on the derivation of an original autoregressive counterpart of Stein's lemma. The accuracy of these oracles and of the resulting estimates are assessed through intensive Monte Carlo simulations on synthetic data. Then, elaborating on recent epidemiological models, a novel weekly scaled Poisson model is proposed, better accounting for intrinsic variability of the contaminations while being robust to reporting errors. Finally, the data-driven procedure is particularized to the estimation of COVID-19 reproduction number from weekly infection counts demonstrating its ability to tackle real-world applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.14937v4</guid>
      <category>stat.ME</category>
      <category>eess.SP</category>
      <category>stat.AP</category>
      <pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Barbara Pascal, Samuel Vaiter</dc:creator>
    </item>
    <item>
      <title>Adaptive Informed Deep Neural Networks for Power Flow Analysis</title>
      <link>https://arxiv.org/abs/2412.02659</link>
      <description>arXiv:2412.02659v3 Announce Type: replace-cross 
Abstract: This study introduces PINN4PF, an end-to-end deep learning architecture for power flow (PF) analysis that effectively captures the nonlinear dynamics of large-scale modern power systems. The proposed neural network (NN) architecture consists of two important advancements in the training pipeline: (A) a double-head feed-forward NN that aligns with PF analysis, including an activation function that adjusts to the net active and reactive power injections patterns, and (B) a physics-based loss function that partially incorporates power system topology information through a novel hidden function. The effectiveness of the proposed architecture is illustrated through 4-bus, 15-bus, 290-bus, and 2224-bus test systems and is evaluated against two baselines: a linear regression model (LR) and a black-box NN (MLP). The comparison is based on (i) generalization ability, (ii) robustness, (iii) impact of training dataset size on generalization ability, (iv) accuracy in approximating derived PF quantities (specifically line current, line active power, and line reactive power), and (v) scalability. Results demonstrate that PINN4PF outperforms both baselines across all test systems by up to two orders of magnitude not only in terms of direct criteria, e.g., generalization ability, but also in terms of approximating derived physical quantities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02659v3</guid>
      <category>eess.SY</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zeynab Kaseb, Stavros Orfanoudakis, Pedro P. Vergara, Peter Palensky</dc:creator>
    </item>
  </channel>
</rss>
