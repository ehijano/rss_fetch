<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.IT</link>
    <description>math.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 26 Nov 2024 04:06:50 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 25 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>DNN based Two-stage Compensation Algorithm for THz Hybrid Beamforming with imperfect Hardware</title>
      <link>https://arxiv.org/abs/2411.14699</link>
      <description>arXiv:2411.14699v1 Announce Type: new 
Abstract: Terahertz (THz) communication is envisioned as a key technology for 6G and beyond wireless systems owing to its multi-GHz bandwidth. To maintain the same aperture area and the same link budget as the lower frequencies, ultra-massive multi-input and multi-output (UM-MIMO) with hybrid beamforming is promising. Nevertheless, the hardware imperfections particularly at THz frequencies, can degrade spectral efficiency and lead to a high symbol error rate (SER), which is often overlooked yet imperative to address in practical THz communication systems. In this paper, the hybrid beamforming is investigated for THz UM-MIMO systems accounting for comprehensive hardware imperfections, including DAC and ADC quantization errors, in-phase and quadrature imbalance (IQ imbalance), phase noise, amplitude and phase error of imperfect phase shifters and power amplifier (PA) nonlinearity. Then, a two-stage hardware imperfection compensation algorithm is proposed. A deep neural network (DNN) is developed in the first stage to represent the combined hardware imperfections, while in the second stage, the digital precoder in the transmitter (Tx) or the combiner in the receiver (Rx) is designed using NN to effectively compensate for these imperfections. Furthermore, to balance the performance and network complexity, three slimming methods including pruning, parameter sharing, and removing parts of the network are proposed and combined to slim the DNN in the first stage. Numerical results show that the Tx compensation can perform better than the Rx compensation. Additionally, using the combined slimming methods can reduce parameters by 97.2% and running time by 39.2% while maintaining nearly the same performance in both uncoded and coded systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14699v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Mon, 25 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenqi Zhao, Chong Han, Ho-Jin Song, Emil Bj\"ornson</dc:creator>
    </item>
    <item>
      <title>Capacity Approximations for Insertion Channels with Small Insertion Probabilities</title>
      <link>https://arxiv.org/abs/2411.14771</link>
      <description>arXiv:2411.14771v1 Announce Type: new 
Abstract: Channels with synchronization errors, exhibiting deletion and insertion errors, find practical applications in DNA storage, data reconstruction, and various other domains. Presence of insertions and deletions render the channel with memory, complicating capacity analysis. For instance, despite the formulation of an independent and identically distributed (i.i.d.) deletion channel more than fifty years ago, and proof that the channel is information stable, hence its Shannon capacity exists, calculation of the capacity remained elusive. However, a relatively recent result establishes the capacity of the deletion channel in the asymptotic regime of small deletion probabilities by computing the dominant terms of the capacity expansion. This paper extends that result to binary insertion channels, determining the dominant terms of the channel capacity for small insertion probabilities and establishing capacity in this asymptotic regime. Specifically, we consider two i.i.d. insertion channel models: insertion channel with possible random bit insertions after every transmitted bit and the Gallager insertion model, for which a bit is replaced by two random bits with a certain probability. To prove our results, we build on methods used for the deletion channel, employing Bernoulli(1/2) inputs for achievability and coupling this with a converse using stationary and ergodic processes as inputs, and show that the channel capacity differs only in the higher order terms from the achievable rates with i.i.d. inputs. The results, for instance, show that the capacity of the random insertion channel is higher than that of the Gallager insertion channel, and quantifies the difference in the asymptotic regime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14771v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 25 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Busra Tegin, Tolga M Duman</dc:creator>
    </item>
    <item>
      <title>New families of non-Reed-Solomon MDS codes</title>
      <link>https://arxiv.org/abs/2411.14779</link>
      <description>arXiv:2411.14779v1 Announce Type: new 
Abstract: MDS codes have garnered significant attention due to their wide applications in practice. To date, most known MDS codes are equivalent to Reed-Solomon codes. The construction of non-Reed-Solomon (non-RS) type MDS codes has emerged as an intriguing and important problem in both coding theory and finite geometry. Although some constructions of non-RS type MDS codes have been presented in the literature, the parameters of these MDS codes remain subject to strict constraints. In this paper, we introduce a general framework of constructing $[n,k]$ MDS codes using the idea of selecting a suitable set of evaluation polynomials and a set of evaluation points such that all nonzero polynomials have at most $k-1$ zeros in the evaluation set. Moreover, these MDS codes can be proved to be non-Reed-Solomon by computing their Schur squares. Furthermore, several explicit constructions of non-RS MDS codes are given by converting to combinatorial problems. As a result, new families of non-RS MDS codes with much more flexible lengths can be obtained and most of them are not covered by the known results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14779v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 25 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lingfei Jin, Liming Ma, Chaoping Xing, Haiyan Zhou</dc:creator>
    </item>
    <item>
      <title>Random Permutation Codes: Lossless Source Coding of Non-Sequential Data</title>
      <link>https://arxiv.org/abs/2411.14879</link>
      <description>arXiv:2411.14879v1 Announce Type: new 
Abstract: This thesis deals with the problem of communicating and storing non-sequential data. We investigate this problem through the lens of lossless source coding, also sometimes referred to as lossless compression, from both an algorithmic and information-theoretic perspective.
  Lossless compression algorithms typically preserve the ordering in which data points are compressed. However, there are data types where order is not meaningful, such as collections of files, rows in a database, nodes in a graph, and, notably, datasets in machine learning applications.
  Compressing with traditional algorithms is possible if we pick an order for the elements and communicate the corresponding ordered sequence. However, unless the order information is somehow removed during the encoding process, this procedure will be sub-optimal, because the order contains information and therefore more bits are used to represent the source than are truly necessary.
  In this work we give a formal definition for non-sequential objects as random sets of equivalent sequences, which we refer to as Combinatorial Random Variables (CRVs). The definition of equivalence, formalized as an equivalence relation, establishes the non-sequential data type represented by the CRV. The achievable rates of CRVs is fully characterized as a function of the equivalence relation as well as the data distribution.
  The optimal rates of CRVs are achieved within the family of Random Permutation Codes (RPCs) developed in later chapters. RPCs randomly select one-of-many possible sequences that can represent the instance of the CRV. Specialized RPCs are given for the case of multisets, graphs, and partitions/clusterings, providing new algorithms for compression of databases, social networks, and web data in the JSON file format.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14879v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Mon, 25 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Severo</dc:creator>
    </item>
    <item>
      <title>Optimal Beamforming for Multi-User Continuous Aperture Array (CAPA) Systems</title>
      <link>https://arxiv.org/abs/2411.14919</link>
      <description>arXiv:2411.14919v1 Announce Type: new 
Abstract: The optimal beamforming design for multi-user continuous aperture array (CAPA) systems is proposed. In contrast to conventional spatially discrete array (SPDA), the beamformer for CAPA is a continuous function rather than a discrete vector or matrix, rendering beamforming optimization a non-convex integral-based functional programming. To address this challenging issue, we first derive the closed-form optimal structure of the CAPA beamformer for maximizing generic system utility functions, by using the Lagrangian duality and the calculus of variations. The derived optimal structure is a linear combination of the continuous channel responses for CAPA, with the linear weights determined by the channel correlations. As a further advance, a monotonic optimization method is proposed for obtaining globally optimal CAPA beamforming based on the derived optimal structure. More particularly, a closed-form fixed-point iteration is proposed to obtain the globally optimal solution to the power minimization problem for CAPA beamforming. Furthermore, based on the optimal structure, the low-complexity maximum ratio transmission (MRT), zero-forcing (ZF), and minimum mean-squared error (MMSE) designs for CAPA beamforming are derived. It is theoretically proved that: 1) the MRT and ZF designs are asymptotically optimal in low and high signal-to-noise ratio (SNR) regimes, respectively, and 2) the MMSE design is optimal for signal-to-leakage-plus-noise ratio (SLNR) maximization. Our numerical results validate the effectiveness of the proposed designs and reveal that: i) CAPA achieves significant communication performance gain over SPDA, and ii) the MMSE design achieves nearly optimal performance in most cases, while the MRT and ZF designs achieve nearly optimal performance in specific cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14919v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Mon, 25 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaolin Wang, Chongjun Ouyang, Yuanwei Liu</dc:creator>
    </item>
    <item>
      <title>Generalized Multivariate Polynomial Codes for Distributed Matrix-Matrix Multiplication</title>
      <link>https://arxiv.org/abs/2411.14980</link>
      <description>arXiv:2411.14980v1 Announce Type: new 
Abstract: Supporting multiple partial computations efficiently at each of the workers is a keystone in distributed coded computing in order to speed up computations and to fully exploit the resources of heterogeneous workers in terms of communication, storage, or computation capabilities. Multivariate polynomial coding schemes have recently been shown to deliver faster results for distributed matrix-matrix multiplication compared to conventional univariate polynomial coding schemes by supporting multiple partial coded computations at each worker at reduced communication costs. In this work, we extend multivariate coding schemes to also support arbitrary matrix partitions. Generalized matrix partitions have been proved useful to trade-off between computation speed and communication costs in distributed (univariate) coded computing. We first formulate the computation latency-communication trade-off in terms of the computation complexity and communication overheads required by coded computing approaches as compared to a single server uncoded computing system. Then, we propose two novel multivariate coded computing schemes supporting arbitrary matrix partitions. The proposed schemes are shown to improve the studied trade-off as compared to univariate schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14980v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 25 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jes\'us G\'omez-Vilardeb\'o, Burak Has{\i}rc{\i}o\u{g}lu, Deniz G\"und\"uz</dc:creator>
    </item>
    <item>
      <title>Output Statistics of Random Binning: Tsallis Divergence and Its Applications</title>
      <link>https://arxiv.org/abs/2304.12606</link>
      <description>arXiv:2304.12606v4 Announce Type: replace 
Abstract: Random binning is a widely used technique in information theory with diverse applications. In this paper, we focus on the output statistics of random binning (OSRB) using the Tsallis divergence $T_\alpha$. We analyze all values of $\alpha \in (0, \infty)\cup\{\infty\}$ and consider three scenarios: (i) the binned sequence is generated i.i.d., (ii) the sequence is randomly chosen from an $\epsilon$-typical set, and (iii) the sequence originates from an $\epsilon$-typical set and is passed through a non-memoryless virtual channel. Our proofs cover both achievability and converse results. To address the unbounded nature of $T_\infty$, we extend the OSRB framework using R\'enyi's divergence with order infinity, denoted $D_\infty$. As part of our exploration, we analyze a specific form of R\'enyi's conditional entropy and its properties. Additionally, we demonstrate the application of this framework in deriving achievability results for the wiretap channel, where Tsallis divergence serves as a security measure. The secure rate we obtain through the OSRB analysis matches the secure capacity for $\alpha \in (0, 2]\cup\{{\infty}\}$ and serves as a potential candidate for the secure capacity when $\alpha \in (2, \infty)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.12606v4</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 25 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Masoud Kavian, Mohammad Mahdi Mojahedian, Mohammad Hossein Yassaee, Mahtab Mirmohseni, Mohammad Reza Aref</dc:creator>
    </item>
    <item>
      <title>Geodesics and dynamical information projections on the manifold of H\"older equilibrium probabilities</title>
      <link>https://arxiv.org/abs/2203.09677</link>
      <description>arXiv:2203.09677v3 Announce Type: replace-cross 
Abstract: We consider here the discrete time dynamics described by a transformation $T:M \to M$, where $T$ is either the action of shift $T=\sigma$ on the symbolic space $M=\{1,2,...,d\}^\mathbb{N}$, or, $T$ describes the action of a $d$ to $1$ expanding transformation $T:S^1 \to S^1$ of class $C^{1+\alpha}$ (\,for example $x \to T(x) =d\, x $ (mod $1) $\,), where $M=S^1$ is the unit circle. It is known that the infinite-dimensional manifold $\mathcal{N}$ of equilibrium probabilities for H\"older potentials $A:M \to \mathbb{R}$ is an analytical manifold and carries a natural Riemannian metric associated with the asymptotic variance. We show here that under the assumption of the existence of a Fourier-like Hilbert basis for the kernel of the Ruelle operator there exists geodesics paths. When $T=\sigma$ and $M=\{0,1\}^\mathbb{N}$ such basis exists.
  In a different direction, we also consider the KL-divergence $D_{KL}(\mu_1,\mu_2)$ for a pair of equilibrium probabilities. If $D_{KL}(\mu_1,\mu_2)=0$, then $\mu_1=\mu_2$. Although $D_{KL}$ is not a metric in $\mathcal{N}$, it describes the proximity between $\mu_1$ and $\mu_2$. A natural problem is: for a fixed probability $\mu_1\in \mathcal{N}$ consider the probability $\mu_2$ in a convex set of probabilities in $\mathcal{N}$ which minimizes $D_{KL}(\mu_1,\mu_2)$. This minimization problem is a dynamical version of the main issues considered in information projections. We consider this problem in $\mathcal{N}$, a case where all probabilities are dynamically invariant, getting explicit equations for the solution sought. Triangle and Pythagorean inequalities will be investigated.</description>
      <guid isPermaLink="false">oai:arXiv.org:2203.09677v3</guid>
      <category>math.DS</category>
      <category>cs.IT</category>
      <category>math-ph</category>
      <category>math.DG</category>
      <category>math.IT</category>
      <category>math.MP</category>
      <category>math.PR</category>
      <pubDate>Mon, 25 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Artur O. Lopes, Rafael O. Ruggiero</dc:creator>
    </item>
    <item>
      <title>Spectrum Breathing: Protecting Over-the-Air Federated Learning Against Interference</title>
      <link>https://arxiv.org/abs/2305.05933</link>
      <description>arXiv:2305.05933v2 Announce Type: replace-cross 
Abstract: Federated Learning (FL) is a widely embraced paradigm for distilling artificial intelligence from distributed mobile data. However, the deployment of FL in mobile networks can be compromised by exposure to interference from neighboring cells or jammers. Existing interference mitigation techniques require multi-cell cooperation or at least interference channel state information, which is expensive in practice. On the other hand, power control that treats interference as noise may not be effective due to limited power budgets, and also that this mechanism can trigger countermeasures by interference sources. As a practical approach for protecting FL against interference, we propose Spectrum Breathing, which cascades stochastic-gradient pruning and spread spectrum to suppress interference without bandwidth expansion. The cost is higher learning latency by exploiting the graceful degradation of learning speed due to pruning. We synchronize the two operations such that their levels are controlled by the same parameter, Breathing Depth. To optimally control the parameter, we develop a martingale-based approach to convergence analysis of Over-the-Air FL with spectrum breathing, termed AirBreathing FL. We show a performance tradeoff between gradient-pruning and interference-induced error as regulated by the breathing depth. Given receive SIR and model size, the optimization of the tradeoff yields two schemes for controlling the breathing depth that can be either fixed or adaptive to channels and the learning process. As shown by experiments, in scenarios where traditional Over-the-Air FL fails to converge in the presence of strong interference, AirBreahing FL with either fixed or adaptive breathing depth can ensure convergence where the adaptive scheme achieves close-to-ideal performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.05933v2</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 25 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TWC.2024.3368197</arxiv:DOI>
      <dc:creator>Zhanwei Wang, Kaibin Huang, Yonina C. Eldar</dc:creator>
    </item>
  </channel>
</rss>
