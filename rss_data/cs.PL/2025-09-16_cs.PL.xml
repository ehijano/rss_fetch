<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.PL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.PL</link>
    <description>cs.PL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.PL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 17 Sep 2025 01:35:49 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Mechanizing Synthetic Tait Computability in Istari</title>
      <link>https://arxiv.org/abs/2509.11418</link>
      <description>arXiv:2509.11418v1 Announce Type: new 
Abstract: Categorical gluing is a powerful technique for proving meta-theorems of type theories such as canonicity and normalization. Synthetic Tait Computability (STC) provides an abstract treatment of the complex gluing models by internalizing the gluing category into a modal dependent type theory with a phase distinction. This work presents a mechanization of STC in the Istari proof assistant. Istari is a Martin-L\"{o}f-style extensional type theory with equality reflection. Equality reflection eliminates the nuisance of transport reasoning typically found in intensional proof assistants. This work develops a reusable library for synthetic phase distinction, including modalities, extension types, and strict glue types, and applies it to two case studies: (1) a canonicity model for dependent type theory with dependent products and booleans with large elimination, and (2) a Kripke canonicity model for the cost-aware logical framework. Our results demonstrate that the core STC constructions can be formalized essentially verbatim in Istari, preserving the elegance of the on-paper arguments while ensuring machine-checked correctness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11418v1</guid>
      <category>cs.PL</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Runming Li, Yue Yao, Robert Harper</dc:creator>
    </item>
    <item>
      <title>Expressive Power of One-Shot Control Operators and Coroutines</title>
      <link>https://arxiv.org/abs/2509.11901</link>
      <description>arXiv:2509.11901v1 Announce Type: new 
Abstract: Control operators, such as exceptions and effect handlers, provide a means of representing computational effects in programs abstractly and modularly. While most theoretical studies have focused on multi-shot control operators, one-shot control operators -- which restrict the use of captured continuations to at most once -- are gaining attention for their balance between expressiveness and efficiency. This study aims to fill the gap. We present a mathematically rigorous comparison of the expressive power among one-shot control operators, including effect handlers, delimited continuations, and even asymmetric coroutines. Following previous studies on multi-shot control operators, we adopt Felleisen's macro-expressiveness as our measure of expressiveness. We verify the folklore that one-shot effect handlers and one-shot delimited-control operators can be macro-expressed by asymmetric coroutines, but not vice versa. We explain why a previous informal argument fails, and how to revise it to make a valid macro-translation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11901v1</guid>
      <category>cs.PL</category>
      <category>cs.LO</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kentaro Kobayashi, Yukiyoshi Kameyama</dc:creator>
    </item>
    <item>
      <title>A Tree Clock Data Structure for Causal Orderings in Concurrent Executions</title>
      <link>https://arxiv.org/abs/2201.06325</link>
      <description>arXiv:2201.06325v1 Announce Type: cross 
Abstract: Dynamic techniques are a scalable and effective way to analyze concurrent programs. Instead of analyzing all behaviors of a program, these techniques detect errors by focusing on a single program execution. Often a crucial step in these techniques is to define a causal ordering between events in the execution, which is then computed using vector clocks, a simple data structure that stores logical times of threads. The two basic operations of vector clocks, namely join and copy, require $\Theta(k)$ time, where $k$ is the number of threads. Thus they are a computational bottleneck when $k$ is large.
  In this work, we introduce tree clocks, a new data structure that replaces vector clocks for computing causal orderings in program executions. Joining and copying tree clocks takes time that is roughly proportional to the number of entries being modified, and hence the two operations do not suffer the a-priori $\Theta(k)$ cost per application. We show that when used to compute the classic happens-before (HB) partial order, tree clocks are optimal, in the sense that no other data structure can lead to smaller asymptotic running time. Moreover, we demonstrate that tree clocks can be used to compute other partial orders, such as schedulable-happens-before (SHB) and the standard Mazurkiewicz (MAZ) partial order, and thus are a versatile data structure. Our experiments show that just by replacing vector clocks with tree clocks, the computation becomes from $2.02 \times$ faster (MAZ) to $2.66 \times$ (SHB) and $2.97 \times$ (HB) on average per benchmark. These results illustrate that tree clocks have the potential to become a standard data structure with wide applications in concurrent analyses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2201.06325v1</guid>
      <category>cs.LO</category>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <category>cs.PL</category>
      <category>cs.SE</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Umang Mathur, Andreas Pavlogiannis, H\"unkar Can Tun\c{c}, Mahesh Viswanathan</dc:creator>
    </item>
    <item>
      <title>Verifying Computational Graphs in Production-Grade Distributed Machine Learning Frameworks</title>
      <link>https://arxiv.org/abs/2509.10694</link>
      <description>arXiv:2509.10694v1 Announce Type: cross 
Abstract: Modern machine learning frameworks support very large models by incorporating parallelism and optimization techniques. Yet, these very techniques add new layers of complexity, introducing silent errors that severely degrade model performance. Existing solutions are either ad hoc or too costly for production.
  We present Scalify, a lightweight framework that exposes silent errors by verifying semantic equivalence of computational graphs using equality saturation and Datalog-style reasoning. To scale, Scalify partitions graphs with parallel rewriting and layer memoization, reuses rewrite templates, and augments equality saturation with relational reasoning and symbolic bijection inference. It further localizes discrepancies to precise code sites, turning verification results into actionable debugging guidance. Scalify verifies models as large as Llama-3.1-405B within minutes on a commodity machine and exposed five unknown bugs in Amazon production machine learning frameworks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10694v1</guid>
      <category>cs.LG</category>
      <category>cs.PL</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kahfi S. Zulkifli, Wenbo Qian, Shaowei Zhu, Yuan Zhou, Zhen Zhang, Chang Lou</dc:creator>
    </item>
    <item>
      <title>Arguzz: Testing zkVMs for Soundness and Completeness Bugs</title>
      <link>https://arxiv.org/abs/2509.10819</link>
      <description>arXiv:2509.10819v1 Announce Type: cross 
Abstract: Zero-knowledge virtual machines (zkVMs) are increasingly deployed in decentralized applications and blockchain rollups since they enable verifiable off-chain computation. These VMs execute general-purpose programs, frequently written in Rust, and produce succinct cryptographic proofs. However, zkVMs are complex, and bugs in their constraint systems or execution logic can cause critical soundness (accepting invalid executions) or completeness (rejecting valid ones) issues.
  We present Arguzz, the first automated tool for testing zkVMs for soundness and completeness bugs. To detect such bugs, Arguzz combines a novel variant of metamorphic testing with fault injection. In particular, it generates semantically equivalent program pairs, merges them into a single Rust program with a known output, and runs it inside a zkVM. By injecting faults into the VM, Arguzz mimics malicious or buggy provers to uncover overly weak constraints.
  We used Arguzz to test six real-world zkVMs (RISC Zero, Nexus, Jolt, SP1, OpenVM, and Pico) and found eleven bugs in three of them. One RISC Zero bug resulted in a $50,000 bounty, despite prior audits, demonstrating the critical need for systematic testing of zkVMs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10819v1</guid>
      <category>cs.SE</category>
      <category>cs.CR</category>
      <category>cs.PL</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christoph Hochrainer, Valentin W\"ustholz, Maria Christakis</dc:creator>
    </item>
    <item>
      <title>ViScratch: Using Large Language Models and Gameplay Videos for Automated Feedback in Scratch</title>
      <link>https://arxiv.org/abs/2509.11065</link>
      <description>arXiv:2509.11065v1 Announce Type: cross 
Abstract: Block-based programming environments such as Scratch are increasingly popular in programming education, in particular for young learners. While the use of blocks helps prevent syntax errors, semantic bugs remain common and difficult to debug. Existing tools for Scratch debugging rely heavily on predefined rules or user manual inputs, and crucially, they ignore the platform's inherently visual nature.
  We introduce ViScratch, the first multimodal feedback generation system for Scratch that leverages both the project's block code and its generated gameplay video to diagnose and repair bugs. ViScratch uses a two-stage pipeline: a vision-language model first aligns visual symptoms with code structure to identify a single critical issue, then proposes minimal, abstract syntax tree level repairs that are verified via execution in the Scratch virtual machine.
  We evaluate ViScratch on a set of real-world Scratch projects against state-of-the-art LLM-based tools and human testers. Results show that gameplay video is a crucial debugging signal: ViScratch substantially outperforms prior tools in both bug identification and repair quality, even without access to project descriptions or goals. This work demonstrates that video can serve as a first-class specification in visual programming environments, opening new directions for LLM-based debugging beyond symbolic code alone.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11065v1</guid>
      <category>cs.SE</category>
      <category>cs.PL</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yuan Si, Daming Li, Hanyuan Shi, Jialu Zhang</dc:creator>
    </item>
    <item>
      <title>ILA: Correctness via Type Checking for Fully Homomorphic Encryption</title>
      <link>https://arxiv.org/abs/2509.11559</link>
      <description>arXiv:2509.11559v1 Announce Type: cross 
Abstract: RLWE-based Fully Homomorphic Encryption (FHE) schemes add some small \emph{noise} to the message during encryption. The noise accumulates with each homomorphic operation. When the noise exceeds a critical value, the FHE circuit produces an incorrect output. This makes developing FHE applications quite subtle, as one must closely track the noise to ensure correctness. However, existing libraries and compilers offer limited support to statically track the noise. Additionally, FHE circuits are also plagued by wraparound errors that are common in finite modulus arithmetic. These two limitations of existing compilers and libraries make FHE applications too difficult to develop with confidence.
  In this work, we present a \emph{correctness-oriented} IR, Intermediate Language for Arithmetic circuits, for type-checking circuits intended for homomorphic evaluation. Our IR is backed by a type system that tracks low-level quantitative bounds (e.g., ciphertext noise) without using the secret key. Using our type system, we identify and prove a strong \emph{functional correctness} criterion for \ila circuits. Additionally, we have designed \ila to be maximally general: our core type system does not directly assume a particular FHE scheme, but instead axiomatizes a \emph{model} of FHE. We instantiate this model with the exact FHE schemes (BGV, BFV and TFHE), and obtain functional correctness for free.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11559v1</guid>
      <category>cs.CR</category>
      <category>cs.PL</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Tarakaram Gollamudi, Anitha Gollamudi, Joshua Gancher</dc:creator>
    </item>
    <item>
      <title>Proceedings 9th edition of Working Formal Methods Symposium</title>
      <link>https://arxiv.org/abs/2509.11877</link>
      <description>arXiv:2509.11877v1 Announce Type: cross 
Abstract: This volume contains the proceedings of the 9th Working Formal Methods Symposium, which was held at the Alexandru Ioan Cuza University, Ia\c{s}i, Romania on September 17-19, 2025. </description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11877v1</guid>
      <category>cs.LO</category>
      <category>cs.PL</category>
      <category>cs.SE</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.427</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 427, 2025</arxiv:journal_reference>
      <dc:creator>Andrei Arusoaie (Alexandru Ioan Cuza University of Ia\c{s}i), Hora\c{t}iu Cheval (University of Bucharest), Radu Iosif (Verimag, CNRS, University of Grenoble Alpes)</dc:creator>
    </item>
    <item>
      <title>Lean4Lean: Verifying a Typechecker for Lean, in Lean</title>
      <link>https://arxiv.org/abs/2403.14064</link>
      <description>arXiv:2403.14064v3 Announce Type: replace 
Abstract: In this paper we present a new "external checker" for the Lean theorem prover, written in Lean itself. This is the first complete typechecker for Lean 4 other than the reference implementation in C++ used by Lean itself, and our new checker is competitive with the original, running between 20% and 50% slower and usable to verify all of Lean's mathlib library, forming an additional step in Lean's aim to self-host the full elaborator and compiler. Moreover, because the checker is written in a language which admits formal verification, it is possible to state and prove properties about the kernel itself, and we report on progress to formalize the Lean type theory abstractly and prove some theorems about it. Finally, we combine these to get a proof of correctness of parts of the kernel. We plan to use this project to help justify any future changes to the kernel and type theory and ensure unsoundness does not sneak in through either the abstract theory or implementation bugs. The verification is already paying off, as one soundness bug has been spotted and fixed as a result of this work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.14064v3</guid>
      <category>cs.PL</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mario Carneiro</dc:creator>
    </item>
    <item>
      <title>Actor Capabilities for Message Ordering (Extended Version)</title>
      <link>https://arxiv.org/abs/2502.07958</link>
      <description>arXiv:2502.07958v2 Announce Type: replace 
Abstract: Actor systems are a flexible model of concurrent and distributed programming, which are efficiently implementable, and avoid many classic concurrency bugs by construction. However actor systems must still deal with the challenge of messages arriving in unexpected orderings.
  We describe an approach to restricting the orders in which actors send messages to each other, by equipping actor references -- the handle used to address another actor -- with a protocol restricting which message types can be sent to another actor and in which order using that particular actor reference. This endows the actor references with the properties of static (flow-sensitive) capabilities, which we call actor capabilities.
  By sending other actors only restricted actor references, they may control which messages are sent in which orders by other actors. Rules for duplicating (splitting) actor references ensure that these restrictions apply even in the presence of delegation. The capabilities themselves restrict message ordering, which may form the foundation for stronger forms of reasoning. We demonstrate this by layering an effect system over the base type system, where the relationships enforced between the actor capabilities and the effects of an actor's behaviour ensure that an actor's behaviour is always prepared to handle any message that may arrive.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07958v2</guid>
      <category>cs.PL</category>
      <category>cs.DC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Colin S. Gordon</dc:creator>
    </item>
    <item>
      <title>Stencil-Lifting: Hierarchical Recursive Lifting System for Extracting Summary of Stencil Kernel in Legacy Codes</title>
      <link>https://arxiv.org/abs/2509.10236</link>
      <description>arXiv:2509.10236v2 Announce Type: replace-cross 
Abstract: We introduce Stencil-Lifting, a novel system for automatically converting stencil kernels written in low-level languages in legacy code into semantically equivalent Domain-Specific Language (DSL) implementations. Targeting the efficiency bottlenecks of existing verified lifting systems, Stencil-Lifting achieves scalable stencil kernel abstraction through two key innovations. First, we propose a hierarchical recursive lifting theory that represents stencil kernels, structured as nested loops, using invariant subgraphs, which are customized data dependency graphs that capture loop-carried computation and structural invariants. Each vertex in the invariant subgraph is associated with a predicate-based summary, encoding its computational semantics. By enforcing self-consistency across these summaries, Stencil-Lifting ensures the derivation of correct loop invariants and postconditions for nested loops, eliminating the need for external verification. Second, we develop a hierarchical recursive lifting algorithm that guarantees termination through a convergent recursive process, avoiding the inefficiencies of search-based synthesis. The algorithm efficiently derives the valid summaries of stencil kernels, and its completeness is formally proven. We evaluate Stencil-Lifting on diverse stencil benchmarks from two different suites and on four real-world applications. Experimental results demonstrate that Stencil-Lifting achieves 31.62$\times$ and 5.8$\times$ speedups compared to the state-of-the-art verified lifting systems STNG and Dexter, respectively, while maintaining full semantic equivalence. Our work significantly enhances the translation efficiency of low-level stencil kernels to DSL implementations, effectively bridging the gap between legacy optimization techniques and modern DSL-based paradigms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10236v2</guid>
      <category>cs.SE</category>
      <category>cs.PF</category>
      <category>cs.PL</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3763159</arxiv:DOI>
      <dc:creator>Mingyi Li, Junmin Xiao, Siyan Chen, Hui Ma, Xi Chen, Peihua Bao, Liang Yuan, Guangming Tan</dc:creator>
    </item>
  </channel>
</rss>
