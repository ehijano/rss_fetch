<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 26 May 2025 04:00:41 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Distribution through Repeated Market with Buying Rights</title>
      <link>https://arxiv.org/abs/2505.17271</link>
      <description>arXiv:2505.17271v1 Announce Type: new 
Abstract: Resource distribution is a fundamental problem in economic and policy design, particularly when demand and supply are not naturally aligned. Without regulation, wealthier individuals may monopolize this resource, leaving the needs of others unsatisfied. While centralized distribution can ensure fairer division, it can struggle to manage logistics efficiently, and adapt to changing conditions, often leading to shortages, surpluses, and bureaucratic inefficiencies. Building on previous research on market-based redistribution, we examine a repeated hybrid market that incorporates buying rights. These rights, distributed iteratively by a central authority (for instance, as digital tokens), are intended to enhance fairness in the system - a unit of right is required to acquire a unit of the resource, but the rights themselves can also be traded alongside the resource in the market. We analyze how this regulatory mechanism influences the distribution of the scarce resource in the hybrid market over time. Unlike past works that relied on empirical methods, we explore the exact analytical properties of a system in which traders optimize over multiple rounds. We identify its market equilibrium, which is a natural generalization of the free market equilibrium, and show that it is coalition-proof. To assess the fairness in the system, we use the concept of frustration, which measures the gap between the resources a buyer is entitled to through their buying rights and what they actually obtain through trading. Our main theoretical result shows that using buying rights reduces the frustration by at least half compared to the free market. Empirical evaluations further support our findings, suggesting the system performs well even beyond the theoretically studied assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.17271v1</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David Sychrovsk\'y, Jakub \v{C}ern\'y, Martin Loebl</dc:creator>
    </item>
    <item>
      <title>Transaction Fee Mechanism Design for Leaderless Blockchain Protocols</title>
      <link>https://arxiv.org/abs/2505.17885</link>
      <description>arXiv:2505.17885v1 Announce Type: new 
Abstract: We initiate the study of transaction fee mechanism design for blockchain protocols in which multiple block producers contribute to the production of each block. Our contributions include:
  - We propose an extensive-form (multi-stage) game model to reason about the game theory of multi-proposer transaction fee mechanisms.
  - We define the strongly BPIC property to capture the idea that all block producers should be motivated to behave as intended: for every user bid profile, following the intended allocation rule is a Nash equilibrium for block producers that Pareto dominates all other Nash equilibria.
  - We propose the first-price auction with equal sharing (FPA-EQ) mechanism as an attractive solution to the multi-proposer transaction fee mechanism design problem. We prove that the mechanism is strongly BPIC and guarantees at least a 63.2% fraction of the maximum-possible expected welfare at equilibrium.
  - We prove that the compromises made by the FPA-EQ mechanism are qualitatively necessary: no strongly BPIC mechanism with non-trivial welfare guarantees can be DSIC, and no strongly BPIC mechanism can guarantee optimal welfare at equilibrium.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.17885v1</guid>
      <category>cs.GT</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pranav Garimidi, Lioba Heimbach, Tim Roughgarden</dc:creator>
    </item>
    <item>
      <title>Posted Pricing and Competition in Large Markets</title>
      <link>https://arxiv.org/abs/2505.18061</link>
      <description>arXiv:2505.18061v1 Announce Type: new 
Abstract: Posted price mechanisms are prevalent in allocating goods within online marketplaces due to their simplicity and practical efficiency. We explore a fundamental scenario where buyers' valuations are independent and identically distributed, focusing specifically on the allocation of a single unit. Inspired by the rapid growth and scalability of modern online marketplaces, we investigate optimal performance guarantees under the assumption of a significantly large market. We show a large market benefit when using fixed prices, improving the known guarantee of $1-1/e\approx 0.632$ to $0.712$. We then study the case of selling $k$ identical units, and we prove that the optimal fixed price guarantee approaches $1-1/\sqrt{2k \pi}$, which implies that the large market advantage vanishes as $k$ grows. We use real-world auction data to test our fixed price policies in the large market regime. Next, under the large market assumption, we show that the competition complexity for the optimal posted price mechanism is constant, and we identify precise scaling factors for the number of bidders that enable it to match benchmark performance. Remarkably, our findings break previously established worst-case impossibility results, underscoring the practical robustness and efficiency of posted pricing in large-scale marketplaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18061v1</guid>
      <category>cs.GT</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jos\'e Correa, Vasilis Livanos, Dana Pizarro, Victor Verdugo</dc:creator>
    </item>
    <item>
      <title>Facility Location with Public Locations and Private Doubly-Peaked Costs</title>
      <link>https://arxiv.org/abs/2505.18114</link>
      <description>arXiv:2505.18114v1 Announce Type: new 
Abstract: In the facility location problem, the task is to place one or more facilities so as to minimize the sum of the agent costs for accessing their nearest facility. Heretofore, in the strategic version, agent locations have been assumed to be private, while their cost measures have been public and identical.
  For the most part, the cost measure has been the distance to the nearest facility.
  However, in multiple natural settings, such as placing a firehouse or a school, this modeling does not appear to be a good fit. For it seems natural that the agent locations would be known, but their costs might be private information. In addition, for these types of settings, agents may well want the nearest facility to be at the right distance: near, but not too near. This is captured by the doubly-peaked cost introduced by Filos-Ratsikas et al. (AAMAS 2017).
  In this paper, we re-examine the facility location problem from this perspective: known agent locations and private preferred distances to the nearest facility.
  We then give lower and upper bounds on achievable approximations, focusing on the problem in 1D, and in 2D with an $L_1$ distance measure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18114v1</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Richard Cole, Pranav Jangir</dc:creator>
    </item>
    <item>
      <title>Various Properties of Various Ultrafilters, Various Graph Width Parameters, and Various Connectivity Systems (with Survey)</title>
      <link>https://arxiv.org/abs/2408.02299</link>
      <description>arXiv:2408.02299v8 Announce Type: cross 
Abstract: This paper investigates ultrafilters in the context of connectivity systems, defined as pairs $(X, f)$ where $X$ is a finite set and $f$ is a symmetric submodular function. Ultrafilters, essential in topology and set theory, are extended to these systems, with a focus on their relationship to graph width parameters, which help analyze graph complexity. We demonstrate theorems for ultrafilters on connectivity systems and explore related concepts such as prefilters, ultra-prefilters, and subbases. New parameters for width, length, and depth are introduced, providing further insight into graph width. The study also includes a comparison of various graph width parameters and their related concepts, offering a foundation for future research in graph theory and computational complexity. Additionally, we explore connections to other mathematical disciplines, including set theory, lattice theory, and matroid theory, expanding the scope of ultrafilters and graph width. (It also includes information similar to that found in surveys, aiming to promote future research on graph width parameters.)</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02299v8</guid>
      <category>math.CO</category>
      <category>cs.DM</category>
      <category>cs.GT</category>
      <category>cs.LO</category>
      <category>math.LO</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Takaaki Fujita</dc:creator>
    </item>
    <item>
      <title>EFX Exists for Three Types of Agents</title>
      <link>https://arxiv.org/abs/2410.13580</link>
      <description>arXiv:2410.13580v3 Announce Type: replace 
Abstract: We study the problem of finding an envy-free allocation of indivisible goods among agents with additive valuations. We focus on the fairness notion of envy-freeness up to any good (EFX). A central open question in fair division is whether EFX allocations always exist for any number of agents. While EFX has been established for three agents [CGM24] and for any number of agents with at most two distinct valuations [Mah23], its existence in more general settings remains open.
  In this paper, we make significant progress by proving that EFX allocations exist for any number of agents when there are at most three distinct additive valuations. This result simultaneously generalizes both the three-agent case and the two-type case, settling an open question in the field (see [Mah23]).</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13580v3</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <category>cs.MA</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Vishwa Prakash HV, Pratik Ghosal, Prajakta Nimbhorkar, Nithin Varma</dc:creator>
    </item>
    <item>
      <title>Online Bidding Algorithms with Strict Return on Spend (ROS) Constraint</title>
      <link>https://arxiv.org/abs/2502.05599</link>
      <description>arXiv:2502.05599v2 Announce Type: replace 
Abstract: Auto-bidding problem under a strict return-on-spend constraint (ROSC) is considered, where an algorithm has to make decisions about how much to bid for an ad slot depending on the revealed value, and the hidden allocation and payment function that describes the probability of winning the ad-slot depending on its bid. The objective of an algorithm is to maximize the expected utility (product of ad value and probability of winning the ad slot) summed across all time slots subject to the total expected payment being less than the total expected utility, called the ROSC. A (surprising) impossibility result is derived that shows that no online algorithm can achieve a sub-linear regret even when the value, allocation and payment function are drawn i.i.d. from an unknown distribution. The problem is non-trivial even when the revealed value remains constant across time slots, and an algorithm with regret guarantee that is optimal up to logarithmic factor is derived.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05599v2</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Rahul Vaze, Abhishek Sinha</dc:creator>
    </item>
    <item>
      <title>The Hamiltonian of Poly-matrix Zero-sum Games</title>
      <link>https://arxiv.org/abs/2505.12609</link>
      <description>arXiv:2505.12609v2 Announce Type: replace 
Abstract: Understanding a dynamical system fundamentally relies on establishing an appropriate Hamiltonian function and elucidating its symmetries. By formulating agents' strategies and cumulative payoffs as canonically conjugate variables, we identify the Hamiltonian function that generates the dynamics of poly-matrix zero-sum games. We reveal the symmetries of our Hamiltonian and derive the associated conserved quantities, showing how the conservation of probability and the invariance of the Fenchel coupling are intrinsically encoded within the system. Furthermore, we propose the dissipation FTRL (DFTRL) dynamics by introducing a perturbation that dissipates the Fenchel coupling, proving convergence to the Nash equilibrium and linking DFTRL to last-iterate convergent algorithms. Our results highlight the potential of Hamiltonian dynamics in uncovering the structural properties of learning dynamics in games, and pave the way for broader applications of Hamiltonian dynamics in game theory and machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12609v2</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <category>nlin.CD</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Toshihiro Ota, Yuma Fujimoto</dc:creator>
    </item>
    <item>
      <title>Algorithmic Collusion by Large Language Models</title>
      <link>https://arxiv.org/abs/2404.00806</link>
      <description>arXiv:2404.00806v3 Announce Type: replace-cross 
Abstract: The rise of algorithmic pricing raises concerns of algorithmic collusion. We conduct experiments with algorithmic pricing agents based on Large Language Models (LLMs). We find that (1) LLM-based agents are adept at pricing tasks, (2) LLM-based pricing agents quickly and autonomously reach supracompetitive prices and profits in oligopoly settings, and (3) variation in seemingly innocuous phrases in LLM instructions ("prompts") may substantially influence the degree of supracompetitive pricing. Off-path analysis using novel techniques uncovers price-war concerns as contributing to these phenomena. Our results extend to auction settings. Our findings uncover unique challenges to any future regulation of LLM-based pricing agents, and generative AI pricing agents more broadly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00806v3</guid>
      <category>econ.GN</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>q-fin.EC</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sara Fish, Yannai A. Gonczarowski, Ran I. Shorrer</dc:creator>
    </item>
    <item>
      <title>Optimal Capacity Modification for Stable Matchings with Ties</title>
      <link>https://arxiv.org/abs/2411.10284</link>
      <description>arXiv:2411.10284v3 Announce Type: replace-cross 
Abstract: We consider the Hospitals/Residents (HR) problem in the presence of ties in preference lists. Among the three notions of stability, viz. weak, strong, and super stability, we focus on the notion of strong stability. Strong stability has many desirable properties, both theoretically and practically; however, its existence is not guaranteed. In this paper, our objective is to optimally increase the quotas of hospitals to ensure that a strongly stable matching exists in the modified instance. First, we show that if ties are allowed in residents' preference lists, it may not be possible to augment the hospital quotas to obtain an instance that admits a strongly stable matching. When residents' preference lists are strict, we explore two natural optimization criteria: (i) minimizing the total capacity increase across all hospitals (MINSUM) and (ii) minimizing the maximum capacity increase for any hospital (MINMAX). We show that the MINSUM problem admits a polynomial-time algorithm, whereas the MINMAX problem is NP-hard. We prove an analogue of the Rural Hospitals theorem for the MINSUM problem. When each hospital incurs a cost for a unit increase in its quota, the MINSUM problem becomes NP-hard, even for 0/1 costs. In fact, we show that the problem cannot be approximated to any multiplicative factor. We also present a polynomial-time algorithm for optimal MINSUM augmentation when a specified subset of edges is required to be included in the matching. We show that the MINMAX problem is NP-hard in general. When hospital preference lists have ties of length at most $\ell+1$, we give a polynomial-time algorithm that increases each hospital's quota by at most $\ell$. Amongst all instances obtained by at most $\ell$ augmentations per hospital, our algorithm produces a strongly stable matching that is best for residents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10284v3</guid>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Keshav Ranjan, Meghana Nasre, Prajakta Nimbhorkar</dc:creator>
    </item>
    <item>
      <title>On the Impact of the Utility in Semivalue-based Data Valuation</title>
      <link>https://arxiv.org/abs/2502.06574</link>
      <description>arXiv:2502.06574v2 Announce Type: replace-cross 
Abstract: Semivalue-based data valuation uses cooperative-game theory intuitions to assign each data point a value reflecting its contribution to a downstream task. Still, those values depend on the practitioner's choice of utility, raising the question: How robust is semivalue-based data valuation to changes in the utility? This issue is critical when the utility is set as a trade-off between several criteria and when practitioners must select among multiple equally valid utilities. We address it by introducing the notion of a dataset's spatial signature: given a semivalue, we embed each data point into a lower-dimensional space where any utility becomes a linear functional, making the data valuation framework amenable to a simpler geometric picture. Building on this, we propose a practical methodology centered on an explicit robustness metric that informs practitioners whether and by how much their data valuation results will shift as the utility changes. We validate this approach across diverse datasets and semivalues, demonstrating strong agreement with rank-correlation analyses and offering analytical insight into how choosing a semivalue can amplify or diminish robustness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06574v2</guid>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>M\'elissa Tamine, Benjamin Heymann, Patrick Loiseau, Maxime Vono</dc:creator>
    </item>
  </channel>
</rss>
