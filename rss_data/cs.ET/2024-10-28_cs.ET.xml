<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 29 Oct 2024 04:00:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>XbarSim: A Decomposition-Based Memristive Crossbar Simulator</title>
      <link>https://arxiv.org/abs/2410.19993</link>
      <description>arXiv:2410.19993v1 Announce Type: new 
Abstract: Given the growing focus on memristive crossbar-based in-memory computing (IMC) architectures as a potential alternative to current energy-hungry machine learning hardware, the availability of a fast and accurate circuit-level simulation framework could greatly enhance research and development efforts in this field. This paper introduces XbarSim, a domain-specific circuit-level simulator designed to analyze the nodal equations of memristive crossbars. The first version of XbarSim, proposed herein, leverages the lower-upper (LU) decomposition approach to solve the nodal equations for the matrices associated with crossbars. The XbarSim is capable of simulating interconnect parasitics within crossbars and supports batch processing of the inputs. Through comprehensive experiments, we demonstrate that the XbarSim can achieve orders of magnitude speedup compared to HSPICE across various sizes of memristive crossbars. The XbarSim's full suite of features is accessible to researchers as an open-source tool.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19993v1</guid>
      <category>cs.ET</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anzhelika Kolinko, Md Hasibul Amin, Ramtin Zand, Jason Bakos</dc:creator>
    </item>
    <item>
      <title>The maximum storage capacity of open-loop written RRAM is around 4 bits</title>
      <link>https://arxiv.org/abs/2410.20332</link>
      <description>arXiv:2410.20332v1 Announce Type: new 
Abstract: There have been a plethora of research on multi-level memory devices, where the resistive random-access memory (RRAM) is a prominent example. Although it is easy to write an RRAM device into multiple (even quasi-continuous) states, it suffers from the inherent variations that should limit the storage capacity, especially in the open-loop writing scenario. There have been many experimental results in this regard, however, it lacks a comprehensive analysis of the valid multi-bit storage capability, especially in theoretical terms. The absence of such an insight usually results in misleading conclusions that either exaggerate or underestimate the storage capacity of RRAM devices. Here, by the concept of information theory, we present a model for evaluating the storage capacity of open-loop written RRAM. Based on the experimental results in the literature and the test results of our own devices, we have carefully examined the effects of number of pre-defined levels, conductance variation, and conductance range, on the storage capacity. The analysis leads to a conclusion that the maximum capacity of RRAM devices is around 4 bits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20332v1</guid>
      <category>cs.ET</category>
      <category>cs.AR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yongxiang Li, Shiqing Wang, Zhong Sun</dc:creator>
    </item>
    <item>
      <title>Smart Space Environments: Key Challenges and Innovative Solutions</title>
      <link>https://arxiv.org/abs/2410.20484</link>
      <description>arXiv:2410.20484v1 Announce Type: new 
Abstract: The integration of LoRaWAN (Long Range Wide Area Network) technology with both active and passive sensors presents a transformative opportunity for the development of smart home systems. This paper explores how active sensors, such as motion detectors and ultrasonic sensors, and passive sensors, including temperature and humidity sensors, work together to enhance connectivity and efficiency within diverse environments while addressing the challenges of modern living. By leveraging LoRaWAN long-range capabilities and low power consumption, the proposed framework enables effective data transmission from remote sensors, facilitating applications such as smart agriculture, environmental monitoring, and comprehensive home automation. Active sensors emit energy to detect changes in their surroundings, providing real-time data crucial for security and automation, while passive sensors capture ambient energy to monitor environmental conditions, ensuring resource efficiency and user comfort. The synergy between LoRaWAN and these various sensor types promotes innovation, contributing to a more responsive and sustainable living experience. Furthermore, this research highlights the adaptability of the proposed system, allowing for seamless integration of new devices and advanced functionalities. As the landscape of smart home technology continues to evolve, ongoing research in this area will yield advanced solutions tailored to user needs, ultimately paving the way for smarter, safer, and more efficient living environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20484v1</guid>
      <category>cs.ET</category>
      <category>cs.DC</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Ramakant Kumar</dc:creator>
    </item>
    <item>
      <title>Scaling Effects of Transistor Leakage Current and IR Drop on 1T1R Memory Arrays</title>
      <link>https://arxiv.org/abs/2410.20560</link>
      <description>arXiv:2410.20560v1 Announce Type: new 
Abstract: 1T1R (1-transistor-1-resistor) memory crossbar arrays represent a promising solution for compute-in-memory matrix-vector multiplication accelerators and embedded or storage-class memory. However, the size and scaling of these arrays are hindered by critical challenges, such as the IR drop on metal lines and the accumulation of leakage current from the transistors. Although the IR drop issue has been extensively investigated, the impact of transistor leakage current has received limited attention. In this work, we investigate both issues and highlight how transistor leakage in 1T1R arrays has effects similar to IR drop, which degrades the memory cell sensing margin, especially as the technology node scales down. This degradation could pose reliability concerns, particularly where the on/off ratio or sensing margin of memristors is critical. We characterized the joint effects of transistor read resistance, transistor leakage current, and IR drop as the array size scales up and the fabrication node scales down. Based on a model developed using specifications of a 22nm FDSOI technology, we found that an optimal resistance range of memristors exists for good array scaling capability, where the transistor read resistance and the IR drop issue establish a lower resistance boundary, while the transistor leakage issue sets an upper resistance boundary. This work provides valuable scaling guidelines for engineering the properties of memristor devices in 1T1R memory arrays.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20560v1</guid>
      <category>cs.ET</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Junren Chen, Giacomo Indiveri</dc:creator>
    </item>
    <item>
      <title>Complexity and nonlinearity of colloid electrical transducers</title>
      <link>https://arxiv.org/abs/2410.19757</link>
      <description>arXiv:2410.19757v1 Announce Type: cross 
Abstract: This work explores the complexity and nonlinearity of seven different colloidal suspensions-Au, ferrofluid, TiO2}, ZnO, g-C3N4, MXene, and PEDOT:PSS-when electrically stimulated with fractal, chaotic, and random binary signals. The recorded electrical responses were analyzed using entropy, file compression, fractal dimension, and Fisher information measures to quantify complexity. The nonlinearity introduced by each colloid was evaluated by the deviation of the output from the best-fit hyperplane of the input-output mapping. The results showed that TiO2 was the most complex colloid across all inputs, exhibiting high entropy, poor compressibility, and an unpredictable response pattern. The colloids also exhibited significant nonlinearity, making them promising candidates for reservoir computation, where the mapping of inputs into high-dimensional nonlinear states is advantageous. This study provides insight into the dynamics of colloids and their potential for unconventional computational applications that exploit their inherent complexity and nonlinearity, and it provides a rapid method for assessing the suitability of a particular material for use as a computational substrate before others.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19757v1</guid>
      <category>cond-mat.soft</category>
      <category>cs.ET</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Raphael Fortulan, Noushin Raeisi Kheirabadi, Alessandro Chiolerio, Andrew Adamatzky</dc:creator>
    </item>
    <item>
      <title>A Scored Non-Deterministic Finite Automata Processor for Sequence Alignment</title>
      <link>https://arxiv.org/abs/2410.19758</link>
      <description>arXiv:2410.19758v1 Announce Type: cross 
Abstract: The rapid growth of symbolic data in areas like internet, biological, and financial data has increased the demand for efficient pattern matching and regular expression processing. Non-deterministic Finite Automata (NFA) are used for these tasks, but general-purpose platforms often face memory bottlenecks due to the concurrent nature of NFAs. To address this, Domain-Specific Architectures (DSAs) like FPGA and ASIC-based automata processors have been developed for improved efficiency. However, many modern applications require identifying the optimal match path, such as in DNA sequence alignment, which demands scoring methods to evaluate the best match. This work enhances the FPGA-based NAPOLY automata processor by integrating scoring capabilities, creating an extended version called NAPOLY+ that assigns weights to transitions, enabling the identification of the highest scoring path. Implementing this approach introduces challenges, including increased state space complexity and resource demands due to multiple active paths. The NAPOLY+ system addresses these by incorporating arithmetic components to calculate scores along paths and using efficient memory management to maintain scalability. Experimental evaluation on the Zynq Ultrascale+ ZCU104 FPGA demonstrated high device utilization and performance variations based on array size and fan-out. While results are preliminary, ongoing testing will include real datasets to assess the end-to-end performance of NAPOLY+ in practical applications such as BLAST.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19758v1</guid>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ryan Karbowniczak Rasha Karakchi</dc:creator>
    </item>
    <item>
      <title>MPLS Network Actions: Technological Overview and P4-Based Implementation on a High-Speed Switching ASIC</title>
      <link>https://arxiv.org/abs/2410.20400</link>
      <description>arXiv:2410.20400v1 Announce Type: cross 
Abstract: The MPLS protocol, traditionally focused on packet forwarding using labels, has evolved to include advanced mechanisms such as Service Function Chaining (SFC), Alternate-Marking Method (AMM), and in-situ OAM (IOAM). However, many of those mechanisms require extensions to existing specifications in MPLS making them difficult to deploy. To bridge this gap, the IETF MPLS WG proposed the MPLS Network Actions (MNA) framework which provides a unified encoding for signaling network actions and their data within the MPLS stack. Network actions in the MNA framework serve a similar role for MPLS as extension headers (EH) do for IPv6. The network actions can be encoded within the label stack (in-stack) or following the stack (post-stack). In this work, we give a comprehensive overview of the design principles of network actions in the MNA framework and the mechanisms that benefit from this framework. We summarize and explain use cases in the MNA framework. Building on this, we implement the MNA framework in P4 on the Intel Tofino 2 switching ASIC. Our work explores an in-stack data (ISD) implementation of the MNA framework. The implementation can process 51 label stack entries containing 32 network actions at a line rate of 400 Gb/s per port. Additionally, we implement and evaluate an exemplary network action for performance measurement with AMM. Finally, we identify challenges with an MNA in-stack implementation and propose an extension to the signaling procedure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20400v1</guid>
      <category>cs.NI</category>
      <category>cs.ET</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fabian Ihle, Michael Menth</dc:creator>
    </item>
    <item>
      <title>Unlocking Comics: The AI4VA Dataset for Visual Understanding</title>
      <link>https://arxiv.org/abs/2410.20459</link>
      <description>arXiv:2410.20459v1 Announce Type: cross 
Abstract: In the evolving landscape of deep learning, there is a pressing need for more comprehensive datasets capable of training models across multiple modalities. Concurrently, in digital humanities, there is a growing demand to leverage technology for diverse media adaptation and creation, yet limited by sparse datasets due to copyright and stylistic constraints. Addressing this gap, our paper presents a novel dataset comprising Franco-Belgian comics from the 1950s annotated for tasks including depth estimation, semantic segmentation, saliency detection, and character identification. It consists of two distinct and consistent styles and incorporates object concepts and labels taken from natural images. By including such diverse information across styles, this dataset not only holds promise for computational creativity but also offers avenues for the digitization of art and storytelling innovation. This dataset is a crucial component of the AI4VA Workshop Challenges~\url{https://sites.google.com/view/ai4vaeccv2024}, where we specifically explore depth and saliency. Dataset details at \url{https://github.com/IVRL/AI4VA}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20459v1</guid>
      <category>cs.CV</category>
      <category>cs.ET</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Peter Gr\"onquist, Deblina Bhattacharjee, Bahar Aydemir, Baran Ozaydin, Tong Zhang, Mathieu Salzmann, Sabine S\"usstrunk</dc:creator>
    </item>
    <item>
      <title>Hypermultiplexed Integrated-Photonics-based Tensor Optical Processor</title>
      <link>https://arxiv.org/abs/2401.18050</link>
      <description>arXiv:2401.18050v4 Announce Type: replace 
Abstract: The escalating data volume and complexity resulting from the rapid expansion of artificial intelligence (AI), internet of things (IoT) and 5G/6G mobile networks is creating an urgent need for energy-efficient, scalable computing hardware. Here we demonstrate a hypermultiplexed integratedphotonics-based tensor optical processor (HITOP) that can perform trillions of operations per second (TOPS) at the energy efficiency of 40 TOPS/W. Space-time-wavelength three-dimensional (3D) optical parallelism enables O($N^{2}$) operations per clock-cycle using O($N$) modulator devices. The system is built with wafer-fabricated III/V micron-scale lasers and high-speed thin-film Lithium-Niobate electro-optics for encoding at 10s femtojoule/symbol. Lasing threshold incorporates analog inline rectifier (ReLu) nonlinearity for low-latency activation. The system scalability is verified with machine learning models of 405,000 parameters. A combination of high clockrates, energy-efficient processing and programmability unlocks the potential of light for large-scale AI accelerators in applications ranging from training of large AI models to real-time decision making in edge deployment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.18050v4</guid>
      <category>cs.ET</category>
      <category>physics.optics</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Shaoyuan Ou, Kaiwen Xue, Lian Zhou, Chun-ho Lee, Alexander Sludds, Ryan Hamerly, Ke Zhang, Hanke Feng, Reshma Kopparapu, Eric Zhong, Cheng Wang, Dirk Englund, Mengjie Yu, Zaijun Chen</dc:creator>
    </item>
    <item>
      <title>Embedding-Aligned Language Models</title>
      <link>https://arxiv.org/abs/2406.00024</link>
      <description>arXiv:2406.00024v2 Announce Type: replace-cross 
Abstract: We propose a novel approach for training large language models (LLMs) to adhere to objectives defined within a latent embedding space. Our method leverages reinforcement learning (RL), treating a pre-trained LLM as an environment. Our embedding-aligned guided language (EAGLE) agent is trained to iteratively steer the LLM's generation towards optimal regions of the latent embedding space, w.r.t. some predefined criterion. We demonstrate the effectiveness of the EAGLE agent using the MovieLens 25M and Amazon Review datasets to surface content gaps that satisfy latent user demand. We also demonstrate the benefit of using an optimal design of a state-dependent action set to improve EAGLE's efficiency. Our work paves the way for controlled and grounded text generation using LLMs, ensuring consistency with domain-specific knowledge and data representations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00024v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guy Tennenholtz, Yinlam Chow, Chih-Wei Hsu, Lior Shani, Ethan Liang, Craig Boutilier</dc:creator>
    </item>
    <item>
      <title>Detection Made Easy: Potentials of Large Language Models for Solidity Vulnerabilities</title>
      <link>https://arxiv.org/abs/2409.10574</link>
      <description>arXiv:2409.10574v2 Announce Type: replace-cross 
Abstract: The large-scale deployment of Solidity smart contracts on the Ethereum mainnet has increasingly attracted financially-motivated attackers in recent years. A few now-infamous attacks in Ethereum's history includes DAO attack in 2016 (50 million dollars lost), Parity Wallet hack in 2017 (146 million dollars locked), Beautychain's token BEC in 2018 (900 million dollars market value fell to 0), and NFT gaming blockchain breach in 2022 ($600 million in Ether stolen). This paper presents a comprehensive investigation of the use of large language models (LLMs) and their capabilities in detecting OWASP Top Ten vulnerabilities in Solidity. We introduce a novel, class-balanced, structured, and labeled dataset named VulSmart, which we use to benchmark and compare the performance of open-source LLMs such as CodeLlama, Llama2, CodeT5 and Falcon, alongside closed-source models like GPT-3.5 Turbo and GPT-4o Mini. Our proposed SmartVD framework is rigorously tested against these models through extensive automated and manual evaluations, utilizing BLEU and ROUGE metrics to assess the effectiveness of vulnerability detection in smart contracts. We also explore three distinct prompting strategies-zero-shot, few-shot, and chain-of-thought-to evaluate the multi-class classification and generative capabilities of the SmartVD framework. Our findings reveal that SmartVD outperforms its open-source counterparts and even exceeds the performance of closed-source base models like GPT-3.5 and GPT-4 Mini. After fine-tuning, the closed-source models, GPT-3.5 Turbo and GPT-4o Mini, achieved remarkable performance with 99% accuracy in detecting vulnerabilities, 94% in identifying their types, and 98% in determining severity. Notably, SmartVD performs best with the `chain-of-thought' prompting technique, whereas the fine-tuned closed-source models excel with the `zero-shot' prompting approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.10574v2</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Md Tauseef Alam, Raju Halder, Abyayananda Maiti</dc:creator>
    </item>
    <item>
      <title>Synthesis of Binary-Input Multi-Valued Output Optical Cascades for Reversible and Quantum Technologies</title>
      <link>https://arxiv.org/abs/2410.18367</link>
      <description>arXiv:2410.18367v2 Announce Type: replace-cross 
Abstract: This paper extends the decomposition from the group theory based methods of Sasao and Saraivanov to design binary input multivalued output quantum cascades realized with optical NOT, SWAP, and Fredkin Gates. We present this method for 3, 5, and 7 valued outputs, but in general it can be used for odd prime valued outputs. The method can be extended to realize hybrid functions with different valued outputs. A class of local transformations is presented that can simplify the final cascade circuits. Using these simplifying transformations, we present an upper bound on the maximum number of gates in an arbitrary $n$-variable input and $k$-valued output function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18367v2</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <category>math.GR</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ishani Agarwal, Miroslav Saraivanov, Marek Perkowski</dc:creator>
    </item>
    <item>
      <title>x-RAGE: eXtended Reality -- Action &amp; Gesture Events Dataset</title>
      <link>https://arxiv.org/abs/2410.19486</link>
      <description>arXiv:2410.19486v2 Announce Type: replace-cross 
Abstract: With the emergence of the Metaverse and focus on wearable devices in the recent years gesture based human-computer interaction has gained significance. To enable gesture recognition for VR/AR headsets and glasses several datasets focusing on egocentric i.e. first-person view have emerged in recent years. However, standard frame-based vision suffers from limitations in data bandwidth requirements as well as ability to capture fast motions. To overcome these limitation bio-inspired approaches such as event-based cameras present an attractive alternative. In this work, we present the first event-camera based egocentric gesture dataset for enabling neuromorphic, low-power solutions for XR-centric gesture recognition. The dataset has been made available publicly at the following URL: https://gitlab.com/NVM_IITD_Research/xrage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19486v2</guid>
      <category>cs.CV</category>
      <category>cs.ET</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vivek Parmar, Dwijay Bane, Syed Shakib Sarwar, Kleber Stangherlin, Barbara De Salvo, Manan Suri</dc:creator>
    </item>
  </channel>
</rss>
