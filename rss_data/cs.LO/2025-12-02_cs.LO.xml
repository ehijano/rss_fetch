<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.LO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.LO</link>
    <description>cs.LO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.LO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 03 Dec 2025 02:38:40 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Strong Normalization for the Safe Fragment of a Minimal Rewrite System: A Triple-Lexicographic Proof and a Conjecture on the Unprovability of Full Termination for Any Relational Operator-Only TRS</title>
      <link>https://arxiv.org/abs/2512.00081</link>
      <description>arXiv:2512.00081v1 Announce Type: new 
Abstract: We present a minimal operator-only term rewriting system with seven constructors and eight reduction rules. Our main contribution is a mechanically-verified proof of strong normalization for a guarded fragment using a novel triple-lexicographic measure combining a phase bit, multiset ordering (Dershowitz-Manna), and ordinal ranking. From strong normalization, we derive a certified normalizer with proven totality and soundness. Assuming local confluence (verified through critical pair analysis), Newman's Lemma yields confluence and therefore unique normal forms for the safe fragment. We establish impossibility results showing that simpler measures, such as additive counters, polynomial interpretations, and single-bit flags, provably fail for rules with term duplication. The work demonstrates fundamental limitations in termination proving for self-referential systems. We state a conjecture: no relational operator-only TRS can have its full-system termination proved by internally definable methods. Here "relational" is equivalent to "capable of ordered computation" - systems with a recursor enabling iteration over successors, comparison, or sequential counting. Such recursors necessarily redistribute step arguments across recursive calls, defeating all additive termination measures. This structural limitation applies to any TRS expressive enough to encode ordered data. All theorems have been formally verified in a proof assistant. The formal development is available to program committee members and referees upon request for purposes of peer review.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00081v1</guid>
      <category>cs.LO</category>
      <category>math.LO</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Moses Rahnama</dc:creator>
    </item>
    <item>
      <title>Compositional Inference for Bayesian Networks and Causality</title>
      <link>https://arxiv.org/abs/2512.00209</link>
      <description>arXiv:2512.00209v1 Announce Type: new 
Abstract: Inference is a fundamental reasoning technique in probability theory. When applied to a large joint distribution, it involves updating with evidence (conditioning) in one or more components (variables) and computing the outcome in other components. When the joint distribution is represented by a Bayesian network, the network structure may be exploited to proceed in a compositional manner -- with great benefits. However, the main challenge is that updating involves (re)normalisation, making it an operation that interacts badly with other operations.
  String diagrams are becoming popular as a graphical technique for probabilistic (and quantum) reasoning. Conditioning has appeared in string diagrams, in terms of a disintegration, using bent wires and shaded (or dashed) normalisation boxes. It has become clear that such normalisation boxes do satisfy certain compositional rules. This paper takes a decisive step in this development by adding a removal rule to the formalism, for the deletion of shaded boxes. Via this removal rule one can get rid of shaded boxes and terminate an inference argument. This paper illustrates via many (graphical) examples how the resulting compositional inference technique can be used for Bayesian networks, causal reasoning and counterfactuals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00209v1</guid>
      <category>cs.LO</category>
      <category>math.CT</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Bart Jacobs, M\'ark Sz\'eles, Dario Stein</dc:creator>
    </item>
    <item>
      <title>A Hierarchy of Supermartingales for $\omega$-Regular Verification</title>
      <link>https://arxiv.org/abs/2512.00270</link>
      <description>arXiv:2512.00270v1 Announce Type: new 
Abstract: We propose new supermartingale-based certificates for verifying almost sure satisfaction of $\omega$-regular properties: (1) generalised Streett supermartingales (GSSMs) and their lexicographic extension (LexGSSMs), (2) distribution-valued Streett supermartingales (DVSSMs), and (3) progress-measure supermartingales (PMSMs) and their lexicographic extension (LexPMSMs). GSSMs, LexGSSMs, and DVSSMs are derived from least-fixed point characterisations of positive recurrence and null recurrence of Markov chains with respect to given Streett conditions; and PMSMs and LexPMSMs are probabilistic extensions of parity progress measures. We study the hierarchy among these certificates and existing certificates, namely Streett supermartingales, by comparing the classes of problems that can be verified by each type of certificates. Notably, we show that our certificates are strictly more powerful than Streett supermartingales. We also prove completeness of GSSMs for positive recurrence and of DVSSMs for null recurrence: DVSSMs are, in theory, the most powerful certificates in the sense that for any Markov chain that almost surely satisfies a given $\omega$-regular property, there exists a DVSSM certifying it. We provide a sound and relatively complete algorithm for synthesising LexPMSMs, the second most powerful certificates in the hierarchy. We have implemented a prototype tool based on this algorithm, and our experiments show that our tool can successfully synthesise certificates for various examples including those that cannot be certified by existing supermartingales.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00270v1</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Satoshi Kura, Hiroshi Unno</dc:creator>
    </item>
    <item>
      <title>Reasoning about Quality in Hyperproperties</title>
      <link>https://arxiv.org/abs/2512.00500</link>
      <description>arXiv:2512.00500v1 Announce Type: new 
Abstract: Hyperproperties allow one to specify properties of systems that inherently involve not single executions of the system, but several of them at once: observational determinism and non-inference are two examples of such properties used to study the security of systems. Logics like HyperLTL have been studied in the past to model check hyperproperties of systems. However, most of the time, requiring strict security properties is actually ineffective as systems do not meet such requirements. To overcome this issue, we introduce qualitative reasoning in HyperLTL, inspired by a similar work on LTL by Almagor, Boker and Kupferman where a formula has a value in the interval [0, 1], obtained by considering either a propositional quality (how much the specification is satisfied), or a temporal quality (when the specification is satisfied). We show decidability of the approximated model checking problem, as well as the model checking of large fragments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00500v1</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Samuel Graepler, Benjamin Monmege, Jean-Marc Talbot</dc:creator>
    </item>
    <item>
      <title>Computational Paths Form a Weak {\omega}-Groupoid</title>
      <link>https://arxiv.org/abs/2512.00657</link>
      <description>arXiv:2512.00657v1 Announce Type: new 
Abstract: Lumsdaine (2010) and van den Berg-Garner (2011) proved that types in Martin-L\"of type theory carry the structure of weak {\omega}-groupoids. Their proofs, while foundational, rely on abstract properties of the identity type without providing explicit computational content for coherence witnesses. We establish an analogous result for computational paths -- an alternative formulation of equality where witnesses are explicit sequences of rewrites from the LNDEQ-TRS term rewriting system. Our main result is that computational paths on any type form a weak {\omega}-groupoid with fully explicit coherence data. The groupoid operations -- identity, composition, and inverse -- are defined at every dimension, and the coherence laws (associativity, unit laws, inverse laws) are witnessed by concrete rewrite derivations rather than abstract existence proofs. The construction provides: (i) a proper tower of n-cells for all dimensions, with 2-cells as derivations between paths and higher cells mediating between lower-dimensional witnesses; (ii) explicit pentagon and triangle coherences built from the rewrite rules; and (iii) contractibility at dimensions $\geq 3$, ensuring all parallel higher cells are connected. The contractibility property is derived from the normalization algorithm of the rewrite system, grounding the higher-dimensional structure in concrete computational content. The entire construction has been formalized in Lean 4, providing machine-checked verification of the weak {\omega}-groupoid structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00657v1</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arthur F. Ramos, Tiago M. L. de Veras, Ruy J. G. B. de Queiroz, Anjolina G. de Oliveira</dc:creator>
    </item>
    <item>
      <title>RapunSL: Untangling Quantum Computing with Separation, Linear Combination and Mixing</title>
      <link>https://arxiv.org/abs/2511.23472</link>
      <description>arXiv:2511.23472v2 Announce Type: cross 
Abstract: Quantum Separation Logic (QSL) has been proposed as an effective tool to improve the scalability of deductive reasoning for quantum programs. In QSL, separation is interpreted as disentanglement, and the frame rule brings a notion of entanglement-local specification (one that only talks about the qubits entangled with those acted upon by the program). In this paper, we identify two notions of locality unique to the quantum domain, and we construct a novel quantum separation logic, RapunSL, which is able to soundly reduce reasoning about superposition states to reasoning about pure states (basis-locality), and reasoning about mixed states arising from measurement to reasoning about pure states (outcome-locality). To do so, we introduce two connectives, linear combination and mixing, which together with separation provide a dramatic improvement in the scalability of reasoning, as we demonstrate on a series of challenging case studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.23472v2</guid>
      <category>cs.PL</category>
      <category>cs.LO</category>
      <category>quant-ph</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3776648</arxiv:DOI>
      <dc:creator>Yusuke Matsushita, Kengo Hirata, Ryo Wakizaka, Emanuele D'Osualdo</dc:creator>
    </item>
    <item>
      <title>High schoolers excel at Oxford quantum course using pictorial mathematics</title>
      <link>https://arxiv.org/abs/2512.00141</link>
      <description>arXiv:2512.00141v1 Announce Type: cross 
Abstract: We are at the dawn of the second quantum revolution, where our ability to create and control individual quantum systems is poised to drive transformative advancements in basic science, computation, and everyday life. However, quantum theory has long been conceived as notoriously hard to learn, creating a significant barrier to workforce development, informed decision-making by stakeholders and policymakers, and broader public understanding.
  This paper is concerned with Quantum Picturalism, a novel visual mathematical language for quantum physics. Originally developed over two decades ago to explore the foundational structure of quantum theory, this rigorous diagrammatic framework has since been adopted in both academia and industry as a powerful tool for quantum computing research and software development. Here, we demonstrate its potential as a transformative educational methodology.
  We report the findings from a pilot study involving 54 UK high school students, randomly selected from a pool of 734 volunteers across the UK. Despite the absence of advanced mathematical prerequisites, these students demonstrated a strong conceptual grasp of key quantum principles and operations. On an assessment comprising university graduate-level exam questions, participants achieved an 82% pass rate, with 48% obtaining a distinction-level grade.
  These results pave the way for making quantum more inclusive, lowering traditional cognitive and demographic barriers to quantum learning. This approach has the potential to broaden participation in the field and provide a promising new entry point for stakeholders, future experts, and the general public.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00141v1</guid>
      <category>physics.ed-ph</category>
      <category>cs.LO</category>
      <category>math.CT</category>
      <category>quant-ph</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bob Coecke, Aleks Kissinger, Stefano Gogioso, Selma D\"undar-Coecke, Caterina Puca, Lia Yeh, Muhammad Hamza Waseem, Emmanuel M. Pothos, Sieglinde Pfaendler, Vincent Wang-Mascianica, Thomas Cervoni, Ferdi Tomassini, Vincent Anandraj, Peter Sigrist, Ilyas Khan</dc:creator>
    </item>
    <item>
      <title>Counting and Sampling Traces in Regular Languages</title>
      <link>https://arxiv.org/abs/2512.00314</link>
      <description>arXiv:2512.00314v1 Announce Type: cross 
Abstract: In this work, we study the problems of counting and sampling Mazurkiewicz traces that a regular language touches. Fix an alphabet $\Sigma$ and an independence relation $\mathbb{I} \subseteq \Sigma \times \Sigma$. The input consists of a regular language $L \subseteq \Sigma^*$, given by a finite automaton with $m$ states, and a natural number $n$ (in unary). For the counting problem, the goal is to compute the number of Mazurkiewicz traces (induced by $\mathbb{I}$) that intersect the $n^\text{th}$ slice $L_n = L \cap \Sigma^n$, i.e., traces that admit at least one linearization in $L_n$. For the sampling problem, the goal is to output a trace drawn from a distribution that is approximately uniform over all such traces. These tasks are motivated by bounded model checking with partial-order reduction, where an \emph{a priori} estimate of the reduced state space is valuable, and by testing methods for concurrent programs that use partial-order-aware random exploration.
  We first show that the counting problem is #P-hard even when $L$ is accepted by a deterministic automaton, in sharp contrast to counting words of a DFA, which is polynomial-time solvable. We then prove that the problem lies in #P for both NFAs and DFAs, irrespective of whether $L$ is trace-closed. Our main algorithmic contributions are a \emph{fully polynomial-time randomized approximation scheme} (FPRAS) that, with high probability, approximates the desired count within a prescribed accuracy, and a \emph{fully polynomial-time almost uniform sampler} (FPAUS) that generates traces whose distribution is provably close to uniform.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00314v1</guid>
      <category>cs.FL</category>
      <category>cs.CC</category>
      <category>cs.LO</category>
      <category>cs.PL</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3776723</arxiv:DOI>
      <dc:creator>Alexis de Colnet, Kuldeep S. Meel, Umang Mathur</dc:creator>
    </item>
    <item>
      <title>Interpolation in Non-Classical Logics</title>
      <link>https://arxiv.org/abs/2512.01600</link>
      <description>arXiv:2512.01600v1 Announce Type: cross 
Abstract: This chapter surveys some of the main results on interpolation in several of the most prominent families of non-classical logics. Special attention is given to the distinction between the two most commonly studied variants of interpolation--namely, Craig interpolation and deductive interpolation. Our discussion focuses primarily on how these properties present in families of logical systems taken as a whole, particularly those comprising all axiomatic extensions of any of several notable non-classical logics. We consider a range of important examples: superintuitionistic and modal logics, fuzzy logics, paraconsistent logics, relevant logics, and substructural logics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.01600v1</guid>
      <category>math.LO</category>
      <category>cs.LO</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wesley Fussner</dc:creator>
    </item>
    <item>
      <title>Complexity of Verification and Synthesis of Threshold Automata</title>
      <link>https://arxiv.org/abs/2007.06248</link>
      <description>arXiv:2007.06248v2 Announce Type: replace 
Abstract: Threshold automata are a formalism for modeling and analyzing fault-tolerant distributed algorithms, recently introduced by Konnov, Veith, and Widder, describing protocols executed by a fixed but arbitrary number of processes. We conduct the first systematic study of the complexity of verification and synthesis problems for threshold automata. We prove that the coverability, reachability, safety, and liveness problems are NP-complete, and that the bounded synthesis problem is $\Sigma_p^2$ complete. A key to our results is a novel characterization of the reachability relation of a threshold automaton as an existential Presburger formula. The characterization also leads to novel verification and synthesis algorithms. We report on an implementation, and provide experimental results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2007.06248v2</guid>
      <category>cs.LO</category>
      <category>cs.DC</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>A. R. Balasubramanian, Javier Esparza, Marijana Lazic</dc:creator>
    </item>
    <item>
      <title>Supermartingales for Unique Fixed Points: A Unified Approach to Lower Bound Verification</title>
      <link>https://arxiv.org/abs/2504.04132</link>
      <description>arXiv:2504.04132v2 Announce Type: replace 
Abstract: Many quantitative properties of probabilistic programs can be characterized as least fixed points, but verifying their lower bounds remains a challenging problem. We present a new approach to lower-bound verification that exploits and extends the connection between the uniqueness of fixed points and program termination. The core technical tool is a generalization of ranking supermartingales, which serves as witnesses of the uniqueness of fixed points. Our method provides a simple and unified reasoning principle applicable to a wide range of quantitative properties, including termination probability, the weakest preexpectation, expected runtime, higher moments of runtime, and conditional weakest preexpectation. We provide a template-based algorithm for automated verification of lower bounds and demonstrate the effectiveness of the proposed method via experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04132v2</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Satoshi Kura, Hiroshi Unno, Takeshi Tsukada</dc:creator>
    </item>
    <item>
      <title>Tractable Weighted First-Order Model Counting with Bounded Treewidth Binary Evidence</title>
      <link>https://arxiv.org/abs/2511.09174</link>
      <description>arXiv:2511.09174v2 Announce Type: replace 
Abstract: The Weighted First-Order Model Counting Problem (WFOMC) asks to compute the weighted sum of models of a given first-order logic sentence over a given domain. Conditioning WFOMC on evidence -- fixing the truth values of a set of ground literals -- has been shown impossible in time polynomial in the domain size (unless $\mathsf{\#P \subseteq FP}$) even for fragments of logic that are otherwise tractable for WFOMC without evidence. In this work, we address the barrier by restricting the binary evidence to the case where the underlying Gaifman graph has bounded treewidth. We present a polynomial-time algorithm in the domain size for computing WFOMC for the two-variable fragments $\text{FO}^2$ and $\text{C}^2$ conditioned on such binary evidence. Furthermore, we show the applicability of our algorithm in combinatorial problems by solving the stable seating arrangement problem on bounded-treewidth graphs of bounded degree, which was an open problem. We also conducted experiments to show the scalability of our algorithm compared to the existing model counting solvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.09174v2</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>V\'aclav K\r{u}la, Qipeng Kuang, Yuyi Wang, Yuanhong Wang, Ond\v{r}ej Ku\v{z}elka</dc:creator>
    </item>
    <item>
      <title>Parameterized Verification of Quantum Circuits (Technical Report)</title>
      <link>https://arxiv.org/abs/2511.19897</link>
      <description>arXiv:2511.19897v3 Announce Type: replace 
Abstract: We present the first fully automatic framework for verifying relational properties of parameterized quantum programs, i.e., a program that, given an input size, generates a corresponding quantum circuit. We focus on verifying input-output correctness as well as equivalence. At the core of our approach is a new automata model, synchronized weighted tree automata (SWTAs), which compactly and precisely captures the infinite families of quantum states produced by parameterized programs. We introduce a class of transducers to model quantum gate semantics and develop composition algorithms for constructing transducers of parameterized circuits. Verification is reduced to functional inclusion or equivalence checking between SWTAs, for which we provide decision procedures. Our implementation demonstrates both the expressiveness and practical efficiency of the framework by verifying a diverse set of representative parameterized quantum programs with verification times ranging from milliseconds to seconds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.19897v3</guid>
      <category>cs.LO</category>
      <category>cs.FL</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Parosh Aziz Abdulla, Yu-Fang Chen, Michal He\v{c}ko, Luk\'a\v{s} Hol\'ik, Ond\v{r}ej Leng\'al, Jyun-Ao Lin, Ramanathan S. Thinniyam</dc:creator>
    </item>
    <item>
      <title>A Mathematical Framework for Transformations of Physical Processes</title>
      <link>https://arxiv.org/abs/2204.04319</link>
      <description>arXiv:2204.04319v3 Announce Type: replace-cross 
Abstract: We observe that the existence of sequential and parallel composition supermaps in higher order theories of transformations can be formalised using enriched category theory. Encouraged by relevant examples such as unitary supermaps and layers within higher order causal categories (HOCCs), we treat the modelling of higher order physical theories with enriched monoidal categories in analogy with the modelling of physical theories with monoidal categories. We use the enriched monoidal setting to construct a suitable definition of structure preserving map between higher order physical theories via the Grothendieck construction. We then show that the convenient feature of currying in higher order physical theories can be seen as a consequence of combining the primitive assumption of the existence of parallel and sequential composition supermaps with an additional feature of linking. We then use our definition of structure preserving map to show that categories containing infinite towers of enriched monoidal categories with full and faithful structure preserving maps between them inevitably lead to closed monoidal structures. The aim of the proposed definitions is to step towards providing a broad framework for the study and comparison of novel causal structures in quantum theory, and, more broadly, a paradigm of physical theory where static and dynamical features are treated in a unified way.</description>
      <guid isPermaLink="false">oai:arXiv.org:2204.04319v3</guid>
      <category>quant-ph</category>
      <category>cs.LO</category>
      <category>math.CT</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matt Wilson, Giulio Chiribella</dc:creator>
    </item>
    <item>
      <title>The internal languages of univalent categories</title>
      <link>https://arxiv.org/abs/2411.06636</link>
      <description>arXiv:2411.06636v4 Announce Type: replace-cross 
Abstract: Internal language theorems are fundamental in categorical logic, since they express an equivalence between syntax and semantics. One of such theorems was proven by Clairambault and Dybjer, who corrected the result originally by Seely. More specifically, they constructed a biequivalence between the bicategory of locally Cartesian closed categories and the bicategory of democratic categories with families with extensional identity types, $\sum$-types, and $\prod$-types. This theorem expresses that the internal language of locally Cartesian closed categories is extensional Martin-L\"of type theory with dependent sums and products. In this paper, we study the theorem by Clairambault and Dybjer for univalent categories, and we extend it to various classes of toposes, among which are $\prod$-pretoposes, elementary toposes, and elementary toposes with a universe. The results in this paper have been formalized using the proof assistant Rocq and the UniMath library.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.06636v4</guid>
      <category>math.CT</category>
      <category>cs.LO</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Niels van der Weide</dc:creator>
    </item>
    <item>
      <title>Quantum Circuits Are Just a Phase</title>
      <link>https://arxiv.org/abs/2507.11676</link>
      <description>arXiv:2507.11676v2 Announce Type: replace-cross 
Abstract: Quantum programs today are written at a low level of abstraction - quantum circuits akin to assembly languages - and the unitary parts of even advanced quantum programming languages essentially function as circuit description languages. This state of affairs impedes scalability, clarity, and support for higher-level reasoning. More abstract and expressive quantum programming constructs are needed. To this end, we introduce a simple syntax for generating unitaries from "just a phase"; we combine a (global) phase operation that captures phase shifts with a quantum analogue of the "if let" construct that captures subspace selection via pattern matching. This minimal language lifts the focus from gates to eigendecomposition, conjugation, and controlled unitaries; common building blocks in quantum algorithm design. We demonstrate several aspects of the expressive power of our language in several ways. Firstly, we establish that our representation is universal by deriving a universal quantum gate set. Secondly, we show that important quantum algorithms can be expressed naturally and concisely, including Grover's search algorithm, Hamiltonian simulation, Quantum Fourier Transform, Quantum Signal Processing, and the Quantum Eigenvalue Transformation. Furthermore, we give clean denotational semantics grounded in categorical quantum mechanics. Finally, we implement a prototype compiler that efficiently translates terms of our language to quantum circuits, and prove that it is sound with respect to these semantics. Collectively, these contributions show that this construct offers a principled and practical step toward more abstract and structured quantum programming.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.11676v2</guid>
      <category>cs.PL</category>
      <category>cs.LO</category>
      <category>quant-ph</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3776731</arxiv:DOI>
      <dc:creator>Chris Heunen, Louis Lemonnier, Christopher McNally, Alex Rice</dc:creator>
    </item>
    <item>
      <title>Combining Textual and Structural Information for Premise Selection in Lean</title>
      <link>https://arxiv.org/abs/2510.23637</link>
      <description>arXiv:2510.23637v2 Announce Type: replace-cross 
Abstract: Premise selection is a key bottleneck for scaling theorem proving in large formal libraries. Yet existing language-based methods often treat premises in isolation, ignoring the web of dependencies that connects them. We present a graph-augmented approach that combines dense text embeddings of Lean formalizations with graph neural networks over a heterogeneous dependency graph capturing both state-premise and premise-premise relations. On the LeanDojo Benchmark, our method outperforms the ReProver language-based baseline by over 25\% across standard retrieval metrics. These results suggest that relational information is beneficial for premise selection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.23637v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.LO</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Job Petrov\v{c}i\v{c}, David Eliecer Narvaez Denis, Ljup\v{c}o Todorovski</dc:creator>
    </item>
    <item>
      <title>Information Physics of Intelligence: Unifying Logical Depth and Entropy under Thermodynamic Constraints</title>
      <link>https://arxiv.org/abs/2511.19156</link>
      <description>arXiv:2511.19156v2 Announce Type: replace-cross 
Abstract: The rapid scaling of artificial intelligence models has revealed a fundamental tension between model capacity (storage) and inference efficiency (computation). While classical information theory focuses on transmission and storage limits, it lacks a unified physical framework to quantify the thermodynamic costs of generating information from compressed laws versus retrieving it from memory. In this paper, we propose a theoretical framework that treats information processing as an enabling mapping from ontological states to carrier states. We introduce a novel metric, Derivation Entropy, which quantifies the effective work required to compute a target state from a given logical depth. By analyzing the interplay between Shannon entropy (storage) and computational complexity (time/energy), we demonstrate the existence of a critical phase transition point. Below this threshold, memory retrieval is thermodynamically favorable; above it, generative computation becomes the optimal strategy. This "Energy-Time-Space" conservation law provides a physical explanation for the efficiency of generative models and offers a rigorous mathematical bound for designing next-generation, energy-efficient AI architectures. Our findings suggest that the minimization of Derivation Entropy is a governing principle for the evolution of both biological and artificial intelligence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.19156v2</guid>
      <category>cs.IT</category>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <category>math.IT</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianfeng Xu, Zeyan Li</dc:creator>
    </item>
  </channel>
</rss>
