<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 07 Jan 2026 05:00:15 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 07 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Thrust Regulation in a Solid Fuel Ramjet using Dynamic Mode Adaptive Control</title>
      <link>https://arxiv.org/abs/2601.02429</link>
      <description>arXiv:2601.02429v1 Announce Type: new 
Abstract: This paper presents the application of a novel data-driven adaptive control technique, called dynamic mode adaptive control (DMAC), for regulating thrust in a solid fuel ramjet (SFRJ). A high-fidelity computational model incorporating compressible flow theory and equilibrium chemistry is used to simulate the combustion dynamics. An adaptive tracking controller is designed using the DMAC framework, which leverages dynamic mode decomposition to approximate the local system behavior, followed by a tracking controller synthesized around the identified model. Simulation results demonstrate that DMAC provides an effective and reliable approach for thrust regulation in SFRJs. In addition, a systematic hyperparameter sensitivity study is conducted by varying the tuning parameters over several orders of magnitude. The resulting responses show that the closed-loop performance and tracking error remain stable across wide parameter variations, indicating that DMAC exhibits strong robustness to hyper parameter tuning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.02429v1</guid>
      <category>math.OC</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 07 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Parham Oveissi, Gohar T. Khokhar, Kyle Hanquist, Ankit Goel</dc:creator>
    </item>
    <item>
      <title>First Provably Optimal Asynchronous SGD for Homogeneous and Heterogeneous Data</title>
      <link>https://arxiv.org/abs/2601.02523</link>
      <description>arXiv:2601.02523v1 Announce Type: new 
Abstract: Artificial intelligence has advanced rapidly through large neural networks trained on massive datasets using thousands of GPUs or TPUs. Such training can occupy entire data centers for weeks and requires enormous computational and energy resources. Yet the optimization algorithms behind these runs have not kept pace. Most large scale training still relies on synchronous methods, where workers must wait for the slowest device, wasting compute and amplifying the effects of hardware and network variability. Removing synchronization seems like a simple fix, but asynchrony introduces staleness, meaning updates computed on outdated models. This makes analysis difficult, especially when delays arise from system level randomness rather than algorithmic choices. As a result, the time complexity of asynchronous methods remains poorly understood. This dissertation develops a rigorous framework for asynchronous first order stochastic optimization, focusing on the core challenge of heterogeneous worker speeds. Within this framework, we show that with proper design, asynchronous SGD can achieve optimal time complexity, matching guarantees previously known only for synchronous methods. Our first contribution, Ringmaster ASGD, attains optimal time complexity in the homogeneous data setting by selectively discarding stale updates. The second, Ringleader ASGD, extends optimality to heterogeneous data, common in federated learning, using a structured gradient table mechanism. Finally, ATA improves resource efficiency by learning worker compute time distributions and allocating tasks adaptively, achieving near optimal wall clock time with less computation. Together, these results establish asynchronous optimization as a theoretically sound and practically efficient foundation for distributed learning, showing that coordination without synchronization can be both feasible and optimal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.02523v1</guid>
      <category>math.OC</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Wed, 07 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.25781/KAUST-WH234</arxiv:DOI>
      <dc:creator>Artavazd Maranjyan</dc:creator>
    </item>
    <item>
      <title>Extremum Seeking Control for Wave-PDE Actuation with Distributed Effects</title>
      <link>https://arxiv.org/abs/2601.02607</link>
      <description>arXiv:2601.02607v1 Announce Type: new 
Abstract: This paper deals with the gradient-based extremum seeking control (ESC) with actuation dynamics governed by distributed wave partial differential equations (PDEs). To achieve the control objective of real-time optimization for this class of infinite-dimensional systems, we first solve the trajectory generation problem to re-design the additive perturbation signal of the ESC system. Then, we develop a boundary control law through the backstepping method to compensate for the wave PDE with distributed effects, which ensures the exponential stability of the average closed-loop system by means of a Lyapunov-based analysis. At last, by employing the averaging theory for infinite-dimensional systems, we prove that the closed-loop trajectories converge to a small neighborhood surrounding the optimal point. Numerical simulations are presented to illustrate the effectiveness of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.02607v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 07 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elisio Juvenal Muchave, Pedro Henrique Silva Coutinho, Tiago Roux Oliveira, Miroslav Krsti\'c</dc:creator>
    </item>
    <item>
      <title>Revisiting a Fast Newton Solver for a 2-D Spectral Estimation Problem: Computations with the Full Hessian</title>
      <link>https://arxiv.org/abs/2601.02690</link>
      <description>arXiv:2601.02690v1 Announce Type: new 
Abstract: Spectral estimation plays a fundamental role in frequency-domain identification and related signal processing problems. This paper revisits a 2-D spectral estimation problem formulated in terms of convex optimization. More precisely, we work with the dual optimization problem and show that the full Hessian of the dual function admits a Toeplitz-block Toeplitz structure which is consistent with our finding in a previous work. This particular structure of the Hessian enables a fast inversion algorithm in the solution of the dual optimization problem via Newton's method whose superior speed of convergence is illustrated via simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.02690v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 07 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ji Cheng, Bin Zhu</dc:creator>
    </item>
    <item>
      <title>Data-Driven Output-Based Approach to the Output Regulation Problem of Unknown Linear Systems via Value Iteration</title>
      <link>https://arxiv.org/abs/2601.02748</link>
      <description>arXiv:2601.02748v1 Announce Type: new 
Abstract: The output regulation problem for unknown linear systems has been studied using state-based and output-based internal model approaches in the special case with no disturbances. This paper further investigates the output regulation problem for unknown linear systems using a data-driven output-based approach via value iteration. For this purpose, we first develop a novel output-feedback control law that does not explicitly rely on the observer gain to solve the output regulation problem. We then show that the data-driven approach for designing an output-feedback control law for the given plant can be reduced to the data-driven design of a state-feedback control law for a well-defined augmented auxiliary system. As a result, we develop a systematic data-driven approach to solve the output regulation problem for unknown linear systems via value iteration. Finally, we establish a relation between the data-driven state-feedback control law and the data-driven output-feedback control law in the LQR sense.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.02748v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 07 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haoyan Lin, Jie Huang</dc:creator>
    </item>
    <item>
      <title>Adapting Polyhedral Dominance Cones to Ordinal Preference Structures</title>
      <link>https://arxiv.org/abs/2601.02796</link>
      <description>arXiv:2601.02796v1 Announce Type: new 
Abstract: In combinatorial optimization, ordinal costs can be used to model the quality of elements whenever numerical values are not available. When considering, for example, routing problems for cyclists, the safety of a street can be ranked in ordered categories like safe (separate bike lane), medium safe (street with a bike lane) and unsafe (street without a bike lane). However, ordinal optimization may suggest unrealistic solutions with huge detours to avoid unsafe street segments. In this paper, we investigate how partial preference information regarding the relative quality of the ordinal categories can be used to improve the relevance of the computed solutions. By introducing preference weights which describe how much better a category is at least or at most, compared to the subsequent category, we enlarge the ordinal dominance cone. This leads to a smaller set of alternatives, i. e., of ordinally efficient solutions. We show that the corresponding weighted ordinal ordering cone is a polyhedral cone and provide descriptions via its extreme rays and via its facets. The latter implies a linear transformation to an associated multi-objective optimization problem. This paves the way for the application of standard multi-objective solution approaches. We demonstrate the usefulness of the weighted ordinal ordering cone by investigating a safest path problem with different preference weights. Moreover, we investigate the interrelation between the weighted ordering cone to standard dominance concepts of multi-objective optimization, like, e.g., Pareto dominance, lexicographic dominance and weighted sum dominance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.02796v1</guid>
      <category>math.OC</category>
      <category>math.CO</category>
      <pubDate>Wed, 07 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Kathrin Klamroth, Michael Stiglmayr, Julia Sudhoff Santos</dc:creator>
    </item>
    <item>
      <title>Log-Polynomial Optimization</title>
      <link>https://arxiv.org/abs/2601.02797</link>
      <description>arXiv:2601.02797v1 Announce Type: new 
Abstract: We study an optimization problem in which the objective is given as a sum of logarithmic-polynomial functions. This formulation is motivated by statistical estimation principles such as maximum likelihood estimation, and by loss functions including cross-entropy and Kullback-Leibler divergence. We propose a hierarchy of moment relaxations based on the truncated $K$-moment problems to solve log-polynomial optimization. We provide sufficient conditions for the hierarchy to be tight and introduce a numerical method to extract the global optimizers when the tightness is achieved. In addition, we modify relaxations with optimality conditions to better fit log-polynomial optimization with convenient Lagrange multipliers expressions. Various applications and numerical experiments are presented to show the efficiency of our method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.02797v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 07 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiyoung Choi, Jiawang Nie, Xindong Tang, Suhan Zhong</dc:creator>
    </item>
    <item>
      <title>Relating Checkpoint Update Probabilities to Momentum Parameters in Single-Loop Variance Reduction Methods</title>
      <link>https://arxiv.org/abs/2601.02899</link>
      <description>arXiv:2601.02899v1 Announce Type: new 
Abstract: Variance reduction (VR) is a crucial tool for solving finite-sum optimization problems, including the composite general convex setting, which is the focus of this work. On the one hand, denoting the number of component functions as $n$ and the target accuracy as $\epsilon$, some VR methods achieve the near-optimal complexity $\widetilde{\mathcal{O}}\left(n+\sqrt{n}/\sqrt{\epsilon}\right)$, but they all have nested structure and fail to provide convergence guarantee for the iterate sequence itself. On the other hand, single-loop VR methods, being free from the aforementioned disadvantages, have complexity no better than $\mathcal{O}\left(n+n/\sqrt{\epsilon}\right)$ which is the complexity of the deterministic method FISTA, thus leaving a critical gap unaddressed. In this work, we propose the \textit{Harmonia} technique which relates checkpoint update probabilities to momentum parameters in single-loop VR methods. Based on this technique, we further propose to vary the growth rate of the momentum parameter, creating a novel continuous trade-off between acceleration and variance reduction, controlled by the key parameter $\alpha\in[0,1]$. The proposed techniques lead to following favourable consequences. First, several known complexity of quite different algorithms are re-discovered under the proposed unifying algorithmic framework Katyusha-H. Second, under an extra mild condition, Katyusha-H achieves the near-optimal complexity for $\alpha$ belonging to a certain interval, highlighting the effectiveness of the acceleration-variance reduction trade-off. Last, without extra conditions, Katyusha-H achieves the complexity $\widetilde{\mathcal{O}}(n+\sqrt{n}/\sqrt{\epsilon})$ with $\alpha=1$ and proper mini-batch sizes. The proposed idea and techniques may be of general interest beyond the considered problem in this work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.02899v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 07 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hai Liu, Tiande Guo, Congying Han</dc:creator>
    </item>
    <item>
      <title>Hopfield neural networks as port-Hamiltonian and gradient systems</title>
      <link>https://arxiv.org/abs/2601.02951</link>
      <description>arXiv:2601.02951v1 Announce Type: new 
Abstract: The structure of continuous Hopfield networks is revisited from a system-theoretic point of view. After adopting a novel electrical network interpretation involving nonlinear capacitors, it is shown that Hopfield networks admit a port-Hamiltonian formulation provided an extra passivity condition is satisfied. Subsequently it is shown that any Hopfield network can be represented as a gradient system, with Riemannian metric given by the inverse of the Hessian matrix of the total energy stored in the nonlinear capacitors. On the other hand, the well-known 'energy' function employed by Hopfield turns out to be the dissipation potential of the gradient system, and this potential is shown to satisfy a dissipation inequality that can be used for analysis and interconnection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.02951v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 07 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arjan van der Schaft</dc:creator>
    </item>
    <item>
      <title>A Relaxation Method for Nonsmooth Nonlinear Optimization with Binary Constraints</title>
      <link>https://arxiv.org/abs/2601.03008</link>
      <description>arXiv:2601.03008v1 Announce Type: new 
Abstract: We study binary optimization problems of the form \( \min_{x\in\{-1,1\}^n} f(Ax-b) \) with possibly nonsmooth loss \(f\). Following the lifted rank-one semidefinite programming (SDP) approach\cite{qian2023matrix}, we develop a majorization-minimization algorithm by using the difference-of-convexity (DC) reformuation for the rank-one constraint and the Moreau envelop for the nonsmooth loss. We provide global complexity guarantees for the proposed \textbf{D}ifference of \textbf{C}onvex \textbf{R}elaxation \textbf{A}lgorithm (DCRA) and show that it produces an approximately feasible binary solution with an explicit bound on the optimality gap. Numerical experiments on synthetic and real datasets confirm that our method achieves superior accuracy and scalability compared with existing approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03008v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 07 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Lianghai Xiao, Yitian Qian, Shaohua Pan</dc:creator>
    </item>
    <item>
      <title>Adaptive Control of Unknown Linear Switched Systems via Policy Gradient Methods</title>
      <link>https://arxiv.org/abs/2601.03016</link>
      <description>arXiv:2601.03016v1 Announce Type: new 
Abstract: We consider the policy gradient adaptive control (PGAC) framework, which adaptively updates a control policy in real time, by performing data-based gradient descent steps on the linear quadratic regulator cost. This method has empirically shown to react to changing circumstances, such as model parameters, efficiently. To formalize this observation, we design a PGAC method which stabilizes linear switched systems, where both model parameters and switching time are unknown. We use sliding window data for the policy gradient estimate and show that under a dwell time condition and small dynamics variation, the policy can track the switching dynamics and ensure closed-loop stability. We perform simulations to validate our theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03016v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 07 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Felix Laurent, Feiran Zhao, Jaap Eising, Florian D\"orfler</dc:creator>
    </item>
    <item>
      <title>Subjective-Objective Median-based Importance Technique (SOMIT) to Aid Multi-Criteria Renewable Energy Evaluation</title>
      <link>https://arxiv.org/abs/2601.03182</link>
      <description>arXiv:2601.03182v1 Announce Type: new 
Abstract: Accelerating the renewable energy transition requires informed decision-making that accounts for the diverse financial, technical, environmental, and social trade-offs across different renewable energy technologies. A critical step in this multi-criteria decision-making (MCDM) process is the determination of appropriate criteria weights. However, deriving these weights often solely involves either subjective assessment from decision-makers or objective weighting methods, each of which has limitations in terms of cognitive burden, potential bias, and insufficient contextual relevance. This study proposes the subjective-objective median-based importance technique (SOMIT), a novel hybrid approach for determining criteria weights in MCDM. By tailoring SOMIT to renewable energy evaluation, the method directly supports applied energy system planning, policy analysis, and technology prioritization under carbon neutrality goals. The practical utility of SOMIT is demonstrated through two MCDM case studies on renewable energy decision-making in India and Saudi Arabia. Using the derived weights from SOMIT, the TOPSIS method ranks the renewable energy alternatives, with solar power achieving the highest performance scores in both cases. The main contributions of this work are five-fold: 1) the proposed SOMIT reduces the number of required subjective comparisons from the conventional quadratic order to a linear order; 2) SOMIT is more robust to outliers in the alternatives-criteria matrix (ACM); 3) SOMIT balances subjective expert knowledge with objective data-driven insights, thereby mitigating bias; 4) SOMIT is inherently modular, allowing both its individual parts and the complete approach to be seamlessly coupled with a wide range of MCDM methods commonly applied in energy systems and policy analysis; 5) a dedicated Python library, pysomit, is developed for SOMIT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03182v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 07 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.apenergy.2025.126872</arxiv:DOI>
      <arxiv:journal_reference>Applied Energy, 402 (2025) 126872</arxiv:journal_reference>
      <dc:creator>Ding Ding, Yang Li, Poh Ling Neo, Zhiyuan Wang, Chongwu Xia</dc:creator>
    </item>
    <item>
      <title>Mass splitting in the time-discrete generalized Euler equations and non-Monge solutions in multi-marginal optimal transport</title>
      <link>https://arxiv.org/abs/2601.02616</link>
      <description>arXiv:2601.02616v1 Announce Type: cross 
Abstract: The time-discretized, spatially continuous generalized Euler equations are a prototype example of multi-marginal optimal transport, yet the question whether they exhibit mass-splitting (or equivalently, whether they have solutions that are not of Monge form) has remained open. Here we resolve this question by giving a mass-splitting example in one spatial dimension. Moreover we present a related and very simple fully discrete example of mass-splitting which reveals a transparent underlying mechanism.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.02616v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Wed, 07 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Gero Friesecke</dc:creator>
    </item>
    <item>
      <title>A Derivative-Free Saddle-search Algorithm With Linear Convergence Rate</title>
      <link>https://arxiv.org/abs/2601.02650</link>
      <description>arXiv:2601.02650v1 Announce Type: cross 
Abstract: We propose a derivative-free saddle-search algorithm designed to locate transition states using only function evaluations. The algorithm employs a nested architecture consisting of an inner eigenvector search and an outer saddle-point search. Through rigorous numerical analysis, we prove the almost sure convergence of the inner step under suitable assumptions. Furthermore, we establish the convergence of the outer search using a decaying step size, while demonstrating linear convergence under constant step size and boundedness conditions. Numerical experiments are provided to validate our theoretical results and demonstrate the algorithm's practical applicability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.02650v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Wed, 07 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiang Du, Baoming Shi, Lei Zhang, Xiangcheng Zheng</dc:creator>
    </item>
    <item>
      <title>Dual-quaternion learning control for autonomous vehicle trajectory tracking with safety guarantees</title>
      <link>https://arxiv.org/abs/2601.03097</link>
      <description>arXiv:2601.03097v1 Announce Type: cross 
Abstract: We propose a learning-based trajectory tracking controller for autonomous robotic platforms whose motion can be described kinematically on $\mathrm{SE}(3)$. The controller is formulated in the dual quaternion framework and operates at the velocity level, assuming direct command of angular and linear velocities, as is standard in many aerial vehicles and omnidirectional mobile robots. Gaussian Process (GP) regression is integrated into a geometric feedback law to learn and compensate online for unknown, state-dependent disturbances and modeling imperfections affecting both attitude and position, while preserving the algebraic structure and coupling properties inherent to rigid-body motion.
  The proposed approach does not rely on explicit parametric models of the unknown effects, making it well-suited for robotic systems subject to sensor-induced disturbances, unmodeled actuation couplings, and environmental uncertainties. A Lyapunov-based analysis establishes probabilistic ultimate boundedness of the pose tracking error under bounded GP uncertainty, providing formal stability guarantees for the learning-based controller.
  Simulation results demonstrate accurate and smooth trajectory tracking in the presence of realistic, localized disturbances, including correlated rotational and translational effects arising from magnetometer perturbations. These results illustrate the potential of combining geometric modeling and probabilistic learning to achieve robust, data-efficient pose control for autonomous robotic systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03097v1</guid>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 07 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Omayra Yago Nieto, Alexandre Anahory Simoes, Juan I. Giribet, Leonardo Colombo</dc:creator>
    </item>
    <item>
      <title>Nonlinear Spectral Modeling and Control of Soft-Robotic Muscles from Data</title>
      <link>https://arxiv.org/abs/2601.03247</link>
      <description>arXiv:2601.03247v1 Announce Type: cross 
Abstract: Artificial muscles are essential for compliant musculoskeletal robotics but complicate control due to nonlinear multiphysics dynamics. Hydraulically amplified electrostatic (HASEL) actuators, a class of soft artificial muscles, offer high performance but exhibit memory effects and hysteresis. Here we present a data-driven reduction and control strategy grounded in spectral submanifold (SSM) theory. In the adiabatic regime, where inputs vary slowly relative to intrinsic transients, trajectories rapidly converge to a low-dimensional slow manifold. We learn an explicit input-to-output map on this manifold from forced-response trajectories alone, avoiding decay experiments that can trigger hysteresis. We deploy the SSM-based model for real-time control of an antagonistic HASEL-clutch joint. This approach yields a substantial reduction in tracking error compared to feedback-only and feedforward-only baselines under identical settings. This record-and-control workflow enables rapid characterization and high-performance control of soft muscles and muscle-driven joints without detailed physics-based modeling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03247v1</guid>
      <category>math.DS</category>
      <category>cs.CE</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 07 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Leonardo Bettini, Amirhossein Kazemipour, Robert K. Katzschmann, George Haller</dc:creator>
    </item>
    <item>
      <title>Decision Making under Costly Sequential Information Acquisition: the Paradigm of Reversible and Irreversible Decisions</title>
      <link>https://arxiv.org/abs/2401.00569</link>
      <description>arXiv:2401.00569v4 Announce Type: replace 
Abstract: Decision making in modern stochastic systems, including e-commerce platforms, financial markets and healthcare systems, has evolved into a multifaceted process that combines information acquisition and adaptive information sources. This paper initiates a study on such integrated settings, where these elements are not only fundamental but, also, interact in a complex and stochastically intertwined manner.
  We introduce a relatively simple model, which, however, captures the involved novel elements. A decision maker (DM) may choose between an established product $A$ of known value and a new product $B$ whose value is unknown. In parallel, the DM observes signals about the unknown value of product $B$ and can, also, opt to exchange it for product $A$ if $B$ is initially chosen. Mathematically, the model gives rise to sequential optimal stopping problems with distinct informational regimes (before and after buying product $B$), differentiated by the initial, coarser signal and the subsequent, more accurate one. We analyze in detail the underlying problems using predominantly viscosity solution techniques, departing from the existing literature on information acquisition which is based on traditional optimal stopping arguments.
  More broadly, the modeling approach introduced herein offers a novel framework for developing more complex interactions among decisions, information sources and information costs in stochastic environments, through a sequence of nested obstacle problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.00569v4</guid>
      <category>math.OC</category>
      <pubDate>Wed, 07 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Renyuan Xu, Thaleia Zariphopoulou, Luhao Zhang</dc:creator>
    </item>
    <item>
      <title>Convergence of Decentralized Stochastic Subgradient-based Methods for Nonsmooth Nonconvex functions</title>
      <link>https://arxiv.org/abs/2403.11565</link>
      <description>arXiv:2403.11565v4 Announce Type: replace 
Abstract: In this paper, we focus on the decentralized stochastic subgradient-based methods in minimizing nonsmooth nonconvex functions without Clarke regularity, especially in the decentralized training of nonsmooth neural networks. We propose a general framework that unifies various decentralized subgradient-based methods, such as decentralized stochastic subgradient descent (DSGD), DSGD with gradient-tracking technique (DSGD-T), and DSGD with momentum (DSGD-M). To establish the convergence properties of our proposed framework, we relate the discrete iterates to the trajectories of a continuous-time differential inclusion, which is assumed to have a coercive Lyapunov function with a stable set $\mathcal{A}$. We prove the asymptotic convergence of the iterates to the stable set $\mathcal{A}$ with sufficiently small and diminishing step-sizes. These results provide first convergence guarantees for some well-recognized of decentralized stochastic subgradient-based methods without Clarke regularity of the objective function. Preliminary numerical experiments demonstrate that our proposed framework yields highly efficient decentralized stochastic subgradient-based methods with convergence guarantees in the training of nonsmooth neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11565v4</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 07 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siyuan Zhang, Nachuan Xiao, Xin Liu</dc:creator>
    </item>
    <item>
      <title>Common Noise by Random Measures: Constructing Mean-Field Equilibria for Competitive Investment and Hedging</title>
      <link>https://arxiv.org/abs/2408.01175</link>
      <description>arXiv:2408.01175v2 Announce Type: replace 
Abstract: We construct Nash-equilibria in mean-field portfolio games of optimal investment and hedging under relative performance concerns with exponential (CARA) utility preferences. Common noise dynamics are modeled by integer-valued random measures, for instance Poisson random measures, in addition to Brownian motions. Agents differ in individual risk aversions, competition weights, and initial capital endowments, while their contingent claim liabilities depend on both common and idiosyncratic risk factors. Mean-field equilibria are characterized by solutions to McKean-Vlasov backward stochastic differential equations with jumps, for which we prove existence and uniqueness of solutions, without assuming mean field interaction to be small. Moreover, we show how the equilibrium can be constructed from the optimal strategy of a single-agent optimization problem (without mean-field interaction) via an appropriate projection. Using successive changes of measure, our derivation provides a decomposition of the equilibrium strategy into three components with clear interpretations. Finally, we show how a limiting mean-field game of quadratic (instead of utility-based) hedging with relative performance concerns arises for vanishing risk aversion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01175v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 07 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Dirk Becherer, Stefanie Hesse</dc:creator>
    </item>
    <item>
      <title>Characterizations of Tilt-Stable Local Minimizers of a Class of Matrix Optimization Problems</title>
      <link>https://arxiv.org/abs/2503.03217</link>
      <description>arXiv:2503.03217v3 Announce Type: replace 
Abstract: Tilt stability plays a pivotal role in understanding how local solutions of an optimization problem respond to small, targeted perturbations of the objective. Although quadratic bundles are a powerful tool for capturing second-order variational behavior, their characterization remains incomplete beyond well-known polyhedral and certain specialized nonpolyhedral settings. To help bridge this gap, we propose a new point-based criterion for tilt stability in prox-regular, subdifferentially continuous functions by exploiting the notion of minimal quadratic bundles. Furthermore, we derive an explicit formula for the minimal quadratic bundle associated with a broad class of general spectral functions, thus providing a practical and unifying framework that significantly extends existing results and offers broader applicability in matrix optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03217v3</guid>
      <category>math.OC</category>
      <pubDate>Wed, 07 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chao Ding, Ebrahim Sarabi, Shiwei Wang</dc:creator>
    </item>
    <item>
      <title>AdGT: Decentralized Gradient Tracking with Tuning-free Per-Agent Stepsize</title>
      <link>https://arxiv.org/abs/2504.15196</link>
      <description>arXiv:2504.15196v4 Announce Type: replace 
Abstract: In decentralized optimization, the choice of stepsize plays a critical role in algorithm performance. A common approach is to use a shared stepsize across all agents to ensure convergence. However, selecting an optimal stepsize often requires careful tuning, which can be time-consuming and may lead to slow convergence, especially when there is significant variation in the smoothness (L-smoothness) of local objective functions across agents. Individually tuning stepsizes per agent is also impractical, particularly in large-scale networks. To address these limitations, we propose AdGT, an adaptive gradient tracking method that enables each agent to adjust its stepsize based on the smoothness of its local objective. We prove that AdGT achieves linear convergence to the global optimal solution. Through numerical experiments, we compare AdGT with fixed-stepsize gradient tracking methods and demonstrate its superior performance. Additionally, we compare AdGT with adaptive gradient descent (AdGD) in a centralized setting and observe that fully adaptive stepsizes offer greater benefits in decentralized networks than in centralized ones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15196v4</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 07 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Diyako Ghaderyan, Stefan Werner</dc:creator>
    </item>
    <item>
      <title>Weak optimal transport with moment constraints: constraint qualification, dual attainment and entropic regularization</title>
      <link>https://arxiv.org/abs/2511.16211</link>
      <description>arXiv:2511.16211v2 Announce Type: replace 
Abstract: We consider weak optimal problems (possibly entropically penalized) incorporating both soft and hard (including the case of the martingale condition) moment constraints. Even in the special case of the martingale optimal transport problem, existence of Lagrange multipliers corresponding to the martingale constraint is notoriously hard (and may fail unless some specific additional assumptions are made). We identify a condition of qualification of the hard moment constraints (which in the martingale case is implied by well-known conditions in the literature) under which general dual attainment results are established. We also analyze the convergence of entropically regularized schemes combined with penalization of the moment constraint and illustrate our theoretical findings by numerically solving in dimension one, the Brenier-Strassen problem of Gozlan and Juillet and a family of problems which interpolates between monotone transport and left-curtain martingale coupling of Beiglb\"{o}ck and Juillet.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16211v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 07 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guillaume Carlier, Hugo Malamut, Maxime Sylvestre</dc:creator>
    </item>
    <item>
      <title>A Trust-region Funnel Algorithm for Grey-Box Optimisation</title>
      <link>https://arxiv.org/abs/2511.18998</link>
      <description>arXiv:2511.18998v2 Announce Type: replace 
Abstract: Grey-box optimisation, where some parts of an optimisation problem are represented by explicit algebraic (glass-box) models while others are treated as black-box models lacking analytic derivatives, remains a challenge in process systems engineering. Trust-region (TR) methods provide a robust framework for grey-box problems by combining accurate glass-box derivatives with local reduced models (RMs) for black-box components. However, existing TR approaches often involve complex multi-layered formulations requiring extensive parameter tuning, or lack open-source implementations. Motivated by the recent advances in funnel-based convergence theory for nonlinear optimisation and the TR filter method, we propose a novel TR funnel algorithm for grey-box optimisation that replaces the filter acceptance criterion with a generalisable uni-dimensional funnel, maintaining a monotonically non-increasing upper bound on approximation error of the local black-box RMs. A global convergence proof to a first-order critical point is established. The algorithm, implemented in an open-source Pyomo framework, supports multiple RM forms and globalisation strategies (filter or funnel). Benchmark tests on seven numerical and engineering problems show that the TR funnel algorithm achieves comparable and often improved performance relative to the classical TR filter method. The TR funnel method thus provides a simpler, and extensible alternative for large-scale grey-box optimisation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.18998v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 07 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gul Hameed, Tao Chen, Antonio del Rio Chanona, Lorenz T. Biegler, Michael Short</dc:creator>
    </item>
    <item>
      <title>Continuized Nesterov Acceleration for Non-Convex Optimization</title>
      <link>https://arxiv.org/abs/2512.16533</link>
      <description>arXiv:2512.16533v2 Announce Type: replace 
Abstract: In convex optimization, continuous-time counterparts have been a fruitful tool for analyzing momentum algorithms. Fewer such examples are available when the function to minimize is non-convex. In several cases, discrepancies arise between the existing discrete-time results, namely those obtained for momentum algorithms, and their continuous-time counterparts, with the latter typically yielding stronger guarantees. We argue that the continuized framework (Even et al., 2021), mixing continuous and discrete components, can tighten the gap between known continuous and discrete results. This framework relies on computations akin to standard Lyapunov analyses, from which are deduced convergence bounds for an algorithm that can be written as a Nesterov momentum algorithm with stochastic parameters. In this work, we extend the range of applicability of the continuized framework, e.g. by allowing it to handle non-smooth Lyapunov functions. We then strengthen its trajectory-wise guarantees for linear convergence rate, deriving finite time bounds with high probability and asymptotic almost sure bounds. We apply this framework to the non-convex class of strongly quasar convex functions. Adapting continuous-time results that have weaker discrete equivalents to the continuized method, we improve by a constant factor the known convergence rate, and relax the existing assumptions on the set of minimizers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.16533v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 07 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julien Hermant, Jean-Fran\c{c}ois Aujol, Charles Dossal, Lorick Huang, Aude Rondepierre</dc:creator>
    </item>
    <item>
      <title>Regularization methods for solving hierarchical variational inequalities with complexity guarantees</title>
      <link>https://arxiv.org/abs/2512.20772</link>
      <description>arXiv:2512.20772v2 Announce Type: replace 
Abstract: We consider hierarchical variational inequality problems, or more generally, variational inequalities defined over the set of zeros of a monotone operator. This framework includes convex optimization over equilibrium constraints and equilibrium selection problems. In a real Hilbert space setting, we combine a Tikhonov regularization and a proximal penalization to develop a flexible double-loop method for which we prove asymptotic convergence and provide rate statements in terms of gap functions. Our method is flexible, and effectively accommodates a large class of structured operator splitting formulations for which fixed-point encodings are available. Finally, we validate our findings numerically on various examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.20772v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 07 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Cortild, Meggie Marschner, Mathias Staudigl</dc:creator>
    </item>
    <item>
      <title>A Perturbed DCA for Computing d-Stationary Points of Nonsmooth DC Programs</title>
      <link>https://arxiv.org/abs/2601.02084</link>
      <description>arXiv:2601.02084v2 Announce Type: replace 
Abstract: This paper introduces an efficient perturbed difference-of-convex algorithm (pDCA) for computing d-stationary points of an important class of structured nonsmooth difference-of-convex problems. Compared to the principal algorithms introduced in [J.-S. Pang, M. Razaviyayn, and A. Alvarado, Math. Oper. Res. 42(1):95--118 (2017)], which may require solving several subproblems for a one-step update, pDCA only requires solving a single subproblem. Therefore, the computational cost of pDCA for one-step update is comparable to the widely used difference-of-convex algorithm (DCA) introduced in [D. T. Pham and H. A. Le Thi, Acta Math. Vietnam. 22(1):289--355 (1997)] for computing a critical point. Importantly, under practical assumptions, we prove that every accumulation point of the sequence generated by pDCA is a d-stationary point almost surely. Numerical experiment results on several important examples of nonsmooth DC programs demonstrate the efficiency of pDCA for computing d-stationary points.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.02084v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 07 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhangcheng Feng, Yancheng Yuan</dc:creator>
    </item>
    <item>
      <title>MAST: Model-Agnostic Sparsified Training</title>
      <link>https://arxiv.org/abs/2311.16086</link>
      <description>arXiv:2311.16086v2 Announce Type: replace-cross 
Abstract: We introduce a novel optimization problem formulation that departs from the conventional way of minimizing machine learning model loss as a black-box function. Unlike traditional formulations, the proposed approach explicitly incorporates an initially pre-trained model and random sketch operators, allowing for sparsification of both the model and gradient during training. We establish the insightful properties of the proposed objective function and highlight its connections to the standard formulation. Furthermore, we present several variants of the Stochastic Gradient Descent (SGD) method adapted to the new problem formulation, including SGD with general sampling, a distributed version, and SGD with variance reduction techniques. We achieve tighter convergence rates and relax assumptions, bridging the gap between theoretical principles and practical applications, covering several important techniques such as Dropout and Sparse training. This work presents promising opportunities to enhance the theoretical understanding of model training through a sparsification-aware optimization approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.16086v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>math.OC</category>
      <pubDate>Wed, 07 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yury Demidovich, Grigory Malinovsky, Egor Shulgin, Peter Richt\'arik</dc:creator>
    </item>
    <item>
      <title>Learning mirror maps in policy mirror descent</title>
      <link>https://arxiv.org/abs/2402.05187</link>
      <description>arXiv:2402.05187v3 Announce Type: replace-cross 
Abstract: Policy Mirror Descent (PMD) is a popular framework in reinforcement learning, serving as a unifying perspective that encompasses numerous algorithms. These algorithms are derived through the selection of a mirror map and enjoy finite-time convergence guarantees. Despite its popularity, the exploration of PMD's full potential is limited, with the majority of research focusing on a particular mirror map -- namely, the negative entropy -- which gives rise to the renowned Natural Policy Gradient (NPG) method. It remains uncertain from existing theoretical studies whether the choice of mirror map significantly influences PMD's efficacy. In our work, we conduct empirical investigations to show that the conventional mirror map choice (NPG) often yields less-than-optimal outcomes across several standard benchmark environments. Using evolutionary strategies, we identify more efficient mirror maps that enhance the performance of PMD. We first focus on a tabular environment, i.e. Grid-World, where we relate existing theoretical bounds with the performance of PMD for a few standard mirror maps and the learned one. We then show that it is possible to learn a mirror map that outperforms the negative entropy in more complex environments, such as the MinAtar suite. Additionally, we demonstrate that the learned mirror maps generalize effectively to different tasks by testing each map across various other environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.05187v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 07 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Carlo Alfano, Sebastian Towers, Silvia Sapora, Chris Lu, Patrick Rebeschini</dc:creator>
    </item>
    <item>
      <title>Information geometric regularization of unidimensional pressureless Euler equations yields global strong solutions</title>
      <link>https://arxiv.org/abs/2411.15121</link>
      <description>arXiv:2411.15121v2 Announce Type: replace-cross 
Abstract: Partial differential equations describing compressible fluids are prone to the formation of shock singularities, arising from faster upstream fluid particles catching up to slower, downstream ones. In geometric terms, this causes the deformation map to leave the manifold of diffeomorphisms. Information geometric regularization addresses this issue by changing the manifold geometry to make it geodesically complete. Empirical evidence suggests that this results in smooth solutions without adding artificial viscosity. This work makes a first step towards understanding this phenomenon rigorously, in the setting of the unidimensional pressureless Euler equations. It shows that their information geometric regularization has smooth global solutions. By establishing $\Gamma$-convergence of its variational description, it proves convergence of these solutions to entropy solutions of the nominal problem, in the limit of vanishing regularization parameter. A consequence of these results is that manifolds of unidimensional diffeomorphisms with information geometric regularization are geodesically complete.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15121v2</guid>
      <category>math.AP</category>
      <category>math.DG</category>
      <category>math.OC</category>
      <pubDate>Wed, 07 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruijia Cao, Florian Sch\"afer</dc:creator>
    </item>
    <item>
      <title>Robust Quantum Control for Bragg Pulse Design in Atom Interferometry</title>
      <link>https://arxiv.org/abs/2502.04618</link>
      <description>arXiv:2502.04618v3 Announce Type: replace-cross 
Abstract: We formulate a robust optimal control algorithm to synthesize minimum energy pulses that can transfer a cold atom system into various momentum states. The algorithm uses adaptive linearization of the evolution operator and sequential quadratic programming to iterate the control towards a minimum energy pulse that achieves optimal target state fidelity. Robustness to parameter variation is achieved using Legendre polynomial approximation over the domain of variation. The method is applied to optimize the Bragg beamsplitting operation in ultra-cold atom interferometry. Even in the presence of 10-40% variability in the initial momentum dispersion of the atomic cloud and the intensity of the optical pulse, the algorithm reliably converges to a control protocol that robustly achieves unprecedented momentum levels with high fidelity for a single-frequency multi-photon Bragg diffraction scheme (e.g. $|\pm 40\hbar k\rangle$). We show the advantages of our method by comparison to stochastic optimization using sampled parameter values, provide detailed sensitivity analyses, and performance of the designed pulses is verified in laboratory experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04618v3</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <pubDate>Wed, 07 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luke S. Baker, Andre Luiz P. de Lima, Andrew Harter, Ceren Uzun, Liam P. Keeley, Jr-Shin Li, Anatoly Zlotnik, Michael J. Martin, Malcolm G. Boshier</dc:creator>
    </item>
    <item>
      <title>Solving the Paint Shop Problem with Flexible Management of Multi-Lane Buffers Using Reinforcement Learning and Action Masking</title>
      <link>https://arxiv.org/abs/2504.02644</link>
      <description>arXiv:2504.02644v2 Announce Type: replace-cross 
Abstract: In the paint shop problem, an unordered incoming sequence of cars assigned to different colors has to be reshuffled with the objective of minimizing the number of color changes. To reshuffle the incoming sequence, manufacturers can employ a first-in-first-out multi-lane buffer system allowing store and retrieve operations. So far, prior studies primarily focused on simple decision heuristics like greedy or simplified problem variants that do not allow full flexibility when performing store and retrieve operations. In this study, we propose a reinforcement learning approach to minimize color changes for the flexible problem variant, where store and retrieve operations can be performed in an arbitrary order. After proving that greedy retrieval is optimal, we incorporate this finding into the model using action masking. Our evaluation, based on 170 problem instances with 2-8 buffer lanes and 5-15 colors, shows that our approach reduces color changes compared to existing methods by considerable margins depending on the problem size. Furthermore, we demonstrate the robustness of our approach towards different buffer sizes and imbalanced color distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02644v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 07 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.ejor.2025.12.017</arxiv:DOI>
      <dc:creator>Mirko Stappert, Bernhard Lutz, Janis Brammer, Dirk Neumann</dc:creator>
    </item>
    <item>
      <title>Constant-Factor Algorithms for Revenue Management with Consecutive Stays</title>
      <link>https://arxiv.org/abs/2506.00909</link>
      <description>arXiv:2506.00909v2 Announce Type: replace-cross 
Abstract: We study network revenue management problems motivated by applications such as railway ticket sales and hotel room bookings. Requests, each requiring a resource for a consecutive stay, arrive sequentially with known arrival probabilities. We investigate two scenarios: the accept-or-reject scenario, where a request can be fulfilled by assigning any available resource; and the BAM-based scenario, which generalizes the former by incorporating customer preferences through the basic attraction model (BAM), allowing the platform to offer an assortment of available resources from which the customer may choose. We develop polynomial-time policies and evaluate their performance using approximation ratios, defined as the ratio between the expected revenue of our policy and that of the optimal online algorithm. When each arrival has a fixed request type (e.g., the interval of the stay is fixed), we establish constant-factor guarantees: a ratio of 1 - 1/e for the accept-or-reject scenario and 0.25 for the BAM-based scenario. We further extend these results to the case where the request type is random (e.g., the interval of the stay is random). In this setting, the approximation ratios incur an additional multiplicative factor of 1 - 1/e, resulting in guarantees of at least 0.399 for the accept-or-reject scenario and 0.156 for the BAM-based scenario. These constant-factor guarantees stand in sharp contrast to the prior nonconstant competitive ratios that are benchmarked against the offline optimum.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00909v2</guid>
      <category>econ.TH</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Wed, 07 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ming Hu, Tongwen Wu</dc:creator>
    </item>
    <item>
      <title>When Indemnity Insurance Fails: Parametric Coverage under Binding Budget and Risk Constraints</title>
      <link>https://arxiv.org/abs/2512.21973</link>
      <description>arXiv:2512.21973v2 Announce Type: replace-cross 
Abstract: In high-risk environments, traditional indemnity insurance is often unaffordable or ineffective, despite its well-known optimality under expected utility. We compare excess-of-loss indemnity insurance with parametric insurance within a common mean-variance framework, allowing for fixed costs, heterogeneous premium loadings, and binding budget constraints. We show that, once these realistic frictions are introduced, parametric insurance can yield higher welfare for risk-averse individuals, even under the same utility objective. The welfare advantage arises precisely when indemnity insurance becomes impractical, and disappears once both contracts are unconstrained. Our results help reconcile classical insurance theory with the growing use of parametric risk transfer in high-risk settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.21973v2</guid>
      <category>econ.GN</category>
      <category>math.OC</category>
      <category>q-fin.EC</category>
      <category>q-fin.RM</category>
      <pubDate>Wed, 07 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Benjamin Avanzi, Debbie Kusch Falden, Mogens Steffensen</dc:creator>
    </item>
  </channel>
</rss>
