<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 16 Jun 2025 04:00:38 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Gradients of unitary optical neural networks using parameter-shift rule</title>
      <link>https://arxiv.org/abs/2506.11565</link>
      <description>arXiv:2506.11565v1 Announce Type: new 
Abstract: This paper explores the application of the parameter-shift rule (PSR) for computing gradients in unitary optical neural networks (UONNs). While backpropagation has been fundamental to training conventional neural networks, its implementation in optical neural networks faces significant challenges due to the physical constraints of optical systems. We demonstrate how PSR, which calculates gradients by evaluating functions at shifted parameter values, can be effectively adapted for training UONNs constructed from Mach-Zehnder interferometer meshes. The method leverages the inherent Fourier series nature of optical interference in these systems to compute exact analytical gradients directly from hardware measurements. This approach offers a promising alternative to traditional in silico training methods and circumvents the limitations of both finite difference approximations and all-optical backpropagation implementations. We present the theoretical framework and practical methodology for applying PSR to optimize phase parameters in optical neural networks, potentially advancing the development of efficient hardware-based training strategies for optical computing systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11565v1</guid>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <category>physics.optics</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinzhe Jiang, Yaqian Zhao, Xin Zhang, Chen Li, Yunlong Yu, Hailing Liu</dc:creator>
    </item>
    <item>
      <title>Large Language models for Time Series Analysis: Techniques, Applications, and Challenges</title>
      <link>https://arxiv.org/abs/2506.11040</link>
      <description>arXiv:2506.11040v1 Announce Type: cross 
Abstract: Time series analysis is pivotal in domains like financial forecasting and biomedical monitoring, yet traditional methods are constrained by limited nonlinear feature representation and long-term dependency capture. The emergence of Large Language Models (LLMs) offers transformative potential by leveraging their cross-modal knowledge integration and inherent attention mechanisms for time series analysis. However, the development of general-purpose LLMs for time series from scratch is still hindered by data diversity, annotation scarcity, and computational requirements. This paper presents a systematic review of pre-trained LLM-driven time series analysis, focusing on enabling techniques, potential applications, and open challenges. First, it establishes an evolutionary roadmap of AI-driven time series analysis, from the early machine learning era, through the emerging LLM-driven paradigm, to the development of native temporal foundation models. Second, it organizes and systematizes the technical landscape of LLM-driven time series analysis from a workflow perspective, covering LLMs' input, optimization, and lightweight stages. Finally, it critically examines novel real-world applications and highlights key open challenges that can guide future research and innovation. The work not only provides valuable insights into current advances but also outlines promising directions for future development. It serves as a foundational reference for both academic and industrial researchers, paving the way for the development of more efficient, generalizable, and interpretable systems of LLM-driven time series analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11040v1</guid>
      <category>cs.LG</category>
      <category>cs.CL</category>
      <category>cs.ET</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Feifei Shi, Xueyan Yin, Kang Wang, Wanyu Tu, Qifu Sun, Huansheng Ning</dc:creator>
    </item>
    <item>
      <title>From over-reliance to smart integration: using Large-Language Models as translators between specialized modeling and simulation tools</title>
      <link>https://arxiv.org/abs/2506.11141</link>
      <description>arXiv:2506.11141v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) offer transformative potential for Modeling &amp; Simulation (M&amp;S) through natural language interfaces that simplify workflows. However, over-reliance risks compromising quality due to ambiguities, logical shortcuts, and hallucinations. This paper advocates integrating LLMs as middleware or translators between specialized tools to mitigate complexity in M&amp;S tasks. Acting as translators, LLMs can enhance interoperability across multi-formalism, multi-semantics, and multi-paradigm systems. We address two key challenges: identifying appropriate languages and tools for modeling and simulation tasks, and developing efficient software architectures that integrate LLMs without performance bottlenecks. To this end, the paper explores LLM-mediated workflows, emphasizes structured tool integration, and recommends Low-Rank Adaptation-based architectures for efficient task-specific adaptations. This approach ensures LLMs complement rather than replace specialized tools, fostering high-quality, reliable M&amp;S processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11141v1</guid>
      <category>cs.SE</category>
      <category>cs.ET</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Philippe J. Giabbanelli, John Beverley, Istvan David, Andreas Tolk</dc:creator>
    </item>
    <item>
      <title>Model Discovery and Graph Simulation: A Lightweight Alternative to Chaos Engineering</title>
      <link>https://arxiv.org/abs/2506.11176</link>
      <description>arXiv:2506.11176v1 Announce Type: cross 
Abstract: Microservice applications are prone to cascading failures because of dense inter-service dependencies. Ensuring resilience usually demands fault-injection experiments in production-like setups. We propose \textit{model discovery} -- an automated CI/CD step that extracts a live dependency graph from trace data -- and show that this lightweight representation is sufficient for accurate resilience prediction. Using the DeathStarBench Social Network, we build the graph, simulate failures via Monte-Carlo, and run matching chaos experiments on the real system. The graph model closely matches reality: with no replication, 16 trials yield an observed resilience of 0.186 versus a predicted 0.161; with replication, both observed and predicted values converge to 0.305 (mean absolute error \leq 0.0004). These results indicate that even a simple, automatically discovered graph can estimate microservice availability with high fidelity, offering rapid design-time insight without full-scale failure testing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11176v1</guid>
      <category>cs.SE</category>
      <category>cs.DC</category>
      <category>cs.DM</category>
      <category>cs.ET</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Anatoly A. Krasnovsky, Alexander Zorkin</dc:creator>
    </item>
    <item>
      <title>Beyond Formal Semantics for Capabilities and Skills: Model Context Protocol in Manufacturing</title>
      <link>https://arxiv.org/abs/2506.11180</link>
      <description>arXiv:2506.11180v1 Announce Type: cross 
Abstract: Explicit modeling of capabilities and skills -- whether based on ontologies, Asset Administration Shells, or other technologies -- requires considerable manual effort and often results in representations that are not easily accessible to Large Language Models (LLMs). In this work-in-progress paper, we present an alternative approach based on the recently introduced Model Context Protocol (MCP). MCP allows systems to expose functionality through a standardized interface that is directly consumable by LLM-based agents. We conduct a prototypical evaluation on a laboratory-scale manufacturing system, where resource functions are made available via MCP. A general-purpose LLM is then tasked with planning and executing a multi-step process, including constraint handling and the invocation of resource functions via MCP. The results indicate that such an approach can enable flexible industrial automation without relying on explicit semantic models. This work lays the basis for further exploration of external tool integration in LLM-driven production systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11180v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luis Miguel Vieira da Silva, Aljosha K\"ocher, Felix Gehlhoff</dc:creator>
    </item>
    <item>
      <title>Bhatt Conjectures: On Necessary-But-Not-Sufficient Benchmark Tautology for Human Like Reasoning</title>
      <link>https://arxiv.org/abs/2506.11423</link>
      <description>arXiv:2506.11423v1 Announce Type: cross 
Abstract: Debates about whether Large Language or Reasoning Models (LLMs/LRMs) truly reason or merely pattern-match suffer from shifting goal posts. In my personal opinion, two analytic--hence "tautological"--benchmarks cut through that fog in my mental model. In this paper, I attempt to write down my mental model in concrete terms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11423v1</guid>
      <category>cs.CR</category>
      <category>cs.ET</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Manish Bhatt</dc:creator>
    </item>
    <item>
      <title>Knapsack and Shortest Path Problems Generalizations From A Quantum-Inspired Tensor Network Perspective</title>
      <link>https://arxiv.org/abs/2506.11711</link>
      <description>arXiv:2506.11711v1 Announce Type: cross 
Abstract: In this paper, we present two tensor network quantum-inspired algorithms to solve the knapsack and the shortest path problems, and enables to solve some of its variations. These methods provide an exact equation which returns the optimal solution of the problems. As in other tensor network algorithms for combinatorial optimization problems, the method is based on imaginary time evolution and the implementation of restrictions in the tensor network. In addition, we introduce the use of symmetries and the reutilization of intermediate calculations, reducing the computational complexity for both problems. To show the efficiency of our implementations, we carry out some performance experiments and compare the results with those obtained by other classical algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11711v1</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sergio Mu\~niz Subi\~nas, Jorge Mart\'inez Mart\'in, Alejandro Mata Ali, Javier Sedano, \'Angel Miguel Garc\'ia-Vico</dc:creator>
    </item>
    <item>
      <title>Fish feeding behavior recognition and intensity quantification methods in aquaculture: From single modality analysis to multimodality fusion</title>
      <link>https://arxiv.org/abs/2502.15311</link>
      <description>arXiv:2502.15311v2 Announce Type: replace-cross 
Abstract: As a key part of aquaculture management, fish feeding behavior recognition and intensity quantification has been a hot area of great concern to researchers, and it plays a crucial role in monitoring fish health, guiding baiting work and improving aquaculture efficiency. In order to better carry out the related work in the future, this paper firstly analyzes and compares the existing reviews. Then reviews the research advances of fish feeding behavior recognition and intensity quantification methods based on computer vision, acoustics and sensors in a single modality. Meanwhile, the application of the current emerging multimodal fusion in fish feeding behavior recognition and intensity quantification methods is expounded. Finally, the advantages and disadvantages of various techniques are compared and analyzed, and the future research directions are envisioned.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.15311v2</guid>
      <category>cs.CV</category>
      <category>cs.ET</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shulong Zhang, Jiayin Zhao, Mingyuan Yao, Xiao Liu, Yukang Huo, Yingyi Chen, Haihua Wang</dc:creator>
    </item>
    <item>
      <title>DURA-CPS: A Multi-Role Orchestrator for Dependability Assurance in LLM-Enabled Cyber-Physical Systems</title>
      <link>https://arxiv.org/abs/2506.06381</link>
      <description>arXiv:2506.06381v2 Announce Type: replace-cross 
Abstract: Cyber-Physical Systems (CPS) increasingly depend on advanced AI techniques to operate in critical applications. However, traditional verification and validation methods often struggle to handle the unpredictable and dynamic nature of AI components. In this paper, we introduce DURA-CPS, a novel framework that employs multi-role orchestration to automate the iterative assurance process for AI-powered CPS. By assigning specialized roles (e.g., safety monitoring, security assessment, fault injection, and recovery planning) to dedicated agents within a simulated environment, DURA-CPS continuously evaluates and refines AI behavior against a range of dependability requirements. We demonstrate the framework through a case study involving an autonomous vehicle navigating an intersection with an AI-based planner. Our results show that DURA-CPS effectively detects vulnerabilities, manages performance impacts, and supports adaptive recovery strategies, thereby offering a structured and extensible solution for rigorous V&amp;V in safety- and security-critical systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.06381v2</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.HC</category>
      <category>cs.MA</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Trisanth Srinivasan, Santosh Patapati, Himani Musku, Idhant Gode, Aditya Arora, Samvit Bhattacharya, Abubakr Nazriev, Sanika Hirave, Zaryab Kanjiani, Srinjoy Ghose</dc:creator>
    </item>
  </channel>
</rss>
