<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.LO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.LO</link>
    <description>cs.LO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.LO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 16 Aug 2024 01:23:57 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 15 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Queries With Exact Truth Values in Paraconsistent Description Logics</title>
      <link>https://arxiv.org/abs/2408.07283</link>
      <description>arXiv:2408.07283v2 Announce Type: new 
Abstract: We present a novel approach to querying classical inconsistent description logic (DL) knowledge bases by adopting a~paraconsistent semantics with the four Belnapian values: exactly true ($\mathbf{T}$), exactly false ($\mathbf{F}$), both ($\mathbf{B}$), and neither ($\mathbf{N}$). In contrast to prior studies on paraconsistent DLs, we allow truth value operators in the query language, which can be used to differentiate between answers having contradictory evidence and those having only positive evidence. We present a reduction to classical DL query answering that allows us to pinpoint the precise combined and data complexity of answering queries with values in paraconsistent $\mathcal{ALCHI}$ and its sublogics. Notably, we show that tractable data complexity is retained for Horn DLs. We present a comparison with repair-based inconsistency-tolerant semantics, showing that the two approaches are incomparable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07283v2</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <category>cs.DB</category>
      <category>math.LO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Meghyn Bienvenu, Camille Bourgaux, Daniil Kozhemiachenko</dc:creator>
    </item>
    <item>
      <title>Abductive Reasoning in a Paraconsistent Framework</title>
      <link>https://arxiv.org/abs/2408.07287</link>
      <description>arXiv:2408.07287v1 Announce Type: new 
Abstract: We explore the problem of explaining observations starting from a classically inconsistent theory by adopting a paraconsistent framework. We consider two expansions of the well-known Belnap--Dunn paraconsistent four-valued logic $\mathsf{BD}$: $\mathsf{BD}_\circ$ introduces formulas of the form $\circ\phi$ (the information on $\phi$ is reliable), while $\mathsf{BD}_\triangle$ augments the language with $\triangle\phi$'s (there is information that $\phi$ is true). We define and motivate the notions of abduction problems and explanations in $\mathsf{BD}_\circ$ and $\mathsf{BD}_\triangle$ and show that they are not reducible to one another. We analyse the complexity of standard abductive reasoning tasks (solution recognition, solution existence, and relevance / necessity of hypotheses) in both logics. Finally, we show how to reduce abduction in $\mathsf{BD}_\circ$ and $\mathsf{BD}_\triangle$ to abduction in classical propositional logic, thereby enabling the reuse of existing abductive reasoning procedures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07287v1</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <category>math.LO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Meghyn Bienvenu, Katsumi Inoue, Daniil Kozhemiachenko</dc:creator>
    </item>
    <item>
      <title>Trade-offs between classical and quantum space using spooky pebbling</title>
      <link>https://arxiv.org/abs/2401.10579</link>
      <description>arXiv:2401.10579v3 Announce Type: cross 
Abstract: Pebble games are used to study space/time trade-offs. Recently, spooky pebble games were introduced to study classical space / quantum space / time trade-offs for simulation of classical circuits on quantum computers. In this paper, the spooky pebble game framework is applied for the first time to general circuits. Using this framework we prove an upper bound for quantum space in the spooky pebble game. We also prove that solving the spooky pebble game is PSPACE-complete. Moreover, we present a solver for the spooky pebble game based on satisfiability solvers combined with heuristic optimizers. This spooky pebble game solver was empirically evaluated by calculating optimal classical space / quantum space / time trade-offs. Within limited runtime, the solver could find a strategy reducing quantum space when classical space is taken into account, showing that the spooky pebble model is useful to reduce quantum space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.10579v3</guid>
      <category>quant-ph</category>
      <category>cs.LO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arend-Jan Quist, Alfons Laarman</dc:creator>
    </item>
    <item>
      <title>On-the-fly Synthesis for LTL over Finite Traces: An Efficient Approach that Counts</title>
      <link>https://arxiv.org/abs/2408.07324</link>
      <description>arXiv:2408.07324v1 Announce Type: cross 
Abstract: We present an on-the-fly synthesis framework for Linear Temporal Logic over finite traces (LTLf) based on top-down deterministic automata construction. Existing approaches rely on constructing a complete Deterministic Finite Automaton (DFA) corresponding to the LTLf specification, a process with doubly exponential complexity relative to the formula size in the worst case. In this case, the synthesis procedure cannot be conducted until the entire DFA is constructed. This inefficiency is the main bottleneck of existing approaches. To address this challenge, we first present a method for converting LTLf into Transition-based DFA (TDFA) by directly leveraging LTLf semantics, incorporating intermediate results as direct components of the final automaton to enable parallelized synthesis and automata construction. We then explore the relationship between LTLf synthesis and TDFA games and subsequently develop an algorithm for performing LTLf synthesis using on-the-fly TDFA game solving. This algorithm traverses the state space in a global forward manner combined with a local backward method, along with the detection of strongly connected components. Moreover, we introduce two optimization techniques -- model-guided synthesis and state entailment -- to enhance the practical efficiency of our approach. Experimental results demonstrate that our on-the-fly approach achieves the best performance on the tested benchmarks and effectively complements existing tools and approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07324v1</guid>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shengping Xiao, Yongkang Li, Shufang Zhu, Jun Sun, Jianwen Li, Geguang Pu, Moshe Y. Vardi</dc:creator>
    </item>
    <item>
      <title>A Quantum-Inspired Analysis of Human Disambiguation Processes</title>
      <link>https://arxiv.org/abs/2408.07402</link>
      <description>arXiv:2408.07402v1 Announce Type: cross 
Abstract: Formal languages are essential for computer programming and are constructed to be easily processed by computers. In contrast, natural languages are much more challenging and instigated the field of Natural Language Processing (NLP). One major obstacle is the ubiquity of ambiguities. Recent advances in NLP have led to the development of large language models, which can resolve ambiguities with high accuracy. At the same time, quantum computers have gained much attention in recent years as they can solve some computational problems faster than classical computers. This new computing paradigm has reached the fields of machine learning and NLP, where hybrid classical-quantum learning algorithms have emerged. However, more research is needed to identify which NLP tasks could benefit from a genuine quantum advantage. In this thesis, we applied formalisms arising from foundational quantum mechanics, such as contextuality and causality, to study ambiguities arising from linguistics. By doing so, we also reproduced psycholinguistic results relating to the human disambiguation process. These results were subsequently used to predict human behaviour and outperformed current NLP methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07402v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <category>quant-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daphne Wang</dc:creator>
    </item>
    <item>
      <title>Optimising Dynamic Traffic Distribution for Urban Networks with Answer Set Programming</title>
      <link>https://arxiv.org/abs/2408.07521</link>
      <description>arXiv:2408.07521v1 Announce Type: cross 
Abstract: Answer Set Programming (ASP) has demonstrated its potential as an effective tool for concisely representing and reasoning about real-world problems. In this paper, we present an application in which ASP has been successfully used in the context of dynamic traffic distribution for urban networks, within a more general framework devised for solving such a real-world problem. In particular, ASP has been employed for the computation of the "optimal" routes for all the vehicles in the network. We also provide an empirical analysis of the performance of the whole framework, and of its part in which ASP is employed, on two European urban areas, which shows the viability of the framework and the contribution ASP can give.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07521v1</guid>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matteo Cardellini, Carmine Dodaro, Marco Maratea, Mauro Vallati</dc:creator>
    </item>
    <item>
      <title>Fast Inference for Probabilistic Answer Set Programs via the Residual Program</title>
      <link>https://arxiv.org/abs/2408.07524</link>
      <description>arXiv:2408.07524v1 Announce Type: cross 
Abstract: When we want to compute the probability of a query from a Probabilistic Answer Set Program, some parts of a program may not influence the probability of a query, but they impact on the size of the grounding. Identifying and removing them is crucial to speed up the computation. Algorithms for SLG resolution offer the possibility of returning the residual program which can be used for computing answer sets for normal programs that do have a total well-founded model. The residual program does not contain the parts of the program that do not influence the probability. In this paper, we propose to exploit the residual program for performing inference. Empirical results on graph datasets show that the approach leads to significantly faster inference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07524v1</guid>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Damiano Azzolini, Fabrizio Riguzzi</dc:creator>
    </item>
    <item>
      <title>Verification of Quantum Circuits through Discrete-Time Barrier Certificates</title>
      <link>https://arxiv.org/abs/2408.07591</link>
      <description>arXiv:2408.07591v1 Announce Type: cross 
Abstract: Current methods for verifying quantum computers are predominately based on interactive or automatic theorem provers. Considering that quantum computers are dynamical in nature, this paper employs and extends the concepts from the verification of dynamical systems to verify properties of quantum circuits. Our main contribution is to propose k-inductive barrier certificates over complex variables and show how to compute them using Hermitian Sum of Squares optimization. We apply this new technique to verify properties of different quantum circuits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07591v1</guid>
      <category>quant-ph</category>
      <category>cs.LO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marco Lewis, Sadegh Soudjani, Paolo Zuliani</dc:creator>
    </item>
    <item>
      <title>Modal Logic with Relations over Paths: a Theoretical Development through Comonadic Semantics</title>
      <link>https://arxiv.org/abs/2307.09679</link>
      <description>arXiv:2307.09679v2 Announce Type: replace 
Abstract: Game comonads provide categorical semantics for comparison games in Finite Model Theory, thus providing an abstract characterisation of logical equivalence for a wide range of logics, each one captured through a specific choice of comonad. Motivated by the goal of applying comonadic tools to the study of data-aware logics such as CoreDataXPath, in this work we introduce a generalisation of Modal Logic that allows relation symbols of arbitrary arity as atoms of the syntax, which we call Path Predicate Modal Logic or PPML. We motivate this logic as arising from a shift in perspective on a previously studied fragment of CoreDataXPath, called DataGL, and prove that PPML recovers DataGL for a specific choice of signature. We argue that this shift in perspective allows the capturing and designing of new data-aware logics. We introduce resource-bounded simulation and bisimulation games for PPML and show the Hennessy-Milner property relating bisimilarity and logical equivalence. We define the PPML comonad and prove that it captures these games. We develop the model-theoretical understanding of PPML by making systematic use of the comonadic framework. This includes results such as a tree-model property and an alternative proof of the one-way Hennessy-Milner property using a correspondence between positive PPML formulas and canonical models. We also use the comonadic perspective to establish connections with other logics, such as bounded quantifier rank and bounded variable number fragments of First Order Logic on one side and Basic Modal Logic on the other, and show how the PPML comonad induces a syntax-free characterisation of logical equivalence for DataGL, our original motivation. With respect to Basic Modal Logic, a functorial assignment from PPML unravellings into Kripke trees enables us to obtain polynomial-time reductions from PPML problems to their Basic Modal Logic counterparts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.09679v2</guid>
      <category>cs.LO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Santiago Figueira, Gabriel Goren-Roig</dc:creator>
    </item>
    <item>
      <title>On the computational properties of basic mathematical notions</title>
      <link>https://arxiv.org/abs/2203.05250</link>
      <description>arXiv:2203.05250v3 Announce Type: replace-cross 
Abstract: We investigate the computational properties of basic mathematical notions pertaining to $\mathbb{R}\rightarrow \mathbb{R}$-functions and subsets of $\mathbb{R}$, like finiteness, countability, (absolute) continuity, bounded variation, suprema, and regularity. We work in higher-order computability theory based on Kleene's S1-S9 schemes. We show that the aforementioned italicised properties give rise to two huge and robust classes of computationally equivalent operations, the latter based on well-known theorems from the mainstream mathematics literature. As part of this endeavour, we develop an equivalent $\lambda$-calculus formulation of S1-S9 that accommodates partial objects. We show that the latter are essential to our enterprise via the study of countably based and partial functionals of type $3$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2203.05250v3</guid>
      <category>math.LO</category>
      <category>cs.LO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1093/logcom/exac075</arxiv:DOI>
      <arxiv:journal_reference>Journal of Logic and Computation, Volume 32, Issue 8, December 2022, Pages 1747-1795</arxiv:journal_reference>
      <dc:creator>Dag Normann, Sam Sanders</dc:creator>
    </item>
    <item>
      <title>On some computational properties of open sets</title>
      <link>https://arxiv.org/abs/2401.09053</link>
      <description>arXiv:2401.09053v4 Announce Type: replace-cross 
Abstract: Open sets are central to mathematics, especially analysis and topology, in ways few notions are. In most, if not all, computational approaches to mathematics, open sets are only studied indirectly via their 'codes' or 'representations'. In this paper, we study how hard it is to compute, given an arbitrary open set of reals, the most common representation, i.e. a countable set of open intervals. We work in Kleene's higher-order computability theory, which was historically based on the S1-S9 schemes and which now has an intuitive lambda calculus formulation due to the authors. We establish many computational equivalences between on one hand the 'structure' functional that converts open sets to the aforementioned representation, and on the other hand functionals arising from mainstream mathematics, like basic properties of semi-continuous functions, the Urysohn lemma, and the Tietze extension theorem. We also compare these functionals to known operations on regulated and bounded variation functions, and the Lebesgue measure restricted to closed sets. We obtain a number of natural computational equivalences for the latter involving theorems from mainstream mathematics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.09053v4</guid>
      <category>math.LO</category>
      <category>cs.LO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dag Normann, Sam Sanders</dc:creator>
    </item>
    <item>
      <title>SAT Encoding of Partial Ordering Models for Graph Coloring Problems</title>
      <link>https://arxiv.org/abs/2403.15961</link>
      <description>arXiv:2403.15961v3 Announce Type: replace-cross 
Abstract: In this paper, we suggest new SAT encodings of the partial-ordering based ILP model for the graph coloring problem (GCP) and the bandwidth coloring problem (BCP). The GCP asks for the minimum number of colors that can be assigned to the vertices of a given graph such that each two adjacent vertices get different colors. The BCP is a generalization, where each edge has a weight that enforces a minimal "distance" between the assigned colors, and the goal is to minimize the "largest" color used. For the widely studied GCP, we experimentally compare our new SAT encoding to the state-of-the-art approaches on the DIMACS benchmark set. Our evaluation confirms that this SAT encoding is effective for sparse graphs and even outperforms the state-of-the-art on some DIMACS instances. For the BCP, our theoretical analysis shows that the partial-ordering based SAT and ILP formulations have an asymptotically smaller size than that of the classical assignment-based model. Our practical evaluation confirms not only a dominance compared to the assignment-based encodings but also to the state-of-the-art approaches on a set of benchmark instances. Up to our knowledge, we have solved several open instances of the BCP from the literature for the first time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15961v3</guid>
      <category>cs.AI</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>cs.LO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Faber, Adalat Jabrayilov, Petra Mutzel</dc:creator>
    </item>
    <item>
      <title>An algebraic proof of the dichotomy for graph orientation problems with forbidden tournaments</title>
      <link>https://arxiv.org/abs/2405.20263</link>
      <description>arXiv:2405.20263v2 Announce Type: replace-cross 
Abstract: For a set F of finite tournaments, the F-free orientation problem is the problem of orienting a given finite undirected graph in such a way that the resulting oriented graph does not contain any member of F. Using the theory of smooth approximations, we give a new shorter proof of the complexity dichotomy for such problems obtained recently by Bodirsky and Guzm\'{a}n-Pro. In fact, our approach yields a complexity dichotomy for a considerably larger class of computational problems where one is given an undirected graph along with additional local constraints on the allowed orientations. Moreover, the border between tractable and hard problems is described by a decidable algebraic condition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20263v2</guid>
      <category>math.CO</category>
      <category>cs.CC</category>
      <category>cs.LO</category>
      <category>math.RA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roman Feller, Michael Pinsker</dc:creator>
    </item>
  </channel>
</rss>
