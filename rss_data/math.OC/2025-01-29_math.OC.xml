<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 29 Jan 2025 05:00:20 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Safe Gradient Flow for Bilevel Optimization</title>
      <link>https://arxiv.org/abs/2501.16520</link>
      <description>arXiv:2501.16520v1 Announce Type: new 
Abstract: Bilevel optimization is a key framework in hierarchical decision-making, where one problem is embedded within the constraints of another. In this work, we propose a control-theoretic approach to solving bilevel optimization problems. Our method consists of two components: a gradient flow mechanism to minimize the upper-level objective and a safety filter to enforce the constraints imposed by the lower-level problem. Together, these components form a safe gradient flow that solves the bilevel problem in a single loop. To improve scalability with respect to the lower-level problem's dimensions, we introduce a relaxed formulation and design a compact variant of the safe gradient flow. This variant minimizes the upper-level objective while ensuring the lower-level solution remains within a user-defined distance. Using Lyapunov analysis, we establish convergence guarantees for the dynamics, proving that they converge to a neighborhood of the optimal solution. Numerical experiments further validate the effectiveness of the proposed approaches. Our contributions provide both theoretical insights and practical tools for efficiently solving bilevel optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16520v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sina Sharifi, Nazanin Abolfazli, Erfan Yazdandoost Hamedani, Mahyar Fazlyab</dc:creator>
    </item>
    <item>
      <title>On characterizing optimal learning trajectories in a class of learning problems</title>
      <link>https://arxiv.org/abs/2501.16521</link>
      <description>arXiv:2501.16521v1 Announce Type: new 
Abstract: In this brief paper, we provide a mathematical framework that exploits the relationship between the maximum principle and dynamic programming for characterizing optimal learning trajectories in a class of learning problem, which is related to point estimations for modeling of high-dimensional nonlinear functions. Here, such characterization for the optimal learning trajectories is associated with the solution of an optimal control problem for a weakly-controlled gradient system with small parameters, whose time-evolution is guided by a model training dataset and its perturbed version, while the optimization problem consists of a cost functional that summarizes how to gauge the quality/performance of the estimated model parameters at a certain fixed final time w.r.t. a model validating dataset. Moreover, using a successive Galerkin approximation method, we provide an algorithmic recipe how to construct the corresponding optimal learning trajectories leading to the optimal estimated model parameters for such a class of learning problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16521v1</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Getachew K Befekadu</dc:creator>
    </item>
    <item>
      <title>Quantum advantage in decentralized control of POMDPs: A control-theoretic view of the Mermin-Peres square</title>
      <link>https://arxiv.org/abs/2501.16690</link>
      <description>arXiv:2501.16690v1 Announce Type: new 
Abstract: Consider a decentralized partially-observed Markov decision problem (POMDP) with multiple cooperative agents aiming to maximize a long-term-average reward criterion. We observe that the availability, at a fixed rate, of entangled states of a product quantum system between the agents, where each agent has access to one of the component systems, can result in strictly improved performance even compared to the scenario where common randomness is provided to the agents, i.e. there is a quantum advantage in decentralized control. This observation comes from a simple reinterpretation of the conclusions of the well-known Mermin-Peres square, which underpins the Mermin-Peres game. While quantum advantage has been demonstrated earlier in one-shot team problems of this kind, it is notable that there are examples where there is a quantum advantage for the one-shot criterion but it disappears in the dynamical scenario. The presence of a quantum advantage in dynamical scenarios is thus seen to be a novel finding relative to the current state of knowledge about the achievable performance in decentralized control problems.
  This paper is dedicated to the memory of Pravin P. Varaiya.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16690v1</guid>
      <category>math.OC</category>
      <category>cs.IT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <category>quant-ph</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Venkat Anantharam</dc:creator>
    </item>
    <item>
      <title>A strategic planning of a digital copy (an enterprise) as a task of control a dynamic system</title>
      <link>https://arxiv.org/abs/2501.16725</link>
      <description>arXiv:2501.16725v1 Announce Type: new 
Abstract: The area of research includes: control theory, dynamic systems, parameters of the external environment, mode, integral indicators, strategy. The general problem of assessing the state of large economic objects (enterprises) is revealed. There is no unified assessment a control of through strategic planning. The article proposes an integral indicator method for a unified assessment of the enterprise. The enterprise is formalized as a digital copy. The digital copy includes all business processes at any given time. The digital copy is presented as a multidimensional dynamic system. Dimension of multidimensional dynamic system is 1.2 parameters This allows you to estimate the modes operation of the enterprise in the normal mode and in the mode for control of strategic planning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16725v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1088/1742-6596/1679/3/032010</arxiv:DOI>
      <arxiv:journal_reference>J. Phys.: Conf. Ser. 1679 032010 (2020)</arxiv:journal_reference>
      <dc:creator>Seregey Masaev, Valentina Vingert, Alexey Bogdanov, Yass Salal</dc:creator>
    </item>
    <item>
      <title>On the acceleration of gradient methods: the triangle steepest descent method</title>
      <link>https://arxiv.org/abs/2501.16731</link>
      <description>arXiv:2501.16731v1 Announce Type: new 
Abstract: The gradient type of methods has been a competitive choice in solving large scale problems arising from various applications such as machine learning. However, there is still space to accelerate the gradient methods. To this end, in this paper, we pay attention to the cyclic steepest descent method (CSD), and prove that the CSD method has a gradient subsequence that is R-superlinearly convergent for the 2-dimensional strictly convex quadratic case. Moreover, we propose a new gradient method called triangle steepest descent method (TSD) which has a parameter $j$ to control the number of cycles. This method is motivated by utilizing a geometric property of the steepest descent method (SD) method to get around the zigzag behavior. We show that the TSD method is at least R-linearly convergent for strictly convex quadratic problems. The advantage of the TSD method is that it is not sensitive to the condition number of a strictly convex quadratic problem. For example, it performs better than other competitive gradient methods when the condition number reaches 1e20 or 1e100 for some strictly convex quadratic problems. Extensive numerical results verify the efficiency of the TSD method compared to other types of gradient methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16731v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ya Shen, Qing-Na Li, Yu-Hong Dai</dc:creator>
    </item>
    <item>
      <title>Information security control as a task of control a dynamic system</title>
      <link>https://arxiv.org/abs/2501.16732</link>
      <description>arXiv:2501.16732v1 Announce Type: new 
Abstract: The area of research includes control theory, dynamic systems, parameters of the external environment, mode, integral indicators, British standards. The main idea of the article is information security. The activity of a large-scale object (enterprise) is considered. The activity of the enterprise is presented as a multidimensional dynamic system and is displayed as a digital copy of 1.2 million parameters. A British digital copy-based information security standard is being introduced. Information security equipment and software were purchased. The training of the company's personnel was completed. Evaluation of implementation (activities) is done as an integral indicator. The dynamics of the integral indicator assesses the implementation of the British standard.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16732v1</guid>
      <category>math.OC</category>
      <category>cs.CR</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1088/1742-6596/1679/3/032012</arxiv:DOI>
      <arxiv:journal_reference>J. Phys.: Conf. Ser. 1679 032012 (2020)</arxiv:journal_reference>
      <dc:creator>Sergey Masaev, Andrey Minkin, Yuri Bezborodov, Dmitry Edimichev, Yass Salal</dc:creator>
    </item>
    <item>
      <title>Topology optimization for microchannel heat sinks with nanofluids using an Eulerian-Eulerian approach</title>
      <link>https://arxiv.org/abs/2501.16749</link>
      <description>arXiv:2501.16749v1 Announce Type: new 
Abstract: The demand for high-performance heat sinks has significantly increased with advancements in computing power and the miniaturization of electronic devices. Among the promising solutions, nanofluids have attracted considerable attention due to their superior thermal conductivity. However, designing a flow field that effectively utilizes nanofluids remains a significant challenge due to the complex interactions between fluid and nanoparticles. In this study, we propose a density-based topology optimization method for microchannel heat sink design using nanofluids. An Eulerian-Eulerian framework is utilized to simulate the behavior of nanofluids, and the optimization problem aims to maximize heat transfer performance under a fixed pressure drop. In numerical examples, we investigate the dependence of the optimized configuration on various parameters and apply the method to the design of a manifold microchannel heat sink. The parametric study reveals that the number of flow branches increases with the increased pressure drop but decreases as the particle volume fraction increases. In the heat sink design, the topology-optimized flow field achieves an 11.6% improvement in heat transfer performance compared to a conventional parallel flow field under identical nanofluid conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16749v1</guid>
      <category>math.OC</category>
      <category>physics.flu-dyn</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chih-Hsiang Chen, Kentaro Yaji</dc:creator>
    </item>
    <item>
      <title>Random attraction in TASEP with time-varying hopping rates</title>
      <link>https://arxiv.org/abs/2501.16777</link>
      <description>arXiv:2501.16777v1 Announce Type: new 
Abstract: The totally asymmetric simple exclusion principle (TASEP) is a fundamental model in nonequilibrium statistical mechanics. It describes the stochastic unidirectional movement of particles along a 1D chain of ordered sites. We consider the continuous-time version of TASEP with a finite number of sites and with time-varying hopping rates between the sites. We show how to formulate this model as a nonautonomous random dynamical system (NRDS) with a finite state-space. We provide conditions guaranteeing that random pullback and forward attractors of such an NRDS exist and consist of singletons. In the context of the nonautonomous TASEP these conditions imply almost sure synchronization of the individual random paths. This implies in particular that perturbations that change the state of the particles along the chain are "filtered out" in the long run. We demonstrate that the required conditions are tight by providing examples where these conditions do not hold and consequently the forward attractor does not exist or the pullback attractor is not a singleton. The results in this paper generalize our earlier results for autonomous TASEP in https://doi.org/10.1137/20M131446X and contain these as a special case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16777v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lars Gr\"une, Kilian Pioch, Thomas Kriecherbauer, Michael Margaliot</dc:creator>
    </item>
    <item>
      <title>Optimal Criteria for Best Subset Selection</title>
      <link>https://arxiv.org/abs/2501.16815</link>
      <description>arXiv:2501.16815v1 Announce Type: new 
Abstract: This paper introduces two novel criteria: one for feature selection and another for feature elimination in the context of best subset selection, which is a benchmark problem in statistics and machine learning. From the perspective of optimization, we revisit the classical selection and elimination criteria in traditional best subset selection algorithms, revealing that these classical criteria capture only partial variations of the objective function after the entry or exit of features. By formulating and solving optimization subproblems for feature entry and exit exactly, new selection and elimination criteria are proposed, proved as the optimal decisions for the current entry-and-exit process compared to classical criteria. Replacing the classical selection and elimination criteria with the proposed ones generates a series of enhanced best subset selection algorithms. These generated algorithms not only preserve the theoretical properties of the original algorithms but also achieve significant meta-gains without increasing computational cost across various scenarios and evaluation metrics on multiple tasks such as compressed sensing and sparse regression.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16815v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhihan Zhu, Yanhao Zhang, Yong Xia</dc:creator>
    </item>
    <item>
      <title>Pessimistic bilevel optimization approach for decision-focused learning</title>
      <link>https://arxiv.org/abs/2501.16826</link>
      <description>arXiv:2501.16826v1 Announce Type: new 
Abstract: The recent interest in contextual optimization problems, where randomness is associated with side information, has led to two primary strategies for formulation and solution. The first, estimate-then-optimize, separates the estimation of the problem's parameters from the optimization process. The second, decision-focused optimization, integrates the optimization problem's structure directly into the prediction procedure. In this work, we propose a pessimistic bilevel approach for solving general decision-focused formulations of combinatorial optimization problems. Our method solves an $\varepsilon$-approximation of the pessimistic bilevel problem using a specialized cut generation algorithm. We benchmark its performance on the 0-1 knapsack problem against estimate-then-optimize and decision-focused methods, including the popular SPO+ approach. Computational experiments highlight the proposed method's advantages, particularly in reducing out-of-sample regret.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16826v1</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Diego Jim\'enez, Bernardo K. Pagnoncelli, Hande Yaman</dc:creator>
    </item>
    <item>
      <title>Electricity Market Bidding for Renewable Electrolyzer Plants: An Opportunity Cost Approach</title>
      <link>https://arxiv.org/abs/2501.16844</link>
      <description>arXiv:2501.16844v1 Announce Type: new 
Abstract: Hydrogen produced through electrolysis with renewable power is considered key to decarbonize several hard-to-electrify sectors. This work proposes a novel approach to model the active electricity market participation of co-located renewable energy and electrolyzer plants, based on opportunity-cost bidding. While a renewable energy plant typically has zero marginal cost, selling power to the grid carries a potential opportunity-cost of not producing hydrogen when it is co-located with a hydrogen electrolyzer. We first consider only the electrolyzer, and derive its revenue of consuming electricity based on the non-convex hydrogen production curve. We then consider the available renewable energy production and form a piece-wise linear cost curve representing the opportunity cost of selling (or revenue from consuming) various levels of electricity. This cost curve can be used to model a stand-alone electrolyzer or a co-located hydrogen and renewable energy plant participating in an electricity market. Our case study analyzes the effects of market-bidding electrolyzers on electricity markets and grid operations. We compare two strategies for a co-located electrolyzer-wind plant; one based on the proposed bid curve and one with a more conventional fixed electrolyzer consumption. The results show that electrolyzers that actively participate in the electricity market lower the average cost of electricity and the amount of curtailed renewable energy in the system compared with a fixed consumption case. However, the difference in total system emissions between the two strategies is insignificant. The specific impacts vary based on electrolyzer capacity and hydrogen price, which determines the location of the co-located plant in the electricity market merit order.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16844v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrea Gloppen Johnsen, Lesia Mitridati, Jalal Kazempour, Line Roald</dc:creator>
    </item>
    <item>
      <title>Hopf-Lax approximation for value functions of L\'evy optimal control problems</title>
      <link>https://arxiv.org/abs/2501.16846</link>
      <description>arXiv:2501.16846v1 Announce Type: new 
Abstract: In this paper, we investigate stochastic versions of the Hopf-Lax formula which are based on compositions of the Hopf-Lax operator with the transition kernel of a L\'evy process taking values in a separable Banach space. We show that, depending on the order of the composition, one obtains upper and lower bounds for the value function of a stochastic optimal control problem associated to the drift controlled L\'evy dynamics. Dynamic consistency is restored by iterating the resulting operators. Moreover, the value function of the control problem is approximated both from above and below as the number of iterations tends to infinity, and we provide explicit convergence rates and guarantees for the approximation procedure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16846v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Kupper, Max Nendel, Alessandro Sgarabottolo</dc:creator>
    </item>
    <item>
      <title>Optimization and Learning in Open Multi-Agent Systems</title>
      <link>https://arxiv.org/abs/2501.16847</link>
      <description>arXiv:2501.16847v1 Announce Type: new 
Abstract: Modern artificial intelligence relies on networks of agents that collect data, process information, and exchange it with neighbors to collaboratively solve optimization and learning problems. This article introduces a novel distributed algorithm to address a broad class of these problems in "open networks", where the number of participating agents may vary due to several factors, such as autonomous decisions, heterogeneous resource availability, or DoS attacks. Extending the current literature, the convergence analysis of the proposed algorithm is based on the newly developed "Theory of Open Operators", which characterizes an operator as open when the set of components to be updated changes over time, yielding to time-varying operators acting on sequences of points of different dimensions and compositions. The mathematical tools and convergence results developed here provide a general framework for evaluating distributed algorithms in open networks, allowing to characterize their performance in terms of the punctual distance from the optimal solution, in contrast with regret-based metrics that assess cumulative performance over a finite-time horizon. As illustrative examples, the proposed algorithm is used to solve dynamic consensus or tracking problems on different metrics of interest, such as average, median, and min/max value, as well as classification problems with logistic loss functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16847v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Diego Deplano, Nicola Bastianello, Mauro Franceschelli, Karl H. Johansson</dc:creator>
    </item>
    <item>
      <title>Generating Random Vectors satisfying Linear and Nonlinear Constraints</title>
      <link>https://arxiv.org/abs/2501.16936</link>
      <description>arXiv:2501.16936v1 Announce Type: new 
Abstract: We consider the problem of generating n-dimensional vectors with a fixed sum, with the goal of generating a uniform distribution of vectors over a valid region. This means that each possible vector has an equal probability of being generated. The Dirichlet-Rescale (DRS) algorithm, introduced by Griffin et al. (2020), aims to generate a uniform distribution of vectors with fixed sum that satisfies lower and upper bounds on the individual entries. However, we demonstrate that the uniform distribution property of the DRS algorithm does not hold in general. Using an analytical procedure and a statistical test, we show that the vectors generated by the DRS algorithm do not appear to be drawn from a uniform distribution. To resolve this issue, we propose the Dirichlet-Rescale-Constraints (DRSC) algorithm, which handles more general constraints, including both linear and nonlinear constraints, while ensuring that the vectors are drawn from a uniform distribution. In our computational experiments we demonstrate the effectiveness of the DRSC algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16936v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rick S. H. Willemsen, Wilco van den Heuvel, Michel van de Velden</dc:creator>
    </item>
    <item>
      <title>Pareto sensitivity, most-changing sub-fronts, and knee solutions</title>
      <link>https://arxiv.org/abs/2501.16993</link>
      <description>arXiv:2501.16993v1 Announce Type: new 
Abstract: When dealing with a multi-objective optimization problem, obtaining a comprehensive representation of the Pareto front can be computationally expensive. Furthermore, identifying the most representative Pareto solutions can be difficult and sometimes ambiguous. A popular selection are the so-called Pareto knee solutions, where a small improvement in any objective leads to a large deterioration in at least one other objective. In this paper, using Pareto sensitivity, we show how to compute Pareto knee solutions according to their verbal definition of least maximal change. We refer to the resulting approach as the sensitivity knee (snee) approach, and we apply it to unconstrained and constrained problems. Pareto sensitivity can also be used to compute the most-changing Pareto sub-fronts around a Pareto solution, where the points are distributed along directions of maximum change, which could be of interest in a decision-making process if one is willing to explore solutions around a current one. Our approach is still restricted to scalarized methods, in particular to the weighted-sum or epsilon-constrained methods, and require the computation or approximations of first- and second-order derivatives. We include numerical results from synthetic problems that illustrate the benefits of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16993v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tommaso Giovannelli, Marcos Medeiros Raimundo, Luis Nunes Vicente</dc:creator>
    </item>
    <item>
      <title>Convergence of two-timescale gradient descent ascent dynamics: finite-dimensional and mean-field perspectives</title>
      <link>https://arxiv.org/abs/2501.17122</link>
      <description>arXiv:2501.17122v1 Announce Type: new 
Abstract: The two-timescale gradient descent-ascent (GDA) is a canonical gradient algorithm designed to find Nash equilibria in min-max games. We analyze the two-timescale GDA by investigating the effects of learning rate ratios on convergence behavior in both finite-dimensional and mean-field settings. In particular, for finite-dimensional quadratic min-max games, we obtain long-time convergence in near quasi-static regimes through the hypocoercivity method. For mean-field GDA dynamics, we investigate convergence under a finite-scale ratio using a mixed synchronous-reflection coupling technique.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.17122v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jing An, Jianfeng Lu</dc:creator>
    </item>
    <item>
      <title>Which Optimizer Works Best for Physics-Informed Neural Networks and Kolmogorov-Arnold Networks?</title>
      <link>https://arxiv.org/abs/2501.16371</link>
      <description>arXiv:2501.16371v1 Announce Type: cross 
Abstract: Physics-Informed Neural Networks (PINNs) have revolutionized the computation of PDE solutions by integrating partial differential equations (PDEs) into the neural network's training process as soft constraints, becoming an important component of the scientific machine learning (SciML) ecosystem. In its current implementation, PINNs are mainly optimized using first-order methods like Adam, as well as quasi-Newton methods such as BFGS and its low-memory variant, L-BFGS. However, these optimizers often struggle with highly non-linear and non-convex loss landscapes, leading to challenges such as slow convergence, local minima entrapment, and (non)degenerate saddle points. In this study, we investigate the performance of Self-Scaled Broyden (SSBroyden) methods and other advanced quasi-Newton schemes, including BFGS and L-BFGS with different line search strategies approaches. These methods dynamically rescale updates based on historical gradient information, thus enhancing training efficiency and accuracy. We systematically compare these optimizers on key challenging linear, stiff, multi-scale and non-linear PDEs benchmarks, including the Burgers, Allen-Cahn, Kuramoto-Sivashinsky, and Ginzburg-Landau equations, and extend our study to Physics-Informed Kolmogorov-Arnold Networks (PIKANs) representation. Our findings provide insights into the effectiveness of second-order optimization strategies in improving the convergence and accurate generalization of PINNs for complex PDEs by orders of magnitude compared to the state-of-the-art.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16371v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Elham Kiyani, Khemraj Shukla, Jorge F. Urb\'an, J\'er\^ome Darbon, George Em Karniadakis</dc:creator>
    </item>
    <item>
      <title>Near-Optimal Parameter Tuning of Level-1 QAOA for Ising Models</title>
      <link>https://arxiv.org/abs/2501.16419</link>
      <description>arXiv:2501.16419v1 Announce Type: cross 
Abstract: The Quantum Approximate Optimisation Algorithm (QAOA) is a hybrid quantum-classical algorithm for solving combinatorial optimisation problems. QAOA encodes solutions into the ground state of a Hamiltonian, approximated by a $p$-level parameterised quantum circuit composed of problem and mixer Hamiltonians, with parameters optimised classically. While deeper QAOA circuits can offer greater accuracy, practical applications are constrained by complex parameter optimisation and physical limitations such as gate noise, restricted qubit connectivity, and state-preparation-and-measurement errors, limiting implementations to shallow depths. This work focuses on QAOA$_1$ (QAOA at $p=1$) for QUBO problems, represented as Ising models. Despite QAOA$_1$ having only two parameters, $(\gamma, \beta)$, we show that their optimisation is challenging due to a highly oscillatory landscape, with oscillation rates increasing with the problem size, density, and weight. This behaviour necessitates high-resolution grid searches to avoid distortion of cost landscapes that may result in inaccurate minima. We propose an efficient optimisation strategy that reduces the two-dimensional $(\gamma, \beta)$ search to a one-dimensional search over $\gamma$, with $\beta^*$ computed analytically. We establish the maximum permissible sampling period required to accurately map the $\gamma$ landscape and provide an algorithm to estimate the optimal parameters in polynomial time. Furthermore, we rigorously prove that for regular graphs on average, the globally optimal $\gamma^* \in \mathbb{R}^+$ values are concentrated very close to zero and coincide with the first local optimum, enabling gradient descent to replace exhaustive line searches. This approach is validated using Recursive QAOA (RQAOA), where it consistently outperforms both coarsely optimised RQAOA and semidefinite programs across all tested QUBO instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16419v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>cs.ET</category>
      <category>math.OC</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>V Vijendran, Dax Enshan Koh, Eunok Bae, Hyukjoon Kwon, Ping Koy Lam, Syed M Assad</dc:creator>
    </item>
    <item>
      <title>Dosimetric impact of real-time re-optimization of proton pencil-beam scanning for moving targets</title>
      <link>https://arxiv.org/abs/2501.16840</link>
      <description>arXiv:2501.16840v1 Announce Type: cross 
Abstract: When treating moving tumors, the precise delivery of proton therapy by pencil beam scanning (PBS) is challenged by the interplay effect. Although several 4D-optimization methods have been proposed, what is the most beneficial motion management technique is still an open question. In this study, we wish to investigate the dosimetric impact of re-optimizing the PBS spot weights during the treatment delivery in response to, and in anticipation of, variations in the patient's breathing pattern. We simulate for PBS the implementation of a real-time adaptive framework based on principles from receding horizon control. We consider the patient motion as characterized by a one-dimensional amplitude signal and a 4DCT, to simulate breathing of variable frequency. The framework tracks the signal and predicts the future motion with uncertainty increasing with the length of the prediction horizon. After each delivered energy layer, the framework re-optimizes the spot weights of the next layer based on the delivered dose and the predicted motion. For three lung patients, we generate 500 variable breathing patterns to evaluate the dosimetric results of the framework and compare them to those of implementations of previously proposed non-adaptive methods. Compared to the best non-adaptive method, the adaptive framework improves the CTV D98 in the near-worst breathing scenario (5th percentile), from 96.4 to 98.9 % of the prescribed dose and considerably reduces the variation as measured by a mean decrease in the inter-quartile range by more than 80 %. The target coverage improvements are achieved without generally compromising target dose homogeneity or OAR dose. The study indicates that a motion-adaptive approach based on re-optimization of spot weights during delivery has the potential to substantially improve the dosimetric performance of PBS given fast and accurate models of patient motion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16840v1</guid>
      <category>physics.med-ph</category>
      <category>math.OC</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ivar Bengtsson, Anders Forsgren, Albin Fredriksson</dc:creator>
    </item>
    <item>
      <title>Guaranteed upper bounds for iteration errors and modified Kacanov schemes via discrete duality</title>
      <link>https://arxiv.org/abs/2501.16850</link>
      <description>arXiv:2501.16850v1 Announce Type: cross 
Abstract: We apply duality theory to discretized convex minimization problems to obtain computable guaranteed upper bounds for the distance of given discrete functions and the exact discrete minimizer. Furthermore, we show that the discrete duality framework extends convergence results for the Kacanov scheme to a broader class of problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16850v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lars Diening, Johannes Storn</dc:creator>
    </item>
    <item>
      <title>Water transport on finite graphs</title>
      <link>https://arxiv.org/abs/2501.16911</link>
      <description>arXiv:2501.16911v1 Announce Type: cross 
Abstract: Consider a simple finite graph and its nodes to represent identical water barrels (containing different amounts of water) on a level plane. Each edge corresponds to a (locked, water-filled) pipe connecting two barrels below the plane. We fix one node $v$ and consider the optimization problem relating to the maximum value to which the level in $v$ can be raised without pumps, i.e. by opening/closing pipes in a suitable order. This fairly natural optimization problem originated from the analysis of an opinion formation process and proved to be not only sufficiently intricate in order to be of independent interest, but also difficult from an algorithmic point of view.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16911v1</guid>
      <category>math.CO</category>
      <category>math.OC</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Timo Vilkas</dc:creator>
    </item>
    <item>
      <title>Hellinger-Kantorovich Gradient Flows: Global Exponential Decay of Entropy Functionals</title>
      <link>https://arxiv.org/abs/2501.17049</link>
      <description>arXiv:2501.17049v1 Announce Type: cross 
Abstract: We investigate a family of gradient flows of positive and probability measures, focusing on the Hellinger-Kantorovich (HK) geometry, which unifies transport mechanism of Otto-Wasserstein, and the birth-death mechanism of Hellinger (or Fisher-Rao). A central contribution is a complete characterization of global exponential decay behaviors of entropy functionals (e.g. KL, $\chi^2$) under Otto-Wasserstein and Hellinger-type gradient flows. In particular, for the more challenging analysis of HK gradient flows on positive measures -- where the typical log-Sobolev arguments fail -- we develop a specialized shape-mass decomposition that enables new analysis results. Our approach also leverages the (Polyak-)\L{}ojasiewicz-type functional inequalities and a careful extension of classical dissipation estimates. These findings provide a unified and complete theoretical framework for gradient flows and underpin applications in computational algorithms for statistical inference, optimization, and machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.17049v1</guid>
      <category>math.AP</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Mielke, Jia-Jie Zhu</dc:creator>
    </item>
    <item>
      <title>Optimal control over Markovian wireless communication channels under generalized packet dropout compensation</title>
      <link>https://arxiv.org/abs/2501.17105</link>
      <description>arXiv:2501.17105v1 Announce Type: cross 
Abstract: Control loops closed over wireless links greatly benefit from accurate estimates of the communication channel condition. To this end, the finite-state Markov channel model allows for reliable channel state estimation. This paper develops a Markov jump linear system representation for wireless networked control with persistent channel state observation, stochastic message losses, and generalized packet dropout compensation. With this model, we solve the finite- and infinite-horizon linear quadratic regulation problems and introduce an easy-to-test stability condition for any given infinite-horizon control law. We also thoroughly analyze the impact of a scalar general dropout compensation factor on the stability and closed-loop performance of a rotary inverted pendulum controlled remotely through a wireless link. Finally, we validate the results numerically via extensive Monte Carlo simulations, showing the benefits of the proposed control strategy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.17105v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuriy Zacchia Lun, Francesco Smarra, Alessandro D'Innocenzo</dc:creator>
    </item>
    <item>
      <title>Bowen's equations for invariance pressure of control systems</title>
      <link>https://arxiv.org/abs/2309.01628</link>
      <description>arXiv:2309.01628v3 Announce Type: replace 
Abstract: We aim to establish Bowen's equations for upper capacity invariance pressure and Pesin-Pitskel invariance pressure of discrete-time control systems. We first introduce a new invariance pressure called induced invariance pressure on partitions that specializes the upper capacity invariance pressure on partitions, and then show that the two types of invariance pressures are related by a Bowen's equation. Besides, to establish Bowen's equation for Pesin-Pitskel invariance pressure on partitions we also introduce a new notion called BS invariance dimension on subsets. Moreover, a variational principle for BS invariance dimension on subsets is established.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.01628v3</guid>
      <category>math.OC</category>
      <category>cs.IT</category>
      <category>math.DS</category>
      <category>math.IT</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rui Yang, Ercai Chen, Jiao Yang, Xiaoyao Zhou</dc:creator>
    </item>
    <item>
      <title>Decentralized Gradient-Free Methods for Stochastic Non-Smooth Non-Convex Optimization</title>
      <link>https://arxiv.org/abs/2310.11973</link>
      <description>arXiv:2310.11973v2 Announce Type: replace 
Abstract: We consider decentralized gradient-free optimization of minimizing Lipschitz continuous functions that satisfy neither smoothness nor convexity assumption. We propose two novel gradient-free algorithms, the Decentralized Gradient-Free Method (DGFM) and its variant, the Decentralized Gradient-Free Method$^+$ (DGFM$^{+}$). Based on the techniques of randomized smoothing and gradient tracking, DGFM requires the computation of the zeroth-order oracle of a single sample in each iteration, making it less demanding in terms of computational resources for individual computing nodes. Theoretically, DGFM achieves a complexity of $\mathcal O(d^{3/2}\delta^{-1}\varepsilon ^{-4})$ for obtaining an $(\delta,\varepsilon)$-Goldstein stationary point. DGFM$^{+}$, an advanced version of DGFM, incorporates variance reduction to further improve the convergence behavior. It samples a mini-batch at each iteration and periodically draws a larger batch of data, which improves the complexity to $\mathcal O(d^{3/2}\delta^{-1} \varepsilon^{-3})$. Moreover, experimental results underscore the empirical advantages of our proposed algorithms when applied to real-world datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.11973v2</guid>
      <category>math.OC</category>
      <category>cs.DC</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhenwei Lin, Jingfan Xia, Qi Deng, Luo Luo</dc:creator>
    </item>
    <item>
      <title>Technical Report: Pose Graph Optimization over Planar Unit Dual Quaternions: Improved Accuracy with Provably Convergent Riemannian Optimization</title>
      <link>https://arxiv.org/abs/2404.00010</link>
      <description>arXiv:2404.00010v3 Announce Type: replace 
Abstract: It is common in pose graph optimization (PGO) algorithms to assume that noise in the translations and rotations of relative pose measurements is uncorrelated. However, existing work shows that in practice these measurements can be highly correlated, which leads to degradation in the accuracy of PGO solutions that rely on this assumption. Therefore, in this paper we develop a novel algorithm derived from a realistic, correlated model of relative pose uncertainty, and we quantify the resulting improvement in the accuracy of the solutions we obtain relative to state-of-the-art PGO algorithms. Our approach utilizes Riemannian optimization on the planar unit dual quaternion (PUDQ) manifold, and we prove that it converges to first-order stationary points of a Lie-theoretic maximum likelihood objective. Then we show experimentally that, compared to state-of-the-art PGO algorithms, this algorithm produces estimation errors that are lower by 10% to 25% across several orders of magnitude of noise levels and graph sizes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00010v3</guid>
      <category>math.OC</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>William D. Warke, J. Humberto Ramos, Prashant Ganesh, Kevin M. Brink, Matthew T. Hale</dc:creator>
    </item>
    <item>
      <title>Local geometry of feasible regions via smooth paths</title>
      <link>https://arxiv.org/abs/2408.06984</link>
      <description>arXiv:2408.06984v2 Announce Type: replace 
Abstract: Variational analysis presents a unified theory encompassing in particular both smoothness and convexity. In a Euclidean space, convex sets and smooth manifolds both have straightforward local geometry. However, in the most basic hybrid case of feasible regions consisting of pre-images of convex sets under maps that are once (but not necessarily twice) continuously differentiable, the geometry is less transparent. We define a new approximate convexity property, that holds both for such feasible regions and also for all prox-regular sets. This new property requires that nearby points can always be joined by smooth feasible paths that are almost straight. In particular, in the terminology of real algebraic geometry, such feasible regions are locally normally embedded in the Euclidean space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06984v2</guid>
      <category>math.OC</category>
      <category>math.MG</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adrian S. Lewis, Adriana Nicolae, Tonghua Tian</dc:creator>
    </item>
    <item>
      <title>Beyond Minimax Optimality: A Subgame Perfect Gradient Method</title>
      <link>https://arxiv.org/abs/2412.06731</link>
      <description>arXiv:2412.06731v2 Announce Type: replace 
Abstract: The study of unconstrained convex optimization has historically been concerned with worst-case a priori convergence rates. The development of the Optimized Gradient Method (OGM), due to Drori and Teboulle, Kim and Fessler, marked a major milestone in this study, as OGM achieves the optimal worst-case convergence rate among all gradient-span first-order methods. However, this notion of worst-case optimality is relatively coarse and allows OGM to have worst-case performance even on instances where stronger convergence guarantees are possible. For example, OGM is known to converge at its worst-case rate even on the toy example $Lx^2/$, where exact convergence in just two steps is possible.
  We introduce a notion of optimality which is stronger than minimax optimality that requires a method to give optimal dynamic guarantees that exploit any "non-adversarialness" in the first-order oracle's reported information. We then give an algorithm which achieves this stronger optimality notion: the Subgame Perfect Gradient Method (SPGM). SPGM is a refinement of OGM whose update rules and convergence guarantees are dynamically computed in response to first-order information seen during the algorithm's execution. From a game-theoretic viewpoint, OGM can be seen as one side of a Nash Equilibrium for the "minimization game" whereas SPGM can be seen as one side of a Subgame Perfect Equilibrium for the same game. We also show that SPGM can be implemented with minimal computational and storage overhead in each iteration and provide a Julia implementation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06731v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Benjamin Grimmer, Kevin Shu, Alex L. Wang</dc:creator>
    </item>
    <item>
      <title>Fortifying Critical Infrastructure Networks with Multicriteria Portfolio Decision Analysis: An Application to Railway Stations in Finland</title>
      <link>https://arxiv.org/abs/2501.06279</link>
      <description>arXiv:2501.06279v2 Announce Type: replace 
Abstract: Advanced societies are crucially dependent on critical infrastructure networks for the reliable delivery of essential goods and services. Hence, well-founded analyses concerning disruptions are needed to guide decisions that seek to ensure the performance of these networks in the face of failures caused by vulnerabilities to external hazards or technical malfunctions. In this setting, we develop an approach based on multicriteria decision analysis to support the identification of cost-efficient portfolios of preventive fortification actions. Our approach (i) allows for multiple objectives, such as those that represent the traffic volume that is enabled between alternative origin-destination pairs in a transportation network, (ii) uses methods of probabilistic risk assessment to quantify the expected performance of the network, and (iii) uses a search algorithm combined with an optimization model to identify those combinations of fortification actions that are cost-efficient in improving the performance of the network, given the available, possibly incomplete information about the relative importance of objectives and minimum performance requirements on them. Our methodological contributions are illustrated by a case study on the analysis of railway switches at a representative Finnish railway station.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.06279v2</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joaqu\'in de la Barra, Ahti Salo, Leevi Olander, Kash Barker, Jussi Kangaspunta</dc:creator>
    </item>
    <item>
      <title>A bang-bang optimal control for a nonlinear system modeling the Gate Control Theory of Pain</title>
      <link>https://arxiv.org/abs/2501.14821</link>
      <description>arXiv:2501.14821v2 Announce Type: replace 
Abstract: We consider a nonlinear system of coupled ordinary differential equations (representing the excitatory, inhibitory, and T-cell potentials) based on the Gate Control Theory of Pain, initially proposed by R. Melzack and P.D. Wall in 1965, and later mathematically modeled by N.F. Britton and S.M. Skevington in 1988.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14821v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Gregorio Diaz, Jesus Ildefonso Diaz</dc:creator>
    </item>
    <item>
      <title>Multicausal transport: barycenters and dynamic matching</title>
      <link>https://arxiv.org/abs/2401.12748</link>
      <description>arXiv:2401.12748v2 Announce Type: replace-cross 
Abstract: We introduce a multivariate version of causal transport, which we name multicausal transport, involving several filtered processes among which causality constraints are imposed. Subsequently, we consider the barycenter problem for stochastic processes with respect to causal and bicausal optimal transport, and study its connection to specific multicausal transport problems. Attainment and duality of the aforementioned problems are provided. As an application, we study a matching problem in a dynamic setting where agent types evolve over time. We link this to a causal barycenter problem and thereby show existence of equilibria.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.12748v2</guid>
      <category>math.PR</category>
      <category>econ.GN</category>
      <category>math.OC</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Beatrice Acciaio, Daniel Kr\v{s}ek, Gudmund Pammer</dc:creator>
    </item>
    <item>
      <title>GCBF+: A Neural Graph Control Barrier Function Framework for Distributed Safe Multi-Agent Control</title>
      <link>https://arxiv.org/abs/2401.14554</link>
      <description>arXiv:2401.14554v3 Announce Type: replace-cross 
Abstract: Distributed, scalable, and safe control of large-scale multi-agent systems is a challenging problem. In this paper, we design a distributed framework for safe multi-agent control in large-scale environments with obstacles, where a large number of agents are required to maintain safety using only local information and reach their goal locations. We introduce a new class of certificates, termed graph control barrier function (GCBF), which are based on the well-established control barrier function theory for safety guarantees and utilize a graph structure for scalable and generalizable distributed control of MAS. We develop a novel theoretical framework to prove the safety of an arbitrary-sized MAS with a single GCBF. We propose a new training framework GCBF+ that uses graph neural networks to parameterize a candidate GCBF and a distributed control policy. The proposed framework is distributed and is capable of taking point clouds from LiDAR, instead of actual state information, for real-world robotic applications. We illustrate the efficacy of the proposed method through various hardware experiments on a swarm of drones with objectives ranging from exchanging positions to docking on a moving target without collision. Additionally, we perform extensive numerical experiments, where the number and density of agents, as well as the number of obstacles, increase. Empirical results show that in complex environments with agents with nonlinear dynamics (e.g., Crazyflie drones), GCBF+ outperforms the hand-crafted CBF-based method with the best performance by up to 20% for relatively small-scale MAS with up to 256 agents, and leading reinforcement learning (RL) methods by up to 40% for MAS with 1024 agents. Furthermore, the proposed method does not compromise on the performance, in terms of goal reaching, for achieving high safety rates, which is a common trade-off in RL-based methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.14554v3</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Songyuan Zhang, Oswin So, Kunal Garg, Chuchu Fan</dc:creator>
    </item>
    <item>
      <title>Geometric and computational hardness of bilevel programming</title>
      <link>https://arxiv.org/abs/2407.12372</link>
      <description>arXiv:2407.12372v2 Announce Type: replace-cross 
Abstract: We first show a simple but striking result in bilevel optimization: unconstrained $C^\infty$ smooth bilevel programming is as hard as general extended-real-valued lower semicontinuous minimization. We then proceed to a worst-case analysis of box-constrained bilevel polynomial optimization.  We show in particular that any extended-real-valued semi-algebraic function, possibly non-continuous, can be expressed as the value function of a polynomial bilevel program. Secondly, from a computational complexity perspective, the decision version of polynomial bilevel programming is one level above NP in the polynomial hierarchy ($\Sigma^p_2$-hard). Both types of difficulties are uncommon in non-linear programs for which objective functions are typically continuous and belong to the class NP. These results highlight the irremediable hardness attached to general bilevel optimization and the necessity of imposing some form of regularity on the lower level.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12372v2</guid>
      <category>cs.CC</category>
      <category>math.OC</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>J\'er\^ome Bolte (TSE-R), Quoc-Tung Le (TSE-R), Edouard Pauwels (TSE-R, IRIT-ADRIA), Samuel Vaiter (CNRS, LJAD)</dc:creator>
    </item>
    <item>
      <title>S-CFE: Simple Counterfactual Explanations</title>
      <link>https://arxiv.org/abs/2410.15723</link>
      <description>arXiv:2410.15723v5 Announce Type: replace-cross 
Abstract: We study the problem of finding optimal sparse, manifold-aligned counterfactual explanations for classifiers. Canonically, this can be formulated as an optimization problem with multiple non-convex components, including classifier loss functions and manifold alignment (or \emph{plausibility}) metrics. The added complexity of enforcing \emph{sparsity}, or shorter explanations, complicates the problem further. Existing methods often focus on specific models and plausibility measures, relying on convex $\ell_1$ regularizers to enforce sparsity. In this paper, we tackle the canonical formulation using the accelerated proximal gradient (APG) method, a simple yet efficient first-order procedure capable of handling smooth non-convex objectives and non-smooth $\ell_p$ (where $0 \leq p &lt; 1$) regularizers. This enables our approach to seamlessly incorporate various classifiers and plausibility measures while producing sparser solutions. Our algorithm only requires differentiable data-manifold regularizers and supports box constraints for bounded feature ranges, ensuring the generated counterfactuals remain \emph{actionable}. Finally, experiments on real-world datasets demonstrate that our approach effectively produces sparse, manifold-aligned counterfactual explanations while maintaining proximity to the factual data and computational efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15723v5</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Shpresim Sadiku, Moritz Wagner, Sai Ganesh Nagarajan, Sebastian Pokutta</dc:creator>
    </item>
    <item>
      <title>Quadratic Modelings of Syndrome Decoding</title>
      <link>https://arxiv.org/abs/2412.04848</link>
      <description>arXiv:2412.04848v2 Announce Type: replace-cross 
Abstract: This paper presents enhanced reductions of the bounded-weight and exact-weight Syndrome Decoding Problem (SDP) to a system of quadratic equations. Over $\mathbb{F}_2$, we improve on a previous work and study the degree of regularity of the modeling of the exact weight SDP. Additionally, we introduce a novel technique that transforms SDP instances over $\mathbb{F}_q$ into systems of polynomial equations and thoroughly investigate the dimension of their varieties. Experimental results are provided to evaluate the complexity of solving SDP instances using our models through Gr\"obner bases techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.04848v2</guid>
      <category>cs.CR</category>
      <category>math.OC</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alessio Caminata, Ryann Cartor, Alessio Meneghetti, Rocco Mora, Alex Pellegrini</dc:creator>
    </item>
    <item>
      <title>LPBSA: Enhancing Optimization Efficiency through Learner Performance-based Behavior and Simulated Annealing</title>
      <link>https://arxiv.org/abs/2501.14759</link>
      <description>arXiv:2501.14759v2 Announce Type: replace-cross 
Abstract: This study introduces the LPBSA, an advanced optimization algorithm that combines Learner Performance-based Behavior (LPB) and Simulated Annealing (SA) in a hybrid approach. Emphasizing metaheuristics, the LPBSA addresses and mitigates the challenges associated with traditional LPB methodologies, enhancing convergence, robustness, and adaptability in solving complex optimization problems. Through extensive evaluations using benchmark test functions, the LPBSA demonstrates superior performance compared to LPB and competes favorably with established algorithms such as PSO, FDO, LEO, and GA. Real-world applications underscore the algorithm's promise, with LPBSA outperforming the LEO algorithm in two tested scenarios. Based on the study results many test function results such as TF5 by recording (4.76762333) and some other test functions provided in the result section prove that LPBSA outperforms popular algorithms. This research highlights the efficacy of a hybrid approach in the ongoing evolution of optimization algorithms, showcasing the LPBSA's capacity to navigate diverse optimization landscapes and contribute significantly to addressing intricate optimization challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14759v2</guid>
      <category>cs.NE</category>
      <category>math.OC</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dana R. Hamad, Tarik A. Rashid</dc:creator>
    </item>
  </channel>
</rss>
