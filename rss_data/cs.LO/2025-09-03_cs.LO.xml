<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.LO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.LO</link>
    <description>cs.LO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.LO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 04 Sep 2025 01:31:46 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Undecidability of Linear Logics without Weakening</title>
      <link>https://arxiv.org/abs/2509.00644</link>
      <description>arXiv:2509.00644v1 Announce Type: new 
Abstract: The goal of this paper is to establish that it remains undecidable whether a sequent is provable in two systems in which a weakening rule for an exponential modality is completely omitted from classical propositional linear logic $\mathbf{CLL}$ introduced by Girard (1987), which is shown to be undecidable by Lincoln et al. (1992). We introduce two logical systems, $\mathbf{CLLR}$ and $\mathbf{CLLRR}$. The first system, $\mathbf{CLLR}$, is obtained by omitting the weakening rule for the exponential modality of $\mathbf{CLL}$. The system $\mathbf{CLLR}$ has been studied by several authors, including Meli\`es-Tabareau (2010), but its undecidability was unknown. This paper shows the undecidability of $\mathbf{CLLR}$ by reducing it to the undecidability of $\mathbf{CLL}$, where the units $\mathbf{1}$ and $\bot$ play a crucial role in simulating the weakening rule. We also omit these units from the syntax and inference rules of $\mathbf{CLLR}$ in order to define the second system, $\mathbf{CLLRR}$. The undecidability of $\mathbf{CLLRR}$ is established by showing that the system can simulate any two-counter machine proposed by Minsky (1961).</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.00644v1</guid>
      <category>cs.LO</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jun Suzuki, Katsuhiko Sano</dc:creator>
    </item>
    <item>
      <title>Formal Verification of Isothermal Chemical Reactors</title>
      <link>https://arxiv.org/abs/2509.01130</link>
      <description>arXiv:2509.01130v1 Announce Type: new 
Abstract: Chemical reactors are dynamic systems that can be described by systems of ordinary differential equations (ODEs). Reactor safety, regulatory compliance, and economics depend on whether certain states are reachable by the reactor, and are generally assessed using numerical simulation. In this work, we show how differential dynamic logic (dL), as implemented in the automated theorem prover KeYmaera X, can be used to symbolically determine reachability in isothermal chemical reactors, providing mathematical guarantees that certain conditions are satisfied (for example, that an outlet concentration never exceeds a regulatory threshold). First, we apply dL to systems whose dynamics can be solved in closed form, such as first-order reactions in batch reactors, proving that such reactors cannot exceed specified concentration limits. We extend this method to reaction models as complex as Michaelis-Menten kinetics, whose dynamics require approximations or numerical solutions. In all cases, proofs are facilitated by identification of invariants; we find that conservation of mass is both a principle proved from the ODEs describing mass action kinetics as well as a useful relationship for proving other properties. Useful invariants for continuous stirred tank reactors (CSTRs) were not found, which limited the complexity of reaction networks that could be proved with dL. While dL provides an interesting symbolic logic approach for reachability in chemical reactions, the bounds we obtained are quite broad relative to those typically achieved via numerical reachability analyses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.01130v1</guid>
      <category>cs.LO</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Parivash Feyzishendi, Sophia Hamer, Jinyu Huang, Tyler R. Josephson</dc:creator>
    </item>
    <item>
      <title>Quantum Petri Nets with Event Structure semantics</title>
      <link>https://arxiv.org/abs/2509.01423</link>
      <description>arXiv:2509.01423v1 Announce Type: new 
Abstract: Classical Petri nets provide a canonical model of concurrency, with unfolding semantics linking nets, occurrence nets, and event structures. No comparable framework exists for quantum concurrency: existing ''quantum Petri nets'' lack rigorous concurrent and sound quantum semantics, analysis tools, and unfolding theory. We introduce Quantum Petri Nets (QPNs), Petri nets equipped with a quantum valuation compatible with the quantum event structure semantics of Clairambault, De Visme, and Winskel (2019). Our contributions are: (i) a local definition of Quantum Occurrence Nets (LQONs) compatible with quantum event structures, (ii) a construction of QPNs with a well-defined unfolding semantics, (iii) a compositional framework for QPNs. This establishes a semantically well grounded model of quantum concurrency, bridging Petri net theory and quantum programming.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.01423v1</guid>
      <category>cs.LO</category>
      <category>quant-ph</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julien Saan Joachim (ENS Paris Saclay, LMF, Inria), Marc de Visme (LMF, Inria, CNRS, ENS Paris Saclay), Stefan Haar (Inria)</dc:creator>
    </item>
    <item>
      <title>TREBL -- A Relative Complete Temporal Event-B Logic. Part I: Theory</title>
      <link>https://arxiv.org/abs/2509.01462</link>
      <description>arXiv:2509.01462v1 Announce Type: new 
Abstract: The verification of liveness conditions is an important aspect of state-based rigorous methods. This article addresses the extension of the logic of Event-B to a powerful logic, in which properties of traces of an Event-B machine can be expressed. However, all formulae of this logic are still interpreted over states of an Event-B machine rather than traces. The logic exploits that for an Event-B machine $M$ a state $S$ determines all traces of $M$ starting in $S$. We identify a fragment called TREBL of this logic, in which all liveness conditions of interest can be expressed, and define a set of sound derivation rules for the fragment. We further show relative completeness of these derivation rules in the sense that for every valid entailment of a formula $\varphi$ one can find a derivation, provided the machine $M$ is sufficiently refined. The decisive property is that certain variant terms must be definable in the refined machine. We show that such refinements always exist. Throughout the article several examples from the field of security are used to illustrate the theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.01462v1</guid>
      <category>cs.LO</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Klaus-Dieter Schewe, Flavio Ferrarotti, Peter Rivi\`ere, Neeraj Kumar Singh, Guillaume Dupont, Yamine A\"it Ameur</dc:creator>
    </item>
    <item>
      <title>An Information-Flow Perspective on Explainability Requirements: Specification and Verification</title>
      <link>https://arxiv.org/abs/2509.01479</link>
      <description>arXiv:2509.01479v1 Announce Type: new 
Abstract: Explainable systems expose information about why certain observed effects are happening to the agents interacting with them. We argue that this constitutes a positive flow of information that needs to be specified, verified, and balanced against negative information flow that may, e.g., violate privacy guarantees. Since both explainability and privacy require reasoning about knowledge, we tackle these tasks with epistemic temporal logic extended with quantification over counterfactual causes. This allows us to specify that a multi-agent system exposes enough information such that agents acquire knowledge on why some effect occurred. We show how this principle can be used to specify explainability as a system-level requirement and provide an algorithm for checking finite-state models against such specifications. We present a prototype implementation of the algorithm and evaluate it on several benchmarks, illustrating how our approach distinguishes between explainable and unexplainable systems, and how it allows to pose additional privacy requirements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.01479v1</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bernd Finkbeiner, Hadar Frenkel, Julian Siber</dc:creator>
    </item>
    <item>
      <title>Derivation and Verification of Array Sorting by Merging, and its Certification in Dafny</title>
      <link>https://arxiv.org/abs/2509.01758</link>
      <description>arXiv:2509.01758v1 Announce Type: new 
Abstract: We provide full certifications of two versions of merge sort of arrays in the verification-aware programming language Dafny. We start by considering schemas for applying the divide-and-conquer or partition method of solution to specifications given by pre- and post-conditions involving linear arrays. We then derive the merge sort and merging algorithms as instances of these schemas, thereby arriving at a fully recursive formulation. Further, the analysis of the tree of subproblems arising from the partition facilitates the design of loop invariants that allow to derive a fully iterative version (sometimes called bottom-up merge sort) that does not employ a stack. We show how the use of the provided schemas conveniently conducts the formalization and actual verification in Dafny. The whole method is also applicable to deriving variants of quicksort, which we sketch.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.01758v1</guid>
      <category>cs.LO</category>
      <category>cs.DS</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Juan Pablo Carbonell, Jos\'e E. Solsona, Nora Szasz, \'Alvaro Tasistro</dc:creator>
    </item>
    <item>
      <title>Probabilistically stable revision and comparative probability: a representation theorem and applications</title>
      <link>https://arxiv.org/abs/2509.02495</link>
      <description>arXiv:2509.02495v1 Announce Type: new 
Abstract: The stability rule for belief, advocated by Leitgeb [Annals of Pure and Applied Logic 164, 2013], is a rule for rational acceptance that captures categorical belief in terms of $\textit{probabilistically stable propositions}$: propositions to which the agent assigns resiliently high credence. The stability rule generates a class of $\textit{probabilistically stable belief revision}$ operators, which capture the dynamics of belief that result from an agent updating their credences through Bayesian conditioning while complying with the stability rule for their all-or-nothing beliefs. In this paper, we prove a representation theorem that yields a complete characterisation of such probabilistically stable revision operators and provides a `qualitative' selection function semantics for the (non-monotonic) logic of probabilistically stable belief revision. Drawing on the theory of comparative probability orders, this result gives necessary and sufficient conditions for a selection function to be representable as a strongest-stable-set operator on a finite probability space. The resulting logic of probabilistically stable belief revision exhibits strong monotonicity properties while failing the AGM belief revision postulates and satisfying only very weak forms of case reasoning. In showing the main theorem, we prove two results of independent interest to the theory of comparative probability: the first provides necessary and sufficient conditions for the joint representation of a pair of (respectively, strict and non-strict) comparative probability orders. The second result provides a method for axiomatising the logic of ratio comparisons of the form ``event $A$ is at least $k$ times more likely than event $B$''. In addition to these measurement-theoretic applications, we point out two applications of our main result to the theory of simple voting games and to revealed preference theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02495v1</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <category>econ.TH</category>
      <category>math.PR</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Krzysztof Mierzewski</dc:creator>
    </item>
    <item>
      <title>Generalised M\"obius Categories and Convolution Kleene Algebras</title>
      <link>https://arxiv.org/abs/2509.00168</link>
      <description>arXiv:2509.00168v1 Announce Type: cross 
Abstract: Convolution algebras on maps from structures such as monoids, groups or categories into semirings, rings or fields abound in mathematics and the sciences. Of special interest in computing are convolution algebras based on variants of Kleene algebras, which are additively idempotent semirings equipped with a Kleene star. Yet an obstacle to the construction of convolution Kleene algebras on a wide class of structures has so far been the definition of a suitable star. We show that a generalisation of M\"obius categories combined with a generalisation of a classical definition of a star for formal power series allow such a construction. We discuss several instances of this construction on generalised M\"obius categories: convolution Kleene algebras with tests, modal convolution Kleene algebras, concurrent convolution Kleene algebras and higher convolution Kleene algebras (e.g. on strict higher categories and higher relational monoids). These are relevant to the verification of weighted and probabilistic sequential and concurrent programs, using quantitative Hoare logics or predicate transformer algebras, as well as for algebraic reasoning in higher-dimensional rewriting. We also adapt the convolution Kleene algebra construction to Conway semirings, which is widely studied in the context of weighted automata. Finally, we compare the convolution Kleene algebra construction with a previous construction of convolution quantales and present concrete example structures in preparation for future applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.00168v1</guid>
      <category>cs.FL</category>
      <category>cs.LO</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>James Cranch, Georg Struth, Jana Wagemaker</dc:creator>
    </item>
    <item>
      <title>Virtual Group Knowledge and Group Belief in Topological Evidence Models (Extended Version)</title>
      <link>https://arxiv.org/abs/2509.00184</link>
      <description>arXiv:2509.00184v1 Announce Type: cross 
Abstract: We study notions of (virtual) group knowledge and group belief within multi-agent evidence models, obtained by extending the topological semantics of evidence-based belief and fallible knowledge from individuals to groups. We completely axiomatize and show the decidability of the logic of ("hard" and "soft") group evidence, and do the same for an especially interesting fragment of it: the logic of group knowledge and group belief. We also extend these languages with dynamic evidence-sharing operators, and completely axiomatize the corresponding logics, showing that they are co-expressive with their static bases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.00184v1</guid>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <category>cs.MA</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexandru Baltag, Malvin Gattinger, Djanira Gomes</dc:creator>
    </item>
    <item>
      <title>Neuro-Symbolic Predictive Process Monitoring</title>
      <link>https://arxiv.org/abs/2509.00834</link>
      <description>arXiv:2509.00834v1 Announce Type: cross 
Abstract: This paper addresses the problem of suffix prediction in Business Process Management (BPM) by proposing a Neuro-Symbolic Predictive Process Monitoring (PPM) approach that integrates data-driven learning with temporal logic-based prior knowledge. While recent approaches leverage deep learning models for suffix prediction, they often fail to satisfy even basic logical constraints due to the absence of explicit integration of domain knowledge during training. We propose a novel method to incorporate Linear Temporal Logic over finite traces (LTLf) into the training process of autoregressive sequence predictors. Our approach introduces a differentiable logical loss function, defined using a soft approximation of LTLf semantics and the Gumbel-Softmax trick, which can be combined with standard predictive losses. This ensures the model learns to generate suffixes that are both accurate and logically consistent. Experimental evaluation on three real-world datasets shows that our method improves suffix prediction accuracy and compliance with temporal constraints. We also introduce two variants of the logic loss (local and global) and demonstrate their effectiveness under noisy and realistic settings. While developed in the context of BPM, our framework is applicable to any symbolic sequence generation task and contributes toward advancing Neuro-Symbolic AI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.00834v1</guid>
      <category>cs.AI</category>
      <category>cs.FL</category>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Axel Mezini, Elena Umili, Ivan Donadello, Fabrizio Maria Maggi, Matteo Mancanelli, Fabio Patrizi</dc:creator>
    </item>
    <item>
      <title>Traq: Estimating the Quantum Cost of Classical Programs</title>
      <link>https://arxiv.org/abs/2509.01508</link>
      <description>arXiv:2509.01508v1 Announce Type: cross 
Abstract: Predicting practical speedups offered by future quantum computers has become a major focus of the quantum computing community. Typically, these predictions are supported by lengthy manual analyses and numerical simulations and are carried out for one specific application at a time. In this paper, we present Traq, a principled approach towards estimating the quantum speedup of classical programs fully automatically and with provable guarantees. It consists of a classical language that includes high-level primitives amenable to quantum speedups, a cost analysis, and a compilation to low-level quantum programs. Our cost analysis upper bounds the complexity of the resulting quantum program in a fine-grained way: it captures non-asymptotic information and is sensitive to the input of the program (rather than providing worst-case costs). We also provide a proof-of-concept implementation and a case study inspired by AND-OR trees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.01508v1</guid>
      <category>quant-ph</category>
      <category>cs.LO</category>
      <category>cs.PL</category>
      <category>cs.SE</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anurudh Peduri, Gilles Barthe, Michael Walter</dc:creator>
    </item>
    <item>
      <title>Constrained Decoding for Robotics Foundation Models</title>
      <link>https://arxiv.org/abs/2509.01728</link>
      <description>arXiv:2509.01728v1 Announce Type: cross 
Abstract: Recent advances in the development of robotic foundation models have led to promising end-to-end and general-purpose capabilities in robotic systems. These models are pretrained on vast datasets of robot trajectories to process multi- modal inputs and directly output a sequence of action that the system then executes in the real world. Although this approach is attractive from the perspective of im- proved generalization across diverse tasks, these models are still data-driven and, therefore, lack explicit notions of behavioral correctness and safety constraints. We address these limitations by introducing a constrained decoding framework for robotics foundation models that enforces logical constraints on action trajec- tories in dynamical systems. Our method ensures that generated actions provably satisfy signal temporal logic (STL) specifications at runtime without retraining, while remaining agnostic of the underlying foundation model. We perform com- prehensive evaluation of our approach across state-of-the-art navigation founda- tion models and we show that our decoding-time interventions are useful not only for filtering unsafe actions but also for conditional action-generation. Videos available on our website: https://constrained-robot-fms.github.io</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.01728v1</guid>
      <category>cs.RO</category>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Parv Kapoor, Akila Ganlath, Changliu Liu, Sebastian Scherer, Eunsuk Kang</dc:creator>
    </item>
    <item>
      <title>Computation of Feasible Assume-Guarantee Contracts: A Resilience-based Approach</title>
      <link>https://arxiv.org/abs/2509.01832</link>
      <description>arXiv:2509.01832v1 Announce Type: cross 
Abstract: We propose a resilience-based framework for computing feasible assume-guarantee contracts that ensure the satisfaction of temporal specifications in interconnected discrete-time systems. Interconnection effects are modeled as structured disturbances. We use a resilience metric, the maximum disturbance under which local specifications hold, to refine assumptions and guarantees across subsystems iteratively. For two subsystems, we demonstrate correctness, monotone refinement of guarantees, and that the resulting assumptions are maximal within ball-shaped sets. Additionally, we extend our approach to general networks of L subsystems using weighted combinations of interconnection effects. We instantiate the framework on linear systems by meeting finite-horizon safety, exact-time reachability, and finite-time reachability specifications, and on nonlinear systems by fulfilling general finite-horizon specifications. Our approach is demonstrated through numerical linear examples, and a nonlinear DC Microgrid case study, showcasing the impact of our framework in verifying temporal logic specifications with compositional reasoning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.01832v1</guid>
      <category>eess.SY</category>
      <category>cs.LO</category>
      <category>cs.SY</category>
      <category>math.DS</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Negar Monir, Youssef Ait Si, Ratnangshu Das, Pushpak Jagtap, Adnane Saoud, Sadegh Soudjani</dc:creator>
    </item>
    <item>
      <title>DTMC Model Checking by Path Abstraction Revisited (extended version)</title>
      <link>https://arxiv.org/abs/2509.02393</link>
      <description>arXiv:2509.02393v1 Announce Type: cross 
Abstract: Computing the probability of reaching a set of goal states G in a discrete-time Markov chain (DTMC) is a core task of probabilistic model checking. We can do so by directly computing the probability mass of the set of all finite paths from the initial state to G; however, when refining counterexamples, it is also interesting to compute the probability mass of subsets of paths. This can be achieved by splitting the computation into path abstractions that calculate "local" reachability probabilities as shown by \'Abrah\'am et al. in 2010. In this paper, we complete and extend their work: We prove that splitting the computation into path abstractions indeed yields the same result as the direct approach, and that the splitting does not need to follow the SCC structure. In particular, we prove that path abstraction can be performed along any finite sequence of sets of non-goal states. Our proofs proceed in a novel way by interpreting the DTMC as a structure on the free monoid on its state space, which makes them clean and concise. Additionally, we provide a compact reference implementation of path abstraction in PARI/GP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02393v1</guid>
      <category>cs.FL</category>
      <category>cs.LO</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arnd Hartmanns, Robert Modderman</dc:creator>
    </item>
    <item>
      <title>RNN Generalization to Omega-Regular Languages</title>
      <link>https://arxiv.org/abs/2509.02491</link>
      <description>arXiv:2509.02491v1 Announce Type: cross 
Abstract: B\"uchi automata (BAs) recognize $\omega$-regular languages defined by formal specifications like linear temporal logic (LTL) and are commonly used in the verification of reactive systems. However, BAs face scalability challenges when handling and manipulating complex system behaviors. As neural networks are increasingly used to address these scalability challenges in areas like model checking, investigating their ability to generalize beyond training data becomes necessary. This work presents the first study investigating whether recurrent neural networks (RNNs) can generalize to $\omega$-regular languages derived from LTL formulas. We train RNNs on ultimately periodic $\omega$-word sequences to replicate target BA behavior and evaluate how well they generalize to out-of-distribution sequences. Through experiments on LTL formulas corresponding to deterministic automata of varying structural complexity, from 3 to over 100 states, we show that RNNs achieve high accuracy on their target $\omega$-regular languages when evaluated on sequences up to $8 \times$ longer than training examples, with $92.6\%$ of tasks achieving perfect or near-perfect generalization. These results establish the feasibility of neural approaches for learning complex $\omega$-regular languages, suggesting their potential as components in neurosymbolic verification methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02491v1</guid>
      <category>cs.LG</category>
      <category>cs.FL</category>
      <category>cs.LO</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Charles Pert, Dalal Alrajeh, Alessandra Russo</dc:creator>
    </item>
    <item>
      <title>Strategies as Resource Terms, and their Categorical Semantics</title>
      <link>https://arxiv.org/abs/2302.04685</link>
      <description>arXiv:2302.04685v5 Announce Type: replace 
Abstract: As shown by Tsukada and Ong, simply-typed, normal and eta-long resource terms correspond to plays in Hyland-Ong games, quotiented by Melli\`es' homotopy equivalence. The original proof of this inspiring result is indirect, relying on the injectivity of the relational model w.r.t. both sides of the correspondence -- in particular, the dynamics of the resource calculus is taken into account only via the compatibility of the relational model with the composition of normal terms defined by normalization.
  In the present paper, we revisit and extend these results. Our first contribution is to restate the correspondence by considering causal structures we call augmentations, which are canonical representatives of Hyland-Ong plays up to homotopy. This allows us to give a direct and explicit account of the connection with normal resource terms. As a second contribution, we extend this account to the reduction of resource terms: building on a notion of strategies as weighted sums of augmentations, we provide a denotational model of the resource calculus, invariant under reduction. A key step -- and our third contribution -- is a categorical model we call a resource category, which is to the resource calculus what differential categories are to the differential lambda-calculus.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.04685v5</guid>
      <category>cs.LO</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lison Blondeau-Patissier, Pierre Clairambault, Lionel Vaux Auclair</dc:creator>
    </item>
    <item>
      <title>Computational expressivity of (circular) proofs with fixed points</title>
      <link>https://arxiv.org/abs/2302.14825</link>
      <description>arXiv:2302.14825v3 Announce Type: replace 
Abstract: We study the computational expressivity of proof systems with fixed point operators, within the 'proofs-as-programs' paradigm. We start with a calculus muLJ (due to Clairambault) that extends intuitionistic logic by least and greatest positive fixed points. Based in the sequent calculus, muLJ admits a standard extension to a 'circular' calculus CmuLJ.
  Our main result is that, perhaps surprisingly, both muLJ and CmuLJ represent the same first-order functions: those provably total in $\Pi^1_2$-$\mathsf{CA}_0$, a subsystem of second-order arithmetic beyond the 'big five' of reverse mathematics and one of the strongest theories for which we have an ordinal analysis (due to Rathjen). This solves various questions in the literature on the computational strength of (circular) proof systems with fixed points.
  For the lower bound we give a realisability interpretation from an extension of Peano Arithmetic by fixed points that has been shown to be arithmetically equivalent to $\Pi^1_2$-$\mathsf{CA}_0$ (due to M\"ollerfeld). For the upper bound we construct a novel computability model in order to give a totality argument for circular proofs with fixed points. In fact we formalise this argument itself within $\Pi^1_2$-$\mathsf{CA}_0$ in order to obtain the tight bounds we are after. Along the way we develop some novel reverse mathematics for the Knaster-Tarski fixed point theorem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.14825v3</guid>
      <category>cs.LO</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gianluca Curzi, Anupam Das</dc:creator>
    </item>
    <item>
      <title>Terminal Coalgebras in Countably Many Steps</title>
      <link>https://arxiv.org/abs/2303.11071</link>
      <description>arXiv:2303.11071v2 Announce Type: replace 
Abstract: We present a collection of results that imply that an endofunctor on a category has a terminal object obtainable as a countable limit of its terminal-coalgebra chain. This holds for finitary endofunctors preserving nonempty binary intersections on locally finitely presentable categories, assuming that the posets of strong quotients and subobjects of finitely presentable objects satisfy the descending chain condition. This allows one to adapt finiteness arguments that were originally advanced by Worrell concerning terminal coalgebras for finitary set functors. Examples include the categories of sets, posets, vector spaces, graphs, nominal sets, and presheaves on finite sets. Worrell also described, without proof, the terminal-coalgebra chain of the finite power-set functor. We provide a detailed proof following his ideas.
  We then turn to polynomial endofunctors on the categories of Hausdorff topological spaces and metric spaces. The Vietoris space of compact subsets of a given Hausdorff space yields an endofunctor $\mathscr{V}$ on the category of Hausdorff spaces. Vietoris polynomial endofunctors on that category are built from $\mathscr{V}$, the identity and constant functors by forming products, coproducts and compositions. We present an analogous class of endofunctors on the category of extended metric spaces, using in lieu of $\mathscr{V}$ the Hausdorff functor $\mathcal{H}$. We prove that the ensuing Hausdorff polynomial functors have terminal coalgebras and initial algebras. We show that every finitary endofunctor on the category of vector spaces over a fixed field again has a terminal coalgebra obtained in $\omega+\omega$ steps. Whereas the canonical constructions of terminal coalgebras for Vietoris polynomial functors takes $\omega$ steps, one needs $\omega + \omega$ steps in general for our other concrete settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.11071v2</guid>
      <category>cs.LO</category>
      <category>math.CT</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ji\v{r}\'i Ad\'amek, Stefan Milius, Lawrence S. Moss</dc:creator>
    </item>
    <item>
      <title>Infinitary Cut-Elimination for Non-Wellfounded Parsimonious Linear Logic</title>
      <link>https://arxiv.org/abs/2308.07789</link>
      <description>arXiv:2308.07789v3 Announce Type: replace 
Abstract: We investigate non-wellfounded proof systems based on parsimonious logic, a weaker variant of linear logic where the exponential modality ! is interpreted as a constructor for streams over finite data. Logical consistency is maintained at a global level by adapting a standard progressing criterion. We present an infinitary version of cut-elimination based on finite approximations, and we prove that, in presence of the progressing criterion, it returns well-defined non-wellfounded proofs at its limit. Furthermore, we show that cut-elimination preserves the progressive criterion and various regularity conditions internalizing degrees of proof-theoretical uniformity. Finally, we provide a denotational semantics for our systems based on the relational model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.07789v3</guid>
      <category>cs.LO</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matteo Acclavio, Gianluca Curzi, Giulio Guerrieri</dc:creator>
    </item>
    <item>
      <title>Mirroring Call-by-Need, or Values Acting Silly</title>
      <link>https://arxiv.org/abs/2402.12078</link>
      <description>arXiv:2402.12078v3 Announce Type: replace 
Abstract: Call-by-need evaluation for the lambda-calculus can be seen as merging the best of call-by-name and call-by-value, namely the wise erasing behaviour of the former and the wise duplicating behaviour of the latter. To better understand how duplication and erasure can be combined, we design a degenerated calculus, dubbed call-by-silly, that is symmetric to call-by-need in that it merges the worst of call-by-name and call-by-value, namely silly duplications by-name and silly erasures by-value.
  We validate the design of the call-by-silly calculus via rewriting properties and multi types. In particular, we mirror the main theorem about call-by-need -- that is, its operational equivalence with call-by-name -- showing that call-by-silly and call-by-value induce the same contextual equivalence. This fact shows the blindness with respect to efficiency of call-by-value contextual equivalence. We also define a call-by-silly strategy and a call-by-silly abstract machine implementing the strategy. Moreover, we measure the number of steps taken by the strategy via tight multi types. Lastly, we prove that the call-by-silly strategy computes evaluation sequences of maximal length in the calculus.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.12078v3</guid>
      <category>cs.LO</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Beniamino Accattoli, Adrienne Lancelot</dc:creator>
    </item>
    <item>
      <title>A Strongly Normalising System of Dependent Types for Transparent and Opaque Probabilistic Computation</title>
      <link>https://arxiv.org/abs/2406.17082</link>
      <description>arXiv:2406.17082v3 Announce Type: replace 
Abstract: We define an extension of lambda-calculus with dependents types that enables us to encode transparent and opaque probabilistic programs and prove a strong normalisation result for it by a reducibility technique. While transparent nondeterministic programs are formalised by rather usual techniques, opaque nondeterministic programs are formalised by introducing in the syntax oracle constants, the behaviour of which is governed by oracular functions. The generality of these functions and the fact that their values are determined by the form of the whole term inside which the relative oracle occurs also enable us to simulate learning-like behaviours. We then extend the calculus in order to define a computational trustworthiness predicate. The extension of the calculus does not only enable us to precisely formalise a notion of trustworthiness and to encode the procedures required to test it on programs, but also to reason, by means of the type system, on the behaviour of programs with respect to trustworthiness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17082v3</guid>
      <category>cs.LO</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Francesco A. Genco</dc:creator>
    </item>
    <item>
      <title>The Complexity of Data-Free Nfer</title>
      <link>https://arxiv.org/abs/2407.03155</link>
      <description>arXiv:2407.03155v3 Announce Type: replace 
Abstract: Nfer is a Runtime Verification language for the analysis of event traces that applies rules to create hierarchies of time intervals. This work examines the complexity of the evaluation and satisfiability problems for the data-free fragment of nfer. The evaluation problem asks whether a given interval is generated by applying rules to a known input, while the satisfiability problem asks if an input exists that will generate a given interval. By excluding data from the language, we obtain polynomial-time algorithms for the evaluation problem and for satisfiability when only considering inclusive rules. Furthermore, we show decidability for the satisfiability problem for cycle-free specifications with a NExpTime lower bound and undecidability for satisfiability of full data-free nfer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03155v3</guid>
      <category>cs.LO</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-031-74234-7_11</arxiv:DOI>
      <dc:creator>Sean Kauffman, Kim Guldstrand Larsen, Martin Zimmermann</dc:creator>
    </item>
    <item>
      <title>The Size-Change Principle for Mixed Inductive and Coinductive types</title>
      <link>https://arxiv.org/abs/2407.05715</link>
      <description>arXiv:2407.05715v4 Announce Type: replace 
Abstract: This paper shows how to use Lee, Jones and Ben Amram's size-change principle to check correctness of arbitrary recursive definitions in an ML / Haskell like programming language with inductive and coinductive types. Naively using the size-change principle to check productivity and termination is straightforward but unsound when inductive and coinductive types are nested. We can however adapt the size-change principle to check ``totality'', which corresponds exactly to correctness with respect to the corresponding (co)inductive type.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05715v4</guid>
      <category>cs.LO</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pierre Hyvernat</dc:creator>
    </item>
    <item>
      <title>Continuous and algebraic domains in univalent foundations</title>
      <link>https://arxiv.org/abs/2407.06956</link>
      <description>arXiv:2407.06956v5 Announce Type: replace 
Abstract: We develop the theory of continuous and algebraic domains in constructive and predicative univalent foundations, building upon our earlier work on basic domain theory in this setting. That we work predicatively means that we do not assume Voevodsky's propositional resizing axioms. Our work is constructive in the sense that we do not rely on excluded middle or the axiom of (countable) choice. To deal with size issues and give a predicatively suitable definition of continuity of a dcpo, we follow Johnstone and Joyal's work on continuous categories. Adhering to the univalent perspective, we explicitly distinguish between data and property. To ensure that being continuous is a property of a dcpo, we turn to the propositional truncation, although we explain that some care is needed to avoid needing the axiom of choice. We also adapt the notion of a domain-theoretic basis to the predicative setting by imposing suitable smallness conditions, analogous to the categorical concept of an accessible category. All our running examples of continuous dcpos are then actually examples of dcpos with small bases which we show to be well behaved predicatively. In particular, such dcpos are exactly those presented by small ideals. As an application of the theory, we show that Scott's $D_\infty$ model of the untyped $\lambda$-calculus is an example of an algebraic dcpo with a small basis. Our work is formalised in the Agda proof assistant and its ability to infer universe levels has been invaluable for our purposes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06956v5</guid>
      <category>cs.LO</category>
      <category>math.LO</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.jpaa.2025.108072</arxiv:DOI>
      <dc:creator>Tom de Jong, Mart\'in H\"otzel Escard\'o</dc:creator>
    </item>
    <item>
      <title>IMALL with a Mixed-State Modality: A Logical Approach to Quantum Computation</title>
      <link>https://arxiv.org/abs/2506.09545</link>
      <description>arXiv:2506.09545v2 Announce Type: replace 
Abstract: We introduce a proof language for Intuitionistic Multiplicative Additive Linear Logic (IMALL), extended with a modality B to capture mixed-state quantum computation. The language supports algebraic constructs such as linear combinations, and embeds pure quantum computations within a mixed-state framework via B, interpreted categorically as a functor from a category of Hilbert Spaces to a category of finite-dimensional C*-algebras. Measurement arises as a definable term, not as a constant, and the system avoids the use of quantum configurations, which are part of the theory of the quantum lambda calculus. Cut-elimination is defined via a composite reduction relation, and shown to be sound with respect to the denotational interpretation. We prove n that any linear map on C 2 can be represented within the system, and illustrate this expressiveness with examples such as quantum teleportation and the quantum switch.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09545v2</guid>
      <category>cs.LO</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kinnari Dave, Alejandro D\'iaz-Caro, Vladimir Zamdzhiev</dc:creator>
    </item>
    <item>
      <title>Model-theoretic Forcing in Transition Algebra</title>
      <link>https://arxiv.org/abs/2506.22828</link>
      <description>arXiv:2506.22828v3 Announce Type: replace 
Abstract: We study L\"owenheim-Skolem and Omitting Types theorems in Transition Algebra, a logical system obtained by enhancing many sorted first-order logic with features from dynamic logic. The sentences we consider include compositions, unions, and transitive closures of transition relations, which are treated similarly to actions in dynamic logics to define necessity and possibility operators. We show that Upward L\"owenheim-Skolem theorem, any form of compactness, and joint Robinson consistency property fail due to the expressivity of transitive closures of transitions. In this non-compact many-sorted logical system, we develop a forcing technique method by generalizing the classical method of forcing used by Keisler to prove Omitting Types theorem. Instead of working within a single signature, we work with a directed diagram of signatures, which allows us to establish Downward L\"owenheim-Skolem and Omitting Types theorems despite the fact that models interpret sorts as sets, possibly empty. Building on a complete system of proof rules for Transition Algebra, we extend it with additional proof rules to reason about constructor-based and/or finite transition algebras. We then establish the completeness of this extended system for a fragment of Transition Algebra obtained by restricting models to constructor-based and/or finite transition algebras.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22828v3</guid>
      <category>cs.LO</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.4230/LIPIcs.MFCS.2025.55</arxiv:DOI>
      <dc:creator>Go Hashimoto, Daniel G\u{a}in\u{a}</dc:creator>
    </item>
    <item>
      <title>A SHACL-based Data Consistency Solution for Contract Compliance Verification (Extended Paper)</title>
      <link>https://arxiv.org/abs/2507.15420</link>
      <description>arXiv:2507.15420v4 Announce Type: replace 
Abstract: In recent years, there have been many developments for GDPR-compliant data access and sharing based on consent. For more complex data sharing scenarios, where consent might not be sufficient, many parties rely on contracts. Before a contract is signed, it must undergo the process of contract negotiation within the contract lifecycle, which consists of negotiating the obligations associated with the contract. Contract compliance verification (CCV) provides a means to verify whether a contract is GDPR-compliant, i.e., adheres to legal obligations and there are no violations. The rise of knowledge graph (KG) adoption, enabling semantic interoperability using well-defined semantics, allows CCV to be applied on KGs. In the scenario of different participants negotiating obligations, there is a need for data consistency to ensure that CCV is done correctly. Recent work introduced the automated contracting tool (ACT), a KG-based and ODRL-employing tool for GDPR CCV, which was developed in the Horizon 2020 project smashHit (https://smashhit.eu). Although the tool reports violations with respect to obligations, it had limitations in verifying and ensuring compliance, as it did not use an interoperable semantic formalism, such as SHACL, and did not support users in resolving data inconsistencies. In this work, we propose a novel approach to overcome these limitations of ACT. We semi-automatically resolve CCV inconsistencies by providing repair strategies, which automatically propose (optimal) solutions to the user to re-establish data consistency and thereby support them in managing GDPR-compliant contract lifecycle data. We have implemented the approach, integrated it into ACT and tested its correctness and performance against basic CCV consistency requirements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.15420v4</guid>
      <category>cs.LO</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Robert David, Albin Ahmeti, Geni Bushati, Amar Tauqeer, Anna Fensel</dc:creator>
    </item>
    <item>
      <title>An Information-Flow Perspective on Algorithmic Fairness</title>
      <link>https://arxiv.org/abs/2312.10128</link>
      <description>arXiv:2312.10128v2 Announce Type: replace-cross 
Abstract: This work presents insights gained by investigating the relationship between algorithmic fairness and the concept of secure information flow. The problem of enforcing secure information flow is well-studied in the context of information security: If secret information may "flow" through an algorithm or program in such a way that it can influence the program's output, then that is considered insecure information flow as attackers could potentially observe (parts of) the secret.
  There is a strong correspondence between secure information flow and algorithmic fairness: if protected attributes such as race, gender, or age are treated as secret program inputs, then secure information flow means that these ``secret'' attributes cannot influence the result of a program. While most research in algorithmic fairness evaluation concentrates on studying the impact of algorithms (often treating the algorithm as a black-box), the concepts derived from information flow can be used both for the analysis of disparate treatment as well as disparate impact w.r.t. a structural causal model.
  In this paper, we examine the relationship between quantitative as well as qualitative information-flow properties and fairness. Moreover, based on this duality, we derive a new quantitative notion of fairness called fairness spread, which can be easily analyzed using quantitative information flow and which strongly relates to counterfactual fairness. We demonstrate that off-the-shelf tools for information-flow properties can be used in order to formally analyze a program's algorithmic fairness properties, including the new notion of fairness spread as well as established notions such as demographic parity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.10128v2</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Samuel Teuber, Bernhard Beckert</dc:creator>
    </item>
    <item>
      <title>An algebraic proof of the dichotomy for graph orientation problems with forbidden tournaments</title>
      <link>https://arxiv.org/abs/2405.20263</link>
      <description>arXiv:2405.20263v3 Announce Type: replace-cross 
Abstract: For a set F of finite tournaments, the F-free orientation problem is the problem of deciding if a given finite undirected graph can be oriented in such a way that the resulting oriented graph does not contain any member of F. Using the theory of smooth approximations, we give a new shorter proof of the complexity dichotomy for such problems obtained recently by Bodirsky and Guzm\'{a}n-Pro. In fact, our approach yields a complexity dichotomy for a considerably larger class of computational problems where one is given an undirected graph along with additional local constraints on the allowed orientations. Moreover, the border between tractable and hard problems is also described by a decidable algebraic condition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20263v3</guid>
      <category>math.CO</category>
      <category>cs.CC</category>
      <category>cs.LO</category>
      <category>math.RA</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roman Feller, Michael Pinsker</dc:creator>
    </item>
    <item>
      <title>A Practical Quantum Hoare Logic with Classical Variables, I</title>
      <link>https://arxiv.org/abs/2412.09869</link>
      <description>arXiv:2412.09869v3 Announce Type: replace-cross 
Abstract: In this paper, we present a Hoare-style logic for reasoning about quantum programs with classical variables. Our approach offers several improvements over previous work:
  (1) Enhanced expressivity of the programming language: Our logic applies to quantum programs with classical variables that incorporate quantum arrays and parameterised quantum gates, which have not been addressed in previous research on quantum Hoare logic, either with or without classical variables.
  (2) Intuitive correctness specifications: In our logic, preconditions and postconditions for quantum programs with classical variables are specified as a pair consisting of a classical first-order logical formula and a quantum predicate formula (possibly parameterised by classical variables). These specifications offer greater clarity and align more closely with the programmer's intuitive understanding of quantum and classical interactions.
  (3) Simplified proof system: By introducing a novel idea in formulating a proof rule for reasoning about quantum measurements, along with (2), we develop a proof system for quantum programs that requires only minimal modifications to classical Hoare logic. Furthermore, this proof system can be effectively and conveniently combined with classical first-order logic to verify quantum programs with classical variables.
  As a result, the learning curve for quantum program verification techniques is significantly reduced for those already familiar with classical program verification techniques, and existing tools for verifying classical programs can be more easily adapted for quantum program verification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09869v3</guid>
      <category>cs.PL</category>
      <category>cs.LO</category>
      <category>quant-ph</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mingsheng Ying</dc:creator>
    </item>
    <item>
      <title>Token Assorted: Mixing Latent and Text Tokens for Improved Language Model Reasoning</title>
      <link>https://arxiv.org/abs/2502.03275</link>
      <description>arXiv:2502.03275v2 Announce Type: replace-cross 
Abstract: Large Language Models (LLMs) excel at reasoning and planning when trained on chainof-thought (CoT) data, where the step-by-step thought process is explicitly outlined by text tokens. However, this results in lengthy inputs where many words support textual coherence rather than core reasoning information, and processing these inputs consumes substantial computation resources. In this work, we propose a hybrid representation of the reasoning process, where we partially abstract away the initial reasoning steps using latent discrete tokens generated by VQ-VAE, significantly reducing the length of reasoning traces. We explore the use of latent trace abstractions in two scenarios: 1) training the model from scratch for the Keys-Finding Maze problem, 2) fine-tuning LLMs on this hybrid data with an extended vocabulary including unseen latent tokens, for both logical and mathematical reasoning problems. To facilitate effective learning, we introduce a simple training procedure that randomly mixes latent and text tokens, which enables fast adaptation to new latent tokens. Our approach consistently outperforms the baselines methods in various benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03275v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>DiJia Su, Hanlin Zhu, Yingchen Xu, Jiantao Jiao, Yuandong Tian, Qinqing Zheng</dc:creator>
    </item>
    <item>
      <title>Three Fundamental Questions in Modern Infinite-Domain Constraint Satisfaction</title>
      <link>https://arxiv.org/abs/2502.06621</link>
      <description>arXiv:2502.06621v3 Announce Type: replace-cross 
Abstract: The Feder-Vardi dichotomy conjecture for Constraint Satisfaction Problems (CSPs) with finite templates, confirmed independently by Bulatov and Zhuk, has an extension to certain well-behaved infinite templates due to Bodirsky and Pinsker which remains wide open. We provide answers to three fundamental questions on the scope of the Bodirsky-Pinsker conjecture. Our first two main results provide two simplifications of this scope, one of structural, and the other one of algebraic nature. The former simplification implies that the conjecture is equivalent to its restriction to templates without algebraicity, a crucial assumption in the most powerful classification methods. The latter yields that the higher-arity invariants of any template within its scope can be assumed to be essentially injective, and any algebraic condition characterizing any complexity class within the conjecture closed under Datalog reductions must be satisfiable by injections, thus lifting the mystery of the better applicability of certain conditions over others. Our third main result uses the first one to show that any non-trivially tractable template within the scope serves, up to a Datalog-computable modification of it, as the witness of the tractability of a non-finitely tractable finite-domain Promise Constraint Satisfaction Problem (PCSP) by the so-called sandwich method. This generalizes a recent result of Mottet and provides a strong hitherto unknown connection between the Bodirsky-Pinsker conjecture and finite-domain PCSPs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06621v3</guid>
      <category>math.LO</category>
      <category>cs.LO</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Pinsker, Jakub Rydval, Moritz Sch\"obi, Christoph Spiess</dc:creator>
    </item>
    <item>
      <title>Lemmanaid: Neuro-Symbolic Lemma Conjecturing</title>
      <link>https://arxiv.org/abs/2504.04942</link>
      <description>arXiv:2504.04942v4 Announce Type: replace-cross 
Abstract: Automatically conjecturing useful, interesting and novel lemmas would greatly improve automated reasoning tools and lower the bar for formalizing mathematics in proof assistants. It is however a very challenging task for both neural and symbolic approaches. We present the first steps towards a practical neuro-symbolic lemma conjecturing tool, Lemmanaid, that combines Large Language Models (LLMs) and symbolic methods, and evaluate it on proof libraries for the Isabelle proof assistant. We train an LLM to generate lemma templates that describe the shape of a lemma, and use symbolic methods to fill in the details. We compare Lemmanaid against an LLM trained to generate complete lemma statements as well as previous fully symbolic conjecturing methods. Lemmanaid outperforms both neural and symbolic methods on test sets from Isabelle's HOL library and from its Archive of Formal Proofs, discovering between 29-39.5% of the gold standard human written lemmas. This is 8-15% more lemmas than the neural-only method. By leveraging the best of both symbolic and neural methods we can generate useful lemmas for a wide range of input domains, facilitating computer-assisted theory development and formalization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04942v4</guid>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yousef Alhessi, S\'olr\'un Halla Einarsd\'ottir, George Granberry, Emily First, Moa Johansson, Sorin Lerner, Nicholas Smallbone</dc:creator>
    </item>
  </channel>
</rss>
