<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 07 Aug 2024 04:00:09 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 07 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Faster and simpler online/sliding rightmost Lempel-Ziv factorizations</title>
      <link>https://arxiv.org/abs/2408.03008</link>
      <description>arXiv:2408.03008v1 Announce Type: new 
Abstract: We tackle the problems of computing the rightmost variant of the Lempel-Ziv factorizations in the online/sliding model. Previous best bounds for this problem are O(n log n) time with O(n) space, due to Amir et al. [IPL 2002] for the online model, and due to Larsson [CPM 2014] for the sliding model. In this paper, we present faster O(n log n/log log n)-time solutions to both of the online/sliding models. Our algorithms are built on a simple data structure named BP-linked trees, and on a slightly improved version of the range minimum/maximum query (RmQ/RMQ) data structure on a dynamic list of integers. We also present other applications of our algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.03008v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wataru Sumiyoshi, Takuya Mieno, Shunsuke Inenaga</dc:creator>
    </item>
    <item>
      <title>Moderate Dimension Reduction for $k$-Center Clustering</title>
      <link>https://arxiv.org/abs/2312.01391</link>
      <description>arXiv:2312.01391v4 Announce Type: replace 
Abstract: The Johnson-Lindenstrauss (JL) Lemma introduced the concept of dimension reduction via a random linear map, which has become a fundamental technique in many computational settings. For a set of $n$ points in $\mathbb{R}^d$ and any fixed $\epsilon&gt;0$, it reduces the dimension $d$ to $O(\log n)$ while preserving, with high probability, all the pairwise Euclidean distances within factor $1+\epsilon$. Perhaps surprisingly, the target dimension can be lower if one only wishes to preserve the optimal value of a certain problem on the pointset, e.g., Euclidean max-cut or $k$-means. However, for some notorious problems, like diameter (aka furthest pair), dimension reduction via the JL map to below $O(\log n)$ does not preserve the optimal value within factor $1+\epsilon$.
  We propose to focus on another regime, of \emph{moderate dimension reduction}, where a problem's value is preserved within factor $\alpha&gt;1$ using target dimension $\tfrac{\log n}{poly(\alpha)}$. We establish the viability of this approach and show that the famous $k$-center problem is $\alpha$-approximated when reducing to dimension $O(\tfrac{\log n}{\alpha^2}+\log k)$. Along the way, we address the diameter problem via the special case $k=1$. Our result extends to several important variants of $k$-center (with outliers, capacities, or fairness constraints), and the bound improves further with the input's doubling dimension.
  While our $poly(\alpha)$-factor improvement in the dimension may seem small, it actually has significant implications for streaming algorithms, and easily yields an algorithm for $k$-center in dynamic geometric streams, that achieves $O(\alpha)$-approximation using space $poly(kdn^{1/\alpha^2})$. This is the first algorithm to beat $O(n)$ space in high dimension $d$, as all previous algorithms require space at least $\exp(d)$. Furthermore, it extends to the $k$-center variants mentioned above.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.01391v4</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4230/LIPIcs.SoCG.2024.64</arxiv:DOI>
      <dc:creator>Shaofeng H. -C. Jiang, Robert Krauthgamer, Shay Sapir</dc:creator>
    </item>
    <item>
      <title>Locally Stationary Distributions: A Framework for Analyzing Slow-Mixing Markov Chains</title>
      <link>https://arxiv.org/abs/2405.20849</link>
      <description>arXiv:2405.20849v2 Announce Type: replace 
Abstract: Many natural Markov chains fail to mix to their stationary distribution in polynomially many steps. Often, this slow mixing is inevitable since it is computationally intractable to sample from their stationary measure.
  Nevertheless, Markov chains can be shown to always converge quickly to measures that are locally stationary, i.e., measures that don't change over a small number of steps. These locally stationary measures are analogous to local minima in continuous optimization, while stationary measures correspond to global minima.
  While locally stationary measures can be statistically far from stationary measures, do they enjoy provable theoretical guarantees that have algorithmic implications? We study this question in this work and demonstrate three algorithmic applications of locally stationary measures:
  1. We show that Glauber dynamics on the hardcore model can be used to find independent sets of size $\Omega\left(\frac{\log d}{d} \cdot n\right)$ in triangle-free graphs of degree at most $d$.
  2. Let $W$ be a symmetric real matrix with bounded spectral diameter and $v$ be a unit vector. Given the matrix $M = \lambda vv^\top + W$ with a planted rank-one spike along vector $v$, for sufficiently large constant $\lambda$, Glauber dynamics on the Ising model defined by $M$ samples vectors $x \in \{\pm 1\}^n$ that have constant correlation with the vector $v$.
  3. Let $M = A_{\mathbf{G}} - \frac{d}{n}\mathbf{1}\mathbf{1}^\top$ be a centered version of the adjacency matrix where the graph $\mathbf{G}$ is drawn from a sparse 2-community stochastic block model. We show that for sufficiently large constant signal-to-noise ratio, Glauber dynamics on the Ising model defined by $M$ samples vectors $x \in \{\pm 1\}^n$ that have constant correlation with the hidden community vector $\mathbf{\sigma}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20849v2</guid>
      <category>cs.DS</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kuikui Liu, Sidhanth Mohanty, Prasad Raghavendra, Amit Rajaraman, David X. Wu</dc:creator>
    </item>
    <item>
      <title>Fast Mixing in Sparse Random Ising Models</title>
      <link>https://arxiv.org/abs/2405.06616</link>
      <description>arXiv:2405.06616v2 Announce Type: replace-cross 
Abstract: Motivated by the community detection problem in Bayesian inference, as well as the recent explosion of interest in spin glasses from statistical physics, we study the classical Glauber dynamics for sampling from Ising models with sparse random interactions. It is now well-known that when the interaction matrix has spectral diameter less than $1$, Glauber dynamics mixes in $O(n\log n)$ steps. Unfortunately, such criteria fail dramatically for interactions supported on arguably the most well-studied sparse random graph: the Erd\H{o}s--R\'{e}nyi random graph $G(n,d/n)$, due to the presence of almost linearly many outlier eigenvalues of unbounded magnitude.
  We prove that for the \emph{Viana--Bray spin glass}, where the interactions are supported on $G(n,d/n)$ and randomly assigned $\pm\beta$, Glauber dynamics mixes in $n^{1+o(1)}$ time with high probability as long as $\beta \le O(1/\sqrt{d})$, independent of $n$. We further extend our results to random graphs drawn according to the $2$-community stochastic block model, as well as when the interactions are given by a "centered" version of the adjacency matrix. The latter setting is particularly relevant for the inference problem in community detection. Indeed, we use this to show that Glauber dynamics succeeds at recovering communities in the stochastic block model in a companion paper [LMR+24].
  The primary technical ingredient in our proof is showing that with high probability, a sparse random graph can be decomposed into two parts -- a \emph{bulk} which behaves like a graph with bounded maximum degree and a well-behaved spectrum, and a \emph{near-forest} with favorable pseudorandom properties. We then use this decomposition to design a localization procedure that interpolates to simpler Ising models supported only on the near-forest, and then execute a pathwise analysis to establish a modified log-Sobolev inequality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06616v2</guid>
      <category>math.PR</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kuikui Liu, Sidhanth Mohanty, Amit Rajaraman, David X. Wu</dc:creator>
    </item>
    <item>
      <title>On the Low-Temperature MCMC threshold: the cases of sparse tensor PCA, sparse regression, and a geometric rule</title>
      <link>https://arxiv.org/abs/2408.00746</link>
      <description>arXiv:2408.00746v2 Announce Type: replace-cross 
Abstract: Over the last years, there has been a significant amount of work studying the power of specific classes of computationally efficient estimators for multiple statistical parametric estimation tasks, including the estimators classes of low-degree polynomials, spectral methods, and others. Despite that, our understanding of the important class of MCMC methods remains quite poorly understood. For instance, for many models of interest, the performance of even zero-temperature (greedy-like) MCMC methods that simply maximize the posterior remains elusive.
  In this work, we provide an easy to check condition under which the low-temperature Metropolis chain maximizes the posterior in polynomial-time with high probability. The result is generally applicable, and in this work, we use it to derive positive MCMC results for two classical sparse estimation tasks: the sparse tensor PCA model and sparse regression. Interestingly, in both cases, we also leverage the Overlap Gap Property framework for inference (Gamarnik, Zadik AoS '22) to prove that our results are tight: no low-temperature local MCMC method can achieve better performance. In particular, our work identifies the "low-temperature (local) MCMC threshold" for both sparse models. Interestingly, in the sparse tensor PCA model our results indicate that low-temperature local MCMC methods significantly underperform compared to other studied time-efficient methods, such as the class of low-degree polynomials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.00746v2</guid>
      <category>math.ST</category>
      <category>cs.DS</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zongchen Chen, Conor Sheehan, Ilias Zadik</dc:creator>
    </item>
    <item>
      <title>Fast Estimation of Percolation Centrality</title>
      <link>https://arxiv.org/abs/2408.02389</link>
      <description>arXiv:2408.02389v2 Announce Type: replace-cross 
Abstract: In this work, we present a new algorithm to approximate the percolation centrality of every node in a graph. Such a centrality measure quantifies the importance of the vertices in a network during a contagious process. In this paper, we present a randomized approximation algorithm that can compute probabilistically guaranteed high-quality percolation centrality estimates, generalizing techniques used by Pellegrina and Vandin (TKDD 2024) for the betweenness centrality. The estimation obtained by our algorithm is within $\varepsilon$ of the value with probability at least $1-\delta$, for fixed constants $\varepsilon,\delta \in (0,1)$. We our theoretical results with an extensive experimental analysis on several real-world networks and provide empirical evidence that our algorithm improves the current state of the art in speed, and sample size while maintaining high accuracy of the percolation centrality estimates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02389v2</guid>
      <category>cs.SI</category>
      <category>cs.DS</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Antonio Cruciani</dc:creator>
    </item>
  </channel>
</rss>
