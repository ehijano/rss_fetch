<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.comp-ph updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.comp-ph</link>
    <description>physics.comp-ph updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.comp-ph" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 29 Sep 2025 04:00:09 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Fracture-Driven Single Bubble Grows and Migration Model in Aquatic Muds</title>
      <link>https://arxiv.org/abs/2509.22439</link>
      <description>arXiv:2509.22439v1 Announce Type: new 
Abstract: Methane (CH$_4$) is the most prevalent hydrocarbon and a significant greenhouse gas found in the atmosphere. Buoyancy-driven CH$_4$ bubble growth and migration within muddy aquatic sediments are closely associated with sediment fracturing. This paper presents a model of buoyancy-driven CH$_4$ single bubble growth in fine-grained cohesive (muddy) aquatic sediment. * Solid mechanics model component simulates bubble elastic expansion caused by solute supply from the surrounding mud, followed by differential fracturing of the mud by the evolving bubble front, a process governed by the principles of Linear Elastic Fracture Mechanics (LEFM). This differential fracturing controls the evolving shape and size of the bubble. * The model integrates the LEFM with the dynamics of solute exchange between the bubble and the surrounding mud, alongside the conservation of CH$_4$ gas within the bubble. * An advanced meshing strategy allows balancing between the geometry resolution and the amount of mesh elements, thereby optimizing for both solution accuracy and computational efficiency. This model is intended to be a foundational tool for proper upscaling of single bubble characteristics to effective gassy medium theories. This will enhance the accuracy of the acoustic applications and could contribute to evaluation of overall CH$_4$ emission from the aquatic muds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22439v1</guid>
      <category>physics.comp-ph</category>
      <category>physics.chem-ph</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:journal_reference>Structural Geology (2015), 70: 56-64; Earth-Science reviews (2024), 257: 104908</arxiv:journal_reference>
      <dc:creator>Regina Katsman</dc:creator>
    </item>
    <item>
      <title>Dimer-driven multiple reentrant localization with composite potential</title>
      <link>https://arxiv.org/abs/2509.21338</link>
      <description>arXiv:2509.21338v1 Announce Type: cross 
Abstract: Recent studies have revealed reentrant localization transitions in quasi-periodic one-dimensional lattices, where the competition between dimerized hopping and staggered disorder plays a central role. Yet the extent to which such reentrant localization persists under more general conditions, such as additional periodic potentials, modified quasi-periodic modulations remains unclear. Here we investigate localization phenomena in a one-dimensional lattice subject to a periodic potential and an additional quasi-periodic modulation. Using both eigenstate-based indicators and experimentally accessible dynamical observables, we identify robust reentrant, or multiple, localization transitions. We show that these transitions are uniquely stabilized by the dimer structure of the unit cell, where the competition between the onsite periodic potential and the quasi-periodic modulation becomes most pronounced. By systematically varying the periodicity parameter $\alpha$ and the quasi-periodic frequency $\beta$, we find that the robust multiple reentrant localization behavior disappears for any deviation from the dimer configuration, confirming its essential role. Our results suggest that the interplay between these competing factors drives the multiple reentrant localization transitions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21338v1</guid>
      <category>cond-mat.dis-nn</category>
      <category>physics.comp-ph</category>
      <category>quant-ph</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pei-Jie Chang, Dong Ruan, Gui-Lu Long</dc:creator>
    </item>
    <item>
      <title>Redesigning GROMACS Halo Exchange: Improving Strong Scaling with GPU-initiated NVSHMEM</title>
      <link>https://arxiv.org/abs/2509.21527</link>
      <description>arXiv:2509.21527v1 Announce Type: cross 
Abstract: Improving time-to-solution in molecular dynamics simulations often requires strong scaling due to fixed-sized problems. GROMACS is highly latency-sensitive, with peak iteration rates in the sub-millisecond, making scalability on heterogeneous supercomputers challenging. MPI's CPU-centric nature introduces additional latencies on GPU-resident applications' critical path, hindering GPU utilization and scalability. To address these limitations, we present an NVSHMEM-based GPU kernel-initiated redesign of the GROMACS domain decomposition halo-exchange algorithm. Highly tuned GPU kernels fuse data packing and communication, leveraging hardware latency-hiding for fine-grained overlap. We employ kernel fusion across overlapped data forwarding communication phases and utilize the asynchronous copy engine over NVLink to optimize latency and bandwidth. Our GPU-resident formulation greatly increases communication-computation overlap, improving GROMACS strong scaling performance across NVLink by up to 1.5x (intra-node) and 2x (multi-node), and up to 1.3x multi-node over NVLink+InfiniBand. This demonstrates the profound benefits of GPU-initiated communication for strong-scaling a broad range of latency-sensitive applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21527v1</guid>
      <category>cs.DC</category>
      <category>cs.PF</category>
      <category>physics.comp-ph</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3731599.3767508</arxiv:DOI>
      <dc:creator>Mahesh Doijade, Andrey Alekseenko, Ania Brown, Alan Gray, Szil\'ard P\'all</dc:creator>
    </item>
    <item>
      <title>Shoot from the HIP: Hessian Interatomic Potentials without derivatives</title>
      <link>https://arxiv.org/abs/2509.21624</link>
      <description>arXiv:2509.21624v1 Announce Type: cross 
Abstract: Fundamental tasks in computational chemistry, from transition state search to vibrational analysis, rely on molecular Hessians, which are the second derivatives of the potential energy. Yet, Hessians are computationally expensive to calculate and scale poorly with system size, with both quantum mechanical methods and neural networks. In this work, we demonstrate that Hessians can be predicted directly from a deep learning model, without relying on automatic differentiation or finite differences. We observe that one can construct SE(3)-equivariant, symmetric Hessians from irreducible representations (irrep) features up to degree $l$=2 computed during message passing in graph neural networks. This makes HIP Hessians one to two orders of magnitude faster, more accurate, more memory efficient, easier to train, and enables more favorable scaling with system size. We validate our predictions across a wide range of downstream tasks, demonstrating consistently superior performance for transition state search, accelerated geometry optimization, zero-point energy corrections, and vibrational analysis benchmarks. We open-source the HIP codebase and model weights to enable further development of the direct prediction of Hessians at https://github.com/BurgerAndreas/hip</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21624v1</guid>
      <category>cs.LG</category>
      <category>physics.chem-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Andreas Burger, Luca Thiede, Nikolaj R{\o}nne, Varinia Bernales, Nandita Vijaykumar, Tejs Vegge, Arghya Bhowmik, Alan Aspuru-Guzik</dc:creator>
    </item>
    <item>
      <title>MORPH: Shape-agnostic PDE Foundation Models</title>
      <link>https://arxiv.org/abs/2509.21670</link>
      <description>arXiv:2509.21670v1 Announce Type: cross 
Abstract: We introduce MORPH, a shape-agnostic, autoregressive foundation model for partial differential equations (PDEs). MORPH is built on a convolutional vision transformer backbone that seamlessly handles heterogeneous spatiotemporal datasets of varying data dimensionality (1D--3D) at different resolutions, multiple fields with mixed scalar and vector components. The architecture combines (i) component-wise convolution, which jointly processes scalar and vector channels to capture local interactions, (ii) inter-field cross-attention, which models and selectively propagates information between different physical fields, (iii) axial attentions, which factorizes full spatiotemporal self-attention along individual spatial and temporal axes to reduce computational burden while retaining expressivity. We pretrain multiple model variants on a diverse collection of heterogeneous PDE datasets and evaluate transfer to a range of downstream prediction tasks. Using both full-model fine-tuning and parameter-efficient low-rank adapters (LoRA), MORPH outperforms models trained from scratch in both zero-shot and full-shot generalization. Across extensive evaluations, MORPH matches or surpasses strong baselines and recent state-of-the-art models. Collectively, these capabilities present a flexible and powerful backbone for learning from heterogeneous and multimodal nature of scientific observations, charting a path toward scalable and data-efficient scientific machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21670v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>physics.comp-ph</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mahindra Singh Rautela, Alexander Most, Siddharth Mansingh, Bradley C. Love, Ayan Biswas, Diane Oyen, Earl Lawrence</dc:creator>
    </item>
    <item>
      <title>Reparameterizing 4DVAR with neural fields</title>
      <link>https://arxiv.org/abs/2509.21751</link>
      <description>arXiv:2509.21751v1 Announce Type: cross 
Abstract: Four-dimensional variational data assimilation (4DVAR) is a cornerstone of numerical weather prediction, but its cost function is difficult to optimize and computationally intensive. We propose a neural field-based reformulation in which the full spatiotemporal state is represented as a continuous function parameterized by a neural network. This reparameterization removes the time-sequential dependency of classical 4DVAR, enabling parallel-in-time optimization in parameter space. Physical constraints are incorporated directly through a physics-informed loss, simplifying implementation and reducing computational cost. We evaluate the method on the two-dimensional incompressible Navier--Stokes equations with Kolmogorov forcing. Compared to a baseline 4DVAR implementation, the neural reparameterized variants produce more stable initial condition estimates without spurious oscillations. Notably, unlike most machine learning-based approaches, our framework does not require access to ground-truth states or reanalysis data, broadening its applicability to settings with limited reference information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21751v1</guid>
      <category>cs.LG</category>
      <category>physics.comp-ph</category>
      <category>physics.flu-dyn</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jaemin Oh</dc:creator>
    </item>
    <item>
      <title>Breakdown of Kolmogorov Scaling and Modified Energy Transfer in Bubble-Laden Turbulence</title>
      <link>https://arxiv.org/abs/2509.22324</link>
      <description>arXiv:2509.22324v1 Announce Type: cross 
Abstract: We investigate the effect of a dispersed bubble phase on forced homogeneous and isotropic turbulence using high-resolution high-performance simulations based on the lattice Boltzmann method. While the classical Kolmogorov energy cascade is largely preserved when considering the system as a whole, a phase-specific analysis reveals striking deviations from the classical turbulence scaling. In particular, the gas phase exhibits significant departures from Kolmogorov's predictions, whereas the continuous liquid phase retains a turbulence structure consistent with classical expectations up to 24% in gas volume fractions. These findings suggest that, despite the presence of a dispersed phase, the global energy transfer remains close to a universal behavior. At the same time, phase-specific interactions are shown to introduce modifications to the turbulent dynamics at small scales. In particular, the gas-phase exhibits a nearly flat spectrum at low wave numbers followed by a k^{-3} scaling at intermediate scales pointing to the presence of patterns of localized bursts uniformly distributed between two finite wavelengths.Our results aim at deepening the understanding of multiphase turbulence, particularly in the context of energy transfer mechanisms and phase interactions in bubble-laden flows. This study provides a framework for future investigations into the fundamental properties of multiphase turbulence and its implications for environmental, atmospheric, and industrial flows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22324v1</guid>
      <category>physics.flu-dyn</category>
      <category>physics.comp-ph</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrea Montessori, Marco Lauricella, Aritra Mukherjee, Luca Brandt</dc:creator>
    </item>
    <item>
      <title>step2point dataset: Detailed shower simulation for data representation studies</title>
      <link>https://arxiv.org/abs/2509.22340</link>
      <description>arXiv:2509.22340v1 Announce Type: cross 
Abstract: This dataset contains a detailed simulation output that allows the construction and study of different data representations for electromagnetic and hadronic showers in calorimeters. It is published so that optimal data representations can be studied, with the ultimate goal of constructing a general tool that takes detailed simulation output and translates it into an optimal representation that can serve as the input to surrogate simulators based on generative models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22340v1</guid>
      <category>hep-ex</category>
      <category>physics.comp-ph</category>
      <category>physics.ins-det</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Anna Zaborowska (CERN), Peter McKeown (CERN)</dc:creator>
    </item>
    <item>
      <title>Fast-Forward Lattice Boltzmann: Learning Kinetic Behaviour with Physics-Informed Neural Operators</title>
      <link>https://arxiv.org/abs/2509.22411</link>
      <description>arXiv:2509.22411v1 Announce Type: cross 
Abstract: The lattice Boltzmann equation (LBE), rooted in kinetic theory, provides a powerful framework for capturing complex flow behaviour by describing the evolution of single-particle distribution functions (PDFs). Despite its success, solving the LBE numerically remains computationally intensive due to strict time-step restrictions imposed by collision kernels. Here, we introduce a physics-informed neural operator framework for the LBE that enables prediction over large time horizons without step-by-step integration, effectively bypassing the need to explicitly solve the collision kernel. We incorporate intrinsic moment-matching constraints of the LBE, along with global equivariance of the full distribution field, enabling the model to capture the complex dynamics of the underlying kinetic system. Our framework is discretization-invariant, enabling models trained on coarse lattices to generalise to finer ones (kinetic super-resolution). In addition, it is agnostic to the specific form of the underlying collision model, which makes it naturally applicable across different kinetic datasets regardless of the governing dynamics. Our results demonstrate robustness across complex flow scenarios, including von Karman vortex shedding, ligament breakup, and bubble adhesion. This establishes a new data-driven pathway for modelling kinetic systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22411v1</guid>
      <category>cs.LG</category>
      <category>nlin.CG</category>
      <category>physics.comp-ph</category>
      <category>physics.flu-dyn</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiao Xue, Marco F. P. ten Eikelder, Mingyang Gao, Xiaoyuan Cheng, Yiming Yang, Yi He, Shuo Wang, Sibo Cheng, Yukun Hu, Peter V. Coveney</dc:creator>
    </item>
    <item>
      <title>Enhancing Molecular Dipole Moment Prediction with Multitask Machine Learning</title>
      <link>https://arxiv.org/abs/2509.22435</link>
      <description>arXiv:2509.22435v1 Announce Type: cross 
Abstract: We present a multitask machine learning strategy for improving the prediction of molecular dipole moments by simultaneously training on quantum dipole magnitudes and inexpensive Mulliken atomic charges. With dipole magnitudes as the primary target and assuming only scalar dipole values are available without vector components we examine whether incorporating lower quality labels that do not quantitatively reproduce the target property can still enhance model accuracy. Mulliken charges were chosen intentionally as an auxiliary task, since they lack quantitative accuracy yet encode qualitative physical information about charge distribution. Our results show that including Mulliken charges with a small weight in the loss function yields up to a 30% improvement in dipole prediction accuracy. This multitask approach enables the model to learn a more physically grounded representation of charge distributions, thereby improving both the accuracy and consistency of dipole magnitude predictions. These findings highlight that even auxiliary data of limited quantitative reliability can provide valuable qualitative physical insights, ultimately strengthening the predictive power of machine learning models for molecular properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22435v1</guid>
      <category>physics.chem-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>William Colglazier, Nicholas Lubbers, Sergei Tretiak, Anders M. N. Niklasson, Maksim Kulichenko</dc:creator>
    </item>
    <item>
      <title>FreeBird.jl: An Extensible Toolbox for Simulating Interfacial Phase Equilibria</title>
      <link>https://arxiv.org/abs/2508.10237</link>
      <description>arXiv:2508.10237v2 Announce Type: replace-cross 
Abstract: We present $\texttt{FreeBird.jl}$, an extensible Julia-based platform for computational studies of phase equilibria at generic interfaces. The package supports a range of system configurations, from atomistic solid surfaces to coarse-grained lattice$-$gas models, with energies evaluated using classical interatomic potentials or lattice Hamiltonians. Both atomistic and lattice systems accommodate single- or multi-component mixtures with flexibly definable surface and lattice geometries. Implemented sampling algorithms include nested sampling, Wang$-$Landau sampling, Metropolis Monte Carlo, and, for tractable lattice systems, exact enumeration. Leveraging Julia's type hierarchies and multiple dispatch, $\texttt{FreeBird.jl}$ provides a modular interface that allows seamless integration of system definitions, energy evaluators, and sampling schemes. Designed for flexibility, extensibility, and performance, $\texttt{FreeBird.jl}$ offers a versatile framework for exploring the thermodynamics of interfacial phenomena.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10237v2</guid>
      <category>cond-mat.stat-mech</category>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.chem-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ray Yang, Junchi Chen, Douglas Thibodeaux, Robert B. Wexler</dc:creator>
    </item>
    <item>
      <title>A Variational Framework for Residual-Based Adaptivity in Neural PDE Solvers and Operator Learning</title>
      <link>https://arxiv.org/abs/2509.14198</link>
      <description>arXiv:2509.14198v2 Announce Type: replace-cross 
Abstract: Residual-based adaptive strategies are widely used in scientific machine learning but remain largely heuristic. We introduce a unifying variational framework that formalizes these methods by integrating convex transformations of the residual. Different transformations correspond to distinct objective functionals: exponential weights target the minimization of uniform error, while linear weights recover the minimization of quadratic error. Within this perspective, adaptive weighting is equivalent to selecting sampling distributions that optimize the primal objective, thereby linking discretization choices directly to error metrics. This principled approach yields three benefits: (1) it enables systematic design of adaptive schemes across norms, (2) reduces discretization error through variance reduction of the loss estimator, and (3) enhances learning dynamics by improving the gradient signal-to-noise ratio. Extending the framework to operator learning, we demonstrate substantial performance gains across optimizers and architectures. Our results provide a theoretical justification of residual-based adaptivity and establish a foundation for principled discretization and training strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14198v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>physics.comp-ph</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Juan Diego Toscano, Daniel T. Chen, Vivek Oommen, J\'er\^ome Darbon, George Em Karniadakis</dc:creator>
    </item>
  </channel>
</rss>
