<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.data-an updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.data-an</link>
    <description>physics.data-an updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.data-an" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 07 Oct 2025 04:01:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Fast frequency reconstruction using Deep Learning for event recognition in ring laser data</title>
      <link>https://arxiv.org/abs/2510.03325</link>
      <description>arXiv:2510.03325v1 Announce Type: cross 
Abstract: The reconstruction of a frequency with minimal delay from a sinusoidal signal is a common task in several fields; for example Ring Laser Gyroscopes, since their output signal is a beat frequency. While conventional methods require several seconds of data, we present a neural network approach capable of reconstructing frequencies of several hundred Hertz within approximately 10 milliseconds. This enables rapid trigger generation. The method outperforms standard Fourier-based techniques, improving frequency estimation precision by a factor of 2 in the operational range of GINGERINO, our Ring Laser Gyroscope.\\ In addition to fast frequency estimation, we introduce an automated classification framework to identify physical disturbances in the signal, such as laser instabilities and seismic events, achieving accuracy rates between 99\% and 100\% on independent test datasets for the seismic class. These results mark a step forward in integrating artificial intelligence into signal analysis for geophysical applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03325v1</guid>
      <category>cs.LG</category>
      <category>physics.comp-ph</category>
      <category>physics.data-an</category>
      <category>physics.geo-ph</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giuseppe Di Somma, Giorgio Carelli, Angela D. V. Di Virgilio, Francesco Fuso, Enrico Maccioni, Paolo Marsili</dc:creator>
    </item>
    <item>
      <title>Field observation of soliton gases in the deep open ocean</title>
      <link>https://arxiv.org/abs/2510.04662</link>
      <description>arXiv:2510.04662v1 Announce Type: cross 
Abstract: Soliton gases are large ensembles of random solitons with distinct characteristics arising from integrable system dynamics. They have been widely studied in theory and experiments, and were observed in natural lagoons. However, it remains an open question whether they occur naturally in the open ocean. Nonlinear ocean states containing solitons have been observed in the literature, but the dominance of solitons over other wave components required for a soliton gas has not been demonstrated. Our study provides the first field evidence of soliton gas sea states in the deep ocean, measured in Taiwan waters. The soliton energy ratio derived from the nonlinear Fourier transform (NFT) is employed as a key parameter to quantify how close sea states are to soliton gases. We identify eleven measurements with extremely high soliton energy ratios. They are characterized by short-period waves with relatively small wave heights, accompanied by extreme steepness and Benjamin-Feir Index (BFI) values. These states are exceptionally rare, representing only 0.054 percent of our dataset. Since directional interference can artificially increase the soliton energy ratio, we furthermore apply a probabilistic directional filtering method to remove the directional interference. Three wave records from the Eluanbi station are found to retain high soliton energy ratios after the directional interference has been removed, confirming that they are indeed soliton gases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04662v1</guid>
      <category>nlin.PS</category>
      <category>nlin.SI</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yu-Chen Lee, Sander Wahls</dc:creator>
    </item>
    <item>
      <title>\mu DeepIQA: deep learning-based fast and robust image quality assessment with local predictions for optical microscopy</title>
      <link>https://arxiv.org/abs/2510.04859</link>
      <description>arXiv:2510.04859v1 Announce Type: cross 
Abstract: Optical microscopy is one of the most widely used techniques in research studies for life sciences and biomedicine. These applications require reliable experimental pipelines to extract valuable knowledge from the measured samples and must be supported by image quality assessment (IQA) to ensure correct processing and analysis of the image data. IQA methods are implemented with variable complexity. However, while most quality metrics have a straightforward implementation, they might be time consuming and computationally expensive when evaluating a large dataset. In addition, quality metrics are often designed for well-defined image features and may be unstable for images out of the ideal domain.
  To overcome these limitations, recent works have proposed deep learning-based IQA methods, which can provide superior performance, increased generalizability and fast prediction. Our method, named $\mathrm{\mu}$DeepIQA, is inspired by previous studies and applies a deep convolutional neural network designed for IQA on natural images to optical microscopy measurements. We retrained the same architecture to predict individual quality metrics and global quality scores for optical microscopy data. The resulting models provide fast and stable predictions of image quality by generalizing quality estimation even outside the ideal range of standard methods. In addition, $\mathrm{\mu}$DeepIQA provides patch-wise prediction of image quality and can be used to visualize spatially varying quality in a single image. Our study demonstrates that optical microscopy-based studies can benefit from the generalizability of deep learning models due to their stable performance in the presence of outliers, the ability to assess small image patches, and rapid predictions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04859v1</guid>
      <category>cs.CV</category>
      <category>physics.data-an</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elena Corbetta, Thomas Bocklitz</dc:creator>
    </item>
    <item>
      <title>Comparative Analysis of Richardson-Lucy Deconvolution and Data Unfolding with Mean Integrated Square Error Optimization</title>
      <link>https://arxiv.org/abs/2505.10283</link>
      <description>arXiv:2505.10283v3 Announce Type: replace 
Abstract: Two maximum likelihood-based algorithms for unfolding or deconvolution are considered: the Richardson-Lucy method and the Data Unfolding method with Mean Integrated Square Error (MISE) optimization [10]. Unfolding is viewed as a procedure for estimating an unknown probability density function. Both external and internal quality assessment methods can be applied for this purpose. In some cases, external criteria exist to evaluate deconvolution quality. A typical example is the deconvolution of a blurred image, where the sharpness of the restored image serves as an indicator of quality. However, defining such external criteria can be challenging, particularly when a measurement has not been performed previously. In such instances, internal criteria are necessary to assess the quality of the result independently of external information. The article discusses two internal criteria: MISE for the unfolded distribution and the condition number of the correlation matrix of the unfolded distribution. These internal quality criteria are applied to a comparative analysis of the two methods using identical numerical data. The results of the analysis demonstrate the superiority of the Data Unfolding method with MISE optimization over the Richardson-Lucy method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.10283v3</guid>
      <category>physics.data-an</category>
      <category>astro-ph.IM</category>
      <category>hep-ex</category>
      <category>nucl-ex</category>
      <category>stat.AP</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nikolay D. Gagunashvili</dc:creator>
    </item>
    <item>
      <title>Taming Uncertainty in a Complex World: The Rise of Uncertainty Quantification -- A Tutorial for Beginners</title>
      <link>https://arxiv.org/abs/2408.01823</link>
      <description>arXiv:2408.01823v3 Announce Type: replace-cross 
Abstract: This paper provides a tutorial about uncertainty quantification (UQ) for those who have no background but are interested in learning more in this area. It exploits many very simple examples, which are understandable to undergraduates, to present the ideas of UQ. Topics include characterizing uncertainties using information theory, UQ in linear and nonlinear dynamical systems, UQ via data assimilation, the role of uncertainty in diagnostics, and UQ in advancing efficient modeling. The surprisingly simple examples in each topic explain why and how UQ is essential. Both MATLAB and Python codes are made available for these simple examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01823v3</guid>
      <category>math.DS</category>
      <category>physics.ao-ph</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1090/noti3120</arxiv:DOI>
      <arxiv:journal_reference>Notices of the American Mathematical Society 72, 03 (2025): 250-260</arxiv:journal_reference>
      <dc:creator>Nan Chen, Stephen Wiggins, Marios Andreou</dc:creator>
    </item>
    <item>
      <title>Stochastic Subspace via Probabilistic Principal Component Analysis for Characterizing Model Error</title>
      <link>https://arxiv.org/abs/2504.19963</link>
      <description>arXiv:2504.19963v3 Announce Type: replace-cross 
Abstract: This paper proposes a probabilistic model of subspaces based on the probabilistic principal component analysis (PCA). Given a sample of vectors in the embedding space -- commonly known as a snapshot matrix -- this method uses quantities derived from the probabilistic PCA to construct distributions of the sample matrix, as well as the principal subspaces. It is applicable to projection-based reduced-order modeling methods, such as proper orthogonal decomposition and related model reduction methods. The stochastic subspace thus constructed can be used, for example, to characterize model-form uncertainty in computational mechanics. The proposed method has multiple desirable properties: (1) it is naturally justified by the probabilistic PCA and has analytic forms for the induced random matrix models; (2) it satisfies linear constraints, such as boundary conditions of all kinds, by default; (3) it has only one hyperparameter, which significantly simplifies training; and (4) its algorithm is very easy to implement. We demonstrate the performance of the proposed method via several numerical examples in computational mechanics and structural dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19963v3</guid>
      <category>cs.CE</category>
      <category>math.ST</category>
      <category>physics.comp-ph</category>
      <category>physics.data-an</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s00466-025-02701-6</arxiv:DOI>
      <dc:creator>Akash Yadav, Ruda Zhang</dc:creator>
    </item>
    <item>
      <title>Functional Information in Quantum Darwinism: An Operational Measure of Objectivity</title>
      <link>https://arxiv.org/abs/2509.17775</link>
      <description>arXiv:2509.17775v2 Announce Type: replace-cross 
Abstract: This paper investigates the emergence of classical objectivity in quantum systems through the measure of Functional Information in Quantum Darwinism ($FI_{QD}$). The goal is to quantify objectivity as the abundance of environment fragments that independently contain sufficient information about a system's pointer states. The method relies on the Holevo quantity -- an upper bound on accessible information -- and introduces a tolerance criterion called $\delta$-adequacy, where fragments are considered adequate if they retain at least $(1-\delta)H_S$ bits of pointer information. Numerical simulations of a dephasing model with fragment sampling reveal three robust features: (i) an early-time regime where $\log R_\delta(t)$ grows approximately linearly, (ii) capacity-limited plateaus determined by fragment size and environment dimension, and (iii) stability of the onset criterion under different sampling strategies and overlap corrections. These results establish $FI_{QD}$ as a practical and conservative yardstick for operational objectivity. Beyond numerical findings, the analysis links redundancy growth to thermodynamic costs of record formation and interprets $FI_{QD}$ as a resource monotone under noisy dynamics. The study suggests that classical objectivity emerges not as an assumption but as a quantifiable, resource-limited abundance of redundant records.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.17775v2</guid>
      <category>quant-ph</category>
      <category>physics.comp-ph</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arda Batin Tank</dc:creator>
    </item>
  </channel>
</rss>
