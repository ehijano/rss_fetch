<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.TH</link>
    <description>stat.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 14 May 2024 04:03:53 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 14 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Hypergeometric Distribution Revisited: Tail Inequalities, Confidence Bounds and Sample Sizes</title>
      <link>https://arxiv.org/abs/2405.06722</link>
      <description>arXiv:2405.06722v1 Announce Type: new 
Abstract: We revisit and refine known tail inequalities and confidence bounds for the hypergeometric distribution, i.e., for the setting where we sample without replacement from a fixed population with binary values or properties. The results are presented in a unified notation in order to increase understanding and facilitate comparisons. We focus on the usability of the results in practice and thus on simple bounds. Further, we make the computation of confidence intervals and necessary sample sizes explicit in our results and demonstrate their use in an extended example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06722v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anne-Marie George</dc:creator>
    </item>
    <item>
      <title>Neural Estimation Of Entropic Optimal Transport</title>
      <link>https://arxiv.org/abs/2405.06734</link>
      <description>arXiv:2405.06734v1 Announce Type: new 
Abstract: Optimal transport (OT) serves as a natural framework for comparing probability measures, with applications in statistics, machine learning, and applied mathematics. Alas, statistical estimation and exact computation of the OT distances suffer from the curse of dimensionality. To circumvent these issues, entropic regularization has emerged as a remedy that enables parametric estimation rates via plug-in and efficient computation using Sinkhorn iterations. Motivated by further scaling up entropic OT (EOT) to data dimensions and sample sizes that appear in modern machine learning applications, we propose a novel neural estimation approach. Our estimator parametrizes a semi-dual representation of the EOT distance by a neural network, approximates expectations by sample means, and optimizes the resulting empirical objective over parameter space. We establish non-asymptotic error bounds on the EOT neural estimator of the cost and optimal plan. Our bounds characterize the effective error in terms of neural network size and the number of samples, revealing optimal scaling laws that guarantee parametric convergence. The bounds hold for compactly supported distributions and imply that the proposed estimator is minimax-rate optimal over that class. Numerical experiments validating our theory are also provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06734v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tao Wang, Ziv Goldfeld</dc:creator>
    </item>
    <item>
      <title>On the orthogonally equivariant estimators of a covariance matrix</title>
      <link>https://arxiv.org/abs/2405.06877</link>
      <description>arXiv:2405.06877v1 Announce Type: new 
Abstract: In this note, when the dimension $p$ is large we look into the insight of the Mar$\check{c}$enko-Pastur equation to get an explicit equality relationship, and use the obtained equality to establish a new kind of orthogonally equivariant estimator of the population covariance matrix. Under some regularity conditions, the proposed novel estimators of the population eigenvalues are shown to be consistent for the eigenvalues of population covariance matrix. It is also shown that the proposed estimator is the best orthogonally equivariant estimator of population covariance matrix under the normalized Stein loss function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06877v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ming-Tien Tsai, Chia-Hsuan Tsai</dc:creator>
    </item>
    <item>
      <title>Multimatricvariate and multimatrix variate distributions based on elliptically contoured laws under real normed division algebras</title>
      <link>https://arxiv.org/abs/2405.06905</link>
      <description>arXiv:2405.06905v1 Announce Type: new 
Abstract: This paper proposes famillies of multimatricvariate and multimatrix variate distributions based on elliptically contoured laws in the context of real normed division algebras. The work allows to answer the following inference problems about random matrix variate distributions: 1) Modeling of two or more probabilistically dependent random variables in all possible combinations whether univariate, vector and matrix simultaneously. 2) Expected marginal distributions under independence and joint estimation of models under likelihood functions of dependent samples. 3) Definition of a likelihood function for dependent samples in the mentioned random dimensions and under real normed division algebras. The corresponding real distributions are alternative approaches to the existing univariate and vector variate copulas, with the additional advantages previously listed. An application for quaternionic algebra is illustrated by a computable dependent sample joint distribution for landmark data emerged from shape theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06905v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jos\'e A. D\'iaz-Garc\'ia, Francisco J. Caro-Lopera</dc:creator>
    </item>
    <item>
      <title>Tests for principal eigenvalues and eigenvectors</title>
      <link>https://arxiv.org/abs/2405.06939</link>
      <description>arXiv:2405.06939v1 Announce Type: new 
Abstract: We establish central limit theorems for principal eigenvalues and eigenvectors under a large factor model setting, and develop two-sample tests of both principal eigenvalues and principal eigenvectors. One important application is to detect structural breaks in large factor models. Compared with existing methods for detecting structural breaks, our tests provide unique insights into the source of structural breaks because they can distinguish between individual principal eigenvalues and/or eigenvectors. We demonstrate the application by comparing the principal eigenvalues and principal eigenvectors of S\&amp;P500 Index constituents' daily returns over different years.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06939v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jianqing Fan, Yingying Li, Ningning Xia, Xinghua Zheng</dc:creator>
    </item>
    <item>
      <title>Fusing independent inferential models in a black-box manner</title>
      <link>https://arxiv.org/abs/2405.07173</link>
      <description>arXiv:2405.07173v1 Announce Type: new 
Abstract: Inferential models (IMs) represent a novel possibilistic approach for achieving provably valid statistical inference. This paper introduces a general framework for fusing independent IMs in a "black-box" manner, requiring no knowledge of the original IMs construction details. The underlying logic of this framework mirrors that of the IMs approach. First, a fusing function for the initial IMs' possibility contours is selected. Given the possible lack of guarantee regarding the calibration of this function for valid inferences, a "validification" step is performed. Subsequently, a straightforward normalization step is executed to ensure that the final output conforms to a possibility contour.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07173v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Leonardo Cella</dc:creator>
    </item>
    <item>
      <title>Unveiling low-dimensional patterns induced by convex non-differentiable regularizers</title>
      <link>https://arxiv.org/abs/2405.07677</link>
      <description>arXiv:2405.07677v1 Announce Type: new 
Abstract: Popular regularizers with non-differentiable penalties, such as Lasso, Elastic Net, Generalized Lasso, or SLOPE, reduce the dimension of the parameter space by inducing sparsity or clustering in the estimators' coordinates. In this paper, we focus on linear regression and explore the asymptotic distributions of the resulting low-dimensional patterns when the number of regressors $p$ is fixed, the number of observations $n$ goes to infinity, and the penalty function increases at the rate of $\sqrt{n}$. While the asymptotic distribution of the rescaled estimation error can be derived by relatively standard arguments, the convergence of the pattern does not simply follow from the convergence in distribution, and requires a careful and separate treatment. For this purpose, we use the Hausdorff distance as a suitable mode of convergence for subdifferentials, resulting in the desired pattern convergence. Furthermore, we derive the exact limiting probability of recovering the true model pattern. This probability goes to 1 if and only if the penalty scaling constant diverges to infinity and the regularizer-specific asymptotic irrepresentability condition is satisfied. We then propose simple two-step procedures that asymptotically recover the model patterns, irrespective whether the irrepresentability condition holds.
  Interestingly, our theory shows that Fused Lasso cannot reliably recover its own clustering pattern, even for independent regressors. It also demonstrates how this problem can be resolved by ``concavifying'' the Fused Lasso penalty coefficients. Additionally, sampling from the asymptotic error distribution facilitates comparisons between different regularizers. We provide short simulation studies showcasing an illustrative comparison between the asymptotic properties of Lasso, Fused Lasso, and SLOPE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07677v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ivan Hejn\'y, Jonas Wallin, Ma{\l}gorzata Bogdan, Micha{\l} Kos</dc:creator>
    </item>
    <item>
      <title>Model Identifiability for Bivariate Failure Time Data with Competing Risk: Non-parametric Cause-specific Hazards and Gamma Frailty</title>
      <link>https://arxiv.org/abs/2405.07722</link>
      <description>arXiv:2405.07722v1 Announce Type: new 
Abstract: In survival analysis, frailty variables are often used to model the association in multivariate survival data. Identifiability is an important issue while working with such multivariate survival data with or without competing risks. In this work, we consider bivariate survival data with competing risks and investigate identifiability results with non-parametric baseline cause-specific hazards and different types of Gamma frailty. Prior to that, we prove that, when both baseline cause-specific hazards and frailty distributions are non-parametric, the model is not identifiable. We also construct a non-identifiable model when baseline cause-specific hazards are non-parametric but frailty distribution may be parametric. Thereafter, we consider four different Gamma frailty distributions, and the corresponding models are shown to be identifiable under fairly general assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07722v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Biswadeep Ghosh, Anup Dewanji, Sudipta Das</dc:creator>
    </item>
    <item>
      <title>Measuring dependence between a scalar response and a functional covariate</title>
      <link>https://arxiv.org/abs/2405.07732</link>
      <description>arXiv:2405.07732v1 Announce Type: new 
Abstract: We extend the scope of a recently introduced dependence coefficient between a scalar response $Y$ and a multivariate covariate $X$ to the case where $X$ takes values in a general metric space. Particular attention is paid to the case where $X$ is a curve. While on the population level, this extension is straight forward, the asymptotic behavior of the estimator we consider is delicate. It crucially depends on the nearest neighbor structure of the infinite-dimensional covariate sample, where deterministic bounds on the degrees of the nearest neighbor graphs available in multivariate settings do no longer exist. The main contribution of this paper is to give some insight into this matter and to advise a way how to overcome the problem for our purposes. As an important application of our results, we consider an independence test.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07732v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Siegfried H\"ormann, Daniel Strenger</dc:creator>
    </item>
    <item>
      <title>Minimax rates in variance and covariance changepoint testing</title>
      <link>https://arxiv.org/abs/2405.07757</link>
      <description>arXiv:2405.07757v1 Announce Type: new 
Abstract: We study the detection of a change in the spatial covariance matrix of $n$ independent sub-Gaussian random variables of dimension $p$. Our first contribution is to show that $\log\log(8n)$ is the exact minimax testing rate for a change in variance when $p=1$, thereby giving a complete characterization of the problem for univariate data. Our second contribution is to derive a lower bound on the minimax testing rate under the operator norm, taking a certain notion of sparsity into account. In the low- to moderate-dimensional region of the parameter space, we are able to match the lower bound from above with an optimal test based on sparse eigenvalues. In the remaining region of the parameter space, where the dimensionality is high, the minimax lower bound implies that changepoint testing is very difficult. As our third contribution, we propose a computationally feasible variant of the optimal multivariate test for a change in covariance, which is also adaptive to the nominal noise level and the sparsity level of the change.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07757v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Per August Jarval Moen</dc:creator>
    </item>
    <item>
      <title>Riemannian radial distributions on Riemannian symmetric spaces: Optimal rates of convergence for parameter estimation</title>
      <link>https://arxiv.org/abs/2405.07852</link>
      <description>arXiv:2405.07852v1 Announce Type: new 
Abstract: Manifold data analysis is challenging due to the lack of parametric distributions on manifolds. To address this, we introduce a series of Riemannian radial distributions on Riemannian symmetric spaces. By utilizing the symmetry, we show that for many Riemannian radial distributions, the Riemannian $L^p$ center of mass is uniquely given by the location parameter, and the maximum likelihood estimator (MLE) of this parameter is given by an M-estimator. Therefore, these parametric distributions provide a promising tool for statistical modeling and algorithmic design.
  In addition, our paper develops a novel theory for parameter estimation and minimax optimality by integrating statistics, Riemannian geometry, and Lie theory. We demonstrate that the MLE achieves a convergence rate of root-$n$ up to logarithmic terms, where the rate is quantified by both the hellinger distance between distributions and geodesic distance between parameters. Then we derive a root-$n$ minimax lower bound for the parameter estimation rate, demonstrating the optimality of the MLE. Our minimax analysis is limited to the case of simply connected Riemannian symmetric spaces for technical reasons, but is still applicable to numerous applications. Finally, we extend our studies to Riemannian radial distributions with an unknown temperature parameter, and establish the convergence rate of the MLE. We also derive the model complexity of von Mises-Fisher distributions on spheres and discuss the effects of geometry in statistical estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07852v1</guid>
      <category>math.ST</category>
      <category>math.DG</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hengchao Chen</dc:creator>
    </item>
    <item>
      <title>A Unification of Exchangeability and Continuous Exposure and Confounder Measurement Errors: Probabilistic Exchangeability</title>
      <link>https://arxiv.org/abs/2405.07910</link>
      <description>arXiv:2405.07910v1 Announce Type: new 
Abstract: Exchangeability concerning a continuous exposure, X, implies no confounding bias when identifying average exposure effects of X, AEE(X). When X is measured with error (Xep), two challenges arise in identifying AEE(X). Firstly, exchangeability regarding Xep does not equal exchangeability regarding X. Secondly, the necessity of the non-differential error assumption (NDEA), overly stringent in practice, remains uncertain. To address them, this article proposes unifying exchangeability and exposure and confounder measurement errors with three novel concepts. The first, Probabilistic Exchangeability (PE), states that the outcomes of those with Xep=e are probabilistically exchangeable with the outcomes of those truly exposed to X=eT. The relationship between AEE(Xep) and AEE(X) in risk difference and ratio scales is mathematically expressed as a probabilistic certainty, termed exchangeability probability (Pe). Squared Pe (Pe.sq) quantifies the extent to which AEE(Xep) differs from AEE(X) due to exposure measurement error not akin to confounding mechanisms. In realistic settings, the coefficient of determination (R.sq) in the regression of X against Xep may be sufficient to measure Pe.sq. The second concept, Emergent Pseudo Confounding (EPC), describes the bias introduced by exposure measurement error, akin to confounding mechanisms. PE can hold when EPC is controlled for, which is weaker than NDEA. The third, Emergent Confounding, describes when bias due to confounder measurement error arises. Adjustment for E(P)C can be performed like confounding adjustment to ensure PE. This paper provides justifies for using AEE(Xep) and maximum insight into potential divergence of AEE(Xep) from AEE(X) and its measurement. Differential errors do not necessarily compromise causal inference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07910v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Honghyok Kim</dc:creator>
    </item>
    <item>
      <title>Record-based transmuted unit omega distribution: different methods of estimation and applications</title>
      <link>https://arxiv.org/abs/2405.07958</link>
      <description>arXiv:2405.07958v1 Announce Type: new 
Abstract: Dombi et al. (2019) introduced a three parameter omega distribution and showed that its asymptotic distribution is the Weibull model. We propose a new record-based transmuted generalization of the unit omega distribution by considering Balakrishnan and He (2021) approach. We call it the RTUOMG distribution. We derive expressions for some statistical quantities, like, probability density function, distribution, hazard function, quantile function, moments, incomplete moments, inverted moments, moment generating function, Lorenz curve, and Bonferroni curve of the proposed distribution. The numerical values of various measures of central tendency and coefficient of skewness and kurtosis are also presented. Concepts of stochastic ordering and some results related to ordered statistics of the RTUOMG distribution are discussed. The parameters of the RTUOMG distribution are estimated using five distinct estimators. Additionally, the Monte Carlo simulations are performed to assess the performance of these estimators. Finally, two real data sets are analyzed to demonstrate the utility of the RTUOMG distribution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07958v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ashok Kumar Pathak, Mohd. Arshad, Alok Kumar Pandey, Alam Ali</dc:creator>
    </item>
    <item>
      <title>The Multiple Change-in-Gaussian-Mean Problem</title>
      <link>https://arxiv.org/abs/2405.06796</link>
      <description>arXiv:2405.06796v1 Announce Type: cross 
Abstract: A manuscript version of the chapter "The Multiple Change-in-Gaussian-Mean Problem" from the book "Change-Point Detection and Data Segmentation" by Fearnhead and Fryzlewicz, currently in preparation. All R code and data to accompany this chapter and the book are gradually being made available through https://github.com/pfryz/cpdds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06796v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paul Fearnhead, Piotr Fryzlewicz</dc:creator>
    </item>
    <item>
      <title>Riemannian Statistics for Any Type of Data</title>
      <link>https://arxiv.org/abs/2405.06799</link>
      <description>arXiv:2405.06799v1 Announce Type: cross 
Abstract: This paper introduces a novel approach to statistics and data analysis, departing from the conventional assumption of data residing in Euclidean space to consider a Riemannian Manifold. The challenge lies in the absence of vector space operations on such manifolds. Pennec X. et al. in their book Riemannian Geometric Statistics in Medical Image Analysis proposed analyzing data on Riemannian manifolds through geometry, this approach is effective with structured data like medical images, where the intrinsic manifold structure is apparent. Yet, its applicability to general data lacking implicit local distance notions is limited. We propose a solution to generalize Riemannian statistics for any type of data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06799v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Oldemar Rodriguez Rojas</dc:creator>
    </item>
    <item>
      <title>A note on distance variance for categorical variables</title>
      <link>https://arxiv.org/abs/2405.06813</link>
      <description>arXiv:2405.06813v1 Announce Type: cross 
Abstract: This study investigates the extension of distance variance, a validated spread metric for continuous and binary variables [Edelmann et al., 2020, Ann. Stat., 48(6)], to quantify the spread of general categorical variables. We provide both geometric and algebraic characterizations of distance variance, revealing its connections to some commonly used entropy measures, and the variance-covariance matrix of the one-hot encoded representation. However, we demonstrate that distance variance fails to satisfy the Schur-concavity axiom for categorical variables with more than two categories, leading to counterintuitive results. This limitation hinders its applicability as a universal measure of spread.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06813v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qingyang Zhang</dc:creator>
    </item>
    <item>
      <title>Factor Strength Estimation in Vector and Matrix Time Series Factor Models</title>
      <link>https://arxiv.org/abs/2405.07294</link>
      <description>arXiv:2405.07294v1 Announce Type: cross 
Abstract: Most factor modelling research in vector or matrix-valued time series assume all factors are pervasive/strong and leave weaker factors and their corresponding series to the noise. Weaker factors can in fact be important to a group of observed variables, for instance a sector factor in a large portfolio of stocks may only affect particular sectors, but can be important both in interpretations and predictions for those stocks. While more recent factor modelling researches do consider ``local'' factors which are weak factors with sparse corresponding factor loadings, there are real data examples in the literature where factors are weak because of weak influence on most/all observed variables, so that the corresponding factor loadings are not sparse (non-local). As a first in the literature, we propose estimators of factor strengths for both local and non-local weak factors, and prove their consistency with rates of convergence spelt out for both vector and matrix-valued time series factor models. Factor strength has an important indication in what estimation procedure of factor models to follow, as well as the estimation accuracy of various estimators (Chen and Lam, 2024). Simulation results show that our estimators have good performance in recovering the true factor strengths, and an analysis on the NYC taxi traffic data indicates the existence of weak factors in the data which may not be localized.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07294v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Weilin Chen, Clifford Lam</dc:creator>
    </item>
    <item>
      <title>Decoding Geometric Properties in Non-Random Data from First Information-Theoretic Principles</title>
      <link>https://arxiv.org/abs/2405.07803</link>
      <description>arXiv:2405.07803v1 Announce Type: cross 
Abstract: Based on the principles of information theory, measure theory, and theoretical computer science, we introduce a univariate signal deconvolution method with a wide range of applications to coding theory, particularly in zero-knowledge one-way communication channels, such as in deciphering messages from unknown generating sources about which no prior knowledge is available and to which no return message can be sent. Our multidimensional space reconstruction method from an arbitrary received signal is proven to be agnostic vis-a-vis the encoding-decoding scheme, computation model, programming language, formal theory, the computable (or semi-computable) method of approximation to algorithmic complexity, and any arbitrarily chosen (computable) probability measure of the events. The method derives from the principles of an approach to Artificial General Intelligence capable of building a general-purpose model of models independent of any arbitrarily assumed prior probability distribution. We argue that this optimal and universal method of decoding non-random data has applications to signal processing, causal deconvolution, topological and geometric properties encoding, cryptography, and bio- and technosignature detection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07803v1</guid>
      <category>cs.IT</category>
      <category>cs.CL</category>
      <category>cs.CR</category>
      <category>cs.IR</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hector Zenil, Felipe S. Abrah\~ao</dc:creator>
    </item>
    <item>
      <title>Uniform Inference for Subsampled Moment Regression</title>
      <link>https://arxiv.org/abs/2405.07860</link>
      <description>arXiv:2405.07860v1 Announce Type: cross 
Abstract: We propose a method for constructing a confidence region for the solution to a conditional moment equation. The method is built around a class of algorithms for nonparametric regression based on subsampled kernels. This class includes random forest regression. We bound the error in the confidence region's nominal coverage probability, under the restriction that the conditional moment equation of interest satisfies a local orthogonality condition. The method is applicable to the construction of confidence regions for conditional average treatment effects in randomized experiments, among many other similar problems encountered in applied economics and causal inference. As a by-product, we obtain several new order-explicit results on the concentration and normal approximation of high-dimensional $U$-statistics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07860v1</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David M. Ritzwoller, Vasilis Syrgkanis</dc:creator>
    </item>
    <item>
      <title>Low-order outcomes and clustered designs: combining design and analysis for causal inference under network interference</title>
      <link>https://arxiv.org/abs/2405.07979</link>
      <description>arXiv:2405.07979v1 Announce Type: cross 
Abstract: Variance reduction for causal inference in the presence of network interference is often achieved through either outcome modeling, which is typically analyzed under unit-randomized Bernoulli designs, or clustered experimental designs, which are typically analyzed without strong parametric assumptions. In this work, we study the intersection of these two approaches and consider the problem of estimation in low-order outcome models using data from a general experimental design. Our contributions are threefold. First, we present an estimator of the total treatment effect (also called the global average treatment effect) in a low-degree outcome model when the data are collected under general experimental designs, generalizing previous results for Bernoulli designs. We refer to this estimator as the pseudoinverse estimator and give bounds on its bias and variance in terms of properties of the experimental design. Second, we evaluate these bounds for the case of cluster randomized designs with both Bernoulli and complete randomization. For clustered Bernoulli randomization, we find that our estimator is always unbiased and that its variance scales like the smaller of the variance obtained from a low-order assumption and the variance obtained from cluster randomization, showing that combining these variance reduction strategies is preferable to using either individually. For clustered complete randomization, we find a notable bias-variance trade-off mediated by specific features of the clustering. Third, when choosing a clustered experimental design, our bounds can be used to select a clustering from a set of candidate clusterings. Across a range of graphs and clustering algorithms, we show that our method consistently selects clusterings that perform well on a range of response models, suggesting that our bounds are useful to practitioners.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07979v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthew Eichhorn, Samir Khan, Johan Ugander, Christina Lee Yu</dc:creator>
    </item>
    <item>
      <title>Entropic estimation of optimal transport maps</title>
      <link>https://arxiv.org/abs/2109.12004</link>
      <description>arXiv:2109.12004v3 Announce Type: replace 
Abstract: We develop a computationally tractable method for estimating the optimal map between two distributions over $\mathbb{R}^d$ with rigorous finite-sample guarantees. Leveraging an entropic version of Brenier's theorem, we show that our estimator -- the \emph{barycentric projection} of the optimal entropic plan -- is easy to compute using Sinkhorn's algorithm. As a result, unlike current approaches for map estimation, which are slow to evaluate when the dimension or number of samples is large, our approach is parallelizable and extremely efficient even for massive data sets. Under smoothness assumptions on the optimal map, we show that our estimator enjoys comparable statistical performance to other estimators in the literature, but with much lower computational cost. We showcase the efficacy of our proposed estimator through numerical examples, even ones not explicitly covered by our assumptions. By virtue of Lepski's method, we propose a modified version of our estimator that is adaptive to the smoothness of the underlying optimal transport map. Our proofs are based on a modified duality principle for entropic optimal transport and on a method for approximating optimal entropic plans due to Pal (2019).</description>
      <guid isPermaLink="false">oai:arXiv.org:2109.12004v3</guid>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aram-Alexandre Pooladian, Jonathan Niles-Weed</dc:creator>
    </item>
    <item>
      <title>Spiked eigenvalues of high-dimensional sample autocovariance matrices: CLT and applications</title>
      <link>https://arxiv.org/abs/2201.03181</link>
      <description>arXiv:2201.03181v2 Announce Type: replace 
Abstract: High-dimensional autocovariance matrices play an important role in dimension reduction for high-dimensional time series. In this article, we establish the central limit theorem (CLT) for spiked eigenvalues of high-dimensional sample autocovariance matrices, which are developed under general conditions. The spiked eigenvalues are allowed to go to infinity in a flexible way without restrictions in divergence order. Moreover, the number of spiked eigenvalues and the time lag of the autocovariance matrix under this study could be either fixed or tending to infinity when the dimension p and the time length T go to infinity together. As a further statistical application, a novel autocovariance test is proposed to detect the equivalence of spiked eigenvalues for two high-dimensional time series. Various simulation studies are illustrated to justify the theoretical findings. Furthermore, a hierarchical clustering approach based on the autocovariance test is constructed and applied to clustering mortality data from multiple countries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2201.03181v2</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daning Bi, Xiao Han, Adam Nie, Yanrong Yang</dc:creator>
    </item>
    <item>
      <title>Dually affine Information Geometry modeled on a Banach space</title>
      <link>https://arxiv.org/abs/2204.00917</link>
      <description>arXiv:2204.00917v2 Announce Type: replace 
Abstract: In this chapter, we study Information Geometry from a particular non-parametric or functional point of view. The basic model is a probabilities subset usually specified by regularity conditions. For example, probability measures mutually absolutely continuous or probability densities with a given degree of smoothness. We construct a manifold structure by giving an atlas of charts as mappings from probabilities to a Banach space. The charts we use are quite peculiar in that we consider only instances where the transition mappings are affine. We chose a particular expression of the tangent and cotangent bundles in this affine setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2204.00917v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Goffredo Chirco, Giovanni Pistone</dc:creator>
    </item>
    <item>
      <title>Testing for jumps in processes with integral fractional part and jump-robust inference on the Hurst exponent</title>
      <link>https://arxiv.org/abs/2305.01751</link>
      <description>arXiv:2305.01751v2 Announce Type: replace 
Abstract: We develop and investigate a test for jumps based on high-frequency observations of a fractional process with an additive jump component. The Hurst exponent of the fractional process is unknown. The asymptotic theory under infill asymptotics builds upon extreme value theory for weakly dependent, stationary time series and extends techniques for the semimartingale case from the literature. It is shown that the statistic on which the test is based on weakly converges to a Gumbel distribution under the null hypothesis of no jumps. We prove consistency under the alternative hypothesis when there are jumps. Moreover, we establish convergence rates for local alternatives and consistent estimation of jump times. In the process, we show that inference on the Hurst exponent of a rough fractional process is robust with respect to jumps. This provides an important insight for the growing literature on rough volatility. We demonstrate sound finite-sample properties in a simulation study and showcase the applicability of our methods in an empirical example with a time series of volatilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.01751v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Markus Bibinger, Michael Sonntag</dc:creator>
    </item>
    <item>
      <title>Multivariate generalized Pareto distributions along extreme directions</title>
      <link>https://arxiv.org/abs/2311.04618</link>
      <description>arXiv:2311.04618v3 Announce Type: replace 
Abstract: When modeling a vector of risk variables, extreme scenarios are often of special interest. The peaks-over-thresholds method hinges on the notion that, asymptotically, the excesses over a vector of high thresholds follow a multivariate generalized Pareto distribution. However, existing literature has primarily concentrated on the setting when all risk variables are always large simultaneously. In reality, this assumption is often not met, especially in high dimensions.
  In response to this limitation, we study scenarios where distinct groups of risk variables may exhibit joint extremes while others do not. These discernible groups are derived from the angular measure inherent in the corresponding max-stable distribution, whence the term extreme direction. We explore such extreme directions within the framework of multivariate generalized Pareto distributions, with a focus on their probability density functions in relation to an appropriate dominating measure.
  Furthermore, we provide a stochastic construction that allows any prespecified set of risk groups to constitute the distribution's extreme directions. This construction takes the form of a smoothed max-linear model and accommodates the full spectrum of conceivable max-stable dependence structures. Additionally, we introduce a generic simulation algorithm tailored for multivariate generalized Pareto distributions, offering specific implementations for extensions of the logistic and H\"usler-Reiss families capable of carrying arbitrary extreme directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.04618v3</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Anas Mourahib, Anna Kiriliouk, Johan Segers</dc:creator>
    </item>
    <item>
      <title>Probability Tools for Sequential Random Projection</title>
      <link>https://arxiv.org/abs/2402.14026</link>
      <description>arXiv:2402.14026v3 Announce Type: replace 
Abstract: We introduce the first probabilistic framework tailored for sequential random projection, an approach rooted in the challenges of sequential decision-making under uncertainty. The analysis is complicated by the sequential dependence and high-dimensional nature of random variables, a byproduct of the adaptive mechanisms inherent in sequential decision processes. Our work features a novel construction of a stopped process, facilitating the analysis of a sequence of concentration events that are interconnected in a sequential manner. By employing the method of mixtures within a self-normalized process, derived from the stopped process, we achieve a desired non-asymptotic probability bound. This bound represents a non-trivial martingale extension of the Johnson-Lindenstrauss (JL) lemma, marking a pioneering contribution to the literature on random projection and sequential analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.14026v3</guid>
      <category>math.ST</category>
      <category>cs.DS</category>
      <category>cs.IT</category>
      <category>cs.NA</category>
      <category>math.IT</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yingru Li</dc:creator>
    </item>
    <item>
      <title>Optimal and instance-dependent guarantees for Markovian linear stochastic approximation</title>
      <link>https://arxiv.org/abs/2112.12770</link>
      <description>arXiv:2112.12770v2 Announce Type: replace-cross 
Abstract: We study stochastic approximation procedures for approximately solving a $d$-dimensional linear fixed point equation based on observing a trajectory of length $n$ from an ergodic Markov chain. We first exhibit a non-asymptotic bound of the order $t_{\mathrm{mix}} \tfrac{d}{n}$ on the squared error of the last iterate of a standard scheme, where $t_{\mathrm{mix}}$ is a mixing time. We then prove a non-asymptotic instance-dependent bound on a suitably averaged sequence of iterates, with a leading term that matches the local asymptotic minimax limit, including sharp dependence on the parameters $(d, t_{\mathrm{mix}})$ in the higher order terms. We complement these upper bounds with a non-asymptotic minimax lower bound that establishes the instance-optimality of the averaged SA estimator. We derive corollaries of these results for policy evaluation with Markov noise -- covering the TD($\lambda$) family of algorithms for all $\lambda \in [0, 1)$ -- and linear autoregressive models. Our instance-dependent characterizations open the door to the design of fine-grained model selection procedures for hyperparameter tuning (e.g., choosing the value of $\lambda$ when running the TD($\lambda$) algorithm).</description>
      <guid isPermaLink="false">oai:arXiv.org:2112.12770v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenlong Mou, Ashwin Pananjady, Martin J. Wainwright, Peter L. Bartlett</dc:creator>
    </item>
    <item>
      <title>Graphical models for cardinal paired comparisons data</title>
      <link>https://arxiv.org/abs/2401.07018</link>
      <description>arXiv:2401.07018v2 Announce Type: replace-cross 
Abstract: Graphical models for cardinal paired comparison data with and without covariates are rigorously analyzed. Novel, graph--based, necessary and sufficient conditions which guarantee strong consistency, asymptotic normality and the exponential convergence of the estimated ranks are emphasized. A complete theory for models with covariates is laid out. In particular conditions under which covariates can be safely omitted from the model are provided. The methodology is employed in the analysis of both finite and infinite sets of ranked items specifically in the case of large sparse comparison graphs. The proposed methods are explored by simulation and applied to the ranking of teams in the National Basketball Association (NBA).</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.07018v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rahul Singh, George Iliopoulos, Ori Davidov</dc:creator>
    </item>
    <item>
      <title>Characteristic Learning for Provable One Step Generation</title>
      <link>https://arxiv.org/abs/2405.05512</link>
      <description>arXiv:2405.05512v2 Announce Type: replace-cross 
Abstract: We propose the characteristic generator, a novel one-step generative model that combines the efficiency of sampling in Generative Adversarial Networks (GANs) with the stable performance of flow-based models. Our model is driven by characteristics, along which the probability density transport can be described by ordinary differential equations (ODEs). Specifically, We estimate the velocity field through nonparametric regression and utilize Euler method to solve the probability flow ODE, generating a series of discrete approximations to the characteristics. We then use a deep neural network to fit these characteristics, ensuring a one-step mapping that effectively pushes the prior distribution towards the target distribution. In the theoretical aspect, we analyze the errors in velocity matching, Euler discretization, and characteristic fitting to establish a non-asymptotic convergence rate for the characteristic generator in 2-Wasserstein distance. To the best of our knowledge, this is the first thorough analysis for simulation-free one step generative models. Additionally, our analysis refines the error analysis of flow-based generative models in prior works. We apply our method on both synthetic and real datasets, and the results demonstrate that the characteristic generator achieves high generation quality with just a single evaluation of neural network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.05512v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhao Ding, Chenguang Duan, Yuling Jiao, Ruoxuan Li, Jerry Zhijian Yang, Pingwen Zhang</dc:creator>
    </item>
  </channel>
</rss>
