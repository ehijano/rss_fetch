<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 08 Oct 2024 03:20:12 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Dynamic Road Management in the Era of CAV</title>
      <link>https://arxiv.org/abs/2410.02785</link>
      <description>arXiv:2410.02785v1 Announce Type: new 
Abstract: Traffic management and on-road safety have been a concern for the transportation authorities and the engineering communities for many years. Most of the implemented technologies for intelligent highways focus on safety measures and increased driver awareness, and expect a centralized management for the vehicular traffic flow. Leveraging recent advances in wireless communication, researchers have proposed solutions based on vehicle-to-vehicle (V2V) and vehicle-to-Infrastructure (V2I) communication in order to detect traffic jams and better disseminate data from on-road and on-vehicle sensors. Moreover, the development of connected autonomous vehicles (CAV) have motivated a paradigm shift in how traffic will be managed. Overall, these major technological advances have motivated the notion of dynamic traffic management (DTM), where smart road reconfiguration capabilities, e.g., dynamic lane reversal, adaptive traffic light timing, etc. will be exploited in real-time to improve traffic flow and adapt to unexpected incidents. This chapter discusses what the challenges in realizing DTM are and covers how CAV has revolutionized traffic management. Moreover, we highlight the issues for handling human-driven vehicles while roads are transitioning to CAV only traffic. Particularly, we articulate a new vision for inter-vehicle communication and assessment of road conditions, and promote a novel system for traffic management. Vehicle to on-road sensors as well as inter-vehicle connectivity will be enabled through the use of handheld devices such as smartphones. This not only enables real-time data sharing but also expedites the adoption of DTM without awaiting the dominant presence of autonomous vehicle on the road. ...</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02785v1</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1201/9780429329401-5</arxiv:DOI>
      <arxiv:journal_reference>Connected and Autonomous Vehicles in Smart Cities. CRC Press, 2020. 133-172</arxiv:journal_reference>
      <dc:creator>Mohamed Younis, Sookyoung Lee, Wassila Lalouani, Dayuan Tan, Sanket Gupte</dc:creator>
    </item>
    <item>
      <title>Digital Twin for O-RAN Towards 6G</title>
      <link>https://arxiv.org/abs/2410.02954</link>
      <description>arXiv:2410.02954v1 Announce Type: new 
Abstract: In future wireless systems of beyond 5G and 6G, addressing diverse applications with varying quality requirements is essential. Open Radio Access Network (O-RAN) architectures offer the potential for dynamic resource adaptation based on traffic demands. However, achieving real-time resource orchestration remains a challenge. Simultaneously, Digital Twin (DT) technology holds promise for testing and analysing complex systems, offering a unique platform for addressing dynamic operation and automation in O-RAN architectures. Yet, developing DTs for complex 5G/6G networks poses challenges, including data exchanges, ML model training data availability, network dynamics, processing power limitations, interdisciplinary collaboration needs, and a lack of standardized methodologies. This paper provides an overview of Open RAN architecture, trend and challenges, proposing the DT concepts for O-RAN with solution examples showcasing its integration into the framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02954v1</guid>
      <category>cs.NI</category>
      <category>cs.ET</category>
      <category>eess.SP</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Huan X. Nguyen, Kexuan Sun, Duc To, Quoc-Tuan Vien, Tuan Anh Le</dc:creator>
    </item>
    <item>
      <title>Hybrid Centralized-Distributed Resource Allocation Based on Deep Reinforcement Learning for Cooperative D2D Communications</title>
      <link>https://arxiv.org/abs/2410.03177</link>
      <description>arXiv:2410.03177v1 Announce Type: new 
Abstract: Device-to-device (D2D) technology enables direct communication between adjacent devices within cellular networks. Due to its high data rate, low latency, and performance improvement in spectrum and energy efficiency, it has been widely investigated and applied as a critical technology in 5G New Radio (NR). In addition to conventional overlay and underlay D2D communications, cooperative D2D communication, which can achieve a win-win situation between cellular users (CUs) and D2D users (DUs) through cooperative relaying technique, has attracted extensive attention from academic and industrial circles in the past decade. This paper delves into optimizing joint spectrum allocation, power control, and link-matching between multiple CUs and DUs for cooperative D2D communications, using weighted sum energy efficiency (WSEE) as the performance metric to address the challenges of green communication and sustainable development. This integer programming problem can be decomposed into a classic weighted bipartite graph matching and a series of nonconvex spectrum allocation and power control problems between potentially matched cellular and D2D link pairs. To address this issue, we propose a hybrid centralized-distributed scheme based on deep reinforcement learning (DRL) and the Kuhn-Munkres (KM) algorithm. Leveraging the latter, the CUs and DUs autonomously optimize spectrum allocation and power control by only utilizing local information. Then, the base station (BS) determines the link matching. Simulation results reveal that it achieves near-optimal performance and significantly enhances the network convergence speed with low signaling overheads. In addition, we also propose and utilize cooperative link sets for corresponding D2D links to accelerate the proposed scheme and reduce signaling exchange further.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03177v1</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yang Yu, Xiaoqing Tang</dc:creator>
    </item>
    <item>
      <title>Tarzan: Passively-Learned Real-Time Rate Control for Video Conferencing</title>
      <link>https://arxiv.org/abs/2410.03339</link>
      <description>arXiv:2410.03339v1 Announce Type: new 
Abstract: Rate control algorithms are at the heart of video conferencing platforms, determining target bitrates that match dynamic network characteristics for high quality. Recent data-driven strategies have shown promise for this challenging task, but the performance degradation they introduce during training has been a nonstarter for many production services, precluding adoption. This paper aims to bolster the practicality of data-driven rate control by presenting an alternative avenue for experiential learning: leveraging purely existing telemetry logs produced by the incumbent algorithm in production. We observe that these logs contain effective decisions, although often at the wrong times or in the wrong order. To realize this approach despite the inherent uncertainty that log-based learning brings (i.e., lack of feedback for new decisions), our system, Tarzan, combines a variety of robust learning techniques (i.e., conservatively reasoning about alternate behavior to minimize risk and using a richer model formulation to account for environmental noise). Across diverse networks (emulated and real-world), Tarzan outperforms the widely deployed GCC algorithm, increasing average video bitrates by 15-39% while reducing freeze rates by 60-100%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03339v1</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Neil Agarwal, Rui Pan, Francis Y. Yan, Ravi Netravali</dc:creator>
    </item>
    <item>
      <title>Performance Analysis of 6TiSCH Networks Using Discrete Events Simulator</title>
      <link>https://arxiv.org/abs/2410.03383</link>
      <description>arXiv:2410.03383v2 Announce Type: new 
Abstract: The Internet of Things (IoT) empowers small devices to sense, react, and communicate, with applications ranging from smart ordinary household objects to complex industrial processes. To provide access to an increasing number of IoT devices, particularly in long-distance communication scenarios, a robust low-power wide area network (LPWAN) protocol becomes essential. A widely adopted protocol for this purpose is 6TiSCH, which builds upon the IEEE 802.15.4 standard. It introduces time-slotted channel hopping (TSCH) mode as a new medium access control (MAC) layer operating mode, in conjunction with IEEE 802.15.4g, which also defines both MAC and physical layer (PHY) layers and provides IPv6 connectivity for LPWAN. Notably, 6TiSCH has gained adoption in significant standards such as Wireless Intelligent Ubiquitous Networks (Wi-SUN). This study evaluates the scalability of 6TiSCH, with a focus on key parameters such as queue size, the maximum number of single-hop retries, and the slotframe length. Computational simulations were performed using an open-source simulator and obtained the following results: increasing the transmission queue size, along with adjusting the number of retries and slotframe length, leads to a reduction in the packet error rate (PER). Notably, the impact of the number of retries is particularly pronounced. Furthermore, the effect on latency varies based on the specific combination of these parameters as the network scales.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03383v2</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guilherme de Santi Peron, Marcos Eduardo Pivaro Monteiro, Jo\~ao Lu\'is Verdegay de Barros, Jamil Farhat, Glauber Brante</dc:creator>
    </item>
    <item>
      <title>Deep Reinforcement Learning for Delay-Optimized Task Offloading in Vehicular Fog Computin</title>
      <link>https://arxiv.org/abs/2410.03472</link>
      <description>arXiv:2410.03472v1 Announce Type: new 
Abstract: The imminent rise of autonomous vehicles (AVs) is revolutionizing the future of transport. The Vehicular Fog Computing (VFC) paradigm has emerged to alleviate the load of compute-intensive and delay-sensitive AV programs via task offloading to nearby vehicles. Effective VFC requires an intelligent and dy?namic offloading algorithm. As a result, this paper adapts Deep Reinforcement Learning (DRL) for VFC offloading. First, a simulation environment utilizing realistic hardware and task specifications, in addition to a novel vehicular movement model based on grid-planned cities, is created. Afterward, a DRL-based algorithm is trained and tested on the environment with the goal of minimizing global task delay. The DRL model displays impressive results, outperforming other greedy and conventional methods. The findings further demonstrate the effectiveness of the DRL model in minimizing queue congestion, especially when compared to traditional cloud computing methods that struggle to handle the demands of a large fleet of vehicles. This is corroborated by queuing theory, highlighting the self-scalability of the VFC-based DRL approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03472v1</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad Parsa Toopchinezhad, Mahmood Ahmadi</dc:creator>
    </item>
    <item>
      <title>AraSync: Precision Time Synchronization in Rural Wireless Living Lab</title>
      <link>https://arxiv.org/abs/2410.03583</link>
      <description>arXiv:2410.03583v1 Announce Type: new 
Abstract: Time synchronization is a critical component in network operation and management, and it is also required by Ultra-Reliable, Low-Latency Communications (URLLC) in next-generation wireless systems such as those of 5G, 6G, and Open RAN. In this context, we design and implement AraSync as an end-to-end time synchronization system in the ARA wireless living lab to enable advanced wireless experiments and applications involving stringent time constraints. We make use of Precision Time Protocol (PTP) at different levels to achieve synchronization accuracy in the order of nanoseconds. Along with fiber networks, AraSync enables time synchronization across the AraHaul wireless x-haul network consisting of long-range, high-capacity mmWave and microwave links. In this paper, we present the detailed design and implementation of AraSync, including its hardware and software components and the PTP network topology. Further, we experimentally characterize the performance of AraSync from spatial and temporal dimensions. Our measurement and analysis of the clock offset and mean path delay show the impact of the wireless channel and weather conditions on the PTP synchronization accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03583v1</guid>
      <category>cs.NI</category>
      <category>cs.PF</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3636534.3697318</arxiv:DOI>
      <dc:creator>Md Nadim, Taimoor Ul Islam, Salil Reddy, Tianyi Zhang, Zhibo Meng, Reshal Afzal, Sarath Babu, Arsalan Ahmad, Daji Qiao, Anish Arora, Hongwei Zhang</dc:creator>
    </item>
    <item>
      <title>Toward Adaptive Tracking and Communication via an Airborne Maneuverable Bi-Static ISAC System</title>
      <link>https://arxiv.org/abs/2410.02796</link>
      <description>arXiv:2410.02796v1 Announce Type: cross 
Abstract: In this letter, we propose an airborne maneuverable bi-static integrated sensing and communication system where both the transmitter and receiver are unmanned aerial vehicles. By timely forming a dynamic bi-static range based on the motion information of the target, such a system can provide an adaptive two dimensional tracking and communication services. Towards this end, a trajectory optimization problem for both transmits and receive UAV is formulated to achieve high-accurate motion state estimation by minimizing the time-variant Cramer Rao bound, subject to the sufficient communication signal-to-noise ratio to maintain communication channel prediction error. Then we develop an efficient approach based on the successive convex approximation technique and the S-procedure to address the problem. Numerical results demonstrate that our proposed airborne maneuverable bi-static ISAC system is able to obtain higher tracking accuracy compared with the static or semi-dynamic ISAC system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02796v1</guid>
      <category>eess.SP</category>
      <category>cs.ET</category>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mingliang Wei, Ruoguang Li, Li Wang, Lianming Xu, Zhu Han</dc:creator>
    </item>
    <item>
      <title>Probabilistic Allocation of Payload Code Rate and Header Copies in LR-FHSS Networks</title>
      <link>https://arxiv.org/abs/2410.03392</link>
      <description>arXiv:2410.03392v2 Announce Type: cross 
Abstract: We evaluate the performance of the LoRaWAN Long-Range Frequency Hopping Spread Spectrum (LR-FHSS) technique using a device-level probabilistic strategy for code rate and header replica allocation. Specifically, we investigate the effects of different header replica and code rate allocations at each end-device, guided by a probability distribution provided by the network server. As a benchmark, we compare the proposed strategy with the standardized LR-FHSS data rates DR8 and DR9. Our numerical results demonstrate that the proposed strategy consistently outperforms the DR8 and DR9 standard data rates across all considered scenarios. Notably, our findings reveal that the optimal distribution rarely includes data rate DR9, while data rate DR8 significantly contributes to the goodput and energy efficiency optimizations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03392v2</guid>
      <category>eess.SP</category>
      <category>cs.NI</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jamil de Araujo Farhat, Jean Michel de Souza Sant'Ana, Jo\~ao Luiz Rebelatto, Nurul Huda Mahmood, Gianni Pasolini, Richard Demo Souza</dc:creator>
    </item>
    <item>
      <title>Routing and Spectrum Allocation in Broadband Degenerate EPR-Pair Distribution</title>
      <link>https://arxiv.org/abs/2311.14613</link>
      <description>arXiv:2311.14613v4 Announce Type: replace 
Abstract: We investigate resource allocation for quantum entanglement distribution over an optical network. We characterize and model a network architecture that employs a single quasideterministic time-frequency heralded EPR-pair source, and develop a routing scheme for distributing entangled photon pairs over such a network. We focus on fairness in entanglement distribution, and compare both the performance of various spectrum allocation schemes as well as their Jain index.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.14613v4</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rohan Bali, Ashley Tittelbaugh, Shelbi L. Jenkins, Anuj Agrawal, Jerry Horgan, Marco Ruffini, Daniel Kilper, Boulat A. Bash</dc:creator>
    </item>
    <item>
      <title>Adversarial Challenges in Network Intrusion Detection Systems: Research Insights and Future Prospects</title>
      <link>https://arxiv.org/abs/2409.18736</link>
      <description>arXiv:2409.18736v2 Announce Type: replace-cross 
Abstract: Machine learning has brought significant advances in cybersecurity, particularly in the development of Intrusion Detection Systems (IDS). These improvements are mainly attributed to the ability of machine learning algorithms to identify complex relationships between features and effectively generalize to unseen data. Deep neural networks, in particular, contributed to this progress by enabling the analysis of large amounts of training data, significantly enhancing detection performance. However, machine learning models remain vulnerable to adversarial attacks, where carefully crafted input data can mislead the model into making incorrect predictions. While adversarial threats in unstructured data, such as images and text, have been extensively studied, their impact on structured data like network traffic is less explored. This survey aims to address this gap by providing a comprehensive review of machine learning-based Network Intrusion Detection Systems (NIDS) and thoroughly analyzing their susceptibility to adversarial attacks. We critically examine existing research in NIDS, highlighting key trends, strengths, and limitations, while identifying areas that require further exploration. Additionally, we discuss emerging challenges in the field and offer insights for the development of more robust and resilient NIDS. In summary, this paper enhances the understanding of adversarial attacks and defenses in NIDS and guide future research in improving the robustness of machine learning models in cybersecurity applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.18736v2</guid>
      <category>cs.CR</category>
      <category>cs.ET</category>
      <category>cs.NI</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sabrine Ennaji, Fabio De Gaspari, Dorjan Hitaj, Alicia K Bidi, Luigi V. Mancini</dc:creator>
    </item>
  </channel>
</rss>
