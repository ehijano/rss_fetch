<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cond-mat.dis-nn updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cond-mat.dis-nn</link>
    <description>cond-mat.dis-nn updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cond-mat.dis-nn" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 18 Oct 2024 04:03:52 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Three state random energy model</title>
      <link>https://arxiv.org/abs/2410.13444</link>
      <description>arXiv:2410.13444v1 Announce Type: new 
Abstract: We introduce a spin-1 version of the random energy model with crystal field. Crystal field controls the density of 0 spins in the system. We solve the model in the micro-canonincal ensemble. The model has a spin-glass transition at a finite temperature for all strengths of the crystal field. By introducing the magnetic field we also obtain the de Almeida Thouless line for the model. The spin-glass transition persists in the presence of external field. We also find that the magnetisation shows non-monotonic behaviour for high positive crystal field strengths. The zero magnetic field specific heat and magnetic susceptibility also exhibit a cusp beyond a threshold value of the crystal field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13444v1</guid>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator> Sumedha, Matteo Marsili</dc:creator>
    </item>
    <item>
      <title>L1-Regularized ICA: A Novel Method for Analysis of Task-related fMRI Data</title>
      <link>https://arxiv.org/abs/2410.13171</link>
      <description>arXiv:2410.13171v1 Announce Type: cross 
Abstract: We propose a new method of independent component analysis (ICA) in order to extract appropriate features from high-dimensional data. In general, matrix factorization methods including ICA have a problem regarding the interpretability of extracted features. For the improvement of interpretability, it is considered that sparse constraint on a factorized matrix is helpful. With this background, we construct a new ICA method with sparsity. In our method, the L1-regularization term is added to the cost function of ICA, and minimization of the cost function is performed by difference of convex functions algorithm. For the validity of our proposed method, we apply it to synthetic data and real functional magnetic resonance imaging data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13171v1</guid>
      <category>stat.ML</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1162/neco_a_01709</arxiv:DOI>
      <arxiv:journal_reference>Neural Computation (2024) 36 (11) 2540-2570</arxiv:journal_reference>
      <dc:creator>Yusuke Endo, Koujin Takeda</dc:creator>
    </item>
    <item>
      <title>A theoretical perspective on mode collapse in variational inference</title>
      <link>https://arxiv.org/abs/2410.13300</link>
      <description>arXiv:2410.13300v1 Announce Type: cross 
Abstract: While deep learning has expanded the possibilities for highly expressive variational families, the practical benefits of these tools for variational inference (VI) are often limited by the minimization of the traditional Kullback-Leibler objective, which can yield suboptimal solutions. A major challenge in this context is \emph{mode collapse}: the phenomenon where a model concentrates on a few modes of the target distribution during training, despite being statistically capable of expressing them all. In this work, we carry a theoretical investigation of mode collapse for the gradient flow on Gaussian mixture models. We identify the key low-dimensional statistics characterizing the flow, and derive a closed set of low-dimensional equations governing their evolution. Leveraging this compact description, we show that mode collapse is present even in statistically favorable scenarios, and identify two key mechanisms driving it: mean alignment and vanishing weight. Our theoretical findings are consistent with the implementation of VI using normalizing flows, a class of popular generative models, thereby offering practical insights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13300v1</guid>
      <category>stat.ML</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roman Soletskyi, Marylou Gabri\'e, Bruno Loureiro</dc:creator>
    </item>
    <item>
      <title>Rapid and Automated Alloy Design with Graph Neural Network-Powered LLM-Driven Multi-Agent Systems</title>
      <link>https://arxiv.org/abs/2410.13768</link>
      <description>arXiv:2410.13768v1 Announce Type: cross 
Abstract: A multi-agent AI model is used to automate the discovery of new metallic alloys, integrating multimodal data and external knowledge including insights from physics via atomistic simulations. Our multi-agent system features three key components: (a) a suite of LLMs responsible for tasks such as reasoning and planning, (b) a group of AI agents with distinct roles and expertise that dynamically collaborate, and (c) a newly developed graph neural network (GNN) model for rapid retrieval of key physical properties. A set of LLM-driven AI agents collaborate to automate the exploration of the vast design space of MPEAs, guided by predictions from the GNN. We focus on the NbMoTa family of body-centered cubic (bcc) alloys, modeled using an ML-based interatomic potential, and target two key properties: the Peierls barrier and solute/screw dislocation interaction energy. Our GNN model accurately predicts these atomic-scale properties, providing a faster alternative to costly brute-force calculations and reducing the computational burden on multi-agent systems for physics retrieval. This AI system revolutionizes materials discovery by reducing reliance on human expertise and overcoming the limitations of direct all-atom simulations. By synergizing the predictive power of GNNs with the dynamic collaboration of LLM-based agents, the system autonomously navigates vast alloy design spaces, identifying trends in atomic-scale material properties and predicting macro-scale mechanical strength, as demonstrated by several computational experiments. This approach accelerates the discovery of advanced alloys and holds promise for broader applications in other complex systems, marking a significant step forward in automated materials design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13768v1</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.mes-hall</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alireza Ghafarollahi, Markus J. Buehler</dc:creator>
    </item>
    <item>
      <title>Probing the Latent Hierarchical Structure of Data via Diffusion Models</title>
      <link>https://arxiv.org/abs/2410.13770</link>
      <description>arXiv:2410.13770v1 Announce Type: cross 
Abstract: High-dimensional data must be highly structured to be learnable. Although the compositional and hierarchical nature of data is often put forward to explain learnability, quantitative measurements establishing these properties are scarce. Likewise, accessing the latent variables underlying such a data structure remains a challenge. In this work, we show that forward-backward experiments in diffusion-based models, where data is noised and then denoised to generate new samples, are a promising tool to probe the latent structure of data. We predict in simple hierarchical models that, in this process, changes in data occur by correlated chunks, with a length scale that diverges at a noise level where a phase transition is known to take place. Remarkably, we confirm this prediction in both text and image datasets using state-of-the-art diffusion models. Our results show how latent variable changes manifest in the data and establish how to measure these effects in real data using diffusion models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13770v1</guid>
      <category>stat.ML</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.LG</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Antonio Sclocchi, Alessandro Favero, Noam Itzhak Levi, Matthieu Wyart</dc:creator>
    </item>
    <item>
      <title>Neural Network Quantum States for the Interacting Hofstadter Model with Higher Local Occupations and Long-Range Interactions</title>
      <link>https://arxiv.org/abs/2405.04472</link>
      <description>arXiv:2405.04472v2 Announce Type: replace 
Abstract: Due to their immense representative power, neural network quantum states (NQS) have gained significant interest in current research. In recent advances in the field of NQS, it has been demonstrated that this approach can compete with state-of-the-art numerical techniques, making NQS a compelling alternative, in particular for the simulation of large, two-dimensional quantum systems. In this study, we show that recurrent neural network (RNN) wave functions can be employed to study systems relevant to current research in quantum many-body physics. Specifically, we employ a 2D tensorized gated RNN to explore the bosonic Hofstadter model with a variable local Hilbert space cut-off and long-range interactions. At first, we benchmark the RNN-NQS for the Hofstadter-Bose-Hubbard (HBH) Hamiltonian on a square lattice. We find that this method is, despite the complexity of the wave function, capable of efficiently identifying and representing most ground state properties. Afterwards, we apply the method to an even more challenging model for current methods, namely the Hofstadter model with long-range interactions. This model describes Rydberg-dressed atoms on a lattice subject to a synthetic magnetic field. We study systems of size up to $12 \times 12$ sites and identify three different regimes by tuning the interaction range and the filling fraction $\nu$. In addition to phases known from the HBH model at short-ranged interaction, we observe bubble crystals and Wigner crystals for long-ranged interactions. Especially interesting is the evidence of a bubble crystal phase on a lattice, as this gives experiments a starting point for the search of clustered liquid phases, possibly hosting non-Abelian anyon excitations. In our work we show that NQS are an efficient and reliable simulation method for quantum systems, which are the subject of current research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04472v2</guid>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.mes-hall</category>
      <category>cond-mat.quant-gas</category>
      <category>cond-mat.str-el</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fabian D\"oschl, Felix A. Palm, Hannah Lange, Fabian Grusdt, Annabelle Bohrdt</dc:creator>
    </item>
    <item>
      <title>Feature learning in finite-width Bayesian deep linear networks with multiple outputs and convolutional layers</title>
      <link>https://arxiv.org/abs/2406.03260</link>
      <description>arXiv:2406.03260v2 Announce Type: replace-cross 
Abstract: Deep linear networks have been extensively studied, as they provide simplified models of deep learning. However, little is known in the case of finite-width architectures with multiple outputs and convolutional layers. In this manuscript, we provide rigorous results for the statistics of functions implemented by the aforementioned class of networks, thus moving closer to a complete characterization of feature learning in the Bayesian setting. Our results include: (i) an exact and elementary non-asymptotic integral representation for the joint prior distribution over the outputs, given in terms of a mixture of Gaussians; (ii) an analytical formula for the posterior distribution in the case of squared error loss function (Gaussian likelihood); (iii) a quantitative description of the feature learning infinite-width regime, using large deviation theory. From a physical perspective, deep architectures with multiple outputs or convolutional layers represent different manifestations of kernel shape renormalization, and our work provides a dictionary that translates this physics intuition and terminology into rigorous Bayesian statistics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03260v2</guid>
      <category>stat.ML</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Federico Bassetti, Marco Gherardi, Alessandro Ingrosso, Mauro Pastore, Pietro Rotondo</dc:creator>
    </item>
    <item>
      <title>Fragility of Chess positions: measure, universality and tipping points</title>
      <link>https://arxiv.org/abs/2410.02333</link>
      <description>arXiv:2410.02333v2 Announce Type: replace-cross 
Abstract: We introduce a novel metric to quantify the fragility of chess positions using the interaction graph of pieces. This fragility score $F$ captures the tension within a position and serves as a strong indicator of tipping points in a game. In well-known games, maximum fragility often aligns with decisive moments marked by brilliant moves. Analyzing a large dataset of games, we find that fragility typically peaks around move $15$, with pawns ($\approx 60\%$) and knights ($\approx 20\%$) frequently involved in high-tension positions. Remarkably, average fragility curves show a universal pattern across a wide range of players, games, and openings, with a subtle deviation observed in games played by the engine Stockfish. Our analysis reveals a gradual buildup of fragility starting around $8$ moves before the peak, followed by a prolonged fragile state lasting up to $15$ moves. This suggests a gradual intensification of positional tension leading to decisive moments in the game. These insights offer a valuable tool for both players and engines to assess critical moments in chess.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02333v2</guid>
      <category>physics.soc-ph</category>
      <category>cond-mat.dis-nn</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marc Barthelemy</dc:creator>
    </item>
  </channel>
</rss>
