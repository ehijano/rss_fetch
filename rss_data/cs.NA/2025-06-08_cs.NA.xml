<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NA</link>
    <description>cs.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 09 Jun 2025 04:04:42 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Approximation of the Pseudospectral Abscissa via Eigenvalue Perturbation Theory</title>
      <link>https://arxiv.org/abs/2506.05535</link>
      <description>arXiv:2506.05535v1 Announce Type: new 
Abstract: Reliable and efficient computation of the pseudospectral abscissa in the large-scale setting is still not settled. Unlike the small-scale setting where there are globally convergent criss-cross algorithms, all algorithms in the large-scale setting proposed to date are at best locally convergent. We first describe how eigenvalue perturbation theory can be put in use to estimate the globally rightmost point in the $\epsilon$-pseudospectrum if $\epsilon$ is small. Our treatment addresses both general nonlinear eigenvalue problems, and the standard eigenvalue problem as a special case. For small $\epsilon$, the estimates by eigenvalue perturbation theory are quite accurate. In the standard eigenvalue case, we even derive a formula with an ${\mathcal O}(\epsilon^3)$ error. For larger $\epsilon$, the estimates can be used to initialize the locally convergent algorithms. We also propose fixed-point iterations built on the the perturbation theory ideas for large $\epsilon$ that are suitable for the large-scale setting. The proposed fixed-point iterations initialized by using eigenvalue perturbation theory converge to the globally rightmost point in the pseudospectrum in a vast majority of the cases that we experiment with.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05535v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Waqar Ahmed, Emre Mengi</dc:creator>
    </item>
    <item>
      <title>ShyLU node: On-node Scalable Solvers and Preconditioners Recent Progresses and Current Performance</title>
      <link>https://arxiv.org/abs/2506.05793</link>
      <description>arXiv:2506.05793v1 Announce Type: new 
Abstract: ShyLU-node is an open-source software package that implements linear solvers and preconditioners on shared-memory multicore CPUs or on a GPU. It is part of the Trilinos software framework and designed to provide a robust and efficient solution of large-scale linear systems from real-world applications on the current and emerging computers. In this paper, we discuss two sparse direct solvers, Basker and Tacho, and an algebraic preconditioner, FastILU, in ShyLU-node package. These ShyLU solvers and preconditioner can be used as a stand-alone global problem solver, as a local subdomain solver for domain decomposition (DD) preconditioner, or as the coarse-problem solver in algebraic multi-grid preconditioner. We present performance results with the sparse direct solvers for real application problems, namely, Basker for Xyce Circuit Simulations and Tacho for Albany Land-Ice Simulation of Antarctica. FastILU has been also used in real-world applications, but in this paper, we illustrate its performance using 3D model problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05793v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ichitaro Yamazaki, Nathan Ellingwood, Sivasankaran Rajamanickam</dc:creator>
    </item>
    <item>
      <title>Inf-sup stable space-time discretization of the wave equation based on a first-order-in-time variational formulation</title>
      <link>https://arxiv.org/abs/2506.05886</link>
      <description>arXiv:2506.05886v1 Announce Type: new 
Abstract: In this paper, we present a conforming space-time discretization of the wave equation based on a first-order-in-time variational formulation with exponential weights in time. We analyze the method, showing its stability without imposing any restrictions on the mesh size or time step, and proving quasi-optimal convergence for any choice of space-time tensor product discrete spaces that satisfies standard approximation assumptions. Numerical examples are provided to support the theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05886v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Matteo Ferrari, Ilaria Perugia, Enrico Zampa</dc:creator>
    </item>
    <item>
      <title>Sequential Monte Carlo approximations of Wasserstein--Fisher--Rao gradient flows</title>
      <link>https://arxiv.org/abs/2506.05905</link>
      <description>arXiv:2506.05905v1 Announce Type: cross 
Abstract: We consider the problem of sampling from a probability distribution $\pi$. It is well known that this can be written as an optimisation problem over the space of probability distribution in which we aim to minimise the Kullback--Leibler divergence from $\pi$. We consider several partial differential equations (PDEs) whose solution is a minimiser of the Kullback--Leibler divergence from $\pi$ and connect them to well-known Monte Carlo algorithms. We focus in particular on PDEs obtained by considering the Wasserstein--Fisher--Rao geometry over the space of probabilities and show that these lead to a natural implementation using importance sampling and sequential Monte Carlo. We propose a novel algorithm to approximate the Wasserstein--Fisher--Rao flow of the Kullback--Leibler divergence which empirically outperforms the current state-of-the-art.
  We study tempered versions of these PDEs obtained by replacing the target distribution with a geometric mixture of initial and target distribution and show that these do not lead to a convergence speed up.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05905v1</guid>
      <category>stat.ME</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Francesca R. Crucinio, Sahani Pathiraja</dc:creator>
    </item>
    <item>
      <title>Antithetic Noise in Diffusion Models</title>
      <link>https://arxiv.org/abs/2506.06185</link>
      <description>arXiv:2506.06185v1 Announce Type: cross 
Abstract: We initiate a systematic study of antithetic initial noise in diffusion models. Across unconditional models trained on diverse datasets, text-conditioned latent-diffusion models, and diffusion-posterior samplers, we find that pairing each initial noise with its negation consistently yields strongly negatively correlated samples. To explain this phenomenon, we combine experiments and theoretical analysis, leading to a symmetry conjecture that the learned score function is approximately affine antisymmetric (odd symmetry up to a constant shift), and provide evidence supporting it. Leveraging this negative correlation, we enable two applications: (1) enhancing image diversity in models like Stable Diffusion without quality loss, and (2) sharpening uncertainty quantification (e.g., up to 90% narrower confidence intervals) when estimating downstream statistics. Building on these gains, we extend the two-point pairing to a randomized quasi-Monte Carlo estimator, which further improves estimation accuracy. Our framework is training-free, model-agnostic, and adds no runtime overhead.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.06185v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jing Jia, Sifan Liu, Bowen Song, Wei Yuan, Liyue Shen, Guanyang Wang</dc:creator>
    </item>
    <item>
      <title>On the stability analysis of perfectly matched layer for the elastic wave equation in layered media</title>
      <link>https://arxiv.org/abs/2210.00229</link>
      <description>arXiv:2210.00229v3 Announce Type: replace 
Abstract: In this paper, we present the stability analysis of the perfectly matched layer (PML) in two-space dimensional layered elastic media. Using normal mode analysis we prove that all interface wave modes present at a planar interface of bi-material elastic solids are dissipated by the PML. Our analysis builds upon the ideas presented in [SIAM Journal on Numerical Analysis 52 (2014) 2883-2904] and extends the stability results of boundary waves (such as Rayleigh waves) on a half-plane elastic solid to interface wave modes (such as Stoneley waves) transmitted into the PML at a planar interface separating two half-plane elastic solids. Numerical experiments in two-layer and multi-layer elastic solids corroborate the theoretical analysis, and generalise the results to complex elastic media. Numerical examples using the Marmousi model demonstrates the utility of the PML and our numerical method for seismological applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.00229v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kenneth Duru, Balaje Kalyanaraman, Siyang Wang</dc:creator>
    </item>
    <item>
      <title>Spatiotemporal evolution of PM2.5 diffusion in Cheng-Yu urban agglomeration in response to COVID-19 lockdown using complex network</title>
      <link>https://arxiv.org/abs/2406.01502</link>
      <description>arXiv:2406.01502v2 Announce Type: replace 
Abstract: As the decrease in human activities resulting from the COVID-19 control measures had a significant impact on air quality, the epidemic provided an opportunity to investigate the extent to which air pollution is influenced by human activities and review existing measures. However, the corresponding diffusion pattern on a city scale is seldom mentioned at present stage, therefore, we chose the Cheng-Yu urban agglomeration, which is the largest city cluster in Southwest China, as our study area during the COVID-19 period, and attempted to investigate the process of PM2.5 diffusion using a complex network method. The results displayed that there was an evident external spillover effect of PM2.5 across all regions, and the PM2.5 spillovers were concentrated in several cities in the Cheng-Yu urban agglomeration during the lockdown period, whereas they are more dispersed during the recovery period. The overall decline in the impact of PM2.5 pollution source areas on receptor areas from a normal year to the pandemic year, and the intensity of PM2.5 spillover decreases gradually as the distance from the center increases. The implementation of the lockdown measures had an impact on both the input and output patterns of PM2.5 pollution in the region, the input pattern of PM2.5 pollution exhibited higher vulnerability, while the output pattern showed higher resilience. Additionally, the spillover relationship of PM2.5 pollution varies between different blocks, with relatively simple spillover relationships observed during the lockdown period and more complex dynamics during the recovery period. These findings have highlighted the importance of joint controls in combating regional air pollution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01502v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.soc-ph</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiaxian Huang, Yi Huang, Yong Zhang, Jiao Zhang</dc:creator>
    </item>
    <item>
      <title>Some remarks on regularized Shannon sampling formulas</title>
      <link>https://arxiv.org/abs/2407.16401</link>
      <description>arXiv:2407.16401v2 Announce Type: replace 
Abstract: The fast reconstruction of a bandlimited function from its sample data is an essential problem in signal processing. In this paper, we consider the widely used Gaussian regularized Shannon sampling formula in comparison to regularized Shannon sampling formulas employing alternative window functions, such as the sinh-type window function and the continuous Kaiser-Bessel window function. It is shown that the approximation errors of these regularized Shannon sampling formulas possess an exponential decay with respect to the truncation parameter. The main focus of this work is to address minor gaps in preceding papers and rigorously prove assumptions that were previously based solely on numerical tests. In doing so, we demonstrate that the sinh-type regularized Shannon sampling formula has the same exponential decay as the continuous Kaiser-Bessel regularized Shannon sampling formula, but both have twice the exponential decay of the Gaussian regularized Shannon sampling formula. Additionally, numerical experiments illustrate the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16401v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Melanie Kircheis, Daniel Potts, Manfred Tasche</dc:creator>
    </item>
    <item>
      <title>A Hybrid Iterative Neural Solver Based on Spectral Analysis for Parametric PDEs</title>
      <link>https://arxiv.org/abs/2408.08540</link>
      <description>arXiv:2408.08540v3 Announce Type: replace 
Abstract: Deep learning-based hybrid iterative methods (DL-HIM) have emerged as a promising approach for designing fast neural solvers to tackle large-scale sparse linear systems. DL-HIM combine the smoothing effect of simple iterative methods with the spectral bias of neural networks, which allows them to effectively eliminate both high-frequency and low-frequency error components. However, their efficiency may decrease if simple iterative methods can not provide effective smoothing, making it difficult for the neural network to learn mid-frequency and high-frequency components. This paper first conducts a convergence analysis for general DL-HIM from a spectral viewpoint, concluding that under reasonable assumptions, DL-HIM exhibit a convergence rate independent of grid size $h$ and physical parameters $\boldsymbol{\mu}$. To meet these assumptions, we design a neural network from an eigen perspective, focusing on learning the eigenvalues and eigenvectors corresponding to error components that simple iterative methods struggle to eliminate. Specifically, the eigenvalues are learned by a meta subnet, while the eigenvectors are approximated using Fourier modes with a transition matrix provided by another meta subnet. The resulting DL-HIM, termed the Fourier Neural Solver (FNS), can be trained to achieve a convergence rate independent of PDE parameters and grid size within a local neighborhood of the training scale by designing a loss function that ensures the neural network complements the smoothing effect of the damped Jacobi iterative methods. We verify the performance of FNS on five types of linear parametric PDEs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08540v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chen Cui, Kai Jiang, Yun Liu, Shi Shu</dc:creator>
    </item>
    <item>
      <title>Subspace correction methods for semicoercive and nearly semicoercive convex optimization with applications to nonlinear PDEs</title>
      <link>https://arxiv.org/abs/2412.17318</link>
      <description>arXiv:2412.17318v2 Announce Type: replace 
Abstract: We present new convergence analyses for subspace correction methods for semicoercive and nearly semicoercive convex optimization problems, generalizing the theory of singular and nearly singular linear problems to the nonlinear domain. Our results demonstrate that the elegant theoretical framework developed for singular and nearly singular linear problems can be extended to semicoercive and nearly semicoercive convex optimization problems. For semicoercive problems, we show that the convergence rate can be estimated in terms of a seminorm stable decomposition over the subspaces and the kernel of the problem, aligning with the theory for singular linear problems. For nearly semicoercive problems, we establish a parameter-independent convergence rate, assuming the kernel of the semicoercive part can be decomposed into a sum of local kernels, which aligns with the theory for nearly singular problems. To demonstrate the applicability of our results, we provide convergence analyses of two-level additive Schwarz methods for solving a nonlinear Neumann boundary value problem and its perturbation within the proposed abstract framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17318v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Young-Ju Lee, Jongho Park</dc:creator>
    </item>
    <item>
      <title>Computing accurate eigenvalues using a mixed-precision Jacobi algorithm</title>
      <link>https://arxiv.org/abs/2501.03742</link>
      <description>arXiv:2501.03742v3 Announce Type: replace 
Abstract: We provide a rounding error analysis of a mixed-precision preconditioned Jacobi algorithm, which uses low precision to compute the preconditioner, applies it at high precision (amounting to two matrix-matrix multiplications) and solves the eigenproblem using the Jacobi algorithm at working precision. Our analysis yields meaningfully smaller relative forward error bounds for the computed eigenvalues compared with those of the Jacobi algorithm. We further prove that, after preconditioning, if the off-diagonal entries of the preconditioned matrix are sufficiently small relative to its smallest diagonal entry, the relative forward error bound is independent of the condition number of the original matrix. We present two constructions for the preconditioner that exploit low precision, along with their error analyses. Our numerical experiments confirm our theoretical results and compare the relative forward error of the proposed algorithm with the Jacobi algorithm, a preconditioned Jacobi algorithm, and MATLAB's $\texttt{eig}$ function. Timings using Julia suggest that the dominant cost of obtaining this level of accuracy comes from the high precision matrix-matrix multiplies; if support in software or hardware for this were improved then this would become a negligible cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03742v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Nicholas J. Higham, Fran\c{c}oise Tisseur, Marcus Webb, Zhengbo Zhou</dc:creator>
    </item>
    <item>
      <title>The Akhiezer iteration and inverse-free solvers for Sylvester matrix equations</title>
      <link>https://arxiv.org/abs/2503.17496</link>
      <description>arXiv:2503.17496v2 Announce Type: replace 
Abstract: Two inverse-free iterative methods are developed for solving Sylvester matrix equations when the spectra of the coefficient matrices are on, or near, known disjoint subintervals of the real axis. Both methods use the recently-introduced Akhiezer iteration: one to address an equivalent problem of approximating the matrix sign function applied to a block matrix and the other to directly approximate the inverse of the Sylvester operator. In each case this results in provable and computable geometric rates of convergence. When the right-hand side matrix is low rank, both methods require only low-rank matrix-matrix products. Relative to existing approaches, the methods presented here can be more efficient and require less storage when the coefficient matrices are dense or otherwise costly to invert. Applications include solving partial differential equations and computing Fr\'echet derivatives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17496v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cade Ballew, Thomas Trogdon, Heather Wilber</dc:creator>
    </item>
    <item>
      <title>Global approximation to the Boys functions for vectorized computation</title>
      <link>https://arxiv.org/abs/2504.07637</link>
      <description>arXiv:2504.07637v2 Announce Type: replace 
Abstract: A fast approximation to the Boys functions (related to the lower incomplete gamma function of half-integer parameter) by a single closed-form analytical expression for all argument values have been developed and tested. Besides the exponential function needed anyway for downward recursion, it uses a small number of addition, multiplication, division, and square root operations, and thus is straightforward to vectorize.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.07637v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dimitri N. Laikov</dc:creator>
    </item>
    <item>
      <title>Local Taylor-based polynomial quasi-Trefftz spaces for scalar linear equations</title>
      <link>https://arxiv.org/abs/2505.18480</link>
      <description>arXiv:2505.18480v2 Announce Type: replace 
Abstract: Trefftz-type of Galerkin methods for numerical PDEs use discrete spaces of problem-dependent functions. While Trefftz methods leverage discrete spaces of local exact solutions to the governing PDE, Taylor-based quasi-Trefftz methods leverage discrete spaces of local approximate solutions to the governing PDE. This notion of approximate solution, understood in the sense of a small Taylor remainder, is defined for differential operators with smooth variable coefficients. In both cases, it is possible to use discrete spaces much smaller than standard polynomial space to achieve the same orders of approximation properties.
  The present work is the first systematic study of local Taylor-based polynomial quasi-Trefftz spaces characterized as the kernel of the quasi-Trefftz operator, defined as the composition of Taylor truncation with the differential operator. The proposed linear algebra framework reveals the general structure of this linear operator and applies to any non-trivial linear scalar differential operator with smooth coefficients. It results in a fully explicit procedure to construct a local quasi-Trefftz basis valid in all dimension and for operators of any order, guaranteeing a minimal computational cost for the construction of these equation-dependent bases.
  The local quasi-Trefftz space is formally defined as the kernel of a linear operator between spaces of polynomials. The systematic approach relies on a detailed study of the structure of this operator, strongly leveraging the graded structure of polynomial spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18480v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Lise-Marie Imbert-Gerard</dc:creator>
    </item>
    <item>
      <title>Covering Number of Real Algebraic Varieties and Beyond: Improved Bounds and Applications</title>
      <link>https://arxiv.org/abs/2311.05116</link>
      <description>arXiv:2311.05116v4 Announce Type: replace-cross 
Abstract: Covering numbers are a powerful tool used in the development of approximation algorithms, randomized dimension reduction methods, smoothed complexity analysis, and others. In this paper we prove upper bounds on the covering number of numerous sets in Euclidean space, namely real algebraic varieties, images of polynomial maps and semialgebraic sets in terms of the number of variables and degrees of the polynomials involved. The bounds remarkably improve the best known general bound by Yomdin-Comte, and our proof is much more straightforward. In particular, our result gives new bounds on the volume of the tubular neighborhood of the image of a polynomial map and a semialgebraic set, where results for varieties by Lotz and Basu-Lerario are not directly applicable. We illustrate the power of the result on three computational applications. Firstly, we derive a near-optimal bound on the covering number of tensors with low canonical polyadic (CP) rank, quantifying their approximation properties and filling in an important missing piece of theory for tensor dimension reduction and reconstruction. Secondly, we prove a bound on dimensionality reduction of images of polynomial maps via randomized sketching, which has direct applications to large scale polynomial optimization. Finally, we deduce generalization error bounds for deep neural networks with rational or ReLU activation functions, improving or matching the best known results in the machine learning literature while helping to quantify the impact of architecture choice on generalization error.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.05116v4</guid>
      <category>math.AG</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yifan Zhang, Joe Kileel</dc:creator>
    </item>
    <item>
      <title>The spectral map for weighted Cauchy matrices is an involution</title>
      <link>https://arxiv.org/abs/2504.18707</link>
      <description>arXiv:2504.18707v2 Announce Type: replace-cross 
Abstract: Let $N$ be a natural number. We consider weighted Cauchy matrices of the form \[ \mathcal{C}_{a,A}=\left\{\frac{\sqrt{A_j A_k}}{a_k+a_j}\right\}_{j,k=1}^N, \] where $A_1,\dots,A_N$ are positive real numbers and $a_1,\dots,a_N$ are distinct positive real numbers, listed in increasing order. Let $b_1,\dots,b_N$ be the eigenvalues of $\mathcal{C}_{a,A}$, listed in increasing order. Let $B_k$ be positive real numbers such that $\sqrt{B_k}$ is the Euclidean norm of the orthogonal projection of the vector \[ v_A=(\sqrt{A_1},\dots,\sqrt{A_N}) \] onto the $k$'th eigenspace of $\mathcal{C}_{a,A}$. We prove that the spectral map $(a,A)\mapsto (b,B)$ is an involution and discuss simple properties of this map.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18707v2</guid>
      <category>math.RA</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Pushnitski, Sergei Treil</dc:creator>
    </item>
    <item>
      <title>GPU-Parallelizable Randomized Sketch-and-Precondition for Linear Regression using Sparse Sign Sketches</title>
      <link>https://arxiv.org/abs/2506.03070</link>
      <description>arXiv:2506.03070v2 Announce Type: replace-cross 
Abstract: A litany of theoretical and numerical results have established the sketch-and-precondition paradigm as a powerful approach to solving large linear regression problems in standard computing environments. Perhaps surprisingly, much less work has been done on understanding how sketch-and-precondition performs on graphics processing unit (GPU) systems. We address this gap by benchmarking an implementation of sketch-and-precondition based on sparse sign-sketches on single and multi-GPU systems. In doing so, we describe a novel, easily parallelized, rejection-sampling based method for generating sparse sign sketches. Our approach, which is particularly well-suited for GPUs, is easily adapted to a variety of computing environments. Taken as a whole, our numerical experiments indicate that sketch-and-precondition with sparse sign sketches is particularly well-suited for GPUs, and may be suitable for use in black-box least-squares solvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03070v2</guid>
      <category>cs.DS</category>
      <category>cs.DC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tyler Chen, Pradeep Niroula, Archan Ray, Pragna Subrahmanya, Marco Pistoia, Niraj Kumar</dc:creator>
    </item>
    <item>
      <title>GP-Recipe: Gaussian Process approximation to linear operations in numerical methods</title>
      <link>https://arxiv.org/abs/2506.03471</link>
      <description>arXiv:2506.03471v2 Announce Type: replace-cross 
Abstract: We introduce new Gaussian Process (GP) high-order approximations to linear operations that are frequently used in various numerical methods. Our method employs the kernel-based GP regression modeling, a non-parametric Bayesian approach to regression that operates on the probability distribution over all admissible functions that fit observed data. We begin in the first part with discrete data approximations to various linear operators applied to smooth data using the most popular squared exponential kernel function. In the second part, we discuss data interpolation across discontinuities with sharp gradients, for which we introduce a new GP kernel that fits discontinuous data without oscillations. The current study extends our previous GP work on polynomial-free shock-capturing methods in finite difference and finite volume methods to a suite of linear operator approximations on smooth data. The formulations introduced in this paper can be readily adopted in daily practices in numerical methods, including numerical approximations of finite differences, quadrature rules, interpolations, and reconstructions, which are most frequently used in numerical modeling in modern science and engineering applications. In the test problems, we demonstrate that the GP approximated solutions feature improved solution accuracy compared to the conventional finite-difference counterparts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03471v2</guid>
      <category>physics.comp-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christopher DeGrendele, Dongwook Lee</dc:creator>
    </item>
  </channel>
</rss>
