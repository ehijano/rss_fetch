<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 22 Aug 2024 01:37:42 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 21 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Continuous difference-in-differences with double/debiased machine learning</title>
      <link>https://arxiv.org/abs/2408.10509</link>
      <description>arXiv:2408.10509v1 Announce Type: new 
Abstract: This paper extends difference-in-differences to settings involving continuous treatments. Specifically, the average treatment effect on the treated (ATT) at any level of continuous treatment intensity is identified using a conditional parallel trends assumption. In this framework, estimating the ATTs requires first estimating infinite-dimensional nuisance parameters, especially the conditional density of the continuous treatment, which can introduce significant biases. To address this challenge, estimators for the causal parameters are proposed under the double/debiased machine learning framework. We show that these estimators are asymptotically normal and provide consistent variance estimators. To illustrate the effectiveness of our methods, we re-examine the study by Acemoglu and Finkelstein (2008), which assessed the effects of the 1983 Medicare Prospective Payment System (PPS) reform. By reinterpreting their research design using a difference-in-differences approach with continuous treatment, we nonparametrically estimate the treatment effects of the 1983 PPS reform, thereby providing a more detailed understanding of its impact.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10509v1</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lucas Zhang</dc:creator>
    </item>
    <item>
      <title>Gradient Wild Bootstrap for Instrumental Variable Quantile Regressions with Weak and Few Clusters</title>
      <link>https://arxiv.org/abs/2408.10686</link>
      <description>arXiv:2408.10686v1 Announce Type: new 
Abstract: We study the gradient wild bootstrap-based inference for instrumental variable quantile regressions in the framework of a small number of large clusters in which the number of clusters is viewed as fixed, and the number of observations for each cluster diverges to infinity. For the Wald inference, we show that our wild bootstrap Wald test, with or without studentization using the cluster-robust covariance estimator (CRVE), controls size asymptotically up to a small error as long as the parameter of endogenous variable is strongly identified in at least one of the clusters. We further show that the wild bootstrap Wald test with CRVE studentization is more powerful for distant local alternatives than that without. Last, we develop a wild bootstrap Anderson-Rubin (AR) test for the weak-identification-robust inference. We show it controls size asymptotically up to a small error, even under weak or partial identification for all clusters. We illustrate the good finite-sample performance of the new inference methods using simulations and provide an empirical application to a well-known dataset about US local labor markets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10686v1</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wenjie Wang, Yichong Zhang</dc:creator>
    </item>
    <item>
      <title>Conditional nonparametric variable screening by neural factor regression</title>
      <link>https://arxiv.org/abs/2408.10825</link>
      <description>arXiv:2408.10825v1 Announce Type: new 
Abstract: High-dimensional covariates often admit linear factor structure. To effectively screen correlated covariates in high-dimension, we propose a conditional variable screening test based on non-parametric regression using neural networks due to their representation power. We ask the question whether individual covariates have additional contributions given the latent factors or more generally a set of variables. Our test statistics are based on the estimated partial derivative of the regression function of the candidate variable for screening and a observable proxy for the latent factors. Hence, our test reveals how much predictors contribute additionally to the non-parametric regression after accounting for the latent factors. Our derivative estimator is the convolution of a deep neural network regression estimator and a smoothing kernel. We demonstrate that when the neural network size diverges with the sample size, unlike estimating the regression function itself, it is necessary to smooth the partial derivative of the neural network estimator to recover the desired convergence rate for the derivative. Moreover, our screening test achieves asymptotic normality under the null after finely centering our test statistics that makes the biases negligible, as well as consistency for local alternatives under mild conditions. We demonstrate the performance of our test in a simulation study and two real world applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10825v1</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jianqing Fan (Princeton University), Weining Wang (University of Groningen), Yue Zhao (University of York)</dc:creator>
    </item>
    <item>
      <title>Marginal treatment effects in the absence of instrumental variables</title>
      <link>https://arxiv.org/abs/2401.17595</link>
      <description>arXiv:2401.17595v2 Announce Type: replace 
Abstract: We propose a method for defining, identifying, and estimating the marginal treatment effect (MTE) without imposing the instrumental variable (IV) assumptions of independence, exclusion, and separability (or monotonicity). Under a new definition of the MTE based on reduced-form treatment error that is statistically independent of the covariates, we find that the relationship between the MTE and standard treatment parameters holds in the absence of IVs. We provide a set of sufficient conditions ensuring the identification of the defined MTE in an environment of essential heterogeneity. The key conditions include a linear restriction on potential outcome regression functions, a nonlinear restriction on the propensity score, and a conditional mean independence restriction that will lead to additive separability. We prove this identification using the notion of semiparametric identification based on functional form. And we provide an empirical application for the Head Start program to illustrate the usefulness of the proposed method in analyzing heterogenous causal effects when IVs are elusive.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.17595v2</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhewen Pan, Zhengxin Wang, Junsen Zhang, Yahong Zhou</dc:creator>
    </item>
    <item>
      <title>Asymptotic Properties of the Distributional Synthetic Controls</title>
      <link>https://arxiv.org/abs/2405.00953</link>
      <description>arXiv:2405.00953v2 Announce Type: replace 
Abstract: As an alternative to synthetic control, the distributional Synthetic Control (DSC) proposed by Gunsilius (2023) provides estimates for quantile treatment effect and thus enabling researchers to comprehensively understand the impact of interventions in causal inference. But the asymptotic properties of DSC have not been built. In this paper, we first establish the DSC estimator's asymptotic optimality in the essence that the treatment effect estimator given by DSC achieves the lowest possible squared prediction error among all potential estimators from averaging quantiles of control units. We then establish the convergence rate of the DSC weights. A significant aspect of our research is that we find the DSC synthesis forms an optimal weighted average, particularly in situations where it is impractical to perfectly fit the treated unit's quantiles through the weighted average of the control units' quantiles. Simulation results verify our theoretical insights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00953v2</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lu Zhang, Xiaomeng Zhang, Xinyu Zhang</dc:creator>
    </item>
    <item>
      <title>Matrix Quantile Factor Model</title>
      <link>https://arxiv.org/abs/2208.08693</link>
      <description>arXiv:2208.08693v3 Announce Type: replace-cross 
Abstract: This paper introduces a matrix quantile factor model for matrix-valued data with low-rank structure. We estimate the row and column factor spaces via minimizing the empirical check loss function with orthogonal rotation constraints. We show that the estimates converge at rate $(\min\{p_1p_2,p_2T,p_1T\})^{-1/2}$ in the average Frobenius norm, where $p_1$, $p_2$ and $T$ are the row dimensionality, column dimensionality and length of the matrix sequence, respectively. This rate is faster than that of the quantile estimates via ``flattening" the matrix model into a large vector model. To derive the central limit theorem, we introduce a novel augmented Lagrangian function, which is equivalent to the original constrained empirical check loss minimization problem. Via the equivalence, we prove that the Hessian matrix of the augmented Lagrangian function is locally positive definite, resulting in a locally convex penalized loss function around the true factors and their loadings. This easily leads to a feasible second-order expansion of the score function and readily established central limit theorems of the smoothed estimates of the loadings. We provide three consistent criteria to determine the pair of row and column factor numbers. Extensive simulation studies and an empirical study justify our theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.08693v3</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Xin-Bing Kong, Yong-Xin Liu, Long Yu, Peng Zhao</dc:creator>
    </item>
    <item>
      <title>Risk management in the use of published statistical results for policy decisions</title>
      <link>https://arxiv.org/abs/2305.03205</link>
      <description>arXiv:2305.03205v2 Announce Type: replace-cross 
Abstract: Statistical inferential results generally come with a measure of reliability for decision-making purposes. For a policy implementer, the value of implementing published policy research depends critically upon this reliability. For a policy researcher, the value of policy implementation may depend weakly or not at all upon the policy's outcome. Some researchers might benefit from overstating the reliability of statistical results. Implementers may find it difficult or impossible to determine whether researchers are overstating reliability. This information asymmetry between researchers and implementers can lead to an adverse selection problem where, at best, the full benefits of a policy are not realized or, at worst, a policy is deemed too risky to implement at any scale. Researchers can remedy this by guaranteeing the policy outcome. Researchers can overcome their own risk aversion and wealth constraints by exchanging risks with other researchers or offering only partial insurance. The problem and remedy are illustrated using a confidence interval for the success probability of a binomial policy outcome.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.03205v2</guid>
      <category>stat.OT</category>
      <category>econ.EM</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Duncan Ermini Leaf</dc:creator>
    </item>
  </channel>
</rss>
