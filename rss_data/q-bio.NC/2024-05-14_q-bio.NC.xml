<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 15 May 2024 04:00:22 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 15 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Cerebralization of mathematical quantities and physical features in neural science: a critical evaluation</title>
      <link>https://arxiv.org/abs/2405.08391</link>
      <description>arXiv:2405.08391v1 Announce Type: new 
Abstract: At the turn of the 20th century, Henri Poincar{\'e} explained that geometry is a convention and that the properties of space and time are the properties of our measuring instruments. Intriguingly, numerous contemporary authors argue that space, time and even number are ''encoded'' within the brain, as a consequence of evolution, adaptation and natural selection. In the neuroscientific study of movement generation, the activity of neurons would ''encode'' kinematic parameters: when they emit action potentials, neurons would ''speak'' a language carrying notions of classical mechanics. In this article, we shall explain that the movement of a body segment is the ultimate product of a measurement, a filtered numerical outcome of multiple processes taking place in parallel in the central nervous system and converging on the groups of neurons responsible for muscle contractions. The fact that notions of classical mechanics efficiently describe movements does not imply their implementation in the inner workings of the brain. Their relevance to the question how the brain activity enables one to produce accurate movements is questioned within the framework of the neurophysiology of orienting gaze movements toward a visual target.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.08391v1</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Laurent Goffart (CGGG)</dc:creator>
    </item>
    <item>
      <title>Self-supervised contrastive learning unveils cortical folding pattern linked to prematurity</title>
      <link>https://arxiv.org/abs/2405.08397</link>
      <description>arXiv:2405.08397v1 Announce Type: new 
Abstract: Brain folding patterns have been reported to carry clinically relevant information. The brain folds mainly during the last trimester of pregnancy, and the process might be durably disturbed by preterm birth. Yet little is known about preterm-specific patterns. In this work, we train a self-supervised model (SimCLR) on the UKBioBank cohort (21070 adults) to represent the right superior temporal sulcus (STS) region and apply it to sulci images of 374 babies from the dHCP database, containing preterms and full-terms, and acquired at 40 weeks post-menstrual age. We find a lower variability in the preterm embeddings, supported by the identification of a knob pattern, missing in the extremely preterm population.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.08397v1</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>MIDL 2024, Jul 2024, Paris, France</arxiv:journal_reference>
      <dc:creator>Julien Laval (BAOBAB), Aymeric Gaudin (BAOBAB), Vincent Frouin (BAOBAB), Jessica Dubois (UNIACT), Andrea Gondova (UNIACT), Jean-Fran\c{c}ois Mangin (BAOBAB), Jo\"el Chavas (BAOBAB), Denis Rivi\`ere (BAOBAB)</dc:creator>
    </item>
    <item>
      <title>The Requirement for Cognition, in an Equation</title>
      <link>https://arxiv.org/abs/2405.08601</link>
      <description>arXiv:2405.08601v1 Announce Type: new 
Abstract: A model of the evolution of cognition is used to derive a Requirement Equation (RE), which defines what computations the fittest possible brain must make, or must choose actions as if it had made those computations. The terms in the RE depend on factors outside an animals brain, which can be modelled without making assumptions about how the brain works, from knowledge of the animals habitat and biology. In simple domains where the choices of actions have small information content, it may not be necessary to build internal models of reality; short cut computations may be just as good at choosing actions. In complex domains such as 3D spatial cognition, which underpins many complex choices of action, the RE implies that brains build Bayesian internal models of the animals surroundings; and that the models are constrained to be true to external reality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.08601v1</guid>
      <category>q-bio.NC</category>
      <category>q-bio.PE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Robert Worden</dc:creator>
    </item>
    <item>
      <title>Computational Thought Experiments for a More Rigorous Philosophy and Science of the Mind</title>
      <link>https://arxiv.org/abs/2405.08304</link>
      <description>arXiv:2405.08304v1 Announce Type: cross 
Abstract: We offer philosophical motivations for a method we call Virtual World Cognitive Science (VW CogSci), in which researchers use virtual embodied agents that are embedded in virtual worlds to explore questions in the field of Cognitive Science. We focus on questions about mental and linguistic representation and the ways that such computational modeling can add rigor to philosophical thought experiments, as well as the terminology used in the scientific study of such representations. We find that this method forces researchers to take a god's-eye view when describing dynamical relationships between entities in minds and entities in an environment in a way that eliminates the need for problematic talk of belief and concept types, such as the belief that cats are silly, and the concept CAT, while preserving belief and concept tokens in individual cognizers' minds. We conclude with some further key advantages of VW CogSci for the scientific study of mental and linguistic representation and for Cognitive Science more broadly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.08304v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Iris Over, Nikhil Krishnaswamy, James Pustejovsky, Joshua Hartshorne</dc:creator>
    </item>
    <item>
      <title>Bifurcation analysis of a two-neuron central pattern generator model for both oscillatory and convergent neuronal activities</title>
      <link>https://arxiv.org/abs/2405.08409</link>
      <description>arXiv:2405.08409v1 Announce Type: cross 
Abstract: The neural oscillator model proposed by Matsuoka is a piecewise affine system, which exhibits distinctive periodic solutions. Although such typical oscillation patterns have been widely studied, little is understood about the dynamics of convergence to certain fixed points and bifurcations between the periodic orbits and fixed points in this model. We performed fixed point analysis on a two-neuron version of the Matsuoka oscillator model, the result of which explains the mechanism of oscillation and the discontinuity-induced bifurcations such as subcritical/supercritical Hopf-like, homoclinic-like, and grazing bifurcations. Furthermore, it provided theoretical predictions concerning a logarithmic oscillation-period scaling law and noise-induced oscillations, which are both observed around those bifurcations. These results are expected to underpin further investigations into both oscillatory and transient neuronal activities with respect to central pattern generators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.08409v1</guid>
      <category>nlin.AO</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kotaro Muramatsu, Hiroshi Kori</dc:creator>
    </item>
    <item>
      <title>CLASH: Contrastive learning through alignment shifting to extract stimulus information from EEG</title>
      <link>https://arxiv.org/abs/2302.01924</link>
      <description>arXiv:2302.01924v2 Announce Type: replace 
Abstract: Stimulus-evoked EEG data has a notoriously low signal-to-noise ratio and high inter-subject variability. We propose a novel paradigm for the self-supervised extraction of stimulus-related brain response data: a model is trained to extract similar information between two time-aligned segments of EEG in response to the same stimulus. The extracted information can subsequently be used to obtain better results in downstream tasks that utilize the response to the stimulus. We show the efficacy of our method for a downstream task of decoding the speech envelope from auditory EEG. Our method outperforms other state-of-the-art denoising techniques, improving reconstruction scores by 45\%. Additionally, we show that in contrast to the baseline denoising techniques, our method can be used with data of unseen subjects and stimuli without retraining, improving decoding performance by 19\% and 34\% over raw EEG for two holdout datasets. Finally, the last experiment reveals that the accuracies obtained in the CLASH paradigm are significantly correlated with the percentile of obtained reconstruction correlation on the null distribution. In general, we showed that the proposed paradigm is suitable to train deep learning models to extract stimulus information from EEG while being stimulus feature agnostic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.01924v2</guid>
      <category>q-bio.NC</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Bernd Accou, Hugo Van hamme, Tom Francart</dc:creator>
    </item>
    <item>
      <title>Alljoined1 -- A dataset for EEG-to-Image decoding</title>
      <link>https://arxiv.org/abs/2404.05553</link>
      <description>arXiv:2404.05553v3 Announce Type: replace 
Abstract: We present Alljoined1, a dataset built specifically for EEG-to-Image decoding. Recognizing that an extensive and unbiased sampling of neural responses to visual stimuli is crucial for image reconstruction efforts, we collected data from 8 participants looking at 10,000 natural images each. We have currently gathered 46,080 epochs of brain responses recorded with a 64-channel EEG headset. The dataset combines response-based stimulus timing, repetition between blocks and sessions, and diverse image classes with the goal of improving signal quality. For transparency, we also provide data quality scores. We publicly release the dataset and all code at https://linktr.ee/alljoined1.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05553v3</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonathan Xu, Bruno Aristimunha, Max Emanuel Feucht, Emma Qian, Charles Liu, Tazik Shahjahan, Martyna Spyra, Steven Zifan Zhang, Nicholas Short, Jioh Kim, Paula Perdomo, Ricky Renfeng Mao, Yashvir Sabharwal, Michael Ahedor Moaz Shoura, Adrian Nestor</dc:creator>
    </item>
    <item>
      <title>On the Shape of Brainscores for Large Language Models (LLMs)</title>
      <link>https://arxiv.org/abs/2405.06725</link>
      <description>arXiv:2405.06725v2 Announce Type: replace 
Abstract: With the rise of Large Language Models (LLMs), the novel metric "Brainscore" emerged as a means to evaluate the functional similarity between LLMs and human brain/neural systems. Our efforts were dedicated to mining the meaning of the novel score by constructing topological features derived from both human fMRI data involving 190 subjects, and 39 LLMs plus their untrained counterparts. Subsequently, we trained 36 Linear Regression Models and conducted thorough statistical analyses to discern reliable and valid features from our constructed ones. Our findings reveal distinctive feature combinations conducive to interpreting existing brainscores across various brain regions of interest (ROIs) and hemispheres, thereby significantly contributing to advancing interpretable machine learning (iML) studies. The study is enriched by our further discussions and analyses concerning existing brainscores. To our knowledge, this study represents the first attempt to comprehend the novel metric brainscore within this interdisciplinary domain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06725v2</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jingkai Li</dc:creator>
    </item>
    <item>
      <title>Collective behavior from surprise minimization</title>
      <link>https://arxiv.org/abs/2307.14804</link>
      <description>arXiv:2307.14804v4 Announce Type: replace-cross 
Abstract: Collective motion is ubiquitous in nature; groups of animals, such as fish, birds, and ungulates appear to move as a whole, exhibiting a rich behavioral repertoire that ranges from directed movement to milling to disordered swarming. Typically, such macroscopic patterns arise from decentralized, local interactions among constituent components (e.g., individual fish in a school). Preeminent models of this process describe individuals as self-propelled particles, subject to self-generated motion and 'social forces' such as short-range repulsion and long-range attraction or alignment. However, organisms are not particles; they are probabilistic decision-makers. Here, we introduce an approach to modelling collective behavior based on active inference. This cognitive framework casts behavior as the consequence of a single imperative: to minimize surprise. We demonstrate that many empirically-observed collective phenomena, including cohesion, milling and directed motion, emerge naturally when considering behavior as driven by active Bayesian inference -- without explicitly building behavioral rules or goals into individual agents. Furthermore, we show that active inference can recover and generalize the classical notion of social forces as agents attempt to suppress prediction errors that conflict with their expectations. By exploring the parameter space of the belief-based model, we reveal non-trivial relationships between the individual beliefs and group properties like polarization and the tendency to visit different collective states. We also explore how individual beliefs about uncertainty determine collective decision-making accuracy. Finally, we show how agents can update their generative model over time, resulting in groups that are collectively more sensitive to external fluctuations and encode information more robustly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.14804v4</guid>
      <category>nlin.AO</category>
      <category>cs.MA</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1073/pnas.2320239121</arxiv:DOI>
      <arxiv:journal_reference>Proceedings of the National Academy of Sciences, 121(17), e2320239121 (2024)</arxiv:journal_reference>
      <dc:creator>Conor Heins, Beren Millidge, Lancelot da Costa, Richard Mann, Karl Friston, Iain Couzin</dc:creator>
    </item>
    <item>
      <title>convSeq: Fast and Scalable Method for Detecting Patterns in Spike Data</title>
      <link>https://arxiv.org/abs/2402.01130</link>
      <description>arXiv:2402.01130v2 Announce Type: replace-cross 
Abstract: Spontaneous neural activity, crucial in memory, learning, and spatial navigation, often manifests itself as repetitive spatiotemporal patterns. Despite their importance, analyzing these patterns in large neural recordings remains challenging due to a lack of efficient and scalable detection methods. Addressing this gap, we introduce convSeq, an unsupervised method that employs backpropagation for optimizing spatiotemporal filters that effectively identify these neural patterns. Our method's performance is validated on various synthetic data and real neural recordings, revealing spike sequences with unprecedented scalability and efficiency. Significantly surpassing existing methods in speed, convSeq sets a new standard for analyzing spontaneous neural activity, potentially advancing our understanding of information processing in neural circuits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.01130v2</guid>
      <category>eess.SP</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roman Koshkin, Tomoki Fukai</dc:creator>
    </item>
  </channel>
</rss>
