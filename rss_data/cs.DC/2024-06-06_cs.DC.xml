<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DC</link>
    <description>cs.DC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 07 Jun 2024 04:00:31 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 07 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Prioritized-MVBA: A New Approach to Design an Optimal Asynchronous Byzantine Agreement Protocol</title>
      <link>https://arxiv.org/abs/2406.03739</link>
      <description>arXiv:2406.03739v1 Announce Type: new 
Abstract: The multi-valued byzantine agreement protocol (MVBA) in the authenticated setting has been widely used as a core to design atomic broadcast and fault-tolerant state machine replication protocols in asynchronous networks. Originating from the seminal work of Cachin et al. \cite{CACHIN01}, subsequent research endeavors have sought to optimize protocol efficiency in terms of communication complexity. Notable advancements following Cachin's contributions include: i) VABA \cite{BYZ17}, requiring multiple protocol instances to achieve agreement on a party's request, and ii) Dumbo-MVBA \cite{LU20}, employing a cryptographic asynchronous dispersal and recovery methods to manage communication complexity alongside additional computational and communication rounds overheads.
  Our objective is to devise an MVBA protocol that achieves agreement in each instance without extra computation and communication rounds while maintaining the optimal metrics. Central to our design approach is the introduction of the committee in the classic MVBA protocol, wherein a randomly selected subset of ($f+1$, where $n=3f+1$) parties get selected and simultaneously broadcast their requests (transactions) to gather verifiable proofs. Successive distributions of these proofs afford us the necessary properties to employ the asynchronous binary Byzantine agreement (ABBA) protocol for reaching an agreement on a selected party's requests. By integrating the committee and ABBA protocols, we devise the optimal MVBA protocol, termed pMVBA (Prioritized-MVBA). This protocol exhibits resilience to tolerate up to $\lfloor \frac{n}{3}\rfloor$ Byzantine failures, with an expected runtime of $O(1)$, optimal message complexity of $O(n^2)$, and optimal communication complexity $O((l+\lambda)n^2)$ .</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03739v1</guid>
      <category>cs.DC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nasit S Sony, Xianzhong Ding, Mukesh Singhal</dc:creator>
    </item>
    <item>
      <title>CORTEX: Large-Scale Brain Simulator Utilizing Indegree Sub-Graph Decomposition on Fugaku Supercomputer</title>
      <link>https://arxiv.org/abs/2406.03762</link>
      <description>arXiv:2406.03762v1 Announce Type: new 
Abstract: We introduce CORTEX, an algorithmic framework designed for large-scale brain simulation. Leveraging the computational capacity of the Fugaku Supercomputer, CORTEX maximizes available problem size and processing performance. Our primary innovation, Indegree Sub-Graph Decomposition, along with a suite of parallel algorithms, facilitates efficient domain decomposition by segmenting the global graph structure into smaller, identically structured sub-graphs. This segmentation allows for parallel processing of synaptic interactions without inter-process dependencies, effectively eliminating data racing at the thread level without necessitating mutexes or atomic operations. Additionally, this strategy enhances the overlap of communication and computation. Benchmark tests conducted on spiking neural networks, characterized by biological parameters, have demonstrated significant enhancements in both problem size and simulation performance, surpassing the capabilities of the current leading open-source solution, the NEST Simulator. Our work offers a powerful new tool for the field of neuromorphic computing and understanding brain function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03762v1</guid>
      <category>cs.DC</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tianxiang Lyu, Mitsuhisa Sato, Shigeki Aoki, Ryutaro Himeno, Zhe Sun</dc:creator>
    </item>
    <item>
      <title>PALM: A Efficient Performance Simulator for Tiled Accelerators with Large-scale Model Training</title>
      <link>https://arxiv.org/abs/2406.03868</link>
      <description>arXiv:2406.03868v1 Announce Type: new 
Abstract: Deep learning (DL) models are piquing high interest and scaling at an unprecedented rate. To this end, a handful of tiled accelerators have been proposed to support such large-scale training tasks. However, these accelerators often incorporate numerous cores or tiles even extending to wafer-scale, substantial on-chip bandwidth, and distributed memory systems. This results in an exceedingly complex design space. Moreover, conducting actual training experiments to find optimal configurations is impractical due to time constraints. Hence, predicting the optimal mapping of various parallelisms to such tiled system architectures becomes crucial. In this study, leveraging an analysis of existing mainstream DL model training strategies, we introduce a performance simulator named PALM. PALM targets both the training and inference processes for tiled accelerators, aiming to inspire the design of current and future accelerators. Specifically, (i) we establish a scheduling mechanism among tiled accelerators based on an event-driven framework; (ii) we support user-configurable pipeline, tensor, and data parallelism on tiled accelerators, determining the absolute performance throughput under these parallelism strategies; (iii) we model the interaction of on-chip SRAM, NoC, and off-chip DRAM during operator execution. This work is available here: https://github.com/fangjh21/PALM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03868v1</guid>
      <category>cs.DC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiahao Fang, Huizheng Wang, Qize Yang, Dehao Kong, Xu Dai, Jinyi Deng, Yang Hu, Shouyi Yin</dc:creator>
    </item>
    <item>
      <title>Gaining Cross-Platform Parallelism for HAL's Molecular Dynamics Package using SYCL</title>
      <link>https://arxiv.org/abs/2406.04210</link>
      <description>arXiv:2406.04210v1 Announce Type: new 
Abstract: Molecular dynamics simulations are one of the methods in scientific computing that benefit from GPU acceleration. For those devices, SYCL is a promising API for writing portable codes. In this paper, we present the case study of "HAL's MD package" that has been successfully migrated from CUDA to SYCL. We describe the different strategies that we followed in the process of porting the code. Following these strategies, we achieved code portability across major GPU vendors. Depending on the actual kernels, both significant performance improvements and regressions are observed. As a side effect of the migration process, we obtained impressing speedups also for execution on CPUs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04210v1</guid>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Viktor Skoblin, Felix H\"ofling, Steffen Christgau</dc:creator>
    </item>
    <item>
      <title>Llumnix: Dynamic Scheduling for Large Language Model Serving</title>
      <link>https://arxiv.org/abs/2406.03243</link>
      <description>arXiv:2406.03243v1 Announce Type: cross 
Abstract: Inference serving for large language models (LLMs) is the key to unleashing their potential in people's daily lives. However, efficient LLM serving remains challenging today because the requests are inherently heterogeneous and unpredictable in terms of resource and latency requirements, as a result of the diverse applications and the dynamic execution nature of LLMs. Existing systems are fundamentally limited in handling these characteristics and cause problems such as severe queuing delays, poor tail latencies, and SLO violations.
  We introduce Llumnix, an LLM serving system that reacts to such heterogeneous and unpredictable requests by runtime rescheduling across multiple model instances. Similar to context switching across CPU cores in modern operating systems, Llumnix reschedules requests to improve load balancing and isolation, mitigate resource fragmentation, and differentiate request priorities and SLOs. Llumnix implements the rescheduling with an efficient and scalable live migration mechanism for requests and their in-memory states, and exploits it in a dynamic scheduling policy that unifies the multiple rescheduling scenarios elegantly. Our evaluations show that Llumnix improves tail latencies by an order of magnitude, accelerates high-priority requests by up to 1.5x, and delivers up to 36% cost savings while achieving similar tail latencies, compared against state-of-the-art LLM serving systems. Llumnix is publicly available at https://github.com/AlibabaPAI/llumnix.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03243v1</guid>
      <category>cs.AR</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Biao Sun, Ziming Huang, Hanyu Zhao, Wencong Xiao, Xinyi Zhang, Yong Li, Wei Lin</dc:creator>
    </item>
    <item>
      <title>Noise-Aware Algorithm for Heterogeneous Differentially Private Federated Learning</title>
      <link>https://arxiv.org/abs/2406.03519</link>
      <description>arXiv:2406.03519v1 Announce Type: cross 
Abstract: High utility and rigorous data privacy are of the main goals of a federated learning (FL) system, which learns a model from the data distributed among some clients. The latter has been tried to achieve by using differential privacy in FL (DPFL). There is often heterogeneity in clients privacy requirements, and existing DPFL works either assume uniform privacy requirements for clients or are not applicable when server is not fully trusted (our setting). Furthermore, there is often heterogeneity in batch and/or dataset size of clients, which as shown, results in extra variation in the DP noise level across clients model updates. With these sources of heterogeneity, straightforward aggregation strategies, e.g., assigning clients aggregation weights proportional to their privacy parameters will lead to lower utility. We propose Robust-HDP, which efficiently estimates the true noise level in clients model updates and reduces the noise-level in the aggregated model updates considerably. Robust-HDP improves utility and convergence speed, while being safe to the clients that may maliciously send falsified privacy parameter to server. Extensive experimental results on multiple datasets and our theoretical analysis confirm the effectiveness of Robust-HDP. Our code can be found here.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03519v1</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Saber Malekmohammadi, Yaoliang Yu, Yang Cao</dc:creator>
    </item>
    <item>
      <title>Fantastyc: Blockchain-based Federated Learning Made Secure and Practical</title>
      <link>https://arxiv.org/abs/2406.03608</link>
      <description>arXiv:2406.03608v1 Announce Type: cross 
Abstract: Federated Learning is a decentralized framework that enables multiple clients to collaboratively train a machine learning model under the orchestration of a central server without sharing their local data. The centrality of this framework represents a point of failure which is addressed in literature by blockchain-based federated learning approaches. While ensuring a fully-decentralized solution with traceability, such approaches still face several challenges about integrity, confidentiality and scalability to be practically deployed. In this paper, we propose Fantastyc, a solution designed to address these challenges that have been never met together in the state of the art.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03608v1</guid>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>William Boitier, Antonella Del Pozzo, \'Alvaro Garc\'ia-P\'erez, Stephane Gazut, Pierre Jobic, Alexis Lemaire, Erwan Mahe, Aurelien Mayoue, Maxence Perion, Deepika Singh, Tuanir Franca Rezende, Sara Tucci-Piergiovanni</dc:creator>
    </item>
    <item>
      <title>FedPylot: Navigating Federated Learning for Real-Time Object Detection in Internet of Vehicles</title>
      <link>https://arxiv.org/abs/2406.03611</link>
      <description>arXiv:2406.03611v1 Announce Type: cross 
Abstract: The Internet of Vehicles (IoV) emerges as a pivotal component for autonomous driving and intelligent transportation systems (ITS), by enabling low-latency big data processing in a dense interconnected network that comprises vehicles, infrastructures, pedestrians and the cloud. Autonomous vehicles are heavily reliant on machine learning (ML) and can strongly benefit from the wealth of sensory data generated at the edge, which calls for measures to reconcile model training with preserving the privacy of sensitive user data. Federated learning (FL) stands out as a promising solution to train sophisticated ML models in vehicular networks while protecting the privacy of road users and mitigating communication overhead. This paper examines the federated optimization of the cutting-edge YOLOv7 model to tackle real-time object detection amid data heterogeneity, encompassing unbalancedness, concept drift, and label distribution skews. To this end, we introduce FedPylot, a lightweight MPI-based prototype to simulate federated object detection experiments on high-performance computing (HPC) systems, where we safeguard server-client communications using hybrid encryption. Our study factors in accuracy, communication cost, and inference speed, thereby presenting a balanced approach to the challenges faced by autonomous vehicles. We demonstrate promising results for the applicability of FL in IoV and hope that FedPylot will provide a basis for future research into federated real-time object detection. The source code is available at https://github.com/cyprienquemeneur/fedpylot.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03611v1</guid>
      <category>cs.LG</category>
      <category>cs.CV</category>
      <category>cs.DC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cyprien Qu\'em\'eneur, Soumaya Cherkaoui</dc:creator>
    </item>
    <item>
      <title>Privacy Preserving Semi-Decentralized Mean Estimation over Intermittently-Connected Networks</title>
      <link>https://arxiv.org/abs/2406.03766</link>
      <description>arXiv:2406.03766v1 Announce Type: cross 
Abstract: We consider the problem of privately estimating the mean of vectors distributed across different nodes of an unreliable wireless network, where communications between nodes can fail intermittently. We adopt a semi-decentralized setup, wherein to mitigate the impact of intermittently connected links, nodes can collaborate with their neighbors to compute a local consensus, which they relay to a central server. In such a setting, the communications between any pair of nodes must ensure that the privacy of the nodes is rigorously maintained to prevent unauthorized information leakage. We study the tradeoff between collaborative relaying and privacy leakage due to the data sharing among nodes and, subsequently, propose PriCER: Private Collaborative Estimation via Relaying -- a differentially private collaborative algorithm for mean estimation to optimize this tradeoff. The privacy guarantees of PriCER arise (i) implicitly, by exploiting the inherent stochasticity of the flaky network connections, and (ii) explicitly, by adding Gaussian perturbations to the estimates exchanged by the nodes. Local and central privacy guarantees are provided against eavesdroppers who can observe different signals, such as the communications amongst nodes during local consensus and (possibly multiple) transmissions from the relays to the central server. We substantiate our theoretical findings with numerical simulations. Our implementation is available at https://github.com/rajarshisaha95/private-collaborative-relaying.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03766v1</guid>
      <category>eess.SP</category>
      <category>cs.DC</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rajarshi Saha, Mohamed Seif, Michal Yemini, Andrea J. Goldsmith, H. Vincent Poor</dc:creator>
    </item>
    <item>
      <title>A Survey of Computation Offloading with Task Type</title>
      <link>https://arxiv.org/abs/2401.01017</link>
      <description>arXiv:2401.01017v3 Announce Type: replace 
Abstract: Computation task offloading plays a crucial role in facilitating computation-intensive applications and edge intelligence, particularly in response to the explosive growth of massive data generation. Various enabling techniques, wireless technologies and mechanisms have already been proposed for task offloading, primarily aimed at improving the quality of services (QoS) for users. While there exists an extensive body of literature on this topic, exploring computation offloading from the standpoint of task types has been relatively underrepresented. This motivates our survey, which seeks to classify the state-of-the-art (SoTA) from the task type point-of-view. To achieve this, a thorough literature review is conducted to reveal the SoTA from various aspects, including architecture, objective, offloading strategy, and task types, with the consideration of task generation. It has been observed that task types are associated with data and have an impact on the offloading process, including elements like resource allocation and task assignment. Building upon this insight, computation offloading is categorized into two groups based on task types: static task-based offloading and dynamic task-based offloading. Finally, a prospective view of the challenges and opportunities in the field of future computation offloading is presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.01017v3</guid>
      <category>cs.DC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siqi Zhang, Na Yi, Yi Ma</dc:creator>
    </item>
    <item>
      <title>DistServe: Disaggregating Prefill and Decoding for Goodput-optimized Large Language Model Serving</title>
      <link>https://arxiv.org/abs/2401.09670</link>
      <description>arXiv:2401.09670v3 Announce Type: replace 
Abstract: DistServe improves the performance of large language models (LLMs) serving by disaggregating the prefill and decoding computation. Existing LLM serving systems colocate the two phases and batch the computation of prefill and decoding across all users and requests. We find that this strategy not only leads to strong prefill-decoding interferences but also couples the resource allocation and parallelism plans for both phases. LLM applications often emphasize individual latency for each phase: time to first token (TTFT) for the prefill phase and time per output token (TPOT) of each request for the decoding phase. In the presence of stringent latency requirements, existing systems have to prioritize one latency over the other, or over-provision compute resources to meet both.
  DistServe assigns prefill and decoding computation to different GPUs, hence eliminating prefill-decoding interferences. Given the application's TTFT and TPOT requirements, DistServe co-optimizes the resource allocation and parallelism strategy tailored for each phase. DistServe also places the two phases according to the serving cluster's bandwidth to minimize the communication caused by disaggregation. As a result, DistServe significantly improves LLM serving performance in terms of the maximum rate that can be served within both TTFT and TPOT constraints on each GPU. Our evaluations show that on various popular LLMs, applications, and latency requirements, DistServe can serve 7.4x more requests or 12.6x tighter SLO, compared to state-of-the-art systems, while staying within latency constraints for &gt; 90% of requests.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.09670v3</guid>
      <category>cs.DC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Yinmin Zhong, Shengyu Liu, Junda Chen, Jianbo Hu, Yibo Zhu, Xuanzhe Liu, Xin Jin, Hao Zhang</dc:creator>
    </item>
    <item>
      <title>BurstAttention: An Efficient Distributed Attention Framework for Extremely Long Sequences</title>
      <link>https://arxiv.org/abs/2403.09347</link>
      <description>arXiv:2403.09347v4 Announce Type: replace 
Abstract: Effective attention modules have played a crucial role in the success of Transformer-based large language models (LLMs), but the quadratic time and memory complexities of these attention modules also pose a challenge when processing long sequences. One potential solution for the long sequence problem is to utilize distributed clusters to parallelize the computation of attention modules across multiple devices (e.g., GPUs). However, adopting a distributed approach inevitably introduces extra memory overheads to store local attention results and incurs additional communication costs to aggregate local results into global ones. In this paper, we propose a distributed attention framework named ``BurstAttention'' to optimize memory access and communication operations at both the global cluster and local device levels. In our experiments, we compare BurstAttention with other competitive distributed attention solutions for long sequence processing. The experimental results under different length settings demonstrate that BurstAttention offers significant advantages for processing long sequences compared with these competitive baselines, reducing 40% communication overheads and achieving 1.37 X speedup during training 128K sequence length on 32 X A100.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09347v4</guid>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ao Sun, Weilin Zhao, Xu Han, Cheng Yang, Zhiyuan Liu, Chuan Shi, Maosong Sun</dc:creator>
    </item>
    <item>
      <title>Automatic BLAS Offloading on Unified Memory Architecture: A Study on NVIDIA Grace-Hopper</title>
      <link>https://arxiv.org/abs/2404.13195</link>
      <description>arXiv:2404.13195v4 Announce Type: replace 
Abstract: Porting codes to GPU often requires major efforts. While several tools exist for automatically offload numerical libraries such as BLAS and LAPACK, they often prove impractical due to the high cost of mandatory data transfer. The new unified memory architecture in NVIDIA Grace-Hopper allows high bandwidth cache-coherent memory access of all memory from both CPU and GPU, potentially eliminating bottleneck faced in conventional architecture. This breakthrough opens up new avenues for application development and porting strategies. In this study, we introduce a new tool for automatic BLAS offload, the tool leverages the high speed cache coherent NVLink C2C interconnect in Grace-Hopper, and enables performant GPU offload for BLAS heavy applications with no code changes or recompilation. The tool was tested on two quantum chemistry or physics codes, great performance benefits were observed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13195v4</guid>
      <category>cs.DC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3626203.3670561</arxiv:DOI>
      <dc:creator>Junjie Li, Yinzhi Wang, Xiao Liang, Hang Liu</dc:creator>
    </item>
    <item>
      <title>Seq1F1B: Efficient Sequence-Level Pipeline Parallelism for Large Language Model Training</title>
      <link>https://arxiv.org/abs/2406.03488</link>
      <description>arXiv:2406.03488v2 Announce Type: replace 
Abstract: The emergence of large language models (LLMs) relies heavily on distributed training strategies, among which pipeline parallelism plays a crucial role. As LLMs' training sequence length extends to 32k or even 128k, the current pipeline parallel methods face severe bottlenecks, including high memory footprints and substantial pipeline bubbles, greatly hindering model scalability and training throughput. To enhance memory efficiency and training throughput, in this work, we introduce an efficient sequence-level one-forward-one-backward (1F1B) pipeline scheduling method tailored for training LLMs on long sequences named Seq1F1B. Seq1F1B decomposes batch-level schedulable units into finer sequence-level units, reducing bubble size and memory footprint. Considering that Seq1F1B may produce slight extra bubbles if sequences are split evenly, we design a computation-wise strategy to partition input sequences and mitigate this side effect. Compared to competitive pipeline baseline methods such as Megatron 1F1B pipeline parallelism, our method achieves higher training throughput with less memory footprint. Notably, Seq1F1B efficiently trains a LLM with 30B parameters on sequences up to 64k using 64 NVIDIA A100 GPUs without recomputation strategies, a feat unachievable with existing methods. Our source code is based on Megatron-LM, and now is avaiable at: https://github.com/MayDomine/Seq1F1B.git.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03488v2</guid>
      <category>cs.DC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ao Sun, Weilin Zhao, Xu Han, Cheng Yang, Zhiyuan Liu, Chuan Shi, Maosong Sun</dc:creator>
    </item>
    <item>
      <title>Compressed and Sparse Models for Non-Convex Decentralized Learning</title>
      <link>https://arxiv.org/abs/2311.05760</link>
      <description>arXiv:2311.05760v2 Announce Type: replace-cross 
Abstract: Recent research highlights frequent model communication as a significant bottleneck to the efficiency of decentralized machine learning (ML), especially for large-scale and over-parameterized neural networks (NNs). To address this, we present Malcom-PSGD, a novel decentralized ML algorithm that combines gradient compression techniques with model sparsification. We promote model sparsity by adding $\ell_1$ regularization to the objective and present a decentralized proximal SGD method for training. Our approach employs vector source coding and dithering-based quantization for the compressed gradient communication of sparsified models. Our analysis demonstrates that Malcom-PSGD achieves a convergence rate of $\mathcal{O}(1/\sqrt{t})$ with respect to the iterations $t$, assuming a constant consensus and learning rate. This result is supported by our proof for the convergence of non-convex compressed Proximal SGD methods. Additionally, we conduct a bit analysis, providing a closed-form expression for the communication costs associated with Malcom-PSGD. Numerical results verify our theoretical findings and demonstrate that our method reduces communication costs by approximately $75\%$ when compared to the state-of-the-art.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.05760v2</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <category>cs.MA</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrew Campbell, Hang Liu, Leah Woldemariam, Anna Scaglione</dc:creator>
    </item>
    <item>
      <title>SoK: Challenges and Opportunities in Federated Unlearning</title>
      <link>https://arxiv.org/abs/2403.02437</link>
      <description>arXiv:2403.02437v2 Announce Type: replace-cross 
Abstract: Federated learning (FL), introduced in 2017, facilitates collaborative learning between non-trusting parties with no need for the parties to explicitly share their data among themselves. This allows training models on user data while respecting privacy regulations such as GDPR and CPRA. However, emerging privacy requirements may mandate model owners to be able to \emph{forget} some learned data, e.g., when requested by data owners or law enforcement. This has given birth to an active field of research called \emph{machine unlearning}. In the context of FL, many techniques developed for unlearning in centralized settings are not trivially applicable! This is due to the unique differences between centralized and distributed learning, in particular, interactivity, stochasticity, heterogeneity, and limited accessibility in FL. In response, a recent line of work has focused on developing unlearning mechanisms tailored to FL.
  This SoK paper aims to take a deep look at the \emph{federated unlearning} literature, with the goal of identifying research trends and challenges in this emerging field. By carefully categorizing papers published on FL unlearning (since 2020), we aim to pinpoint the unique complexities of federated unlearning, highlighting limitations on directly applying centralized unlearning methods. We compare existing federated unlearning methods regarding influence removal and performance recovery, compare their threat models and assumptions, and discuss their implications and limitations. For instance, we analyze the experimental setup of FL unlearning studies from various perspectives, including data heterogeneity and its simulation, the datasets used for demonstration, and evaluation metrics. Our work aims to offer insights and suggestions for future research on federated unlearning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02437v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hyejun Jeong, Shiqing Ma, Amir Houmansadr</dc:creator>
    </item>
    <item>
      <title>VORTEX: Real-Time Off-Chain Payments and Cross-Chain Swaps for Cryptocurrencies</title>
      <link>https://arxiv.org/abs/2403.15191</link>
      <description>arXiv:2403.15191v3 Announce Type: replace-cross 
Abstract: In this paper, we present VERTEX, a TEE-based layer-2 solution that tackles two crucial challenges in the realm of cryptocurrencies: off-chain payments and cross-chain swaps. It offers three notable features: - Channel-free off-chain payments: it allows a payer to make direct payments to anyone without requiring any on-chain relationship or intermediary channels. - Real-time yet decentralized cross-chain swaps: it is the first known solution that enables real-time cross-chain swaps without relying on a central server. This novel feature is made possible through a ground-breaking fair exchange protocol. - TEE crash-tolerance: it offers two solutions to handle TEE crashes, one of which involves an innovative application of time-lock puzzles in this context. We evaluate ECHO on a network consists of 1000 nodes and the evaluation results show that ECHO can achieve 7000 TPS</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15191v3</guid>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Di Wu, Jian Liu, Zhengwei Hou, Wu Wen, Kui Ren</dc:creator>
    </item>
    <item>
      <title>Byzantine Attacks Exploiting Penalties in Ethereum PoS</title>
      <link>https://arxiv.org/abs/2404.16363</link>
      <description>arXiv:2404.16363v2 Announce Type: replace-cross 
Abstract: In May 2023, the Ethereum blockchain experienced its first inactivity leak, a mechanism designed to reinstate chain finalization amid persistent network disruptions. This mechanism aims to reduce the voting power of validators who are unreachable within the network, reallocating this power to active validators. This paper investigates the implications of the inactivity leak on safety within the Ethereum blockchain. Our theoretical analysis reveals scenarios where actions by Byzantine validators expedite the finalization of two conflicting branches, and instances where Byzantine validators reach a voting power exceeding the critical safety threshold of one-third. Additionally, we revisit the probabilistic bouncing attack, illustrating how the inactivity leak can result in a probabilistic breach of safety, potentially allowing Byzantine validators to exceed the one-third safety threshold. Our findings uncover how penalizing inactive nodes can compromise blockchain properties, particularly in the presence of Byzantine validators capable of coordinating actions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16363v2</guid>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ulysse Pavloff, Yackolley Amoussou-Genou, Sara Tucci-Piergiovanni</dc:creator>
    </item>
    <item>
      <title>Communication-Efficient Distributed Deep Learning via Federated Dynamic Averaging</title>
      <link>https://arxiv.org/abs/2405.20988</link>
      <description>arXiv:2405.20988v2 Announce Type: replace-cross 
Abstract: Driven by the ever-growing volume and decentralized nature of data, coupled with the need to harness this data and generate knowledge from it, has led to the extensive use of distributed deep learning (DDL) techniques for training. These techniques rely on local training that is performed at the distributed nodes based on locally collected data, followed by a periodic synchronization process that combines these models to create a global model. However, frequent synchronization of DL models, encompassing millions to many billions of parameters, creates a communication bottleneck, severely hindering scalability. Worse yet, DDL algorithms typically waste valuable bandwidth, and make themselves less practical in bandwidth-constrained federated settings, by relying on overly simplistic, periodic, and rigid synchronization schedules. These drawbacks also have a direct impact on the time required for the training process, necessitating excessive time for data communication. To address these shortcomings, we propose Federated Dynamic Averaging (FDA), a communication-efficient DDL strategy that dynamically triggers synchronization based on the value of the model variance. In essence, the costly synchronization step is triggered only if the local models, which are initialized from a common global model after each synchronization, have significantly diverged. This decision is facilitated by the communication of a small local state from each distributed node/worker. Through extensive experiments across a wide range of learning tasks we demonstrate that FDA reduces communication cost by orders of magnitude, compared to both traditional and cutting-edge communication-efficient algorithms. Additionally, we show that FDA maintains robust performance across diverse data heterogeneity settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20988v2</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Michail Theologitis, Georgios Frangias, Georgios Anestis, Vasilis Samoladas, Antonios Deligiannakis</dc:creator>
    </item>
  </channel>
</rss>
