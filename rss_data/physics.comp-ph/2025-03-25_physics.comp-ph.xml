<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.comp-ph updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.comp-ph</link>
    <description>physics.comp-ph updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.comp-ph" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 26 Mar 2025 04:00:14 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 26 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Notes on Quantum Computing for Thermal Science</title>
      <link>https://arxiv.org/abs/2503.19109</link>
      <description>arXiv:2503.19109v1 Announce Type: new 
Abstract: This document explores the potential of quantum computing in Thermal Science. Conceived as a living document, it will be continuously updated with experimental findings and insights for the research community in Thermal Science. By experiments, we refer both to the search for the most effective algorithms and to the performance of real quantum hardware. Those are fields that are evolving rapidly, driving a technological race to define the best architectures. The development of novel algorithms for engineering problems aims at harnessing the unique strengths of quantum computing. Expectations are high, as users seek concrete evidence of quantum supremacy - a true game changer for engineering applications. Among all heat transfer mechanisms (conduction, convection, radiation), we start with conduction as a paradigmatic test case in the field being characterized by a rich mathematical foundation for our investigations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.19109v1</guid>
      <category>physics.comp-ph</category>
      <category>quant-ph</category>
      <pubDate>Wed, 26 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pietro Asinari, Nada Alghamdi, Paolo De Angelis, Giovanni Trezza, Giulio Barletta, Marina Provenzano, Matteo Maria Piredda, Matteo Fasano, Eliodoro Chiavazzo</dc:creator>
    </item>
    <item>
      <title>New analytic formulae for memory and prediction functions in reservoir computers with time delays</title>
      <link>https://arxiv.org/abs/2503.19806</link>
      <description>arXiv:2503.19806v1 Announce Type: new 
Abstract: Time delays increase the effective dimensionality of reservoirs, thus suggesting that time delays in reservoirs can enhance their performance, particularly their memory and prediction abilities. We find new closed-form expressions for memory and prediction functions of linear time-delayed reservoirs in terms of the power spectrum of the input and the reservoir transfer function. We confirm this relationship numerically for some time-delayed reservoirs using simulations, including when the reservoir can be linearized but is actually nonlinear. Finally, we use these closed-form formulae to address the utility of multiple time delays in linear reservoirs in order to perform memory and prediction, finding similar results to previous work on nonlinear reservoirs. We hope these closed-form formulae can be used to understand memory and predictive capabilities in time-delayed reservoirs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.19806v1</guid>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 26 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Peyton Mullarkey, Sarah Marzen</dc:creator>
    </item>
    <item>
      <title>Probabilistic combination of loads in topology optimization designs via cumulative damage criteria</title>
      <link>https://arxiv.org/abs/2503.19807</link>
      <description>arXiv:2503.19807v1 Announce Type: new 
Abstract: Topology optimization (TO) is a well-established methodology for structural design under user-defined constraints, e.g. minimum volume and maximum stiffness. However, such methods have traditionally been applied to static, deterministic loading, in which modulus, position and direction are known and invariant. This is against the probabilistic load combination used in the structural engineering designs, and entails two important shortcomings.
  The first one is related to maintenance and reliability: static loading fails to consider naturally occurring uncertainties in the loading process, measurements or regular service; also ignoring (quantitatively) unforeseen phenomena such as vibrations, and the material's behavior is assumed linear isotropic, ignoring fatigue, plasticity and anisotropy in functionally-graded materials. The second one concerns optimality itself: often times, the structure presented as "optimal" in fact over-estimates loading and thus wastes material by exceeding its real needs and/or distributing it poorly throughout the design dominion.
  In this article, a probabilistic framework is presented: uncertain and pseudo-dynamic loading is introduced to create robust topologies via a reinforced SIMP scheme with embedded penalization addressing fatigue damage, layer direction, mechanical response (traction/compression) and yield limit (von Mises equivalent stress). This computationally efficient framework is applied to various loading scenarios, generating diverse designs for the same volume fraction constraint with improved and more realistic performances. Under the proposed method, if loads are permanent and damage isotropic, the methodology converges to the traditional (deterministic) topological optimization results. Future ramifications of this work are pondered, especially regarding metamaterial design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.19807v1</guid>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 26 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Luis Irastorza-Valera, Luis Saucedo-Mora</dc:creator>
    </item>
    <item>
      <title>New Diamond Magnet CaCo2TeO6: Strong Quantum Fluctuations and Enhanced Competing Exchange Interactions Enabled by Octahedral Co2+ Ligand Fields</title>
      <link>https://arxiv.org/abs/2503.18977</link>
      <description>arXiv:2503.18977v1 Announce Type: cross 
Abstract: Diamond lattice magnets, formed by a framework of corner-sharing tetrahedra of magnetic cations, offer unique opportunities to realize novel states of matter for potential utility in information technology. However, research has mostly focused on AB2X4 spinels with Td magnetic ions. This hinders the atomically enabled tunability of competing interactions at different energy scales and the ability to harness many-body electronic states in quantum materials, making the discovery of quantum fluctuations and spin dynamics less accessible. We discover a new material CaCo2TeO6 featuring a diamond lattice of two distinct Oh-Co2+ sites. This material displays strong quantum fluctuations, increased competing magnetic exchange interactions, and field-induced tunability of magnetic structures. The results demonstrate how simple, fundamental refinements in ligand fields can profoundly influence the phase space of quantum matter.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.18977v1</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.chem-ph</category>
      <category>physics.comp-ph</category>
      <category>quant-ph</category>
      <pubDate>Wed, 26 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xudong Huai, Luke Pritchard Cairns, Bridget Delles, Micha{\l} J. Winiarski, Maurice Sorolla II, Xinshu Zhang, Youzhe Chen, Anshul Kogar, Robert Birgeneau, James Analytis, Stuart Calder, Danielle Yahne, Thao T. Tran</dc:creator>
    </item>
    <item>
      <title>Direct evidence and atomic-scale mechanisms of reduced dislocation mobility in an inorganic semiconductor under illumination</title>
      <link>https://arxiv.org/abs/2503.19189</link>
      <description>arXiv:2503.19189v1 Announce Type: cross 
Abstract: Photo-plasticity in semiconductors, wherein their mechanical properties such as strength, hardness and ductility are influenced by light exposure, has been reported for several decades. Although such phenomena have drawn significant attention for the manufacturability and usage of deformable semiconductor devices, their underlying mechanisms are not well understood due to the lack of direct evidence. Here we provide experimental observation and atomic insights into the reduced mobility of dislocations in zinc sulfide, as a model material, under light. Using photo-nanoindentation and transmission electron microscopy, we observe that dislocations glide shorter distances under light than those in darkness and there are no apparent deformation twins in both conditions. By atomic-scale simulations, we demonstrate that the decreased dislocation mobility is attributed to the increased Peierls stress for dislocation motion and enhanced stress fields around dislocation cores due to photoexcitation. This study improves the understanding of photo-plastic effects in inorganic semiconductors, offering the opportunities for modulating their mechanical properties using light.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.19189v1</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 26 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mingqiang Li, Kun Luo, Xiumei Ma, Boran Kumral, Peng Gao, Tobin Filleter, Qi An, Yu Zou</dc:creator>
    </item>
    <item>
      <title>Feature-Guided Sampling Strategy for Adaptive Model Order Reduction of Convection-Dominated Problems</title>
      <link>https://arxiv.org/abs/2503.19321</link>
      <description>arXiv:2503.19321v1 Announce Type: cross 
Abstract: Though high-performance computing enables high-fidelity simulations of complex engineering systems, accurately resolving multi-scale physics for real-world problems remains computationally prohibitive, particularly in many-query applications such as optimization and uncertainty quantification. Projection-based model order reduction (MOR) has demonstrated significant potential for reducing computational costs by orders of magnitude through the creation of reduced-order models (ROMs). However, physical problems featuring strong convection, such as hypersonic flows and detonations, pose significant challenges to conventional MOR techniques due to the slow decay of Kolmogorov N-width present in these problems. In the past few years various approaches have been proposed to address this challenge; one of the promising methods is the adaptive MOR. In this work, we introduce a feature-guided adaptive projection-based MOR framework tailored for convection-dominated problems involving flames and shocks. This approach dynamically updates the ROM subspace and incorporates a feature-guided sampling method that strategically selects sampling points to capture prominent convective features, ensuring accurate predictions of crucial dynamics in the target problems. We evaluate the proposed methodology using a suite of challenging convection-dominated test problems, including shocks, flames, and detonations. The results demonstrate the feature-guided adaptive ROM's capability in producing efficient and reliable predictions of the nonlinear convection-dominated physical phenomena in the selected test suite, which are well recognized to be challenging for conventional ROM methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.19321v1</guid>
      <category>physics.flu-dyn</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 26 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ali Mohaghegh, Cheng Huang</dc:creator>
    </item>
    <item>
      <title>Empirical Hyper Element Integration Method (EHEIM) with Unified Integration Criteria for Efficient Hyper Reduced FE$^2$ Simulations</title>
      <link>https://arxiv.org/abs/2503.19483</link>
      <description>arXiv:2503.19483v1 Announce Type: cross 
Abstract: Numerical homogenization for mechanical multiscale modeling by means of the finite element method (FEM) is an elegant way of obtaining structure-property relations, if the behavior of the constituents of the lower scale is well understood. However, the computational costs of this so-called FE$^2$ method are so high that reduction methods are essential. While the construction of a reduced basis for the microscopic nodal displacements using proper orthogonal decomposition (POD) has become a standard technique, the reduction of the computational effort for the projected nodal forces, the so-called hyper reduction, is an additional challenge, for which different strategies have been proposed in the literature. The empirical cubature method (ECM), which has been proven to be very robust, implemented the conservation of the total volume is used as a constraint in the resulting optimization problem, while energy-based criteria have been proposed in other contributions.
  The present contribution presents a unified integration criteria concept, involving the aforementioned criteria, among others. These criteria are used both with a Gauss point-based as well as with an element-based hyper reduction scheme, the latter retaining full compatibility with the common modular finite element framework. The methods are combined with a previously proposed clustered training strategy and a monolithic solver. Numerical examples empirically demonstrate that the additional criteria improve the accuracy for a given number of modes. Vice verse, less modes and thus lower computational costs are required to reach a given level of accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.19483v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 26 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nils Lange, Geralf H\"utter, Bjoern Kiefer</dc:creator>
    </item>
    <item>
      <title>Optimization through In-Context Learning and Iterative LLM Prompting for Nuclear Engineering Design Problems</title>
      <link>https://arxiv.org/abs/2503.19620</link>
      <description>arXiv:2503.19620v1 Announce Type: cross 
Abstract: The optimization of nuclear engineering designs, such as nuclear fuel assembly configurations, involves managing competing objectives like reactivity control and power distribution. This study explores the use of Optimization by Prompting, an iterative approach utilizing large language models (LLMs), to address these challenges. The method is straightforward to implement, requiring no hyperparameter tuning or complex mathematical formulations. Optimization problems can be described in plain English, with only an evaluator and a parsing script needed for execution. The in-context learning capabilities of LLMs enable them to understand problem nuances, therefore, they have the potential to surpass traditional metaheuristic optimization methods. This study demonstrates the application of LLMs as optimizers to Boiling Water Reactor (BWR) fuel lattice design, showing the capability of commercial LLMs to achieve superior optimization results compared to traditional methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.19620v1</guid>
      <category>cs.LG</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 26 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>M. Rizki Oktavian, Anirudh Tunga, Amandeep Bakshi, Michael J. Mueterthies, J. Thomas Gruenwald, Jonathan Nistor</dc:creator>
    </item>
    <item>
      <title>Characteristic boundary conditions for Hybridizable Discontinuous Galerkin methods</title>
      <link>https://arxiv.org/abs/2503.19684</link>
      <description>arXiv:2503.19684v1 Announce Type: cross 
Abstract: In this work we introduce the concept of characteristic boundary conditions (CBCs) within the framework of Hybridizable Discontinuous Galerkin (HDG) methods, including both the Navier-Stokes characteristic boundary conditions (NSCBCs) and a novel approach to generalized characteristic relaxation boundary conditions (GRCBCs). CBCs are based on the characteristic decomposition of the compressible Euler equations and are designed to prevent the reflection of waves at the domain boundaries. We show the effectiveness of the proposed method for weakly compressible flows through a series of numerical experiments by comparing the results with common boundary conditions in the HDG setting and reference solutions available in the literature. In particular, HDG with CBCs show superior performance minimizing the reflection of vortices at artificial boundaries, for both inviscid and viscous flows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.19684v1</guid>
      <category>math.NA</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <category>physics.flu-dyn</category>
      <pubDate>Wed, 26 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jan Ellmenreich, Matteo Giacomini, Antonio Huerta, Philip L. Lederer</dc:creator>
    </item>
    <item>
      <title>Defects and Impurity Properties of VN precipitates in ARAFM Steels: Modelling using a Universal Machine Learning Potential and Experimental Validation</title>
      <link>https://arxiv.org/abs/2503.19720</link>
      <description>arXiv:2503.19720v1 Announce Type: cross 
Abstract: VN precipitates used to strengthen ARAFM steels for fusion applications, have been shown to undergo dissolution under high Fe ion irradiation doses of 100 dpa at dose rates of 10^-3 dpa/s at 600 C. Here, point defects and solute substitutions have been studied using atom probe tomography (APT), universal machine learning interatomic potentials (uMLIPs), and density functional theory. Through a combination of transmission electron microscopy (TEM), APT, and atomic scale calculations, N-vacancies and substitutional Cr are found to be present in VN precipitates prior to irradiation. Ternary convex hulls were calculated for ten VNX (X=Cr, Fe, C, Si, Mn, W, Ta, B, S, P) systems with an uMLIP. These calculations predict Fe, P, Mn, and Si to be unstable solutes in the VN precipitate. Therefore, Fe, P, Mn and Si implantation via collision cascades is found to be a possible mechanism driving dissolution of VN.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.19720v1</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.app-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 26 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>R. S. Stroud, C. Reynolds, T. Melichar, J. Haley, M. Carter, M. Moody, C. Hardie, D. Bowden, D. Nguyen-Manh, M. R. Wenman</dc:creator>
    </item>
    <item>
      <title>Role of spatial embedding and planarity in shaping the topology of the Street Networks</title>
      <link>https://arxiv.org/abs/2503.19723</link>
      <description>arXiv:2503.19723v1 Announce Type: cross 
Abstract: The topology of city street networks (SNs) is constrained by spatial embedding, requiring non-crossing links and preventing random node placement or overlap. Here, we analyzed SNs of $33$ Indian cities to explore how the spatial embedding and the planarity jointly shape their topology. Overall, we found that all the studied SNs have small-world properties with higher clustering and efficiency. The efficiency of the empirical networks is even higher than that of the corresponding degree of preserved random networks. This increased efficiency can be explained by Dijkstra's path-length distribution, which closely fits a right-skewed normal or log-normal distribution. Moreover, we observed that the connectivity of the streets is length-dependent: the smaller streets connect preferably to the smaller streets, while longer streets tend to connect with the longer counterparts. This length-dependent connectivity is more profound in the empirical SNs than in the corresponding degree preserved random and random planar networks. However, planar networks maintaining the empirical spatial coordinates replicate the connectivity behavior of empirical SNs, highlighting the influence of spatial embedding. Moreover, the robustness of the cities in terms of resilience to random errors and targeted attacks is independent of the SN's size, indicating other factors, such as geographical constraints, substantially influence network stability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.19723v1</guid>
      <category>physics.soc-ph</category>
      <category>physics.comp-ph</category>
      <category>physics.data-an</category>
      <pubDate>Wed, 26 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ritish Khetarpal, Aradhana Singh</dc:creator>
    </item>
    <item>
      <title>Grid-Free Evaluation of Phonon-Limited Electronic Relaxation Times and Transport Properties</title>
      <link>https://arxiv.org/abs/2503.19732</link>
      <description>arXiv:2503.19732v1 Announce Type: cross 
Abstract: Present calculations of electrical transport properties of materials require evaluations of electron-phonon coupling constants on dense predefined grids of electron and phonon momenta and performing the sums over these momenta. In this work, we present the methodology for calculation of carrier relaxation times and electrical transport properties without the use of a predefined grid. The relaxation times are evaluated by integrating out the delta function that ensures energy conservation and performing an average over the angular components of phonon momentum. The charge carrier mobility is then evaluated as a sum over appropriately sampled electronic momenta. We illustrate our methodology by applying to the Fr{\"o}hlich model and to a real semiconducting material ZnTe. We find that rather accurate results can be obtained with a modest number of electron and phonon momenta, on the order of one hundred each, regardless of the carrier effective mass.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.19732v1</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 26 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.cpc.2025.109583</arxiv:DOI>
      <arxiv:journal_reference>Comput. Phys. Commun. 312, 109583 (2025)</arxiv:journal_reference>
      <dc:creator>Nenad Vukmirovi\'c</dc:creator>
    </item>
    <item>
      <title>Machine Learning and Data-Driven Methods in Computational Surface and Interface Science</title>
      <link>https://arxiv.org/abs/2503.19814</link>
      <description>arXiv:2503.19814v1 Announce Type: cross 
Abstract: Nanoscale design of surfaces and interfaces is essential for modern technologies like organic LEDs, batteries, fuel cells, superlubricating surfaces, and heterogeneous catalysis. However, these systems often exhibit complex surface reconstructions and polymorphism, with properties influenced by kinetic processes and dynamic behavior. A lack of accurate and scalable simulation tools has limited computational modeling of surfaces and interfaces. Recently, machine learning and data-driven methods have expanded the capabilities of theoretical modeling, enabling, for example, the routine use of machine-learned interatomic potentials to predict energies and forces across numerous structures. Despite these advances, significant challenges remain, including the scarcity of large, consistent datasets and the need for computational and data-efficient machine learning methods. Additionally, a major challenge lies in the lack of accurate reference data and electronic structure methods for interfaces. Density Functional Theory, while effective for bulk materials, is less reliable for surfaces, and too few accurate experimental studies on interface structure and stability exist. Here, we will sketch the current state of data-driven methods and machine learning in computational surface science and provide a perspective on how these methods will shape the field in the future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.19814v1</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 26 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lukas H\"ormann, Wojciech G. Stark, Reinhard J. Maurer</dc:creator>
    </item>
    <item>
      <title>Ab-initio simulation of excited-state potential energy surfaces with transferable deep quantum Monte Carlo</title>
      <link>https://arxiv.org/abs/2503.19847</link>
      <description>arXiv:2503.19847v1 Announce Type: cross 
Abstract: The accurate quantum chemical calculation of excited states is a challenging task, often requiring computationally demanding methods. When entire ground and excited potential energy surfaces (PESs) are desired, e.g., to predict the interaction of light excitation and structural changes, one is often forced to use cheaper computational methods at the cost of reduced accuracy. Here we introduce a novel method for the geometrically transferable optimization of neural network wave functions that leverages weight sharing and dynamical ordering of electronic states. Our method enables the efficient prediction of ground and excited-state PESs and their intersections at the highest accuracy, demonstrating up to two orders of magnitude cost reduction compared to single-point calculations. We validate our approach on three challenging excited-state PESs, including ethylene, the carbon dimer, and the methylenimmonium cation, indicating that transferable deep-learning QMC can pave the way towards highly accurate simulation of excited-state dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.19847v1</guid>
      <category>physics.chem-ph</category>
      <category>cs.LG</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 26 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zeno Sch\"atzle, P. Bern\'at Szab\'o, Alice Cuzzocrea, Frank No\'e</dc:creator>
    </item>
    <item>
      <title>Kinetically Consistent Coarse Graining using Kernel-based Extended Dynamic Mode Decomposition</title>
      <link>https://arxiv.org/abs/2409.16396</link>
      <description>arXiv:2409.16396v2 Announce Type: replace 
Abstract: In this paper, we show how kernel-based models for the Koopman generator -- the gEDMD method -- can be used to identify coarse-grained dynamics on reduced variables, which retain the slowest transition timescales of the original dynamics. The centerpiece of this study is a learning method to identify an effective diffusion in coarse-grained space, which is similar in spirit to the force matching method. By leveraging the gEDMD model for the Koopman generator, the kinetic accuracy of the CG model can be evaluated. By combining this method with a suitable learning method for the effective free energy, such as force matching, a complete model for the effective dynamics can be inferred. Using a two-dimensional model system and molecular dynamics simulation data of alanine dipeptide and the Chignolin mini-protein, we demonstrate that the proposed method successfully and robustly recovers the essential kinetic and also thermodynamic properties of the full model. The parameters of the method can be determined using standard model validation techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.16396v2</guid>
      <category>physics.comp-ph</category>
      <category>math.DS</category>
      <pubDate>Wed, 26 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vahid Nateghi, Feliks N\"uske</dc:creator>
    </item>
    <item>
      <title>Benchmarking Data Efficiency in $\Delta$-ML and Multifidelity Models for Quantum Chemistry</title>
      <link>https://arxiv.org/abs/2410.11391</link>
      <description>arXiv:2410.11391v3 Announce Type: replace-cross 
Abstract: The development of machine learning (ML) methods has made quantum chemistry (QC) calculations more accessible by reducing the compute cost incurred in conventional QC methods. This has since been translated into the overhead cost of generating training data. Increased work in reducing the cost of generating training data resulted in the development of $\Delta$-ML and multifidelity machine learning methods which use data at more than one QC level of accuracy, or fidelity.
  This work compares the data costs associated with $\Delta$-ML, multifidelity machine learning (MFML), and optimized MFML (o-MFML) in contrast with a newly introduced Multifidelity$\Delta$-Machine Learning (MF$\Delta$ML) method for the prediction of ground state energies, vertical excitation energies, and the magnitude of electronic contribution of molecular dipole moments from the multifidelity benchmark dataset QeMFi. This assessment is made on the basis of training data generation cost associated with each model and is compared with the single fidelity kernel ridge regression (KRR) case. The results indicate that the use of multifidelity methods surpasses the standard $\Delta$-ML approaches in cases of a large number of predictions. For applications which require only a few evaluations to be made using ML models, while the $\Delta$-ML method might be favored, the MF$\Delta$ML method is shown to be more efficient.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11391v3</guid>
      <category>physics.chem-ph</category>
      <category>cs.LG</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 26 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vivin Vinod, Peter Zaspel</dc:creator>
    </item>
    <item>
      <title>Investigating Data Hierarchies in Multifidelity Machine Learning for Excitation Energies</title>
      <link>https://arxiv.org/abs/2410.11392</link>
      <description>arXiv:2410.11392v2 Announce Type: replace-cross 
Abstract: Recent progress in machine learning (ML) has made high-accuracy quantum chemistry (QC) calculations more accessible. Of particular interest are multifidelity machine learning (MFML) methods where training data from differing accuracies or fidelities are used. These methods usually employ a fixed scaling factor, $\gamma$, to relate the number of training samples across different fidelities, which reflects the cost and assumed sparsity of the data. This study investigates the impact of modifying $\gamma$ on model efficiency and accuracy for the prediction of vertical excitation energies using the QeMFi benchmark dataset. Further, this work introduces QC compute time informed scaling factors, denoted as $\theta$, that vary based on QC compute times at different fidelities. A novel error metric, error contours of MFML, is proposed to provide a comprehensive view of model error contributions from each fidelity. The results indicate that high model accuracy can be achieved with just 2 training samples at the target fidelity when a larger number of samples from lower fidelities are used. This is further illustrated through a novel concept, the $\Gamma$-curve, which compares model error against the time-cost of generating training samples, demonstrating that multifidelity models can achieve high accuracy while minimizing training data costs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11392v2</guid>
      <category>physics.chem-ph</category>
      <category>cs.LG</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 26 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1021/acs.jctc.4c01491</arxiv:DOI>
      <dc:creator>Vivin Vinod, Peter Zaspel</dc:creator>
    </item>
    <item>
      <title>Addressing general measurements in quantum Monte Carlo</title>
      <link>https://arxiv.org/abs/2412.01384</link>
      <description>arXiv:2412.01384v3 Announce Type: replace-cross 
Abstract: Among present quantum many-body computational methods, quantum Monte Carlo (QMC) is one of the most promising approaches for dealing with large-scale complex systems. It has played an extremely important role in understanding quantum many-body physics. However, two dark clouds, namely the sign problem and general measurement issues, have seriously hampered its scope of application. We propose a universal scheme to tackle the problems of general measurement. The target observables are expressed as the ratio of two types of partition functions $\langle \mathrm{O} \rangle=\bar{Z}/Z$, where $\bar{Z}=\mathrm{tr} (\mathrm{Oe^{-\beta H}})$ and $Z=\mathrm{tr} (\mathrm{e^{-\beta H}})$. These two partition functions can be estimated separately within the reweight-annealing frame, and then be connected by an easily solvable reference point. We have successfully applied this scheme to XXZ model and transverse field Ising model, from 1D to 2D systems, from two-body to multi-body correlations and even non-local disorder operators, and from equal-time to imaginary-time correlations. The reweighting path is not limited to physical parameters, but also works for space and time. Essentially, this scheme solves the long-standing problem of calculating the overlap between different distribution functions in mathematical statistics, which can be widely used in statistical problems, such as quantum many-body computation, big data and machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01384v3</guid>
      <category>cond-mat.str-el</category>
      <category>cond-mat.stat-mech</category>
      <category>physics.comp-ph</category>
      <category>quant-ph</category>
      <pubDate>Wed, 26 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhiyan Wang, Zenan Liu, Bin-Bin Mao, Zhe Wang, Zheng Yan</dc:creator>
    </item>
    <item>
      <title>From non-equilibrium Green's functions to Lattice Wigner: A toy model for quantum nanofluidics simulations</title>
      <link>https://arxiv.org/abs/2501.18634</link>
      <description>arXiv:2501.18634v2 Announce Type: replace-cross 
Abstract: Recent experiments of fluid transport in nano-channels have shown evidence of a coupling between charge-fluctuations in polar fluids and electronic excitations in graphene solids, which may lead to a significant reduction of friction a phenomenon dubbed "negative quantum friction". In this paper, we present a semi-classical mesoscale Boltzmann-Wigner lattice kinetic model of quantum- nanoscale transport and perform a numerical study of the effects of the quantum interactions on the evolution of a one-dimensional nano-fluid subject to a periodic external potential. It is shown that the effects of quantum fluctuations become visible once the quantum length scale (Fermi wavelength) of the quasiparticles becomes comparable to the lengthscale of the external potential. Under such conditions, quantum fluctuations are mostly felt on the odd kinetic moments, while the even ones remain nearly unaffected because they are "protected" by thermal fluctuations. It is hoped that the present Boltzmann-Wigner lattice model and extensions thereof may offer a useful tool for the computer simulation of quantum-nanofluidic transport phenomena at scales of engineering relevance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18634v2</guid>
      <category>cond-mat.mes-hall</category>
      <category>physics.comp-ph</category>
      <category>physics.flu-dyn</category>
      <pubDate>Wed, 26 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>S. Succi, M. Lauricella, A. Tiribocchi</dc:creator>
    </item>
    <item>
      <title>Constructing optimal Wannier functions via potential theory: isolated single band for matrix models</title>
      <link>https://arxiv.org/abs/2502.08641</link>
      <description>arXiv:2502.08641v2 Announce Type: replace-cross 
Abstract: We present a rapidly convergent scheme for computing globally optimal Wannier functions of isolated single bands for matrix models in two dimensions. The scheme proceeds first by constructing provably exponentially localized Wannier functions directly from parallel transport (with simple analytically computable corrections) when topological obstructions are absent. We prove that the corresponding Wannier functions are real when the matrix model possesses time-reversal symmetry. When a band has a nonzero Berry curvature, the resulting Wannier function is not optimal, but it is transformed into the global optimum by a single gauge transformation that eliminates the divergence of the Berry connection. Complete analysis of the construction is presented, paving the way for further improvements and generalizations. The performance of the scheme is illustrated with several numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08641v2</guid>
      <category>math-ph</category>
      <category>cs.NA</category>
      <category>math.MP</category>
      <category>math.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 26 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hanwen Zhang</dc:creator>
    </item>
    <item>
      <title>Noise-strength-adapted approximate quantum codes inspired by machine learning</title>
      <link>https://arxiv.org/abs/2503.11783</link>
      <description>arXiv:2503.11783v2 Announce Type: replace-cross 
Abstract: We demonstrate that machine learning provides a powerful tool for discovering new approximate quantum error-correcting (AQEC) codes beyond conventional algebraic frameworks. Building upon direct observations through hybrid quantum-classical learning, we discover two new 4-qubit amplitude damping codes with an innovative noise-strength-adaptive (NSA) feature where the codeword varies with noise strength. They are NSA self-complementary and NSA pair-complementary codes. We show that they can both outperform conventional codes for amplitude damping (AD) noise. The 4-qubit self-complementary NSA code outperforms the standard LNCY AD code in fidelity and Knill-Laflamme condition violation. The pair-complementary code, which has no known non-NSA analog, achieves even better performance with higher-order loss suppression and better fidelity. We further generalize both approaches to families of NSA AD codes for arbitrary system size, as well as an NSA variant of the 0-2-4 binomial code for single-photon loss. Our results demonstrate that adaptation to noise strength can systematically lead to significant improvements in error correction capability, and also showcase how machine learning can help discover new valuable code formalisms that may not emerge from traditional design approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.11783v2</guid>
      <category>quant-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 26 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuwei Liu, Shiyu Zhou, Zi-Wen Liu, Jinmin Yi</dc:creator>
    </item>
  </channel>
</rss>
