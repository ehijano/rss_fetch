<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 03 Oct 2025 04:00:05 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>MMGaP: Multi-User MIMO Detection and Precoding using GPU-assisted Physics-inspired Computation</title>
      <link>https://arxiv.org/abs/2510.01579</link>
      <description>arXiv:2510.01579v1 Announce Type: new 
Abstract: Physics-inspired and quantum compute based methods for processing in the physical layer of next-generation cellular radio access networks have demonstrated theoretical advances in spectral efficiency in recent years, but have stopped short of practical realization on commodity processors, leaving a gap between the throughput practical systems can achieve and the projected throughput the state-of-the-art should achieve. To fill this gap, this paper proposes MMGaP, an uplink multi-user MIMO detector and downlink Vector perturbation precoder for next-generation cellular networks. MMGaP realizes these large MIMO processing algorithms for the first time on bare-metal CUDA kernels that scale to run on large GPU processing platforms, and can be packaged as TensorFlow modules, allowing easy integration with a variety of systems. We integrate MMGaP with NVIDIA's software-defined, GPU-accelerated 5G platform and evaluate its performance against the state-of-the-art. In a 5G cellular network using 100 MHz of radio bandwidth, eight antennas at the base station and eight concurrent users, we show that MMGaP improves uplink throughput by approximately 50 Mbps per user and downlink throughput by 100 Mbps per user over a wide range of SNR. We further show that MMGaP can also support larger MIMO sizes: for 16 antennas at the base station and 16 concurrent users, MMGaP provides more than 50 Mbps higher uplink throughput per user. We measure the execution time of MMGaP on different NVIDIA GPUs and show that it can operate at line-rate and meet the timing requirements of state-of-the-art 5G systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01579v1</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abhishek Kumar Singh, Kyle Jamieson</dc:creator>
    </item>
    <item>
      <title>ReSSFormer: A Recursive Sparse Structured Transformer for Scalable and Long-Context Reasoning</title>
      <link>https://arxiv.org/abs/2510.01585</link>
      <description>arXiv:2510.01585v1 Announce Type: cross 
Abstract: While Transformer architectures have demonstrated impressive scalability across domains, they continue to face challenges in long-context reasoning, computational efficiency, and structural generalization - largely due to rigid layer stacking, dense attention, and reliance on positional encodings. We present ReSSFormer, a Recursive Sparse Structured Transformer that integrates three complementary innovations: Recurrent Reasoning &amp; Memory Unit (R2MU) for iterative reasoning with bounded depth, Adaptive Sparse Attention Module (ASAM) for efficient and focused context selection, and Self-Organizing Encoder Structure (SOES) for position-free structure induction. ReSSFormer replaces conventional depth stacking with recurrent inference, substitutes full attention with token- and expert-level sparsity, and models latent token topology directly from content. Across language modeling, multi-hop QA, and structure-sensitive tasks, ReSSFormer consistently outperforms strong baselines under comparable FLOPs and parameter budgets, highlighting its scalability, efficiency, and structural flexibility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01585v1</guid>
      <category>cs.CL</category>
      <category>cs.NI</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haochen You, Baojing Liu</dc:creator>
    </item>
    <item>
      <title>Accuracy vs Performance: An abstraction model for deadline constrained offloading at the mobile-edge</title>
      <link>https://arxiv.org/abs/2510.01885</link>
      <description>arXiv:2510.01885v1 Announce Type: cross 
Abstract: In this paper, we present a solution for low-latency deadline-constrained DNN offloading on mobile edge devices. We design a scheduling algorithm with lightweight network state representation, considering device availability, communication on the network link, priority-aware pre-emption, and task deadlines. The scheduling algorithm aims to reduce latency by designing a resource availability representation, as well as a network discretisation and a dynamic bandwidth estimation mechanism. We implement the scheduling algorithm into a system composed of four Raspberry Pi 2 (model Bs) mobile edge devices, sampling a waste classification conveyor belt at a set frame rate. The system is evaluated and compared to a previous approach of ours, which was proven to outcompete work-stealers and a non-pre-emption based scheduling heuristic under the aforementioned waste classification scenario. Our findings show the novel lower latency abstraction models yield better performance under high-volume workloads, with the dynamic bandwidth estimation assisting the task placement while, ultimately, increasing task throughput in times of resource scarcity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01885v1</guid>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jamie Cotter, Ignacio Castineiras, Victor Cionca</dc:creator>
    </item>
    <item>
      <title>How to Combat Reactive and Dynamic Jamming Attacks with Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2510.02265</link>
      <description>arXiv:2510.02265v1 Announce Type: cross 
Abstract: This paper studies the problem of mitigating reactive jamming, where a jammer adopts a dynamic policy of selecting channels and sensing thresholds to detect and jam ongoing transmissions. The transmitter-receiver pair learns to avoid jamming and optimize throughput over time (without prior knowledge of channel conditions or jamming strategies) by using reinforcement learning (RL) to adapt transmit power, modulation, and channel selection. Q-learning is employed for discrete jamming-event states, while Deep Q-Networks (DQN) are employed for continuous states based on received power. Through different reward functions and action sets, the results show that RL can adapt rapidly to spectrum dynamics and sustain high rates as channels and jamming policies change over time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02265v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yalin E. Sagduyu, Tugba Erpek, Kemal Davaslioglu, Sastry Kompella</dc:creator>
    </item>
    <item>
      <title>A Deep Incremental Framework for Multi-Service Multi-Modal Devices in NextG AI-RAN Systems</title>
      <link>https://arxiv.org/abs/2504.01730</link>
      <description>arXiv:2504.01730v3 Announce Type: replace 
Abstract: In this paper, we propose a deep incremental framework for efficient RAN management, introducing the Multi-Service-Modal UE (MSMU) system, which enables a single UE to handle eMBB and uRLLC services simultaneously. We formulate an optimization problem integrating traffic demand prediction, route optimization, RAN slicing, service identification, and radio resource management under uncertainty. We decompose it into long-term (L-SP) and short-term (S-SP) subproblems then propose a Transformer model for L-SP optimization, predicting eMBB and uRLLC traffic demands and optimizing routes for RAN slicing. To address non-stationary network traffic with evolving trends and scale variations, we integrate reversible instance normalization (ReVIN) into the forecasting pipeline. For the S-SP, we propose an LSTM model enabling real-time service type identification and resource management, utilizing L-SP predictions. We incorporate continual learning into the S-SP framework to adapt to new service types while preserving prior knowledge. Experimental results demonstrate that our proposed framework achieves up to 46.86% reduction in traffic demand prediction error, 26.70% and 18.79% improvement in PRBs and power estimation, 7.23% higher route selection accuracy, and 7.29% improvement in service identification over the baselines with 95% average accuracy in continual service identification across seven sequential tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01730v3</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mrityunjoy Gain, Kitae Kim, Avi Deb Raha, Apurba Adhikary, Walid Saad, Zhu Han, Choong Seon Hong</dc:creator>
    </item>
    <item>
      <title>An Architecture for Spatial Networking</title>
      <link>https://arxiv.org/abs/2507.22687</link>
      <description>arXiv:2507.22687v2 Announce Type: replace 
Abstract: Physical spaces are increasingly dense with networked devices, promising seamless coordination and ambient intelligence. Yet today, cloud-first architectures force all communication through wide-area networks regardless of physical proximity. We lack an abstraction for spatial networking: using physical spaces to create boundaries for private, robust, and low-latency communication. We introduce $\textit{Bifr\"ost}$, a programming model that realizes spatial networking using bigraphs to express both containment and connectivity, enabling policies to be scoped by physical boundaries, devices to be named by location, the instantiation of spatial services, and the composition of spaces while maintaining local autonomy. Bifr\"ost enables a new class of spatially-aware applications, where co-located devices communicate directly, physical barriers require explicit gateways, and local control bridges to global coordination.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.22687v2</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <category>cs.MA</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Josh Millar, Ryan Gibb, Roy Ang, Hamed Haddadi, Anil Madhavapeddy</dc:creator>
    </item>
    <item>
      <title>Morphlux: Transforming Torus Fabrics for Efficient Multi-tenant ML</title>
      <link>https://arxiv.org/abs/2508.03674</link>
      <description>arXiv:2508.03674v2 Announce Type: replace 
Abstract: We develop Morphlux, a server-scale programmable photonic fabric to interconnect accelerators within servers. We show that augmenting state-of-the-art torus-based ML data-centers with Morphlux can improve the bandwidth of tenant compute allocations by up to 66%, reduce compute fragmentation by up to 70%, and minimize the blast radius of chip failures. We develop a novel end-to-end hardware prototype of Morphlux to demonstrate these performance benefits which translate to 1.72X improvement in training throughput of ML models. By rapidly programming the server-scale fabric in our hardware testbed, Morphlux can replace a failed accelerator chip with a healthy one in 1.2 seconds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03674v2</guid>
      <category>cs.NI</category>
      <category>cs.AR</category>
      <category>cs.LG</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abhishek Vijaya Kumar, Eric Ding, Arjun Devraj, Rachee Singh</dc:creator>
    </item>
  </channel>
</rss>
