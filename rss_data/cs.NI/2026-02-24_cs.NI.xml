<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 25 Feb 2026 02:45:46 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>On the Inherent Resilience of Task-Oriented V2X Networks to Content-Selection Errors</title>
      <link>https://arxiv.org/abs/2602.18620</link>
      <description>arXiv:2602.18620v1 Announce Type: new 
Abstract: Task-oriented Vehicle-to-Everything (V2X) networks have recently been proposed to scalably support the large-scale deployment of connected vehicles within the Internet of Vehicles (IoV) vision. In task-oriented V2X networks, vehicles select the content of the transmitted messages based on its relevance to the intended receivers. However, relevance estimation can be quite challenging, especially in highly dynamic and complex vehicular scenarios. Relevance estimation errors can cause a vehicle to omit relevant information from its transmitted message, leading to a content-selection error. Content-selection errors reduce the amount of relevant information available at the receivers and can potentially impair their situational awareness. This work analyses the impact of content-selection errors on task-oriented V2X networks. Our analysis reveals that task-oriented V2X networks feature an inherent resilience to content-selection errors that guarantees a consistent delivery of relevant information even under high relevance estimation error conditions. Moreover, we identify the fundamental conditions underpinning such inherent resilience. These conditions can be encountered in other task-oriented networks where multiple transmitters select the content of their messages based on the task-related requirements of a common set of intended receivers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.18620v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luca Lusvarghi, Javier Gozalvez</dc:creator>
    </item>
    <item>
      <title>Federated Learning-Assisted Optimization of Mobile Transmission with Digital Twins</title>
      <link>https://arxiv.org/abs/2602.18627</link>
      <description>arXiv:2602.18627v1 Announce Type: new 
Abstract: A Digital Twin (DT) may protect information that is considered private to its associated physical system. For a mobile device, this may include its mobility profile, recent location(s), and experienced channel conditions. Online schedulers, however, typically use this type of information to perform tasks such as shared bandwidth and channel time slot assignments. In this paper, we consider three transmission scheduling problems with energy constraints, where such information is needed, and yet must remain private: minimizing total transmission time when (i) fixed-power or (ii) fixed-rate time slotting with power control is used, and (iii) maximizing the amount of data uploaded in a fixed time period. Using a real-time federated optimization framework, we show how the scheduler can iteratively interact only with the DTs to produce global fractional solutions to these problems, without the latter revealing their private information. Then dependent rounding is used to round the fractional solution into a channel transmission schedule for the physical systems. Experiments show consistent makespan reductions with near-zero bandwidth/energy violations and millisecond-order end-to-end runtime for typical edge server hardware. To the best of our knowledge, this is the first framework that enables channel sharing across DTs using operations that do not expose private data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.18627v1</guid>
      <category>cs.NI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammad Heydari, Terence D. Todd, Dongmei Zhao, George Karakostas</dc:creator>
    </item>
    <item>
      <title>MetaBlue: A Metasurface-Assisted Acoustic Underwater Localization System</title>
      <link>https://arxiv.org/abs/2602.19252</link>
      <description>arXiv:2602.19252v1 Announce Type: new 
Abstract: Underwater localization is essential for marine exploration and autonomous underwater operations, yet existing radio frequency and optical approaches are limited by rapid attenuation or limited visibility. Acoustic sensing remains the most practical choice, but conventional acoustic systems typically rely on large arrays or multiple synchronized anchors, resulting in high hardware costs and complex deployment. This paper introduces a novel low-cost passive acoustic metasurface, MetaBlue , explicitly designed for underwater localization, which, when attached to an ordinary ultrasonic transmitter, transforms it into a directional "super-transmitter." The metasurface embeds direction-dependent spectral patterns into the transmitted waveform, enabling accurate angle-of-arrival (AoA) estimation using only a single hydrophone. For ranging, we present a new EM-acoustic mixed time-of-arrival (ToA) method that leverages the acoustic transducer's inherent low-frequency EM leakage as a timing reference, enabling precise ranging without shared clocks. This allows complete 3D localization with a single low-cost anchor. We evaluate the system across diverse real-world underwater settings, including pools, tanks, and outdoor environments. Experiments show that our design achieves an average AoA error of 8.7 degree and 3D localization error of 0.37 m at distances over 10 m. Even with a single anchor, the system maintains 0.73 m precision.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.19252v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junling Wang, Yi Guo, Bojun Yang, Yazhou Yuan, Zhenlin An</dc:creator>
    </item>
    <item>
      <title>EMS-FL: Federated Tuning of Mixture-of-Experts in Satellite-Terrestrial Networks via Expert-Driven Model Splitting</title>
      <link>https://arxiv.org/abs/2602.19485</link>
      <description>arXiv:2602.19485v1 Announce Type: new 
Abstract: The rapid advancement of large AI models imposes stringent demands on data volume and computational resources. Federated learning, though designed to exploit distributed data and computational resources, faces data shortage from limited network coverage and computational constraints from edge devices. To address these issues, both the mixture-of-experts (MoE) and satellite-terrestrial network (STN) provide promising solutions, offering lightweight computation overhead and broad coverage, respectively. However, the satellite-ground relative motion results in intermittent connectivity, hindering conventional federated learning that relies on model synchronization across devices. To leverage the coverage of STN while preserving training efficiency, we propose EMS-FL, an expert-driven model splitting and federated learning method. EMS-FL assigns each device cluster only the experts highly correlated to their local data. Through non-overlapping expert assignments, asynchronous local learning is further proposed, where each device cluster trains its assigned experts consecutively and only uploads local parameters to the satellite during connected phases for aggregation and model updates. Consequently, EMS-FL effectively reduces the training overhead and achieves both faster convergence and higher accuracy compared with conventional federated learning. Rigorous convergence analysis is provided to theoretically characterize the learning performance. Furthermore, comprehensive experiments are conducted using public datasets and large models, validating the superiority of EMS-FL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.19485v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Angzi Xu, Zezhong Zhang, Zhi Liu, Shuguang Cui</dc:creator>
    </item>
    <item>
      <title>Spritz: Path-Aware Load Balancing in Low-Diameter Networks</title>
      <link>https://arxiv.org/abs/2602.19567</link>
      <description>arXiv:2602.19567v1 Announce Type: new 
Abstract: Low-diameter topologies such as Dragonfly and Slim Fly are increasingly adopted in HPC and datacenter networks, yet existing load balancing techniques either rely on proprietary in-network mechanisms or fail to utilize the full path diversity of these topologies. We introduce Spritz, a flexible sender-based load balancing framework that shifts adaptive topology-aware routing to the endpoints using only standard Ethernet features. We propose two algorithms, Spritz-Scout and Spritz-Spray that, respectively, explore and adaptively cache efficient paths using ECN, packet trimming, and timeout feedback. Through simulation on Dragonfly and Slim Fly topologies with over 1000 endpoints, Spritz outperforms ECMP, UGAL-L, and prior sender-based approaches by up to 1.8x in flow completion time under AI training and datacenter workloads, while offering robust failover with performance improvements of up to 25.4x under link failures, all without additional hardware support. Spritz enables datacenter-scale, commodity Ethernet networks to efficiently leverage low-diameter topologies, offering unified routing and load balancing for the Ultra Ethernet era.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.19567v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Proc. 40th IEEE International Parallel and Distributed Processing Symposium (IPDPS), 2026</arxiv:journal_reference>
      <dc:creator>Tommaso Bonato, Ales Kubicek, Abdul Kabbani, Ahmad Ghalayini, Maciej Besta, Torsten Hoefler</dc:creator>
    </item>
    <item>
      <title>Traffic-Aware Configuration of OPC UA PubSub in Industrial Automation Networks</title>
      <link>https://arxiv.org/abs/2602.19603</link>
      <description>arXiv:2602.19603v1 Announce Type: new 
Abstract: Interoperability across industrial automation systems is a cornerstone of Industry 4.0. To address this need, the OPC Unified Architecture (OPC UA) Publish-Subscribe (PubSub) model offers a promising mechanism for enabling efficient communication among heterogeneous devices. PubSub facilitates resource sharing and communication configuration between devices, but it lacks clear guidelines for mapping diverse industrial traffic types to appropriate PubSub configurations. This gap can lead to misconfigurations that degrade network performance and compromise real-time requirements. This paper proposes a set of guidelines for mapping industrial traffic types, based on their timing and quality-of-service specifications, to OPC UA PubSub configurations. The goal is to ensure predictable communication and support real-time performance in industrial networks. The proposed guidelines are evaluated through an industrial use case that demonstrates the impact of incorrect configuration on latency and throughput. The results underline the importance of traffic-aware PubSub configuration for achieving interoperability in Industry 4.0 systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.19603v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kasra Ekrad, Bjarne Johansson, In\'es Alvarez Vadillo, Saad Mubeen, Mohammad Ashjaei</dc:creator>
    </item>
    <item>
      <title>AI-Powered Conflict Management in Open RAN: Detection, Classification, and Mitigation</title>
      <link>https://arxiv.org/abs/2602.19758</link>
      <description>arXiv:2602.19758v1 Announce Type: new 
Abstract: Open Radio Access Network (RAN) was designed with native Artificial Intelligence (AI) as a core pillar, enabling AI- driven xApps and rApps to dynamically optimize network performance. However, the independent ICP adjustments made by these applications can inadvertently create conflicts- direct, indirect, and implicit, which lead to network instability and KPI degradation. Traditional rule-based conflict management becomes increasingly impractical as Open RAN scales in terms of xApps, associated ICPs, and relevant KPIs, struggling to handle the complexity of multi-xApp interactions. This highlights the necessity for AI-driven solutions that can efficiently detect, classify, and mitigate conflicts in real-time. This paper proposes an AI-powered framework for conflict detection, classification, and mitigation in Open RAN. We introduce GenC, a synthetic conflict generation framework for large-scale labeled datasets with controlled parameter sharing and realistic class imbalance, enabling robust training and evaluation of AI models. Our classification pipeline leverages GNNs, Bi-LSTM, and SMOTE-enhanced GNNs, with results demonstrating SMOTE-GNN's superior robustness in handling imbalanced data. Experimental validation using both synthetic datasets (5-50 xApps) and realistic ns3-oran simulations with OpenCellID-derived Dublin topology shows that AI-based methods achieve 3.2x faster classification than rule-based approaches while maintaining near-perfect accuracy. Our framework successfully addresses Energy Saving (ES)/Mobility Robustness Optimization (MRO) conflict scenarios using realistic ns3-oran and scales efficiently to large-scale xApp environments. By embedding this workflow into Open RAN's AI-driven architecture, our solution ensures autonomous and self-optimizing conflict management, paving the way for resilient, ultra-low-latency, and energy-efficient 6G networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.19758v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abdul Wadud, Nima Afraz, Fatemeh Golpayegani</dc:creator>
    </item>
    <item>
      <title>BeamVLM for Low-altitude Economy: Generative Beam Prediction via Vision-language Models</title>
      <link>https://arxiv.org/abs/2602.19929</link>
      <description>arXiv:2602.19929v1 Announce Type: new 
Abstract: For low-altitude economy (LAE), fast and accurate beam prediction between high-mobility unmanned aerial vehicles (UAVs) and ground base stations is of paramount importance, which ensures seamless coverage and reliable communications. However, existing deep learning-based beam prediction methods lack high-level semantic understanding of dynamic environments, resulting in poor generalization. On the other hand, the emerging large language model (LLM) based approaches show promise in enhancing generalization, but they typically lack rich environmental perception, thereby failing to capture fine-grained spatial semantics essential for precise beam alignment. To tackle these limitations, we propose in this correspondence a novel end-to-end generative framework for beam prediction, called BeamVLM, which treats beam prediction as a vision question answering task capitalizing on powerful existing vision-language models (VLMs). By projecting raw visual patches directly into the language domain and judiciously designing an instructional prompt, the proposed BeamVLM enables the VLM to jointly reason over UAV trajectories and environmental context. Last, experimental results on real-world datasets demonstrate that the proposed BeamVLM outperforms state-of-the-art methods in prediction accuracy and also exhibits superior generalization for other scenarios such as vehicle-to-infrastructure (V2I) beam prediction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.19929v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chenran Kou, Changsheng You, Mingjiang Wu, Dingzhu Wen, Zezhong Zhang, Chengwen Xing</dc:creator>
    </item>
    <item>
      <title>Adaptive Underwater Acoustic Communications with Limited Feedback: An AoI-Aware Hierarchical Bandit Approach</title>
      <link>https://arxiv.org/abs/2602.20105</link>
      <description>arXiv:2602.20105v1 Announce Type: new 
Abstract: Underwater Acoustic (UWA) networks are vital for remote sensing and ocean exploration but face inherent challenges such as limited bandwidth, long propagation delays, and highly dynamic channels. These constraints hinder real-time communication and degrade overall system performance. To address these challenges, this paper proposes a bilevel Multi-Armed Bandit (MAB) framework. At the fast inner level, a Contextual Delayed MAB (CD-MAB) jointly optimizes adaptive modulation and transmission power based on both channel state feedback and its Age of Information (AoI), thereby maximizing throughput. At the slower outer level, a Feedback Scheduling MAB dynamically adjusts the channel-state feedback interval according to throughput dynamics: stable throughput allows longer update intervals, while throughput drops trigger more frequent updates. This adaptive mechanism reduces feedback overhead and enhances responsiveness to varying network conditions. The proposed bilevel framework is computationally efficient and well-suited to resource-constrained UWA networks. Simulation results using the DESERT Underwater Network Simulator demonstrate throughput gains of up to 20.61% and energy savings of up to 36.60% compared with Deep Reinforcement Learning (DRL) baselines reported in the existing literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.20105v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fabio Busacca, Andrea Panebianco, Yin Sun</dc:creator>
    </item>
    <item>
      <title>EdgeSketch: Efficient Analysis of Massive Graph Streams</title>
      <link>https://arxiv.org/abs/2602.18957</link>
      <description>arXiv:2602.18957v1 Announce Type: cross 
Abstract: We introduce EdgeSketch, a compact graph representation for efficient analysis of massive graph streams. EdgeSketch provides unbiased estimators for key graph properties with controllable variance and supports implementing graph algorithms on the stored summary directly. It is constructed in a fully streaming manner, requiring a single pass over the edge stream, while offline analysis relies solely on the sketch. We evaluate the proposed approach on two representative applications: community detection via the Louvain method and graph reconstruction through node similarity estimation. Experiments demonstrate substantial memory savings and runtime improvements over both lossless representations and prior sketching approaches, while maintaining reliable accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.18957v1</guid>
      <category>cs.DS</category>
      <category>cs.NI</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jakub Lemiesz, Dingqi Yang, Philippe Cudr\'e-Mauroux</dc:creator>
    </item>
    <item>
      <title>A Quantum Internet Protocol Suite Beyond Layering</title>
      <link>https://arxiv.org/abs/2602.19998</link>
      <description>arXiv:2602.19998v1 Announce Type: cross 
Abstract: Layering, the protocol organization principle underpinning the classical Internet, is ill-suited to the Quantum Internet, built around entanglement, which is non-local and stateful. This paper proposes a quantum-native organizational principle based on dynamic composition, which replaces static layering with a distributed orchestration fabric driven by the node local state and in-band control. Each node runs a Dynamic Kernel that i) constructs a local PoA of candidate steps to advance a service intent, and ii) executes the PoA by composing atomic micro-protocols into context-aware procedures (the meta-protocols). Quantum packets carry an in-band control-field (the meta-header) containing the service intent and an append-only list of action-commit records, termed as stamps. Successive nodes exploit this minimal, authoritative history to construct their local PoAs. As quantum packets progress, these local commits collectively induce a network-wide, direct acyclic graph that certifies end-to-end service fulfillment, without requiring global synchronization. In contrast to classical encapsulation, the proposed suite enforces order by certification: dependency-aware local scheduling decides what may run at a certain node, stamps certify what did run and constrain subsequent planning. By embedding procedural control within the quantum packet, the design ensures coherence and consistency between entanglement-state evolution and control-flow, preventing divergence between resource state ad protocol logic, while remaining MP-agnostic and implementation-decoupled. The resulting suite is modular, adaptable to entanglement dynamics, and scalable. It operates correctly with or without optional control-plane hints. Indeed, when present, hints can steer QoS policies, without changing semantics. We argue that dynamic composition is the organizing principle required for a truly quantum-native Internet.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.19998v1</guid>
      <category>quant-ph</category>
      <category>cs.NI</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Angela Sara Cacciapuoti, Marcello Caleffi</dc:creator>
    </item>
    <item>
      <title>Digital Twin--Driven Adaptive Wavelet Strategy for Efficient 6G Backbone Network Telemetry</title>
      <link>https://arxiv.org/abs/2602.20034</link>
      <description>arXiv:2602.20034v1 Announce Type: cross 
Abstract: Classical orthogonal wavelets guarantee perfect reconstruction but rely on fixed bases optimized for polynomial smoothness, achieving suboptimal compression on signals with fractal spectral signatures. Conversely, learned methods offer adaptivity but typically enforce orthogonality via soft penalties, sacrificing structural guarantees.
  This work establishes a rigorous equivalence between Multiscale Entanglement Renormalization Ansatz (MERA) tensor networks and paraunitary filter banks. The resulting framework learns adaptive wavelets while enforcing exact orthogonality through manifold-constrained optimization, guaranteeing perfect reconstruction and energy conservation throughout training.
  Validation on Long-Range Dependent (LRD) network traffic demonstrates that learned filters outperform classical wavelets by 0.5--3.8~dB PSNR on six MAWI backbone traces (2020--2025, 314~Mbps--1.75~Gbps) while preserving the Hurst exponent within estimation uncertainty ($|\Delta H| \le 0.03$). These results establish MERA-inspired wavelets as a principled approach for telemetry compression in 6G digital twin synchronization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.20034v1</guid>
      <category>eess.SP</category>
      <category>cs.NI</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexandre Barbosa de Lima, Xavier Hesselbach, Jos\'e Roberto de Almeida Amazonas</dc:creator>
    </item>
    <item>
      <title>Agentic AI for Scalable and Robust Optical Systems Control</title>
      <link>https://arxiv.org/abs/2602.20144</link>
      <description>arXiv:2602.20144v1 Announce Type: cross 
Abstract: We present AgentOptics, an agentic AI framework for high-fidelity, autonomous optical system control built on the Model Context Protocol (MCP). AgentOptics interprets natural language tasks and executes protocol-compliant actions on heterogeneous optical devices through a structured tool abstraction layer. We implement 64 standardized MCP tools across 8 representative optical devices and construct a 410-task benchmark to evaluate request understanding, role-aware responses, multi-step coordination, robustness to linguistic variation, and error handling. We assess two deployment configurations--commercial online LLMs and locally hosted open-source LLMs--and compare them with LLM-based code generation baselines. AgentOptics achieves 87.7%--99.0% average task success rates, significantly outperforming code-generation approaches, which reach up to 50% success. We further demonstrate broader applicability through five case studies extending beyond device-level control to system orchestration, monitoring, and closed-loop optimization. These include DWDM link provisioning and coordinated monitoring of coherent 400 GbE and analog radio-over-fiber (ARoF) channels; autonomous characterization and bias optimization of a wideband ARoF link carrying 5G fronthaul traffic; multi-span channel provisioning with launch power optimization; closed-loop fiber polarization stabilization; and distributed acoustic sensing (DAS)-based fiber monitoring with LLM-assisted event detection. These results establish AgentOptics as a scalable, robust paradigm for autonomous control and orchestration of heterogeneous optical systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.20144v1</guid>
      <category>eess.SY</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zehao Wang, Mingzhe Han, Wei Cheng, Yue-Kai Huang, Philip Ji, Denton Wu, Mahdi Safari, Flemming Holtorf, Kenaish AlQubaisi, Norbert M. Linke, Danyang Zhuo, Yiran Chen, Ting Wang, Dirk Englund, Tingjun Chen</dc:creator>
    </item>
    <item>
      <title>A Hierarchical Gradient Tracking Algorithm for Mitigating Subnet-Drift in Fog Learning Networks</title>
      <link>https://arxiv.org/abs/2409.17430</link>
      <description>arXiv:2409.17430v3 Announce Type: replace 
Abstract: Federated learning (FL) encounters scalability challenges when implemented over fog networks that do not follow FL's conventional star topology architecture. Semi-decentralized FL (SD-FL) has proposed a solution for device-to-device (D2D) enabled networks that divides model cooperation into two stages: at the lower stage, D2D communications is employed for local model aggregations within subnetworks (subnets), while the upper stage handles device-server (DS) communications for global model aggregations. However, existing SD-FL schemes are based on gradient diversity assumptions that become performance bottlenecks as data distributions become more heterogeneous. In this work, we develop semi-decentralized gradient tracking (SD-GT), the first SD-FL methodology that removes the need for such assumptions by incorporating tracking terms into device updates for each communication layer. Our analytical characterization of SD-GT reveals upper bounds on convergence for non-convex, convex, and strongly-convex problems. We show how the bounds enable the development of an optimization algorithm that navigates the performance-efficiency trade-off by tuning subnet sampling rate and D2D rounds for each global training interval. Our subsequent numerical evaluations demonstrate that SD-GT obtains substantial improvements in trained model quality and communication cost relative to baselines in SD-FL and gradient tracking on several datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.17430v3</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Evan Chen, Shiqiang Wang, Christopher G. Brinton</dc:creator>
    </item>
    <item>
      <title>ASL360: AI-Enabled Adaptive Streaming of Layered 360$^\circ$ Video over UAV-assisted Wireless Networks</title>
      <link>https://arxiv.org/abs/2509.10544</link>
      <description>arXiv:2509.10544v2 Announce Type: replace 
Abstract: We propose ASL360, an adaptive deep reinforcement learning-based scheduler for on-demand 360$^\circ$ video streaming to mobile VR users in next generation wireless networks. We aim to maximize the overall Quality of Experience (QoE) of the users served over a UAV-assisted 5G wireless network. Our system model comprises a macro base station (MBS) and a UAV-mounted base station which both deploy mm-Wave transmission to the users. The 360$^\circ$ video is encoded into dependent layers and segmented tiles, allowing a user to schedule downloads of each layer's segments. Furthermore, each user utilizes multiple buffers to store the corresponding video layer's segments. We model the scheduling decision as a Constrained Markov Decision Process (CMDP), where the agent selects Base or Enhancement layers to maximize the QoE and use a policy gradient-based method (PPO) to find the optimal policy. Additionally, we implement a dynamic adjustment mechanism for cost components, allowing the system to adaptively balance and prioritize the video quality, buffer occupancy, and quality change based on real-time network and streaming session conditions. We demonstrate that ASL360 significantly improves the QoE, achieving approximately 2 dB higher average video quality, 80% lower average rebuffering time, and 57% lower video quality variation, relative to competitive baseline methods. Our results show the effectiveness of our layered and adaptive approach in enhancing the QoE in immersive videostreaming applications, particularly in dynamic and challenging network environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10544v2</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.MM</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alireza Mohammadhosseini, Jacob Chakareski, Nicholas Mastronarde</dc:creator>
    </item>
    <item>
      <title>Automatic Network Planning with Digital Radio Twin</title>
      <link>https://arxiv.org/abs/2509.12441</link>
      <description>arXiv:2509.12441v3 Announce Type: replace 
Abstract: Network planning seeks to determine base station parameters that maximize coverage and capacity in cellular networks. However, achieving optimal planning remains challenging due to the diversity of deployment scenarios and the significant simulation-to-reality discrepancy. In this paper, we propose \emph{AutoPlan}, a new automatic network planning framework by leveraging digital radio twin (DRT) techniques. We derive the DRT by finetuning the parameters of building materials to reduce the sim-to-real discrepancy based on crowdsource real-world user data. Leveraging the DRT, we design a Bayesian optimization based algorithm to optimize the deployment parameters of base stations efficiently. Using the field measurement from Husker-Net, we extensively evaluate \emph{AutoPlan} under various deployment scenarios, in terms of both coverage and capacity. The evaluation results show that \emph{AutoPlan} flexibly adapts to different scenarios and achieves performance comparable to exhaustive search, while requiring less than 2\% of its computation time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.12441v3</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaomeng Li, Yuru Zhang, Qiang Liu, Mehmet Can Vuran, Nathan Huynh, Li Zhao, Mizan Rahman, Eren Erman Ozguven</dc:creator>
    </item>
    <item>
      <title>Improving Outdoor Multi-cell Fingerprinting-based Positioning via Mobile Data Augmentation</title>
      <link>https://arxiv.org/abs/2509.19405</link>
      <description>arXiv:2509.19405v2 Announce Type: replace 
Abstract: Accurate outdoor positioning in cellular networks is hindered by sparse, heterogeneous measurement collections and the high cost of exhaustive site surveys. This paper introduces a lightweight, modular mobile data augmentation framework designed to enhance multi-cell fingerprinting-based positioning using operator-collected minimization of drive test (MDT) records. The proposed approach decouples spatial and radio-feature synthesis: kernel density estimation (KDE) models the empirical spatial distribution to generate geographically coherent synthetic locations, while a k-nearest-neighbor (KNN)-based block produces augmented per-cell radio fingerprints. The architecture is intentionally training-free, interpretable, and suitable for distributed or on-premise operator deployments, supporting privacy-aware workflows. We both validate each augmentation module independently and assess its end-to-end impact on fingerprinting-based positioning using a real-world MDT dataset provided by an Italian mobile network operator across diverse urban and peri-urban scenarios. Results show that the proposed KDE-KNN augmentation consistently improves positioning performance with respect to state-of-the-art approaches, reducing the median positioning error by up to 30% in the most sparsely sampled or structurally complex regions. We also observe region-dependent saturation effects, which emerge most rapidly in scenarios with high user density where the information gain from additional synthetic samples quickly diminishes. Overall, the framework offers a practical, low-complexity path to enhance operator positioning services using existing mobile data traces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.19405v2</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Tony Chahoud, Lorenzo Mario Amorosa, Riccardo Marini, Luca De Nardis</dc:creator>
    </item>
    <item>
      <title>Parametric Traversal for Multi-Dimensional Cost-Aware Graph Reasoning</title>
      <link>https://arxiv.org/abs/2602.13369</link>
      <description>arXiv:2602.13369v2 Announce Type: replace 
Abstract: Classical path search assumes complete graphs and scalar optimization metrics, yet real infrastructure networks are incomplete and require multi-dimensional evaluation. We introduce the concept of traversal: a generalization of paths that combines existing edges with gap transitions, missing but acceptable connections representing links that can be built. This abstraction captures how engineers actually reason about infrastructure: not just what exists, but what can be realized.
  We present a parametric framework that treats planned connections as first-class transitions, scales to large graphs through efficient candidate filtering, and uses multi-dimensional criteria to decide whether a traversal should continue to be explored or be abandoned. We evaluate the framework through representative scenarios in datacenter circuit design and optical route construction in telecommunication networks, demonstrating conditional feasibility, non-scalarizable trade-offs, and policy calibration capabilities beyond the reach of classical formulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13369v2</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicolas Tacheny</dc:creator>
    </item>
    <item>
      <title>Editable-DeepSC: Reliable Cross-Modal Semantic Communications for Facial Editing</title>
      <link>https://arxiv.org/abs/2411.15702</link>
      <description>arXiv:2411.15702v4 Announce Type: replace-cross 
Abstract: Interactive computer vision (CV) plays a crucial role in various real-world applications, whose performance is highly dependent on communication networks. Nonetheless, the data-oriented characteristics of conventional communications often do not align with the special needs of interactive CV tasks. To alleviate this issue, the recently emerged semantic communications only transmit task-related semantic information and exhibit a promising landscape to address this problem. However, the communication challenges associated with Semantic Facial Editing, one of the most important interactive CV applications on social media, still remain largely unexplored. In this paper, we fill this gap by proposing Editable-DeepSC, a novel cross-modal semantic communication approach for facial editing. Firstly, we theoretically discuss different transmission schemes that separately handle communications and editings, and emphasize the necessity of Joint Editing-Channel Coding (JECC) via iterative attributes matching, which integrates editings into the communication chain to preserve more semantic mutual information. To compactly represent the high-dimensional data, we leverage inversion methods via pre-trained StyleGAN priors for semantic coding. To tackle the dynamic channel noise conditions, we propose SNR-aware channel coding via model fine-tuning. Extensive experiments indicate that Editable-DeepSC can achieve superior editings while significantly saving the transmission bandwidth, even under high-resolution and out-of-distribution (OOD) settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15702v4</guid>
      <category>cs.IT</category>
      <category>cs.CV</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bin Chen, Wenbo Yu, Qinshan Zhang, Tianqu Zhuang, Hao Wu, Yong Jiang, Shu-Tao Xia</dc:creator>
    </item>
  </channel>
</rss>
