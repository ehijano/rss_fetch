<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 10 Jun 2025 09:23:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Efficient Computation of Closed Substrings</title>
      <link>https://arxiv.org/abs/2506.06452</link>
      <description>arXiv:2506.06452v1 Announce Type: new 
Abstract: A closed string $u$ is either of length one or contains a border that occurs only as a prefix and as a suffix in $u$ and nowhere else within $u$. In this paper, we present a fast and practical $O(n\log n)$ time algorithm to compute all $\Theta(n^2)$ closed substrings by introducing a compact representation for all closed substrings of a string $ w[1..n]$, using only $O(n \log n)$ space. We also present a simple and space-efficient solution to compute all maximal closed substrings (MCSs) using the suffix array ($\mathsf{SA}$) and the longest common prefix ($\mathsf{LCP}$) array of $w[1..n]$. Finally, we show that the exact number of MCSs ($M(f_n)$) in a Fibonacci word $ f_n $, for $n \geq 5$, is $\approx \left(1 + \frac{1}{\phi^2}\right) F_n \approx 1.382 F_n$, where $ \phi $ is the golden ratio.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.06452v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Samkith K Jain, Neerja Mhaskar</dc:creator>
    </item>
    <item>
      <title>Sample and Expand: Discovering Low-rank Submatrices With Quality Guarantees</title>
      <link>https://arxiv.org/abs/2506.06456</link>
      <description>arXiv:2506.06456v1 Announce Type: new 
Abstract: The problem of approximating a matrix by a low-rank one has been extensively studied. This problem assumes, however, that the whole matrix has a low-rank structure. This assumption is often false for real-world matrices. We consider the problem of discovering submatrices from the given matrix with bounded deviations from their low-rank approximations. We introduce an effective two-phase method for this task: first, we use sampling to discover small nearly low-rank submatrices, and then they are expanded while preserving proximity to a low-rank approximation. An extensive experimental evaluation confirms that the method we introduce compares favorably to existing approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.06456v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martino Ciaperoni, Aristides Gionis, Heikki Mannila</dc:creator>
    </item>
    <item>
      <title>Modern Minimal Perfect Hashing: A Survey</title>
      <link>https://arxiv.org/abs/2506.06536</link>
      <description>arXiv:2506.06536v1 Announce Type: new 
Abstract: Given a set $S$ of $n$ keys, a perfect hash function for $S$ maps the keys in $S$ to the first $m \geq n$ integers without collisions. It may return an arbitrary result for any key not in $S$ and is called minimal if $m = n$. The most important parameters are its space consumption, construction time, and query time. Years of research now enable modern perfect hash functions to be extremely fast to query, very space-efficient, and scale to billions of keys. Different approaches give different trade-offs between these aspects. For example, the smallest constructions get within 0.1% of the space lower bound of $\log_2(e)$ bits per key. Others are particularly fast to query, requiring only one memory access. Perfect hashing has many applications, for example to avoid collision resolution in static hash tables, and is used in databases, bioinformatics, and stringology.
  Since the last comprehensive survey in 1997, significant progress has been made. This survey covers the latest developments and provides a starting point for getting familiar with the topic. Additionally, our extensive experimental evaluation can serve as a guide to select a perfect hash function for use in applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.06536v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hans-Peter Lehmann, Thomas Mueller, Rasmus Pagh, Giulio Ermanno Pibiri, Peter Sanders, Sebastiano Vigna, Stefan Walzer</dc:creator>
    </item>
    <item>
      <title>Online Job Assignment</title>
      <link>https://arxiv.org/abs/2506.06893</link>
      <description>arXiv:2506.06893v1 Announce Type: new 
Abstract: Motivated primarily by applications in cloud computing, we study a simple, yet powerful, online allocation problem in which jobs of varying durations arrive over continuous time and must be assigned immediately and irrevocably to one of the available offline servers. Each server has a fixed initial capacity, with assigned jobs occupying one unit for their duration and releasing it upon completion. The algorithm earns a reward for each assignment upon completion. We consider a general heterogeneous setting where both the reward and duration of a job depend on the job-server pair. The objective of the online algorithm is to maximize the total collected reward, and remain competitive against an omniscient benchmark that knows all job arrivals in advance. Our main contribution is the design of a new online algorithm, termed Forward-Looking BALANCE (FLB), and using primal-dual framework to establish that it is (asymptotically) optimal-competitive.
  This meta-algorithm has two main primitives: (i) keeping track of the capacity used for each server at each time and applying a penalty function to this quantity, and (ii) adjusting the reward of assigning a job to a server by subtracting the total penalty of a particularly chosen subset of future times, in contrast to just looking at the current time. The FLB algorithm then assigns the arriving job to the server with the maximum adjusted reward. If R and D are the ratios of maximum over minimum rewards and durations, we show that the FLB algorithm obtains an asymptotic competitive ratio of ln(RD)+3lnln(max(R,D))+O(1). We further show this bound has optimal dependencies on all the parameters. Our main analysis combines a novel dual-fitting technique, which leverages the configuration LP benchmark for this problem, and a novel inductive argument to establish the capacity feasibility of the algorithm, which might be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.06893v1</guid>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Farbod Ekbatani, Yiding Feng, Ian Kash, Rad Niazadeh</dc:creator>
    </item>
    <item>
      <title>On Sketching Trimmed Statistics</title>
      <link>https://arxiv.org/abs/2506.07342</link>
      <description>arXiv:2506.07342v1 Announce Type: new 
Abstract: We present space-efficient linear sketches for estimating trimmed statistics of an $n$-dimensional frequency vector $x$, e.g., the sum of $p$-th powers of the largest $k$ frequencies (i.e., entries) in absolute value, or the $k$-trimmed vector, which excludes the top and bottom $k$ frequencies. This is called the $F_p$ moment of the trimmed vector. Trimmed measures are used in robust estimation, as seen in the R programming language's `trim.var' function and the `trim' parameter in the mean function. Linear sketches improve time and memory efficiency and are applicable to streaming and distributed settings. We initiate the study of sketching these statistics and give a new condition for capturing their space complexity. When $k \ge n/poly\log n$, we give a linear sketch using $poly(1/\varepsilon, \log n)$ space which provides a $(1 \pm \varepsilon)$ approximation to the top-$k$ $F_p$ moment for $p \in [0,2]$. For general $k$, we give a sketch with the same guarantees under a condition relating the $k$-th largest frequency to the tail mass, and show this condition is necessary. For the $k$-trimmed version, our sketch achieves optimal error guarantees under the same condition. We extend our methods to $p &gt; 2$ and also address related problems such as computing the $F_p$ moment of frequencies above a threshold, finding the largest $k$ such that the $F_p$ moment of the top $k$ exceeds $k^{p+1}$, and the $F_p$ moment of the top $k$ frequencies such that each entry is at least $k$. Notably, our algorithm for this third application improves upon the space bounds of the algorithm of Govindan, Monemizadeh, and Muthukrishnan (PODS '17) for computing the $h$-index. We show empirically that our top $k$ algorithm uses much less space compared to Count-Sketch while achieving the same error.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.07342v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Honghao Lin, Hoai-An Nguyen, David P. Woodruff</dc:creator>
    </item>
    <item>
      <title>On Deterministically Finding an Element of High Order Modulo a Composite</title>
      <link>https://arxiv.org/abs/2506.07668</link>
      <description>arXiv:2506.07668v1 Announce Type: new 
Abstract: We give a deterministic algorithm that, given a composite number $N$ and a target order $D \ge N^{1/6}$, runs in time $D^{1/2+o(1)}$ and finds either an element $a \in \mathbb{Z}_N^*$ of multiplicative order at least $D$, or a nontrivial factor of $N$. Our algorithm improves upon an algorithm of Hittmeir (arXiv:1608.08766), who designed a similar algorithm under the stronger assumption $D \ge N^{2/5}$. Hittmeir's algorithm played a crucial role in the recent breakthrough deterministic integer factorization algorithms of Hittmeir and Harvey (arXiv:2006.16729, arXiv:2010.05450, arXiv:2105.11105). When $N$ is assumed to have an $r$-power divisor with $r\ge 2$, our algorithm provides the same guarantees assuming $D \ge N^{1/6r}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.07668v1</guid>
      <category>cs.DS</category>
      <category>math.NT</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziv Oznovich, Ben Lee Volk</dc:creator>
    </item>
    <item>
      <title>#P is Sandwiched by One and Two #2DNF Calls: Is Subtraction Stronger Than We Thought?</title>
      <link>https://arxiv.org/abs/2506.06716</link>
      <description>arXiv:2506.06716v1 Announce Type: cross 
Abstract: The canonical class in the realm of counting complexity is #P. It is well known that the problem of counting the models of a propositional formula in disjunctive normal form (#DNF) is complete for #P under Turing reductions. On the other hand, #DNF $\in$ spanL and spanL $\not\subseteq$ #P unless NL = NP. Hence, the class of functions logspace-reducible to #DNF is a strict subset of #P under plausible complexity-theoretic assumptions. By contrast, we show that two calls to a (restricted) #2DNF oracle suffice to capture gapP, namely, that the logspace many-one closure of the subtraction between the results of two #2DNF calls is gapP. Because #P $\not\subseteq$ gapP, #P is strictly contained between one and two #2DNF oracle calls.
  Surprisingly, the propositional formulas needed in both calls are linear-time computable, and the reduction preserves interesting structural as well as symmetry properties, leading to algorithmic applications. We show that a single subtraction suffices to compensate for the absence of negation while still capturing gapP, i.e., our results carry over to the monotone fragments of #2SAT and #2DNF. Since our reduction is linear-time, it preserves sparsity and, as a consequence we obtain a sparsification lemma for both #2SAT and #2DNF. This has only been known for kSAT with k $\geq$ 3 and respective counting versions. We further show that both #2DNF calls can be combined into a single call if we allow a little postprocessing (computable by AC0- or TC0-circuits). Consequently, we derive refined versions of Toda's Theorem: PH $\subseteq$ [#MON2SAT]$^{log}_{TC0}$ = [#MON2DNF]$^{log}_{TC0}$ and PH $\subseteq$ [#IMPL2SAT]$^{log}_{AC0}$. Our route to these results is via structure-aware reductions that preserve parameters like treewidth up to an additive overhead. The absence of multiplicative overhead indeed yields parameterized SETH-tight lower bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.06716v1</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>cs.LO</category>
      <category>math.CO</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Max Bannach, Erik D. Demaine, Timothy Gomez, Markus Hecher</dc:creator>
    </item>
    <item>
      <title>Delegation with Costly Inspection</title>
      <link>https://arxiv.org/abs/2506.07162</link>
      <description>arXiv:2506.07162v1 Announce Type: cross 
Abstract: We study the problem of delegated choice with inspection cost (DCIC), which is a variant of the delegated choice problem by Kleinberg and Kleinberg (EC'18) as well as an extension of the Pandora's box problem with nonobligatory inspection (PNOI) by Doval (JET'18). In our model, an agent may strategically misreport the proposed element's utility, unlike the standard delegated choice problem which assumes that the agent truthfully reports the utility for the proposed alternative. Thus, the principal needs to inspect the proposed element possibly along with other alternatives to maximize its own utility, given an exogenous cost of inspecting each element. Further, the delegation itself incurs a fixed cost, thus the principal can decide whether to delegate or not and inspect by herself.
  We show that DCIC indeed is a generalization of PNOI where the side information from a strategic agent is available at certain cost, implying its NP-hardness by Fu, Li, and Liu (STOC'23). We first consider a costless delegation setting in which the cost of delegation is free. We prove that the maximal mechanism over the pure delegation with a single inspection and an PNOI policy without delegation achieves a $3$-approximation for DCIC with costless delegation, which is further proven to be tight. These results hold even when the cost comes from an arbitrary monotone set function, and can be improved to a $2$-approximation if the cost of inspection is the same for every element. We extend these techniques by presenting a constant factor approximate mechanism for the general setting for rich class of instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.07162v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <category>econ.TH</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammad T. Hajiaghayi, Piotr Krysta, Mohammad Mahdavi, Suho Shin</dc:creator>
    </item>
    <item>
      <title>CNFs and DNFs with Exactly $k$ Solutions</title>
      <link>https://arxiv.org/abs/2506.07268</link>
      <description>arXiv:2506.07268v1 Announce Type: cross 
Abstract: Model counting is a fundamental problem that consists of determining the number of satisfying assignments for a given Boolean formula. The weighted variant, which computes the weighted sum of satisfying assignments, has extensive applications in probabilistic reasoning, network reliability, statistical physics, and formal verification. A common approach for solving weighted model counting is to reduce it to unweighted model counting, which raises an important question: {\em What is the minimum number of terms (or clauses) required to construct a DNF (or CNF) formula with exactly $k$ satisfying assignments?}
  In this paper, we establish both upper and lower bounds on this question. We prove that for any natural number $k$, one can construct a monotone DNF formula with exactly $k$ satisfying assignments using at most $O(\sqrt{\log k}\log\log k)$ terms. This construction represents the first $o(\log k)$ upper bound for this problem. We complement this result by showing that there exist infinitely many values of $k$ for which any DNF or CNF representation requires at least $\Omega(\log\log k)$ terms or clauses. These results have significant implications for the efficiency of model counting algorithms based on formula transformations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.07268v1</guid>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>cs.LO</category>
      <category>math.CO</category>
      <category>math.LO</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>L. Sunil Chandran, Rishikesh Gajjala, Kuldeep S. Meel</dc:creator>
    </item>
    <item>
      <title>Discrete and Continuous Difference of Submodular Minimization</title>
      <link>https://arxiv.org/abs/2506.07952</link>
      <description>arXiv:2506.07952v1 Announce Type: cross 
Abstract: Submodular functions, defined on continuous or discrete domains, arise in numerous applications. We study the minimization of the difference of two submodular (DS) functions, over both domains, extending prior work restricted to set functions. We show that all functions on discrete domains and all smooth functions on continuous domains are DS. For discrete domains, we observe that DS minimization is equivalent to minimizing the difference of two convex (DC) functions, as in the set function case. We propose a novel variant of the DC Algorithm (DCA) and apply it to the resulting DC Program, obtaining comparable theoretical guarantees as in the set function case. The algorithm can be applied to continuous domains via discretization. Experiments demonstrate that our method outperforms baselines in integer compressive sensing and integer least squares.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.07952v1</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Proceedings of the 42nd International Conference on Machine Learning, Vancouver, Canada. PMLR 267, 2025</arxiv:journal_reference>
      <dc:creator>George Orfanides, Tim Hoheisel, Marwa El Halabi</dc:creator>
    </item>
    <item>
      <title>Analysis of Two-variable Recurrence Relations with Application to Parameterized Approximations</title>
      <link>https://arxiv.org/abs/1911.02653</link>
      <description>arXiv:1911.02653v3 Announce Type: replace 
Abstract: In this paper we introduce randomized branching as a tool for parameterized approximation and develop the mathematical machinery for its analysis. Our algorithms improve the best known running times of parameterized approximation algorithms for Vertex Cover and $3$-Hitting Set for a wide range of approximation ratios. One notable example is a simple parameterized random $1.5$-approximation algorithm for Vertex Cover, whose running time of $\tilde{O}(1.01657^k)$ substantially improves the best known runnning time of $\tilde{O}(1.0883^k)$ [Brankovic and Fernau, 2013]. For $3$-Hitting Set we present a parameterized random $2$-approximation algorithm with running time of $\tilde{O}(1.0659^k)$, improving the best known $\tilde{O}(1.29^k)$ algorithm of [Brankovic and Fernau, 2012].
  The running times of our algorithms are derived from an asymptotic analysis of a wide class of two-variable recurrence relations of the form: $$p(b,k) = \min_{1\leq j \leq N} \sum_{i=1}^{r_j} \bar{\gamma}_i^j \cdot p(b-\bar{b}^j_i, k-\bar{k}_i^j),$$ where $\bar{b}^j$ and $\bar{k}^j$ are vectors of natural numbers, and $\bar{\gamma}^j$ is a probability distribution over $r_j$ elements, for $1\leq j \leq N$. Our main theorem asserts that for any $\alpha&gt;0$, $$\lim_{k \rightarrow \infty } \frac{1}{k} \cdot \ln p(\lfloor{\alpha k}\rfloor,k) = -\max_{1\leq j \leq N} M_j,$$
  where $M_j$ depends only on $\alpha$, $\bar{\gamma}^j$, $\bar{b}^j$ and $\bar{k}^j$, and can be efficiently calculated by solving a simple numerical optimization problem. To prove the theorem we show an equivalence between the recurrence and a stochastic process. We analyze this process using the {\em method of types}, by introducing an adaptation of Sanov's theorem to our setting. We believe our novel analysis of recurrence relations which is of independent interest is a main contribution of this paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:1911.02653v3</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ariel Kulik, Hadas Shachnai</dc:creator>
    </item>
    <item>
      <title>Bit catastrophes for the Burrows-Wheeler Transform</title>
      <link>https://arxiv.org/abs/2404.10426</link>
      <description>arXiv:2404.10426v2 Announce Type: replace 
Abstract: A bit catastrophe, loosely defined, is when a change in just one character of a string causes a significant change in the size of the compressed string. We study this phenomenon for the Burrows-Wheeler Transform (BWT), a string transform at the heart of several of the most popular compressors and aligners today. The parameter determining the size of the compressed data is the number of equal-letter runs of the BWT, commonly denoted $r$.
  We exhibit infinite families of strings in which insertion, deletion, resp. substitution of one character increases $r$ from constant to $\Theta(\log n)$, where $n$ is the length of the string. These strings can be interpreted both as examples for an increase by a multiplicative or an additive $\Theta(\log n)$-factor. As regards multiplicative factor, they attain the upper bound given by Akagi, Funakoshi, and Inenaga [Inf &amp; Comput. 2023] of $O(\log n \log r)$, since here $r=O(1)$.
  We then give examples of strings in which insertion, deletion, resp. substitution of a character increases $r$ by a $\Theta(\sqrt{n})$ additive factor. These strings significantly improve the best known lower bound for an additive factor of $\Omega(\log n)$ [Giuliani et al., SOFSEM 2021].</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10426v2</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s00224-024-10212-9</arxiv:DOI>
      <arxiv:journal_reference>Theory of Computing Systems 69, 19 (2025)</arxiv:journal_reference>
      <dc:creator>Sara Giuliani, Shunsuke Inenaga, Zsuzsanna Lipt\'ak, Giuseppe Romana, Marinella Sciortino, Cristian Urbina</dc:creator>
    </item>
    <item>
      <title>KeBaB: $k$-mer based breaking for finding long MEMs</title>
      <link>https://arxiv.org/abs/2502.20338</link>
      <description>arXiv:2502.20338v3 Announce Type: replace 
Abstract: Long maximal exact matches (MEMs) are used in many genomics applications such as read classification and sequence alignment. Li's ropebwt3 finds long MEMs quickly because it can often ignore much of its input. In this paper we show that a fast and space efficient $k$-mer filtration step using a Bloom filter speeds up MEM-finders such as ropebwt3 even further by letting them ignore even more. We also show experimentally that our approach can accelerate metagenomic classification without significantly hurting accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20338v3</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nathaniel K. Brown, Lore Depuydt, Mohsen Zakeri, Anas Alhadi, Nour Allam, Dove Begleiter, Nithin Bharathi Kabilan Karpagavalli, Suchith Sridhar Khajjayam, Hamza Wahed, Travis Gagie, Ben Langmead</dc:creator>
    </item>
    <item>
      <title>Cost-driven prunings for iterative solving of constrained routing problem with SRLG-disjoint protection</title>
      <link>https://arxiv.org/abs/2503.08262</link>
      <description>arXiv:2503.08262v2 Announce Type: replace 
Abstract: The search for the optimal pair of active and protection paths in a network with Shared Risk Link Groups (SRLG) is a challenging but high-value problem in the industry that is inevitable in ensuring reliable connections on the modern Internet. We propose a new approach to solving this problem, with a novel use of statistical analysis of the distribution of paths with respect to their cost, which is an integral part of our innovation. The key idea in our algorithm is to employ iterative updates of cost bounds, allowing efficient pruning of suboptimal paths. This idea drives an efficacious exploration of the search space. We benchmark our algorithms against the state-of-the-art algorithms that exploit the alternative strategy of conflicting links exclusion, showing that our approach has the advantage of finding more feasible connections within a set time limit.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08262v2</guid>
      <category>cs.DS</category>
      <category>cs.NI</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>P. A. Mosharev, Choon-Meng Lee, Xu Shu, Xiaoshan Zhang, Man-Hong Yung</dc:creator>
    </item>
    <item>
      <title>New Distributed Interactive Proofs for Planarity: A Matter of Left and Right</title>
      <link>https://arxiv.org/abs/2505.00338</link>
      <description>arXiv:2505.00338v2 Announce Type: replace 
Abstract: We provide new distributed interactive proofs (DIP) for planarity and related graph families. The notion of a \emph{distributed interactive proof} (DIP) was introduced by Kol, Oshman, and Saxena (PODC 2018). In this setting, the verifier consists of $n$ nodes connected by a communication graph $G$. The prover is a single entity that communicates with all nodes by short messages. The goal is to verify that the graph $G$ satisfies a certain property (e.g., planarity) in a small number of rounds, and with a small communication bound, denoted as the \emph{proof size}.
  Prior work by Naor, Parter and Yogev (SODA 2020) presented a DIP for planarity that uses three interaction rounds and a proof size of $O(\log n)$. Feuilloley et al.\ (PODC 2020) showed that the same can be achieved with a single interaction round and without randomization, by providing a proof labeling scheme with a proof size of $O(\log n)$. In a subsequent work, Bousquet, Feuilloley, and Pierron (OPODIS 2021) achieved the same bound for related graph families such as outerplanarity, series-parallel graphs, and graphs of treewidth at most $2$. In this work, we design new DIPs that use exponentially shorter proofs compared to the state-of-the-art bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00338v2</guid>
      <category>cs.DS</category>
      <category>cs.DC</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuval Gil, Merav Parter</dc:creator>
    </item>
    <item>
      <title>Shuffling Cards When You Are of Very Little Brain: Low Memory Generation of Permutations</title>
      <link>https://arxiv.org/abs/2505.01287</link>
      <description>arXiv:2505.01287v2 Announce Type: replace 
Abstract: How can we generate a permutation of the numbers $1$ through $n$ so that it is hard to guess the next element given the history so far? The twist is that the generator of the permutation (the ``Dealer") has limited memory, while the ``Guesser" has unlimited memory. With unbounded memory (actually $n$ bits suffice), the Dealer can generate a truly random permutation where $\ln n$ is the expected number of correct guesses.
  Our main results establish tight bounds for the relationship between the guessing probability and the memory $m$ required to generate the permutation. We suggest a method for an $m$-bit Dealer that operates in constant time per turn, and any Guesser can pick correctly only $O(n/m+\log m)$ cards in expectation. The method is fully transparent, requiring no hidden information from the Dealer (i.e., it is "open book" or "whitebox").
  We show that this bound is the best possible, even with secret memory. Specifically, for any $m$-bit Dealer, there is a (computationally powerful) guesser that achieves $\Omega(n/m+\log m)$ correct guesses in expectation. We point out that the assumption that the Guesser is computationally powerful is necessary: under cryptographic assumptions, there exists a low-memory Dealer that can fool any computationally bounded guesser.
  We also give an $O(n)$ bit memory Dealer that generates perfectly random permutations and operates in constant time per turn.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01287v2</guid>
      <category>cs.DS</category>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Boaz Menuhin, Moni Naor</dc:creator>
    </item>
    <item>
      <title>On the Complexity of Finding Approximate LCS of Multiple Strings</title>
      <link>https://arxiv.org/abs/2505.15992</link>
      <description>arXiv:2505.15992v2 Announce Type: replace 
Abstract: Finding an Approximate Longest Common Substring (ALCS) within a given set $S=\{s_1,s_2,\ldots,s_m\}$ of $m \ge 2$ strings is a problem of particular importance in computational biology (e.g., identifying related mutations across multiple genetic sequences). In this paper, we study several ALCS problems that, for given integers $k$ and $t \le m$, require finding a longest string $u$ -- or a longest substring $u$ of any string in $S$ -- that lies within distance $k$ of at least one substring in $t$ distinct strings of $S$. Although two of these problems, denoted $k$-LCS and \textit{k-t} LCS, are NP-hard, nevertheless restricted variations of them under Hamming and edit distance can be solved in $O(N^2)$ and $O(k\ell N^2)$ time, respectively, where $\ell$ is the length of each string and $N=m\ell$. Further, we show that using the $k$-errata tree data structure, a restricted variation of the ALCS problem under both Hamming and edit distance can be computed in $O(mN\log^k \ell)$ time. We also establish an $O(N^2)$ conditional lower bound for a variation of the ALCS problem under the Strong Exponential Time Hypothesis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.15992v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Hamed Hasibi, Neerja Mhaskar, W. F. Smyth</dc:creator>
    </item>
    <item>
      <title>Unique Decoding of Reed-Solomon and Related Codes for Semi-Adversarial Errors</title>
      <link>https://arxiv.org/abs/2504.10399</link>
      <description>arXiv:2504.10399v2 Announce Type: replace-cross 
Abstract: For over a quarter century, the Guruswami--Sudan algorithm has served as the state-of-the-art for list-decoding Reed--Solomon (RS) codes up to the Johnson bound against adversarial errors. However, some recent structural results on the combinatorial list decoding of randomly punctured Reed--Solomon codes suggest that Johnson bound can likely be broken for some subclasses of RS codes. Motivated by these results, we seek to make traction on understanding adversarial decoding by considering a new model: semi-adversarial errors. This error model bridges between fully random errors and fully adversarial errors by allowing some symbols of a message to be corrupted by an adversary while others are replaced with uniformly random symbols.
  As our main quest, we seek to understand optimal efficient unique decoding algorithms in the semi-adversarial model. In particular, we revisit some classical results on decoding interleaved Reed--Solomon codes (aka subfield evaluation RS codes) in the random error model by Bleichenbacher--Kiayias--Yung (BKY) and work to improve and extend their analysis. First, we give an improved implementation and analysis of the BKY algorithm for interleaved Reed--Solomon codes in the semi-adversarial model. In particular, our algorithm runs in near-linear time, and for most mixtures of random and adversarial errors, our analysis matches the information-theoretic optimum.
  Moreover, inspired by the BKY algorithm, we use a novel interpolation to extend our approach to the settings of folded Reed--Solomon and multiplicity codes, resulting in fast algorithms for unique decoding against semi-adversarial errors. A particular advantage of our near-linear time algorithm over state-of-the-art decoding algorithms for adversarial errors is that its running time depends only on a polynomial function of the folding parameter rather than on an exponential function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10399v2</guid>
      <category>cs.IT</category>
      <category>cs.DS</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joshua Brakensiek, Yeyuan Chen, Manik Dhar, Zihan Zhang</dc:creator>
    </item>
    <item>
      <title>Computing Diverse and Nice Triangulations</title>
      <link>https://arxiv.org/abs/2506.01323</link>
      <description>arXiv:2506.01323v2 Announce Type: replace-cross 
Abstract: We initiate the study of computing diverse triangulations to a given polygon. Given a simple $n$-gon $P$, an integer $ k \geq 2 $, a quality measure $\sigma$ on the set of triangulations of $P$ and a factor $ \alpha \geq 1 $, we formulate the Diverse and Nice Triangulations (DNT) problem that asks to compute $k$ \emph{distinct} triangulations $T_1,\dots,T_k$ of $P$ such that a) their diversity, $\sum_{i &lt; j} d(T_i,T_j) $, is as large as possible \emph{and} b) they are nice, i.e., $\sigma(T_i) \leq \alpha \sigma^* $ for all $1\leq i \leq k$. Here, $d$ denotes the symmetric difference of edge sets of two triangulations, and $\sigma^*$ denotes the best quality of triangulations of $P$, e.g., the minimum Euclidean length.
  As our main result, we provide a $\mathrm{poly}(n,k)$-time approximation algorithm for the DNT problem that returns a collection of $k$ distinct triangulations whose diversity is at least $1 - \Theta(1/k)$ of the optimal, and each triangulation satisfies the quality constraint. This is accomplished by studying \emph{bi-criteria triangulations} (BCT), which are triangulations that simultaneously optimize two criteria, a topic of independent interest. We complement our approximation algorithms by showing that the DNT problem and the BCT problem are NP-hard.
  Finally, for the version where diversity is defined as $\min_{i &lt; j} d(T_i,T_j) $, we show a reduction from the problem of computing optimal Hamming codes, and provide an $n^{O(k)}$-time $\tfrac12$-approximation algorithm. This improves over the naive ${C_{n-2} \choose k} \approx 2^{O(nk)}$ time bound for enumerating all $k$-tuples among the triangulations of a simple $n$-gon, where $C_n$ denotes the $n$-th Catalan number.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01323v2</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Waldo G\'alvez, Mayank Goswami, Arturo Merino, GiBeom Park, Meng-Tsung Tsai</dc:creator>
    </item>
    <item>
      <title>An $O(log log n)$-approximate budget feasible mechanism for subadditive valuations</title>
      <link>https://arxiv.org/abs/2506.04665</link>
      <description>arXiv:2506.04665v2 Announce Type: replace-cross 
Abstract: In budget-feasible mechanism design, there is a set of items $U$, each owned by a distinct seller. The seller of item $e$ incurs a private cost $\overline{c}_e$ for supplying her item. A buyer wishes to procure a set of items from the sellers of maximum value, where the value of a set $S\subseteq U$ of items is given by a valuation function $v:2^U\to \mathbb{R}_+$. The buyer has a budget of $B \in \mathbb{R}_+$ for the total payments made to the sellers. We wish to design a mechanism that is truthful, that is, sellers are incentivized to report their true costs, budget-feasible, that is, the sum of the payments made to the sellers is at most the budget $B$, and that outputs a set whose value is large compared to $\text{OPT}:=\max\{v(S):\overline{c}(S)\le B,S\subseteq U\}$.
  Budget-feasible mechanism design has been extensively studied, with the literature focussing on (classes of) subadditive valuation functions, and various polytime, budget-feasible mechanisms, achieving constant-factor approximation, have been devised for the special cases of additive, submodular, and XOS valuations. However, for general subadditive valuations, the best-known approximation factor achievable by a polytime budget-feasible mechanism (given access to demand oracles) was only $O(\log n / \log \log n)$, where $n$ is the number of items.
  We improve this state-of-the-art significantly by designing a randomized budget-feasible mechanism for subadditive valuations that \emph{achieves a substantially-improved approximation factor of $O(\log\log n)$ and runs in polynomial time, given access to demand oracles.}</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04665v2</guid>
      <category>cs.GT</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rian Neogi, Kanstantsin Pashkovich, Chaitanya Swamy</dc:creator>
    </item>
  </channel>
</rss>
