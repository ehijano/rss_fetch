<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DC</link>
    <description>cs.DC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 15 Aug 2025 04:00:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Hard Shell, Reliable Core: Improving Resilience in Replicated Systems with Selective Hybridization</title>
      <link>https://arxiv.org/abs/2508.10141</link>
      <description>arXiv:2508.10141v1 Announce Type: new 
Abstract: Hybrid fault models are known to be an effective means for enhancing the robustness of consensus-based replicated systems. However, existing hybridization approaches suffer from limited flexibility with regard to the composition of crash-tolerant and Byzantine fault-tolerant system parts and/or are associated with a significant diversification overhead. In this paper we address these issues with ShellFT, a framework that leverages the concept of micro replication to allow system designers to freely choose the parts of the replication logic that need to be resilient against Byzantine faults. As a key benefit, such a selective hybridization makes it possible to develop hybrid solutions that are tailored to the specific characteristics and requirements of individual use cases. To illustrate this flexibility, we present three custom ShellFT protocols and analyze the complexity of their implementations. Our evaluation shows that compared with traditional hybridization approaches, ShellFT is able to decrease diversification costs by more than 70%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10141v1</guid>
      <category>cs.DC</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Laura Lawniczak, Tobias Distler</dc:creator>
    </item>
    <item>
      <title>Mixed-Precision Performance Portability of FFT-Based GPU-Accelerated Algorithms for Block-Triangular Toeplitz Matrices</title>
      <link>https://arxiv.org/abs/2508.10202</link>
      <description>arXiv:2508.10202v1 Announce Type: new 
Abstract: The hardware diversity displayed in leadership-class computing facilities, alongside the immense performance boosts exhibited by today's GPUs when computing in lower precision, provide a strong incentive for scientific HPC workflows to adopt mixed-precision algorithms and performance portability models. We present an on-the-fly framework using Hipify for performance portability and apply it to FFTMatvec-an HPC application that computes matrix-vector products with block-triangular Toeplitz matrices. Our approach enables FFTMatvec, initially a CUDA-only application, to run seamlessly on AMD GPUs with excellent observed performance. Performance optimizations for AMD GPUs are integrated directly into the open-source rocBLAS library, keeping the application code unchanged. We then present a dynamic mixed-precision framework for FFTMatvec; a Pareto front analysis determines the optimal mixed-precision configuration for a desired error tolerance. Results are shown for AMD Instinct MI250X, MI300X, and the newly launched MI355X GPUs. The performance-portable, mixed-precision FFTMatvec is scaled to 2,048 GPUs on the OLCF Frontier supercomputer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10202v1</guid>
      <category>cs.DC</category>
      <category>cs.NA</category>
      <category>cs.PF</category>
      <category>math.NA</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sreeram Venkat, Kasia Swirydowicz, Noah Wolfe, Omar Ghattas</dc:creator>
    </item>
    <item>
      <title>GPZ: GPU-Accelerated Lossy Compressor for Particle Data</title>
      <link>https://arxiv.org/abs/2508.10305</link>
      <description>arXiv:2508.10305v1 Announce Type: new 
Abstract: Particle-based simulations and point-cloud applications generate massive, irregular datasets that challenge storage, I/O, and real-time analytics. Traditional compression techniques struggle with irregular particle distributions and GPU architectural constraints, often resulting in limited throughput and suboptimal compression ratios. In this paper, we present GPZ, a high-performance, error-bounded lossy compressor designed specifically for large-scale particle data on modern GPUs. GPZ employs a novel four-stage parallel pipeline that synergistically balances high compression efficiency with the architectural demands of massively parallel hardware. We introduce a suite of targeted optimizations for computation, memory access, and GPU occupancy that enables GPZ to achieve near-hardware-limit throughput. We conduct an extensive evaluation on three distinct GPU architectures (workstation, data center, and edge) using six large-scale, real-world scientific datasets from five distinct domains. The results demonstrate that GPZ consistently and significantly outperforms five state-of-the-art GPU compressors, delivering up to 8x higher end-to-end throughput while simultaneously achieving superior compression ratios and data quality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10305v1</guid>
      <category>cs.DC</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruoyu Li, Yafan Huang, Longtao Zhang, Zhuoxun Yang, Sheng Di, Jiajun Huang, Jinyang Liu, Jiannan Tian, Xin Liang, Guanpeng Li, Hanqi Guo, Franck Cappello, Kai Zhao</dc:creator>
    </item>
    <item>
      <title>Flexible Personalized Split Federated Learning for On-Device Fine-Tuning of Foundation Models</title>
      <link>https://arxiv.org/abs/2508.10349</link>
      <description>arXiv:2508.10349v1 Announce Type: new 
Abstract: Fine-tuning foundation models is critical for superior performance on personalized downstream tasks, compared to using pre-trained models. Collaborative learning can leverage local clients' datasets for fine-tuning, but limited client data and heterogeneous data distributions hinder effective collaboration. To address the challenge, we propose a flexible personalized federated learning paradigm that enables clients to engage in collaborative learning while maintaining personalized objectives. Given the limited and heterogeneous computational resources available on clients, we introduce \textbf{flexible personalized split federated learning (FlexP-SFL)}. Based on split learning, FlexP-SFL allows each client to train a portion of the model locally while offloading the rest to a server, according to resource constraints. Additionally, we propose an alignment strategy to improve personalized model performance on global data. Experimental results show that FlexP-SFL outperforms baseline models in personalized fine-tuning efficiency and final accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10349v1</guid>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianjun Yuan, Jiaxiang Geng, Pengchao Han, Xianhao Chen, Bing Luo</dc:creator>
    </item>
    <item>
      <title>Dalek: An Unconventional and Energy-Aware Heterogeneous Cluster</title>
      <link>https://arxiv.org/abs/2508.10481</link>
      <description>arXiv:2508.10481v1 Announce Type: new 
Abstract: Dalek is an experimental compute cluster designed to evaluate the performance of heterogeneous, consumer-grade hardware for software design, prototyping, and algorithm development. In contrast to traditional computing centers that rely on costly, server-class components, Dalek integrates CPUs and GPUs typically found in mini-PCs, laptops, and gaming desktops, providing a cost-effective yet versatile platform. This document details the cluster's architecture and software stack, and presents results from synthetic benchmarks. Furthermore, it introduces a custom energy monitoring platform capable of delivering 1000 averaged samples per second with milliwatt-level resolution. This high-precision monitoring capability enables a wide range of energy-aware research experiments in applied Computer Science.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10481v1</guid>
      <category>cs.DC</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adrien Cassagne (ALSOC), No\'e Amiot (ALSOC), Manuel Bouyer (ALSOC)</dc:creator>
    </item>
    <item>
      <title>Introducing CQ: A C-like API for Quantum Accelerated HPC</title>
      <link>https://arxiv.org/abs/2508.10854</link>
      <description>arXiv:2508.10854v1 Announce Type: new 
Abstract: In this paper we present CQ, a specification for a C-like API for quantum accelerated HPC, as well as CQ-SimBE, a reference implementation of CQ written in C99, and built on top of the statevector simulator QuEST. CQ focuses on enabling the incremental integration of quantum computing into classical HPC codes by supporting runtime offloading from languages such as C and Fortran. It provides a way of describing and offloading quantum computations which is compatible with strictly and strongly typed compiled languages, and gives the programmer fine-grained control over classical data movement. The CQ Simulated Backend (CQ-SimBE) provides both a way to demonstrate the usage and utility of CQ, and a space to experiment with new features such as support for analogue quantum computing. Both the CQ specification and CQ-SimBE are open-source, and available in public repositories.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10854v1</guid>
      <category>cs.DC</category>
      <category>quant-ph</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Oliver Thomson Brown, Mateusz Meller, James Richings</dc:creator>
    </item>
    <item>
      <title>Minimmit: Fast Finality with Even Faster Blocks</title>
      <link>https://arxiv.org/abs/2508.10862</link>
      <description>arXiv:2508.10862v1 Announce Type: new 
Abstract: Minimmit is a new protocol for State-Machine-Replication (SMR) that extends the '2-round finality' approach of protocols such as Alpenglow to further reduce latency, by allowing for faster progression through 'views'. This preliminary draft provides motivation and pseudocode, together with proofs of consistency and liveness. An updated draft with a proof of optimistic responsiveness, suggested optimizations, and experiments, is to follow.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10862v1</guid>
      <category>cs.DC</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Brendan Kobayashi Chou, Andrew Lewis-Pye, Patrick O'Grady</dc:creator>
    </item>
    <item>
      <title>Efficient Parallel Execution of Blockchain Transactions Leveraging Conflict Specifications</title>
      <link>https://arxiv.org/abs/2503.03203</link>
      <description>arXiv:2503.03203v2 Announce Type: replace 
Abstract: Parallel execution of smart contract transactions in large multicore architectures is critical for higher efficiency and improved throughput. The main bottleneck for maximizing the throughput of a node through parallel execution is transaction conflict resolution: when two transactions interact with the same data, like an account balance, their order matters. Imagine one transaction sends tokens from account A to account B, and another tries to send tokens from account B to account C. If the second transaction happens before the first one, the token balance in account B might be wrong, causing the entire system to break. Conflicts like these must be managed carefully, or you end up with an inconsistent, unusable blockchain state.
  Traditional software transactional memory (STM) has been identified as a possible abstraction for the concurrent execution of transactions within a block, with Block-STM pioneering its application for efficient blockchain transaction processing on multicore validator nodes. This paper presents a parallel execution methodology that leverages conflict specification information of the transactions for block transactional memory (BTM) algorithms. Our experimental analysis, conducted over synthetic transactional workloads and real-world blocks, demonstrates that BTMs leveraging conflict specifications outperform their plain counterparts on both EVM and MoveVM. Our proposed BTM implementations achieve up to 1.75x speedup over sequential execution and outperform the state-of-the-art Parallel-EVM (PEVM) execution by up to 1.33x across synthetic workloads.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03203v2</guid>
      <category>cs.DC</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Parwat Singh Anjana, Matin Amini, Rohit Kapoor, Rahul Parmar, Raghavendra Ramesh, Srivatsan Ravi, Joshua Tobkin</dc:creator>
    </item>
    <item>
      <title>An Empirical Study of Production Incidents in Generative AI Cloud Services</title>
      <link>https://arxiv.org/abs/2504.08865</link>
      <description>arXiv:2504.08865v2 Announce Type: replace 
Abstract: The ever-increasing demand for generative artificial intelligence (GenAI) has motivated cloud-based GenAI services such as Azure OpenAI Service and Amazon Bedrock. Like any large-scale cloud service, failures are inevitable in cloud-based GenAI services, resulting in user dissatisfaction and significant monetary losses. However, GenAI cloud services, featured by their massive parameter scales, hardware demands, and usage patterns, present unique challenges, including generated content quality issues and privacy concerns, compared to traditional cloud services. To understand the production reliability of GenAI cloud services, we analyzed production incidents from a leading GenAI cloud service provider spanning in the past four years. Our study (1) presents the general characteristics of GenAI cloud service incidents at different stages of the incident life cycle; (2) identifies the symptoms and impacts of these incidents on GenAI cloud service quality and availability; (3) uncovers why these incidents occurred and how they were resolved; (4) discusses open research challenges in terms of incident detection, triage, and mitigation, and sheds light on potential solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.08865v2</guid>
      <category>cs.DC</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haoran Yan, Yinfang Chen, Minghua Ma, Ming Wen, Shan Lu, Shenglin Zhang, Tianyin Xu, Rujia Wang, Chetan Bansal, Saravan Rajmohan, Qingwei Lin, Chaoyun Zhang, Dongmei Zhang</dc:creator>
    </item>
    <item>
      <title>From Data Center IoT Telemetry to Data Analytics Chatbots -- Virtual Knowledge Graph is All You Need</title>
      <link>https://arxiv.org/abs/2506.22267</link>
      <description>arXiv:2506.22267v2 Announce Type: replace 
Abstract: Industry 5.0 demands IoT systems that support seamless human-machine collaboration, yet current IoT data analysis requires deep domain, deployment, and query expertise. We show that combining Large Language Models (LLMs) with Knowledge Graphs (KGs) enables natural language access to heterogeneous IoT data. Focusing on data center IoT telemetry, we introduce a rule-based Virtual Knowledge Graph (VKG) construction process and an on-premise LLM inference service to create an end-to-end Data Analytics (DA) chatbot. Our system dynamically generates VKGs per query and translates user input into SPARQL, achieving 92.5% accuracy (vs. 25% for LLM-to-NoSQL) while reducing latency by 85% (20.36s to 3.03s) and keeping VKG sizes under 179 MiB. This work demonstrates that VKG-powered LLM interfaces deliver accurate, low-latency, and relationship-aware access to large-scale telemetry, bridging the gap between users and complex IoT systems in Industry 5.0.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22267v2</guid>
      <category>cs.DC</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Junaid Ahmed Khan, Hiari Pizzini Cavagna, Andrea Proia, Andrea Bartolini</dc:creator>
    </item>
    <item>
      <title>Oranits: Mission Assignment and Task Offloading in Open RAN-based ITS using Metaheuristic and Deep Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2507.19712</link>
      <description>arXiv:2507.19712v2 Announce Type: replace 
Abstract: In this paper, we explore mission assignment and task offloading in an Open Radio Access Network (Open RAN)-based intelligent transportation system (ITS), where autonomous vehicles leverage mobile edge computing for efficient processing. Existing studies often overlook the intricate interdependencies between missions and the costs associated with offloading tasks to edge servers, leading to suboptimal decision-making. To bridge this gap, we introduce Oranits, a novel system model that explicitly accounts for mission dependencies and offloading costs while optimizing performance through vehicle cooperation. To achieve this, we propose a twofold optimization approach. First, we develop a metaheuristic-based evolutionary computing algorithm, namely the Chaotic Gaussian-based Global ARO (CGG-ARO), serving as a baseline for one-slot optimization. Second, we design an enhanced reward-based deep reinforcement learning (DRL) framework, referred to as the Multi-agent Double Deep Q-Network (MA-DDQN), that integrates both multi-agent coordination and multi-action selection mechanisms, significantly reducing mission assignment time and improving adaptability over baseline methods. Extensive simulations reveal that CGG-ARO improves the number of completed missions and overall benefit by approximately 7.1% and 7.7%, respectively. Meanwhile, MA-DDQN achieves even greater improvements of 11.0% in terms of mission completions and 12.5% in terms of the overall benefit. These results highlight the effectiveness of Oranits in enabling faster, more adaptive, and more efficient task processing in dynamic ITS environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19712v2</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ngoc Hung Nguyen, Nguyen Van Thieu, Quang-Trung Luu, Anh Tuan Nguyen, Senura Wanasekara, Nguyen Cong Luong, Fatemeh Kavehmadavani, Van-Dinh Nguyen</dc:creator>
    </item>
    <item>
      <title>Blockchain-Enabled Federated Learning</title>
      <link>https://arxiv.org/abs/2508.06406</link>
      <description>arXiv:2508.06406v3 Announce Type: replace 
Abstract: Blockchain-enabled federated learning (BCFL) addresses fundamental challenges of trust, privacy, and coordination in collaborative AI systems. This chapter provides comprehensive architectural analysis of BCFL systems through a systematic four-dimensional taxonomy examining coordination structures, consensus mechanisms, storage architectures, and trust models. We analyze design patterns from blockchain-verified centralized coordination to fully decentralized peer-to-peer networks, evaluating trade-offs in scalability, security, and performance. Through detailed examination of consensus mechanisms designed for federated learning contexts, including Proof of Quality and Proof of Federated Learning, we demonstrate how computational work can be repurposed from arbitrary cryptographic puzzles to productive machine learning tasks. The chapter addresses critical storage challenges by examining multi-tier architectures that balance blockchain's transaction constraints with neural networks' large parameter requirements while maintaining cryptographic integrity. A technical case study of the TrustMesh framework illustrates practical implementation considerations in BCFL systems through distributed image classification training, demonstrating effective collaborative learning across IoT devices with highly non-IID data distributions while maintaining complete transparency and fault tolerance. Analysis of real-world deployments across healthcare consortiums, financial services, and IoT security applications validates the practical viability of BCFL systems, achieving performance comparable to centralized approaches while providing enhanced security guarantees and enabling new models of trustless collaborative intelligence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.06406v3</guid>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Murtaza Rangwala, KR Venugopal, Rajkumar Buyya</dc:creator>
    </item>
    <item>
      <title>A Reference Architecture for Governance of Cloud Native Applications</title>
      <link>https://arxiv.org/abs/2302.11617</link>
      <description>arXiv:2302.11617v3 Announce Type: replace-cross 
Abstract: The evolution of cloud computing has given rise to Cloud Native Applications (CNAs), presenting new challenges in governance, particularly when faced with strict compliance requirements. This work explores the unique characteristics of CNAs and their impact on governance. We introduce a comprehensive reference architecture designed to streamline governance across CNAs, along with a sample implementation, offering insights for both single and multi-cloud environments. Our architecture seamlessly integrates governance within the CNA framework, adhering to a ``battery-included'' philosophy. Tailored for both expansive and compact CNA deployments across various industries, this design enables cloud practitioners to prioritize product development by alleviating the complexities associated with governance. In addition, it provides a building block for academic exploration of generic CNA frameworks, highlighting their relevance in the evolving cloud computing landscape.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.11617v3</guid>
      <category>cs.SE</category>
      <category>cs.DC</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TCC.2025.3578557</arxiv:DOI>
      <arxiv:journal_reference>In IEEE Transactions on Cloud Computing, 2025</arxiv:journal_reference>
      <dc:creator>William Pourmajidi, Lei Zhang, John Steinbacher, Tony Erwin, Andriy Miranskyy</dc:creator>
    </item>
    <item>
      <title>Extending DD-$\alpha$AMG on heterogeneous machines</title>
      <link>https://arxiv.org/abs/2407.08092</link>
      <description>arXiv:2407.08092v3 Announce Type: replace-cross 
Abstract: Multigrid solvers are the standard in modern scientific computing simulations. Domain Decomposition Aggregation-Based Algebraic Multigrid, also known as the DD-$\alpha$AMG solver, is a successful realization of an algebraic multigrid solver for lattice quantum chromodynamics. Its CPU implementation has made it possible to construct, for some particular discretizations, simulations otherwise computationally unfeasible, and furthermore it has motivated the development and improvement of other algebraic multigrid solvers in the area. From an existing version of DD-$\alpha$AMG already partially ported via CUDA to run some finest-level operations of the multigrid solver on Nvidia GPUs, we translate the CUDA code here by using HIP to run on the ORISE supercomputer. We moreover extend the smoothers available in DD-$\alpha$AMG, paying particular attention to Richardson smoothing, which in our numerical experiments has led to a multigrid solver faster than smoothing with GCR and only 10% slower compared to SAP smoothing. Then we port the odd-even-preconditioned versions of GMRES and Richardson via CUDA. Finally, we extend some computationally intensive coarse-grid operations via advanced vectorization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.08092v3</guid>
      <category>hep-lat</category>
      <category>cs.DC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gustavo Ramirez-Hidalgo, Lianhua He, Ke-Long Zhang</dc:creator>
    </item>
    <item>
      <title>MPPI-Generic: A CUDA Library for Stochastic Trajectory Optimization</title>
      <link>https://arxiv.org/abs/2409.07563</link>
      <description>arXiv:2409.07563v3 Announce Type: replace-cross 
Abstract: This paper introduces a new C++/CUDA library for GPU-accelerated stochastic optimization called MPPI-Generic. It provides implementations of Model Predictive Path Integral control, Tube-Model Predictive Path Integral Control, and Robust Model Predictive Path Integral Control, and allows for these algorithms to be used across many pre-existing dynamics models and cost functions. Furthermore, researchers can create their own dynamics models or cost functions following our API definitions without needing to change the actual Model Predictive Path Integral Control code. Finally, we compare computational performance to other popular implementations of Model Predictive Path Integral Control over a variety of GPUs to show the real-time capabilities our library can allow for. Library code can be found at: https://acdslab.github.io/mppi-generic-website/ .</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07563v3</guid>
      <category>cs.MS</category>
      <category>cs.DC</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bogdan Vlahov, Jason Gibson, Manan Gandhi, Evangelos A. Theodorou</dc:creator>
    </item>
    <item>
      <title>Federated Time Series Generation on Feature and Temporally Misaligned Data</title>
      <link>https://arxiv.org/abs/2410.21072</link>
      <description>arXiv:2410.21072v3 Announce Type: replace-cross 
Abstract: Distributed time series data presents a challenge for federated learning, as clients often possess different feature sets and have misaligned time steps. Existing federated time series models are limited by the assumption of perfect temporal or feature alignment across clients. In this paper, we propose FedTDD, a novel federated time series diffusion model that jointly learns a synthesizer across clients. At the core of FedTDD is a novel data distillation and aggregation framework that reconciles the differences between clients by imputing the misaligned timesteps and features. In contrast to traditional federated learning, FedTDD learns the correlation across clients' time series through the exchange of local synthetic outputs instead of model parameters. A coordinator iteratively improves a global distiller network by leveraging shared knowledge from clients through the exchange of synthetic data. As the distiller becomes more refined over time, it subsequently enhances the quality of the clients' local feature estimates, allowing each client to then improve its local imputations for missing data using the latest, more accurate distiller. Experimental results on five datasets demonstrate FedTDD's effectiveness compared to centralized training, and the effectiveness of sharing synthetic outputs to transfer knowledge of local time series. Notably, FedTDD achieves 79.4% and 62.8% improvement over local training in Context-FID and Correlational scores.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21072v3</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhi Wen Soi, Chenrui Fan, Aditya Shankar, Abele M\u{a}lan, Lydia Y. Chen</dc:creator>
    </item>
    <item>
      <title>Characterization of GPU TEE Overheads in Distributed Data Parallel ML Training</title>
      <link>https://arxiv.org/abs/2501.11771</link>
      <description>arXiv:2501.11771v3 Announce Type: replace-cross 
Abstract: Confidential computing (CC) or trusted execution enclaves (TEEs) is now the most common approach to enable secure computing in the cloud. The recent introduction of GPU TEEs by NVIDIA enables machine learning (ML) models to be trained without leaking model weights or data to the cloud provider. However, the potential performance implications of using GPU TEEs for ML training are not well characterized. In this work, we present an in-depth characterization study on performance overhead associated with running distributed data parallel (DDP) ML training with GPU Trusted Execution Environments (TEE).
  Our study reveals the performance challenges in DDP training within GPU TEEs. DDP uses ring-all-reduce, a well-known approach, to aggregate gradients from multiple devices. Ring all-reduce consists of multiple scatter-reduce and all-gather operations. In GPU TEEs only the GPU package (GPU and HBM memory) is trusted. Hence, any data communicated outside the GPU packages must be encrypted and authenticated for confidentiality and integrity verification. Hence, each phase of the ring-all-reduce requires encryption and message authentication code (MAC) generation from the sender, and decryption and MAC authentication on the receiver. As the number of GPUs participating in DDP increases, the overhead of secure inter-GPU communication during ring-all-reduce grows proportionally. Additionally, larger models lead to more asynchronous all-reduce operations, exacerbating the communication cost. Our results show that with four GPU TEEs, depending on the model that is being trained, the runtime per training iteration increases by an average of 8x and up to a maximum of 41.6x compared to DDP training without TEE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11771v3</guid>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonghyun Lee, Yongqin Wang, Rachit Rajat, Murali Annavaram</dc:creator>
    </item>
    <item>
      <title>Faster Multi-Source Reachability and Approximate Distances via Shortcuts, Hopsets and Matrix Multiplication</title>
      <link>https://arxiv.org/abs/2507.13470</link>
      <description>arXiv:2507.13470v2 Announce Type: replace-cross 
Abstract: Given an $n$-vertex $m$-edge digraph $G = (V,E)$ and a subset $S \subseteq V$ of $|S| = n^{\sigma}$ (for some $0 \le \sigma \le 1$) designated sources, the $S \times V$ reachability problem is to compute the sets $\mathcal V_s$ of vertices reachable from $s$, for every $s \in S$. Naive centralized algorithms run BFS/DFS from each source in $O(m \cdot n^{\sigma})$ time or compute $G$'s transitive closure in $\hat O(n^{\omega})$ time, where $\omega \le 2.371552\ldots$ is the matrix multiplication exponent. Thus, the best known bound is $\hat O(n^{\min \{ 2 + \sigma, \omega\}})$. Leveraging shortcut constructions by Kogan and Parter [SODA 2022, ICALP 2022], we develop a centralized algorithm with running time $\hat O(n^{1 + \frac{2}{3} \omega(\sigma)})$, where $\omega(\sigma)$ is the rectangular matrix multiplication exponent. Using current estimates on $\omega(\sigma)$, our exponent improves upon $\min \{2 + \sigma, \omega \}$ for $\tilde \sigma \leq \sigma \leq 0.53$, where $1/3 &lt; \tilde \sigma &lt; 0.3336$ is a universal constant.
  In a classical result, Cohen [Journal of Algorithms, 1996] devised parallel algorithms for $S \times V$ reachability on graphs admitting balanced recursive separators of size $n^{\rho}$ for $\rho &lt; 1$, requiring polylogarithmic time and work $n^{\max \{\omega \rho, 2\rho + \sigma \} + o(1)}$. We significantly improve, extend, and generalize Cohen's result. First, our parallel algorithm for graphs with small recursive separators has lower work complexity than Cohen's in boraod paramater ranges. Second, we generalize our algorithm to graphs of treewidth at most $n^{\rho}$ ($\rho &lt; 1$) and provide a centralized algorithm that outperforms existing bounds for $S \times V$ reachability on such graphs. We also do this for some other graph familes with small separators. Finally, we extend these results to $(1 + \epsilon)$-approximate distance computation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13470v2</guid>
      <category>cs.DS</category>
      <category>cs.DC</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Elkin, Chhaya Trehan</dc:creator>
    </item>
  </channel>
</rss>
