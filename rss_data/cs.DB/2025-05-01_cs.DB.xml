<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DB updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DB</link>
    <description>cs.DB updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DB" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 02 May 2025 04:00:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>S3AND: Efficient Subgraph Similarity Search Under Aggregated Neighbor Difference Semantics (Technical Report)</title>
      <link>https://arxiv.org/abs/2505.00393</link>
      <description>arXiv:2505.00393v1 Announce Type: new 
Abstract: For the past decades, the \textit{subgraph similarity search} over a large-scale data graph has become increasingly important and crucial in many real-world applications, such as social network analysis, bioinformatics network analytics, knowledge graph discovery, and many others. While previous works on subgraph similarity search used various graph similarity metrics such as the graph isomorphism, graph edit distance, and so on, in this paper, we propose a novel problem, namely \textit{subgraph similarity search under aggregated neighbor difference semantics} (S$^3$AND), which identifies subgraphs $g$ in a data graph $G$ that are similar to a given query graph $q$ by considering both keywords and graph structures (under new keyword/structural matching semantics). To efficiently tackle the S$^3$AND problem, we design two effective pruning methods, \textit{keyword set} and \textit{aggregated neighbor difference lower bound pruning}, which rule out false alarms of candidate vertices/subgraphs to reduce the S$^3$AND search space. Furthermore, we construct an effective indexing mechanism to facilitate our proposed efficient S$^3$AND query answering algorithm. Through extensive experiments, we demonstrate the effectiveness and efficiency of our S$^3$AND approach over both real and synthetic graphs under various parameter settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00393v1</guid>
      <category>cs.DB</category>
      <category>cs.SI</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qi Wen, Yutong Ye, Xiang Lian, Mingsong Chen</dc:creator>
    </item>
    <item>
      <title>ReCellTy: Domain-specific knowledge graph retrieval-augmented LLMs workflow for single-cell annotation</title>
      <link>https://arxiv.org/abs/2505.00017</link>
      <description>arXiv:2505.00017v1 Announce Type: cross 
Abstract: To enable precise and fully automated cell type annotation with large language models (LLMs), we developed a graph structured feature marker database to retrieve entities linked to differential genes for cell reconstruction. We further designed a multi task workflow to optimize the annotation process. Compared to general purpose LLMs, our method improves human evaluation scores by up to 0.21 and semantic similarity by 6.1% across 11 tissue types, while more closely aligning with the cognitive logic of manual annotation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00017v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.DB</category>
      <category>cs.LG</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Dezheng Han, Yibin Jia, Ruxiao Chen, Wenjie Han, Shuaishuai Guo, Jianbo Wang</dc:creator>
    </item>
    <item>
      <title>Optimization of embeddings storage for RAG systems using quantization and dimensionality reduction techniques</title>
      <link>https://arxiv.org/abs/2505.00105</link>
      <description>arXiv:2505.00105v1 Announce Type: cross 
Abstract: Retrieval-Augmented Generation enhances language models by retrieving relevant information from external knowledge bases, relying on high-dimensional vector embeddings typically stored in float32 precision. However, storing these embeddings at scale presents significant memory challenges. To address this issue, we systematically investigate on MTEB benchmark two complementary optimization strategies: quantization, evaluating standard formats (float16, int8, binary) and low-bit floating-point types (float8), and dimensionality reduction, assessing methods like PCA, Kernel PCA, UMAP, Random Projections and Autoencoders. Our results show that float8 quantization achieves a 4x storage reduction with minimal performance degradation (&lt;0.3%), significantly outperforming int8 quantization at the same compression level, being simpler to implement. PCA emerges as the most effective dimensionality reduction technique. Crucially, combining moderate PCA (e.g., retaining 50% dimensions) with float8 quantization offers an excellent trade-off, achieving 8x total compression with less performance impact than using int8 alone (which provides only 4x compression). To facilitate practical application, we propose a methodology based on visualizing the performance-storage trade-off space to identify the optimal configuration that maximizes performance within their specific memory constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00105v1</guid>
      <category>cs.IR</category>
      <category>cs.CL</category>
      <category>cs.DB</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Naam\'an Huerga-P\'erez, Rub\'en \'Alvarez, Rub\'en Ferrero-Guill\'en, Alberto Mart\'inez-Guti\'errez, Javier D\'iez-Gonz\'alez</dc:creator>
    </item>
    <item>
      <title>A Unified Approach for Multi-Granularity Search over Spatial Datasets</title>
      <link>https://arxiv.org/abs/2412.04805</link>
      <description>arXiv:2412.04805v4 Announce Type: replace 
Abstract: There has been increased interest in data search as a means to find relevant datasets or data points in data lakes and repositories. Although approaches have been proposed to support spatial dataset search and data point search, they consider the two types of searches independently. To enable search operations ranging from the coarse-grained dataset level to the fine-grained data point level, we provide an integrated one that supports diverse query types and distance metrics. In this paper, we focus on designing a multi-granularity spatial data search system, called Spadas, that supports both dataset and data point search operations. To address the challenges of the high cost of indexing and susceptibility to outliers, we propose a unified index that can drastically improve query efficiency in various scenarios by organizing data reasonably and removing outliers in datasets. Moreover, to accelerate all data search operations, we propose a set of pruning mechanisms based on the unified index, including fast bound estimation, approximation technique with error bound, and pruning in batch techniques, to effectively filter out non-relevant datasets and points. Finally, we report the results of a detailed experimental evaluation using six spatial data repositories, achieving orders of magnitude faster than the state-of-the-art algorithms and demonstrating the effectiveness by case study. An online spatial data search system of Spadas is also implemented and made accessible to users.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.04805v4</guid>
      <category>cs.DB</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenzhe Yang, Sheng Wang, Shixun Huang, Yuyang Liao, Yuan Sun, Juliana Freire, Zhiyong Peng</dc:creator>
    </item>
    <item>
      <title>SQL-Factory: A Multi-Agent Framework for High-Quality and Large-Scale SQL Generation</title>
      <link>https://arxiv.org/abs/2504.14837</link>
      <description>arXiv:2504.14837v4 Announce Type: replace 
Abstract: High quality SQL corpus is essential for intelligent database. For example, Text-to-SQL requires SQL queries and correspond natural language questions as training samples. However, collecting such query corpus remains challenging in practice due to the high cost of manual annotation, which highlights the importance of automatic SQL generation. Despite recent advances, existing generation methods still face limitations in achieving both diversity and cost-effectiveness. Besides, many methods also treat all tables equally, which overlooks schema complexity and leads to under-utilization of structurally rich tables. To address these issues, this paper proposes a multi-agent framework for high-quality and large-scale SQL generation, dubbed SQL-Factory. It decomposes the generation process into three collaborative teams: the Generation Team explores diverse query structures using a powerful language model, the Expansion Team scales promising patterns via a lightweight language model, and the Management Team adaptively schedules the workflow and evaluates the quality of synthesized queries. This modular framework ensures a balanced trade-off between diversity, scalability, and generation cost. We apply SQL-Factory to four widely used benchmarks and generate over 300,000 SQL queries with less than $200 API cost. Our generated queries achieve higher diversity compared to other methods, and extensive experiments demonstrate that the generated queries significantly improve the model performance in various downstream tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14837v4</guid>
      <category>cs.DB</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiahui Li, Tongwang Wu, Yuren Mao, Yunjun Gao, Yajie Feng, Huaizhong Liu</dc:creator>
    </item>
  </channel>
</rss>
