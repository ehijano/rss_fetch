<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 31 May 2024 04:00:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 31 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>How Gold to Make the Golden Snitch: Designing the "Game Changer" in Esports</title>
      <link>https://arxiv.org/abs/2405.19843</link>
      <description>arXiv:2405.19843v1 Announce Type: new 
Abstract: Many battling games utilize a special item (e.g. Roshan in Defense of the Ancients 2 (DOTA 2), Baron Nashor in League of Legends (LOL), Golden Snitch in Quidditch) as a potential ``Game Changer''. The reward of this item can enable the underdog to make a comeback. However, if the reward is excessively high, the whole game may devolve into a chase for the ``Game Changer''. Our research initiates with a Quidditch case study, a fictional sport in Harry Potter series, wherein we architect the Golden Snitch's reward to maximize the audience's surprise. Surprisingly, we discover that for equally competent teams, the optimal Snitch reward is zero. Moreover, we establish that under most circumstances the optimal score aligns with the game's expected duration multiplied by the teams' strength difference. Finally, we explore the correlation between the ``Game Changer's'' reward and audience surprise in Multiplayer Online Battle Arena (MOBA) games including DOTA 2 and LOL, finding that the optimal reward escalates with increasing team strength inequality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19843v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhihuan Huang, Yuxuan Lu, Yongkang Guo, Yuqing Kong</dc:creator>
    </item>
    <item>
      <title>Truthful Budget Aggregation: Beyond Moving-Phantom Mechanisms</title>
      <link>https://arxiv.org/abs/2405.20303</link>
      <description>arXiv:2405.20303v1 Announce Type: new 
Abstract: We study a budget-aggregation setting in which a number of voters report their ideal distribution of a budget over a set of alternatives, and a mechanism aggregates these reports into an allocation. Ideally, such mechanisms are truthful, i.e., voters should not be incentivized to misreport their preferences. For the case of two alternatives, the set of mechanisms that are truthful and additionally meet a range of basic desiderata (anonymity, neutrality, and continuity) exactly coincides with the so-called moving-phantom mechanisms, but whether this space is richer for more alternatives was repeatedly stated as an open question. We answer this question in the affirmative by presenting a new mechanism that is not a moving-phantom mechanism but satisfies the four properties. Since moving-phantom mechanisms can only provide limited fairness guarantees (measured as the worst-case distance to a fair share solution), one motivation for broadening the class of truthful mechanisms is the hope for improved fairness guarantees. We dispel this hope by showing that lower bounds holding for the class of moving-phantom mechanisms extend to all truthful, anonymous, neutral, and continuous mechanisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20303v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mark de Berg, Rupert Freeman, Ulrike Schmidt-Kraepelin, Markus Utke</dc:creator>
    </item>
    <item>
      <title>Unbending strategies shepherd cooperation and suppress extortion in spatial populations</title>
      <link>https://arxiv.org/abs/2405.19565</link>
      <description>arXiv:2405.19565v1 Announce Type: cross 
Abstract: Evolutionary game dynamics on networks typically consider the competition among simple strategies such as cooperation and defection in the Prisoner's Dilemma and summarize the effect of population structure as network reciprocity. However, it remains largely unknown regarding the evolutionary dynamics involving multiple powerful strategies typically considered in repeated games, such as the zero-determinant (ZD) strategies that are able to enforce a linear payoff relationship between them and their co-players. Here, we consider the evolutionary dynamics of always cooperate (AllC), extortionate ZD (extortioners), and unbending players in lattice populations based on the commonly used death-birth updating. Out of the class of unbending strategies, we consider a particular candidate, PSO Gambler, a machine-learning-optimized memory-one strategy, which can foster reciprocal cooperation and fairness among extortionate players. We derive analytical results under weak selection and rare mutations, including pairwise fixation probabilities and long-term frequencies of strategies. In the absence of the third unbending type, extortioners can achieve a half-half split in equilibrium with unconditional cooperators for sufficiently large extortion factors. However, the presence of unbending players fundamentally changes the dynamics and tilts the system to favor unbending cooperation. Most surprisingly, extortioners cannot dominate at all regardless of how large their extortion factor is, and the long-term frequency of unbending players is maintained almost as a constant. Our analytical method is applicable to studying the evolutionary dynamics of multiple strategies in structured populations. Our work provides insights into the interplay between network reciprocity and direct reciprocity, revealing the role of unbending strategies in enforcing fairness and suppressing extortion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19565v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.GT</category>
      <category>q-bio.PE</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zijie Chen, Yuxin Geng, Xingru Chen, Feng Fu</dc:creator>
    </item>
    <item>
      <title>Learning from Random Demonstrations: Offline Reinforcement Learning with Importance-Sampled Diffusion Models</title>
      <link>https://arxiv.org/abs/2405.19878</link>
      <description>arXiv:2405.19878v1 Announce Type: cross 
Abstract: Generative models such as diffusion have been employed as world models in offline reinforcement learning to generate synthetic data for more effective learning. Existing work either generates diffusion models one-time prior to training or requires additional interaction data to update it. In this paper, we propose a novel approach for offline reinforcement learning with closed-loop policy evaluation and world-model adaptation. It iteratively leverages a guided diffusion world model to directly evaluate the offline target policy with actions drawn from it, and then performs an importance-sampled world model update to adaptively align the world model with the updated policy. We analyzed the performance of the proposed method and provided an upper bound on the return gap between our method and the real environment under an optimal policy. The result sheds light on various factors affecting learning performance. Evaluations in the D4RL environment show significant improvement over state-of-the-art baselines, especially when only random or medium-expertise demonstrations are available -- thus requiring improved alignment between the world model and offline policy evaluation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19878v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Zeyu Fang, Tian Lan</dc:creator>
    </item>
    <item>
      <title>On the interpretation of quantum theory as games between physicists and nature played in Minkowski spacetime</title>
      <link>https://arxiv.org/abs/2405.20143</link>
      <description>arXiv:2405.20143v1 Announce Type: cross 
Abstract: In 2019, we introduced games in Minkowski spacetime as a generalization of game theory to special relativity that subsumes games in normal form (spacelike separation) and games in extensive form (timelike separation). Many concepts including Nash equilibria naturally extend to spacetime games. We also emphasized the importance of these games to model quantum experiments such as Bell experiments and more generally any adaptive measurements. Subsequent work suggested to formalize a special case of such games in terms of strategy presheaves. In the case that measurements have a unique causal bridge and if a natural cover is taken, we show that the two frameworks are isomorphic to each other and provide complementary perspectives. Spacetime games provide a visual and intuitive framework that also captures the distinction between joint experiments and either-or experiments, so that they are rich enough in their causal structure to imply a natural cover for the corresponding causal contextuality scenario. Based on this observation, we suggest to define the strategy presheaf directly based on the pure strategies (and restrictions thereof) of the spacetime game, and we show that the sheaf property obtains for the games at hand. The argument is rather simple and similar to event sheaves for the flat case. Finally, we explain how, in the other direction, the failure of the sheaf property on strategy distribution presheaves is consistent with our previous argument that Nash game theory is not compatible with quantum physics. This shows that the insights of the two frameworks, taken together, can contribute positively to the advancement of the field of quantum foundations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20143v1</guid>
      <category>quant-ph</category>
      <category>cs.GT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ghislain Fourny</dc:creator>
    </item>
    <item>
      <title>A generalization to networks of Young's characterization of the Borda rule</title>
      <link>https://arxiv.org/abs/2211.06626</link>
      <description>arXiv:2211.06626v2 Announce Type: replace 
Abstract: We prove that, for any given set of networks satisfying suitable conditions, the net-oudegree network solution, the net-indegree network solution, and the total network solution are the unique network solutions on that set satisfying neutrality, consistency and cancellation. The generality of the result obtained allows to get an analogous result for social choice correspondences: for any given set of preference profiles satisfying suitable conditions, the net-oudegree social choice correspondence, the net-indegree social choice correspondence and the total social choice correspondence are the unique social choice correspondences on that set satisfying neutrality, consistency and cancellation. Using the notable fact that several well-known voting rules coincide with the restriction of net-oudegree social choice correspondence to appropriate sets of preference profiles, we are able to deduce a variety of new and known characterization theorems for the Borda rule, the Partial Borda rule, the Averaged Borda rule, the Approval Voting, the Plurality rule and the anti-Plurality rule, among which Young's characterization of the Borda rule and Fishburn's characterization of the Approval Voting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.06626v2</guid>
      <category>cs.GT</category>
      <category>math.CO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniela Bubboloni, Michele Gori</dc:creator>
    </item>
    <item>
      <title>Evaluating and Managing Tokenomics for Non-Fungible Tokens in Game-Based Blockchain Networks</title>
      <link>https://arxiv.org/abs/2306.13672</link>
      <description>arXiv:2306.13672v2 Announce Type: replace 
Abstract: Non-fungible tokens (NFTs) are becoming increasingly popular in Play-to-Earn (P2E) Web3 applications as a means of incentivizing user engagement. In Web3, users with NFTs ownership are entitled to monetize them. However, due to lack of objective NFT valuation, which makes NFT value determination challenging, P2E applications ecosystems have experienced inflation. In this paper, we propose a method that enables NFT inflation value management in P2E applications. Our method leverages the contribution-rewards model proposed by Curve Finance and the automated market maker (AMM) of decentralized exchanges. In decentralized systems, P2E Web3 applications inclusive, not all participants contribute in good faith. Therefore, rewards are provided to incentivize contribution. Our mechanism proves that burning NFTs, indicating the permanent removal of NFTs, contributes to managing inflation by reducing the number of NFTs in circulation. As a reward for this contribution, our method mints a compensation (CP) token as an ERC-20 token, which can be exchanged for NFTs once enough tokens have been accumulated. To further increase the value of the CP token, we suggest using governance tokens and CP tokens to create liquidity pools for AMM. The value of the governance token is determined by the market, and the CP token derives its value from the governance token in AMM. The CP token can determine its worth based on the market value of the governance token. Additionally, since CP tokens are used for exchanging NFTs, the value of the NFT is ultimately determined by the value of the CP token. To further illustrate our concept, we show how to adjust burning rewards based on factors such as the probability of upgrading NFTs' rarity or the current swap ratio of governance and CP tokens in AMM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.13672v2</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hyoungsung Kim, Hyun-Sik Kim, Yong-Suk Park</dc:creator>
    </item>
    <item>
      <title>Verifying Cake-Cutting, Faster</title>
      <link>https://arxiv.org/abs/2405.14068</link>
      <description>arXiv:2405.14068v2 Announce Type: replace 
Abstract: Envy-free cake-cutting protocols procedurally divide an infinitely divisible good among a set of agents so that no agent prefers another's allocation to their own. These protocols are highly complex and difficult to prove correct. Recently, Bertram, Levinson, and Hsu introduced a language called Slice for describing and verifying cake-cutting protocols. Slice programs can be translated to formulas encoding envy-freeness, which are solved by SMT. While Slice works well on smaller protocols, it has difficulty scaling to more complex cake-cutting protocols.
  We improve Slice in two ways. First, we show any protocol execution in Slice can be replicated using piecewise uniform valuations. We then reduce Slice's constraint formulas to formulas within the theory of linear real arithmetic, showing that verifying envy-freeness is efficiently decidable. Second, we design and implement a linear type system which enforces that no two agents receive the same part of the good. We implement our methods and verify a range of challenging examples, including the first nontrivial four-agent protocol.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14068v2</guid>
      <category>cs.GT</category>
      <category>cs.PL</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Noah Bertram, Tean Lai, Justin Hsu</dc:creator>
    </item>
    <item>
      <title>Manipulation and Peer Mechanisms: A Survey</title>
      <link>https://arxiv.org/abs/2210.01984</link>
      <description>arXiv:2210.01984v3 Announce Type: replace-cross 
Abstract: In peer mechanisms, the competitors for a prize also determine who wins. Each competitor may be asked to rank, grade, or nominate peers for the prize. Since the prize can be valuable, such as financial aid, course grades, or an award at a conference, competitors may be tempted to manipulate the mechanism. We survey approaches to prevent or discourage the manipulation of peer mechanisms. We conclude our survey by identifying several important research challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.01984v3</guid>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthew Olckers, Toby Walsh</dc:creator>
    </item>
  </channel>
</rss>
