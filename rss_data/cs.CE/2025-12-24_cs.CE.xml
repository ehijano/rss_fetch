<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 25 Dec 2025 02:17:33 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 24 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Solving strategies for data-driven one-dimensional elasticity exhibiting nonlinear strains</title>
      <link>https://arxiv.org/abs/2512.19912</link>
      <description>arXiv:2512.19912v1 Announce Type: new 
Abstract: In this work, we extend and generalize our solving strategy, first introduced in [1], based on a greedy optimization algorithm and the alternating direction method (ADM) for nonlinear systems computed with multiple load steps. In particular, we combine the greedy optimization algorithm with the direct data-driven solver based on ADM which is firstly introduced in [2] and combined with the Newton-Raphson method for nonlinear elasticity in [3]. We numerically illustrate via one- and two-dimensional bar and truss structures exhibiting nonlinear strain measures and different constitutive datasets that our solving strategy generally achieves a better approximation of the globally optimal solution. This, however, comes at the expense of higher computational cost which is scaled by the number of "greedy" searches. Using this solving strategy, we reproduce the first cycle of the cyclic testing for a nylon rope that was performed at industrial testing facilities for mooring lines manufacturers. We also numerically illustrate for a truss structure that our solving strategy generally improves the accuracy and robustness in cases of an unsymmetrical data distribution and noisy data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.19912v1</guid>
      <category>cs.CE</category>
      <category>math.OC</category>
      <pubDate>Wed, 24 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Thi-Hoa Nguyen, Viljar H. Gjerde, Bruno A. Roccia, Cristian G. Gebhardt</dc:creator>
    </item>
    <item>
      <title>A hybrid global local computational framework for ship hull structural analysis using homogenized model and graph neural network</title>
      <link>https://arxiv.org/abs/2512.20020</link>
      <description>arXiv:2512.20020v1 Announce Type: new 
Abstract: This study presents a computational framework for global local structural analysis of ship hull girders that integrates an equivalent single layer (ESL) model with a graph neural network (GNN). A coarse mesh homogenized ESL model efficiently predicts the global displacement field, from which degrees of freedom (DOFs) along stiffened panel boundaries are extracted. A global to local DOF mapping and reconstruction procedure is developed to recover detailed boundary kinematics for local analysis. The reconstructed DOFs, together with panel geometry and loading, serve as inputs to a heterogeneous graph transformer (HGT), a subtype of GNN, which rapidly and accurately predicts the detailed stress and displacement fields for any panel within the hull girder. The HGT is trained using high fidelity 3D panel finite element model with reconstructed boundary conditions, enabling it to generalize across varying panel geometries, loadings, and boundary behaviors. Once trained, the framework requires only the global ESL solution in order to generate detailed local responses, making it highly suitable for optimization. Validation on three box beam case studies demonstrates that the global prediction error is governed by the coarse mesh ESL solution, while the HGT maintains high local accuracy and clearly outperforms conventional ESL based stress estimation method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.20020v1</guid>
      <category>cs.CE</category>
      <pubDate>Wed, 24 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuecheng Cai, Jasmin Jelovica</dc:creator>
    </item>
    <item>
      <title>Auditing Reproducibility in Non-Targeted Analysis: 103 LC/GC--HRMS Tools Reveal Temporal Divergence Between Openness and Operability</title>
      <link>https://arxiv.org/abs/2512.20279</link>
      <description>arXiv:2512.20279v1 Announce Type: new 
Abstract: In 2008, melamine in infant formula forced laboratories across three continents to verify a compound they had never monitored. Non-targeted analysis using LC/GC-HRMS handles these cases. But when findings trigger regulatory action, reproducibility becomes operational: can an independent laboratory repeat the analysis and reach the same conclusion?
  We assessed 103 tools (2004-2025) against six pillars drawn from FAIR and BP4NTA principles: laboratory validation (C1), data availability (C2), code availability (C3), standardised formats (C4), knowledge integration (C5), and portable implementation (C6). Health contributed 51 tools, Pharma 31, and Chemistry 21.
  Nine in ten tools shared data (C2, 90/103, 87%). Fewer than four in ten supported portable implementations (C6, 40/103, 39%). Validation and portability rarely appeared together (C1+C6, 18/103, 17%). Over twenty-one years, openness climbed from 56% to 86% while operability dropped from 55% to 43%. No tool addressed food safety.
  Journal data-sharing policies increased what authors share but not what reviewers can run. Tools became easier to find but harder to execute. Strengthening C1, C4, and C6 would turn documented artifacts into workflows that external laboratories can replay.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.20279v1</guid>
      <category>cs.CE</category>
      <category>cs.SE</category>
      <pubDate>Wed, 24 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sarah Alsubaie (King Abdullah University of Science,Technology), Sakhaa Alsaedi (King Abdullah University of Science,Technology), Xin Gao (King Abdullah University of Science,Technology)</dc:creator>
    </item>
    <item>
      <title>Replacing Gas with Low-cost, Abundant Long-duration Pumped Hydro in Electricity Systems</title>
      <link>https://arxiv.org/abs/2512.20286</link>
      <description>arXiv:2512.20286v1 Announce Type: new 
Abstract: Fossil gas is sometimes presented as an enabler of variable solar and wind generation beyond 2050, despite being a primary source of greenhouse gas emissions from methane leakage and combustion. We find that balancing solar and wind generation with pumped hydro energy storage eliminates the need for fossil gas without incurring a cost penalty. However, many existing long-term electricity system plans are biased to rely on fossil gas due to using temporal aggregation methods that either heavily constrain storage cycling behaviour or lose track of the state-of-charge, failing to consider the potential of low-cost long-duration off-river pumped hydro, and ignoring the broad suite of near-optimal energy transition pathways. We show that a temporal aggregation method based on 'segmentation' (fitted chronology) closely resembles the full-series optimisation, captures long-duration storage behaviour (48- and 160-hour durations), and finds a near-optimal 100% renewable electricity solution. We develop a new electricity system model to rapidly evaluate millions of other near-optimal solutions, stressing the importance of modelling pumped hydro sites with a low energy volume cost (&lt;US$50 per kilowatt-hour), long economic lifetime (~75 years), and low real discount rate akin to other natural monopolies (&lt;=3%). Almost every region of the world has access to sufficient 50 - 5000 gigawatt-hour off-river pumped hydro options that enable them to entirely decarbonise their future electricity systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.20286v1</guid>
      <category>cs.CE</category>
      <category>econ.GN</category>
      <category>math.OC</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 24 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Timothy Weber, Cheng Cheng, Harry Thawley, Kylie Catchpole, Andrew Blakers, Bin Lu, Jennifer Zhao, Anna Nadolny</dc:creator>
    </item>
    <item>
      <title>Expected Revenue, Risk, and Grid Impact of Bitcoin Mining: A Decision-Theoretic Perspective</title>
      <link>https://arxiv.org/abs/2512.20518</link>
      <description>arXiv:2512.20518v1 Announce Type: new 
Abstract: Most current assessments use ex post proxies that miss uncertainty and fail to consistently capture the rapid change in bitcoin mining. We introduce a unified, ex ante statistical model that derives expected return, downside risk, and upside potential profit from the first principles of mining: Each hash is a Bernoulli trial with a Bitcoin block difficulty-based success probability. The model yields closed-form expected revenue per hash-rate unit, risk metrics in different scenarios, and upside-profit probabilities for different fleet sizes. Empirical calibration closely matches previously reported observations, yielding a unified, faithful quantification across hardware, pools, and operating conditions. This foundation enables more reliable analysis of mining impacts and behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.20518v1</guid>
      <category>cs.CE</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 24 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuting Cai, Ruthav Sadali, Korok Ray, Chao Tian</dc:creator>
    </item>
    <item>
      <title>Structured Event Representation and Stock Return Predictability</title>
      <link>https://arxiv.org/abs/2512.19484</link>
      <description>arXiv:2512.19484v1 Announce Type: cross 
Abstract: We find that event features extracted by large language models (LLMs) are effective for text-based stock return prediction. Using a pre-trained LLM to extract event features from news articles, we propose a novel deep learning model based on structured event representation (SER) and attention mechanisms to predict stock returns in the cross-section. Our SER-based model provides superior performance compared with other existing text-driven models to forecast stock returns out of sample and offers highly interpretable feature structures to examine the mechanisms underlying the stock return predictability. We further provide various implications based on SER and highlight the crucial benefit of structured model inputs in stock return predictability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.19484v1</guid>
      <category>econ.GN</category>
      <category>cs.CE</category>
      <category>q-fin.EC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 24 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gang Li, Dandan Qiao, Mingxuan Zheng</dc:creator>
    </item>
    <item>
      <title>Self-Guided Diffusion Model for Accelerating Computational Fluid Dynamics</title>
      <link>https://arxiv.org/abs/2504.04375</link>
      <description>arXiv:2504.04375v3 Announce Type: replace 
Abstract: Machine learning methods, such as diffusion models, are widely explored as a promising way to accelerate high-fidelity fluid dynamics computation via a super-resolution process from faster-to-compute low-fidelity input. However, existing approaches usually make impractical assumptions that the low-fidelity data is down-sampled from high-fidelity data. In reality, low-fidelity data is produced by numerical solvers that use a coarser resolution. Solver-generated low-fidelity data usually sacrifices fine-grained details, such as small-scale vortices compared to high-fidelity ones. Our findings show that SOTA diffusion models struggle to reconstruct fine-scale details when faced with solver-generated low-fidelity inputs. To bridge this gap, we propose SG-Diff, a novel diffusion model for reconstruction, where both low-fidelity inputs and high-fidelity targets are generated from numerical solvers. We propose an \textit{Importance Weight} strategy during training that serves as a form of self-guidance, focusing on intricate fluid details, and a \textit{Predictor-Corrector-Advancer} SDE solver that embeds physical guidance into the diffusion sampling process. Together, these techniques steer the diffusion model toward more accurate reconstructions. Experimental results on four 2D turbulent flow datasets demonstrate the efficacy of \model~against state-of-the-art baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04375v3</guid>
      <category>cs.CE</category>
      <pubDate>Wed, 24 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Proc. 32nd ACM SIGKDD Conf. on Knowledge Discovery and Data Mining (KDD 2026)</arxiv:journal_reference>
      <dc:creator>Ruoyan Li, Zijie Huang, Haixin Wang, Guancheng Wan, Yizhou Sun, Wei Wang</dc:creator>
    </item>
    <item>
      <title>Very-low-field MRI scanners: from the ideal to the real permanent magnet array</title>
      <link>https://arxiv.org/abs/2509.11762</link>
      <description>arXiv:2509.11762v2 Announce Type: replace 
Abstract: Very-low-field MRIs are becoming increasingly popular due to their portability and adaptability to different environments. They are being successfully used for various clinical applications, leading to a paradigm shift in the way imaging care is typically performed. The development of low-cost MRI scanner prototypes began a few years ago, with some interesting and promising open-source projects emerging in both hardware and software design. Using permanent magnets (PMs) to generate the static magnetic field B0 can substantially reduce the manufacturing cost while achieving satisfactory homogeneity. This article aims to explore the reasons behind discrepancies between magnet design and prototype performance in terms of magnetic field homogeneity. Understanding the impact of the practical implementation of magnet design could inform the development of more tolerant designs in future, simplifying subsequent B0 shimming procedures or even making them unnecessary. This work also evidences the impact of using different numerical model approximations in the modelling phase, proving how they also impact the quality of the design outcomes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11762v2</guid>
      <category>cs.CE</category>
      <category>physics.med-ph</category>
      <pubDate>Wed, 24 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TIM.2025.3638912</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Instrumentation and Measurement (2025) Vol. 74, Art. no. 4021514</arxiv:journal_reference>
      <dc:creator>Umberto Zanovello, Alessandro Arduino, Vittorio Basso, Luca Zilberti, Alessandro Sola, Andrea Agosto, Luca Toso, Oriano Bottauscio</dc:creator>
    </item>
    <item>
      <title>Multi-Physics-Enhanced Bayesian Inverse Analysis: Information Gain from Additional Fields</title>
      <link>https://arxiv.org/abs/2510.11095</link>
      <description>arXiv:2510.11095v2 Announce Type: replace 
Abstract: Inverse analysis, such as model calibration, often suffers from a lack of informative data in complex real-world scenarios. The standard remedy, designing new experimental setups, is often costly and time-consuming, while readily available but seemingly useless data are ignored.
  This work proposes incorporating such data from additional physical fields into the inverse analysis, even when the forward model solves a single-physics problem. A Bayesian framework easily incorporates the additional data and quantifies the resulting uncertainty reduction.
  We formally introduce the proposed method, which we denote as multi-physics-enhanced Bayesian inverse analysis. Moreover, this work is the first to quantify the reduction in parameter uncertainty by comparing the information gain from the prior to the posterior when using single-physics versus multi-physics data.
  We demonstrate the potential of the proposed method in two exemplary applications. Our results show that even a few or noisy data points from an additional physical field can considerably increase the information gain, even when the physical field is only weakly or one-way coupled.
  Overall, this work proposes and promotes the future use of multi-physics-enhanced Bayesian inverse analysis as a cost- and time-saving game-changer across various fields of science and industry, particularly in medicine.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.11095v2</guid>
      <category>cs.CE</category>
      <pubDate>Wed, 24 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Lea J. Haeusel, Jonas Nitzler, Lea J. K\"oglmeier, Wolfgang A. Wall</dc:creator>
    </item>
    <item>
      <title>Foundation Model for Polycrystalline Material Informatics</title>
      <link>https://arxiv.org/abs/2512.06770</link>
      <description>arXiv:2512.06770v3 Announce Type: replace 
Abstract: We present a three-dimensional foundation model for polycrystalline materials based on a masked autoencoder trained via large-scale self-supervised learning. The model is pretrained on $100{,}000$ voxelized synthetic face-centered cubic (FCC) microstructures whose crystallographic textures systematically span the texture hull using hierarchical simplex sampling. The transferability of the learned latent representations is evaluated on two downstream tasks: homogenized elastic stiffness prediction and nonlinear stress-strain response prediction. For the nonlinear task, the pretrained encoder is coupled with an orientation-aware interaction-based deep material network (ODMN), where latent features are used to infer microstructure-dependent surrogate parameters. The inferred ODMNs are subsequently combined with crystal plasticity to predict stress--strain responses for previously unseen microstructures. In stiffness prediction, the pretrained model achieves validation $R^2$ values exceeding 0.8, compared to below 0.1 for non-pretrained baselines. In nonlinear response prediction, mean stress errors remain below 4\%. These results demonstrate that self-supervised pretraining yields physically meaningful and transferable microstructural representations, providing a scalable framework for microstructure-property inference in polycrystalline materials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06770v3</guid>
      <category>cs.CE</category>
      <pubDate>Wed, 24 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ting-Ju Wei, Chuin-Shan Chen</dc:creator>
    </item>
    <item>
      <title>Multiscale Corrections by Continuous Super-Resolution</title>
      <link>https://arxiv.org/abs/2411.07576</link>
      <description>arXiv:2411.07576v2 Announce Type: replace-cross 
Abstract: Finite element methods typically require a high resolution to satisfactorily approximate micro and even macro patterns of an underlying physical model. This issue can be circumvented by appropriate multiscale strategies that are able to obtain reasonable approximations on under-resolved scales. In this paper, we study the implicit neural representation and propose a continuous super-resolution network as a correction strategy for multiscale effects. It can take coarse finite element data to learn both in-distribution and out-of-distribution high-resolution finite element predictions. Our highlight is the design of a local implicit transformer, which is able to learn multiscale features. We also propose Gabor wavelet-based coordinate encodings, which can overcome the bias of neural networks learning low-frequency features. Finally, perception is often preferred over distortion, so scientists can recognize the visual pattern for further investigation. However, implicit neural representation is known for its lack of local pattern supervision. We propose to use stochastic cosine similarities to compare the local feature differences between prediction and ground truth. It shows better performance on structural alignments. Our experiments show that our proposed strategy achieves superior performance as an in-distribution and out-of-distribution super-resolution strategy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07576v2</guid>
      <category>math.NA</category>
      <category>cs.CE</category>
      <category>cs.CV</category>
      <category>cs.NA</category>
      <category>eess.IV</category>
      <pubDate>Wed, 24 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhi-Song Liu, Roland Maier, Andreas Rupp</dc:creator>
    </item>
    <item>
      <title>Noise-robust multi-fidelity surrogate modelling for parametric partial differential equations</title>
      <link>https://arxiv.org/abs/2507.03691</link>
      <description>arXiv:2507.03691v3 Announce Type: replace-cross 
Abstract: We address the challenge of constructing noise-robust surrogate models for quantities of interest (QoIs) arising from parametric partial differential equations (PDEs), using multi-fidelity collocation techniques; specifically, the Multi-Index Stochastic Collocation (MISC). In practical scenarios, the PDE evaluations used to build a response surface are often corrupted by numerical noise, especially for the low-fidelity models. This noise, which may originate from loose solver tolerances, coarse discretisations, or transient effects, can lead to overfitting in MISC, degrading surrogate quality through nonphysical oscillations and loss of convergence, thereby limiting its utility in downstream tasks like uncertainty quantification, optimisation, and control. To correct this behaviour, we propose an improved version of MISC that can automatically detect the presence of solver noise during the surrogate model construction and then ignore the exhausted fidelities. Our approach monitors the spectral decay of the surrogate at each iteration, identifying stagnation in the coefficient spectrum that signals the onset of noise. Once detected, the algorithm selectively halts the use of noisy fidelities, focusing computational resources on those fidelities that still provide meaningful information. The effectiveness of this approach is numerically validated on two challenging test cases: a parabolic advection--diffusion PDE with uncertain coefficients, and a parametric turbulent incompressible Navier--Stokes problem. The results showcase the accuracy and robustness of the resulting multi-fidelity surrogate and its capability to extract relevant information, even from under-resolved meshes not suitable for reliable single-fidelity computations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.03691v3</guid>
      <category>math.NA</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <pubDate>Wed, 24 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Benjamin M. Kent, Lorenzo Tamellini, Matteo Giacomini, Antonio Huerta</dc:creator>
    </item>
    <item>
      <title>BConformeR: A Conformer Based on Mutual Sampling for Unified Prediction of Continuous and Discontinuous Antibody Binding Sites</title>
      <link>https://arxiv.org/abs/2508.12029</link>
      <description>arXiv:2508.12029v3 Announce Type: replace-cross 
Abstract: Accurate prediction of antibody-binding sites (epitopes) on antigens is crucial for vaccine design, immunodiagnostics, therapeutic antibody development, antibody engineering, research into autoimmune and allergic diseases, and advancing our understanding of immune responses. Despite in silico methods that have been proposed to predict both linear (continuous) and conformational (discontinuous) epitopes, they consistently underperform in predicting conformational epitopes. In this work, we propose Conformer-based models trained separately on AlphaFold-predicted structures and experimentally determined structures, leveraging convolutional neural networks (CNNs) to extract local features and Transformers to capture long-range dependencies within antigen sequences. Ablation studies demonstrate that CNN enhances the prediction of linear epitopes, and the Transformer module improves the prediction of conformational epitopes. Experimental results show that our model outperforms existing baselines in terms of MCC, ROC-AUC, PR-AUC, and F1 scores on both linear and conformational epitopes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.12029v3</guid>
      <category>q-bio.BM</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <pubDate>Wed, 24 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhangyu You, Jiahao Ma, Hongzong Li, Ye-Fan Hu, Jian-Dong Huang</dc:creator>
    </item>
    <item>
      <title>Cash Flow Underwriting with Bank Transaction Data: Advancing MSME Financial Inclusion in Malaysia</title>
      <link>https://arxiv.org/abs/2510.16066</link>
      <description>arXiv:2510.16066v3 Announce Type: replace-cross 
Abstract: Despite accounting for 96.1% of all businesses in Malaysia, access to financing remains one of the most persistent challenges faced by Micro, Small, and Medium Enterprises (MSMEs). Newly established businesses are often excluded from formal credit markets as traditional underwriting approaches rely heavily on credit bureau data. This study investigates the potential of bank statement data as an alternative data source for credit assessment to promote financial inclusion in emerging markets. First, we propose a cash flow-based underwriting pipeline where we utilise bank statement data for end-to-end data extraction and machine learning credit scoring. Second, we introduce a novel dataset of 611 loan applicants from a Malaysian lending institution. Third, we develop and evaluate credit scoring models based on application information and bank transaction-derived features. Empirical results show that the use of such data boosts the performance of all models on our dataset, which can improve credit scoring for new-to-lending MSMEs. Finally, we will release the anonymised bank transaction dataset to facilitate further research on MSME financial inclusion within Malaysia's emerging economy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16066v3</guid>
      <category>q-fin.ST</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <category>q-fin.RM</category>
      <pubDate>Wed, 24 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chun Chet Ng, Wei Zeng Low, Jia Yu Lim, Yin Yin Boon</dc:creator>
    </item>
    <item>
      <title>FORWARD: Dataset of a forwarder operating in rough terrain</title>
      <link>https://arxiv.org/abs/2511.17318</link>
      <description>arXiv:2511.17318v2 Announce Type: replace-cross 
Abstract: We present FORWARD, a high-resolution multimodal dataset of a cut-to-length forwarder operating in rough terrain on two harvest sites in the middle part of Sweden. The forwarder is a large Komatsu model equipped with vehicle telematics sensors, including global positioning via satellite navigation, movement sensors, accelerometers, and engine sensors. The vehicle was additionally equipped with cameras, operator vibration sensors, and multiple IMUs. The data includes event time logs recorded at 5 Hz of driving speed, fuel consumption, vehicle position with centimeter accuracy, and crane use while the vehicle operates in forest areas, aerially laser-scanned with a resolution of around 1500 points per square meter. Production log files (StanForD standard) with time-stamped machine events, extensive video material, and terrain data in various formats are included as well. About 18 hours of regular wood extraction work during three days is annotated from 360-video material into individual work elements and included in the dataset. We also include scenario specifications of conducted experiments on forest roads and in terrain. Scenarios include repeatedly driving the same routes with and without steel tracks, different load weights, and different target driving speeds. The dataset is intended for developing models and algorithms for trafficability, perception, and autonomous control of forest machines using artificial intelligence, simulation, and experiments on physical testbeds. In part, we focus on forwarders traversing terrain, avoiding or handling obstacles, and loading or unloading logs, with consideration for efficiency, fuel consumption, safety, and environmental impact. Other benefits of the open dataset include the ability to explore auto-generation and calibration of forestry machine simulators and automation scenario descriptions using the data recorded in the field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.17318v2</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>physics.app-ph</category>
      <pubDate>Wed, 24 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mikael Lundb\"ack, Erik Wallin, Carola H\"aggstr\"om, Mattias Nystr\"om, Andreas Gr\"onlund, Mats Richardson, Petrus J\"onsson, William Arnvik, Lucas Hedstr\"om, Arvid F\"alldin, Martin Servin</dc:creator>
    </item>
  </channel>
</rss>
