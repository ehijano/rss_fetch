<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.LO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.LO</link>
    <description>cs.LO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.LO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 29 Jan 2025 05:00:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Codd's Theorem for Databases over Semirings</title>
      <link>https://arxiv.org/abs/2501.16543</link>
      <description>arXiv:2501.16543v1 Announce Type: new 
Abstract: Codd's Theorem, a fundamental result of database theory, asserts that relational algebra and relational calculus have the same expressive power on relational databases. We explore Codd's Theorem for databases over semirings and establish two different versions of this result for such databases: the first version involves the five basic operations of relational algebra, while in the second version the division operation is added to the five basic operations of relational algebra. In both versions, the difference operation of relations is given semantics using semirings with monus, while on the side of relational calculus a limited form of negation is used. The reason for considering these two different versions of Codd's theorem is that, unlike the case of ordinary relational databases, the division operation need not be expressible in terms of the five basic operations of relational algebra for databases over an arbitrary positive semiring; in fact, we show that this inexpressibility result holds even for bag databases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16543v1</guid>
      <category>cs.LO</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guillermo Badia, Phokion G. Kolaitis, Carles Noguera</dc:creator>
    </item>
    <item>
      <title>Sharing and Linear Logic with Restricted Access (Extended Version)</title>
      <link>https://arxiv.org/abs/2501.16576</link>
      <description>arXiv:2501.16576v1 Announce Type: new 
Abstract: The two Girard translations provide two different means of obtaining embeddings of Intuitionistic Logic into Linear Logic, corresponding to different lambda-calculus calling mechanisms. The translations, mapping A -&gt; B respectively to !A -o B and !(A -o B), have been shown to correspond respectively to call-by-name and call-by-value. In this work, we split the of-course modality of linear logic into two modalities, written "!" and "$\bullet$". Intuitively, the modality "!" specifies a subproof that can be duplicated and erased, but may not necessarily be "accessed", i.e. interacted with, while the combined modality "$!\bullet$" specifies a subproof that can moreover be accessed. The resulting system, called MSCLL, enjoys cut-elimination and is conservative over MELL. We study how restricting access to subproofs provides ways to control sharing in evaluation strategies. For this, we introduce a term-assignment for an intuitionistic fragment of MSCLL, called the $\lambda!\bullet$-calculus, which we show to enjoy subject reduction, confluence, and strong normalization of the simply typed fragment. We propose three sound and complete translations that respectively simulate call-by-name, call-by-value, and a variant of call-by-name that shares the evaluation of its arguments (similarly as in call-by-need). The translations are extended to simulate the Bang-calculus, as well as weak reduction strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16576v1</guid>
      <category>cs.LO</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pablo Barenbaum, Eduardo Bonelli</dc:creator>
    </item>
    <item>
      <title>The sorrows of a smooth digraph: the first hardness criterion for infinite directed graph-colouring problems</title>
      <link>https://arxiv.org/abs/2501.17060</link>
      <description>arXiv:2501.17060v1 Announce Type: new 
Abstract: Two major milestones on the road to the full complexity dichotomy for finite-domain constraint satisfaction problems were Bulatov's proof of the dichotomy for conservative templates, and the structural dichotomy for smooth digraphs of algebraic length 1 due to Barto, Kozik, and Niven. We lift the combined scenario to the infinite, and prove that any smooth digraph of algebraic length 1 pp-constructs, together with pairs of orbits of an oligomorphic subgroup of its automorphism group, every finite structure -- and hence its conservative graph-colouring problem is NP-hard -- unless the digraph has a pseudo-loop, i.e. an edge within an orbit. We thereby overcome, for the first time, previous obstacles to lifting structural results for digraphs in this context from finite to $\omega$-categorical structures; the strongest lifting results hitherto not going beyond a generalisation of the Hell-Ne\v{s}et\v{r}il theorem for undirected graphs. As a consequence, we obtain a new algebraic invariant of arbitrary $\omega$-categorical structures enriched by pairs of orbits which fail to pp-construct some finite structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.17060v1</guid>
      <category>cs.LO</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Johanna Brunar, Marcin Kozik, Tom\'a\v{s} Nagy, Michael Pinsker</dc:creator>
    </item>
    <item>
      <title>Higher Eckmann-Hilton Arguments in Type Theory</title>
      <link>https://arxiv.org/abs/2501.16465</link>
      <description>arXiv:2501.16465v1 Announce Type: cross 
Abstract: We use a type theory for omega-categories to produce higher-dimensional generalisations of the Eckmann-Hilton argument. The heart of our construction is a family of padding and repadding techniques, which give a notion of congruence between cells of different types. This gives explicit witnesses in all dimensions that, for cells with degenerate boundary, all composition operations are congruent and commutative. Our work has been implemented, allowing us to explicitly compute these witnesses, and we show these grow rapidly in complexity as the parameters are varied. Our results can also be exported as elements of identity types in Martin-Lof type theory, and hence are of relevance in homotopy type theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16465v1</guid>
      <category>math.CT</category>
      <category>cs.LO</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thibaut Benjamin, Ioannis Markakis, Wilfred Offord, Chiara Sarti, Jamie Vicary</dc:creator>
    </item>
    <item>
      <title>VeriFact: Verifying Facts in LLM-Generated Clinical Text with Electronic Health Records</title>
      <link>https://arxiv.org/abs/2501.16672</link>
      <description>arXiv:2501.16672v1 Announce Type: cross 
Abstract: Methods to ensure factual accuracy of text generated by large language models (LLM) in clinical medicine are lacking. VeriFact is an artificial intelligence system that combines retrieval-augmented generation and LLM-as-a-Judge to verify whether LLM-generated text is factually supported by a patient's medical history based on their electronic health record (EHR). To evaluate this system, we introduce VeriFact-BHC, a new dataset that decomposes Brief Hospital Course narratives from discharge summaries into a set of simple statements with clinician annotations for whether each statement is supported by the patient's EHR clinical notes. Whereas highest agreement between clinicians was 88.5%, VeriFact achieves up to 92.7% agreement when compared to a denoised and adjudicated average human clinican ground truth, suggesting that VeriFact exceeds the average clinician's ability to fact-check text against a patient's medical record. VeriFact may accelerate the development of LLM-based EHR applications by removing current evaluation bottlenecks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16672v1</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.IR</category>
      <category>cs.LO</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Philip Chung, Akshay Swaminathan, Alex J. Goodell, Yeasul Kim, S. Momsen Reincke, Lichy Han, Ben Deverett, Mohammad Amin Sadeghi, Abdel-Badih Ariss, Marc Ghanem, David Seong, Andrew A. Lee, Caitlin E. Coombes, Brad Bradshaw, Mahir A. Sufian, Hyo Jung Hong, Teresa P. Nguyen, Mohammad R. Rasouli, Komal Kamra, Mark A. Burbridge, James C. McAvoy, Roya Saffary, Stephen P. Ma, Dev Dash, James Xie, Ellen Y. Wang, Clifford A. Schmiesing, Nigam Shah, Nima Aghaeepour</dc:creator>
    </item>
    <item>
      <title>Quantitative Equality in Substructural Logic via Lipschitz Doctrines</title>
      <link>https://arxiv.org/abs/2110.05388</link>
      <description>arXiv:2110.05388v5 Announce Type: replace 
Abstract: Substructural logics naturally support a quantitative interpretation of formulas, as they are seen as consumable resources. Distances are the quantitative counterpart of equivalence relations: they measure how much two objects are similar, rather than just saying whether they are equivalent or not. Hence, they provide the natural choice for modelling equality in a substructural setting. In this paper, we develop this idea, using the categorical language of Lawvere's doctrines. We work in a minimal fragment of Linear Logic enriched by graded modalities, which are needed to write a resource sensitive substitution rule for equality, enabling its quantitative interpretation as a distance. We introduce both a deductive calculus and the notion of Lipschitz doctrine to give it a sound and complete categorical semantics. The study of 2-categorical properties of Lipschitz doctrines provides us with a universal construction, which generates examples based for instance on metric spaces and quantitative realisability. Finally, we show how to smoothly extend our results to richer substructural logics, up to full Linear Logic with quantifiers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2110.05388v5</guid>
      <category>cs.LO</category>
      <category>math.CT</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Francesco Dagnino, Fabio Pasquali</dc:creator>
    </item>
    <item>
      <title>A Rewriting Theory for Quantum Lambda-Calculus</title>
      <link>https://arxiv.org/abs/2411.14856</link>
      <description>arXiv:2411.14856v2 Announce Type: replace 
Abstract: Quantum lambda calculus has been studied mainly as an idealized programming language -- the evaluation essentially corresponds to a deterministic abstract machine. Very little work has been done to develop a rewriting theory for quantum lambda calculus. Recent advances in the theory of probabilistic rewriting give us a way to tackle this task with tools unavailable a decade ago. Our primary focus is standardization and normalization results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14856v2</guid>
      <category>cs.LO</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Claudia Faggian, Gaetan Lopez, Beno\^it Valiron</dc:creator>
    </item>
    <item>
      <title>Constant-delay enumeration for SLP-compressed documents</title>
      <link>https://arxiv.org/abs/2209.12301</link>
      <description>arXiv:2209.12301v4 Announce Type: replace-cross 
Abstract: We study the problem of enumerating results from a query over a compressed document. The model we use for compression are straight-line programs (SLPs), which are defined by a context-free grammar that produces a single string. For our queries, we use a model called Annotated Automata, an extension of regular automata that allows annotations on letters. This model extends the notion of Regular Spanners as it allows arbitrarily long outputs. Our main result is an algorithm that evaluates such a query by enumerating all results with output-linear delay after a preprocessing phase which takes linear time on the size of the SLP, and cubic time over the size of the automaton. This is an improvement over Schmid and Schweikardt's result, which, with the same preprocessing time, enumerates with a delay that is logarithmic on the size of the uncompressed document. We achieve this through a persistent data structure named Enumerable Compact Sets with Shifts which guarantees output-linear delay under certain restrictions. These results imply constant-delay enumeration algorithms in the context of regular spanners. Further, we use an extension of annotated automata which utilizes succinctly encoded annotations to save an exponential factor from previous results that dealt with constant-delay enumeration over vset automata. Lastly, we extend our results in the same fashion Schmid and Schweikardt did to allow complex document editing while maintaining the constant delay guarantee.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.12301v4</guid>
      <category>cs.DS</category>
      <category>cs.FL</category>
      <category>cs.LO</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mart\'in Mu\~noz, Cristian Riveros</dc:creator>
    </item>
    <item>
      <title>Interchangeable Token Embeddings for Extendable Vocabulary and Alpha-Equivalence</title>
      <link>https://arxiv.org/abs/2410.17161</link>
      <description>arXiv:2410.17161v2 Announce Type: replace-cross 
Abstract: We propose a novel approach for learning interchangeable tokens in language models to obtain an extendable vocabulary that can generalize to new tokens. Our method addresses alpha-equivalence, the principle that renaming bound variables preserves semantics. This property arises in many formal languages such as temporal logics, where all proposition symbols represent the same concept but remain distinct. To handle such tokens, we develop a dual-part embedding approach. The first part is shared across all interchangeable tokens, enforcing that they represent the same core concept. The second part is randomly generated for each token, enabling distinguishability. As a baseline, we consider a simpler approach that uses alpha-renaming for data augmentation. We also present alpha-covariance, a metric for measuring robustness against alpha-conversions. When evaluated in a Transformer encoder-decoder model for solving linear temporal logic formulae and copying with extendable vocabulary, our method demonstrates promising generalization capabilities as well as a favorable inductive bias for alpha-equivalence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.17161v2</guid>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>\.Ilker I\c{s}{\i}k, Ramazan Gokberk Cinbis, Ebru Aydin Gol</dc:creator>
    </item>
    <item>
      <title>Naturality for higher-dimensional path types</title>
      <link>https://arxiv.org/abs/2501.11620</link>
      <description>arXiv:2501.11620v2 Announce Type: replace-cross 
Abstract: We define a naturality construction for the operations of weak omega-categories, as a meta-operation in a dependent type theory. Our construction has a geometrical motivation as a local tensor product with a directed interval, and behaves logically as a globular analogue of Reynolds parametricity. Our construction operates as a ``power tool'' to support construction of terms with geometrical structure, and we use it to define composition operations for cylinders and cones in omega-categories. The machinery can generate terms of high complexity, and we have implemented our construction in a proof assistant, which verifies that the generated terms have the correct type. All our results can be exported to homotopy type theory, allowing the explicit computation of complex path type inhabitants.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11620v2</guid>
      <category>math.CT</category>
      <category>cs.LO</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thibaut Benjamin, Ioannis Markakis, Wilfred Offord, Chiara Sarti, Jamie Vicary</dc:creator>
    </item>
  </channel>
</rss>
