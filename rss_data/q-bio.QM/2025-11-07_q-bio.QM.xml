<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.QM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.QM</link>
    <description>q-bio.QM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.QM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 07 Nov 2025 05:01:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Attention-based ROI Discovery in 3D Tissue Images</title>
      <link>https://arxiv.org/abs/2511.03751</link>
      <description>arXiv:2511.03751v1 Announce Type: new 
Abstract: High-dimensional tissue imaging generates highly complex 3D data containing multiple biomarkers, making it challenging to identify biologically relevant regions without an expert user specifying manual labels for regions of interest. We introduce an approach to automatically identifying regions of interest (ROIs) in the 3D microscopy data. Our approach is based on a novel self-supervised multi-layer graph attention network (SSGAT), coupled with a React interactive interface wrapped around Vitessce. SSGAT employs an adversarial self-supervised learning objective to identify meaningful immune microenvironments through marker interactions. Our method reveals complex spatial bioreactions that can be visually assessed to assess their distribution across tissue. Index Terms: Biomedical visualization, graph attention networks,self-supervised learning, spatial interaction analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03751v1</guid>
      <category>q-bio.QM</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hossein Fathollahian (University of Illinois Chicago), Siyuan Zhao (University of Illinois Chicago), Nafiul Nipu (University of Illinois Chicago), G. Elisabeta Marai (University of Illinois Chicago)</dc:creator>
    </item>
    <item>
      <title>Phenotype discovery of traumatic brain injury segmentations from heterogeneous multi-site data</title>
      <link>https://arxiv.org/abs/2511.03767</link>
      <description>arXiv:2511.03767v1 Announce Type: new 
Abstract: Traumatic brain injury (TBI) is intrinsically heterogeneous, and typical clinical outcome measures like the Glasgow Coma Scale complicate this diversity. The large variability in severity and patient outcomes render it difficult to link structural damage to functional deficits. The Federal Interagency Traumatic Brain Injury Research (FITBIR) repository contains large-scale multi-site magnetic resonance imaging data of varying resolutions and acquisition parameters (25 shared studies with 7,693 sessions that have age, sex and TBI status defined - 5,811 TBI and 1,882 controls). To reveal shared pathways of injury of TBI through imaging, we analyzed T1-weighted images from these sessions by first harmonizing to a local dataset and segmenting 132 regions of interest (ROIs) in the brain. After running quality assurance, calculating the volumes of the ROIs, and removing outliers, we calculated the z-scores of volumes for all participants relative to the mean and standard deviation of the controls. We regressed out sex, age, and total brain volume with a multivariate linear regression, and we found significant differences in 37 ROIs between subjects with TBI and controls (p &lt; 0.05 with independent t-tests with false discovery rate correction). We found that differences originated in 1) the brainstem, occipital pole and structures posterior to the orbit, 2) subcortical gray matter and insular cortex, and 3) cerebral and cerebellar white matter using independent component analysis and clustering the component loadings of those with TBI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03767v1</guid>
      <category>q-bio.QM</category>
      <category>eess.IV</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adam M. Saunders, Michael E. Kim, Gaurav Rudravaram, Lucas W. Remedios, Chloe Cho, Elyssa M. McMaster, Daniel R. Gillis, Yihao Liu, Lianrui Zuo, Bennett A. Landman, Tonia S. Rex</dc:creator>
    </item>
    <item>
      <title>Climbing the label tree: Hierarchy-preserving contrastive learning for medical imaging</title>
      <link>https://arxiv.org/abs/2511.03771</link>
      <description>arXiv:2511.03771v1 Announce Type: new 
Abstract: Medical image labels are often organized by taxonomies (e.g., organ - tissue - subtype), yet standard self-supervised learning (SSL) ignores this structure. We present a hierarchy-preserving contrastive framework that makes the label tree a first-class training signal and an evaluation target. Our approach introduces two plug-in objectives: Hierarchy-Weighted Contrastive (HWC), which scales positive/negative pair strengths by shared ancestors to promote within-parent coherence, and Level-Aware Margin (LAM), a prototype margin that separates ancestor groups across levels. The formulation is geometry-agnostic and applies to Euclidean and hyperbolic embeddings without architectural changes. Across several benchmarks, including breast histopathology, the proposed objectives consistently improve representation quality over strong SSL baselines while better respecting the taxonomy. We evaluate with metrics tailored to hierarchy faithfulness: HF1 (hierarchical F1), H-Acc (tree-distance-weighted accuracy), and parent-distance violation rate. We also report top-1 accuracy for completeness. Ablations show that HWC and LAM are effective even without curvature, and combining them yields the most taxonomy-aligned representations. Taken together, these results provide a simple, general recipe for learning medical image representations that respect the label tree and advance both performance and interpretability in hierarchy-rich domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03771v1</guid>
      <category>q-bio.QM</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alif Elham Khan</dc:creator>
    </item>
    <item>
      <title>CORE - A Cell-Level Coarse-to-Fine Image Registration Engine for Multi-stain Image Alignment</title>
      <link>https://arxiv.org/abs/2511.03826</link>
      <description>arXiv:2511.03826v1 Announce Type: new 
Abstract: Accurate and efficient registration of whole slide images (WSIs) is essential for high-resolution, nuclei-level analysis in multi-stained tissue slides. We propose a novel coarse-to-fine framework CORE for accurate nuclei-level registration across diverse multimodal whole-slide image (WSI) datasets. The coarse registration stage leverages prompt-based tissue mask extraction to effectively filter out artefacts and non-tissue regions, followed by global alignment using tissue morphology and ac- celerated dense feature matching with a pre-trained feature extractor. From the coarsely aligned slides, nuclei centroids are detected and subjected to fine-grained rigid registration using a custom, shape-aware point-set registration model. Finally, non-rigid alignment at the cellular level is achieved by estimating a non-linear dis- placement field using Coherent Point Drift (CPD). Our approach benefits from automatically generated nuclei that enhance the accuracy of deformable registra- tion and ensure precise nuclei-level correspondence across modalities. The pro- posed model is evaluated on three publicly available WSI registration datasets, and two private datasets. We show that CORE outperforms current state-of-the-art methods in terms of generalisability, precision, and robustness in bright-field and immunofluorescence microscopy WSIs</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03826v1</guid>
      <category>q-bio.QM</category>
      <category>cs.AI</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Esha Sadia Nasir, Behnaz Elhaminia, Mark Eastwood, Catherine King, Owen Cain, Lorraine Harper, Paul Moss, Dimitrios Chanouzas, David Snead, Nasir Rajpoot, Adam Shephard, Shan E Ahmed Raza</dc:creator>
    </item>
    <item>
      <title>Infrared Microscopy of Biochemistry and Metabolism in Single Living Eukaryotic Cells</title>
      <link>https://arxiv.org/abs/2511.04143</link>
      <description>arXiv:2511.04143v1 Announce Type: new 
Abstract: The turn of the millennium has seen a growing interest in the study of live cells by infrared (IR) spectroscopy, driven by the versatility, wealth of molecular information, and potential for high-throughput screening of the technique. Measurements on individual cells, either isolated or within a multi-cellular structure, provide information that is not available from ensemble samples. The present review discusses the use of infrared (IR) microscopy to analyse live single cells from a biochemical perspective, seeking information on real-time processes. The emphasis is on the use of the technique to quantify metabolic turnover, with the aim of providing a complementary method for metabolomics, and for toxicological and pharmacological studies. The present work highlights the methodological advances and proof-of-concept experiments that took place over the past few years in this direction. It discusses current advantages and limitations of the technique, including the possibility of detecting specific biomolecules and their reactivity, and it concludes with a brief outline of future perspectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.04143v1</guid>
      <category>q-bio.QM</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Luca Quaroni</dc:creator>
    </item>
    <item>
      <title>SILVI: Simple Interface for Labeling Video Interactions</title>
      <link>https://arxiv.org/abs/2511.03819</link>
      <description>arXiv:2511.03819v1 Announce Type: cross 
Abstract: Computer vision methods are increasingly used for the automated analysis of large volumes of video data collected through camera traps, drones, or direct observations of animals in the wild. While recent advances have focused primarily on detecting individual actions, much less work has addressed the detection and annotation of interactions -- a crucial aspect for understanding social and individualized animal behavior. Existing open-source annotation tools support either behavioral labeling without localization of individuals, or localization without the capacity to capture interactions. To bridge this gap, we present SILVI, an open-source labeling software that integrates both functionalities. SILVI enables researchers to annotate behaviors and interactions directly within video data, generating structured outputs suitable for training and validating computer vision models. By linking behavioral ecology with computer vision, SILVI facilitates the development of automated approaches for fine-grained behavioral analyses. Although developed primarily in the context of animal behavior, SILVI could be useful more broadly to annotate human interactions in other videos that require extracting dynamic scene graphs. The software, along with documentation and download instructions, is available at: https://gitlab.gwdg.de/kanbertay/interaction-labelling-app.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03819v1</guid>
      <category>cs.CV</category>
      <category>q-bio.QM</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ozan Kanbertay (Institute of Computer Science and Campus Institute Data Science, University of G\"ottingen), Richard Vogg (Institute of Computer Science and Campus Institute Data Science, University of G\"ottingen, Behavioral Ecology &amp; Sociobiology Unit, German Primate Center, G\"ottingen, Germany), Elif Karakoc (Behavioral Ecology &amp; Sociobiology Unit, German Primate Center, G\"ottingen, Germany), Peter M. Kappeler (Behavioral Ecology &amp; Sociobiology Unit, German Primate Center, G\"ottingen, Germany, Department of Sociobiology/Anthropology, University of G\"ottingen, G\"ottingen, Germany), Claudia Fichtel (Behavioral Ecology &amp; Sociobiology Unit, German Primate Center, G\"ottingen, Germany), Alexander S. Ecker (Institute of Computer Science and Campus Institute Data Science, University of G\"ottingen)</dc:creator>
    </item>
    <item>
      <title>Use of Continuous Glucose Monitoring with Machine Learning to Identify Metabolic Subphenotypes and Inform Precision Lifestyle Changes</title>
      <link>https://arxiv.org/abs/2511.03986</link>
      <description>arXiv:2511.03986v1 Announce Type: cross 
Abstract: The classification of diabetes and prediabetes by static glucose thresholds obscures the pathophysiological dysglycemia heterogeneity, primarily driven by insulin resistance (IR), beta-cell dysfunction, and incretin deficiency. This review demonstrates that continuous glucose monitoring and wearable technologies enable a paradigm shift towards non-invasive, dynamic metabolic phenotyping. We show evidence that machine learning models can leverage high-resolution glucose data from at-home, CGM-enabled oral glucose tolerance tests to accurately predict gold-standard measures of muscle IR and beta-cell function. This personalized characterization extends to real-world nutrition, where an individual's unique postprandial glycemic response (PPGR) to standardized meals, such as the relative glucose spike to potatoes versus grapes, could serve as a biomarker for their metabolic subtype. Moreover, integrating wearable data reveals that habitual diet, sleep, and physical activity patterns, particularly their timing, are uniquely associated with specific metabolic dysfunctions, informing precision lifestyle interventions. The efficacy of dietary mitigators in attenuating PPGR is also shown to be phenotype-dependent. Collectively, this evidence demonstrates that CGM can deconstruct the complexity of early dysglycemia into distinct, actionable subphenotypes. This approach moves beyond simple glycemic control, paving the way for targeted nutritional, behavioral, and pharmacological strategies tailored to an individual's core metabolic defects, thereby paving the way for a new era of precision diabetes prevention.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03986v1</guid>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ahmed A. Metwally, Heyjun Park, Yue Wu, Tracey McLaughlin, Michael P. Snyder</dc:creator>
    </item>
    <item>
      <title>Integrating protein sequence embeddings with structure via graph-based deep learning for single-residue property prediction</title>
      <link>https://arxiv.org/abs/2502.17294</link>
      <description>arXiv:2502.17294v2 Announce Type: replace 
Abstract: Understanding the intertwined contributions of amino acid sequence and spatial structure is essential to explain protein behaviour. Here, we introduce INFUSSE (Integrated Network Framework Unifying Structure and Sequence Embeddings), a deep learning framework for the prediction of single-residue properties that combines fine-tuning of sequence embeddings derived from a Large Language Model with the inclusion of graph-based representations of protein structures via a diffusive Graph Convolutional Network. To illustrate the benefits of jointly leveraging sequence and structure, we apply INFUSSE to the prediction of B-factors in antibodies, a residue property that reflects the local flexibility shaped by biochemical and structural constraints in these highly variable and dynamic proteins. Using a dataset of 1510 antibody and antibody-antigen complexes from the database SAbDab, we show that INFUSSE improves performance over current machine learning (ML) methods based on sequence or structure alone, and allows for the systematic disentanglement of sequence and structure contributions to the performance. Our results show that adding structural information via geometric graphs enhances predictions especially for intrinsically disordered regions, protein-protein interaction sites, and highly variable amino acid positions -- all key structural features for antibody function which are not well captured by purely sequence-based ML descriptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.17294v2</guid>
      <category>q-bio.QM</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Kevin Michalewicz, Mauricio Barahona, Barbara Bravi</dc:creator>
    </item>
    <item>
      <title>Convergence-divergence models: Generalizations of phylogenetic trees modeling gene flow over time</title>
      <link>https://arxiv.org/abs/2504.07384</link>
      <description>arXiv:2504.07384v2 Announce Type: replace-cross 
Abstract: Phylogenetic trees are simple models of evolutionary processes. They describe conditionally independent divergent evolution from common ancestors. However, they often lack the flexibility to represent processes like introgressive hybridization, which leads to gene flow between taxa. Phylogenetic networks generalize trees but typically assume that ancestral taxa merge instantaneously to form ``hybrid'' descendants. In contrast, convergence-divergence models retain a single underlying ``principal tree'' and permit gene flow over arbitrary time frames. They can also model other biological processes leading to taxa becoming more similar, such as replicated evolution. We present novel maximum likelihood algorithms to infer most aspects of $N$-taxon convergence-divergence models - many consistently - using a quartet-based approach. All algorithms use $4$-taxon convergence-divergence models, inferred from subsets of the $N$ taxa using a model selection criterion. The first algorithm infers an $N$-taxon principal tree; the second infers sets of converging taxa; and the third infers model parameters - root probabilities, edge lengths and convergence parameters. The algorithms can be applied to multiple sequence alignments restricted to genes or genomic windows or to gene presence/absence datasets. We demonstrate that convergence-divergence models can be accurately recovered from simulated data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.07384v2</guid>
      <category>q-bio.PE</category>
      <category>math.ST</category>
      <category>q-bio.QM</category>
      <category>stat.TH</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonathan D. Mitchell, Barbara R. Holland</dc:creator>
    </item>
  </channel>
</rss>
