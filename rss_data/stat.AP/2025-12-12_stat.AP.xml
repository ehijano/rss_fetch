<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 12 Dec 2025 05:00:57 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 12 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Classifying Metamorphic versus Single-Fold Proteins with Statistical Learning and AlphaFold2</title>
      <link>https://arxiv.org/abs/2512.10066</link>
      <description>arXiv:2512.10066v1 Announce Type: new 
Abstract: The remarkable success of AlphaFold2 in providing accurate atomic-level prediction of protein structures from their amino acid sequence has transformed approaches to the protein folding problem. However, its core paradigm of mapping one sequence to one structure may only be appropriate for single-fold proteins with one stable conformation. Metamorphic proteins, which can adopt multiple distinct conformations, have conformational diversity that cannot be adequately modeled by AlphaFold2. Hence, classifying whether a given protein is metamorphic or single-fold remains a critical challenge for both laboratory experiments and computational methods. To address this challenge, we developed a novel classification framework by re-purposing AlphaFold2 to generate conformational ensembles via a multiple sequence alignment sampling method. From these ensembles, we extract a comprehensive set of features characterizing the conformational ensemble's modality and structural dispersion. A random forest classifier trained on a carefully curated benchmark dataset of known metamorphic and single-fold proteins achieves a mean AUC of 0.869 with cross-validation, demonstrating the effectiveness of our integrated approach. Furthermore, by applying our classifier to 600 randomly sampled proteins from the Protein Data Bank, we identified several potential metamorphic protein candidates -- including the 40S ribosomal protein S30, whose conformational change is crucial for its secondary function in antimicrobial defense. By combining AI-driven protein structure prediction with statistical learning, our work provides a powerful new approach for discovering metamorphic proteins and deepens our understanding of their role in their molecular function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.10066v1</guid>
      <category>stat.AP</category>
      <category>cs.AI</category>
      <pubDate>Fri, 12 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yongkai Chen, Samuel WK Wong, SC Kou</dc:creator>
    </item>
    <item>
      <title>Alpha Power Harris-G Family of Distributions: Properties and Application to Burr XII Distribution</title>
      <link>https://arxiv.org/abs/2512.10276</link>
      <description>arXiv:2512.10276v1 Announce Type: new 
Abstract: This study introduces a new family of probability distributions, termed the alpha power Harris-generalized (APHG) family. The generator arises by incorporating two shape parameters from the Harris-G framework into the alpha power transformation, resulting in a more flexible class for modelling survival and reliability data. A special member of this family, obtained using the two-parameter Burr XII distribution as the baseline, is developed and examined in detail. Several analytical properties of the proposed alpha power Harris Burr XII (APHBXII) model are derived, which include closed-form expressions for its moments, mean and median deviations, Bonferroni and Lorenz curves, order statistics, and Renyi and Tsallis entropies. Parameter estimation is performed via maximum likelihood, and a Monte Carlo simulation study is carried out to assess the finite-sample performance of the estimators. In addition, three real lifetime datasets are analyzed to evaluate the empirical performance of the APHBXII distribution relative to four competing models. The results show that the five-parameter APHBXII model provides superior fit across all datasets, as supported by model-selection criteria and goodness-of-fit statistics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.10276v1</guid>
      <category>stat.AP</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Fri, 12 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gbenga A. Olalude, Taiwo A. Ojurongbe, Olalekan A. Bello, Kehinde A. Bashiru, Kazeem A. Alamu</dc:creator>
    </item>
    <item>
      <title>Beyond prewhitening: detection of gravity modes and their period spacings in slowly pulsating B stars using the multitaper F-test</title>
      <link>https://arxiv.org/abs/2512.10019</link>
      <description>arXiv:2512.10019v1 Announce Type: cross 
Abstract: Gravity modes in main-sequence stars have traditionally been studied using a prewhitening approach, which iteratively identifies modes in the Fourier domain and subsequently tunes their frequencies, amplitudes, and phases through time-domain regression. While effective, this method becomes inefficient when analysing large volumes of long time-series data and often relies on subjective stopping criteria to determine the number of iterations. We aim to perform frequency extraction of gravity modes in slowly pulsating B (SPB) stars using a statistically robust, data-driven approach based on advanced power spectrum and harmonic analysis techniques. Our approach employs the multitaper non-uniform fast Fourier transform, mtNUFFT, a power spectrum estimator that addresses several statistical limitations of traditional methods such as the Lomb-Scargle periodogram. We apply its extension, the multitaper F-test, to extract coherent gravity modes from 4-year Kepler light curves of SPB stars and to search for period spacing patterns among the extracted modes. The multitaper F-test enables fast and accurate extraction of the properties of gravity modes with quasi-infinite lifetimes, preferentially selecting modes that exhibit purely periodic behaviour. Although the method typically extracts fewer frequencies than conventional prewhitening, it recovers most known modes and, in some cases, reveals new ones. We also find evidence for gravity modes with long but finite lifetimes, and detect more than one period spacing pattern in some of the studied SPB stars. Overall, the multitaper F-test offers a more objective and statistically sound alternative to prewhitening. It scales efficiently to large datasets containing thousands of pulsators, and has the potential to facilitate mode identification and to distinguish between the different excitation mechanisms operating in SPB stars.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.10019v1</guid>
      <category>astro-ph.SR</category>
      <category>astro-ph.IM</category>
      <category>stat.AP</category>
      <pubDate>Fri, 12 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Aarya A. Patil, Conny Aerts, Nikki Y. N. Wang, Jordan Van Beeck, May G. Pedersen</dc:creator>
    </item>
    <item>
      <title>A Primer on Bayesian Parameter Estimation and Model Selection for Battery Simulators</title>
      <link>https://arxiv.org/abs/2512.10055</link>
      <description>arXiv:2512.10055v1 Announce Type: cross 
Abstract: Physics-based battery modelling has emerged to accelerate battery materials discovery and performance assessment. Its success, however, is still hindered by difficulties in aligning models to experimental data. Bayesian approaches are a valuable tool to overcome these challenges, since they enable prior assumptions and observations to be combined in a principled manner that improves numerical conditioning. Here we introduce two new algorithms to the battery community, SOBER and BASQ, that greatly speed up Bayesian inference for parameterisation and model comparison. We showcase how Bayesian model selection allows us to tackle data observability, model identifiability, and data-informed model development together. We propose this approach for the search for battery models of novel materials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.10055v1</guid>
      <category>stat.ME</category>
      <category>physics.data-an</category>
      <category>stat.AP</category>
      <pubDate>Fri, 12 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yannick Kuhn, Masaki Adachi, Micha Philipp, David A. Howey, Birger Horstmann</dc:creator>
    </item>
    <item>
      <title>Time-Averaged Drift Approximations are Inconsistent for Inference in Drift Diffusion Models</title>
      <link>https://arxiv.org/abs/2512.10250</link>
      <description>arXiv:2512.10250v1 Announce Type: cross 
Abstract: Drift diffusion models (DDMs) have found widespread use in computational neuroscience and other fields. They model evidence accumulation in simple decision tasks as a stochastic process drifting towards a decision barrier. In models where the drift rate is both time-varying within a trial and variable across trials, the high computational cost for accurate likelihood evaluation has led to the common use of a computationally convenient surrogate for parameter inference, the time-averaged drift approximation (TADA). In each trial, the TADA assumes that the time-varying drift rate can be replaced by its temporal average throughout the trial. This approach enables fast parameter inference using analytical likelihood formulas for DDMs with constant drift. In this work, we show that such an estimator is inconsistent: it does not converge to the true drift, posing a risk of biasing scientific conclusions drawn from parameter estimates produced by TADA and similar surrogates. We provide an elementary proof of this inconsistency in what is perhaps the simplest possible setting: a Brownian motion with piecewise constant drift hitting a one-sided upper boundary. Furthermore, we conduct numerical examples with an attentional DDM (aDDM) to show that the use of TADA systematically misestimates the effect of attention in decision making.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.10250v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Fri, 12 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sicheng Liu, Alexander Fengler, Michael J. Frank, Matthew T. Harrison</dc:creator>
    </item>
    <item>
      <title>Peace Sells, But Whose Songs Connect? Bayesian Multilayer Network Analysis of the Big 4 of Thrash Metal</title>
      <link>https://arxiv.org/abs/2512.10254</link>
      <description>arXiv:2512.10254v1 Announce Type: cross 
Abstract: We propose a Bayesian framework for multilayer song similarity networks and apply it to the complete studio discographies of the "Big 4" of thrash metal (Metallica, Slayer, Megadeth, Anthrax). Starting from raw audio, we construct four feature-specific layers (loudness, brightness, tonality, rhythm), augment them with song exogenous information, and represent each layer as a k-nearest neighbor graph. We then fit a family of hierarchical probit models with global and layer-specific baselines, node- and layer-specific sociability effects, dyadic covariates, and alternative forms of latent structure (bilinear, distance-based, and stochastic block communities), comparing increasingly flexible specifications using posterior predictive checks, discrimination and calibration metrics (AUC, Brier score, log-loss), and information criteria (DIC, WAIC). Across all bands, the richest stochastic block specification attains the best predictive performance and posterior predictive fit, while revealing sparse but structured connectivity, interpretable covariate effects (notably album membership and temporal proximity), and latent communities and hubs that cut across albums and eras. Taken together, these results illustrate how Bayesian multilayer network models can help organize high-dimensional audio and text features into coherent, musically meaningful patterns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.10254v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <pubDate>Fri, 12 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Juan Sosa, Erika Mart\'inez, Danna L. Cruz-Reyes</dc:creator>
    </item>
    <item>
      <title>Supporting Migration Policies with Forecasts: Illegal Border Crossings in Europe through a Mixed Approach</title>
      <link>https://arxiv.org/abs/2512.10633</link>
      <description>arXiv:2512.10633v1 Announce Type: cross 
Abstract: This paper presents a mixed-methodology to forecast illegal border crossings in Europe across five key migratory routes, with a one-year time horizon. The methodology integrates machine learning techniques with qualitative insights from migration experts. This approach aims at improving the predictive capacity of data-driven models through the inclusion of a human-assessed covariate, an innovation that addresses challenges posed by sudden shifts in migration patterns and limitations in traditional datasets. The proposed methodology responds directly to the forecasting needs outlined in the EU Pact on Migration and Asylum, supporting the Asylum and Migration Management Regulation (AMMR). It is designed to provide policy-relevant forecasts that inform strategic decisions, early warning systems, and solidarity mechanisms among EU Member States. By joining data-driven modeling with expert judgment, this work aligns with existing academic recommendations and introduces a novel operational tool tailored for EU migration governance. The methodology is tested and validated with known data to demonstrate its applicability and reliability in migration-related policy context.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.10633v1</guid>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <category>stat.AP</category>
      <pubDate>Fri, 12 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>C. Bosco, U. Minora, D. de Rigo, J. Pingsdorf, R. Cortinovis</dc:creator>
    </item>
    <item>
      <title>Further Statistical Study of NISQ Experiments</title>
      <link>https://arxiv.org/abs/2512.10722</link>
      <description>arXiv:2512.10722v1 Announce Type: cross 
Abstract: We revisit and extend some topics that we studied in our previous works (Rinott, Kalai and Shoham 2022; Kalai, Rinott and Shoham, 2023,2024) regarding the Google 2019 "quantum supremacy" experiment. We extend our analysis of the prediction based on Google's digital error model (Formula (77)), based on more detailed data provided by Google. We also provide some preliminary analysis for a few other NISQ experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.10722v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>stat.AP</category>
      <pubDate>Fri, 12 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gil Kalai, Tomer Shoham, Carsten Voelkmann</dc:creator>
    </item>
    <item>
      <title>Evaluating Organizational Effectiveness: A New Strategy to Leverage Multisite Randomized Trials for Valid Assessment</title>
      <link>https://arxiv.org/abs/2407.18360</link>
      <description>arXiv:2407.18360v4 Announce Type: replace 
Abstract: Determining which organizations are more effective in implementing an intervention program is essential for theoretically and empirically characterizing exemplary practice and for intervening to enhance the capacity of ineffective ones. Yet sites differ in their local ecological conditions including client composition, alternative programs, and community context. Applying the causal inference framework, this study proposes a formal mathematical definition for the local relative effectiveness of an organization attributable solely to malleable organizational practice. Capitalizing on multisite randomized trials, the identification leverages observed control group outcomes that capture some of the confounding impacts of otherwise unmeasured contextual variation. We propose a two-step mixed-effects modeling (2SME) procedure that adjusts for pre-existing between-site variation. A series of Monte Carlo simulations reveals its superior performance in comparison with conventional methods. We apply the new strategy to an evaluation of Job Corps centers nationwide serving disadvantaged youths.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18360v4</guid>
      <category>stat.AP</category>
      <pubDate>Fri, 12 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guanglei Hong (University of Chicago), Jonah Deutsch (Mathematica), Peter Kress (Mathematica), Jose Eos Trinidad (University of California-Berkeley), Zhengyan Xu (University of Pennsylvania)</dc:creator>
    </item>
    <item>
      <title>Bayesian Matrix Factor Models for Demographic Analysis Across Age and Time</title>
      <link>https://arxiv.org/abs/2502.09255</link>
      <description>arXiv:2502.09255v2 Announce Type: replace 
Abstract: Analyzing demographic data collected across multiple populations, time periods, and age groups is challenging due to the interplay of high dimensionality, demographic heterogeneity among groups, and stochastic variability within smaller groups. This paper proposes a Bayesian matrix factor model to address these challenges. By factorizing count data matrices as the product of low-dimensional latent age and time factors, the model achieves a parsimonious representation that mitigates overfitting and remains computationally feasible even when hundreds of populations are involved. Informative priors enforce smoothness in the age factors and allow for the dynamic evolution of the time factors. A straightforward Markov chain Monte Carlo algorithm is developed for posterior inference. Applying the model to Austrian district-level migration data from 2002 to 2023 demonstrates its ability to accurately reconstruct complex demographic processes using only a fraction of the parameters required by conventional demographic factor models. A forecasting exercise shows that the proposed model consistently outperforms standard benchmarks. Beyond statistical demography, the framework holds promise for a wide range of applications involving noisy, heterogeneous, and high-dimensional non-Gaussian matrix-valued data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09255v2</guid>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Fri, 12 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gregor Zens</dc:creator>
    </item>
    <item>
      <title>Group Cooperation Diverges onto Durable Low versus High Paths: Public Goods Experiments in 134 Honduran Villages</title>
      <link>https://arxiv.org/abs/2512.09316</link>
      <description>arXiv:2512.09316v2 Announce Type: replace 
Abstract: We performed large, lab-in-the-field experiment (2,591 participants across 134 Honduran villages; ten rounds) and tracked how contribution behavior unfolds in fixed, anonymous groups of size five. Contribution separates early into two durable paths, one low and one high, with rare convergence thereafter. High-path players can be identified with strong accuracy early on. Groups that begin with an early majority of above-norm contributors (about 60%) are very likely finish high. The empirical finding of a bifurcation, consistent with the theory, shows that early, high contributions by socially central people steer groups onto, and help keep them on, a high-cooperation path.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.09316v2</guid>
      <category>stat.AP</category>
      <category>stat.OT</category>
      <pubDate>Fri, 12 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marios Papamichalis, Nicholas Christakis, Feng Fu</dc:creator>
    </item>
    <item>
      <title>Bayesian Model Selection with an Application to Cosmology</title>
      <link>https://arxiv.org/abs/2512.09724</link>
      <description>arXiv:2512.09724v2 Announce Type: replace 
Abstract: We investigate cosmological parameter inference and model selection from a Bayesian perspective. Type Ia supernova data from the Dark Energy Survey (DES-SN5YR) are used to test the $\Lambda$CDM, $w$CDM, and CPL cosmological models. Posterior inference is performed via Hamiltonian Monte Carlo using the No-U-Turn Sampler (NUTS) implemented in NumPyro and analyzed with ArviZ in Python. Bayesian model comparison is conducted through Bayes factors computed using the bridgesampling library in R. The results indicate that all three models demonstrate similar predictive performance, but $w$CDM shows stronger evidence relative to $\Lambda$CDM and CPL. We conclude that, under the assumptions and data used in this study, $w$CDM provides a better description of cosmological expansion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.09724v2</guid>
      <category>stat.AP</category>
      <category>astro-ph.CO</category>
      <category>stat.ME</category>
      <pubDate>Fri, 12 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nikoloz Gigiberia</dc:creator>
    </item>
    <item>
      <title>A Bayesian Framework for Multivariate Differential Analysis</title>
      <link>https://arxiv.org/abs/2307.08975</link>
      <description>arXiv:2307.08975v3 Announce Type: replace-cross 
Abstract: Differential analysis is a routine procedure in the statistical analysis toolbox across many applied fields, including quantitative proteomics, the main illustration of the present paper. The state-of-the-art limma approach uses a hierarchical formulation with moderated-variance estimators for each analyte directly injected into the t-statistic. While standard hypothesis testing strategies are recognised for their low computational cost, allowing for quick extraction of the most differential among thousands of elements, they generally overlook key aspects such as handling missing values, inter-element correlations, and uncertainty quantification. The present paper proposes a fully Bayesian framework for differential analysis, leveraging a conjugate hierarchical formulation for both the mean and the variance. Inference is performed by computing the posterior distribution of compared experimental conditions and sampling from the distribution of differences. This approach provides well-calibrated uncertainty quantification at a similar computational cost as hypothesis testing by leveraging closed-form equations. Furthermore, a natural extension enables multivariate differential analysis that accounts for possible inter-element correlations. We also demonstrate that, in this Bayesian treatment, missing data should generally be ignored in univariate settings, and further derive a tailored approximation that handles multiple imputation for the multivariate setting. We argue that probabilistic statements in terms of effect size and associated uncertainty are better suited to practical decision-making. Therefore, we finally propose simple and intuitive inference criteria, such as the overlap coefficient, which express group similarity as a probability rather than traditional, and often misleading, p-values.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.08975v3</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Fri, 12 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Marie Chion, Arthur Leroy</dc:creator>
    </item>
    <item>
      <title>Potential Landscapes Reveal Spatiotemporal Structure in Urban Mobility: Hodge Decomposition and Principal Component Analysis of Tokyo Before and During COVID-19</title>
      <link>https://arxiv.org/abs/2505.20929</link>
      <description>arXiv:2505.20929v4 Announce Type: replace-cross 
Abstract: Understanding human mobility is vital to solving societal challenges, such as epidemic control and urban transportation optimization. Recent advancements in data collection now enable the exploration of dynamic mobility patterns in human flow. However, the vast volume and complexity of mobility data make it difficult to interpret spatiotemporal patterns directly, necessitating effective information reduction. The core challenge is to balance data simplification with information preservation: methods must retain location-specific information about human flows from origins to destinations while reducing the data to a comprehensible level. This study proposes a two-step dimensionality reduction framework: First, combinatorial Hodge theory is applied to the given origin--destination (OD) matrices with timestamps to construct a set of potential landscapes of human flow, preserving imbalanced trip information between locations. Second, principal component analysis (PCA) expresses the time series of potential landscapes as a linear combination of a few static spatial components, with their coefficients representing temporal variations. The framework systematically decouples the spatial and temporal components of the given data. By implementing this two-step reduction method, we reveal large weight variations during a pandemic, characterized by an overall decline in mobility and stark contrasts between weekdays and holidays. These findings demonstrate the effectiveness of our framework in uncovering complex mobility patterns and its potential to inform urban planning and public health interventions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20929v4</guid>
      <category>cs.SI</category>
      <category>physics.soc-ph</category>
      <category>stat.AP</category>
      <pubDate>Fri, 12 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yunhan Du, Takaaki Aoki, Naoya Fujiwara</dc:creator>
    </item>
    <item>
      <title>Optimal designs for identifying effective doses in drug combination studies</title>
      <link>https://arxiv.org/abs/2506.05913</link>
      <description>arXiv:2506.05913v2 Announce Type: replace-cross 
Abstract: We consider the optimal design problem for identifying effective dose combinations within drug combination studies where the effect of the combination of two drugs is investigated. Drug combination studies are becoming increasingly important as they investigate potential interaction effects rather than the individual impacts of the drugs. In this situation, identifying effective dose combinations that yield a prespecified effect is of special interest. If nonlinear surface models are used to describe the dose combination-response relationship, these effective dose combinations result in specific contour lines of the fitted response model.
  We propose a novel design criterion that targets the precise estimation of these effective dose combinations. In particular, an optimal design minimizes the width of the confidence band of the contour lines of interest. Optimal design theory is developed for this problem, including equivalence theorems and efficiency bounds. The performance of the optimal design is illustrated in different examples modeling dose combination data by various nonlinear surface models. It is demonstrated that the proposed optimal design for identifying effective dose combinations yields a more precise estimation of the effective dose combinations than ray or factorial designs, which are commonly used in practice. This particularly holds true for a case study motivated by data from an oncological dose combination study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05913v2</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Fri, 12 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Leonie Sch\"urmeyer, Ludger Sandig, Jorrit K\"uhne, Leonie Theresa Hezler, Bernd-Wolfgang Igl, Kirsten Schorning</dc:creator>
    </item>
    <item>
      <title>Trustworthy scientific inference with generative models</title>
      <link>https://arxiv.org/abs/2508.02602</link>
      <description>arXiv:2508.02602v2 Announce Type: replace-cross 
Abstract: Generative artificial intelligence (AI) excels at producing complex data structures (text, images, videos) by learning patterns from training examples. Across scientific disciplines, researchers are now applying generative models to "inverse problems" to directly predict hidden parameters from observed data along with measures of uncertainty. While these predictive or posterior-based methods can handle intractable likelihoods and large-scale studies, they can also produce biased or overconfident conclusions even without model misspecifications. We present a solution with Frequentist-Bayes (FreB), a mathematically rigorous protocol that reshapes AI-generated posterior probability distributions into (locally valid) confidence regions that consistently include true parameters with the expected probability, while achieving minimum size when training and target data align. We demonstrate FreB's effectiveness by tackling diverse case studies in the physical sciences: identifying unknown sources under dataset shift, reconciling competing theoretical models, and mitigating selection bias and systematics in observational studies. By providing validity guarantees with interpretable diagnostics, FreB enables trustworthy scientific inference across fields where direct likelihood evaluation remains impossible or prohibitively expensive.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02602v2</guid>
      <category>stat.ML</category>
      <category>astro-ph.IM</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Fri, 12 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>James Carzon, Luca Masserano, Joshua D. Ingram, Alex Shen, Antonio Carlos Herling Ribeiro Junior, Tommaso Dorigo, Michele Doro, Joshua S. Speagle, Rafael Izbicki, Ann B. Lee</dc:creator>
    </item>
    <item>
      <title>Principal component analysis in econometrics: a selective inference perspective</title>
      <link>https://arxiv.org/abs/2511.10419</link>
      <description>arXiv:2511.10419v2 Announce Type: replace-cross 
Abstract: We study the long-standing problem of determining the number of principal components in econometric applications from a selective inference perspective. We consider i.i.d. observations from a $p$-dimensional random vector with $p&lt;n$ and define the ``true'' dimensionality as the rank of the population covariance matrix. Building on the sequential testing viewpoint, we propose a data-driven procedure that estimates $\rank(\Sigma_X)$ using a statistic that depends on the eigenvalues of the sample covariance matrix. While the test statistic shares the functional form of its fixed design counterpart Choi et al. (2017), our analysis departs from the non-stochastic setting by treating the design as random and by avoiding parametric Gaussian assumptions. Under a locally defined null hypothesis, we establish asymptotically exact type~I error controls in the sequential testing procedure, with simulation results indicating empirical validity of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.10419v2</guid>
      <category>econ.EM</category>
      <category>stat.AP</category>
      <pubDate>Fri, 12 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yasuyuki Matsumura, Chisato Tachibana</dc:creator>
    </item>
    <item>
      <title>Latency-Response Theory Model: Evaluating Large Language Models via Response Accuracy and Chain-of-Thought Length</title>
      <link>https://arxiv.org/abs/2512.07019</link>
      <description>arXiv:2512.07019v2 Announce Type: replace-cross 
Abstract: The proliferation of Large Language Models (LLMs) necessitates valid evaluation methods to guide downstream applications and actionable future improvements. The Item Response Theory (IRT) has recently emerged as a promising framework for evaluating LLMs via their response accuracy. Beyond simple response accuracy, LLMs' chain of thought (CoT) lengths serve as a vital indicator of their reasoning ability. To leverage the CoT length information to assist the evaluation of LLMs, we propose Latency-Response Theory (LaRT) to jointly model the response accuracy and CoT length by introducing the latent ability, latent speed, and a key correlation parameter between them. We derive an efficient estimation algorithm and establish rigorous identifiability results for the population parameters to ensure the statistical validity of estimation. Theoretical asymptotic analyses and simulation studies demonstrate LaRT's advantages over IRT in terms of higher estimation accuracy and shorter confidence intervals for latent traits. A key finding is that the asymptotic estimation precision of the latent ability under LaRT exceeds that of IRT whenever the latent ability and latent speed are correlated. We collect real responses from diverse LLMs on popular benchmark datasets. The application of LaRT reveals a strong negative correlation between the latent ability and latent speed in all benchmarks, with stronger correlation for more difficult benchmarks. This finding supports the intuition that higher reasoning ability correlates with slower speed and longer response latency. LaRT yields different LLM rankings than IRT and outperforms IRT across multiple key evaluation metrics including predictive power, item efficiency, ranking validity, and LLM evaluation efficiency. Code and data are available at https://github.com/Toby-X/Latency-Response-Theory-Model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.07019v2</guid>
      <category>stat.ME</category>
      <category>cs.AI</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <pubDate>Fri, 12 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhiyu Xu, Jia Liu, Yixin Wang, Yuqi Gu</dc:creator>
    </item>
  </channel>
</rss>
