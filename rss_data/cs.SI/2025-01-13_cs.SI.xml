<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SI</link>
    <description>cs.SI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 13 Jan 2025 05:00:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 13 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Identifying rich clubs in spatiotemporal interaction networks</title>
      <link>https://arxiv.org/abs/2501.05636</link>
      <description>arXiv:2501.05636v1 Announce Type: new 
Abstract: Spatial networks are widely used in various fields to represent and analyze interactions or relationships between locations or spatially distributed entities.There is a network science concept known as the 'rich club' phenomenon, which describes the tendency of 'rich' nodes to form densely interconnected sub-networks. Although there are established methods to quantify topological, weighted, and temporal rich clubs individually, there is limited research on measuring the rich club effect in spatially-weighted temporal networks, which could be particularly useful for studying dynamic spatial interaction networks. To address this gap, we introduce the spatially-weighted temporal rich club (WTRC), a metric that quantifies the strength and consistency of connections between rich nodes in a spatiotemporal network. Additionally, we present a unified rich club framework that distinguishes the WTRC effect from other rich club effects, providing a way to measure topological, weighted, and temporal rich club effects together. Through two case studies of human mobility networks at different spatial scales, we demonstrate how the WTRC is able to identify significant weighted temporal rich club effects, whereas the unweighted equivalent in the same network either fails to detect a rich club effect or inaccurately estimates its significance. In each case study, we explore the spatial layout and temporal variations revealed by the WTRC analysis, showcasing its particular value in studying spatiotemporal interaction networks. This research offers new insights into the study of spatiotemporal networks, with critical implications for applications such as transportation, redistricting, and epidemiology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.05636v1</guid>
      <category>cs.SI</category>
      <category>physics.soc-ph</category>
      <pubDate>Mon, 13 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Annals of the American Association of Geographers, 2025</arxiv:journal_reference>
      <dc:creator>Jacob Kruse, Song Gao, Yuhan Ji, Keith Levin, Qunying Huang, Kenneth R. Mayer</dc:creator>
    </item>
    <item>
      <title>Collaborative Content Moderation in the Fediverse</title>
      <link>https://arxiv.org/abs/2501.05871</link>
      <description>arXiv:2501.05871v1 Announce Type: new 
Abstract: The Fediverse, a group of interconnected servers providing a variety of interoperable services (e.g. micro-blogging in Mastodon) has gained rapid popularity. This sudden growth, partly driven by Elon Musk's acquisition of Twitter, has created challenges for administrators though. This paper focuses on one particular challenge: content moderation, e.g. the need to remove spam or hate speech. While centralized platforms like Facebook and Twitter rely on automated tools for moderation, their dependence on massive labeled datasets and specialized infrastructure renders them impractical for decentralized, low-resource settings like the Fediverse. In this work, we design and evaluate FedMod, a collaborative content moderation system based on federated learning. Our system enables servers to exchange parameters of partially trained local content moderation models with similar servers, creating a federated model shared among collaborating servers. FedMod demonstrates robust performance on three different content moderation tasks: harmful content detection, bot content detection, and content warning assignment, achieving average per-server macro-F1 scores of 0.71, 0.73, and 0.58, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.05871v1</guid>
      <category>cs.SI</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Mon, 13 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haris Bin Zia, Aravindh Raman, Ignacio Castro, Gareth Tyson</dc:creator>
    </item>
    <item>
      <title>Expressing One's Identity Online: Left-Right and cross EU-country variation in self-representation in social media</title>
      <link>https://arxiv.org/abs/2501.05927</link>
      <description>arXiv:2501.05927v1 Announce Type: new 
Abstract: We examine how social media users from eight European Union (EU) member states express their socio-political identities, focusing on users' online self-presentation and group identity cues conveyed through bios. Our goal is to explore commonalities and differences in topics discussed in social media profiles, across Left-and Right-wing user groups, within and across EU countries. Through a novel approach we map how identity-related discourse varies by country and political orientation, revealing how group identity is expressed within the EU. We find that topics related to democracy, national way of life, and decentralization emerge as particularly divisive, showing considerable variation both within and between EU countries. A subset of topics, which includes education, environmentalism, sustainability, equality, freedom &amp; human rights, and traditional morality, among others, clearly differentiate Left-from Right-leaning user groups. These partisan topics are relevant as they could be leveraged for mobilizing ideological groups and highlight Left-Right identitarian differences at the EU level. Finally, we show that our Left-Right identity similarity metrics reflect aspects of real-world political fragmentation, which are closely aligned to the perceptions of political conflict intensity by country, as measured by the 2022 PEW survey.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.05927v1</guid>
      <category>cs.SI</category>
      <pubDate>Mon, 13 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Carlo Romano Marcello Alessandro Santagiustina (m\'edialab), Jean-Philippe Cointet (m\'edialab), Pedro Ramaciotti Morales (ISC-PIF, m\'edialab)</dc:creator>
    </item>
    <item>
      <title>HP-BERT: A framework for longitudinal study of Hinduphobia on social media via LLMs</title>
      <link>https://arxiv.org/abs/2501.05482</link>
      <description>arXiv:2501.05482v1 Announce Type: cross 
Abstract: During the COVID-19 pandemic, community tensions intensified, fuelling Hinduphobic sentiments and discrimination against individuals of Hindu descent within India and worldwide. Large language models (LLMs) have become prominent in natural language processing (NLP) tasks and social media analysis, enabling longitudinal studies of platforms like X (formerly Twitter) for specific issues during COVID-19. We present an abuse detection and sentiment analysis framework that offers a longitudinal analysis of Hinduphobia on X (Twitter) during and after the COVID-19 pandemic. This framework assesses the prevalence and intensity of Hinduphobic discourse, capturing elements such as derogatory jokes and racist remarks through sentiment analysis and abuse detection from pre-trained and fine-tuned LLMs. Additionally, we curate and publish a "Hinduphobic COVID-19 X (Twitter) Dataset" of 8,000 tweets annotated for Hinduphobic abuse detection, which is used to fine-tune a BERT model, resulting in the development of the Hinduphobic BERT (HP-BERT) model. We then further fine-tune HP-BERT using the SenWave dataset for multi-label sentiment analysis. Our study encompasses approximately 27.4 million tweets from six countries, including Australia, Brazil, India, Indonesia, Japan, and the United Kingdom. Our findings reveal a strong correlation between spikes in COVID-19 cases and surges in Hinduphobic rhetoric, highlighting how political narratives, misinformation, and targeted jokes contributed to communal polarisation. These insights provide valuable guidance for developing strategies to mitigate communal tensions in future crises, both locally and globally. We advocate implementing automated monitoring and removal of such content on social media to curb divisive discourse.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.05482v1</guid>
      <category>cs.CL</category>
      <category>cs.SI</category>
      <pubDate>Mon, 13 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ashutosh Singh, Rohitash Chandra</dc:creator>
    </item>
    <item>
      <title>Negative Ties Highlight Hidden Extremes in Social Media Polarization</title>
      <link>https://arxiv.org/abs/2501.05590</link>
      <description>arXiv:2501.05590v1 Announce Type: cross 
Abstract: Human interactions in the online world comprise a combination of positive and negative exchanges. These diverse interactions can be captured using signed network representations, where edges take positive or negative weights to indicate the sentiment of the interaction between individuals. Signed networks offer valuable insights into online political polarization by capturing antagonistic interactions and ideological divides on social media platforms. This study analyzes polarization on Men\'eame, a Spanish social media that facilitates engagement with news stories through comments and voting. Using a dual-method approach -- Signed Hamiltonian Eigenvector Embedding for Proximity (SHEEP) for signed networks and Correspondence Analysis (CA) for unsigned networks -- we investigate how including negative ties enhances the understanding of structural polarization levels across different conversation topics on the platform. We find that the unsigned Men\'eame network accurately delineates ideological communities, but negative ties are necessary for detecting extreme users who engage in antagonistic behaviors. We also show that far-left users are more likely to use negative interactions to engage across ideological lines, while far-right users interact primarily with users similar to themselves.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.05590v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.SI</category>
      <pubDate>Mon, 13 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elena Candellone, Shazia'Ayn Babul, \"Ozg\"ur Togay, Alexandre Bovet, Javier Garcia-Bernardo</dc:creator>
    </item>
    <item>
      <title>Social web and Wikipedia: an opportunity to rethink the links between sources' credibility, trust and authority</title>
      <link>https://arxiv.org/abs/2501.05813</link>
      <description>arXiv:2501.05813v1 Announce Type: cross 
Abstract: The Web and its main tools (Google, Wikipedia, Facebook, Twitter) deeply raise and renew fundamental questions, that everyone asks almost every day: Is this information or content true? Can I trust this author or source? These questions are not new, they have been the same with books, newspapers, broadcasting and television, and, more fundamentally, in every human interpersonal communication. This paper is focused on two scientific problems on this issue. The first one is theoretical: to address this issue, many concepts have been used in library and information sciences, communication and psychology. The links between these concepts are not clear: sometimes two concepts are considered as synonymous, sometimes as very different. The second one is historical: sources like Wikipedia deeply challenge the epistemic evaluation of information sources, compared to previous modes of information production. This paper proposes an integrated and simple model considering the relation between a user, a document and an author as human communication. It reduces the problem to three concepts: credibility as a characteristic granted to information depending on its truth-value; trust as the ability to produce credible information; authority when the power to influence of an author is accepted, i.e., when readers accept that the source can modify their opinion, knowledge and decisions. The model describes also two kinds of relationships between the three concepts: an upward link and a downward link. The model is confronted with findings of empirical research on Wikipedia in particular.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.05813v1</guid>
      <category>cs.IR</category>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <pubDate>Mon, 13 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>First Monday, 2017, 23 (1)</arxiv:journal_reference>
      <dc:creator>Gilles Sahut (LERASS), Andr\'e Tricot (CLLE-LTC)</dc:creator>
    </item>
    <item>
      <title>Supervision policies can shape long-term risk management in general-purpose AI models</title>
      <link>https://arxiv.org/abs/2501.06137</link>
      <description>arXiv:2501.06137v1 Announce Type: cross 
Abstract: The rapid proliferation and deployment of General-Purpose AI (GPAI) models, including large language models (LLMs), present unprecedented challenges for AI supervisory entities. We hypothesize that these entities will need to navigate an emergent ecosystem of risk and incident reporting, likely to exceed their supervision capacity. To investigate this, we develop a simulation framework parameterized by features extracted from the diverse landscape of risk, incident, or hazard reporting ecosystems, including community-driven platforms, crowdsourcing initiatives, and expert assessments. We evaluate four supervision policies: non-prioritized (first-come, first-served), random selection, priority-based (addressing the highest-priority risks first), and diversity-prioritized (balancing high-priority risks with comprehensive coverage across risk types). Our results indicate that while priority-based and diversity-prioritized policies are more effective at mitigating high-impact risks, particularly those identified by experts, they may inadvertently neglect systemic issues reported by the broader community. This oversight can create feedback loops that amplify certain types of reporting while discouraging others, leading to a skewed perception of the overall risk landscape. We validate our simulation results with several real-world datasets, including one with over a million ChatGPT interactions, of which more than 150,000 conversations were identified as risky. This validation underscores the complex trade-offs inherent in AI risk supervision and highlights how the choice of risk management policies can shape the future landscape of AI risks across diverse GPAI models used in society.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.06137v1</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <pubDate>Mon, 13 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Manuel Cebrian, Emilia Gomez, David Fernandez Llorca</dc:creator>
    </item>
    <item>
      <title>DeepTrace: Learning to Optimize Contact Tracing in Epidemic Networks with Graph Neural Networks</title>
      <link>https://arxiv.org/abs/2211.00880</link>
      <description>arXiv:2211.00880v4 Announce Type: replace 
Abstract: Digital contact tracing aims to curb epidemics by identifying and mitigating public health emergencies through technology. Backward contact tracing, which tracks the sources of infection, proved crucial in places like Japan for identifying COVID-19 infections from superspreading events. This paper presents a novel perspective of digital contact tracing as online graph exploration and addresses the forward and backward contact tracing problem as a maximum-likelihood (ML) estimation problem using iterative epidemic network data sampling. The challenge lies in the combinatorial complexity and rapid spread of infections. We introduce DeepTrace, an algorithm based on a Graph Neural Network (GNN) that iteratively updates its estimations as new contact tracing data is collected, learning to optimize the maximum likelihood estimation by utilizing topological features to accelerate learning and improve convergence. The contact tracing process combines either BFS or DFS to expand the network and trace the infection source, ensuring comprehensive and efficient exploration. Additionally, the GNN model is fine-tuned through a two-phase approach: pre-training with synthetic networks to approximate likelihood probabilities and fine-tuning with high-quality data to refine the model. Using COVID-19 variant data, we illustrate that DeepTrace surpasses current methods in identifying superspreaders, providing a robust basis for a scalable digital contact tracing strategy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.00880v4</guid>
      <category>cs.SI</category>
      <category>physics.soc-ph</category>
      <pubDate>Mon, 13 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chee Wei Tan, Pei-Duo Yu, Siya Chen, H. Vincent Poor</dc:creator>
    </item>
    <item>
      <title>Flexible inference in heterogeneous and attributed multilayer networks</title>
      <link>https://arxiv.org/abs/2405.20918</link>
      <description>arXiv:2405.20918v2 Announce Type: replace 
Abstract: Networked datasets can be enriched by different types of information about individual nodes or edges. However, most existing methods for analyzing such datasets struggle to handle the complexity of heterogeneous data, often requiring substantial model-specific analysis. In this paper, we develop a probabilistic generative model to perform inference in multilayer networks with arbitrary types of information. Our approach employs a Bayesian framework combined with the Laplace matching technique to ease interpretation of inferred parameters. Furthermore, the algorithmic implementation relies on automatic differentiation, avoiding the need for explicit derivations. This makes our model scalable and flexible to adapt to any combination of input data. We demonstrate the effectiveness of our method in detecting overlapping community structures and performing various prediction tasks on heterogeneous multilayer data, where nodes and edges have different types of attributes. Additionally, we showcase its ability to unveil a variety of patterns in a social support network among villagers in rural India by effectively utilizing all input information in a meaningful way.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20918v2</guid>
      <category>cs.SI</category>
      <category>physics.data-an</category>
      <category>stat.ML</category>
      <pubDate>Mon, 13 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Martina Contisciani, Marius Hobbhahn, Eleanor A. Power, Philipp Hennig, Caterina De Bacco</dc:creator>
    </item>
    <item>
      <title>The Expressive Power of Graph Neural Networks: A Survey</title>
      <link>https://arxiv.org/abs/2308.08235</link>
      <description>arXiv:2308.08235v2 Announce Type: replace-cross 
Abstract: Graph neural networks (GNNs) are effective machine learning models for many graph-related applications. Despite their empirical success, many research efforts focus on the theoretical limitations of GNNs, i.e., the GNNs expressive power. Early works in this domain mainly focus on studying the graph isomorphism recognition ability of GNNs, and recent works try to leverage the properties such as subgraph counting and connectivity learning to characterize the expressive power of GNNs, which are more practical and closer to real-world. However, no survey papers and open-source repositories comprehensively summarize and discuss models in this important direction. To fill the gap, we conduct a first survey for models for enhancing expressive power under different forms of definition. Concretely, the models are reviewed based on three categories, i.e., Graph feature enhancement, Graph topology enhancement, and GNNs architecture enhancement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.08235v2</guid>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <pubDate>Mon, 13 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TKDE.2024.3523700</arxiv:DOI>
      <dc:creator>Bingxu Zhang, Changjun Fan, Shixuan Liu, Kuihua Huang, Xiang Zhao, Jincai Huang, Zhong Liu</dc:creator>
    </item>
  </channel>
</rss>
