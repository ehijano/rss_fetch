<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NE</link>
    <description>cs.NE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 31 Oct 2025 01:39:32 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Exponential Dynamic Energy Network for High Capacity Sequence Memory</title>
      <link>https://arxiv.org/abs/2510.24965</link>
      <description>arXiv:2510.24965v1 Announce Type: new 
Abstract: The energy paradigm, exemplified by Hopfield networks, offers a principled framework for memory in neural systems by interpreting dynamics as descent on an energy surface. While powerful for static associative memories, it falls short in modeling sequential memory, where transitions between memories are essential. We introduce the Exponential Dynamic Energy Network (EDEN), a novel architecture that extends the energy paradigm to temporal domains by evolving the energy function over multiple timescales. EDEN combines a static high-capacity energy network with a slow, asymmetrically interacting modulatory population, enabling robust and controlled memory transitions. We formally derive short-timescale energy functions that govern local dynamics and use them to analytically compute memory escape times, revealing a phase transition between static and dynamic regimes. The analysis of capacity, defined as the number of memories that can be stored with minimal error rate as a function of the dimensions of the state space (number of feature neurons), for EDEN shows that it achieves exponential sequence memory capacity $O(\gamma^N)$, outperforming the linear capacity $O(N)$ of conventional models. Furthermore, EDEN's dynamics resemble the activity of time and ramping cells observed in the human brain during episodic memory tasks, grounding its biological relevance. By unifying static and sequential memory within a dynamic energy framework, EDEN offers a scalable and interpretable model for high-capacity temporal memory in both artificial and biological systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.24965v1</guid>
      <category>cs.NE</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arjun Karuvally, Pichsinee Lertsaroj, Terrence J. Sejnowski, Hava T. Siegelmann</dc:creator>
    </item>
    <item>
      <title>Maximum-Entropy Analog Computing Approaching ExaOPS-per-Watt Energy-efficiency at the RF-Edge</title>
      <link>https://arxiv.org/abs/2510.24975</link>
      <description>arXiv:2510.24975v1 Announce Type: new 
Abstract: In this paper, we demonstrate how the physics of entropy production, when combined with symmetry constraints, can be used for implementing high-performance and energy-efficient analog computing systems. At the core of the proposed framework is a generalized maximum-entropy principle that can describe the evolution of a mesoscopic physical system formed by an interconnected ensemble of analog elements, including devices that can be readily fabricated on standard integrated circuit technology. We show that the maximum-entropy state of this ensemble corresponds to a margin-propagation (MP) distribution and can be used for computing correlations and inner products as the ensemble's macroscopic properties. Furthermore, the limits of computational throughput and energy efficiency can be pushed by extending the framework to non-equilibrium or transient operating conditions, which we demonstrate using a proof-of-concept radio-frequency (RF) correlator integrated circuit fabricated in a 22 nm SOI CMOS process. The measured results show a compute efficiency greater than 2 Peta ($10^{15}$) Bit Operations per second per Watt (PetaOPS/W) at 8-bit precision and greater than 0.8 Exa ($10^{18}$) Bit Operations per second per Watt (ExaOPS/W) at 3-bit precision for RF data sampled at rates greater than 4 GS/s. Using the fabricated prototypes, we also showcase several real-world RF applications at the edge, including spectrum sensing, and code-domain communications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.24975v1</guid>
      <category>cs.NE</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.ET</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aswin Undavalli, Kareem Rashed, Zhili Xiao, Arun Natarajan, Shantanu Chakrabartty, Aravind Nagulu</dc:creator>
    </item>
    <item>
      <title>Socio-cognitive agent-oriented evolutionary algorithm with trust-based optimization</title>
      <link>https://arxiv.org/abs/2510.25095</link>
      <description>arXiv:2510.25095v1 Announce Type: new 
Abstract: This paper introduces the Trust-Based Optimization (TBO), a novel extension of the island model in evolutionary computation that replaces conventional periodic migrations with a flexible, agent-driven interaction mechanism based on trust or reputation. Experimental results demonstrate that TBO generally outperforms the standard island model evolutionary algorithm across various optimization problems. Nevertheless, algorithm performance varies depending on the problem type, with certain configurations being more effective for specific landscapes or dimensions. The findings suggest that trust and reputation mechanisms provide a flexible and adaptive approach to evolutionary optimization, improving solution quality in many cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25095v1</guid>
      <category>cs.NE</category>
      <category>math.OC</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-031-97554-7_18</arxiv:DOI>
      <arxiv:journal_reference>Computational Science - ICCS 2025 Workshops, Lecture Notes in Computer Science, 15907, 249-264</arxiv:journal_reference>
      <dc:creator>Aleksandra Urba\'nczyk, Krzysztof Czech, Piotr Urba\'nczyk, Marek Kisiel-Dorohinicki, Aleksander Byrski</dc:creator>
    </item>
    <item>
      <title>A Benchmark Suite for Multi-Objective Optimization in Battery Thermal Management System Design</title>
      <link>https://arxiv.org/abs/2510.25219</link>
      <description>arXiv:2510.25219v1 Announce Type: new 
Abstract: Synthetic Benchmark Problems (SBPs) are commonly used to evaluate the performance of metaheuristic algorithms. However, these SBPs often contain various unrealistic properties, potentially leading to underestimation or overestimation of algorithmic performance. While several benchmark suites comprising real-world problems have been proposed for various types of metaheuristics, a notable gap exists for Constrained Multi-objective Optimization Problems (CMOPs) derived from practical engineering applications, particularly in the domain of Battery Thermal Management System (BTMS) design. To address this gap, this study develops and presents a specialized benchmark suite for multi-objective optimization in BTMS. This suite comprises a diverse collection of real-world constrained problems, each defined via accurate surrogate models based on recent research to efficiently represent complex thermal-fluid interactions. The primary goal of this benchmark suite is to provide a practical and relevant testing ground for evolutionary algorithms and optimization methods focused on energy storage thermal management. Future work will involve establishing comprehensive baseline results using state-of-the-art algorithms, conducting comparative analyses, and developing a standardized ranking scheme to facilitate robust performance assessment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25219v1</guid>
      <category>cs.NE</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kaichen Ouyang, Yezhi Xia</dc:creator>
    </item>
    <item>
      <title>Resource-Efficient and Robust Inference of Deep and Bayesian Neural Networks on Embedded and Analog Computing Platforms</title>
      <link>https://arxiv.org/abs/2510.24951</link>
      <description>arXiv:2510.24951v1 Announce Type: cross 
Abstract: While modern machine learning has transformed numerous application domains, its growing computational demands increasingly constrain scalability and efficiency, particularly on embedded and resource-limited platforms. In practice, neural networks must not only operate efficiently but also provide reliable predictions under distributional shifts or unseen data. Bayesian neural networks offer a principled framework for quantifying uncertainty, yet their computational overhead further compounds these challenges.
  This work advances resource-efficient and robust inference for both conventional and Bayesian neural networks through the joint pursuit of algorithmic and hardware efficiency. The former reduces computation through model compression and approximate Bayesian inference, while the latter optimizes deployment on digital accelerators and explores analog hardware, bridging algorithmic design and physical realization. The first contribution, Galen, performs automatic layer-specific compression guided by sensitivity analysis and hardware-in-the-loop feedback. Analog accelerators offer efficiency gains at the cost of noise; this work models device imperfections and extends noisy training to nonstationary conditions, improving robustness and stability. A second line of work advances probabilistic inference, developing analytic and ensemble approximations that replace costly sampling, integrate into a compiler stack, and optimize embedded inference. Finally, probabilistic photonic computing introduces a paradigm where controlled analog noise acts as an intrinsic entropy source, enabling fast, energy-efficient probabilistic inference directly in hardware.
  Together, these studies demonstrate how efficiency and reliability can be advanced jointly through algorithm-hardware co-design, laying the foundation for the next generation of trustworthy, energy-efficient machine-learning systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.24951v1</guid>
      <category>cs.LG</category>
      <category>cs.AR</category>
      <category>cs.NE</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bernhard Klein</dc:creator>
    </item>
    <item>
      <title>Dynamically Weighted Momentum with Adaptive Step Sizes for Efficient Deep Network Training</title>
      <link>https://arxiv.org/abs/2510.25042</link>
      <description>arXiv:2510.25042v1 Announce Type: cross 
Abstract: Within the current sphere of deep learning research, despite the extensive application of optimization algorithms such as Stochastic Gradient Descent (SGD) and Adaptive Moment Estimation (Adam), there remains a pronounced inadequacy in their capability to address fluctuations in learning efficiency, meet the demands of complex models, and tackle non-convex optimization issues. These challenges primarily arise from the algorithms' limitations in handling complex data structures and models, for instance, difficulties in selecting an appropriate learning rate, avoiding local optima, and navigating through high-dimensional spaces. To address these issues, this paper introduces a novel optimization algorithm named DWMGrad. This algorithm, building on the foundations of traditional methods, incorporates a dynamic guidance mechanism reliant on historical data to dynamically update momentum and learning rates. This allows the optimizer to flexibly adjust its reliance on historical information, adapting to various training scenarios. This strategy not only enables the optimizer to better adapt to changing environments and task complexities but also, as validated through extensive experimentation, demonstrates DWMGrad's ability to achieve faster convergence rates and higher accuracies under a multitude of scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25042v1</guid>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhifeng Wang, Longlong Li, Chunyan Zeng</dc:creator>
    </item>
    <item>
      <title>Position: Biology is the Challenge Physics-Informed ML Needs to Evolve</title>
      <link>https://arxiv.org/abs/2510.25368</link>
      <description>arXiv:2510.25368v1 Announce Type: cross 
Abstract: Physics-Informed Machine Learning (PIML) has successfully integrated mechanistic understanding into machine learning, particularly in domains governed by well-known physical laws. This success has motivated efforts to apply PIML to biology, a field rich in dynamical systems but shaped by different constraints. Biological modeling, however, presents unique challenges: multi-faceted and uncertain prior knowledge, heterogeneous and noisy data, partial observability, and complex, high-dimensional networks. In this position paper, we argue that these challenges should not be seen as obstacles to PIML, but as catalysts for its evolution. We propose Biology-Informed Machine Learning (BIML): a principled extension of PIML that retains its structural grounding while adapting to the practical realities of biology. Rather than replacing PIML, BIML retools its methods to operate under softer, probabilistic forms of prior knowledge. We outline four foundational pillars as a roadmap for this transition: uncertainty quantification, contextualization, constrained latent structure inference, and scalability. Foundation Models and Large Language Models will be key enablers, bridging human expertise with computational modeling. We conclude with concrete recommendations to build the BIML ecosystem and channel PIML-inspired innovation toward challenges of high scientific and societal relevance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25368v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julien Martinelli</dc:creator>
    </item>
    <item>
      <title>Bridging Expressivity and Scalability with Adaptive Unitary SSMs</title>
      <link>https://arxiv.org/abs/2507.05238</link>
      <description>arXiv:2507.05238v2 Announce Type: replace 
Abstract: Recent work has revealed that state space models (SSMs), while efficient for long-sequence processing, are fundamentally limited in their ability to represent formal languages-particularly due to time-invariant and real-valued recurrence structures. In this work, we draw inspiration from adaptive and structured dynamics observed in biological neural systems and introduce the Adaptive Unitary State Space Model (AUSSM), a novel class of SSMs that leverages skew-symmetric, input-dependent recurrence to achieve unitary evolution and high expressive power. Using algebraic automata theory, we prove that AUSSM can perform modulo counting and simulate solvable group automata at finite precision, enabling AUSSM to model a broad class of regular languages out of reach for other SSM architectures. To overcome the practical inefficiencies of adaptive recurrence, we develop a separable convolution formulation and a CUDA implementation that enables scalable parallel training. Empirically, we show that AUSSM and its hybrid variant-interleaved with Mamba-outperform prior SSMs on formal algorithmic tasks such as parity and modular arithmetic, and achieve competent performance on real-world long time-series classification benchmarks. Our results demonstrate that adaptive unitary recurrence provides a powerful and efficient inductive bias for both symbolic and continuous sequence modeling. The code is available at https://github.com/arjunkaruvally/AUSSM</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.05238v2</guid>
      <category>cs.NE</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arjun Karuvally, Franz Nowak, Anderson T. Keller, Carmen Amo Alonso, Terrence J. Sejnowski, Hava T. Siegelmann</dc:creator>
    </item>
    <item>
      <title>Explainable Framework for Swarm Intelligence Based on Fitness Landscape Features and Machine Learning</title>
      <link>https://arxiv.org/abs/2509.06272</link>
      <description>arXiv:2509.06272v2 Announce Type: replace 
Abstract: Swarm based optimization algorithms have demonstrated remarkable success in solving complex optimization problems. However, their widespread adoption remains sceptical due to limited transparency in how different algorithmic components influence the overall performance of the algorithm. This work presents a multi-faceted interpretability related investigations of one of the popular swarm algorithms, Particle Swarm Optimization. Through this work, we provide a framework that makes the role of different topologies and parameters in PSO interpretable and explainable using novel machine learning approach. We first developed a comprehensive landscape characterization framework using Exploratory Landscape Analysis to quantify problem difficulty and identify critical features in the problem that affects the optimization performance of PSO. Secondly, we rigorously compare three topologies -- Ring, Star, and Von Neumann -- analyzing their distinct impacts on exploration-exploitation balance, convergence behavior, and solution quality and eventually develop an explainable benchmarking framework for PSO. The work successfully decodes how swarm topologies affect information flow, diversity, and convergence. Through systematic experimentation across 24 benchmark functions in multiple dimensions, we establish practical guidelines for topology selection and parameter configuration. These findings uncover the black-box nature of PSO, providing more transparency and interpretability to swarm intelligence systems. The source code is available at https://github.com/GitNitin02/ioh_pso.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.06272v2</guid>
      <category>cs.NE</category>
      <category>cs.LG</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Nitin Gupta, Bapi Dutta, Anupam Yadav</dc:creator>
    </item>
    <item>
      <title>Brain-inspired Computational Intelligence via Predictive Coding</title>
      <link>https://arxiv.org/abs/2308.07870</link>
      <description>arXiv:2308.07870v3 Announce Type: replace-cross 
Abstract: Artificial intelligence (AI) is rapidly becoming one of the key technologies of this century. The majority of results in AI thus far have been achieved using deep neural networks trained with a learning algorithm called error backpropagation, always considered biologically implausible. To this end, recent works have studied learning algorithms for deep neural networks inspired by the neurosciences. One such theory, called predictive coding (PC), has shown promising properties that make it potentially valuable for the machine learning community: it can model information processing in different areas of the brain, can be used in control and robotics, has a solid mathematical foundation in variational inference, and performs its computations asynchronously. Inspired by such properties, works that propose novel PC-like algorithms are starting to be present in multiple sub-fields of machine learning and AI at large. Here, we survey such efforts by first providing a broad overview of the history of PC to provide common ground for the understanding of the recent developments, then by describing current efforts and results, and concluding with a large discussion of possible implications and ways forward.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.07870v3</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tommaso Salvatori, Ankur Mali, Christopher L. Buckley, Thomas Lukasiewicz, Rajesh P. N. Rao, Karl Friston, Alexander Ororbia</dc:creator>
    </item>
    <item>
      <title>Artificial Neural Networks Trained on Noisy Speech Exhibit the McGurk Effect</title>
      <link>https://arxiv.org/abs/2411.05715</link>
      <description>arXiv:2411.05715v2 Announce Type: replace-cross 
Abstract: Humans are able to fuse information from both auditory and visual modalities to help with understanding speech. This is demonstrated through a phenomenon known as the McGurk Effect, during which a listener is presented with incongruent auditory and visual speech that fuse together into the percept of illusory intermediate phonemes. Building on a recent framework that proposes how to address developmental 'why' questions using artificial neural networks, we evaluated a set of recent artificial neural networks trained on audiovisual speech by testing them with audiovisually incongruent words designed to elicit the McGurk effect. We show that networks trained entirely on congruent audiovisual speech nevertheless exhibit the McGurk percept. We further investigated 'why' by comparing networks trained on clean speech to those trained on noisy speech, and discovered that training with noisy speech led to a pronounced increase in both visual responses and McGurk responses across all models. Furthermore, we observed that systematically increasing the level of auditory noise during ANN training also increased the amount of audiovisual integration up to a point, but at extreme noise levels, this integration failed to develop. These results suggest that excessive noise exposure during critical periods of audiovisual learning may negatively influence the development of audiovisual speech integration. This work also demonstrates that the McGurk effect reliably emerges untrained from the behaviour of both supervised and unsupervised networks, even networks trained only on congruent speech. This supports the notion that artificial neural networks might be useful models for certain aspects of perception and cognition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05715v2</guid>
      <category>cs.SD</category>
      <category>cs.MM</category>
      <category>cs.NE</category>
      <category>eess.AS</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lukas Grasse, Matthew S. Tata</dc:creator>
    </item>
    <item>
      <title>SNN-Based Online Learning of Concepts and Action Laws in an Open World</title>
      <link>https://arxiv.org/abs/2411.12308</link>
      <description>arXiv:2411.12308v4 Announce Type: replace-cross 
Abstract: We present the architecture of a fully autonomous, bio-inspired cognitive agent built around a spiking neural network (SNN) implementing the agent's semantic memory. This agent explores its universe and learns concepts of objects/situations and of its own actions in a one-shot manner. While object/situation concepts are unary, action concepts are triples made up of an initial situation, a motor activity, and an outcome. They embody the agent's knowledge of its universe's action laws. Both kinds of concepts have different degrees of generality. To make decisions the agent queries its semantic memory for the expected outcomes of envisaged actions and chooses the action to take on the basis of these predictions. Our experiments show that the agent handles new situations by appealing to previously learned general concepts and rapidly modifies its concepts to adapt to environment changes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12308v4</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <category>cs.RO</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christel Grimaud (IRIT-LILaC), Dominique Longin (IRIT-LILaC), Andreas Herzig (IRIT-LILaC)</dc:creator>
    </item>
    <item>
      <title>Scaling Up Liquid-Resistance Liquid-Capacitance Networks for Efficient Sequence Modeling</title>
      <link>https://arxiv.org/abs/2505.21717</link>
      <description>arXiv:2505.21717v5 Announce Type: replace-cross 
Abstract: We present LrcSSM, a $\textit{non-linear}$ recurrent model that processes long sequences as fast as today's linear state-space layers. By forcing its Jacobian matrix to be diagonal, the full sequence can be solved in parallel, giving $\mathcal{O}(TD)$ time and memory and only $\mathcal{O}(\log T)$ sequential depth, for input-sequence length $T$ and a state dimension $D$. Moreover, LrcSSM offers a formal gradient-stability guarantee that other input-varying systems such as Liquid-S4 and Mamba do not provide. Importantly, the diagonal Jacobian structure of our model results in no performance loss compared to the original model with dense Jacobian, and the approach can be generalized to other non-linear recurrent models, demonstrating broader applicability. On a suite of long-range forecasting tasks, we demonstrate that LrcSSM outperforms Transformers, LRU, S5, and Mamba.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21717v5</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>M\'onika Farsang, Ramin Hasani, Daniela Rus, Radu Grosu</dc:creator>
    </item>
    <item>
      <title>Towards Scaling Deep Neural Networks with Predictive Coding: Theory and Practice</title>
      <link>https://arxiv.org/abs/2510.23323</link>
      <description>arXiv:2510.23323v2 Announce Type: replace-cross 
Abstract: Backpropagation (BP) is the standard algorithm for training the deep neural networks that power modern artificial intelligence including large language models. However, BP is energy inefficient and unlikely to be implemented by the brain. This thesis studies an alternative, potentially more efficient brain-inspired algorithm called predictive coding (PC). Unlike BP, PC networks (PCNs) perform inference by iterative equilibration of neuron activities before learning or weight updates. Recent work has suggested that this iterative inference procedure provides a range of benefits over BP, such as faster training. However, these advantages have not been consistently observed, the inference and learning dynamics of PCNs are still poorly understood, and deep PCNs remain practically untrainable. Here, we make significant progress towards scaling PCNs by taking a theoretical approach grounded in optimisation theory. First, we show that the learning dynamics of PC can be understood as an approximate trust-region method using second-order information, despite explicitly using only first-order local updates. Second, going beyond this approximation, we show that PC can in principle make use of arbitrarily higher-order information, such that for feedforward networks the effective landscape on which PC learns is far more benign and robust to vanishing gradients than the (mean squared error) loss landscape. Third, motivated by a study of the inference dynamics of PCNs, we propose a new parameterisation called "$\mu$PC", which for the first time allows stable training of 100+ layer networks with little tuning and competitive performance on simple tasks. Overall, this thesis significantly advances our fundamental understanding of the inference and learning dynamics of PCNs, while highlighting the need for future research to focus on hardware co-design if PC is to compete with BP at scale.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.23323v2</guid>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Francesco Innocenti</dc:creator>
    </item>
  </channel>
</rss>
