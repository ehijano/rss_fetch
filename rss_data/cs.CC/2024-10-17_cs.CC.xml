<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 18 Oct 2024 02:17:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>NP-hardness of testing equivalence to sparse polynomials and to constant-support polynomials</title>
      <link>https://arxiv.org/abs/2410.12251</link>
      <description>arXiv:2410.12251v1 Announce Type: new 
Abstract: An $s$-sparse polynomial has at most $s$ monomials with nonzero coefficients. The Equivalence Testing problem for sparse polynomials (ETsparse) asks to decide if a given polynomial $f$ is equivalent to (i.e., in the orbit of) some $s$-sparse polynomial. In other words, given $f \in \mathbb{F}[\mathbf{x}]$ and $s \in \mathbb{N}$, ETsparse asks to check if there exist $A \in \mathrm{GL}(|\mathbf{x}|, \mathbb{F})$ and $\mathbf{b} \in \mathbb{F}^{|\mathbf{x}|}$ such that $f(A\mathbf{x} + \mathbf{b})$ is $s$-sparse. We show that ETsparse is NP-hard over any field $\mathbb{F}$, if $f$ is given in the sparse representation, i.e., as a list of nonzero coefficients and exponent vectors. This answers a question posed in [Gupta-Saha-Thankey, SODA'23] and [Baraskar-Dewan-Saha, STACS'24]. The result implies that the Minimum Circuit Size Problem (MCSP) is NP-hard for a dense subclass of depth-$3$ arithmetic circuits if the input is given in sparse representation. We also show that approximating the smallest $s_0$ such that a given $s$-sparse polynomial $f$ is in the orbit of some $s_0$-sparse polynomial to within a factor of $s^{\frac{1}{3} - \epsilon}$ is NP-hard for any $\epsilon &gt; 0$; observe that $s$-factor approximation is trivial as the input is $s$-sparse. Finally, we show that for any constant $\sigma \geq 5$, checking if a polynomial (given in sparse representation) is in the orbit of some support-$\sigma$ polynomial is NP-hard. Support of a polynomial $f$ is the maximum number of variables present in any monomial of $f$. These results are obtained via direct reductions from the $3$-SAT problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12251v1</guid>
      <category>cs.CC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Omkar Baraskar, Agrim Dewan, Chandan Saha, Pulkit Sinha</dc:creator>
    </item>
    <item>
      <title>Commuting Local Hamiltonians Beyond 2D</title>
      <link>https://arxiv.org/abs/2410.10495</link>
      <description>arXiv:2410.10495v3 Announce Type: cross 
Abstract: Commuting local Hamiltonians provide a testing ground for studying many of the most interesting open questions in quantum information theory, including the quantum PCP conjecture and the existence of area laws. Although they are a simplified model of quantum computation, the status of the commuting local Hamiltonian problem remains largely unknown. A number of works have shown that increasingly expressive families of commuting local Hamiltonians admit completely classical verifiers. Despite intense work, the largest class of commuting local Hamiltonians we can place in NP are those on a square lattice, where each lattice site is a qutrit. Even worse, many of the techniques used to analyze these problems rely heavily on the geometry of the square lattice and the properties of the numbers 2 and 3 as local dimensions. In this work, we present a new technique to analyze the complexity of various families of commuting local Hamiltonians: guided reductions. Intuitively, these are a generalization of typical reduction where the prover provides a guide so that the verifier can construct a simpler Hamiltonian. The core of our reduction is a new rounding technique based on a combination of Jordan's Lemma and the Structure Lemma. Our rounding technique is much more flexible than previous work, and allows us to show that a larger family of commuting local Hamiltonians is in NP, albiet with the restriction that all terms are rank-1. Specifically, we prove the following two results:
  1. Commuting local Hamiltonians in 2D that are rank-1 are contained in NP, independent of the qudit dimension. Note that this family of commuting local Hamiltonians has no restriction on the local dimension or the locality.
  2. We prove that rank-1, 3D commuting Hamiltonians with qudits on edges are in NP. To our knowledge this is the first time a family of 3D commuting local Hamiltonians has been contained in NP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10495v3</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>John Bostanci, Yeongwoo Hwang</dc:creator>
    </item>
    <item>
      <title>On the time complexity analysis of numerical percolation threshold estimation</title>
      <link>https://arxiv.org/abs/2410.11874</link>
      <description>arXiv:2410.11874v1 Announce Type: cross 
Abstract: The main purpose of percolation theory is to model phase transitions in a variety of random systems, which is highly valuable in fields related to materials physics, biology, or otherwise unrelated areas like oil extraction or even quantum computing. Thus, one of the problems encountered is the calculation of the threshold at which such transition occurs, known as percolation threshold. Since there are no known closed forms to determine the threshold in an exact manner in systems with particular properties, it is decided to rely on numerical methods as the Monte Carlo approach, which provides a sufficiently accurate approximation to serve as a valid estimate in the projects or research where it is involved. However, in order to achieve an exact characterization of the threshold in two-dimensional systems with site percolation, in this work it is performed an analysis of the complexity, both temporal and spatial, of an algorithm that implements its computation from the aforementioned numerical method. Specifically, the conduction of an accurate analysis of the cost of such algorithm implies a deep enough knowledge about certain metrics regarding its duration, or work completed per iteration, which along with its formalization may contribute to the determination of the threshold based on these metrics. Nevertheless, as a result, various bounds are achieved for the best, average and worst cases of the execution on systems spanning several dimensions, revealing that in 1 and 2 the complexity is directly conditioned by the duration, although from 3 onwards no proof for this point has been found, notwithstanding the evidence suggesting its compliance. Furthermore, based on the average case, several methods are proposed that could be applied to characterize the threshold, although they have not been thoroughly explored beyond what is necessary for the complexity analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11874v1</guid>
      <category>cond-mat.stat-mech</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.CC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Garc\'ia Solla</dc:creator>
    </item>
    <item>
      <title>On the Power of Clifford Strategies in Interactive Protocols</title>
      <link>https://arxiv.org/abs/2410.12030</link>
      <description>arXiv:2410.12030v1 Announce Type: cross 
Abstract: The Gottesman-Knill theorem shows that Clifford circuits operating on stabilizer states can be efficiently simulated classically. However, in the setting of interactive protocols, it has remained unclear whether Clifford strategies with shared entanglement between provers offer any advantage over classical ones. We provide a negative answer to this question, demonstrating that even when Clifford provers are additionally allowed to perform general classical operations on measured qubits $-$ a computational model for which we introduce the complexity class $\text{Clifford-MIP}^\ast$ $-$ there is no advantage over classical strategies. Our results imply that $\text{Clifford-MIP}^\ast = \text{MIP}$.
  Furthermore, we utilize our findings to resolve an open question posed by Kalai et al. (STOC 2023). We show that quantum advantage in any non-local game requires at least two quantum provers operating outside the $\text{Clifford-MIP}^\ast$ computational model. This rules out a suggested approach for significantly improving the efficiency of tests for quantum advantage that are based on compiling non-local games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12030v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.CR</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Itay Shalit</dc:creator>
    </item>
    <item>
      <title>Distributed inner product estimation with limited quantum communication</title>
      <link>https://arxiv.org/abs/2410.12684</link>
      <description>arXiv:2410.12684v1 Announce Type: cross 
Abstract: We consider the task of distributed inner product estimation when allowed limited quantum communication. Here, Alice and Bob are given $k$ copies of an unknown $n$-qubit quantum states $\vert \psi \rangle,\vert \phi \rangle$ respectively. They are allowed to communicate $q$ qubits and unlimited classical communication, and their goal is to estimate $|\langle \psi|\phi\rangle|^2$ up to constant accuracy. We show that $k=\Theta(\sqrt{2^{n-q}})$ copies are essentially necessary and sufficient for this task (extending the work of Anshu, Landau and Liu (STOC'22) who considered the case when $q=0$). Additionally, we consider estimating $|\langle \psi|M|\phi\rangle|^2$, for arbitrary Hermitian $M$. For this task we show that certain norms on $M$ characterize the sample complexity of estimating $|\langle \psi|M|\phi\rangle|^2$ when using only classical~communication.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12684v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Srinivasan Arunachalam, Louis Schatzki</dc:creator>
    </item>
    <item>
      <title>Identity Testing for Radical Expressions</title>
      <link>https://arxiv.org/abs/2202.07961</link>
      <description>arXiv:2202.07961v4 Announce Type: replace 
Abstract: We study the Radical Identity Testing problem (RIT): Given an algebraic circuit representing a polynomial $f\in \mathbb{Z}[x_1, \ldots, x_k]$ and nonnegative integers $a_1, \ldots, a_k$ and $d_1, \ldots,$ $d_k$, written in binary, test whether the polynomial vanishes at the real radicals $\sqrt[d_1]{a_1}, \ldots,\sqrt[d_k]{a_k}$, i.e., test whether $f(\sqrt[d_1]{a_1}, \ldots,\sqrt[d_k]{a_k}) = 0$. We place the problem in coNP assuming the Generalised Riemann Hypothesis (GRH), improving on the straightforward PSPACE upper bound obtained by reduction to the existential theory of reals. Next we consider a restricted version, called $2$-RIT, where the radicals are square roots of prime numbers, written in binary. It was known since the work of Chen and Kao that $2$-RIT is at least as hard as the polynomial identity testing problem, however no better upper bound than PSPACE was known prior to our work. We show that $2$-RIT is in coRP assuming GRH and in coNP unconditionally. Our proof relies on theorems from algebraic and analytic number theory, such as the Chebotarev density theorem and quadratic reciprocity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2202.07961v4</guid>
      <category>cs.CC</category>
      <category>cs.LO</category>
      <category>cs.SC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nikhil Balaji, Klara Nosan, Mahsa Shirmohammadi, James Worrell</dc:creator>
    </item>
    <item>
      <title>A parametric version of the Hilbert Nullstellensatz</title>
      <link>https://arxiv.org/abs/2408.13027</link>
      <description>arXiv:2408.13027v2 Announce Type: replace 
Abstract: Hilbert's Nullstellensatz is a fundamental result in algebraic geometry that gives a necessary and sufficient condition for a finite collection of multivariate polynomials to have a common zero in an algebraically closed field. Associated with this result, there is the computational problem HN of determining whether a system of polynomials with coefficients in the field of rational numbers has a common zero over the field of algebraic numbers.
  In an influential paper, Koiran showed that HN can be determined in the polynomial hierarchy assuming the Generalised Riemann Hypothesis (GRH). More precisely, he showed that HN lies in the complexity class AM under GRH. In a later work he generalised this result by showing that the problem DIM, which asks to determine the dimension of the set of solutions of a given polynomial system, also lies in AM subject to GRH.
  In this paper we study the solvability of polynomial equations over arbitrary algebraically closed fields of characteristic zero. Up to isomorphism, every such field is the algebraic closure of a field of rational functions. We thus formulate a parametric version of HN, called HNP, in which the input is a system of polynomials with coefficients in a function field $\mathbb{Q}(\mathbf{x})$ and the task is to determine whether the polynomials have a common zero in the algebraic closure $\overline{\mathbb{Q}(\mathbf{x})}$.
  We observe that Koiran's proof that DIM lies in AM can be interpreted as a randomised polynomial-time reduction of DIM to HNP, followed by an argument that HNP lies in AM. Our main contribution is a self-contained proof that HNP lies in AM that follows the same basic idea as Koiran's argument -- namely random instantiation of the parameters -- but whose justification is purely algebraic, relying on a parametric version of Hilbert's Nullstellensatz, and avoiding recourse to semi-algebraic geometry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.13027v2</guid>
      <category>cs.CC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rida Ait El Manssour, Nikhil Balaji, Klara Nosan, Mahsa Shirmohammadi, James Worrell</dc:creator>
    </item>
    <item>
      <title>Causal Discovery under Latent Class Confounding</title>
      <link>https://arxiv.org/abs/2311.07454</link>
      <description>arXiv:2311.07454v5 Announce Type: replace-cross 
Abstract: An acyclic causal structure can be described with directed acyclic graph (DAG), where arrows indicate the possibility of direct causation. The task of learning this structure from data is known as "causal discovery." Diverse populations or changing environments can sometimes give rise to data that is heterogeneous in the following sense: each population/environment is a "source" which idiosyncratically determines the forms of those direct causal effects. From this perspective, the source is a latent common cause for every observed variable. While some methods for causal discovery are able to work around latent confounding in special cases, especially when only few observables are confounded, a global confounder is a difficult challenge. The only known ways to deal with latent global confounding involve assumptions that limit the structural equations and/or noise functions. We demonstrate that globally confounded causal structures can still be identifiable with arbitrary structural equations and noise functions, so long as the number of latent classes remains small relative to the size and sparsity of the underlying DAG.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.07454v5</guid>
      <category>cs.LG</category>
      <category>cs.CC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bijan Mazaheri, Spencer Gordon, Yuval Rabani, Leonard Schulman</dc:creator>
    </item>
  </channel>
</rss>
