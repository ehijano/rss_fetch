<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CY updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CY</link>
    <description>cs.CY updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CY" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 12 Mar 2024 04:00:15 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 12 Mar 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Explaining Code Examples in Introductory Programming Courses: LLM vs Humans</title>
      <link>https://arxiv.org/abs/2403.05538</link>
      <description>arXiv:2403.05538v1 Announce Type: new 
Abstract: Worked examples, which present an explained code for solving typical programming problems are among the most popular types of learning content in programming classes. Most approaches and tools for presenting these examples to students are based on line-by-line explanations of the example code. However, instructors rarely have time to provide explanations for many examples typically used in a programming class. In this paper, we assess the feasibility of using LLMs to generate code explanations for passive and active example exploration systems. To achieve this goal, we compare the code explanations generated by chatGPT with the explanations generated by both experts and students.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05538v1</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Peter Brusilovsky, Arun-Balajiee Lekshmi-Narayanan, Priti Oli, Jeevan Chapagain, Mohammad Hassany, Rabin Banjade, Vasile Rus</dc:creator>
    </item>
    <item>
      <title>Insights from the Field: A Comprehensive Analysis of Industrial Accidents in Plants and Strategies for Enhanced Workplace Safety</title>
      <link>https://arxiv.org/abs/2403.05539</link>
      <description>arXiv:2403.05539v1 Announce Type: new 
Abstract: The study delves into 425 industrial incidents documented on Kaggle [1], all of which occurred in 12 separate plants in the South American region. By meticulously examining this extensive dataset, we aim to uncover valuable insights into the occurrence of accidents, identify recurring trends, and illuminate underlying causes. The implications of this analysis extend beyond mere statistical observation, offering organizations an opportunity to enhance safety and health management practices. Our findings underscore the importance of addressing specific areas for improvement, empowering organizations to fortify safety measures, mitigate risks, and cultivate a secure working environment. We advocate for strategically applying statistical analysis and data visualization techniques to leverage this wealth of information effectively. This approach facilitates the extraction of meaningful insights and empowers decision-makers to implement targeted improvements, fostering a preventive mindset, and promoting a safety culture within organizations. This research is a crucial resource for organizations committed to transforming data into actionable strategies for accident prevention and creating a safer workplace.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05539v1</guid>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hasanika Samarasinghe, Shadi Heenatigala</dc:creator>
    </item>
    <item>
      <title>Extinction Risks from AI: Invisible to Science?</title>
      <link>https://arxiv.org/abs/2403.05540</link>
      <description>arXiv:2403.05540v1 Announce Type: new 
Abstract: In an effort to inform the discussion surrounding existential risks from AI, we formulate Extinction-level Goodhart's Law as "Virtually any goal specification, pursued to the extreme, will result in the extinction of humanity", and we aim to understand which formal models are suitable for investigating this hypothesis. Note that we remain agnostic as to whether Extinction-level Goodhart's Law holds or not. As our key contribution, we identify a set of conditions that are necessary for a model that aims to be informative for evaluating specific arguments for Extinction-level Goodhart's Law. Since each of the conditions seems to significantly contribute to the complexity of the resulting model, formally evaluating the hypothesis might be exceedingly difficult. This raises the possibility that whether the risk of extinction from artificial intelligence is real or not, the underlying dynamics might be invisible to current scientific methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05540v1</guid>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vojtech Kovarik, Christian van Merwijk, Ida Mattsson</dc:creator>
    </item>
    <item>
      <title>AI in ESG for Financial Institutions: An Industrial Survey</title>
      <link>https://arxiv.org/abs/2403.05541</link>
      <description>arXiv:2403.05541v1 Announce Type: new 
Abstract: The burgeoning integration of Artificial Intelligence (AI) into Environmental, Social, and Governance (ESG) initiatives within the financial sector represents a paradigm shift towards more sus-tainable and equitable financial practices. This paper surveys the industrial landscape to delineate the necessity and impact of AI in bolstering ESG frameworks. With the advent of stringent regulatory requirements and heightened stakeholder awareness, financial institutions (FIs) are increasingly compelled to adopt ESG criteria. AI emerges as a pivotal tool in navigating the complex in-terplay of financial activities and sustainability goals. Our survey categorizes AI applications across three main pillars of ESG, illustrating how AI enhances analytical capabilities, risk assessment, customer engagement, reporting accuracy and more. Further, we delve into the critical con-siderations surrounding the use of data and the development of models, underscoring the importance of data quality, privacy, and model robustness. The paper also addresses the imperative of responsible and sustainable AI, emphasizing the ethical dimensions of AI deployment in ESG-related banking processes. Conclusively, our findings suggest that while AI offers transformative potential for ESG in banking, it also poses significant challenges that necessitate careful consideration. The final part of the paper synthesizes the survey's insights, proposing a forward-looking stance on the adoption of AI in ESG practices. We conclude with recommendations with a reference architecture for future research and development, advocating for a balanced approach that leverages AI's strengths while mitigating its risks within the ESG domain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05541v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>q-fin.CP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jun Xu</dc:creator>
    </item>
    <item>
      <title>Nurses as agents for achieving Environmentally Sustainable Health Systems: A bibliometric analysis</title>
      <link>https://arxiv.org/abs/2403.05543</link>
      <description>arXiv:2403.05543v1 Announce Type: new 
Abstract: Objective: To analyze the current scientific knowledge and research lines focused on environmentally sustainable health systems, including the role of nurses. Background: There seem to be differences between creating interventions focused on environmentally sustainable health systems, including nurses, and the scarcity of research on this topic, framed on the Sustainable Development Goals. Methods: A bibliometric analysis was carried out, via three databases (Web of Science, Scopus, and Pubmed), and the guideline recommendations were followed to select bibliometric data. Results: The search resulted in 159 publications, significantly increasing the trends from 2017 to 2021 (p=0.028). The most relevant countries in this area were the United States of America, the United Kingdom, and Sweden. Also, the top articles were from relevant journals, indexed in Journal Citation Report, and the first and the second quartile linked to the nursing field and citations (p&lt;0.001). Conclusion: Education is key to achieving environmentally sustainable health systems via institutions and policies. Implications for nursing management: There is a lack of experimental data and policies on achieving or maintaining environmentally sustainable health care systems, indicating that nurses have an important role and should be consulted and included in decision-making policies regarding sustainability in the healthcare systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05543v1</guid>
      <category>cs.CY</category>
      <category>cs.DL</category>
      <category>cs.SI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>0.1111/jonm.13798</arxiv:DOI>
      <dc:creator>Olga Maria Luque Alcaraz, Pilar Aparicio-Mart\'inez, Antonio Gomera, Manuel Vaquero-Abell\'an</dc:creator>
    </item>
    <item>
      <title>From Algorithm Worship to the Art of Human Learning: Insights from 50-year journey of AI in Education</title>
      <link>https://arxiv.org/abs/2403.05544</link>
      <description>arXiv:2403.05544v1 Announce Type: new 
Abstract: Current discourse surrounding Artificial Intelligence (AI) oscillates between hope and apprehension, painting a future where AI reshapes every facet of human life, including Education. This paper delves into the complexities of AI's role in Education, addressing the mixed messages that have both enthused and alarmed educators, policymakers, and the public. It explores the promises that AI holds for enhancing learning through personalisation at scale, against the backdrop of concerns about ethical implications, the devaluation of non-STEM subjects, and the potential transformative impact on our neurocognitive and socio-emotional functioning. Drawing on recent research and global discourse, the paper seeks to unpack the reasons behind the vagueness of current discussions on AI in Education (AIED) and the implications of this ambiguity for future educational practices and policies. By highlighting insights from educational research and synthesising evidence-based best practices in AIED, the aim is to provide a clearer understanding of how AI technologies can be aligned with the fundamental principles of learning and teaching, and explore what concrete actions may need to be prioritised now to truly enhance learning experiences and outcomes for all in the future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05544v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kaska Porayska-Pomsta</dc:creator>
    </item>
    <item>
      <title>Unveiling the influence of behavioural, built environment and socio-economic features on the spatial and temporal variability of bus use using explainable machine learning</title>
      <link>https://arxiv.org/abs/2403.05545</link>
      <description>arXiv:2403.05545v1 Announce Type: new 
Abstract: Understanding the variability of people's travel patterns is key to transport planning and policy-making. However, to what extent daily transit use displays geographic and temporal variabilities, and what are the contributing factors have not been fully addressed. Drawing on smart card data in Beijing, China, this study seeks to address these deficits by adopting new indices to capture the spatial and temporal variability of bus use during peak hours and investigate their associations with relevant contextual features. Using explainable machine learning, our findings reveal non-linear interaction between spatial and temporal variability and trip frequency. Furthermore, greater distance to the urban centres (&gt;10 kilometres) is associated with increased spatial variability of bus use, while greater separation of trip origins and destinations from the subcentres reduces both spatial and temporal variability. Higher availability of bus routes is linked to higher spatial variability but lower temporal variability. Meanwhile, both lower and higher road density is associated with higher spatial variability of bus use especially in morning times. These findings indicate that different built environment features moderate the flexibility of travel time and locations. Implications are derived to inform more responsive and reliable operation and planning of transit systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05545v1</guid>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sui Tao, Francisco Rowe, Hongyu Shan</dc:creator>
    </item>
    <item>
      <title>Unified Occupancy on a Public Transport Network through Combination of AFC and APC Data</title>
      <link>https://arxiv.org/abs/2403.05546</link>
      <description>arXiv:2403.05546v1 Announce Type: new 
Abstract: In a transport network, the onboard occupancy is key for gaining insights into travelers' habits and adjusting the offer. Traditionally, operators have relied on field studies to evaluate ridership of a typical workday. However, automated fare collection (AFC) and automatic passenger counting (APC) data, which provide complete temporal coverage, are often available but underexploited. It should be noted, however, that each data source comes with its own biases: AFC data may not account for fraud, while not all vehicles are equipped with APC systems.
  This paper introduces the unified occupancy method, a geostatistical model to extrapolate occupancy to every course of a public transportation network by combining AFC and APC data with partial coverage. Unified occupancy completes missing APC information for courses on lines where other courses have APC measures, as well as for courses on lines where no APC data is available at all. The accuracy of this method is evaluated on real data from several public transportation networks in France.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05546v1</guid>
      <category>cs.CY</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amir Dib, No\"elie Cherrier, Martin Graive, Baptiste R\'erolle, Eglantine Schmitt</dc:creator>
    </item>
    <item>
      <title>AI for non-programmers: Applied AI in the lectures for students without programming skills</title>
      <link>https://arxiv.org/abs/2403.05547</link>
      <description>arXiv:2403.05547v1 Announce Type: new 
Abstract: Applications such as ChatGPT and WOMBO Dream make it easy to inspire students without programming knowledge to use artificial intelligence (AI). Therefore, given the increasing importance of AI in all disciplines, innovative strategies are needed to educate students in AI without programming knowledge so that AI can be integrated into their study modules as a future skill. This work presents a didactic planning script for applied AI. The didactic planning script is based on the AI application pipeline and links AI concepts with study-relevant topics. These linkages open up a new solution space and promote students' interest in and understanding of the potentials and risks of AI. An example lecture series for master students in energy management shows how AI can be seamlessly integrated into discipline-specific lectures. To this end, the planning script for applied AI is adapted to fit the study programs' topic. This specific teaching scenario enables students to solve a discipline-specific task step by step using the AI application pipeline. Thus, the application of the didactic planning script for applied AI shows the practical implementation of the theoretical concepts of AI. In addition, a checklist is presented that can be used to assess whether AI can be used in the discipline-specific lecture. AI as a future skill must be learned by students based on use cases that are relevant to the course of studies. For this reason, AI education should fit seamlessly into various curricula, even if the students do not have a programming background due to their field of study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05547v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Voneinander Lehren lernen (5) (2024)</arxiv:journal_reference>
      <dc:creator>Julius Sch\"oning, Tim Wawer, Kai-Michael Griese</dc:creator>
    </item>
    <item>
      <title>Monitoring the evolution of antisemitic discourse on extremist social media using BERT</title>
      <link>https://arxiv.org/abs/2403.05548</link>
      <description>arXiv:2403.05548v1 Announce Type: new 
Abstract: Racism and intolerance on social media contribute to a toxic online environment which may spill offline to foster hatred, and eventually lead to physical violence. That is the case with online antisemitism, the specific category of hatred considered in this study. Tracking antisemitic themes and their associated terminology over time in online discussions could help monitor the sentiments of their participants and their evolution, and possibly offer avenues for intervention that may prevent the escalation of hatred. Due to the large volume and constant evolution of online traffic, monitoring conversations manually is impractical. Instead, we propose an automated method that extracts antisemitic themes and terminology from extremist social media over time and captures their evolution. Since supervised learning would be too limited for such a task, we created an unsupervised online machine learning approach that uses large language models to assess the contextual similarity of posts. The method clusters similar posts together, dividing, and creating additional clusters over time when sub-themes emerge from existing ones or new themes appear. The antisemitic terminology used within each theme is extracted from the posts in each cluster. Our experiments show that our methodology outperforms existing baselines and demonstrates the kind of themes and sub-themes it discovers within antisemitic discourse along with their associated terminology. We believe that our approach will be useful for monitoring the evolution of all kinds of hatred beyond antisemitism on social platforms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05548v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.IR</category>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Raza Ul Mustafa, Nathalie Japkowicz</dc:creator>
    </item>
    <item>
      <title>A Scheduling Perspective on Modular Educational Systems in Europe</title>
      <link>https://arxiv.org/abs/2403.05549</link>
      <description>arXiv:2403.05549v1 Announce Type: new 
Abstract: In modular educational systems, students are allowed to choose a part of their own curriculum themselves. This is typically done in the final class levels which lead to maturity for university access. The rationale behind letting students choose their courses themselves is to enhance self-responsibility, improve student motivation, and allow a focus on specific areas of interest. A central instrument for bringing these systems to fruition is the timetable. However, scheduling the timetable in such systems can be an extremely challenging and time-consuming task. In this study, we present a framework for classifying modular educational systems in Europe that reflects different degrees of freedom regarding student choices, and explore the consequences from the perspective of scheduling a timetable that satisfies all requirements from the organizational and the pedagogical perspective. For this purpose, we conducted interviews in Austria, Germany, Finland, Switzerland, the Netherlands, and Luxembourg and apply the framework to these educational systems, finding that among them the Finnish system shows the highest degree of modularity. After analyzing the consequences of modularity from the scheduling perspective, we assess the necessity for automated scheduling methods, which are central for realizing the potential and many benefits of modular education in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05549v1</guid>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Rub\'en Ruiz-Torrubiano, Sebastian Knopp, Lukas Matthias Wolf, Andreas Krystallidis</dc:creator>
    </item>
    <item>
      <title>Teranga Go!: Carpooling Collaborative Consumption Community with multi-criteria hesitant fuzzy linguistic term set opinions to build confidence and trust</title>
      <link>https://arxiv.org/abs/2403.05550</link>
      <description>arXiv:2403.05550v1 Announce Type: new 
Abstract: Classic Delphi and Fuzzy Delphi methods are used to test content validity of a data collection tools such as questionnaires. Fuzzy Delphi takes the opinion issued by judges from a linguistic perspective reducing ambiguity in opinions by using fuzzy numbers. We propose an extension named 2-Tuple Fuzzy Linguistic Delphi method to deal with scenarios in which judges show different expertise degrees by using fuzzy multigranular semantics of the linguistic terms and to obtain intermediate and final results expressed by 2-tuple linguistic values. The key idea of our proposal is to validate the full questionnaire by means of the evaluation of its parts, defining the validity of each item as a Decision Making problem. Taking the opinion of experts, we measure the degree of consensus, the degree of consistency, and the linguistic score of each item, in order to detect those items that affect, positively or negatively, the quality of the instrument. Considering the real need to evaluate a b-learning educational experience with a consensual questionnaire, we present a Decision Making model for questionnaire validation that solve it. Additionally, we contribute to this consensus reaching problem by developing an online tool under GPL v3 license. The software visualizes the collective valuations for each iteration and assists to determine which parts of the questionnaire should be modified to reach a consensual solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05550v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.asoc.2017.05.039</arxiv:DOI>
      <arxiv:journal_reference>Applied Soft Computing 67, 2018, Pages 941-952</arxiv:journal_reference>
      <dc:creator>Rosana Montes, Ana M. Sanchez, Pedro Villar, Francisco Herrera</dc:creator>
    </item>
    <item>
      <title>A Bibliometric View of AI Ethics Development</title>
      <link>https://arxiv.org/abs/2403.05551</link>
      <description>arXiv:2403.05551v1 Announce Type: new 
Abstract: Artificial Intelligence (AI) Ethics is a nascent yet critical research field. Recent developments in generative AI and foundational models necessitate a renewed look at the problem of AI Ethics. In this study, we perform a bibliometric analysis of AI Ethics literature for the last 20 years based on keyword search. Our study reveals a three-phase development in AI Ethics, namely an incubation phase, making AI human-like machines phase, and making AI human-centric machines phase. We conjecture that the next phase of AI ethics is likely to focus on making AI more machine-like as AI matches or surpasses humans intellectually, a term we coin as "machine-like human".</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05551v1</guid>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Di Kevin Gao, Andrew Haverly, Sudip Mittal, Jingdao Chen</dc:creator>
    </item>
    <item>
      <title>Multi-source and multimodal data fusion for predicting academic performance in blended learning university courses</title>
      <link>https://arxiv.org/abs/2403.05552</link>
      <description>arXiv:2403.05552v1 Announce Type: new 
Abstract: In this paper we applied data fusion approaches for predicting the final academic performance of university students using multiple-source, multimodal data from blended learning environments. We collected and preprocessed data about first-year university students from different sources: theory classes, practical sessions, on-line Moodle sessions, and a final exam. Our objective was to discover which data fusion approach produced the best results using our data. We carried out experiments by applying four different data fusion approaches and six classification algorithms. The results showed that the best predictions were produced using ensembles and selecting the best attributes approach with discretized data. The best prediction models showed us that the level of attention in theory classes, scores in Moodle quizzes, and the level of activity in Moodle forums were the best set of attributes for predicting students' final performance in our courses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05552v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.compeleceng.2020.106908</arxiv:DOI>
      <arxiv:journal_reference>Chango, W., Cerezo, R., &amp; Romero, C. (2021). Multi-source and multimodal data fusion for predicting academic performance in blended learning university courses. Computers &amp; Electrical Engineering, 89, 106908</arxiv:journal_reference>
      <dc:creator>W. Chango, R. Cerezo, C. Romero</dc:creator>
    </item>
    <item>
      <title>Understanding the Progression of Educational Topics via Semantic Matching</title>
      <link>https://arxiv.org/abs/2403.05553</link>
      <description>arXiv:2403.05553v1 Announce Type: new 
Abstract: Education systems are dynamically changing to accommodate technological advances, industrial and societal needs, and to enhance students' learning journeys. Curriculum specialists and educators constantly revise taught subjects across educational grades to identify gaps, introduce new learning topics, and enhance the learning outcomes. This process is usually done within the same subjects (e.g. math) or across related subjects (e.g. math and physics) considering the same and different educational levels, leading to massive multi-layer comparisons. Having nuanced data about subjects, topics, and learning outcomes structured within a dataset, empowers us to leverage data science to better understand the progression of various learning topics. In this paper, Bidirectional Encoder Representations from Transformers (BERT) topic modeling was used to extract topics from the curriculum, which were then used to identify relationships between subjects, track their progression, and identify conceptual gaps. We found that grouping learning outcomes by common topics helped specialists reduce redundancy and introduce new concepts in the curriculum. We built a dashboard to avail the methodology to curriculum specials. Finally, we tested the validity of the approach with subject matter experts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05553v1</guid>
      <category>cs.CY</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tamador AlkhidirCurriculum Department, Ministry of Education, United Arab Emirates, Edmond AwadDepartment of Economics and Institute for Data Science and AI, University of Exeter, United Kingdom, Aamena AlshamsiHeuristic World, Dubai, United Arab Emirates</dc:creator>
    </item>
    <item>
      <title>Subgroup Discovery in MOOCs: A Big Data Application for Describing Different Types of Learners</title>
      <link>https://arxiv.org/abs/2403.05555</link>
      <description>arXiv:2403.05555v1 Announce Type: new 
Abstract: The aim of this paper is to categorize and describe different types of learners in massive open online courses (MOOCs) by means of a subgroup discovery approach based on MapReduce. The final objective is to discover IF-THEN rules that appear in different MOOCs. The proposed subgroup discovery approach, which is an extension of the well-known FP-Growth algorithm, considers emerging parallel methodologies like MapReduce to be able to cope with extremely large datasets. As an additional feature, the proposal includes a threshold value to denote the number of courses that each discovered rule should satisfy. A post-processing step is also included so redundant subgroups can be removed. The experimental stage is carried out by considering de-identified data from the first year of 16 MITx and HarvardX courses on the edX platform. Experimental results demonstrate that the proposed MapReduce approach outperforms traditional sequential subgroup discovery approaches, achieving a runtime that is almost constant for different courses. Additionally, thanks to the final post-processing step, only interesting and not-redundant rules are discovered, hence reducing the number of subgroups in one or two orders of magnitude. Finally, the discovered subgroups are easily used by courses' instructors not only for descriptive purposes but also for additional tasks such as recommendation or personalization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05555v1</guid>
      <category>cs.CY</category>
      <category>cs.DB</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s10115-022-01674-9</arxiv:DOI>
      <arxiv:journal_reference>Knowledge and Information Systems (2022); 64:1349-1384</arxiv:journal_reference>
      <dc:creator>J. M. Luna, H. M. Fardoun, F. Padillo, C. Romero, S. Ventura</dc:creator>
    </item>
    <item>
      <title>Modeling and predicting students' engagement behaviors using mixture Markov models</title>
      <link>https://arxiv.org/abs/2403.05556</link>
      <description>arXiv:2403.05556v1 Announce Type: new 
Abstract: Students' engagements reflect their level of involvement in an ongoing learning process which can be estimated through their interactions with a computer-based learning or assessment system. A pre-requirement for stimulating student engagement lies in the capability to have an approximate representation model for comprehending students' varied (dis)engagement behaviors. In this paper, we utilized model-based clustering for this purpose which generates K mixture Markov models to group students' traces containing their (dis)engagement behavioral patterns. To prevent the Expectation-Maximization (EM) algorithm from getting stuck in a local maxima, we also introduced a K-means-based initialization method named as K-EM. We performed an experimental work on two real datasets using the three variants of the EM algorithm: the original EM, emEM, K-EM; and, non-mixture baseline models for both datasets. The proposed K-EM has shown very promising results and achieved significant performance difference in comparison with the other approaches particularly using the Dataset. Hence, we suggest to perform further experiments using large dataset(s) to validate our method. Additionally, visualization of the resultant clusters through first-order Markov chains reveals very useful insights about (dis)engagement behaviors depicted by the students. We conclude the paper with a discussion on the usefulness of our approach, limitations and potential extensions of this work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05556v1</guid>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Knowledge and Information System (2022); 64:1349-1384</arxiv:journal_reference>
      <dc:creator>R. Maqsood, P. Ceravolo, C. Romero, S. Ventura</dc:creator>
    </item>
    <item>
      <title>Ethical and Privacy Considerations with Location Based Data Research</title>
      <link>https://arxiv.org/abs/2403.05558</link>
      <description>arXiv:2403.05558v1 Announce Type: new 
Abstract: Networking research, especially focusing on human mobility, has evolved significantly in the last two decades and now relies on collection and analyzing larger datasets. The increasing sizes of datasets are enabled by larger automated efforts to collect data as well as by scalable methods to analyze and unveil insights, which was not possible many years ago. However, this fast expansion and innovation in human-centric research often comes at a cost of privacy or ethics. In this work, we review a vast corpus of scientific work on human mobility and how ethics and privacy were considered. We reviewed a total of 118 papers, including 149 datasets on individual mobility. We demonstrate that these ever growing collections, while enabling new and insightful studies, have not all consistently followed a pre-defined set of guidelines regarding acceptable practices in data governance as well as how their research was communicated. We conclude with a series of discussions on how data, privacy and ethics could be dealt within our community.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05558v1</guid>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Leonardo Tonetto, Pauline Kister, Nitinder Mohan, J\"org Ott</dc:creator>
    </item>
    <item>
      <title>Improving Cognitive Diagnosis Models with Adaptive Relational Graph Neural Networks</title>
      <link>https://arxiv.org/abs/2403.05559</link>
      <description>arXiv:2403.05559v1 Announce Type: new 
Abstract: Cognitive Diagnosis (CD) algorithms receive growing research interest in intelligent education. Typically, these CD algorithms assist students by inferring their abilities (i.e., their proficiency levels on various knowledge concepts). The proficiency levels can enable further targeted skill training and personalized exercise recommendations, thereby promoting students' learning efficiency in online education. Recently, researchers have found that building and incorporating a student-exercise bipartite graph is beneficial for enhancing diagnostic performance. However, there are still limitations in their studies. On one hand, researchers overlook the heterogeneity within edges, where there can be both correct and incorrect answers. On the other hand, they disregard the uncertainty within edges, e.g., a correct answer can indicate true mastery or fortunate guessing. To address the limitations, we propose Adaptive Semantic-aware Graph-based Cognitive Diagnosis model (ASG-CD), which introduces a novel and effective way to leverage bipartite graph information in CD. Specifically, we first map students, exercises, and knowledge concepts into a latent representation space and combine these latent representations to obtain student abilities and exercise difficulties. After that, we propose a Semantic-aware Graph Neural Network Layer to address edge heterogeneity. This layer splits the original bipartite graph into two subgraphs according to edge semantics, and aggregates information based on these two subgraphs separately. To mitigate the impact of edge uncertainties, we propose an Adaptive Edge Differentiation Layer that dynamically differentiates edges, followed by keeping reliable edges and filtering out uncertain edges. Extensive experiments on three real-world datasets have demonstrated the effectiveness of ASG-CD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05559v1</guid>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pengyang Shao, Chen Gao, Lei Chen, Yonghui Yang, Kun Zhang, Meng Wang</dc:creator>
    </item>
    <item>
      <title>Detecting a Proxy for Potential Comorbid ADHD in People Reporting Anxiety Symptoms from Social Media Data</title>
      <link>https://arxiv.org/abs/2403.05561</link>
      <description>arXiv:2403.05561v1 Announce Type: new 
Abstract: We present a novel task that can elucidate the connection between anxiety and ADHD; use Transformers to make progress toward solving a task that is not solvable by keyword-based classifiers; and discuss a method for visualization of our classifier illuminating the connection between anxiety and ADHD presentations.
  Up to approximately 50% of adults with ADHD may also have an anxiety disorder and approximately 30\% of adults with anxiety may also have ADHD. Patients presenting with anxiety may be treated for anxiety without ADHD ever being considered, possibly affecting treatment. We show how data that bears on ADHD that is comorbid with anxiety can be obtained from social media data, and show that Transformers can be used to detect a proxy for possible comorbid ADHD in people with anxiety symptoms.
  We collected data from anxiety and ADHD online forums (subreddits). We identified posters who first started posting in the Anxiety subreddit and later started posting in the ADHD subreddit as well. We use this subset of the posters as a proxy for people who presented with anxiety symptoms and then became aware that they might have ADHD. We fine-tune a Transformer architecture-based classifier to classify people who started posting in the Anxiety subreddit and then started posting in the ADHD subreddit vs. people who posted in the Anxiety subreddit without later posting in the ADHD subreddit. We show that a Transformer architecture is capable of achieving reasonable results (76% correct for RoBERTa vs. under 60% correct for the best keyword-based model, both with 50% base rate).</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05561v1</guid>
      <category>cs.CY</category>
      <category>cs.CL</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Claire S. Lee, Noelle Lim, Michael Guerzhoy</dc:creator>
    </item>
    <item>
      <title>The challenges of massification in higher education in Africa</title>
      <link>https://arxiv.org/abs/2403.05563</link>
      <description>arXiv:2403.05563v1 Announce Type: new 
Abstract: Like many developing countries, Togo faces the challenge of massification in higher education resulting from a large increase in the number of students enrolled in its public universities. Encouraged by the public authorities, with the support of the United Nations and Unesco, the number of students to be trained continues to grow to provide the country with qualified professionals and meet its socioeconomic needs. The number of students in large groups (over 3,000 in some courses) raises issues of training quality and equity (availability of resources, reproducibility of content, study conditions, access to digital solutions, etc.). Access to this type of training requires special training conditions and infrastructures that are not always available in developing countries. This article presents a qualitative study carried out with undergraduate students and teachers at the University of Lom{\'e} concerning teaching and learning conditions in large groups and a critical analysis of the solutions implemented by the university. This work can be transposed to other African countries with similar needs and will open the way to a solution analogous to intelligent classrooms for face-to-face courses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05563v1</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kossi TepeUTT, Yann VerchierUTT, Yetongnon KokouUB</dc:creator>
    </item>
    <item>
      <title>Promoting Fair Vaccination Strategies Through Influence Maximization: A Case Study on COVID-19 Spread</title>
      <link>https://arxiv.org/abs/2403.05564</link>
      <description>arXiv:2403.05564v1 Announce Type: new 
Abstract: The aftermath of the Covid-19 pandemic saw more severe outcomes for racial minority groups and economically-deprived communities. Such disparities can be explained by several factors, including unequal access to healthcare, as well as the inability of low income groups to reduce their mobility due to work or social obligations. Moreover, senior citizens were found to be more susceptible to severe symptoms, largely due to age-related health reasons. Adapting vaccine distribution strategies to consider a range of demographics is therefore essential to address these disparities. In this study, we propose a novel approach that utilizes influence maximization (IM) on mobility networks to develop vaccination strategies which incorporate demographic fairness. By considering factors such as race, social status, age, and associated risk factors, we aim to optimize vaccine distribution to achieve various fairness definitions for one or more protected attributes at a time. Through extensive experiments conducted on Covid-19 spread in three major metropolitan areas across the United States, we demonstrate the effectiveness of our proposed approach in reducing disease transmission and promoting fairness in vaccination distribution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05564v1</guid>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicola Neophytou, Afaf Ta\"ik, Golnoosh Farnadi</dc:creator>
    </item>
    <item>
      <title>Beyond Predictive Algorithms in Child Welfare</title>
      <link>https://arxiv.org/abs/2403.05573</link>
      <description>arXiv:2403.05573v1 Announce Type: new 
Abstract: Caseworkers in the child welfare (CW) sector use predictive decision-making algorithms built on risk assessment (RA) data to guide and support CW decisions. Researchers have highlighted that RAs can contain biased signals which flatten CW case complexities and that the algorithms may benefit from incorporating contextually rich case narratives, i.e. - casenotes written by caseworkers. To investigate this hypothesized improvement, we quantitatively deconstructed two commonly used RAs from a United States CW agency. We trained classifier models to compare the predictive validity of RAs with and without casenote narratives and applied computational text analysis on casenotes to highlight topics uncovered in the casenotes. Our study finds that common risk metrics used to assess families and build CWS predictive risk models (PRMs) are unable to predict discharge outcomes for children who are not reunified with their birth parent(s). We also find that although casenotes cannot predict discharge outcomes, they contain contextual case signals. Given the lack of predictive validity of RA scores and casenotes, we propose moving beyond quantitative risk assessments for public sector algorithms and towards using contextual sources of information such as narratives to study public sociotechnical systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05573v1</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erina Seh-Young Moon, Devansh Saxena, Tegan Maharaj, Shion Guha</dc:creator>
    </item>
    <item>
      <title>Enhancing Health Care Accessibility and Equity Through a Geoprocessing Toolbox for Spatial Accessibility Analysis: Development and Case Study</title>
      <link>https://arxiv.org/abs/2403.05575</link>
      <description>arXiv:2403.05575v1 Announce Type: new 
Abstract: Access to health care services is a critical determinant of population health and well-being. Measuring spatial accessibility to health services is essential for understanding health care distribution and addressing potential inequities. In this study, we developed a geoprocessing toolbox including Python script tools for the ArcGIS Pro environment to measure the spatial accessibility of health services using both classic and enhanced versions of the 2-step floating catchment area method. Each of our tools incorporated both distance buffers and travel time catchments to calculate accessibility scores based on users' choices. Additionally, we developed a separate tool to create travel time catchments that is compatible with both locally available network data sets and ArcGIS Online data sources. We conducted a case study focusing on the accessibility of hemodialysis services in the state of Tennessee using the 4 versions of the accessibility tools. Notably, the calculation of the target population considered age as a significant nonspatial factor influencing hemodialysis service accessibility. Weighted populations were calculated using end-stage renal disease incidence rates in different age groups. The implemented tools are made accessible through ArcGIS Online for free use by the research community. The case study revealed disparities in the accessibility of hemodialysis services, with urban areas demonstrating higher scores compared to rural and suburban regions. These geoprocessing tools can serve as valuable decision-support resources for health care providers, organizations, and policy makers to improve equitable access to health care services. This comprehensive approach to measuring spatial accessibility can empower health care stakeholders to address health care distribution challenges effectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05575v1</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.2196/51727</arxiv:DOI>
      <arxiv:journal_reference>JMIR Form Res JMIR Formative Research. 2024 Feb 21:8:e51727</arxiv:journal_reference>
      <dc:creator>Soheil Hashtarkhani, David L Schwartz, Arash Shaban-Nejad</dc:creator>
    </item>
    <item>
      <title>And Then the Hammer Broke: Reflections on Machine Ethics from Feminist Philosophy of Science</title>
      <link>https://arxiv.org/abs/2403.05805</link>
      <description>arXiv:2403.05805v1 Announce Type: new 
Abstract: Vision is an important metaphor in ethical and political questions of knowledge. The feminist philosopher Donna Haraway points out the ``perverse'' nature of an intrusive, alienating, all-seeing vision (to which we might cry out ``stop looking at me!''), but also encourages us to embrace the embodied nature of sight and its promises for genuinely situated knowledge. Current technologies of machine vision -- surveillance cameras, drones (for war or recreation), iPhone cameras -- are usually construed as instances of the former rather than the latter, and for good reasons. However, although in no way attempting to diminish the real suffering these technologies have brought about in the world, I make the case for understanding technologies of computer vision as material instances of embodied seeing and situated knowing. Furthermore, borrowing from Iris Murdoch's concept of moral vision, I suggest that these technologies direct our labor towards self-reflection in ethically significant ways. My approach draws upon paradigms in computer vision research, phenomenology, and feminist epistemology. Ultimately, this essay is an argument for directing more philosophical attention from merely criticizing technologies of vision as ethically deficient towards embracing them as complex, methodologically and epistemologically important objects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05805v1</guid>
      <category>cs.CY</category>
      <category>cs.CV</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andre Ye</dc:creator>
    </item>
    <item>
      <title>Sistemas de informaci\'on de salud en contextos extremos: Uso de tel\'efonos m\'oviles para combatir el sida en Uganda</title>
      <link>https://arxiv.org/abs/2403.06076</link>
      <description>arXiv:2403.06076v1 Announce Type: new 
Abstract: The HIV/AIDS pandemic is a global issue that has unequally affected several countries. Due to the complexity of this condition and the human drama it represents to those most affected by it, several fields have contributed to solving or at least alleviating this situation, and the information systems (IS) field has not been absent from these efforts. With the importance of antiretroviral therapy (ART) as a starting point, several initiatives in the IS field have focused on ways to improve the adherence and effectiveness of this therapy: mobile phone reminders (for pill intake and appointments), and mobile interfaces between patients and health workers are popular contributions. However, many of these solutions have been difficult to implement or deploy in some countries in the Global South, which are among the most affected by this pandemic. This paper presents one such case. Using a case-study approach with an extreme-case selection technique, the paper studies an m-health system for HIV patients in the Kalangala region of Uganda. Using Heeks' design-reality gap model for data analysis, the paper shows that the rich interaction between social context and technology should be considered a central concern when designing or deploying such systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06076v1</guid>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1002/isd2.12314</arxiv:DOI>
      <arxiv:journal_reference>The Electronic Journal of Information Systems in Developing Countries, e12314</arxiv:journal_reference>
      <dc:creator>Livingstone NjubaKalangala Infrastructure Services Ltd, University of Manchester, Juan E. G\'omez-MorantesPontificia Universidad Javeriana, Andrea HerreraUniversidad de los Andes, Sonia CamachoUniversidad de los Andes</dc:creator>
    </item>
    <item>
      <title>Simulating Family Conversations using LLMs: Demonstration of Parenting Styles</title>
      <link>https://arxiv.org/abs/2403.06144</link>
      <description>arXiv:2403.06144v1 Announce Type: new 
Abstract: This study presents a framework for conducting psychological and linguistic research through simulated conversations using large language models (LLMs). The proposed methodology offers significant advantages, particularly for simulating human interactions involving potential unethical language or behaviors that would be impermissible in traditional experiments with human participants. As a demonstration, we employed LLMs to simulate family conversations across four parenting styles (authoritarian, authoritative, permissive, and uninvolved). In general, we observed that the characteristics of the four parenting styles were portrayed in the simulated conversations. Several strategies could be used to improve the simulation quality, such as including context awareness, employing a few-shot prompting approach or fine-tuning models to cater to specific simulation requirements. Overall, this study introduces a promising methodology for conducting psychological and linguistic research through simulated conversations, while acknowledging the current limitations and proposing potential solutions for future refinement and improvement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06144v1</guid>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Frank Tian-fang YeDepartment of Applied Social Sciences, The Hong Kong Polytechnic University, Hong Kong SAR, Xiaozi GaoDepartment of Early Childhood Education, The Education University of Hong Kong, Hong Kong SAR</dc:creator>
    </item>
    <item>
      <title>Design and Development of a Multi-Purpose Collaborative Remote Laboratory Platform</title>
      <link>https://arxiv.org/abs/2403.06207</link>
      <description>arXiv:2403.06207v1 Announce Type: new 
Abstract: This work-in-progress paper presents the current development of a new collaborative remote laboratory platform. The results are intended to serve as a foundation for future research on collaborative work in remote laboratories. Our platform, standing out with its adaptive and collaborative capabilities, integrates a distributed web-application for streamlined management and engagement in diverse remote educational environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06207v1</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sven Jacobs, Timo Hardebusch, Esther Franke, Henning Peters, Rashed Al Amin, Veit Wiese, Steffen Jaschke</dc:creator>
    </item>
    <item>
      <title>Exploiting the Margin: How Capitalism Fuels AI at the Expense of Minoritized Groups</title>
      <link>https://arxiv.org/abs/2403.06332</link>
      <description>arXiv:2403.06332v1 Announce Type: new 
Abstract: This article investigates the complex nexus of capitalism, racial oppression, and artificial intelligence (AI), revealing how these elements coalesce to deepen social inequities. By tracing the historical exploitation of marginalized communities through capitalist practices, the study demonstrates how AI technologies not only reflect but also amplify societal biases, particularly in exacerbating racial disparities. Through a focused analysis, the paper presents how AI's development and application exploit marginalized groups via mechanisms such as gig economy labor abuses, biased facial recognition technologies, and the disproportionate mental health burdens placed on these communities. These examples underscore the critical role of AI in reinforcing and intensifying existing inequalities. Concluding that unregulated AI significantly threatens to compound current oppressions, the article calls for a concerted effort towards responsible AI development. This entails adopting a holistic approach that rectifies systemic flaws and champions the empowerment of marginalized individuals, ensuring that technological advancement contributes to societal healing rather than perpetuating cycles of exploitation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06332v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nelson Col\'on Vargas</dc:creator>
    </item>
    <item>
      <title>Authorship and the Politics and Ethics of LLM Watermarks</title>
      <link>https://arxiv.org/abs/2403.06593</link>
      <description>arXiv:2403.06593v1 Announce Type: new 
Abstract: Recently, watermarking schemes for large language models (LLMs) have been proposed to distinguish text generated by machines and by humans. The present paper explores philosophical, political, and ethical ramifications of implementing and using watermarking schemes. A definition of authorship that includes both machines (LLMs) and humans is proposed to serve as a backdrop. It is argued that private watermarks may provide private companies with sweeping rights to determine authorship, which is incompatible with traditional standards of authorship determination. Then, possible ramifications of the so-called entropy dependence of watermarking mechanisms are explored. It is argued that entropy may vary for different, socially salient groups. This could lead to group dependent rates at which machine generated text is detected. Specifically, groups more interested in low entropy text may face the challenge that it is harder to detect machine generated text that is of interest to them.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06593v1</guid>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tim R\"az</dc:creator>
    </item>
    <item>
      <title>Improving Low-Resource Knowledge Tracing Tasks by Supervised Pre-training and Importance Mechanism Fine-tuning</title>
      <link>https://arxiv.org/abs/2403.06725</link>
      <description>arXiv:2403.06725v1 Announce Type: new 
Abstract: Knowledge tracing (KT) aims to estimate student's knowledge mastery based on their historical interactions. Recently, the deep learning based KT (DLKT) approaches have achieved impressive performance in the KT task. These DLKT models heavily rely on the large number of available student interactions. However, due to various reasons such as budget constraints and privacy concerns, observed interactions are very limited in many real-world scenarios, a.k.a, low-resource KT datasets. Directly training a DLKT model on a low-resource KT dataset may lead to overfitting and it is difficult to choose the appropriate deep neural architecture. Therefore, in this paper, we propose a low-resource KT framework called LoReKT to address above challenges. Inspired by the prevalent "pre-training and fine-tuning" paradigm, we aim to learn transferable parameters and representations from rich-resource KT datasets during the pre-training stage and subsequently facilitate effective adaptation to low-resource KT datasets. Specifically, we simplify existing sophisticated DLKT model architectures with purely a stack of transformer decoders. We design an encoding mechanism to incorporate student interactions from multiple KT data sources and develop an importance mechanism to prioritize updating parameters with high importance while constraining less important ones during the fine-tuning stage. We evaluate LoReKT on six public KT datasets and experimental results demonstrate the superiority of our approach in terms of AUC and Accuracy. To encourage reproducible research, we make our data and code publicly available at https://anonymous.4open.science/r/LoReKT-C619.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06725v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hengyuan Zhang, Zitao Liu, Shuyan Huang, Chenming Shang, Bojun Zhan, Yong Jiang</dc:creator>
    </item>
    <item>
      <title>On the Preservation of Africa's Cultural Heritage in the Age of Artificial Intelligence</title>
      <link>https://arxiv.org/abs/2403.06865</link>
      <description>arXiv:2403.06865v1 Announce Type: new 
Abstract: In this paper we delve into the historical evolution of data as a fundamental element in communication and knowledge transmission. The paper traces the stages of knowledge dissemination from oral traditions to the digital era, highlighting the significance of languages and cultural diversity in this progression. It also explores the impact of digital technologies on memory, communication, and cultural preservation, emphasizing the need for promoting a culture of the digital (rather than a digital culture) in Africa and beyond. Additionally, it discusses the challenges and opportunities presented by data biases in AI development, underscoring the importance of creating diverse datasets for equitable representation. We advocate for investing in data as a crucial raw material for fostering digital literacy, economic development, and, above all, cultural preservation in the digital age.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06865v1</guid>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohamed El Louadi</dc:creator>
    </item>
    <item>
      <title>SDXL Finetuned with LoRA for Coloring Therapy: Generating Graphic Templates Inspired by United Arab Emirates Culture</title>
      <link>https://arxiv.org/abs/2403.05562</link>
      <description>arXiv:2403.05562v1 Announce Type: cross 
Abstract: A transformative approach to mental health therapy lies at the crossroads of cultural heritage and advanced technology. This paper introduces an innovative method that fuses machine learning techniques with traditional Emirati motifs, focusing on the United Arab Emirates (UAE). We utilize the Stable Diffusion XL (SDXL) model, enhanced with Low-Rank Adaptation (LoRA), to create culturally significant coloring templates featuring Al-Sadu weaving patterns. This novel approach leverages coloring therapy for its recognized stress-relieving benefits and embeds deep cultural resonance, making it a potent tool for therapeutic intervention and cultural preservation. Specifically targeting Generalized Anxiety Disorder (GAD), our method demonstrates significant potential in reducing associated symptoms. Additionally, the paper delves into the broader implications of color and music therapy, emphasizing the importance of culturally tailored content. The technical aspects of the SDXL model and its LoRA fine-tuning showcase its capability to generate high-quality, culturally specific images. This research stands at the forefront of integrating mental wellness practices with cultural heritage, providing a groundbreaking perspective on the synergy between technology, culture, and healthcare. In future work, we aim to employ biosignals to assess the level of engagement and effectiveness of color therapy. A key focus will be to examine the impact of the Emirati heritage Al Sadu art on Emirati individuals and compare their responses with those of other nationalities. This will provide deeper insights into the cultural specificity of therapeutic interventions and further the understanding of the unique interplay between cultural identity and mental health therapy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05562v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abdulla Alfalasi, Esrat Khan, Mohamed Alhashmi, Raed Aldweik, Davor Svetinovic</dc:creator>
    </item>
    <item>
      <title>Cultural Bias in Explainable AI Research: A Systematic Analysis</title>
      <link>https://arxiv.org/abs/2403.05579</link>
      <description>arXiv:2403.05579v1 Announce Type: cross 
Abstract: For synergistic interactions between humans and artificial intelligence (AI) systems, AI outputs often need to be explainable to people. Explainable AI (XAI) systems are commonly tested in human user studies. However, whether XAI researchers consider potential cultural differences in human explanatory needs remains unexplored. We highlight psychological research that found significant differences in human explanations between many people from Western, commonly individualist countries and people from non-Western, often collectivist countries. We argue that XAI research currently overlooks these variations and that many popular XAI designs implicitly and problematically assume that Western explanatory needs are shared cross-culturally. Additionally, we systematically reviewed over 200 XAI user studies and found that most studies did not consider relevant cultural variations, sampled only Western populations, but drew conclusions about human-XAI interactions more generally. We also analyzed over 30 literature reviews of XAI studies. Most reviews did not mention cultural differences in explanatory needs or flag overly broad cross-cultural extrapolations of XAI user study results. Combined, our analyses provide evidence of a cultural bias toward Western populations in XAI research, highlighting an important knowledge gap regarding how culturally diverse users may respond to widely used XAI systems that future work can and should address.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05579v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Uwe Peters, Mary Carman</dc:creator>
    </item>
    <item>
      <title>Internet Sanctions on Russian Media: Actions and Effects</title>
      <link>https://arxiv.org/abs/2403.05638</link>
      <description>arXiv:2403.05638v1 Announce Type: cross 
Abstract: As a response to the Russian aggression against Ukraine, the European Union (EU), through the notion of "digital sovereignty", imposed sanctions on organizations and individuals affiliated with the Russian Federation that prohibit broadcasting content, including online distribution. In this paper, we interrogate the implementation of these sanctions and interpret them as a means to translate the union of states' governmental edicts into effective technical countermeasures. Through longitudinal traffic analysis, we construct an understanding of how ISPs in different EU countries attempted to enforce these sanctions, and compare these implementations to similar measures in other western countries. We find a wide variation of blocking coverage, both internationally and within individual member states. We draw the conclusion that digital sovereignty through sanctions in the EU has a concrete but distinctly limited impact on information flows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05638v1</guid>
      <category>cs.NI</category>
      <category>cs.CR</category>
      <category>cs.CY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>John Kristoff, Moritz M\"uller, Arturo Filast\`o, Max Resing, Chris Kanich, Niels ten Oever</dc:creator>
    </item>
    <item>
      <title>Engineering Formality and Software Risk in Debian Python Packages</title>
      <link>https://arxiv.org/abs/2403.05728</link>
      <description>arXiv:2403.05728v1 Announce Type: cross 
Abstract: While free/libre and open source software (FLOSS) is critical to global computing infrastructure, the maintenance of widely-adopted FLOSS packages is dependent on volunteer developers who select their own tasks. Risk of failure due to the misalignment of engineering supply and demand -- known as underproduction -- has led to code base decay and subsequent cybersecurity incidents such as the Heartbleed and Log4Shell vulnerabilities. FLOSS projects are self-organizing but can often expand into larger, more formal efforts. Although some prior work suggests that becoming a more formal organization decreases project risk, other work suggests that formalization may increase the likelihood of project abandonment. We evaluate the relationship between underproduction and formality, focusing on formal structure, developer responsibility, and work process management. We analyze 182 packages written in Python and made available via the Debian GNU/Linux distribution. We find that although more formal structures are associated with higher risk of underproduction, more elevated developer responsibility is associated with less underproduction, and the relationship between formal work process management and underproduction is not statistically significant. Our analysis suggests that a FLOSS organization's transformation into a more formal structure may face unintended consequences which must be carefully managed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05728v1</guid>
      <category>cs.SE</category>
      <category>cs.CY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Matthew Gaughan, Kaylea Champion, Sohyeon Hwang</dc:creator>
    </item>
    <item>
      <title>Extending Activation Steering to Broad Skills and Multiple Behaviours</title>
      <link>https://arxiv.org/abs/2403.05767</link>
      <description>arXiv:2403.05767v1 Announce Type: cross 
Abstract: Current large language models have dangerous capabilities, which are likely to become more problematic in the future. Activation steering techniques can be used to reduce risks from these capabilities. In this paper, we investigate the efficacy of activation steering for broad skills and multiple behaviours. First, by comparing the effects of reducing performance on general coding ability and Python-specific ability, we find that steering broader skills is competitive to steering narrower skills. Second, we steer models to become more or less myopic and wealth-seeking, among other behaviours. In our experiments, combining steering vectors for multiple different behaviours into one steering vector is largely unsuccessful. On the other hand, injecting individual steering vectors at different places in a model simultaneously is promising.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05767v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Teun van der Weij, Massimo Poesio, Nandi Schoots</dc:creator>
    </item>
    <item>
      <title>The rise and fall of WallStreetBets: social roles and opinion leaders across the GameStop saga</title>
      <link>https://arxiv.org/abs/2403.05876</link>
      <description>arXiv:2403.05876v1 Announce Type: cross 
Abstract: Nowadays human interactions largely take place on social networks, with online users' behavior often falling into a few general typologies or "social roles". Among these, opinion leaders are of crucial importance as they have the ability to spread an idea or opinion on a large scale across the network, with possible tangible consequences in the real world. In this work we extract and characterize the different social roles of users within the Reddit WallStreetBets community, around the time of the GameStop short squeeze of January 2021 -- when a handful of committed users led the whole community to engage in a large and risky financial operation. We identify the profiles of both average users and of relevant outliers, including opinion leaders, using an iterative, semi-supervised classification algorithm, which allows us to discern the characteristics needed to play a particular social role. The key features of opinion leaders are large risky investments and constant updates on a single stock, which allowed them to attract a large following and, in the case of GameStop, ignite the interest of the community. Finally, we observe a substantial change in the behavior and attitude of users after the short squeeze event: no new opinion leaders are found and the community becomes less focused on investments. Overall, this work sheds light on the users' roles and dynamics that led to the GameStop short squeeze, while also suggesting why WallStreetBets no longer wielded such large influence on financial markets, in the aftermath of this event.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05876v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.CY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Anna Mancini, Antonio Desiderio, Giovanni Palermo, Riccardo Di Clemente, Giulio Cimini</dc:creator>
    </item>
    <item>
      <title>Addressing Shortcomings in Fair Graph Learning Datasets: Towards a New Benchmark</title>
      <link>https://arxiv.org/abs/2403.06017</link>
      <description>arXiv:2403.06017v1 Announce Type: cross 
Abstract: Fair graph learning plays a pivotal role in numerous practical applications. Recently, many fair graph learning methods have been proposed; however, their evaluation often relies on poorly constructed semi-synthetic datasets or substandard real-world datasets. In such cases, even a basic Multilayer Perceptron (MLP) can outperform Graph Neural Networks (GNNs) in both utility and fairness. In this work, we illustrate that many datasets fail to provide meaningful information in the edges, which may challenge the necessity of using graph structures in these problems. To address these issues, we develop and introduce a collection of synthetic, semi-synthetic, and real-world datasets that fulfill a broad spectrum of requirements. These datasets are thoughtfully designed to include relevant graph structures and bias information crucial for the fair evaluation of models. The proposed synthetic and semi-synthetic datasets offer the flexibility to create data with controllable bias parameters, thereby enabling the generation of desired datasets with user-defined bias values with ease. Moreover, we conduct systematic evaluations of these proposed datasets and establish a unified evaluation approach for fair graph learning models. Our extensive experimental results with fair graph learning methods across our datasets demonstrate their effectiveness in benchmarking the performance of these methods. Our datasets and the code for reproducing our experiments are available at https://github.com/XweiQ/Benchmark-GraphFairness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06017v1</guid>
      <category>cs.LG</category>
      <category>cs.CY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaowei Qian, Zhimeng Guo, Jialiang Li, Haitao Mao, Bingheng Li, Suhang Wang, Yao Ma</dc:creator>
    </item>
    <item>
      <title>FairTargetSim: An Interactive Simulator for Understanding and Explaining the Fairness Effects of Target Variable Definition</title>
      <link>https://arxiv.org/abs/2403.06031</link>
      <description>arXiv:2403.06031v1 Announce Type: cross 
Abstract: Machine learning requires defining one's target variable for predictions or decisions, a process that can have profound implications on fairness: biases are often encoded in target variable definition itself, before any data collection or training. We present an interactive simulator, FairTargetSim (FTS), that illustrates how target variable definition impacts fairness. FTS is a valuable tool for algorithm developers, researchers, and non-technical stakeholders. FTS uses a case study of algorithmic hiring, using real-world data and user-defined target variables. FTS is open-source and available at: http://tinyurl.com/ftsinterface. The video accompanying this paper is here: http://tinyurl.com/ijcaifts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06031v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dalia Gala, Milo Phillips-Brown, Naman Goel, Carinal Prunkl, Laura Alvarez Jubete, medb corcoran, Ray Eitel-Porter</dc:creator>
    </item>
    <item>
      <title>Predicting Depression and Anxiety: A Multi-Layer Perceptron for Analyzing the Mental Health Impact of COVID-19</title>
      <link>https://arxiv.org/abs/2403.06033</link>
      <description>arXiv:2403.06033v1 Announce Type: cross 
Abstract: We introduce a multi-layer perceptron (MLP) called the COVID-19 Depression and Anxiety Predictor (CoDAP) to predict mental health trends, particularly anxiety and depression, during the COVID-19 pandemic. Our method utilizes a comprehensive dataset, which tracked mental health symptoms weekly over ten weeks during the initial COVID-19 wave (April to June 2020) in a diverse cohort of U.S. adults. This period, characterized by a surge in mental health symptoms and conditions, offers a critical context for our analysis. Our focus was to extract and analyze patterns of anxiety and depression through a unique lens of qualitative individual attributes using CoDAP. This model not only predicts patterns of anxiety and depression during the pandemic but also unveils key insights into the interplay of demographic factors, behavioral changes, and social determinants of mental health. These findings contribute to a more nuanced understanding of the complexity of mental health issues in times of global health crises, potentially guiding future early interventions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06033v1</guid>
      <category>cs.LG</category>
      <category>cs.CY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David Fong, Tianshu Chu, Matthew Heflin, Xiaosi Gu, Oshani Seneviratne</dc:creator>
    </item>
    <item>
      <title>Content Moderation Justice and Fairness on Social Media: Comparisons Across Different Contexts and Platforms</title>
      <link>https://arxiv.org/abs/2403.06034</link>
      <description>arXiv:2403.06034v1 Announce Type: cross 
Abstract: Social media users may perceive moderation decisions by the platform differently, which can lead to frustration and dropout. This study investigates users' perceived justice and fairness of online moderation decisions when they are exposed to various illegal versus legal scenarios, retributive versus restorative moderation strategies, and user-moderated versus commercially moderated platforms. We conduct an online experiment on 200 American social media users of Reddit and Twitter. Results show that retributive moderation delivers higher justice and fairness for commercially moderated than for user-moderated platforms in illegal violations; restorative moderation delivers higher fairness for legal violations than illegal ones. We discuss the opportunities for platform policymaking to improve moderation system design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06034v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3613905.3650882</arxiv:DOI>
      <dc:creator>Jie Cai, Aashka Patel, Azadeh Naderi, Donghee Yvette Wohn</dc:creator>
    </item>
    <item>
      <title>Explaining Code with a Purpose: An Integrated Approach for Developing Code Comprehension and Prompting Skills</title>
      <link>https://arxiv.org/abs/2403.06050</link>
      <description>arXiv:2403.06050v1 Announce Type: cross 
Abstract: Reading, understanding and explaining code have traditionally been important skills for novices learning programming. As large language models (LLMs) become prevalent, these foundational skills are more important than ever given the increasing need to understand and evaluate model-generated code. Brand new skills are also needed, such as the ability to formulate clear prompts that can elicit intended code from an LLM. Thus, there is great interest in integrating pedagogical approaches for the development of both traditional coding competencies and the novel skills required to interact with LLMs. One effective way to develop and assess code comprehension ability is with ``Explain in plain English'' (EiPE) questions, where students succinctly explain the purpose of a fragment of code. However, grading EiPE questions has always been difficult given the subjective nature of evaluating written explanations and this has stifled their uptake. In this paper, we explore a natural synergy between EiPE questions and code-generating LLMs to overcome this limitation. We propose using an LLM to generate code based on students' responses to EiPE questions -- not only enabling EiPE responses to be assessed automatically, but helping students develop essential code comprehension and prompt crafting skills in parallel. We investigate this idea in an introductory programming course and report student success in creating effective prompts for solving EiPE questions. We also examine student perceptions of this activity and how it influences their views on the use of LLMs for aiding and assessing learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06050v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <category>cs.SE</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paul Denny, David H. Smith IV, Max Fowler, James Prather, Brett A. Becker, Juho Leinonen</dc:creator>
    </item>
    <item>
      <title>Dynamics of Polarization Under Normative Institutions and Opinion Expression Stewarding</title>
      <link>https://arxiv.org/abs/2403.06264</link>
      <description>arXiv:2403.06264v1 Announce Type: cross 
Abstract: Although there is mounting empirical evidence for the increase in affective polarization, few mechanistic models can explain its emergence at the population level. The question of how such a phenomenon can emerge from divergent opinions of a population on an ideological issue is still an open issue. In this paper, we establish that human normativity, that is, individual expression of normative opinions based on beliefs about the population, can lead to population-level polarization when ideological institutions distort beliefs in accordance with their objective of moving expressed opinion to one extreme. Using a game-theoretic model, we establish that individuals with more extreme opinions will have more extreme rhetoric and higher misperceptions about their outgroup members. Our model also shows that when social recommendation systems mediate institutional signals, we can observe the formation of different institutional communities, each with its unique community structure and characteristics. Using the model, we identify practical strategies platforms can implement, such as reducing exposure to signals from ideological institutions and a tailored approach to content moderation, both of which can rectify the affective polarization problem within its purview.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06264v1</guid>
      <category>cs.MA</category>
      <category>cs.CY</category>
      <category>physics.soc-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Atrisha Sarkar, Gillian K. Hadfield</dc:creator>
    </item>
    <item>
      <title>From Fitting Participation to Forging Relationships: The Art of Participatory ML</title>
      <link>https://arxiv.org/abs/2403.06431</link>
      <description>arXiv:2403.06431v1 Announce Type: cross 
Abstract: Participatory machine learning (ML) encourages the inclusion of end users and people affected by ML systems in design and development processes. We interviewed 18 participation brokers -- individuals who facilitate such inclusion and transform the products of participants' labour into inputs for an ML artefact or system -- across a range of organisational settings and project locations. Our findings demonstrate the inherent challenges of integrating messy contextual information generated through participation with the structured data formats required by ML workflows and the uneven power dynamics in project contexts. We advocate for evolution in the role of brokers to more equitably balance value generated in Participatory ML projects for design and development teams with value created for participants. To move beyond `fitting' participation to existing processes and empower participants to envision alternative futures through ML, brokers must become educators and advocates for end users, while attending to frustration and dissent from indirect stakeholders.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06431v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ned Cooper, Alex Zafiroglu</dc:creator>
    </item>
    <item>
      <title>Academically intelligent LLMs are not necessarily socially intelligent</title>
      <link>https://arxiv.org/abs/2403.06591</link>
      <description>arXiv:2403.06591v1 Announce Type: cross 
Abstract: The academic intelligence of large language models (LLMs) has made remarkable progress in recent times, but their social intelligence performance remains unclear. Inspired by established human social intelligence frameworks, particularly Daniel Goleman's social intelligence theory, we have developed a standardized social intelligence test based on real-world social scenarios to comprehensively assess the social intelligence of LLMs, termed as the Situational Evaluation of Social Intelligence (SESI). We conducted an extensive evaluation with 13 recent popular and state-of-art LLM agents on SESI. The results indicate the social intelligence of LLMs still has significant room for improvement, with superficially friendliness as a primary reason for errors. Moreover, there exists a relatively low correlation between the social intelligence and academic intelligence exhibited by LLMs, suggesting that social intelligence is distinct from academic intelligence for LLMs. Additionally, while it is observed that LLMs can't ``understand'' what social intelligence is, their social intelligence, similar to that of humans, is influenced by social factors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06591v1</guid>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ruoxi Xu, Hongyu Lin, Xianpei Han, Le Sun, Yingfei Sun</dc:creator>
    </item>
    <item>
      <title>Restoring Ancient Ideograph: A Multimodal Multitask Neural Network Approach</title>
      <link>https://arxiv.org/abs/2403.06682</link>
      <description>arXiv:2403.06682v1 Announce Type: cross 
Abstract: Cultural heritage serves as the enduring record of human thought and history. Despite significant efforts dedicated to the preservation of cultural relics, many ancient artefacts have been ravaged irreversibly by natural deterioration and human actions. Deep learning technology has emerged as a valuable tool for restoring various kinds of cultural heritages, including ancient text restoration. Previous research has approached ancient text restoration from either visual or textual perspectives, often overlooking the potential of synergizing multimodal information. This paper proposes a novel Multimodal Multitask Restoring Model (MMRM) to restore ancient texts, particularly emphasising the ideograph. This model combines context understanding with residual visual information from damaged ancient artefacts, enabling it to predict damaged characters and generate restored images simultaneously. We tested the MMRM model through experiments conducted on both simulated datasets and authentic ancient inscriptions. The results show that the proposed method gives insightful restoration suggestions in both simulation experiments and real-world scenarios. To the best of our knowledge, this work represents the pioneering application of multimodal deep learning in ancient text restoration, which will contribute to the understanding of ancient society and culture in digital humanities fields.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06682v1</guid>
      <category>cs.CL</category>
      <category>cs.CV</category>
      <category>cs.CY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Siyu Duan, Jun Wang, Qi Su</dc:creator>
    </item>
    <item>
      <title>Defaults: a double-edged sword in governing common resources</title>
      <link>https://arxiv.org/abs/2403.06796</link>
      <description>arXiv:2403.06796v1 Announce Type: cross 
Abstract: Extracting from shared resources requires making choices to balance personal profit and sustainability. We present the results of a behavioural experiment wherein we manipulate the default extraction from a finite resource. Participants were exposed to two treatments -- pro-social or self-serving extraction defaults -- and a control without defaults. We examined the persistence of these nudges by removing the default after five rounds. Results reveal that a self-serving default increased the average extraction while present, whereas a pro-social default only decreased extraction for the first two rounds. Notably, the influence of defaults depended on individual inclinations, with cooperative individuals extracting more under a self-serving default, and selfish individuals less under a pro-social default. After the removal of the default, we observed no significant differences with the control treatment. Our research highlights the potential of defaults as cost-effective tools for promoting sustainability, while also advocating for a careful use to avoid adverse effects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06796v1</guid>
      <category>cs.GT</category>
      <category>cs.CY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eladio Montero-Porras, R\'emi Suchon, Tom Lenaerts, Elias Fern\'andez Domingos</dc:creator>
    </item>
    <item>
      <title>Monotone Individual Fairness</title>
      <link>https://arxiv.org/abs/2403.06812</link>
      <description>arXiv:2403.06812v1 Announce Type: cross 
Abstract: We revisit the problem of online learning with individual fairness, where an online learner strives to maximize predictive accuracy while ensuring that similar individuals are treated similarly. We first extend the frameworks of Gillen et al. (2018); Bechavod et al. (2020), which rely on feedback from human auditors regarding fairness violations, as we consider auditing schemes that are capable of aggregating feedback from any number of auditors, using a rich class we term monotone aggregation functions. We then prove a characterization for such auditing schemes, practically reducing the analysis of auditing for individual fairness by multiple auditors to that of auditing by (instance-specific) single auditors. Using our generalized framework, we present an oracle-efficient algorithm achieving an upper bound frontier of $(\mathcal{O}(T^{1/2+2b}),\mathcal{O}(T^{3/4-b}))$ respectively for regret, number of fairness violations, for $0\leq b \leq 1/4$. We then study an online classification setting where label feedback is available for positively-predicted individuals only, and present an oracle-efficient algorithm achieving an upper bound frontier of $(\mathcal{O}(T^{2/3+2b}),\mathcal{O}(T^{5/6-b}))$ for regret, number of fairness violations, for $0\leq b \leq 1/6$. In both settings, our algorithms improve on the best known bounds for oracle-efficient algorithms. Furthermore, our algorithms offer significant improvements in computational efficiency, greatly reducing the number of required calls to an (offline) optimization oracle per round, to $\tilde{\mathcal{O}}(\alpha^{-2})$ in the full information setting, and $\tilde{\mathcal{O}}(\alpha^{-2} + k^2T^{1/3})$ in the partial information setting, where $\alpha$ is the sensitivity for reporting fairness violations, and $k$ is the number of individuals in a round.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06812v1</guid>
      <category>cs.LG</category>
      <category>cs.CY</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yahav Bechavod</dc:creator>
    </item>
    <item>
      <title>Transparent AI Disclosure Obligations: Who, What, When, Where, Why, How</title>
      <link>https://arxiv.org/abs/2403.06823</link>
      <description>arXiv:2403.06823v1 Announce Type: cross 
Abstract: Advances in Generative Artificial Intelligence (AI) are resulting in AI-generated media output that is (nearly) indistinguishable from human-created content. This can drastically impact users and the media sector, especially given global risks of misinformation. While the currently discussed European AI Act aims at addressing these risks through Article 52's AI transparency obligations, its interpretation and implications remain unclear. In this early work, we adopt a participatory AI approach to derive key questions based on Article 52's disclosure obligations. We ran two workshops with researchers, designers, and engineers across disciplines (N=16), where participants deconstructed Article 52's relevant clauses using the 5W1H framework. We contribute a set of 149 questions clustered into five themes and 18 sub-themes. We believe these can not only help inform future legal developments and interpretations of Article 52, but also provide a starting point for Human-Computer Interaction research to (re-)examine disclosure transparency from a human-centered AI lens.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06823v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3613905.3650750</arxiv:DOI>
      <dc:creator>Abdallah El Ali, Karthikeya Puttur Venkatraj, Sophie Morosoli, Laurens Naudts, Natali Helberger, Pablo Cesar</dc:creator>
    </item>
    <item>
      <title>Responsible Artificial Intelligence: A Structured Literature Review</title>
      <link>https://arxiv.org/abs/2403.06910</link>
      <description>arXiv:2403.06910v1 Announce Type: cross 
Abstract: Our research endeavors to advance the concept of responsible artificial intelligence (AI), a topic of increasing importance within EU policy discussions. The EU has recently issued several publications emphasizing the necessity of trust in AI, underscoring the dual nature of AI as both a beneficial tool and a potential weapon. This dichotomy highlights the urgent need for international regulation. Concurrently, there is a need for frameworks that guide companies in AI development, ensuring compliance with such regulations. Our research aims to assist lawmakers and machine learning practitioners in navigating the evolving landscape of AI regulation, identifying focal areas for future attention. This paper introduces a comprehensive and, to our knowledge, the first unified definition of responsible AI. Through a structured literature review, we elucidate the current understanding of responsible AI. Drawing from this analysis, we propose an approach for developing a future framework centered around this concept. Our findings advocate for a human-centric approach to Responsible AI. This approach encompasses the implementation of AI methods with a strong emphasis on ethics, model explainability, and the pillars of privacy, security, and trust.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06910v1</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sabrina Goellner, Marina Tropmann-Frick, Bostjan Brumen</dc:creator>
    </item>
    <item>
      <title>Unraveling the Geography of Infection Spread: Harnessing Super-Agents for Predictive Modeling</title>
      <link>https://arxiv.org/abs/2309.07055</link>
      <description>arXiv:2309.07055v5 Announce Type: replace 
Abstract: Our study presents an intermediate-level modeling approach that bridges the gap between complex Agent-Based Models (ABMs) and traditional compartmental models for infectious diseases. We introduce "super-agents" to simulate infection spread in cities, reducing computational complexity while retaining individual-level interactions. This approach leverages real-world mobility data and strategic geospatial tessellations for efficiency. Voronoi Diagram tessellations, based on specific street network locations, outperform standard Census Block Group tessellations, and a hybrid approach balances accuracy and efficiency. Benchmarking against existing ABMs highlights key optimizations. This research improves disease modeling in urban areas, aiding public health strategies in scenarios requiring geographic specificity and high computational efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.07055v5</guid>
      <category>cs.CY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amir Mohammad Esmaieeli Sikaroudi, Alon Efrat, Michael Chertkov</dc:creator>
    </item>
    <item>
      <title>Visual Political Communication in a Polarized Society: A Longitudinal Study of Brazilian Presidential Elections on Instagram</title>
      <link>https://arxiv.org/abs/2310.00349</link>
      <description>arXiv:2310.00349v2 Announce Type: replace 
Abstract: In today's digital age, images have emerged as powerful tools for politicians to engage with their voters on social media platforms. Visual content possesses a unique emotional appeal that often leads to increased user engagement. However, research on visual communication remains relatively limited, particularly in the Global South. This study aims to bridge this gap by employing a combination of computational methods and qualitative approach to investigate the visual communication strategies employed in a dataset of 11,263 Instagram posts by 19 Brazilian presidential candidates in 2018 and 2022 national elections. Through two studies, we observed consistent patterns across these candidates on their use of visual political communication. Notably, we identify a prevalence of celebratory and positively toned images. They also exhibit a strong sense of personalization, portraying candidates connected with their voters on a more emotional level. Our research also uncovers unique contextual nuances specific to the Brazilian political landscape. We note a substantial presence of screenshots from news websites and other social media platforms. Furthermore, text-edited images with portrayals emerge as a prominent feature. In light of these results, we engage in a discussion regarding the implications for the broader field of visual political communication. This article serves as a testament to the pivotal role that Instagram has played in shaping the narrative of two fiercely polarized Brazilian elections, casting a revealing light on the ever-evolving dynamics of visual political communication in the digital age. Finally, we propose avenues for future research in the realm of visual political communication.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.00349v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mathias-Felipe de-Lima-Santos, Isabella Gon\c{c}alves, Marcos G. Quiles, Lucia Mesquita, Wilson Ceron, Maria Clara Couto Lorena</dc:creator>
    </item>
    <item>
      <title>Generative AI in EU Law: Liability, Privacy, Intellectual Property, and Cybersecurity</title>
      <link>https://arxiv.org/abs/2401.07348</link>
      <description>arXiv:2401.07348v3 Announce Type: replace 
Abstract: The advent of Generative AI, particularly through Large Language Models (LLMs) like ChatGPT and its successors, marks a paradigm shift in the AI landscape. Advanced LLMs exhibit multimodality, handling diverse data formats, thereby broadening their application scope. However, the complexity and emergent autonomy of these models introduce challenges in predictability and legal compliance. This paper delves into the legal and regulatory implications of Generative AI and LLMs in the European Union context, analyzing aspects of liability, privacy, intellectual property, and cybersecurity. It critically examines the adequacy of the existing and proposed EU legislation, including the Artificial Intelligence Act (AIA) draft, in addressing the unique challenges posed by Generative AI in general and LLMs in particular. The paper identifies potential gaps and shortcomings in the legislative framework and proposes recommendations to ensure the safe and compliant deployment of generative models, ensuring they align with the EU's evolving digital landscape and legal standards.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.07348v3</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Claudio Novelli, Federico Casolari, Philipp Hacker, Giorgio Spedicato, Luciano Floridi</dc:creator>
    </item>
    <item>
      <title>Analyzing Fairness in Deepfake Detection With Massively Annotated Databases</title>
      <link>https://arxiv.org/abs/2208.05845</link>
      <description>arXiv:2208.05845v4 Announce Type: replace-cross 
Abstract: In recent years, image and video manipulations with Deepfake have become a severe concern for security and society. Many detection models and datasets have been proposed to detect Deepfake data reliably. However, there is an increased concern that these models and training databases might be biased and, thus, cause Deepfake detectors to fail. In this work, we investigate factors causing biased detection in public Deepfake datasets by (a) creating large-scale demographic and non-demographic attribute annotations with 47 different attributes for five popular Deepfake datasets and (b) comprehensively analysing attributes resulting in AI-bias of three state-of-the-art Deepfake detection backbone models on these datasets. The analysis shows how various attributes influence a large variety of distinctive attributes (from over 65M labels) on the detection performance which includes demographic (age, gender, ethnicity) and non-demographic (hair, skin, accessories, etc.) attributes. The results examined datasets show limited diversity and, more importantly, show that the utilised Deepfake detection backbone models are strongly affected by investigated attributes making them not fair across attributes. The Deepfake detection backbone methods trained on such imbalanced/biased datasets result in incorrect detection results leading to generalisability, fairness, and security issues. Our findings and annotated datasets will guide future research to evaluate and mitigate bias in Deepfake detection techniques. The annotated datasets and the corresponding code are publicly available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.05845v4</guid>
      <category>cs.CV</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ying Xu, Philipp Terh\"orst, Kiran Raja, Marius Pedersen</dc:creator>
    </item>
    <item>
      <title>On the Limitations of Carbon-Aware Temporal and Spatial Workload Shifting in the Cloud</title>
      <link>https://arxiv.org/abs/2306.06502</link>
      <description>arXiv:2306.06502v2 Announce Type: replace-cross 
Abstract: Cloud platforms have been focusing on reducing their carbon emissions by shifting workloads across time and locations to when and where low-carbon energy is available. Despite the prominence of this idea, prior work has only quantified the potential of spatiotemporal workload shifting in narrow settings, i.e., for specific workloads in select regions. In particular, there has been limited work on quantifying an upper bound on the ideal and practical benefits of carbon-aware spatiotemporal workload shifting for a wide range of cloud workloads. To address the problem, we conduct a detailed data-driven analysis to understand the benefits and limitations of carbon-aware spatiotemporal scheduling for cloud workloads. We utilize carbon intensity data from 123 regions, encompassing most major cloud sites, to analyze two broad classes of workloads -- batch and interactive -- and their various characteristics, e.g., job duration, deadlines, and SLOs. Our findings show that while spatiotemporal workload shifting can reduce workloads' carbon emissions, the practical upper bounds of these carbon reductions are currently limited and far from ideal. We also show that simple scheduling policies often yield most of these reductions, with more sophisticated techniques yielding little additional benefit. Notably, we also find that the benefit of carbon-aware workload scheduling relative to carbon-agnostic scheduling will decrease as the energy supply becomes "greener".</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.06502v2</guid>
      <category>cs.DC</category>
      <category>cs.CY</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3627703.3650079</arxiv:DOI>
      <dc:creator>Thanathorn Sukprasert, Abel Souza, Noman Bashir, David Irwin, Prashant Shenoy</dc:creator>
    </item>
    <item>
      <title>Computer Vision Datasets and Models Exhibit Cultural and Linguistic Diversity in Perception</title>
      <link>https://arxiv.org/abs/2310.14356</link>
      <description>arXiv:2310.14356v3 Announce Type: replace-cross 
Abstract: Computer vision often treats human perception as homogeneous: an implicit assumption that visual stimuli are perceived similarly by everyone. This assumption is reflected in the way researchers collect datasets and train vision models. By contrast, literature in cross-cultural psychology and linguistics has provided evidence that people from different cultural backgrounds observe vastly different concepts even when viewing the same visual stimuli. In this paper, we study how these differences manifest themselves in vision-language datasets and models, using language as a proxy for culture. By comparing textual descriptions generated across 7 languages for the same images, we find significant differences in the semantic content and linguistic expression. When datasets are multilingual as opposed to monolingual, descriptions have higher semantic coverage on average, where coverage is measured using scene graphs, model embeddings, and linguistic taxonomies. For example, multilingual descriptions have on average 29.9% more objects, 24.5% more relations, and 46.0% more attributes than a set of monolingual captions. When prompted to describe images in different languages, popular models (e.g. LLaVA) inherit this bias and describe different parts of the image. Moreover, finetuning models on captions from one language performs best on corresponding test data from that language, while finetuning on multilingual data performs consistently well across all test data compositions. Our work points towards the need to account for and embrace the diversity of human perception in the computer vision community.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.14356v3</guid>
      <category>cs.CV</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andre Ye, Sebastin Santy, Jena D. Hwang, Amy X. Zhang, Ranjay Krishna</dc:creator>
    </item>
    <item>
      <title>Who Are We Missing? A Principled Approach to Characterizing the Underrepresented Population</title>
      <link>https://arxiv.org/abs/2401.14512</link>
      <description>arXiv:2401.14512v3 Announce Type: replace-cross 
Abstract: Randomized controlled trials (RCTs) serve as the cornerstone for understanding causal effects, yet extending inferences to target populations presents challenges due to effect heterogeneity and underrepresentation. Our paper addresses the critical issue of identifying and characterizing underrepresented subgroups in RCTs, proposing a novel framework for refining target populations to improve generalizability. We introduce an optimization-based approach, Rashomon Set of Optimal Trees (ROOT), to characterize underrepresented groups. ROOT optimizes the target subpopulation distribution by minimizing the variance of the target average treatment effect estimate, ensuring more precise treatment effect estimations. Notably, ROOT generates interpretable characteristics of the underrepresented population, aiding researchers in effective communication. Our approach demonstrates improved precision and interpretability compared to alternatives, as illustrated with synthetic data experiments. We apply our methodology to extend inferences from the Starting Treatment with Agonist Replacement Therapies (START) trial -- investigating the effectiveness of medication for opioid use disorder -- to the real-world population represented by the Treatment Episode Dataset: Admissions (TEDS-A). By refining target populations using ROOT, our framework offers a systematic approach to enhance decision-making accuracy and inform future trials in diverse populations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.14512v3</guid>
      <category>stat.ME</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Harsh Parikh, Rachael Ross, Elizabeth Stuart, Kara Rudolph</dc:creator>
    </item>
    <item>
      <title>Modeling the amplification of epidemic spread by misinformed populations</title>
      <link>https://arxiv.org/abs/2402.11351</link>
      <description>arXiv:2402.11351v2 Announce Type: replace-cross 
Abstract: Understanding how misinformation affects the spread of disease is crucial for public health, especially given recent research indicating that misinformation can increase vaccine hesitancy and discourage vaccine uptake. However, it is difficult to investigate the interaction between misinformation and epidemic outcomes due to the dearth of data-informed holistic epidemic models. Here, we propose an epidemic model that incorporates a large, mobility-informed physical contact network as well as the distribution of misinformed individuals across counties derived from social media data. Our model allows us to simulate and estimate various scenarios to understand the impact of misinformation on epidemic spreading. Using this model, we estimate that misinformation could have led to 47 million additional COVID-19 infections in the U.S. in a worst-case scenario.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.11351v2</guid>
      <category>cs.SI</category>
      <category>cs.CY</category>
      <category>physics.soc-ph</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthew R. DeVerna, Francesco Pierri, Yong-Yeol Ahn, Santo Fortunato, Alessandro Flammini, Filippo Menczer</dc:creator>
    </item>
    <item>
      <title>The Case for Globalizing Fairness: A Mixed Methods Study on Colonialism, AI, and Health in Africa</title>
      <link>https://arxiv.org/abs/2403.03357</link>
      <description>arXiv:2403.03357v2 Announce Type: replace-cross 
Abstract: With growing application of machine learning (ML) technologies in healthcare, there have been calls for developing techniques to understand and mitigate biases these systems may exhibit. Fair-ness considerations in the development of ML-based solutions for health have particular implications for Africa, which already faces inequitable power imbalances between the Global North and South.This paper seeks to explore fairness for global health, with Africa as a case study. We conduct a scoping review to propose axes of disparities for fairness consideration in the African context and delineate where they may come into play in different ML-enabled medical modalities. We then conduct qualitative research studies with 672 general population study participants and 28 experts inML, health, and policy focused on Africa to obtain corroborative evidence on the proposed axes of disparities. Our analysis focuses on colonialism as the attribute of interest and examines the interplay between artificial intelligence (AI), health, and colonialism. Among the pre-identified attributes, we found that colonial history, country of origin, and national income level were specific axes of disparities that participants believed would cause an AI system to be biased.However, there was also divergence of opinion between experts and general population participants. Whereas experts generally expressed a shared view about the relevance of colonial history for the development and implementation of AI technologies in Africa, the majority of the general population participants surveyed did not think there was a direct link between AI and colonialism. Based on these findings, we provide practical recommendations for developing fairness-aware ML solutions for health in Africa.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.03357v2</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mercy Asiedu, Awa Dieng, Iskandar Haykel, Negar Rostamzadeh, Stephen Pfohl, Chirag Nagpal, Maria Nagawa, Abigail Oppong, Sanmi Koyejo, Katherine Heller</dc:creator>
    </item>
    <item>
      <title>An AI-enabled Agent-Based Model and Its Application in Measles Outbreak Simulation for New Zealand</title>
      <link>https://arxiv.org/abs/2403.03434</link>
      <description>arXiv:2403.03434v2 Announce Type: replace-cross 
Abstract: Agent Based Models (ABMs) have emerged as a powerful tool for investigating complex social interactions, particularly in the context of public health and infectious disease investigation. In an effort to enhance the conventional ABM, enabling automated model calibration and reducing the computational resources needed for scaling up the model, we have developed a tensorized and differentiable agent-based model by coupling Graph Neural Network (GNN) and Long Short-Term Memory (LSTM) network. The model was employed to investigate the 2019 measles outbreak occurred in New Zealand, demonstrating a promising ability to accurately simulate the outbreak dynamics, particularly during the peak period of repeated cases. This paper shows that by leveraging the latest Artificial Intelligence (AI) technology and the capabilities of traditional ABMs, we gain deeper insights into the dynamics of infectious disease outbreaks. This, in turn, helps us make more informed decision when developing effective strategies that strike a balance between managing outbreaks and minimizing disruptions to everyday life.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.03434v2</guid>
      <category>cs.MA</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sijin Zhang, Alvaro Orsi, Lei Chen</dc:creator>
    </item>
    <item>
      <title>Personalizing explanations of AI-driven hints to users' cognitive abilities: an empirical evaluation</title>
      <link>https://arxiv.org/abs/2403.04035</link>
      <description>arXiv:2403.04035v2 Announce Type: replace-cross 
Abstract: We investigate personalizing the explanations that an Intelligent Tutoring System generates to justify the hints it provides to students to foster their learning. The personalization targets students with low levels of two traits, Need for Cognition and Conscientiousness, and aims to enhance these students' engagement with the explanations, based on prior findings that these students do not naturally engage with the explanations but they would benefit from them if they do. To evaluate the effectiveness of the personalization, we conducted a user study where we found that our proposed personalization significantly increases our target users' interaction with the hint explanations, their understanding of the hints and their learning. Hence, this work provides valuable insights into effectively personalizing AI-driven explanations for cognitively demanding tasks such as learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.04035v2</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vedant Bahel, Harshinee Sriram, Cristina Conati</dc:creator>
    </item>
  </channel>
</rss>
