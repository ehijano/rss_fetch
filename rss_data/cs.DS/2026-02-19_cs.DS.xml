<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 19 Feb 2026 05:00:16 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Latent Objective Induction and Diversity-Constrained Selection: Algorithms for Multi-Locale Retrieval Pipelines</title>
      <link>https://arxiv.org/abs/2602.15921</link>
      <description>arXiv:2602.15921v1 Announce Type: new 
Abstract: We present three algorithms with formal correctness guarantees and complexity bounds for the problem of selecting a diverse, multi-locale set of sources from ranked search results. First, we formulate weighted locale allocation as a constrained integer partition problem and give an $O(n \log n)$ algorithm that simultaneously satisfies minimum-representation, budget-exhaustion, and proportionality-bound constraints; we prove all three hold with a tight deviation bound of $&lt; 1$. Second, we define a cascaded country-code inference function as a deterministic priority chain over heterogeneous signals (TLD structure, model-inferred metadata, language fallback) and prove it satisfies both determinism and graceful degradation. Third, we introduce a $\kappa$-domain diversity constraint for source selection and give an $O(|K| \cdot R)$ algorithm that maintains the invariant via hash-map lookup, eliminating the aggregator monopolization pathology present in URL-level deduplication. We further formalize Latent Objective Induction (LOI), an environment-shaping operator over prompt spaces that steers downstream model behavior without restricting the feasible output set, and prove its convergence under mild assumptions. Applied to a multi-locale retrieval pipeline, these algorithms yield 62% improvement in first-party source ratio and 89% reduction in same-domain duplication across 120 multilingual queries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15921v1</guid>
      <category>cs.DS</category>
      <category>cs.IR</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Faruk Alpay, Levent Sarioglu</dc:creator>
    </item>
    <item>
      <title>Computing Approximate Pareto Frontiers for Submodular Utility and Cost Tradeoffs</title>
      <link>https://arxiv.org/abs/2602.15964</link>
      <description>arXiv:2602.15964v1 Announce Type: new 
Abstract: In many data-mining applications, including recommender systems, influence maximization, and team formation, the goal is to pick a subset of elements (e.g., items, nodes in a network, experts to perform a task) to maximize a monotone submodular utility function while simultaneously minimizing a cost function. Classical formulations model this tradeoff via cardinality or knapsack constraints, or by combining utility and cost into a single weighted objective. However, such approaches require committing to a specific tradeoff in advance and return only a single solution, offering limited insight into the space of viable utility-cost tradeoffs. In this paper, we depart from the single-solution paradigm and examine the problem of computing representative sets of high-quality solutions that expose different tradeoffs between submodular utility and cost. For this, we introduce $(\alpha_1,\alpha_2)$-approximate Pareto frontiers that provably approximate the achievable tradeoffs between submodular utility and cost. Specifically, we formalize the Pareto-$\langle f,c \rangle$ problem and develop efficient algorithms for multiple instantiations arising from different combinations of submodular utility $f$ and cost functions $c$. Our results offer a principled and practical framework for understanding and exploiting utility-cost tradeoffs in submodular optimization. Experiments on datasets from diverse application domains demonstrate that our algorithms efficiently compute approximate Pareto frontiers in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15964v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>cs.SI</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Karan Vombatkere, Evimaria Terzi</dc:creator>
    </item>
    <item>
      <title>Universally Optimal Decremental Tree Minima</title>
      <link>https://arxiv.org/abs/2602.15977</link>
      <description>arXiv:2602.15977v1 Announce Type: new 
Abstract: An algorithm on weighted graphs is called universally optimal if it is optimal for every input graph, in the worst case taken over all weight assignments. Informally, this means the algorithm is competitive even with algorithms that are optimized for only one specific input graph. Universal optimality was recently introduced [Haeupler et al. 2024] as an alternative to the stronger, but often unachievable instance optimality.
  In this paper, we extend the concept of universal optimality to data structures. In particular, we investigate the following dynamic graph problem: Given a vertex-weighted forest, maintain the minimum-weight vertex of every tree under edge deletions. The problem requires $\Theta(\log n)$ amortized time per operation in general, but only $O(1)$ time if the initial forest is a path.
  We present a data structure that has optimal total running time for every fixed initial forest and every fixed number of operations/queries $m$, when taking the worst case over all weight assignments and operation sequences of length $m$. This definition of universal optimality is easily adapted to other data structure problems.
  Our result combines two techniques: (1) A decomposition of the input into paths, to take advantage of the $O(1)$-time path-specific data structure; and (2) splay trees [Sleator and Tarjan 1985], which, informally speaking, are used to optimally handle a certain sorting-related subproblem. We apply our data structure to solve problems related to Cartesian trees, path minimum queries, and bottleneck vertex/edge queries, each with a certain universal optimality guarantee. Our data structure also can be modified to support edge weights instead of vertex weights. Further, it generalizes to support semigroup sum queries instead of minimum queries, in universally optimal time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15977v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Benjamin Aram Berendsohn</dc:creator>
    </item>
    <item>
      <title>Markov Chains with Rewinding</title>
      <link>https://arxiv.org/abs/2602.16028</link>
      <description>arXiv:2602.16028v1 Announce Type: new 
Abstract: Motivated by techniques developed in recent progress on lower bounds for sublinear time algorithms (Behnezhad, Roghani and Rubinstein, STOC 2023, FOCS 2023, and STOC 2024) we introduce and study a new class of randomized algorithmic processes that we call Markov Chains with Rewinding. In this setting, an algorithm interacts with a (partially observable) Markovian random evolution by strategically rewinding the Markov chain to previous states. Depending on the application, this may lead the evolution to desired states faster, or allow the agent to efficiently learn or test properties of the underlying Markov chain that may be infeasible or inefficient with passive observation.
  We study the task of identifying the initial state in a given partially observable Markov chain. Analysis of this question in specific Markov chains is the central ingredient in the above cited works and we aim to systematize the analysis in our work. Our first result is that any pair of states distinguishable with any rewinding strategy can also be distinguished with a non-adaptive rewinding strategy (one whose rewinding choices are determined before observing any outcomes of the chain). Therefore, while rewinding strategies can be shown to be strictly more powerful than passive strategies (those that do not rewind back to previous states), adaptivity does not give additional power to a rewinding strategy in the absence of efficiency considerations.
  The difference becomes apparent however when we introduce a natural efficiency measure, namely the query complexity (i.e., the number of observations they need to identify distinguishable states). Our second main contribution is to quantify this efficiency gap. We present a non-adaptive rewinding strategy whose query complexity is within a polynomial of that of the optimal (adaptive) strategy, and show that such a polynomial loss is necessary in general.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16028v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amir Azarmehr, Soheil Behnezhad, Alma Ghafari, Madhu Sudan</dc:creator>
    </item>
    <item>
      <title>Bellman-Ford in Almost-Linear Time for Dense Graphs</title>
      <link>https://arxiv.org/abs/2602.16153</link>
      <description>arXiv:2602.16153v1 Announce Type: new 
Abstract: We consider the single-source shortest paths problem on a directed graph with real-valued (possibly negative) edge weights and solve this problem in $n^{2+o(1)}$ time by refining the shortcutting procedure introduced in Li, Li, Rao, and Zhang (2026).</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16153v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>George Z. Li, Jason Li, Junkai Zhang</dc:creator>
    </item>
    <item>
      <title>Submodular Maximization under Supermodular Constraint: Greedy Guarantees</title>
      <link>https://arxiv.org/abs/2602.16240</link>
      <description>arXiv:2602.16240v1 Announce Type: new 
Abstract: Motivated by a wide range of applications in data mining and machine learning, we consider the problem of maximizing a submodular function subject to supermodular cost constraints. In contrast to the well-understood setting of cardinality and matroid constraints, where greedy algorithms admit strong guarantees, the supermodular constraint regime remains poorly understood -- guarantees for greedy methods and other efficient algorithmic paradigms are largely open. We study this family of fundamental optimization problems under an upper-bound constraint on a supermodular cost function with curvature parameter $\gamma$. Our notion of supermodular curvature is less restrictive than prior definitions, substantially expanding the class of admissible cost functions. We show that our greedy algorithm that iteratively includes elements maximizing the ratio of the objective and constraint functions, achieves a $\left(1 - e^{-(1-\gamma)}\right)$-approximation before stopping. We prove that this approximation is indeed tight for this algorithm. Further, if the objective function has a submodular curvature $c$, then we show that the bound further improves to $\left(1 - (1- (1-c)(1-\gamma))^{1/(1-c)}\right)$, which can be further improved by continuing to violate the constraint. Finally, we show that the Greedy-Ratio-Marginal in conjunction with binary search leads to a bicriteria approximation for the dual problem -- minimizing a supermodular function under a lower bound constraint on a submodular function. We conduct a number of experiments on a simulation of LLM agents debating over multiple rounds -- the task is to select a subset of agents to maximize correctly answered questions. Our algorithm outperforms all other greedy heuristics, and on smaller problems, it achieves the same performance as the optimal set found by exhaustive search.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16240v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ajitesh Srivastava, Shanghua Teng</dc:creator>
    </item>
    <item>
      <title>When to Identify Is to Control: On the Controllability of Combinatorial Optimization Problems</title>
      <link>https://arxiv.org/abs/2602.16311</link>
      <description>arXiv:2602.16311v1 Announce Type: new 
Abstract: Consider a finite ground set $E$, a set of feasible solutions $X \subseteq \mathbb{R}^{E}$, and a class of objective functions $\mathcal{C}$ defined on $X$. We are interested in subsets $S$ of $E$ that control $X$ in the sense that we can induce any given solution $x \in X$ as an optimum for any given objective function $c \in \mathcal{C}$ by adding linear terms to $c$ on the coordinates corresponding to $S$. This problem has many applications, e.g., when $X$ corresponds to the set of all traffic flows, the ability to control implies that one is able to induce all target flows by imposing tolls on the edges in $S$.
  Our first result shows the equivalence between controllability and identifiability. If $X$ is convex, or if $X$ consists of binary vectors, then $S$ controls $X$ if and only if the restriction of $x$ to $S$ uniquely determines $x$ among all solutions in $X$. In the convex case, we further prove that the family of controlling sets forms a matroid. This structural insight yields an efficient algorithm for computing minimum-weight controlling sets from a description of the affine hull of $X$.
  While the equivalence extends to matroid base families, the picture changes sharply for other discrete domains. We show that when $X$ is equal to the set of $s$-$t$-paths in a directed graph, deciding whether an identifying set of a given cardinality exists is $\Sigma\mathsf{_2^P}$-complete. The problem remains $\mathsf{NP}$-hard even on acyclic graphs. For acyclic instances, however, we obtain an approximation guarantee by proving a tight bound on the gap between the smallest identifying sets for $X$ and its convex hull, where the latter corresponds to the $s$-$t$-flow polyhedron.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16311v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Max Klimm, Jannik Matuschke</dc:creator>
    </item>
    <item>
      <title>Computing Tarski Fixed Points in Financial Networks</title>
      <link>https://arxiv.org/abs/2602.16387</link>
      <description>arXiv:2602.16387v1 Announce Type: new 
Abstract: Modern financial networks are highly connected and result in complex interdependencies of the involved institutions. In the prominent Eisenberg-Noe model, a fundamental aspect is clearing -- to determine the amount of assets available to each financial institution in the presence of potential defaults and bankruptcy. A clearing state represents a fixed point that satisfies a set of natural axioms. Existence can be established (even in broad generalizations of the model) using Tarski's theorem.
  While a maximal fixed point can be computed in polynomial time, the complexity of computing other fixed points is open. In this paper, we provide an efficient algorithm to compute a minimal fixed point that runs in strongly polynomial time. It applies in a broad generalization of the Eisenberg-Noe model with any monotone, piecewise-linear payment functions and default costs. Moreover, in this scenario we provide a polynomial-time algorithm to compute a maximal fixed point. For networks without default costs, we can efficiently decide the existence of fixed points in a given range.
  We also study claims trading, a local network adjustment to improve clearing, when networks are evaluated with minimal clearing. We provide an efficient algorithm to decide existence of Pareto-improving trades and compute optimal ones if they exist.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16387v1</guid>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <category>q-fin.RM</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Leander Besting, Martin Hoefer, Lars Huth</dc:creator>
    </item>
    <item>
      <title>The S-Hamiltonian Cycle Problem</title>
      <link>https://arxiv.org/abs/2602.16532</link>
      <description>arXiv:2602.16532v1 Announce Type: new 
Abstract: Determining if an input undirected graph is Hamiltonian, i.e., if it has a cycle that visits every vertex exactly once, is one of the most famous NP-complete problems. We consider the following generalization of Hamiltonian cycles: for a fixed set $S$ of natural numbers, we want to visit each vertex of a graph $G$ exactly once and ensure that any two consecutive vertices can be joined in $k$ hops for some choice of $k \in S$. Formally, an $S$-Hamiltonian cycle is a permutation $(v_0,\ldots,v_{n-1})$ of the vertices of $G$ such that, for $0 \leq i \leq n-1$, there exists a walk between $v_i$ and $v_{i+1 \bmod n}$ whose length is in $S$. (We do not impose any constraints on how many times vertices can be visited as intermediate vertices of walks.) Of course Hamiltonian cycles in the standard sense correspond to $S=\{1\}$. We study the $S$-Hamiltonian cycle problem of deciding whether an input graph $G$ has an $S$-Hamiltonian cycle. Our goal is to determine the complexity of this problem depending on the fixed set $S$. It is already known that the problem remains NP-complete for $S=\{1,2\}$, whereas it is trivial for $S=\{1,2,3\}$ because any connected graph contains a $\{1,2,3\}$-Hamiltonian cycle.
  Our work classifies the complexity of this problem for most kinds of sets $S$, with the key new results being the following: we have NP-completeness for $S = \{2\}$ and for $S = \{2, 4\}$, but tractability for $S = \{1, 2, 4\}$, for $S = \{2, 4, 6\}$, for any superset of these two tractable cases, and for $S$ the infinite set of all odd integers. The remaining open cases are the non-singleton finite sets of odd integers, in particular $S = \{1, 3\}$. Beyond cycles, we also discuss the complexity of finding $S$-Hamiltonian paths, and show that our problems are all tractable on graphs of bounded cliquewidth.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16532v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Antoine Amarilli, Arthur Lombardo, Mika\"el Monet</dc:creator>
    </item>
    <item>
      <title>Fast Shortest Path in Graphs With Sparse Signed Tree Models and Applications</title>
      <link>https://arxiv.org/abs/2602.16605</link>
      <description>arXiv:2602.16605v1 Announce Type: new 
Abstract: A signed tree model of a graph $G$ is a compact binary structure consisting of a rooted binary tree whose leaves are bijectively mapped to the vertices of $G$, together with 2-colored edges $xy$, called transversal pairs, interpreted as bicliques or anti-bicliques whose sides are the leaves of the subtrees rooted at $x$ and at $y$. We design an algorithm that, given such a representation of an $n$-vertex graph $G$ with $p$ transversal pairs and a source $v \in V(G)$, computes a shortest-path tree rooted at $v$ in $G$ in time $O(p \log n)$. A wide variety of graph classes are such that for all $n$, their $n$-vertex graphs admit signed tree models with $O(n)$ transversal pairs: for instance, those of bounded symmetric difference, more generally of bounded sd-degeneracy, as well as interval graphs.
  As applications of our Single-Source Shortest Path algorithm and new techniques, we
  - improve the runtime of the fixed-parameter algorithm for first-order model checking on graphs given with a witness of low merge-width from cubic [Dreier and Toru\'nczyk, STOC '25] to quadratic;
  - give an $O(n^2 \log n)$-time algorithm for All-Pairs Shortest Path (APSP) on graphs given with a witness of low merge-width, generalizing a result known on twin-width [Twin-Width III, SICOMP '24];
  - extend and simplify an $O(n^2 \log n)$-time algorithm for multiplying two $n \times n$ matrices $A, B$ of bounded twin-width in [Twin-Width V, STACS '23]: now $A$ solely has to be an adjacency matrix of a graph of bounded twin-width and $B$ can be arbitrary;
  - give an $O(n^2 \log^2 n)$-time algorithm for APSP on graphs of bounded twin-width, bypassing the need for contraction sequences in [Twin-Width III, SICOMP '24; Bannach et al. STACS '24];
  - give an $O(n^{7/3} \log^2 n)$-time algorithm for APSP on graphs of symmetric difference $O(n^{1/3})$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16605v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>\'Edouard Bonnet, Colin Geniet, Eun Jung Kim, Sungmin Moon</dc:creator>
    </item>
    <item>
      <title>An $n^{2+o(1)}$ Time Algorithm for Single-Source Negative Weight Shortest Paths</title>
      <link>https://arxiv.org/abs/2602.16638</link>
      <description>arXiv:2602.16638v1 Announce Type: new 
Abstract: We present a randomized algorithm for the single-source shortest paths (SSSP) problem on directed graphs with arbitrary real-valued edge weights that runs in $n^{2+o(1)}$ time with high probability. This result yields the first almost linear-time algorithm for the problem on dense graphs ($m = \Theta(n^2)$) and improves upon the best previously known bounds for moderately dense graphs ($m = \omega(n^{1.306})$).
  Our approach builds on the hop-reduction via shortcutting framework introduced by Li, Li, Rao, and Zhang (2025), which iteratively augments the graph with shortcut edges to reduce the negative hop count of shortest paths. The central computational bottleneck in prior work is the cost of explicitly constructing these shortcuts in dense regions. We overcome this by introducing a new compression technique using auxiliary Steiner vertices. Specifically, we construct these vertices to represent large neighborhoods compactly in a structured manner, allowing us to efficiently generate and propagate shortcuts while strictly controlling the growth of vertex degrees and graph size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16638v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sanjeev Khanna, Junkai Song</dc:creator>
    </item>
    <item>
      <title>Near-optimal population protocols on bounded-degree trees</title>
      <link>https://arxiv.org/abs/2602.16222</link>
      <description>arXiv:2602.16222v1 Announce Type: cross 
Abstract: We investigate space-time trade-offs for population protocols in sparse interaction graphs. In complete interaction graphs, optimal space-time trade-offs are known for the leader election and exact majority problems. However, it has remained open if other graph families exhibit similar space-time complexity trade-offs, as existing lower bound techniques do not extend beyond highly dense graphs.
  In this work, we show that -- unlike in complete graphs -- population protocols on bounded-degree trees do not exhibit significant asymptotic space-time trade-offs for leader election and exact majority. For these problems, we give constant-space protocols that have near-optimal worst-case expected stabilisation time. These new protocols achieve a linear speed-up compared to the state-of-the-art.
  Our results are based on two novel protocols, which we believe are of independent interest. First, we give a new fast self-stabilising 2-hop colouring protocol for general interaction graphs, whose stabilisation time we bound using a stochastic drift argument. Second, we give a self-stabilising tree orientation algorithm that builds a rooted tree in optimal time on any tree. As a consequence, we can use simple constant-state protocols designed for directed trees to solve leader election and exact majority fast. For example, we show that ``directed'' annihilation dynamics solve exact majority in $O(n^2 \log n)$ steps on directed trees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16222v1</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joel Rybicki, Jakob Solnerzik, Robin Vacus</dc:creator>
    </item>
    <item>
      <title>Condorcet Dimension and Pareto Optimality for Matchings and Beyond</title>
      <link>https://arxiv.org/abs/2602.16289</link>
      <description>arXiv:2602.16289v1 Announce Type: cross 
Abstract: We study matching problems in which agents form one side of a bipartite graph and have preferences over objects on the other side. A central solution concept in this setting is popularity: a matching is popular if it is a (weak) Condorcet winner, meaning that no other matching is preferred by a strict majority of agents. It is well known, however, that Condorcet winners need not exist. We therefore turn to a natural and prominent relaxation. A set of matchings is a Condorcet-winning set if, for every competing matching, a majority of agents prefers their favorite matching in the set over the competitor. The Condorcet dimension is the smallest cardinality of a Condorcet-winning set.
  Our main results reveal a connection between Condorcet-winning sets and Pareto optimality. We show that any Pareto-optimal set of two matchings is, in particular, a Condorcet-winning set. This implication continues to hold when we impose matroid constraints on the set of matched objects, and even when agents' valuations are given as partial orders. The existence picture, however, changes sharply with partial orders. While for weak orders a Pareto-optimal set of two matchings always exists, this is -- surprisingly -- not the case under partial orders. Consequently, although the Condorcet dimension for matchings is 2 under weak orders (even under matroid constraints), this guarantee fails for partial orders: we prove that the Condorcet dimension is $\Theta(\sqrt{n})$, and rises further to $\Theta(n)$ when matroid constraints are added. On the computational side, we show that, under partial orders, deciding whether there exists a Condorcet -- winning set of a given fixed size is NP-hard. The same holds for deciding the existence of a Pareto-optimal matching, which we believe to be of independent interest. Finally, we also show that the Condorcet dimension for a related problem on arborescences is also 2.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16289v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Telikepalli Kavitha, Jannik Matuschke, Ulrike Schmidt-Kraepelin</dc:creator>
    </item>
    <item>
      <title>Dynamic and Streaming Algorithms for Union Volume Estimation</title>
      <link>https://arxiv.org/abs/2602.16306</link>
      <description>arXiv:2602.16306v1 Announce Type: cross 
Abstract: The union volume estimation problem asks to $(1\pm\varepsilon)$-approximate the volume of the union of $n$ given objects $X_1,\ldots,X_n \subset \mathbb{R}^d$. In their seminal work in 1989, Karp, Luby, and Madras solved this problem in time $O(n/\varepsilon^2)$ in an oracle model where each object $X_i$ can be accessed via three types of queries: obtain the volume of $X_i$, sample a random point from $X_i$, and test whether $X_i$ contains a given point $x$. This running time was recently shown to be optimal [Bringmann, Larsen, Nusser, Rotenberg, and Wang, SoCG'25]. In another line of work, Meel, Vinodchandran, and Chakraborty [PODS'21] designed algorithms that read the objects in one pass using polylogarithmic time per object and polylogarithmic space; this can be phrased as a dynamic algorithm supporting insertions of objects for union volume estimation in the oracle model.
  In this paper, we study algorithms for union volume estimation in the oracle model that support both insertions and deletions of objects. We obtain the following results:
  - an algorithm supporting insertions and deletions in polylogarithmic update and query time and linear space (this is the first such dynamic algorithm, even for 2D triangles);
  - an algorithm supporting insertions and suffix queries (which generalizes the sliding window setting) in polylogarithmic update and query time and space;
  - an algorithm supporting insertions and deletions of convex bodies of constant dimension in polylogarithmic update and query time and space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16306v1</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sujoy Bhore, Karl Bringmann, Timothy M. Chan, Yanheng Wang</dc:creator>
    </item>
    <item>
      <title>The Complexity Landscape of Two-Stage Robust Selection Problems with Budgeted Uncertainty</title>
      <link>https://arxiv.org/abs/2602.16465</link>
      <description>arXiv:2602.16465v1 Announce Type: cross 
Abstract: A standard type of uncertainty set in robust optimization is budgeted uncertainty, where an interval of possible values for each parameter is given and the total deviation from their lower bounds is bounded. In the two-stage setting, discrete and continuous budgeted uncertainty have to be distinguished. The complexity of such problems is largely unexplored, in particular if the underlying nominal optimization problem is simple, such as for selection problems. In this paper, we give a comprehensive answer to long-standing open complexity questions for three types of selection problems and three types of budgeted uncertainty sets. In particular, we demonstrate that the two-stage selection problem with continuous budgeted uncertainty is NP-hard, while the corresponding two-stage representative selection problem is solvable in polynomial time. Our hardness result implies that also the two-stage assignment problem with continuous budgeted uncertainty is NP-hard.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16465v1</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marc Goerigk, Dorothee Henke, Lasse Wulf</dc:creator>
    </item>
    <item>
      <title>Separating Oblivious and Adaptive Models of Variable Selection</title>
      <link>https://arxiv.org/abs/2602.16568</link>
      <description>arXiv:2602.16568v1 Announce Type: cross 
Abstract: Sparse recovery is among the most well-studied problems in learning theory and high-dimensional statistics. In this work, we investigate the statistical and computational landscapes of sparse recovery with $\ell_\infty$ error guarantees. This variant of the problem is motivated by \emph{variable selection} tasks, where the goal is to estimate the support of a $k$-sparse signal in $\mathbb{R}^d$. Our main contribution is a provable separation between the \emph{oblivious} (``for each'') and \emph{adaptive} (``for all'') models of $\ell_\infty$ sparse recovery. We show that under an oblivious model, the optimal $\ell_\infty$ error is attainable in near-linear time with $\approx k\log d$ samples, whereas in an adaptive model, $\gtrsim k^2$ samples are necessary for any algorithm to achieve this bound. This establishes a surprising contrast with the standard $\ell_2$ setting, where $\approx k \log d$ samples suffice even for adaptive sparse recovery. We conclude with a preliminary examination of a \emph{partially-adaptive} model, where we show nontrivial variable selection guarantees are possible with $\approx k\log d$ measurements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16568v1</guid>
      <category>math.ST</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziyun Chen, Jerry Li, Kevin Tian, Yusong Zhu</dc:creator>
    </item>
    <item>
      <title>Steering diffusion models with quadratic rewards: a fine-grained analysis</title>
      <link>https://arxiv.org/abs/2602.16570</link>
      <description>arXiv:2602.16570v1 Announce Type: cross 
Abstract: Inference-time algorithms are an emerging paradigm in which pre-trained models are used as subroutines to solve downstream tasks. Such algorithms have been proposed for tasks ranging from inverse problems and guided image generation to reasoning. However, the methods currently deployed in practice are heuristics with a variety of failure modes -- and we have very little understanding of when these heuristics can be efficiently improved.
  In this paper, we consider the task of sampling from a reward-tilted diffusion model -- that is, sampling from $p^{\star}(x) \propto p(x) \exp(r(x))$ -- given a reward function $r$ and pre-trained diffusion oracle for $p$. We provide a fine-grained analysis of the computational tractability of this task for quadratic rewards $r(x) = x^\top A x + b^\top x$. We show that linear-reward tilts are always efficiently sampleable -- a simple result that seems to have gone unnoticed in the literature. We use this as a building block, along with a conceptually new ingredient -- the Hubbard-Stratonovich transform -- to provide an efficient algorithm for sampling from low-rank positive-definite quadratic tilts, i.e. $r(x) = x^\top A x$ where $A$ is positive-definite and of rank $O(1)$. For negative-definite tilts, i.e. $r(x) = - x^\top A x$ where $A$ is positive-definite, we prove that the problem is intractable even if $A$ is of rank 1 (albeit with exponentially-large entries).</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16570v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ankur Moitra, Andrej Risteski, Dhruv Rohatgi</dc:creator>
    </item>
    <item>
      <title>On the Hardness of Approximation of the Fair k-Center Problem</title>
      <link>https://arxiv.org/abs/2602.16688</link>
      <description>arXiv:2602.16688v1 Announce Type: cross 
Abstract: In this work, we study the hardness of approximation of the fair $k$-center problem. Here the data points are partitioned into groups and the task is to choose a prescribed number of data points from each group, called centers, while minimizing the maximum distance from any point to its closest center. Although a polynomial-time $3$-approximation is known for this problem in general metrics, it has remained open whether this approximation guarantee is tight or could be further improved, especially since the unconstrained $k$-center problem admits a polynomial-time factor-$2$ approximation. We resolve this open question by proving that, for every $\epsilon&gt;0$, achieving a $(3-\epsilon)$-approximation is NP-hard, assuming $\text{P} \neq \text{NP}$.
  Our inapproximability results hold even when only two disjoint groups are present and at least one center must be chosen from each group. Further, it extends to the canonical one-per-group setting with $k$-groups (for arbitrary $k$), where exactly one center must be selected from each group. Consequently, the factor-$3$ barrier for fair $k$-center in general metric spaces is inherent, and existing $3$-approximation algorithms are optimal up to lower-order terms even in these restricted regimes. This result stands in sharp contrast to the $k$-supplier formulation, where both the unconstrained and fair variants admit factor-$3$ approximation in polynomial time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16688v1</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Suhas Thejaswi</dc:creator>
    </item>
    <item>
      <title>Protecting the Undeleted in Machine Unlearning</title>
      <link>https://arxiv.org/abs/2602.16697</link>
      <description>arXiv:2602.16697v1 Announce Type: cross 
Abstract: Machine unlearning aims to remove specific data points from a trained model, often striving to emulate "perfect retraining", i.e., producing the model that would have been obtained had the deleted data never been included. We demonstrate that this approach, and security definitions that enable it, carry significant privacy risks for the remaining (undeleted) data points. We present a reconstruction attack showing that for certain tasks, which can be computed securely without deletions, a mechanism adhering to perfect retraining allows an adversary controlling merely $\omega(1)$ data points to reconstruct almost the entire dataset merely by issuing deletion requests. We survey existing definitions for machine unlearning, showing they are either susceptible to such attacks or too restrictive to support basic functionalities like exact summation. To address this problem, we propose a new security definition that specifically safeguards undeleted data against leakage caused by the deletion of other points. We show that our definition permits several essential functionalities, such as bulletin boards, summations, and statistical learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16697v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aloni Cohen, Refael Kohen, Kobbi Nissim, Uri Stemmer</dc:creator>
    </item>
    <item>
      <title>Overcoming Non-Submodularity: Towards Constant Approximation for Network Immunization</title>
      <link>https://arxiv.org/abs/2410.19205</link>
      <description>arXiv:2410.19205v5 Announce Type: replace 
Abstract: Given a network with an ongoing epidemic, the network immunization problem seeks to identify a fixed number of nodes to immunize in order to maximize the number of infections prevented. A fundamental computational challenge in network immunization is that the objective function is generally neither submodular nor supermodular. Consequently, no efficient algorithm is known to consistently achieve a constant-factor approximation. Traditionally, this problem is partially addressed using proxy objectives that offer better approximation properties, but these indirect optimizations often introduce losses in effectiveness due to gaps between the proxy and natural objectives.
  In this paper, we overcome these fundamental barriers by leveraging the underlying stochastic structure of the diffusion process. Similar to the traditional influence objective, the immunization objective is an expectation expressed as a sum over deterministic instances. However, unlike the former, some of these terms are not submodular. Our key step is to prove that this sum has a bounded deviation from submodularity, enabling the classic greedy algorithm to achieve a constant-factor approximation for any sparse cascading network. We demonstrate that this approximation holds across various immunization settings and spread models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19205v5</guid>
      <category>cs.DS</category>
      <category>cs.SI</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ajitesh Srivastava, Shang-Hua Teng</dc:creator>
    </item>
    <item>
      <title>Availability is all you need: achieving optimal regret with minimal information for dynamic matching</title>
      <link>https://arxiv.org/abs/2503.09762</link>
      <description>arXiv:2503.09762v3 Announce Type: replace 
Abstract: We study a centralized discrete-time dynamic two-way matching model with finitely many agent types. Agents arrive stochastically over time and join their type-dedicated queues waiting to be matched. We focus on availability-based policies that make matching decisions based solely on agent availability across types (i.e., whether queues are empty or not), rather than relying on complete queue-length information (e.g., the longest-queue policy). We aim to achieve constant regret at all times with optimal scaling in terms of the general position gap, $\epsilon$, which measures the distance of the fluid relaxation from degeneracy.
  We classify availability-based policies into global and local policies based on the scope of information they utilize. First, for general networks (possibly cyclic), we propose a global availability-based policy, probabilistic matching, and prove that it achieves the optimal all-time regret scaling of $O(\epsilon^{-1})$, matching the known lower bound established by [KAG24]. Second, for acyclic networks, we focus on the class of local availability-based policies, specifically static priority policies that prioritize matches based on a fixed order. Within this class, we derive the first explicit regret bound for the previously proposed tree priority policy, showing all-time regret scaling of $O(\epsilon^{-(d+1)/2})$, where $d$ is the network depth. Next, we introduce a new truncated tree priority policy and prove that it is the first static priority policy to achieve the optimal all-time regret scaling of $O(\epsilon^{-1})$. These policies are appealing for matching systems such as queueing and load balancing; they reduce operational costs by using minimal information while effectively balancing the trade-off between immediate and future rewards.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09762v3</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>S\"uleyman Kerimov, Pengyu Qian, Mingwei Yang, Sophie H. Yu</dc:creator>
    </item>
    <item>
      <title>Stable coresets: Unleashing the power of uniform sampling</title>
      <link>https://arxiv.org/abs/2509.22189</link>
      <description>arXiv:2509.22189v2 Announce Type: replace 
Abstract: Uniform sampling is a highly efficient method for data summarization. However, its effectiveness in producing coresets for clustering problems is not yet well understood, primarily because it generally does not yield a strong coreset, which is the prevailing notion in the literature. We formulate \emph{stable coresets}, a notion that is intermediate between the standard notions of weak and strong coresets, and effectively combines the broad applicability of strong coresets with highly efficient constructions, through uniform sampling, of weak coresets. Our main result is that a uniform sample of size $O(\epsilon^{-2}\log d)$ yields, with high constant probability, a stable coreset for $1$-median in $\mathbb{R}^d$ under the $\ell_1$ metric. We then leverage the powerful properties of stable coresets to easily derive new coreset constructions, all through uniform sampling, for $\ell_1$ and related metrics, such as Kendall-tau and Jaccard. We also show applications to fair rank aggregation and to approximation algorithms for $k$-median problem in these metric spaces. Our experiments validate the benefits of stable coresets in practice, in terms of both construction time and approximation quality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22189v2</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amir Carmel, Robert Krauthgamer</dc:creator>
    </item>
    <item>
      <title>The matrix-vector complexity of $Ax=b$</title>
      <link>https://arxiv.org/abs/2602.04842</link>
      <description>arXiv:2602.04842v2 Announce Type: replace 
Abstract: Matrix--vector algorithms, particularly Krylov subspace methods, are widely viewed as the most effective algorithms for solving large systems of linear equations. This paper establishes lower bounds on the worst-case number of matrix--vector products needed by such an algorithm to approximately solve a general linear system. The first main result is that, for any matrix--vector algorithm which is allowed the use of randomization and can perform products with both a matrix and its transpose, $\Omega(\kappa \log(1/\varepsilon))$ matrix--vector products are necessary to solve a linear system with condition number $\kappa$ to accuracy $\varepsilon$, matching an upper bound for conjugate gradient on the normal equations. The second main result is that one-sided algorithms, which lack access to the transpose, must use $n$ matrix--vector products to solve an $n \times n$ linear system, even when the problem is perfectly conditioned. Both main results include explicit constants that match known upper bounds up to a factor of four. These results rigorously demonstrate the limitations of matrix--vector algorithms and confirm the optimality of widely used Krylov subspace algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.04842v2</guid>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Micha{\l} Derezi\'nski, Ethan N. Epperly, Raphael A. Meyer</dc:creator>
    </item>
    <item>
      <title>Catalytic Tree Evaluation From Matching Vectors</title>
      <link>https://arxiv.org/abs/2602.14320</link>
      <description>arXiv:2602.14320v2 Announce Type: replace 
Abstract: We give new algorithms for tree evaluation (S. Cook et al. TOCT 2012) in the catalytic-computing model (Buhrman et al. STOC 2014). Two existing approaches aim to solve tree evaluation in low space: on the one hand, J. Cook and Mertz (STOC 2024) give an algorithm for TreeEval running in super-logarithmic space $O(\log n\log\log n)$ and super-polynomial time $n^{O(\log\log n)}$. On the other hand, a simple reduction from TreeEval to circuit evaluation, combined with the result of Buhrman et al. (STOC 2014), gives a catalytic algorithm for TreeEval running in logarithmic $O(\log n)$ free space and polynomial time, but with polynomial catalytic space.
  We show that the latter result can be improved. We give a catalytic algorithm for TreeEval with logarithmic $O(\log n)$ free space, polynomial runtime, and subpolynomial $2^{\log^\epsilon n}$ catalytic space (for any $\epsilon &gt; 0$). Our result opens a new line of attack on putting TreeEval in logspace, and immediately implies an improved simulation of time by catalytic space, by the reduction of Williams (STOC 2025).
  Our catalytic TreeEval algorithm is inspired by a connection to matching-vector families and private information retrieval, and improved constructions of (uniform) matching-vector families would imply improvements to our algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14320v2</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexandra Henzinger, Edward Pyne, Seyoon Ragavan</dc:creator>
    </item>
    <item>
      <title>Improved Approximation Algorithms for Relational Clustering</title>
      <link>https://arxiv.org/abs/2409.18498</link>
      <description>arXiv:2409.18498v2 Announce Type: replace-cross 
Abstract: Clustering plays a crucial role in computer science, facilitating data analysis and problem-solving across numerous fields. By partitioning large datasets into meaningful groups, clustering reveals hidden structures and relationships within the data, aiding tasks such as unsupervised learning, classification, anomaly detection, and recommendation systems. Particularly in relational databases, where data is distributed across multiple tables, efficient clustering is essential yet challenging due to the computational complexity of joining tables. This paper addresses this challenge by introducing efficient algorithms for $k$-median and $k$-means clustering on relational data without the need for pre-computing the join query results. For the relational $k$-median clustering, we propose the first efficient relative approximation algorithm. For the relational $k$-means clustering, our algorithm significantly improves both the approximation factor and the running time of the known relational $k$-means clustering algorithms, which suffer either from large constant approximation factors, or expensive running time. Given a join query $Q$ and a database instance $D$ of $O(N)$ tuples, for both $k$-median and $k$-means clustering on the results of $Q$ on $D$, we propose randomized $(1+\varepsilon)\gamma$-approximation algorithms that run in roughly $O(k^2N^{\mathsf{fhw}})+T_\gamma(k^2)$ time, where $\varepsilon\in (0,1)$ is a constant parameter decided by the user, $\mathsf{fhw}$ is the fractional hyper-tree width of $Q$, while $\gamma$ and $T_\gamma(x)$ are respectively the approximation factor and the running time of a traditional clustering algorithm in the standard computational setting over $x$ points.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.18498v2</guid>
      <category>cs.DB</category>
      <category>cs.DS</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aryan Esmailpour, Stavros Sintos</dc:creator>
    </item>
    <item>
      <title>Fermion-to-Fermion Low-Density Parity-Check Codes</title>
      <link>https://arxiv.org/abs/2508.15323</link>
      <description>arXiv:2508.15323v4 Announce Type: replace-cross 
Abstract: Simulating fermionic systems on qubit-based quantum computers often demands significant computational resources due to the requirement to map fermions to qubits. Thus, designing a fault-tolerant quantum computer that operates directly with fermions offers an effective solution to this challenge. Here, we introduce a protocol for fault-tolerant fermionic quantum computation utilizing fermion-to-fermion low-density parity-check (LDPC) codes. Our method employs a fermionic LDPC memory, which transfers its state to fermionic color code processors, where logical operations are subsequently performed. We propose using odd-weight logical Majorana operators to form the code space, serving as memory for the fermionic LDPC code, and provide an algorithm to identify these logical operators. We present examples showing that the encoding rate of fermionic codes often matches that of qubit codes, while the logical failure rate can be significantly lower than the physical error rate. Furthermore, we propose two methods for performing fermionic lattice surgery to facilitate state transfer. Finally, we simulate the dynamics of a fermionic system using our protocol, illustrating effective error suppression.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.15323v4</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chong-Yuan Xu, Ze-Chuan Liu, Yong Xu</dc:creator>
    </item>
    <item>
      <title>A Tight Double-Exponentially Lower Bound for High-Multiplicity Bin Packing</title>
      <link>https://arxiv.org/abs/2512.02691</link>
      <description>arXiv:2512.02691v2 Announce Type: replace-cross 
Abstract: Consider a high-multiplicity Bin Packing instance $I$ with $d$ distinct item types. In 2014, Goemans and Rothvoss gave an algorithm with runtime ${{|I|}^2}^{O(d)}$ for this problem~[SODA'14], where $|I|$ denotes the encoding length of the instance $I$. Although Jansen and Klein~[SODA'17] later developed an algorithm that improves upon this runtime in a special case, it has remained a major open problem by Goemans and Rothvoss~[J.ACM'20] whether the doubly exponential dependency on $d$ is necessary.
  We solve this open problem by showing that unless the ETH fails, there is no algorithm solving the high-multiplicity Bin Packing problem in time ${{|I|}^2}^{o(d)}$. To prove this, we introduce a novel reduction from 3-SAT. The core of our construction is efficiently encoding all information from a 3-SAT instance with $n$ variables into an ILP with $O(\log(n))$ variables and constraints.
  This result confirms that the Goemans and Rothvoss algorithm is essentially best-possible for Bin Packing parameterized by the number $d$ of item sizes in the context of XP time algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02691v2</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Klaus Jansen, Felix Ohnesorge, Lis Pirotton</dc:creator>
    </item>
    <item>
      <title>Hardness of Regular Expression Matching with Extensions</title>
      <link>https://arxiv.org/abs/2601.03020</link>
      <description>arXiv:2601.03020v2 Announce Type: replace-cross 
Abstract: The regular expression matching problem asks whether a given regular expression of length $m$ matches a given string of length $n$. As is well known, the problem can be solved in $O(nm)$ time using Thompson's algorithm. Moreover, recent studies have shown that the matching problem for regular expressions extended with a practical extension called lookaround can be solved in the same time complexity. In this work, we consider four well-known extensions to regular expressions called backreference, squaring, intersection and complement, and we show that, unlike in the case of lookaround, the matching problem for regular expressions extended with any of the four (for backreference, even when restricted to one capturing group) cannot be solved in $O(n^{2-\varepsilon} \mathrm{poly}(m))$ time for any constant $\varepsilon &gt; 0$ under the Orthogonal Vectors Conjecture. Moreover, we study the matching problem for regular expressions extended with complement in more detail, which is also known as extended regular expression (ERE) matching. We show that there is no ERE matching algorithm that runs in $O(n^{\omega-\varepsilon} \mathrm{poly}(m))$ time ($2 \le \omega &lt; 2.3714$ is the exponent of square matrix multiplication) for any constant $\varepsilon &gt; 0$ under the $k$-Clique Hypothesis, and there is no combinatorial ERE matching algorithm that runs in $O(n^{3-\varepsilon} \mathrm{poly}(m))$ time for any constant $\varepsilon &gt; 0$ under the Combinatorial $k$-Clique Hypothesis. This shows that the $O(n^3 m)$-time algorithm introduced by Hopcroft and Ullman in 1979 and recently improved by Bille et al. to run in $O(n^\omega m)$ time using fast matrix multiplication was already optimal in a sense, and sheds light on why the theoretical computer science community has struggled to improve the time complexity of ERE matching with respect to $n$ and $m$ for more than 45 years.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03020v2</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>cs.FL</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Taisei Nogami, Tachio Terauchi</dc:creator>
    </item>
    <item>
      <title>A uniformity principle for spatial matching</title>
      <link>https://arxiv.org/abs/2601.13426</link>
      <description>arXiv:2601.13426v3 Announce Type: replace-cross 
Abstract: Platforms matching spatially distributed supply to demand face a fundamental design choice: given a fixed total budget of service range, how should it be allocated across supply nodes ex ante, i.e. before supply and demand locations are realized, to maximize fulfilled demand? We model this problem using bipartite random geometric graphs where $n$ supply and $m$ demand nodes are uniformly distributed on $[0,1]^k$ ($k \ge 1$), and edges form when demand falls within a supply node's service region, the volume of which is determined by its service range. Since each supply node serves at most one demand, platform performance is determined by the expected size of a maximum matching. We establish a uniformity principle: whenever one service range allocation is more uniform than the other, the more uniform allocation yields a larger expected matching. This principle emerges from diminishing marginal returns to range expanding service range, and limited interference between supply nodes due to bounded ranges naturally fragmenting the graph. For $k=1$, we further characterize the expected matching size through a Markov chain embedding and derive closed-form expressions for special cases. Our results provide theoretical guidance for service-range allocation and incentive design in ride-hailing, on-demand labor markets, and drone delivery platforms, highlighting the benefits of reducing disparities in supply-side flexibility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.13426v3</guid>
      <category>math.PR</category>
      <category>cs.DS</category>
      <category>econ.GN</category>
      <category>math.OC</category>
      <category>q-fin.EC</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Taha Ameen, Flore Sentenac, Sophie H. Yu</dc:creator>
    </item>
  </channel>
</rss>
