<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 17 May 2024 04:00:06 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 17 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Zero-shot counting with a dual-stream neural network model</title>
      <link>https://arxiv.org/abs/2405.09953</link>
      <description>arXiv:2405.09953v1 Announce Type: new 
Abstract: Deep neural networks have provided a computational framework for understanding object recognition, grounded in the neurophysiology of the primate ventral stream, but fail to account for how we process relational aspects of a scene. For example, deep neural networks fail at problems that involve enumerating the number of elements in an array, a problem that in humans relies on parietal cortex. Here, we build a 'dual-stream' neural network model which, equipped with both dorsal and ventral streams, can generalise its counting ability to wholly novel items ('zero-shot' counting). In doing so, it forms spatial response fields and lognormal number codes that resemble those observed in macaque posterior parietal cortex. We use the dual-stream network to make successful predictions about behavioural studies of the human gaze during similar counting tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.09953v1</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jessica A. F. Thompson, Hannah Sheahan, Tsvetomira Dumbalska, Julian Sandbrink, Manuela Piazza, Christopher Summerfield</dc:creator>
    </item>
    <item>
      <title>A quality control analysis of the resting state hypothesis via permutation entropy on EEG recordings</title>
      <link>https://arxiv.org/abs/2405.10035</link>
      <description>arXiv:2405.10035v1 Announce Type: new 
Abstract: The analysis of electrophysiological recordings of the human brain in resting state is a key experimental technique in neuroscience. Resting state is indeed the default condition to characterize brain dynamics. Its successful implementation relies both on the capacity of subjects to comply with the requirement of staying awake while not performing any cognitive task, and on the capacity of the experimenter to validate that compliance. Here we propose a novel approach, based on permutation entropy, to provide a quality control of the resting state condition by evaluating its stability during a recording. We combine the calculation of permutation entropy with a method for the estimation of its uncertainty out of a single time series, thus enabling a statistically robust assessment of resting state stationarity. The approach is showcased on electroencephalographic data recorded from young and elderly subjects and considering both eyes-closed and eyes-opened resting state conditions. Besides showing the reliability of the approach, the results showed higher instability in elderly subjects that hint at a qualitative difference between the two age groups with regard to the distribution of unstable activity within the brain. The method is therefore a tool that provides insights on the issue of resting state stability of interest for neuroscience experiments. The method can be applied to other kinds of electrophysiological data like, for example, magnetoencephalographic recordings. In addition, provided that suitable hardware and software processing units are used, its implementation, which consists here of a posteriori analysis, can be translated into a real time one.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10035v1</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alessio Perinelli, Leonardo Ricci</dc:creator>
    </item>
    <item>
      <title>Spurious reconstruction from brain activity</title>
      <link>https://arxiv.org/abs/2405.10078</link>
      <description>arXiv:2405.10078v1 Announce Type: new 
Abstract: Advances in brain decoding, particularly visual image reconstruction, have sparked discussions about the societal implications and ethical considerations of neurotechnology. As these methods aim to recover visual experiences from brain activity and achieve prediction beyond training samples (zero-shot prediction), it is crucial to assess their capabilities and limitations to inform public expectations and regulations. Our case study of recent text-guided reconstruction methods, which leverage a large-scale dataset (NSD) and text-to-image diffusion models, reveals limitations in their generalizability. We found decreased performance when applying these methods to a different dataset designed to prevent category overlaps between training and test sets. UMAP visualization of the text features with NSD images showed limited diversity of semantic and visual clusters, with overlap between training and test sets. Formal analysis and simulations demonstrated that clustered training samples can lead to "output dimension collapse," restricting predictable output feature dimensions. Diversifying the training set improved generalizability. However, text features alone are insufficient for mapping to the visual space. We argue that recent photo-like reconstructions may primarily be a blend of classification into trained categories and generation of inauthentic images through text-to-image diffusion (hallucination). Diverse datasets and compositional representations spanning the image space are essential for genuine zero-shot prediction. Interdisciplinary discussions grounded in understanding the current capabilities and limitations, as well as ethical considerations, of the technology are crucial for its responsible development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10078v1</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ken Shirakawa, Yoshihiro Nagano, Misato Tanaka, Shuntaro C. Aoki, Kei Majima, Yusuke Muraki, Yukiyasu Kamitani</dc:creator>
    </item>
    <item>
      <title>Spatial Cognition: a Wave Hypothesis</title>
      <link>https://arxiv.org/abs/2405.10112</link>
      <description>arXiv:2405.10112v1 Announce Type: new 
Abstract: Animals build Bayesian 3D models of their surroundings, to control their movements. There is strong selection pressure to make these models as precise as possible, given their sense data. A previous paper has described how a precise 3D model of space can be built by object tracking. This only works if 3D locations are stored with high spatial precision. Neural models of 3D spatial memory have large random errors; too large to support the tracking model. An alternative is described, in which neurons couple to a wave excitation in the brain, representing 3-D space. This can give high spatial precision, fast response, and other benefits. Three lines of evidence support the wave hypothesis: (1) it has better precision and speed than neural spatial memory, and is good enough to support object tracking; (2) the central body of the insect brain, whose form is highly conserved across all insect species, is well suited to hold a wave; and (3) the thalamus, whose round shape is conserved across all mammal species, is well suited to hold a wave. These lines of evidence strongly support the wave hypothesis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10112v1</guid>
      <category>q-bio.NC</category>
      <category>q-bio.PE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Robert Worden</dc:creator>
    </item>
    <item>
      <title>Cerebralization of mathematical quantities and physical features in neural science: a critical evaluation</title>
      <link>https://arxiv.org/abs/2405.08391</link>
      <description>arXiv:2405.08391v2 Announce Type: replace 
Abstract: At the turn of the 20th century, Henri Poincar{\'e} explained that geometry is a convention and that the properties of space and time are the properties of our measuring instruments. Intriguingly, numerous contemporary authors argue that space, time and even number are ''encoded'' within the brain, as a consequence of evolution, adaptation and natural selection. In the neuroscientific study of movement generation, the activity of neurons would ''encode'' kinematic parameters: when they emit action potentials, neurons would ''speak'' a language carrying notions of classical mechanics. In this article, we shall explain that the movement of a body segment is the ultimate product of a measurement, a filtered numerical outcome of multiple processes taking place in parallel in the central nervous system and converging on the groups of neurons responsible for muscle contractions. The fact that notions of classical mechanics efficiently describe movements does not imply their implementation in the inner workings of the brain. Their relevance to the question how the brain activity enables one to produce accurate movements is questioned within the framework of the neurophysiology of orienting gaze movements toward a visual target.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.08391v2</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Laurent Goffart (CGGG)</dc:creator>
    </item>
    <item>
      <title>Action potential propagation properties of 4D, 3D and 2D Hodgkin-Huxley type models</title>
      <link>https://arxiv.org/abs/2402.16711</link>
      <description>arXiv:2402.16711v3 Announce Type: replace-cross 
Abstract: We explore the relationship between the sodium and potassium gating variables in the Hodgkin-Huxley electrophysiology model, reducing the dimension of the original 4-dimensional (4D) HH model and decreasing the complexity of the model equations. New 3D and 2D model equations have been derived. The new 3D and 2D models result from the relationship $h\simeq c-n$, where $c$ is a constant, of the gate variables $h$ and $n$ of the 4D HH model, suggesting an interdependence between the dynamics of the Na$^+$ and K$^+$ transmembrane pumps. We have derived the main properties of the propagation speed and width of action potentials for axons with Na$^+$ and K$^+$ active channels as a function of the transmembrane capacity $C_m$ and resistivity $R$ of the conducting axon. For the three HH type models, we show that the action potential propagates along the axon with speed well described by $v(R, C_m)=\alpha /({C_m R^{\beta}})=\gamma D^{\beta}$, where $\alpha&gt;0 $, $0&lt;\beta &lt;1$ and $\gamma$ are constants independent of the local intensity stimulus, and $D$ is the diffusion coefficient of the axon. The width $w$ of the action potential spikes depends on the resistivity of the axon with $w = \alpha_2 /R^{\beta_2}$, where $\alpha_2$ and $\beta_2$ are positive constants.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.16711v3</guid>
      <category>physics.bio-ph</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>L\'izia Branco, Rui Dil\~ao</dc:creator>
    </item>
  </channel>
</rss>
