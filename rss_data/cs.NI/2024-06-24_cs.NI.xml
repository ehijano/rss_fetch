<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 25 Jun 2024 04:00:14 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 25 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Root Cause Analysis of Anomalies in 5G RAN Using Graph Neural Network and Transformer</title>
      <link>https://arxiv.org/abs/2406.15638</link>
      <description>arXiv:2406.15638v1 Announce Type: new 
Abstract: The emergence of 5G technology marks a significant milestone in developing telecommunication networks, enabling exciting new applications such as augmented reality and self-driving vehicles. However, these improvements bring an increased management complexity and a special concern in dealing with failures, as the applications 5G intends to support heavily rely on high network performance and low latency. Thus, automatic self-healing solutions have become effective in dealing with this requirement, allowing a learning-based system to automatically detect anomalies and perform Root Cause Analysis (RCA). However, there are inherent challenges to the implementation of such intelligent systems. First, there is a lack of suitable data for anomaly detection and RCA, as labelled data for failure scenarios is uncommon. Secondly, current intelligent solutions are tailored to LTE networks and do not fully capture the spatio-temporal characteristics present in the data. Considering this, we utilize a calibrated simulator, Simu5G, and generate open-source data for normal and failure scenarios. Using this data, we propose Simba, a state-of-the-art approach for anomaly detection and root cause analysis in 5G Radio Access Networks (RANs). We leverage Graph Neural Networks to capture spatial relationships while a Transformer model is used to learn the temporal dependencies of the data. We implement a prototype of Simba and evaluate it over multiple failures. The outcomes are compared against existing solutions to confirm the superiority of Simba.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15638v1</guid>
      <category>cs.NI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Antor Hasan, Conrado Boeira, Khaleda Papry, Yue Ju, Zhongwen Zhu, Israat Haque</dc:creator>
    </item>
    <item>
      <title>Dyna-5G: A Dynamic, Flexible, and Self-Organizing 5G Network for M2M Ecosystems</title>
      <link>https://arxiv.org/abs/2406.15681</link>
      <description>arXiv:2406.15681v1 Announce Type: new 
Abstract: In this work, we present Dyna-5G, a dynamic, self-organizing 5G New Radio (5G-NR) network designed for massive Machine-to-Machine (M2M) networks. Traditional 5G NR networks, characterized by their centralized architecture, face challenges in supporting applications that require dynamic, decentralized communication, such as autonomous vehicles and drone swarms for emergency responses. These scenarios often suffer from the centralized model's single point of failure, undermining the reliability required in critical and fully autonomous applications. Dyna-5G addresses these challenges by allowing each device in the network to function as either part of the Radio Access Network (RAN) and Core Network, or as User Equipment (UE), thus maintaining network functionality even when conventional infrastructure components are compromised. Dyna-5G has built-in mechanisms carefully designed specifically for M2M networks, such as failure-recovery and ad-hoc entry and exit. We demonstrate the performance and feasibility of Dyna-5G using a custom-built testbed that simulates real-world missions, demonstrating our network's robustness, adaptability, and failure recovery capabilities. The results indicate that our entire 5G network model can fully re-organize in 6 seconds at maximum, without compromising the mission.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15681v1</guid>
      <category>cs.NI</category>
      <category>cs.ET</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Evangelos Bitsikas, Adam Belfki, Aanjhan Ranganathan</dc:creator>
    </item>
    <item>
      <title>Shaping Radio Access to Match Variable Wireless Fronthaul Quality in Next-Generation Networks</title>
      <link>https://arxiv.org/abs/2406.15899</link>
      <description>arXiv:2406.15899v1 Announce Type: new 
Abstract: The emergence of Centralized-RAN (C-RAN) has revolutionized mobile network infrastructure, offering streamlined cell-site engineering and enhanced network management capabilities. As C-RAN gains momentum, the focus shifts to optimizing fronthaul links. While fiber fronthaul guarantees performance, wireless alternatives provide cost efficiency and scalability, making them preferable in densely urbanized areas. However, wireless fronthaul often requires expensive over-dimensioning to overcome the challenging atmospheric attenuation typical of high frequencies. We propose a framework designed to continuously align radio access capacity with fronthaul link quality to overcome this rigidity. By gradually adapting radio access capacity to available fronthaul capacity, the framework ensures smooth degradation rather than complete service loss. Various strategies are proposed, considering factors like functional split and beamforming technology and exploring the tradeoff between adaptation strategy complexity and end-to-end system performance. Numerical evaluations using experimental rain attenuation data illustrate the framework's effectiveness in optimizing radio access capacity under realistically variable fronthaul link quality, ultimately proving the importance of adaptive capacity management in maximizing C-RAN efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15899v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marcello Morini, Eugenio Moro, Ilario Filippini, Danilo De Donno, Antonio Capone</dc:creator>
    </item>
    <item>
      <title>OpticGAI: Generative AI-aided Deep Reinforcement Learning for Optical Networks Optimization</title>
      <link>https://arxiv.org/abs/2406.15906</link>
      <description>arXiv:2406.15906v1 Announce Type: new 
Abstract: Deep Reinforcement Learning (DRL) is regarded as a promising tool for optical network optimization. However, the flexibility and efficiency of current DRL-based solutions for optical network optimization require further improvement. Currently, generative models have showcased their significant performance advantages across various domains. In this paper, we introduce OpticGAI, the AI-generated policy design paradigm for optical networks. In detail, it is implemented as a novel DRL framework that utilizes generative models to learn the optimal policy network. Furthermore, we assess the performance of OpticGAI on two NP-hard optical network problems, Routing and Wavelength Assignment (RWA) and dynamic Routing, Modulation, and Spectrum Allocation (RMSA), to show the feasibility of the AI-generated policy paradigm. Simulation results have shown that OpticGAI achieves the highest reward and the lowest blocking rate of both RWA and RMSA problems. OpticGAI poses a promising direction for future research on generative AI-enhanced flexible optical network optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15906v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siyuan Li, Xi Lin, Yaju Liu, Gaolei Li, Jianhua Li</dc:creator>
    </item>
    <item>
      <title>X5G: An Open, Programmable, Multi-vendor, End-to-end, Private 5G O-RAN Testbed with NVIDIA ARC and OpenAirInterface</title>
      <link>https://arxiv.org/abs/2406.15935</link>
      <description>arXiv:2406.15935v1 Announce Type: new 
Abstract: As Fifth generation (5G) cellular systems transition to softwarized, programmable, and intelligent networks, it becomes fundamental to enable public and private 5G deployments that are (i) primarily based on software components while (ii) maintaining or exceeding the performance of traditional monolithic systems and (iii) enabling programmability through bespoke configurations and optimized deployments. This requires hardware acceleration to scale the Physical (PHY) layer performance, programmable elements in the Radio Access Network (RAN) and intelligent controllers at the edge, careful planning of the Radio Frequency (RF) environment, as well as end-to-end integration and testing. In this paper, we describe how we developed the programmable X5G testbed, addressing these challenges through the deployment of the first 8-node network based on the integration of NVIDIA Aerial RAN CoLab (ARC), OpenAirInterface (OAI), and a near-real-time RAN Intelligent Controller (RIC). The Aerial Software Development Kit (SDK) provides the PHY layer, accelerated on Graphics Processing Unit (GPU), with the higher layers from the OAI open-source project interfaced with the PHY through the Small Cell Forum (SCF) Functional Application Platform Interface (FAPI). An E2 agent provides connectivity to the O-RAN Software Community (OSC) near-real-time RIC. We discuss software integration, the network infrastructure, and a digital twin framework for RF planning. We then profile the performance with up to 4 Commercial Off-the-Shelf (COTS) smartphones for each base station with iPerf and video streaming applications, measuring a cell rate higher than 500 Mbps in downlink and 45 Mbps in uplink.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15935v1</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Davide Villa, Imran Khan, Florian Kaltenberger, Nicholas Hedberg, R\'uben Soares da Silva, Stefano Maxenti, Leonardo Bonati, Anupa Kelkar, Chris Dick, Eduardo Baena, Josep M. Jornet, Tommaso Melodia, Michele Polese, Dimitrios Koutsonikolas</dc:creator>
    </item>
    <item>
      <title>A Queuing Envelope Model for Estimating Latency Guarantees in Deterministic Networking Scenarios</title>
      <link>https://arxiv.org/abs/2406.16452</link>
      <description>arXiv:2406.16452v1 Announce Type: new 
Abstract: Accurate estimation of queuing delays is crucial for designing and optimizing communication networks, particularly in the context of Deterministic Networking (DetNet) scenarios. This study investigates the approximation of Internet queuing delays using an M/M/1 envelope model, which provides a simple methodology to find tight upper bounds of real delay percentiles. Real traffic statistics collected at large Internet Exchange Points (like Amsterdam and San Francisco) have been used to fit polynomial regression models for transforming packet queuing delays into the M/M/1 envelope models. We finally propose a methodology for providing delay percentiles in DetNet scenarios where tight latency guarantees need to be assured.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16452v1</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nataliia Koneva, Alfonso S\'anchez-Maci\'an, Jos\'e Alberto Hern\'andez, Farhad Arpanaei, \'Oscar Gonz\'alez de Dios</dc:creator>
    </item>
    <item>
      <title>A Flexible Cryptographic Infrastructure for High-security SDR-based Systems</title>
      <link>https://arxiv.org/abs/2406.15489</link>
      <description>arXiv:2406.15489v1 Announce Type: cross 
Abstract: Military software defined radio (SDR) systems are a major factor in future network-centric operations due to their flexibility and support for more capable radio communications systems. The inherent nature of software-based systems requires a more complex auxiliary infrastructure and multiple independent levels of security compared with typical systems: Secure booting of the SDR device, cryptographically signed software, real time operating platform software as well as radio applications. This technology raises new challenges with respect to the management. The largest impact on SDR deployments is due to the auxiliary cryptographic infrastructure for the security of the software life cycle and the cyclic update of the keys. Compared to conventional radio devices, the SDR system with the cryptographic infrastructure described in this paper reaches a higher security level and is more flexible. The advantage is the possibility to deploy trunked radio system and further waveforms, such as coalition wideband, which will be standardized in the future. Also it is possible to update cryptographic mechanisms. In this work, we analyze the requirements for a high secure SDR deployment and model the life cycle of the components of a deployed SDR node based on the Joint Program Executive Office (JPEO) Software Communication Architecture (SCA).</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15489v1</guid>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1109/MilCIS.2013.6694489</arxiv:DOI>
      <arxiv:journal_reference>Military Communications and Information Systems Conference (MilCIS 2013)</arxiv:journal_reference>
      <dc:creator>Peter Hillmann, Bj\"orn Stelte</dc:creator>
    </item>
    <item>
      <title>Cyclic Scheduler Design for Minimizing Age of Information in Massive Scale Networks Susceptible to Packet Errors</title>
      <link>https://arxiv.org/abs/2406.15541</link>
      <description>arXiv:2406.15541v1 Announce Type: cross 
Abstract: In multi-source status update systems, sources need to be scheduled appropriately to maintain timely communication between each of the sources and the monitor. A cyclic schedule is an age-agnostic schedule in which the sources are served according to a fixed finite transmission pattern, which upon completion, repeats itself. Such a scheme has a low $O(1)$ runtime complexity, which is desirable in large networks. This paper's focus is on designing transmission patterns so as to be used in massive scale networking scenarios involving a very large number of sources, e.g., up to thousands of IoT sources, with service time requirements and weights being heterogeneous in nature. The goal is to minimize the weighted sum age of information (AoI), called weighted AoI, when transmitting users' packets over a channel susceptible to heterogeneous packet errors. The main tool we use is a stochastic modeling framework using either Markov chains (MC) or moment generating functions (MGF), by which we obtain the weighted AoI for a given transmission pattern, which is not straightforward in the presence of packet drops. Using this framework, we provide a lower bound on the weighted AoI for the particular case of two sources, and also an algorithm to attain this lower bound. Then, by using the same framework, we design a cyclic scheduler for general number of sources with reasonable complexity using convex optimization and well-established packet spreading algorithms, and comparatively evaluate the proposed algorithm and existing age-agnostic scheduling schemes for general number of sources (resp.~two sources) when the lower bound is not available (resp.~when it is available). We present extensive numerical results to validate the effectiveness of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15541v1</guid>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>cs.PF</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sahan Liyanaarachchi, Sennur Ulukus, Nail Akar</dc:creator>
    </item>
    <item>
      <title>Ten Years of ZMap</title>
      <link>https://arxiv.org/abs/2406.15585</link>
      <description>arXiv:2406.15585v1 Announce Type: cross 
Abstract: Since ZMap's debut in 2013, networking and security researchers have used the open-source scanner to write hundreds of research papers that study Internet behavior. In addition, ZMap powers much of the attack-surface management and security ratings industries, and more than a dozen security companies have built products on top of ZMap. Behind the scenes, much of ZMap's behavior - ranging from its pseudorandom IP generation to its packet construction - has quietly evolved as we have learned more about how to scan the Internet. In this work, we quantify ZMap's adoption over the ten years since its release, describe its modern behavior (and the measurements that motivated those changes), and offer lessons from releasing and maintaining ZMap.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15585v1</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zakir Durumeric, David Adrian, Phillip Stephens, Eric Wustrow, J. Alex Halderman</dc:creator>
    </item>
    <item>
      <title>The Case for Transport-Level Encryption in Datacenter Networks</title>
      <link>https://arxiv.org/abs/2406.15686</link>
      <description>arXiv:2406.15686v1 Announce Type: cross 
Abstract: Cloud applications need network data encryption to isolate from other tenants and protect their data from potential eavesdroppers in the network infrastructure. This paper presents SDP, a protocol design for emerging datacenter transport protocols, such as pHost, NDP, and Homa, to integrate data encryption with the use of existing NIC offloading of cryptographic operations designed for TLS over TCP. Therefore, SDP could enable a deployment path of new transport protocols in datacenters without giving up hardware offloading support, which would otherwise make encryption on those protocols even slower than TLS over TCP. SDP is based on Homa, and outperforms TLS over TCP by up to 29 % in throughput. SDP currently supports two real-world applications, Redis, improving throughput by up to 24 %, and in-kernel NVMe-oF, cutting P99 latency by up to 21 %.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15686v1</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tianyi Gao, Xinshu Ma, Suhas Narreddy, Eugenio Luo, Steven W. D. Chien, Michio Honda</dc:creator>
    </item>
    <item>
      <title>Automatic AI Model Selection for Wireless Systems: Online Learning via Digital Twinning</title>
      <link>https://arxiv.org/abs/2406.15819</link>
      <description>arXiv:2406.15819v1 Announce Type: cross 
Abstract: In modern wireless network architectures, such as O-RAN, artificial intelligence (AI)-based applications are deployed at intelligent controllers to carry out functionalities like scheduling or power control. The AI "apps" are selected on the basis of contextual information such as network conditions, topology, traffic statistics, and design goals. The mapping between context and AI model parameters is ideally done in a zero-shot fashion via an automatic model selection (AMS) mapping that leverages only contextual information without requiring any current data. This paper introduces a general methodology for the online optimization of AMS mappings. Optimizing an AMS mapping is challenging, as it requires exposure to data collected from many different contexts. Therefore, if carried out online, this initial optimization phase would be extremely time consuming. A possible solution is to leverage a digital twin of the physical system to generate synthetic data from multiple simulated contexts. However, given that the simulator at the digital twin is imperfect, a direct use of simulated data for the optimization of the AMS mapping would yield poor performance when tested in the real system. This paper proposes a novel method for the online optimization of AMS mapping that corrects for the bias of the simulator by means of limited real data collected from the physical system. Experimental results for a graph neural network-based power control app demonstrate the significant advantages of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15819v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiushuo Hou, Matteo Zecchin, Sangwoo Park, Yunlong Cai, Guanding Yu, Kaushik Chowdhury, Osvaldo Simeone</dc:creator>
    </item>
    <item>
      <title>Placing Timely Refreshing Services at the Network Edge</title>
      <link>https://arxiv.org/abs/2406.16280</link>
      <description>arXiv:2406.16280v1 Announce Type: cross 
Abstract: Accommodating services at the network edge is favorable for time-sensitive applications. However, maintaining service usability is resource-consuming in terms of pulling service images to the edge, synchronizing databases of service containers, and hot updates of service modules. Accordingly, it is critical to determine which service to place based on the received user requests and service refreshing (maintaining) cost, which is usually neglected in existing studies. In this work, we study how to cooperatively place timely refreshing services and offload user requests among edge servers to minimize the backhaul transmission costs. We formulate an integer non-linear programming problem and prove its NP-hardness. This problem is highly non-tractable due to the complex spatial-and-temporal coupling effect among service placement, offloading, and refreshing costs. We first decouple the problem in the temporal domain by transforming it into a Markov shortest-path problem. We then propose a light-weighted Discounted Value Approximation (DVA) method, which further decouples the problem in the spatial domain by estimating the offloading costs among edge servers. The worst performance of DVA is proved to be bounded. 5G service placement testbed experiments and real-trace simulations show that DVA reduces the total transmission cost by up to 59.1% compared with the state-of-the-art baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16280v1</guid>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/JIOT.2023.3268308</arxiv:DOI>
      <dc:creator>Xishuo Li, Shan Zhang, Hongbin Luo, Xiao Ma, Junyi He</dc:creator>
    </item>
    <item>
      <title>Never Gonna Give You Up: Exploring Deprecated NULL Ciphers in Commercial VoWiFi Deployments</title>
      <link>https://arxiv.org/abs/2406.12348</link>
      <description>arXiv:2406.12348v2 Announce Type: replace 
Abstract: In today's cellular network evolutions, such as 4G and 5G, the IMS (IP Multimedia Subsystem) serves as a crucial component in managing voice calls and handling short messages. Besides accessing the IMS over the traditional radio layer, many operators use Voice over Wi-Fi (VoWiFi) allowing customers to dial into their core network over the public Internet using an (insecure) Wi-Fi connection.
  To protect against malicious actors on the WiFi or Internet domain, the traffic is sent over a series of IPsec tunnels, ensuring confidentiality and integrity. Similar to other encrypted protocols (e.g. TLS), the client and server use a handshake protocol (i.e., IKEv2) to communicate their supported security configurations and to agree upon the used parameters (e.g., keys or an encryption algorithm) for the ongoing session. This however opens the door for security vulnerabilities introduced by misconfiguration.
  We want to analyze security configurations within commercial VoWiFi deployments, both on the client and server side, spotting deprecated configurations that undermine communication security.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12348v2</guid>
      <category>cs.NI</category>
      <category>cs.CR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>17th ACM Conference on Security and Privacy in Wireless and Mobile Networks (WiSec 2024)</arxiv:journal_reference>
      <dc:creator>Gabriel Karl Gegenhuber, Philipp Frenzel, Edgar Weippl</dc:creator>
    </item>
    <item>
      <title>Learning and Communications Co-Design for Remote Inference Systems: Feature Length Selection and Transmission Scheduling</title>
      <link>https://arxiv.org/abs/2308.10094</link>
      <description>arXiv:2308.10094v3 Announce Type: replace-cross 
Abstract: In this paper, we consider a remote inference system, where a neural network is used to infer a time-varying target (e.g., robot movement), based on features (e.g., video clips) that are progressively received from a sensing node (e.g., a camera). Each feature is a temporal sequence of sensory data. The inference error is determined by (i) the timeliness and (ii) the sequence length of the feature, where we use Age of Information (AoI) as a metric for timeliness. While a longer feature can typically provide better inference performance, it often requires more channel resources for sending the feature. To minimize the time-averaged inference error, we study a learning and communication co-design problem that jointly optimizes feature length selection and transmission scheduling. When there is a single sensor-predictor pair and a single channel, we develop low-complexity optimal co-designs for both the cases of time-invariant and time-variant feature length. When there are multiple sensor-predictor pairs and multiple channels, the co-design problem becomes a restless multi-arm multi-action bandit problem that is PSPACE-hard. For this setting, we design a low-complexity algorithm to solve the problem. Trace-driven evaluations demonstrate the potential of these co-designs to reduce inference error by up to 10000 times.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.10094v3</guid>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/JSAIT.2023.3322620</arxiv:DOI>
      <arxiv:journal_reference>IEEE Journal on Selected Areas in Information Theory, vol. 4, pp. 524-538, 2023</arxiv:journal_reference>
      <dc:creator>Md Kamran Chowdhury Shisher, Bo Ji, I-Hong Hou, Yin Sun</dc:creator>
    </item>
  </channel>
</rss>
