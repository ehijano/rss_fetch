<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 05 Dec 2025 05:00:26 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Human-Centred Evaluation of Text-to-Image Generation Models for Self-expression of Mental Distress: A Dataset Based on GPT-4o</title>
      <link>https://arxiv.org/abs/2512.04087</link>
      <description>arXiv:2512.04087v1 Announce Type: new 
Abstract: Effective communication is central to achieving positive healthcare outcomes in mental health contexts, yet international students often face linguistic and cultural barriers that hinder their communication of mental distress. In this study, we evaluate the effectiveness of AI-generated images in supporting self-expression of mental distress. To achieve this, twenty Chinese international students studying at UK universities were invited to describe their personal experiences of mental distress. These descriptions were elaborated using GPT-4o with four persona-based prompt templates rooted in contemporary counselling practice to generate corresponding images. Participants then evaluated the helpfulness of generated images in facilitating the expression of their feelings based on their original descriptions. The resulting dataset comprises 100 textual descriptions of mental distress, 400 generated images, and corresponding human evaluation scores. Findings indicate that prompt design substantially affects perceived helpfulness, with the illustrator persona achieving the highest ratings. This work introduces the first publicly available text-to-image evaluation dataset with human judgment scores in the mental health domain, offering valuable resources for image evaluation, reinforcement learning with human feedback, and multi-modal research on mental health communication.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.04087v1</guid>
      <category>q-bio.NC</category>
      <category>cs.CL</category>
      <category>cs.CV</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sui He, Shenbin Qian</dc:creator>
    </item>
    <item>
      <title>Limit cycles for speech</title>
      <link>https://arxiv.org/abs/2512.04642</link>
      <description>arXiv:2512.04642v1 Announce Type: new 
Abstract: Rhythmic fluctuations in acoustic energy and accompanying neuronal excitations in cortical oscillations are characteristic of human speech, yet whether a corresponding rhythmicity inheres in the articulatory movements that generate speech remains unclear. The received understanding of speech movements as discrete, goal-oriented actions struggles to make contact with the rhythmicity findings. In this work, we demonstrate that an unintuitive -- but no less principled than the conventional -- representation for discrete movements reveals a pervasive limit cycle organization and unlocks the recovery of previously inaccessible rhythmic structure underlying the motor activity of speech. These results help resolve a time-honored tension between the ubiquity of biological rhythmicity and discreteness in speech, the quintessential human higher function, by revealing a rhythmic organization at the most fundamental level of individual articulatory actions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.04642v1</guid>
      <category>q-bio.NC</category>
      <category>cs.CL</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adamantios I. Gafos, Stephan R. Kuberski</dc:creator>
    </item>
    <item>
      <title>Setting up for failure: automatic discovery of the neural mechanisms of cognitive errors</title>
      <link>https://arxiv.org/abs/2512.04808</link>
      <description>arXiv:2512.04808v1 Announce Type: new 
Abstract: Discovering the neural mechanisms underpinning cognition is one of the grand challenges of neuroscience. However, previous approaches for building models of RNN dynamics that explain behaviour required iterative refinement of architectures and/or optimisation objectives, resulting in a piecemeal, and mostly heuristic, human-in-the-loop process. Here, we offer an alternative approach that automates the discovery of viable RNN mechanisms by explicitly training RNNs to reproduce behaviour, including the same characteristic errors and suboptimalities, that humans and animals produce in a cognitive task. Achieving this required two main innovations. First, as the amount of behavioural data that can be collected in experiments is often too limited to train RNNs, we use a non-parametric generative model of behavioural responses to produce surrogate data for training RNNs. Second, to capture all relevant statistical aspects of the data, we developed a novel diffusion model-based approach for training RNNs. To showcase the potential of our approach, we chose a visual working memory task as our test-bed, as behaviour in this task is well known to produce response distributions that are patently multimodal (due to swap errors). The resulting network dynamics correctly qualitative features of macaque neural data. Importantly, these results were not possible to obtain with more traditional approaches, i.e., when only a limited set of behavioural signatures (rather than the full richness of behavioural response distributions) were fitted, or when RNNs were trained for task optimality (instead of reproducing behaviour). Our approach also yields novel predictions about the mechanism of swap errors, which can be readily tested in experiments. These results suggest that fitting RNNs to rich patterns of behaviour provides a powerful way to automatically discover mechanisms of important cognitive functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.04808v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Puria Radmard, Paul M. Bays, M\'at\'e Lengyel</dc:creator>
    </item>
    <item>
      <title>Influence of Object Affordance on Action Language Understanding: Evidence from Dynamic Causal Modeling Analysis</title>
      <link>https://arxiv.org/abs/2512.04989</link>
      <description>arXiv:2512.04989v1 Announce Type: new 
Abstract: This study investigates the causal neural dynamics by which affordance representations influence action language comprehension. In this study, 18 participants observed stimuli displayed in two conditions during the experiment: text-only (e.g., `Hit with a hammer') and video+text (visual clips with matching phrases). EEG data were recorded from 32 channels and analyzed for event-related potentials and source localization using LORETA, which identified four left-hemisphere regions of interest: the Lateral Occipital Cortex (LOC), Posterior Superior Temporal Gyrus (pSTG), Ventral Premotor Cortex (PMv), and Inferior Parietal Lobule (IPL). A space of dynamic causal modeling (DCM) was constructed with driving inputs to LOC and pSTG, and multiple connectivity configurations were tested. Bayesian Model Selection revealed a dominant model in which PMv causally influenced IPL and pSTG, reflecting a feedforward architecture from affordance-related motor regions to semantic hubs. Bayesian Model Averaging further confirmed strong endogenous connections from LOC to PMv and IPL, and significant modulation from PMv to IPL. These findings provide direct evidence that affordance processing in premotor regions drives action language understanding by engaging downstream parietal and temporal areas. The results support grounded cognition theories and offer a mechanistic account of how sensorimotor information contributes to linguistic comprehension.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.04989v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Supriya Bordoloi, Cota Navin Gupta, Shyamanta M. Hazarika</dc:creator>
    </item>
    <item>
      <title>Revealing stimulus-dependent dynamics through statistical complexity</title>
      <link>https://arxiv.org/abs/2512.05007</link>
      <description>arXiv:2512.05007v1 Announce Type: new 
Abstract: Advances in large-scale neural recordings have expanded our ability to describe the activity of distributed brain circuits. However, understanding how neural population dynamics differ across regions and behavioral contexts remains challenging. Here, we surveyed neuronal population dynamics across multiple mouse brain areas (visual cortex, hippocampus, thalamus, and midbrain) using spike data from local ensembles. Two complementary measures were used to characterize these dynamics: the coefficient of variation (CV), a classical indicator of spike-time variability, and statistical complexity, an information-theoretic quantifier of organizational structure. To probe stimulus-dependent activity, we segmented and concatenated recordings from behavioral experiments into distinct time series corresponding to natural image presentations, blank screens during visual task, and spontaneous activity. While the CV failed to discriminate between these conditions, statistical complexity revealed clear, stimulus-specific motifs in population activity. These results indicate that information-theoretic measures can uncover structured, stimulus-dependent patterns in neural population dynamics that remain unobserved in traditional variability metrics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05007v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Edson V. de Paula, Rafael M. Jungmann, Antonio J. Fontenele, Leandro A. A. Aguiar, Pedro V. Carelli, Fernanda S. Matias, Mauro Copelli, Nivaldo A. P. de Vasconcelos</dc:creator>
    </item>
    <item>
      <title>Covering Relations in the Poset of Combinatorial Neural Codes</title>
      <link>https://arxiv.org/abs/2512.04241</link>
      <description>arXiv:2512.04241v1 Announce Type: cross 
Abstract: A combinatorial neural code is a subset of the power set $2^{[n]}$ on $[n]=\{1,\dots, n\}$, in which each $1\leq i\leq n$ represents a neuron and each element (codeword) represents the co-firing event of some neurons. Consider a space $X\subseteq\mathbb{R}^d$, simulating an animal's environment, and a collection $\mathcal{U}=\{U_1,\dots,U_n\}$ of open subsets of $X$. Each $U_i\subseteq X$ simulates a place field which is a specific region where a place cell $i$ is active. Then, the code of $\mathcal{U}$ in $X$ is defined as $\text{code}(\mathcal{U},X)=\left\{\sigma\subseteq[n]\bigg|\bigcap_{i\in\sigma} U_i\setminus\bigcup_{j\notin\sigma}U_j\neq\varnothing\right\}$. If a neural code $\mathcal{C}=\text{code}(\mathcal{U},X)$ for some $X$ and $\mathcal{U}$, we say $\mathcal{C}$ has a realization of open subsets of some space $X$. Although every combinatorial neural code obviously has a realization by some open subsets, determining whether it has a realization by some open convex subsets remains unsolved. Many studies attempted to tackle this decision problem, but only partial results were achieved. In fact, a previous study showed that the decision problem of convex neural codes is NP-hard. Furthermore, the authors of this study conjectured that every convex neural code can be realized as a minor of a neural code arising from a representable oriented matroid, which can lead to an equivalence between convex and polytope convex neural codes. Even though this conjecture has been confirmed in dimension two, its validity in higher dimensions is still unknown. To advance the investigation of this conjecture, we provide a complete characterization of the covering relations within the poset $\mathbf{P_{Code}}$ of neural codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.04241v1</guid>
      <category>math.CO</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>R. Amzi Jeffs, Trong-Thuc Trang</dc:creator>
    </item>
    <item>
      <title>RNNs perform task computations by dynamically warping neural representations</title>
      <link>https://arxiv.org/abs/2512.04310</link>
      <description>arXiv:2512.04310v1 Announce Type: cross 
Abstract: Analysing how neural networks represent data features in their activations can help interpret how they perform tasks. Hence, a long line of work has focused on mathematically characterising the geometry of such "neural representations." In parallel, machine learning has seen a surge of interest in understanding how dynamical systems perform computations on time-varying input data. Yet, the link between computation-through-dynamics and representational geometry remains poorly understood. Here, we hypothesise that recurrent neural networks (RNNs) perform computations by dynamically warping their representations of task variables. To test this hypothesis, we develop a Riemannian geometric framework that enables the derivation of the manifold topology and geometry of a dynamical system from the manifold of its inputs. By characterising the time-varying geometry of RNNs, we show that dynamic warping is a fundamental feature of their computations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.04310v1</guid>
      <category>cs.LG</category>
      <category>math.DG</category>
      <category>math.DS</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arthur Pellegrino, Angus Chadwick</dc:creator>
    </item>
    <item>
      <title>Developing a General Personal Tutor for Education</title>
      <link>https://arxiv.org/abs/2512.04869</link>
      <description>arXiv:2512.04869v1 Announce Type: cross 
Abstract: The vision of a universal AI tutor has remained elusive, despite decades of effort. Could LLMs be the game-changer? We overview novel issues arising from developing a nationwide AI tutor. We highlight the practical questions that point to specific gaps in our scientific understanding of the learning process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.04869v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.tics.2025.09.010</arxiv:DOI>
      <arxiv:journal_reference>Aru, J., &amp; Laak, K. J. (2025). Developing an AI-based General Personal Tutor for education. Trends in Cognitive Sciences, 29 (11),957-960</arxiv:journal_reference>
      <dc:creator>Jaan Aru, Kristjan-Julius Laak</dc:creator>
    </item>
    <item>
      <title>The Copernican Argument for Alien Consciousness; The Mimicry Argument Against Robot Consciousness</title>
      <link>https://arxiv.org/abs/2412.00008</link>
      <description>arXiv:2412.00008v2 Announce Type: replace 
Abstract: On broadly Copernican grounds, we are entitled to assume that apparently behaviorally sophisticated extraterrestrial entities ("aliens") would be conscious. Otherwise, we humans would be inexplicably, implausibly lucky to have consciousness, while similarly behaviorally sophisticated entities elsewhere would be mere shells, devoid of consciousness. However, this Copernican default assumption is canceled in the case of behaviorally sophisticated entities designed to mimic superficial features associated with consciousness ("consciousness mimics"), and in particular a broad class of current, near-future, and hypothetical robots. These considerations, which we formulate, respectively, as the Copernican and Mimicry Arguments, jointly defeat an otherwise potentially attractive parity principle, according to which we should apply the same types of behavioral or cognitive tests to aliens and robots, attributing or denying consciousness similarly to the extent they perform similarly. Our approach is unusual in the following respect: Instead of grounding speculations about alien and robot consciousness in a particular metaphysical or scientific theory about the physical or functional bases of consciousness, we appeal directly to the epistemic principles of Copernican mediocrity and inference to the best explanation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00008v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Eric Schwitzgebel, Jeremy Pober</dc:creator>
    </item>
    <item>
      <title>BrainPath: A Biologically-Informed AI Framework for Individualized Aging Brain Generation</title>
      <link>https://arxiv.org/abs/2508.16667</link>
      <description>arXiv:2508.16667v3 Announce Type: replace 
Abstract: The global population is aging rapidly, and aging is a major risk factor for various diseases. It is an important task to predict how each individual's brain will age, as the brain supports many human functions. This capability can greatly facilitate healthcare automation by enabling personalized, proactive intervention and efficient healthcare resource allocation. However, this task is extremely challenging because of the brain's complex 3D anatomy. While there have been successes in natural image generation and brain MRI synthesis, existing methods fall short in generating individualized, anatomically faithful aging brain trajectories. To address these gaps, we propose BrainPath, a novel AI model that, given a single structural MRI of an individual, generates synthetic longitudinal MRIs that represent that individual's expected brain anatomy as they age. BrainPath introduces three architectural innovations: an age-aware encoder with biologically grounded supervision, a differential age conditioned decoder for anatomically faithful MRI synthesis, and a swap-learning strategy that implicitly separates stable subject-specific anatomy from aging effects. We further design biologically informed loss functions, including an age calibration loss and an age and structural perceptual loss, to complement the conventional reconstruction loss. This enables the model to capture subtle, temporally meaningful anatomical changes associated with aging. We apply BrainPath to two of the largest public aging datasets and conduct a comprehensive, multifaceted evaluation. Our results demonstrate BrainPath's superior performance in generation accuracy, anatomical fidelity, and cross-dataset generalizability, outperforming competing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16667v3</guid>
      <category>q-bio.NC</category>
      <category>cs.CV</category>
      <category>eess.IV</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yifan Li, Javad Sohankar, Ji Luo, Jing Li, Yi Su</dc:creator>
    </item>
    <item>
      <title>Principles of Physiological Closed-Loop Controllers in Neuromodulation</title>
      <link>https://arxiv.org/abs/2508.11422</link>
      <description>arXiv:2508.11422v2 Announce Type: replace-cross 
Abstract: As neurostimulation devices increasingly incorporate closed-loop functionality, the greater design complexity brings additional requirements for risk management and special considerations to optimise benefit. This manuscript creates a common framework upon which all current and planned neuromodulation-based physiological closed-loop controllers (PCLCs) can be mapped including integration of the Technical Considerations of Medical Devices with Physiologic Closed-Loop Control Technology guidance published in 2023 by the United States Food and Drug Administration (FDA), a classification of feedback (reactive) and feedforward (predictive) biomarkers, and control systems theory. We explain risk management in the context of this framework and illustrate its applications for three exemplary technologies. This manuscript serves as guidance to the emerging field of PCLCs in neuromodulation, mitigating risk through standardized nomenclature and a systematic outline for rigorous device development, testing, and implementation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.11422v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Victoria S. Marks, Joram vanRheede, Dean Karantonis, Rosana Esteller, David Dinsmoor, John Fleming, Barrett Larson, Lane Desborough, Peter Single, Robert Raike, Pierre-Francois DHaese, Dario J. Englot, Scott Lempka, Richard North, Lawrence Poree, Marom Bikson, Tim J. Denison</dc:creator>
    </item>
    <item>
      <title>Mesoscale tissue properties and electric fields in brain stimulation -- bridging the macroscopic and microscopic scales</title>
      <link>https://arxiv.org/abs/2511.16465</link>
      <description>arXiv:2511.16465v3 Announce Type: replace-cross 
Abstract: Accurate simulations of electric fields (E-fields) in brain stimulation depend on tissue conductivity representations that link macroscopic assumptions with underlying microscopic tissue structure. Mesoscale conductivity variations can produce meaningful changes in E-fields and neural activation thresholds but remain largely absent from standard macroscopic models. Recent microscopic models have suggested substantial local E-field perturbations and could, in principle, inform mesoscale conductivity. However, the quantitative validity of microscopic models is limited by fixation-related tissue distortion and incomplete extracellular-space reconstruction. We outline approaches that bridge macro- and microscales to derive consistent mesoscale conductivity distributions, providing a foundation for accurate multiscale models of E-fields and neural activation in brain stimulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16465v3</guid>
      <category>physics.bio-ph</category>
      <category>physics.app-ph</category>
      <category>physics.med-ph</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Boshuo Wang, Torge Worbs, Minhaj A. Hussain, Aman S. Aberra, Axel Thielscher, Warren M. Grill, Angel V. Peterchev</dc:creator>
    </item>
  </channel>
</rss>
