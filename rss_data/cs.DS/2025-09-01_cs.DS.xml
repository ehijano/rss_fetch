<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 01 Sep 2025 04:00:12 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Faster Linear Algebra Algorithms with Structured Random Matrices</title>
      <link>https://arxiv.org/abs/2508.21189</link>
      <description>arXiv:2508.21189v1 Announce Type: new 
Abstract: To achieve the greatest possible speed, practitioners regularly implement randomized algorithms for low-rank approximation and least-squares regression with structured dimension reduction maps. Despite significant research effort, basic questions remain about the design and analysis of randomized linear algebra algorithms that employ structured random matrices.
  This paper develops a new perspective on structured dimension reduction, based on the oblivious subspace injection (OSI) property. The OSI property is a relatively weak assumption on a random matrix that holds when the matrix preserves the length of vectors on average and, with high probability, does not annihilate any vector in a low-dimensional subspace. With the OSI abstraction, the analysis of a randomized linear algebra algorithm factors into two parts: (i) proving that the algorithm works when implemented with an OSI; and (ii) proving that a given random matrix model has the OSI property.
  This paper develops both parts of the program. First, it analyzes standard randomized algorithms for low-rank approximation and least-squares regression under the OSI assumption. Second, it identifies many examples of OSIs, including random sparse matrices, randomized trigonometric transforms, and random matrices with tensor product structure. These theoretical results imply faster, near-optimal runtimes for several fundamental linear algebra tasks. The paper also provides guidance on implementation, along with empirical evidence that structured random matrices offer exemplary performance for a range of synthetic problems and contemporary scientific applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.21189v1</guid>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chris Cama\~no, Ethan N. Epperly, Raphael A. Meyer, Joel A. Tropp</dc:creator>
    </item>
    <item>
      <title>$\Delta$-Motif: Subgraph Isomorphism at Scale via Data-Centric</title>
      <link>https://arxiv.org/abs/2508.21287</link>
      <description>arXiv:2508.21287v1 Announce Type: new 
Abstract: Subgraph isomorphism is a fundamental problem in graph analysis that seeks to find all instances of a pattern graph within a larger data graph while preserving structural relationships. This NP-complete problem is central to domains such as biological network analysis, social network mining, and quantum circuit optimization. Traditional approaches rely on backtracking algorithms like VF2, which suffer from sequential bottlenecks that limit their ability to exploit modern parallel hardware. In this work, we introduce $\Delta$-Motif, a GPU-accelerated subgraph isomorphism algorithm that reformulates the task through the lens of database operations. Our key insight is to represent both data and pattern graphs in tabular form, turning subgraph isomorphism into database primitives including joins, sorts, merges, and filters. $\Delta$-Motif decomposes graphs into small building blocks called motifs and systematically combines them using scalable relational operations. By leveraging mature, optimized libraries from the NVIDIA RAPIDS ecosystem and Pandas framework, our solution achieves massive parallelism while remaining portable across systems supporting standard relational primitives. Benchmarks show that $\Delta$-Motif outperforms established algorithms like VF2, achieving speedups of up to $595\times$ on GPUs. We further demonstrate its impact by applying it to quantum circuit compilation, addressing a critical bottleneck in quantum computing and enabling scaling to near- and medium-term devices. Our approach democratizes high-performance graph processing by exposing it through familiar database abstractions, eliminating the need for low-level programming while delivering exceptional computational efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.21287v1</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yulun Wang, Esteban Ginez, Jamie Friel, Yuval Baum, Jin-Sung Kim, Alex Shih, Oded Green</dc:creator>
    </item>
    <item>
      <title>Some Applications and Limitations of Convex Optimization Hierarchies for Discrete and Continuous Optimization Problems</title>
      <link>https://arxiv.org/abs/2508.21327</link>
      <description>arXiv:2508.21327v1 Announce Type: cross 
Abstract: This thesis explores algorithmic applications and limitations of convex relaxation hierarchies for approximating some discrete and continuous optimization problems.
  - We show a dichotomy of approximability of constraint satisfaction problems (CSPs) by linear programming (LP) relaxations: for every CSP, the approximation obtained by a basic LP relaxation, is no weaker than the approximation obtained using relaxations given by super-constant levels of the Sherali-Adams hierarchy on instances of size $n$.
  - For the problem of approximating the absolute maximum of an n-variate degree-d homogeneous polynomial f with real coefficients over the unit sphere, we analyze the optimum value of the level-t sum-of-squares (SoS) SDP relaxation of the problem. Our results offer a trade-off between the approximation ratio and running time, which can take advantage of additional structure in the polynomial, such as non-negativity or sparsity of the coefficients.
  - We study the problem of approximating the $p \to q$-norm of a matrix $A$, and prove the first NP-hardness result for approximating norms in the hypercontractive case $1&lt; p &lt; q &lt; \infty$. We also prove almost tight algorithmic results for the case when $p \geq q$ (with $2 \in [q,p]$) where constant factor approximations for the matrix norms are possible.
  A common theme for these results is their connection to geometry. For the discrete optimization problem of CSP, geometry appears as a crucial tool for our lower bound proof. For the problem of polynomial optimization, we show that SDPs capture and extend earlier algorithms based on diameter estimation for convex bodies. For the matrix (operator) norm problem, the definition itself is geometric in nature and embedding theorems play a crucial role in our proofs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.21327v1</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mrinalkanti Ghosh</dc:creator>
    </item>
    <item>
      <title>Constructive l2-Discrepancy Minimization with Additive Deviations</title>
      <link>https://arxiv.org/abs/2508.21423</link>
      <description>arXiv:2508.21423v1 Announce Type: cross 
Abstract: The \emph{signed series} problem in the $\ell_2$ norm asks, given set of vectors $v_1,\ldots,v_n\in \mathbf{R}^d$ having at most unit $\ell_2$ norm, does there always exist a series $(\varepsilon_i)_{i\in [n]}$ of $\pm 1$ signs such that for all $i\in [n]$, $\max_{i\in [n]} \|\sum_{j=1}^i \varepsilon_i v_i\|_2 = O(\sqrt{d})$. A result of Banaszczyk [2012, \emph{Rand. Struct. Alg.}] states that there exist signs $\varepsilon_i\in \{-1,1\},\; i\in [n]$ such that $\max_{i\in [n]} \|\sum_{j=1}^i \varepsilon_i v_i\|_2 = O(\sqrt{d+\log n})$. The best constructive bound known so far is of $O(\sqrt{d\log n})$, by Bansal and Garg [2017, \emph{STOC.}, 2019, \emph{SIAM J. Comput.}]. We give a polynomial-time randomized algorithm to find signs $x(i) \in \{-1,1\},\; i\in [n]$ such that \[ \max_{i\in [n]} \|\sum_{j=1}^i x(i)v_i\|_2 = O(\sqrt{d + \log^2 n}) = O(\sqrt{d}+\log n).\] By the constructive reduction of Harvey and Samadi [\emph{COLT}, 2014], this also yields a constructive bound of $O(\sqrt{d}+\log n)$ for the Steinitz problem in the $\ell_2$-norm. Thus, our result settles both conjectures when $d \geq \log^2n$. Our algorithm is based on the framework on Bansal and Garg, together with a new analysis involving $(i)$ additional linear and spectral orthogonality constraints during the construction of the covariance matrix of the random walk steps, which allow us to control the quadratic variation in the linear as well as the quadratic components of the discrepancy increment vector, alongwith $(ii)$ a ``Freedman-like" version of the Hanson-Wright concentration inequality, for filtration-dependent sums of subgaussian chaoses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.21423v1</guid>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.PR</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kunal Dutta</dc:creator>
    </item>
    <item>
      <title>Block Encoding of Sparse Matrices via Coherent Permutation</title>
      <link>https://arxiv.org/abs/2508.21667</link>
      <description>arXiv:2508.21667v1 Announce Type: cross 
Abstract: Block encoding of sparse matrices underpins powerful quantum algorithms such as quantum singular value transformation, Hamiltonian simulation, and quantum linear solvers, but its efficient gate-level implementation for arbitrary sparse matrices remains a major challenge. We introduce a unified framework that overcomes the key obstacles of multi-controlled X gates overhead, amplitude reordering, and hardware connectivity, enabling efficient block encoding for arbitrary sparse matrices with explicit gate-level constructions. Central to our approach are a novel connection with combinatorial optimization, which enables systematic assignment of control qubits to achieve nearest-neighbor connectivity, and coherent permutation operators that preserve superposition while enabling amplitude reordering. We demonstrate our methods on structured sparse matrices, showing significant reductions in circuit depth and control overhead, thereby bridging the gap between theoretical formulations and practical circuit implementations for quantum algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.21667v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abhishek Setty</dc:creator>
    </item>
    <item>
      <title>Hilbert Forest in the SISAP 2025 Indexing Challenge</title>
      <link>https://arxiv.org/abs/2508.21682</link>
      <description>arXiv:2508.21682v1 Announce Type: cross 
Abstract: We report our participation in the SISAP 2025 Indexing Challenge using a novel indexing technique called the Hilbert forest. The method is based on the fast Hilbert sort algorithm, which efficiently orders high-dimensional points along a Hilbert space-filling curve, and constructs multiple Hilbert trees to support approximate nearest neighbor search. We submitted implementations to both Task 1 (approximate search on the PUBMED23 dataset) and Task 2 (k-nearest neighbor graph construction on the GOOAQ dataset) under the official resource constraints of 16 GB RAM and 8 CPU cores. The Hilbert forest demonstrated competitive performance in Task 1 and achieved the fastest construction time in Task 2 while satisfying the required recall levels. These results highlight the practical effectiveness of Hilbert order-based indexing under strict memory limitations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.21682v1</guid>
      <category>cs.DB</category>
      <category>cs.DS</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yasunobu Imamura, Takeshi Shinohara, Naoya Higuchi, Kouichi Hirata, Tetsuji Kuboyama</dc:creator>
    </item>
    <item>
      <title>Deterministic Dynamic Maximal Matching in Sublinear Update Time</title>
      <link>https://arxiv.org/abs/2504.20780</link>
      <description>arXiv:2504.20780v2 Announce Type: replace 
Abstract: We give a fully dynamic deterministic algorithm for maintaining a maximal matching of an $n$-vertex graph in $\tilde{O}(n^{8/9})$ amortized update time. This breaks the long-standing $\Omega(n)$-update-time barrier on dense graphs, achievable by trivially scanning all incident vertices of the updated edge, and affirmatively answers a major open question repeatedly asked in the literature [BGS15, BCHN18, Sol22]. We also present a faster randomized algorithm against an adaptive adversary with $\tilde{O}(n^{3/4})$ amortized update time.
  Our approach employs the edge degree constrained subgraph (EDCS), a central object for optimizing approximation ratio, in a completely novel way; we instead use it for maintaining a matching that matches all high degree vertices in sublinear update time so that it remains to handle low degree vertices rather straightforwardly. To optimize this approach, we employ tools never used in the dynamic matching literature prior to our work, including sublinear-time algorithms for matching high degree vertices, random walks on directed expanders, and the monotone Even-Shiloach tree for dynamic shortest paths.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.20780v2</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aaron Bernstein, Sayan Bhattacharya, Peter Kiss, Thatchaphol Saranurak</dc:creator>
    </item>
  </channel>
</rss>
