<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 17 Sep 2024 04:00:15 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Distributed Binary Optimization with In-Memory Computing: An Application for the SAT Problem</title>
      <link>https://arxiv.org/abs/2409.09152</link>
      <description>arXiv:2409.09152v1 Announce Type: new 
Abstract: In-memory computing (IMC) has been shown to be a promising approach for solving binary optimization problems while significantly reducing energy and latency. Building on the advantages of parallel computation, we propose an IMC-compatible parallelism framework inspired by parallel tempering (PT), enabling cross-replica communication to improve the performance of IMC solvers. This framework enables an IMC solver not only to improve performance beyond what can be achieved through parallelization, but also affords greater flexibility for the search process with low hardware overhead. We justify that the framework can be applied to almost any IMC solver. We demonstrate the effectiveness of the framework for the Boolean satisfiability (SAT) problem, using the WalkSAT heuristic as a proxy for existing IMC solvers. The resulting PT-inspired cooperative WalkSAT (PTIC-WalkSAT) algorithm outperforms the traditional WalkSAT heuristic in terms of the iterations-to-solution in 76.3% of the tested problem instances and its na\"ive parallel variant (PA-WalkSAT) does so in 68.4% of the instances. An estimate of the energy overhead of the PTIC framework for two hardware accelerator architectures indicates that in both cases the overhead of running the PTIC framework would be less than 1% of the total energy required to run each accelerator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.09152v1</guid>
      <category>cs.ET</category>
      <category>cs.AR</category>
      <category>math.OC</category>
      <pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiangyi Zhang, Ignacio Rozada, Fabian B\"ohm, Elisabetta Valiante, Moslem Noori, Thomas Van Vaerenbergh, Chan-Woo Yang, Giacomo Pedretti, Masoud Mohseni, Raymond Beausoleil</dc:creator>
    </item>
    <item>
      <title>Quantum data encoding as a distinct abstraction layer in the design of quantum circuits</title>
      <link>https://arxiv.org/abs/2409.09339</link>
      <description>arXiv:2409.09339v1 Announce Type: new 
Abstract: Complex quantum circuits are constituted by combinations of quantum subroutines. The computation is possible as long as the quantum data encoding is consistent throughout the circuit. Despite its fundamental importance, the formalization of quantum data encoding has never been addressed systematically so far. We formalize the concept of quantum data encoding, namely the format providing a representation of a data set through a quantum state, as a distinct abstract layer with respect to the associated data loading circuit. We survey existing encoding methods and their respective strategies for classical-to-quantum exact and approximate data loading, for the quantum-to-classical extraction of information from states, and for quantum-to-quantum encoding conversion. Next, we show how major quantum algorithms find a natural interpretation in terms of data loading. For instance, the Quantum Fourier Transform is described as a quantum encoding converter, while the Quantum Amplitude Estimation as an extraction routine. The new conceptual framework is exemplified by considering its application to quantum-based Monte Carlo simulations, thus showcasing the power of the proposed formalism for the description of complex quantum circuits. Indeed, the approach clarifies the structure of complex quantum circuits and enables their efficient design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.09339v1</guid>
      <category>cs.ET</category>
      <category>quant-ph</category>
      <pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gabriele Agliardi, Enrico Prati</dc:creator>
    </item>
    <item>
      <title>Exploring Utility in a Real-World Warehouse Optimization Problem: Formulation Based on Quantun Annealers and Preliminary Results</title>
      <link>https://arxiv.org/abs/2409.09706</link>
      <description>arXiv:2409.09706v1 Announce Type: new 
Abstract: In the current NISQ-era, one of the major challenges faced by researchers and practitioners lies in figuring out how to combine quantum and classical computing in the most efficient and innovative way. In this paper, we present a mechanism coined as Quantum Initialization for Warehouse Optimization Problem that resorts to D-Wave's Quantum Annealer. The module has been specifically designed to be embedded into already existing classical software dedicated to the optimization of a real-world industrial problem. We preliminary tested the implemented mechanism through a two-phase experiment against the classical version of the software.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.09706v1</guid>
      <category>cs.ET</category>
      <category>cs.AI</category>
      <pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Eneko Osaba, Esther Villar-Rodriguez, Ant\'on Asla</dc:creator>
    </item>
    <item>
      <title>3D System Design: A Case for Building Customized Modular Systems in 3D</title>
      <link>https://arxiv.org/abs/2409.09068</link>
      <description>arXiv:2409.09068v1 Announce Type: cross 
Abstract: 3D promises a new dimension in composing systems by aggregating chips. Literally. While the most common uses are still tightly connected with its early forms as a packaging technology, new application domains have been emerging. As the underlying technology continues to evolve, the unique leverages of 3D have become increasingly appealing to a larger range of applications: from embedded mobile applications to servers and memory systems. In this paper we focus on the system-level implications of 3D technology, trying to differentiate the unique advantages that it provides to different market segments and applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.09068v1</guid>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>In Proceedings of 2010 IEEE International Interconnect Technology Conference. IEEE, 2010. p. 1-3</arxiv:journal_reference>
      <dc:creator>Philip Emma, Eren Kurshan</dc:creator>
    </item>
    <item>
      <title>Improving the Reliability of Quantum Circuits by Evolving Heterogeneous Ensembles</title>
      <link>https://arxiv.org/abs/2409.09103</link>
      <description>arXiv:2409.09103v1 Announce Type: cross 
Abstract: Quantum computers can perform certain operations exponentially faster than classical computers, but designing quantum circuits is challenging. To that end, researchers used evolutionary algorithms to produce probabilistic quantum circuits that give the correct output more often than not for any input. They can be executed multiple times, with the outputs combined using a classical method (such as voting) to produce the final output, effectively creating a homogeneous ensemble of circuits (i.e., all identical). Inspired by n-version programming and ensemble learning, we developed a tool that uses an evolutionary algorithm to generate heterogeneous ensembles of circuits (i.e., all different), named QuEEn. We used it to evolve ensembles to solve the Iris classification problem. When using ideal simulation, we found the performance of heterogeneous ensembles to be greater than that of homogeneous ensembles to a statistically significant degree. When using noisy simulation, we still observed a statistically significant improvement in the majority of cases. Our results indicate that evolving heterogeneous ensembles is an effective strategy for improving the reliability of quantum circuits. This is particularly relevant in the current NISQ era of quantum computing where computers do not yet have good tolerance to quantum noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.09103v1</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Owain Parry, John Clark, Phil McMinn</dc:creator>
    </item>
    <item>
      <title>ProcessTBench: An LLM Plan Generation Dataset for Process Mining</title>
      <link>https://arxiv.org/abs/2409.09191</link>
      <description>arXiv:2409.09191v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) have shown significant promise in plan generation. Yet, existing datasets often lack the complexity needed for advanced tool use scenarios - such as handling paraphrased query statements, supporting multiple languages, and managing actions that can be done in parallel. These scenarios are crucial for evaluating the evolving capabilities of LLMs in real-world applications. Moreover, current datasets don't enable the study of LLMs from a process perspective, particularly in scenarios where understanding typical behaviors and challenges in executing the same process under different conditions or formulations is crucial. To address these gaps, we present the ProcessTBench dataset, an extension of the TaskBench dataset specifically designed to evaluate LLMs within a process mining framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.09191v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrei Cosmin Redis, Mohammadreza Fani Sani, Bahram Zarrin, Andrea Burattin</dc:creator>
    </item>
    <item>
      <title>High Definition Map Mapping and Update: A General Overview and Future Directions</title>
      <link>https://arxiv.org/abs/2409.09726</link>
      <description>arXiv:2409.09726v1 Announce Type: cross 
Abstract: Along with the rapid growth of autonomous vehicles (AVs), more and more demands are required for environment perception technology. Among others, HD mapping has become one of the more prominent roles in helping the vehicle realize essential tasks such as localization and path planning. While increasing research efforts have been directed toward HD Map development. However, a comprehensive overview of the overall HD map mapping and update framework is still lacking. This article introduces the development and current state of the algorithm involved in creating HD map mapping and its maintenance. As part of this study, the primary data preprocessing approach of processing raw data to information ready to feed for mapping and update purposes, semantic segmentation, and localization are also briefly reviewed. Moreover, the map taxonomy, ontology, and quality assessment are extensively discussed, the map data's general representation method is presented, and the mapping algorithm ranging from SLAM to transformers learning-based approaches are also discussed. The development of the HD map update algorithm, from change detection to the update methods, is also presented. Finally, the authors discuss possible future developments and the remaining challenges in HD map mapping and update technology. This paper simultaneously serves as a position paper and tutorial to those new to HD map mapping and update domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.09726v1</guid>
      <category>cs.RO</category>
      <category>cs.ET</category>
      <pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Benny Wijaya, Kun Jiang, Mengmeng Yang, Tuopu Wen, Yunlong Wang, Xuewei Tang, Zheng Fu, Taohua Zhou, Diange Yang</dc:creator>
    </item>
    <item>
      <title>A Global Perspective on the Past, Present, and Future of Video Streaming over Starlink</title>
      <link>https://arxiv.org/abs/2409.09846</link>
      <description>arXiv:2409.09846v1 Announce Type: cross 
Abstract: This study presents the first global analysis of on-demand video streaming over Low Earth Orbit (LEO) satellite networks, using data from over one million households across 85 countries. We highlight Starlink's role as a major LEO provider, enhancing connectivity in underserved regions. Our findings reveal that while overall video quality on Starlink matches that of traditional networks, the inherent variability in LEO conditions -- such as throughput fluctuations and packet loss -- leads to an increase in bitrate switches and rebuffers. To further improve the quality of experience for the LEO community, we manipulate existing congestion control and adaptive bitrate streaming algorithms using simulation and real A/B tests deployed on over one million households. Our results underscore the need for video streaming and congestion control algorithms to adapt to rapidly evolving network landscapes, ensuring high-quality service across diverse and dynamic network types.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.09846v1</guid>
      <category>cs.NI</category>
      <category>cs.ET</category>
      <category>cs.MM</category>
      <category>cs.PF</category>
      <pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liz Izhikevich, Reese Enghardt, Te-Yuan Huang, Renata Teixeira</dc:creator>
    </item>
    <item>
      <title>The Landscape of GPU-Centric Communication</title>
      <link>https://arxiv.org/abs/2409.09874</link>
      <description>arXiv:2409.09874v1 Announce Type: cross 
Abstract: n recent years, GPUs have become the preferred accelerators for HPC and ML applications due to their parallelism and fast memory bandwidth. While GPUs boost computation, inter-GPU communication can create scalability bottlenecks, especially as the number of GPUs per node and cluster grows. Traditionally, the CPU managed multi-GPU communication, but advancements in GPU-centric communication now challenge this CPU dominance by reducing its involvement, granting GPUs more autonomy in communication tasks, and addressing mismatches in multi-GPU communication and computation.
  This paper provides a landscape of GPU-centric communication, focusing on vendor mechanisms and user-level library supports. It aims to clarify the complexities and diverse options in this field, define the terminology, and categorize existing approaches within and across nodes. The paper discusses vendor-provided mechanisms for communication and memory management in multi-GPU execution and reviews major communication libraries, their benefits, challenges, and performance insights. Then, it explores key research paradigms, future outlooks, and open research questions. By extensively describing GPU-centric communication techniques across the software and hardware stacks, we provide researchers, programmers, engineers, and library designers insights on how to exploit multi-GPU systems at their best.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.09874v1</guid>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <category>cs.PF</category>
      <pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Didem Unat, Ilyas Turimbetov, Mohammed Kefah Taha Issa, Do\u{g}an Sa\u{g}bili, Flavio Vella, Daniele De Sensi, Ismayil Ismayilov</dc:creator>
    </item>
    <item>
      <title>An integrated design of robust decentralized observer and controller for load frequency control</title>
      <link>https://arxiv.org/abs/2409.10098</link>
      <description>arXiv:2409.10098v1 Announce Type: cross 
Abstract: This paper focuses on designing completely decentralized load frequency control (LFC) for multi-area power systems to achieve global optimized performance. To this end, a new concept of integrated design is introduced for designing the decentralized LFC observers and controllers simultaneously off-line, by taking into account of the interactions between areas and the bidirectional effects between the local observer and controller in each area. The integrated design in this paper is realized via $H_\infty$ optimization with a single-step linear matrix inequality (LMI) formulation. The LMI regional eigenvalue assignment technique is further incorporated with $H_\infty$ optimization to improve the closed-loop system transient performance. A three-area power system is simulated to validate the superiority of the proposed integrated design over the conventional decentralized designs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.10098v1</guid>
      <category>eess.SY</category>
      <category>cs.ET</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Xianxian Zhao, Jianglin Lan</dc:creator>
    </item>
    <item>
      <title>Analysing Attacks on Blockchain Systems in a Layer-based Approach</title>
      <link>https://arxiv.org/abs/2409.10109</link>
      <description>arXiv:2409.10109v1 Announce Type: cross 
Abstract: Blockchain is a growing decentralized system built for transparency and immutability. There have been several major attacks on blockchain-based systems, leaving a gap in the trustability of this system. This article presents a comprehensive study of 23 attacks on blockchain systems and categorizes them using a layer-based approach. This approach provides an in-depth analysis of the feasibility and motivation of these attacks. In addition, a framework is proposed that enables a systematic analysis of the impact and interconnection of these attacks, thereby providing a means of identifying potential attack vectors and designing appropriate countermeasures to strengthen any blockchain system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.10109v1</guid>
      <category>cs.CR</category>
      <category>cs.ET</category>
      <pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joydip Das, Syed Ashraf Al Tasin, Md. Forhad Rabbi, Md Sadek Ferdous</dc:creator>
    </item>
    <item>
      <title>Count2Multiply: Reliable In-memory High-Radix Counting</title>
      <link>https://arxiv.org/abs/2409.10136</link>
      <description>arXiv:2409.10136v1 Announce Type: cross 
Abstract: Big data processing has exposed the limits of compute-centric hardware acceleration due to the memory-to-processor bandwidth bottleneck. Consequently, there has been a shift towards memory-centric architectures, leveraging substantial compute parallelism by processing using the memory elements directly. Computing-in-memory (CIM) proposals for both conventional and emerging memory technologies often target massively parallel operations. However, current CIM solutions face significant challenges. For emerging data-intensive applications, such as advanced machine learning techniques and bioinformatics, where matrix multiplication is a key primitive, memristor crossbars suffer from limited write endurance and expensive write operations. In contrast, while DRAM-based solutions have successfully demonstrated multiplication using additions, they remain prohibitively slow. This paper introduces Count2Multiply, a technology-agnostic digital-CIM method for performing integer-binary and integer-integer matrix multiplications using high-radix, massively parallel counting implemented with bitwise logic operations. In addition, Count2Multiply is designed with fault tolerance in mind and leverages traditional scalable row-wise error correction codes, such as Hamming and BCH codes, to protect against the high error rates of existing CIM designs. We demonstrate Count2Multiply with a detailed application to CIM in conventional DRAM due to its ubiquity and high endurance. We also explore the acceleration potential of racetrack memories due to their shifting properties, which are natural for Count2Multiply, and their high endurance. Compared to the state-of-the-art in-DRAM method, Count2Multiply achieves up to 10x speedup, 3.8x higher GOPS/Watt, and 1.4x higher GOPS/area, while the RTM counterpart offers gains of 10x, 57x, and 3.8x.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.10136v1</guid>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jo\~ao Paulo Cardoso de Lima, Benjamin Franklin Morris III, Asif Ali Khan, Jeronimo Castrillon, Alex K. Jones</dc:creator>
    </item>
    <item>
      <title>PASS: An Asynchronous Probabilistic Processor for Next Generation Intelligence</title>
      <link>https://arxiv.org/abs/2409.10325</link>
      <description>arXiv:2409.10325v1 Announce Type: cross 
Abstract: New computing paradigms are required to solve the most challenging computational problems where no exact polynomial time solution exists.Probabilistic Ising Accelerators has gained promise on these problems with the ability to model complex probability distributions and find ground states of intractable problems. In this context, we have demonstrated the Parallel Asynchronous Stochastic Sampler (PASS), the first fully on-chip integrated, asynchronous, probabilistic accelerator that takes advantage of the intrinsic fine-grained parallelism of the Ising Model and built in state of the art 14nm CMOS FinFET technology. We have demonstrated broad applicability of this accelerator on problems ranging from Combinatorial Optimization, Neural Simulation, to Machine Learning along with up to $23,000$x energy to solution improvement compared to CPUs on probabilistic problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.10325v1</guid>
      <category>cs.DC</category>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Saavan Patel, Philip Canoza, Adhiraj Datar, Steven Lu, Chirag Garg, Sayeef Salahuddin</dc:creator>
    </item>
    <item>
      <title>Pennsieve - A Collaborative Platform for Translational Neuroscience and Beyond</title>
      <link>https://arxiv.org/abs/2409.10509</link>
      <description>arXiv:2409.10509v1 Announce Type: cross 
Abstract: The exponential growth of neuroscientific data necessitates platforms that facilitate data management and multidisciplinary collaboration. In this paper, we introduce Pennsieve - an open-source, cloud-based scientific data management platform built to meet these needs. Pennsieve supports complex multimodal datasets and provides tools for data visualization and analyses. It takes a comprehensive approach to data integration, enabling researchers to define custom metadata schemas and utilize advanced tools to filter and query their data. Pennsieve's modular architecture allows external applications to extend its capabilities, and collaborative workspaces with peer-reviewed data publishing mechanisms promote high-quality datasets optimized for downstream analysis, both in the cloud and on-premises.
  Pennsieve forms the core for major neuroscience research programs including the NIH SPARC Initiative, NIH HEAL Initiative's PRECISION Human Pain Network, and NIH HEAL RE-JOIN Initiative. It serves more than 80 research groups worldwide, along with several large-scale, inter-institutional projects at clinical sites through the University of Pennsylvania. Underpinning the SPARC.Science, Epilepsy.Science, and Pennsieve Discover portals, Pennsieve stores over 125 TB of scientific data, with 35 TB of data publicly available across more than 350 high-impact datasets. It adheres to the findable, accessible, interoperable, and reusable (FAIR) principles of data sharing and is recognized as one of the NIH-approved Data Repositories. By facilitating scientific data management, discovery, and analysis, Pennsieve fosters a robust and collaborative research ecosystem for neuroscience and beyond.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.10509v1</guid>
      <category>cs.CY</category>
      <category>cs.DB</category>
      <category>cs.DL</category>
      <category>cs.ET</category>
      <pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zack Goldblum (University of Pennsylvania), Zhongchuan Xu (University of Pennsylvania), Haoer Shi (University of Pennsylvania), Patryk Orzechowski (University of Pennsylvania, AGH University of Krakow), Jamaal Spence (University of Pennsylvania), Kathryn A Davis (University of Pennsylvania), Brian Litt (University of Pennsylvania), Nishant Sinha (University of Pennsylvania), Joost Wagenaar (University of Pennsylvania)</dc:creator>
    </item>
    <item>
      <title>A MAC Protocol with Time Reversal for Wireless Networks within Computing Packages</title>
      <link>https://arxiv.org/abs/2408.07421</link>
      <description>arXiv:2408.07421v2 Announce Type: replace 
Abstract: Wireless Network-on-Chip (WNoC) is a promising concept which provides a solution to overcome the scalability issues in prevailing networks-in-package for many-core processors. However, the electromagnetic propagation inside the chip package leads to energy reverberation, resulting in Inter-Symbol Interference (ISI) with high delay spreads. Time Reversal (TR) is a technique that benefits the unique time-invariant channel with rich multipath effects to focus the energy to the desired transceiver. TR mitigates both ISI and co-channel interference, hence providing parallel communications in both space and time. Thus, TR is a versatile candidate to improve the aggregate bandwidth of wireless on-chip networks provided that a Medium Access Control (MAC) is used to efficiently share the wireless medium. In this paper, we explore a simple yet resilient TR-based MAC protocol (TR-MAC) design for WNoC. We propose to manage multiple parallel transmissions with simultaneous spatial channels in the same time slot with TR precoding and focused energy detection at the transceiver. Our results show that TR-MAC can be employed in massive computing architectures with improved latency and throughput while matching with the stringent requirements of the physical layer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07421v2</guid>
      <category>cs.ET</category>
      <category>cs.NI</category>
      <pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ama Bandara, Abhijit Das, F\'atima Rodr\'iguez-Gal\'an, Eduard Alarc\'on, Sergi Abadal</dc:creator>
    </item>
    <item>
      <title>Exponential Quantum Speedup for Simulation-Based Optimization Applications</title>
      <link>https://arxiv.org/abs/2305.08482</link>
      <description>arXiv:2305.08482v3 Announce Type: replace-cross 
Abstract: The simulation of many industrially relevant physical processes can be executed up to exponentially faster using quantum algorithms. However, this speedup can only be leveraged if the data input and output of the simulation can be implemented efficiently. While we show that recent advancements for optimal state preparation can effectively solve the problem of data input at a moderate cost of ancillary qubits in many cases, the output problem can provably not be solved efficiently in general. By acknowledging that many simulation problems arise only as a subproblem of a larger optimization problem in many practical applications however, we identify and define a class of practically relevant problems that does not suffer from the output problem: Quantum Simulation-based Optimization (QuSO). QuSO represents optimization problems whose objective function and/or constraints depend on summary statistic information on the result of a simulation, i.e., information that can be efficiently extracted from a quantum state vector. In this article, we focus on the LinQuSO subclass of QuSO, which is characterized by the linearity of the simulation problem, i.e., the simulation problem can be formulated as a system of linear equations. By cleverly combining the quantum singular value transformation (QSVT) with the quantum approximate optimization algorithm (QAOA), we prove that a large subgroup of LinQuSO problems can be solved with up to exponential quantum speedups with regards to their simulation component. Finally, we present two practically relevant use cases that fall within this subgroup of QuSO problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.08482v3</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonas Stein, Lukas M\"uller, Leonhard H\"olscher, Georgios Chnitidis, Jezer Jojo, Afrah Farea, Mustafa Serdar \c{C}elebi, David Bucher, Jonathan Wulf, David Fischer, Philipp Altmann, Claudia Linnhoff-Popien, Sebastian Feld</dc:creator>
    </item>
    <item>
      <title>Closed Loop Superparamagnetic Tunnel Junctions for Reliable True Randomness and Generative Artificial Intelligence</title>
      <link>https://arxiv.org/abs/2407.08665</link>
      <description>arXiv:2407.08665v2 Announce Type: replace-cross 
Abstract: Physical devices exhibiting stochastic functions with low energy consumption and high device density have the potential to enable complex probability-based computing algorithms, accelerate machine learning tasks, and enhance hardware security. Recently, superparamagnetic tunnel junctions (sMTJs) have been widely explored for such purposes, leading to the development of sMTJ-based systems; however, the reliance on nanoscale ferromagnets limits scalability and reliability, making sMTJs sensitive to external perturbations and prone to significant device variations. Here, we present an experimental demonstration of closed loop three-terminal sMTJs as reliable and potentially scalable sources of true randomness in the field-free regime. By leveraging dual-current controllability and incorporating feedback, we stabilize the switching operation of superparamagnets and reach cryptographic-quality random bitstreams. The realization of controllable and robust true random sMTJs underpin a general hardware platform for computing schemes exploiting the stochasticity in the physical world, as demonstrated by the generative artificial intelligence example in our experiment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.08665v2</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>cs.ET</category>
      <pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dooyong Koh, Qiuyuan Wang, Brooke C. McGoldrick, Chung-Tao Chou, Luqiao Liu, Marc A. Baldo</dc:creator>
    </item>
    <item>
      <title>Towards Enabling 5G-NTN Satellite Communications for Manned and Unmanned Rotary Wing Aircraft</title>
      <link>https://arxiv.org/abs/2407.10177</link>
      <description>arXiv:2407.10177v3 Announce Type: replace-cross 
Abstract: Satellite Communications (SatCom) are a backbone of worldwide development. In contrast with the past, when the GEO satellites were the only means for such connectivity, nowadays the multi-orbital connectivity is emerging, especially with the use of satellite constellations. Simultaneously, SatCom enabled the so-called In-Flight Connectivity, while with the advent of 5G-NTN, the development of this market is being accelerated. However, there are still various missing points before such a technology becomes mainstream, especially in the case of Rotary Wing Aircraft (RWA). Indeed, due to their particular characteristics, such as the low altitude flights and the blade interference, there are still open challenges. In this work, an End-to-End (E2E) analysis for the performance of SatCom under 5G-NTN for manned and unmanned RWA is performed. Various scenarios are examined, and related requirements are shown. The effects of blades and other characteristics of the RWA are established, and simulations for these cases are developed. Results along with related discussion are presented, while future directions for development are suggested. This work is part of the ESA ACROSS-AIR project.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10177v3</guid>
      <category>cs.NI</category>
      <category>cs.ET</category>
      <pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vasileios Leon, Ilias Christofilos, Athanasios Nesiadis, Iosif Paraskevas, Juan Perrela, Georgios Ioannopoulos, Alexandros Tasoulis-Nonikas, Mathieu Bernou, Jacques Reading</dc:creator>
    </item>
  </channel>
</rss>
