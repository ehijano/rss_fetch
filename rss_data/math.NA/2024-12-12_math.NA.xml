<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.NA</link>
    <description>math.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 13 Dec 2024 02:43:19 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Error estimate for the first order energy stable scheme of Q-tensor nematic model</title>
      <link>https://arxiv.org/abs/2412.08027</link>
      <description>arXiv:2412.08027v1 Announce Type: new 
Abstract: We present rigorous error estimates towards a first-order unconditionally energy stable scheme designed for 3D hydrodynamic Q-tensor model of nematic liquid crystals. This scheme combines the scalar auxiliary variable (SAV), stabilization and projection method together. The unique solvability and energy dissipation of the scheme are proved. We further derive the boundness of numerical solution in L^{\infty} norm with mathematical deduction. Then, we can give the rigorous error estimate of order O({\delta}t) in the sense of L2 norm, where {\delta}t is the time step.Finally, we give some numerical simulations to demonstrate the theoretical analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.08027v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jin Huang, Xiao Li, Guanghua Ji</dc:creator>
    </item>
    <item>
      <title>Scaling Optimized Hermite Approximation Methods</title>
      <link>https://arxiv.org/abs/2412.08044</link>
      <description>arXiv:2412.08044v1 Announce Type: new 
Abstract: Hermite polynomials and functions are widely used for scientific and engineering problems. Although it is known that using the scaled Hermite function instead of the standard one can significantly enhance approximation performance, understanding of the scaling factor is inadequate. To this end, we propose a novel error analysis framework for the scaled Hermite approximation. Taking the $L^2$ projection error as an example, our results illustrate that when using truncated $N$ terms of scaled Hermite functions to approximate a function, there are three different components of error: spatial truncation error; frequency truncation error; and Hermite spectral approximation error. Through our insight, finding the optimal scaling factor is equivalent to balancing the spatial and frequency truncation error. As an example, we show that geometric convergence can be recovered by proper scaling for a class of functions. Furthermore, we show that proper scaling can double the convergence order for smooth functions with algebraic decay. The puzzling pre-asymptotic sub-geometric convergence when approximating algebraic decay functions can be perfectly explained by this framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.08044v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Hao Hu, Haijun Yu</dc:creator>
    </item>
    <item>
      <title>Parameter optimization for restarted mixed precision iterative sparse solver</title>
      <link>https://arxiv.org/abs/2412.08059</link>
      <description>arXiv:2412.08059v2 Announce Type: new 
Abstract: We consider the problem of optimizing the parameter of a two-stage algorithm for approximate solution of a system of linear algebraic equations with a sparse $n\times n$-matrix, i.e., with one in which the number of nonzero elements is $m\!=\!O(n)$. The two-stage algorithm uses conjugate gradient method at its stages. At the 1st stage, an approximate solution with accuracy $\varepsilon_1$ is found for zero initial vector. All numerical values used at this stage are represented as single-precision numbers. The obtained solution is used as initial approximation for an approximate solution with a given accuracy $\varepsilon_2$ that we obtain at the 2nd stage, where double-precision numbers are used. Based on the values of some matrix parameters, computed in a time not exceeding $O(m)$, we need to determine the value $\varepsilon_1$ which minimizes the total computation time at two stages.
  Using single-precision numbers for computations at the 1st stage is advantageous, since the execution time of one iteration will be approximately half that of one iteration at the 2nd stage. At the same time, using machine numbers with half the mantissa length accelerates the growth of the rounding error per iteration of the conjugate gradient method at the 1st stage, which entails an increase in the number of iterations performed at 2nd stage.
  As parameters that allow us to determine $\varepsilon_1$ for the input matrix, we use $n$, $m$, an estimate of the diameter of the graph associated with the matrix, an estimate of the spread of the matrix' eigenvalues, and estimates of its maximum eigenvalue. The optimal or close to the optimal value of $\varepsilon_1$ can be determined for matrix with such a vector of parameters using the nearest neighbor regression or some other type of regression.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.08059v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Alexander V. Prolubnikov</dc:creator>
    </item>
    <item>
      <title>Momentum-Accelerated Richardson(m) and Their Multilevel Neural Solvers</title>
      <link>https://arxiv.org/abs/2412.08076</link>
      <description>arXiv:2412.08076v1 Announce Type: new 
Abstract: Recently, designing neural solvers for large-scale linear systems of equations has emerged as a promising approach in scientific and engineering computing. This paper first introduce the Richardson(m) neural solver by employing a meta network to predict the weights of the long-step Richardson iterative method. Next, by incorporating momentum and preconditioning techniques, we further enhance convergence. Numerical experiments on anisotropic second-order elliptic equations demonstrate that these new solvers achieve faster convergence and lower computational complexity compared to both the Chebyshev iterative method with optimal weights and the Chebyshev semi-iteration method. To address the strong dependence of the aforementioned single-level neural solvers on PDE parameters and grid size, we integrate them with two multilevel neural solvers developed in recent years. Using alternating optimization techniques, we construct Richardson(m)-FNS for anisotropic equations and NAG-Richardson(m)-WANS for the Helmholtz equation. Numerical experiments show that these two multilevel neural solvers effectively overcome the drawback of single-level methods, providing better robustness and computational efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.08076v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhen Wang, Yun Liu, Chen Cui, Shi Shu</dc:creator>
    </item>
    <item>
      <title>Geometric low-rank approximation of the Zeitlin model of incompressible fluids on the sphere</title>
      <link>https://arxiv.org/abs/2412.08182</link>
      <description>arXiv:2412.08182v1 Announce Type: new 
Abstract: We consider the vorticity formulation of the Euler equations describing the flow of a two-dimensional incompressible ideal fluid on the sphere. Zeitlin's model provides a finite-dimensional approximation of the vorticity formulation that preserves the underlying geometric structure: it consists of an isospectral Lie--Poisson flow on the Lie algebra of skew-Hermitian matrices. We propose an approximation of Zeitlin's model based on a time-dependent low-rank factorization of the vorticity matrix and evolve a basis of eigenvectors according to the Euler equations. In particular, we show that the approximate flow remains isospectral and Lie--Poisson and that the error in the solution, in the approximation of the Hamiltonian and of the Casimir functions only depends on the approximation of the vorticity matrix at the initial time. The computational complexity of solving the approximate model is shown to scale quadratically with the order of the vorticity matrix and linearly if a further approximation of the stream function is introduced.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.08182v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cecilia Pagliantini</dc:creator>
    </item>
    <item>
      <title>An Exponential Stochastic Runge-Kutta Type Method of Order up to 1.5 for SPDEs of Nemytskii-type</title>
      <link>https://arxiv.org/abs/2412.08299</link>
      <description>arXiv:2412.08299v1 Announce Type: new 
Abstract: For the approximation of solutions for stochastic partial differential equations, numerical methods that obtain a high order of convergence and at the same time involve reasonable computational cost are of particular interest. We therefore propose a new numerical method of exponential stochastic Runge-Kutta type that allows for convergence with a temporal order of up to 3/2 and that can be combined with several spatial discretizations. The developed family of derivative-free schemes is tailored to stochastic partial differential equations of Nemytskii-type, i.e., with pointwise multiplicative noise operators. We prove the strong convergence of these schemes in the root mean-square sense and present some numerical examples that reveal the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.08299v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Claudine von Hallern, Ricarda Mi{\ss}feldt, Andreas R\"o{\ss}ler</dc:creator>
    </item>
    <item>
      <title>Multiscale approximation and two-grid preconditioner for extremely anisotropic heat flow</title>
      <link>https://arxiv.org/abs/2412.08355</link>
      <description>arXiv:2412.08355v1 Announce Type: new 
Abstract: We consider anisotropic heat flow with extreme anisotropy, as arises in magnetized plasmas for fusion applications. Such problems pose significant challenges in both obtaining an accurate approximation as well in the construction of an efficient solver. In both cases, the underlying difficulty is in forming an accurate approximation of temperature fields that follow the direction of complex, non-grid-aligned magnetic fields. In this work, we construct a highly accurate coarse grid approximation using spectral multiscale basis functions based on local anisotropic normalized Laplacians. We show that the local generalized spectral problems yield local modes that align with magnetic fields, and provide an excellent coarse-grid approximation of the problem. We then utilize this spectral coarse space as an approximation in itself, and as the coarse-grid in a two-level spectral preconditioner. Numerical results are presented for several magnetic field distributions and anisotropy ratios up to $10^{12}$, showing highly accurate results with a large system size reduction, and two-grid preconditioning that converges in $O(1)$ iterations, independent of anisotropy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.08355v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maria Vasilyeva, Golo A. Wimmer, Ben S. Southworth</dc:creator>
    </item>
    <item>
      <title>Hybrid GFD-RBF Method for Convection-Diffusion Problems</title>
      <link>https://arxiv.org/abs/2412.08365</link>
      <description>arXiv:2412.08365v1 Announce Type: new 
Abstract: In this paper, we present a meshless hybrid method combining the Generalized Finite Difference (GFD) and Finite Difference based Radial Basis Function (RBF-FD) approaches to solve non-homogeneous partial differential equations (PDEs) involving both lower and higher order derivatives. The proposed method eliminates the need for mesh generation by leveraging the strengths of both GFD and RBF-FD techniques. The GFD method is robust and stable, effectively handling ill-conditioned systems, while the RBF-FD method excels in extending to higher-order derivatives and higher-dimensional problems. Despite their individual advantages, each method has its limitations. To address these, we developed a hybrid GFD-RBF approach that combines their strengths. Specifically, the GFD method is employed to approximate lower order terms (convective terms), and the RBF method is used for higher order terms (diffusive terms). The performance of the proposed hybrid method is tested on both linear and nonlinear PDEs, considering uniform and non-uniform distributions of nodes within the domain. This approach demonstrates the versatility and effectiveness of the hybrid GFD-RBF method in solving second and higher order convection-diffusion problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.08365v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Priyal Garg, T. V. S. Sekhar</dc:creator>
    </item>
    <item>
      <title>Error analysis for discontinuous Galerkin time-stepping methods for nonlinear parabolic equations via maximal regularity</title>
      <link>https://arxiv.org/abs/2412.08375</link>
      <description>arXiv:2412.08375v1 Announce Type: new 
Abstract: We consider the discretization of a class of nonlinear parabolic equations by discontinuous Galerkin time-stepping methods and establish a priori as well as conditional a posteriori error estimates. Our approach is motivated by the error analysis in [9] for Runge-Kutta methods for nonlinear parabolic equations; in analogy to [9], the proofs are based on maximal regularity properties of discontinuous Galerkin methods for non-autonomous linear parabolic equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.08375v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Georgios Akrivis, Stig Larsson</dc:creator>
    </item>
    <item>
      <title>Determining superconvergence points for $L2-1_\sigma$ scheme of variable-exponent subdiffusion and error estimate</title>
      <link>https://arxiv.org/abs/2412.08379</link>
      <description>arXiv:2412.08379v1 Announce Type: new 
Abstract: We consider the $L2-1_\sigma$ scheme for subdiffusion of variable exponent. In existing works, determining the superconvergence points requires solving a nonlinear equation relate to the variable exponent at each time step. This work relaxes the selection criterion of superconvergence points without affecting the numerical accuracy, which may reduce the cost of determining superconvergence points. Then we prove error estimates for the $L2-1_\sigma$ scheme of variable-exponent subdiffusion. Numerical results are performed to substantiate the theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.08379v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongying Huang, Huili Zhang, Xiangcheng Zheng</dc:creator>
    </item>
    <item>
      <title>A simplified method for the evaluation of the total resistance of a foiling yacht in upright condition</title>
      <link>https://arxiv.org/abs/2412.08438</link>
      <description>arXiv:2412.08438v1 Announce Type: new 
Abstract: An extremely schematic model of the forces acting an a sailing yacht equipped with a system of foils is here presented and discussed. The role of the foils is to raise the hull from the water in order to reduce the total resistance and then increase the speed. Some CFD simulations are providing the total resistance of the bare hull at some values of speed and displacement, as well as the characteristics (drag and lift coefficients) of the 2D foil sections used for the appendages. A parametric study has been performed for the characterization of a foil of finite dimensions. The equilibrium of the vertical forces and longitudinal moments, as well as a reduced displacement, is obtained by controlling the pitch angle of the foils. The value of the total resistance of the yacht with foils is then compared with the case without foils, evidencing the speed regime where an advantage is obtained, if any.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.08438v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniele Peri</dc:creator>
    </item>
    <item>
      <title>Sparse Signature Coefficient Recovery via Kernels</title>
      <link>https://arxiv.org/abs/2412.08579</link>
      <description>arXiv:2412.08579v1 Announce Type: new 
Abstract: Central to rough path theory is the signature transform of a path, an infinite series of tensors given by the iterated integrals of the underlying path. The signature poses an effective way to capture sequentially ordered information, thanks both to its rich analytic and algebraic properties as well as its universality when used as a basis to approximate functions on path space. Whilst a truncated version of the signature can be efficiently computed using Chen's identity, there is a lack of efficient methods for computing a sparse collection of iterated integrals contained in high levels of the signature. We address this problem by leveraging signature kernels, defined as the inner product of two signatures, and computable efficiently by means of PDE-based methods. By forming a filter in signature space with which to take kernels, one can effectively isolate specific groups of signature coefficients and, in particular, a singular coefficient at any depth of the transform. We show that such a filter can be expressed as a linear combination of suitable signature transforms and demonstrate empirically the effectiveness of our approach. To conclude, we give an example use case for sparse collections of signature coefficients based on the construction of N-step Euler schemes for sparse CDEs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.08579v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>stat.ML</category>
      <pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniil Shmelev, Cristopher Salvi</dc:creator>
    </item>
    <item>
      <title>Numerical Analysis of HiPPO-LegS ODE for Deep State Space Models</title>
      <link>https://arxiv.org/abs/2412.08595</link>
      <description>arXiv:2412.08595v1 Announce Type: new 
Abstract: In deep learning, the recently introduced state space models utilize HiPPO (High-order Polynomial Projection Operators) memory units to approximate continuous-time trajectories of input functions using ordinary differential equations (ODEs), and these techniques have shown empirical success in capturing long-range dependencies in long input sequences. However, the mathematical foundations of these ODEs, particularly the singular HiPPO-LegS (Legendre Scaled) ODE, and their corresponding numerical discretizations remain unexplored. In this work, we fill this gap by establishing that HiPPO-LegS ODE is well-posed despite its singularity, albeit without the freedom of arbitrary initial conditions, and by establishing convergence of the associated numerical discretization schemes for Riemann-integrable input functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.08595v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jaesung R. Park, Jaewook J. Suh, Ernest K. Ryu</dc:creator>
    </item>
    <item>
      <title>Dirichlet-Neumann Averaging: The DNA of Efficient Gaussian Process Simulation</title>
      <link>https://arxiv.org/abs/2412.07929</link>
      <description>arXiv:2412.07929v1 Announce Type: cross 
Abstract: Gaussian processes (GPs) and Gaussian random fields (GRFs) are essential for modelling spatially varying stochastic phenomena. Yet, the efficient generation of corresponding realisations on high-resolution grids remains challenging, particularly when a large number of realisations are required. This paper presents two novel contributions. First, we propose a new methodology based on Dirichlet-Neumann averaging (DNA) to generate GPs and GRFs with isotropic covariance on regularly spaced grids. The combination of discrete cosine and sine transforms in the DNA sampling approach allows for rapid evaluations without the need for modification or padding of the desired covariance function. While this introduces an error in the covariance, our numerical experiments show that this error is negligible for most relevant applications, representing a trade-off between efficiency and precision. We provide explicit error estimates for Mat\'ern covariances. The second contribution links our new methodology to the stochastic partial differential equation (SPDE) approach for sampling GRFs. We demonstrate that the concepts developed in our methodology can also guide the selection of boundary conditions in the SPDE framework. We prove that averaging specific GRFs sampled via the SPDE approach yields genuinely isotropic realisations without domain extension, with the error bounds established in the first part remaining valid.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.07929v1</guid>
      <category>stat.CO</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <category>stat.ME</category>
      <pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Robert Kutri (Institute for Mathematics, Heidelberg, Interdisciplinary Center for Scientific Computing), Robert Scheichl (Institute for Mathematics, Heidelberg, Interdisciplinary Center for Scientific Computing)</dc:creator>
    </item>
    <item>
      <title>Statistical Downscaling via High-Dimensional Distribution Matching with Generative Models</title>
      <link>https://arxiv.org/abs/2412.08079</link>
      <description>arXiv:2412.08079v1 Announce Type: cross 
Abstract: Statistical downscaling is a technique used in climate modeling to increase the resolution of climate simulations. High-resolution climate information is essential for various high-impact applications, including natural hazard risk assessment. However, simulating climate at high resolution is intractable. Thus, climate simulations are often conducted at a coarse scale and then downscaled to the desired resolution. Existing downscaling techniques are either simulation-based methods with high computational costs, or statistical approaches with limitations in accuracy or application specificity. We introduce Generative Bias Correction and Super-Resolution (GenBCSR), a two-stage probabilistic framework for statistical downscaling that overcomes the limitations of previous methods. GenBCSR employs two transformations to match high-dimensional distributions at different resolutions: (i) the first stage, bias correction, aligns the distributions at coarse scale, (ii) the second stage, statistical super-resolution, lifts the corrected coarse distribution by introducing fine-grained details. Each stage is instantiated by a state-of-the-art generative model, resulting in an efficient and effective computational pipeline for the well-studied distribution matching problem. By framing the downscaling problem as distribution matching, GenBCSR relaxes the constraints of supervised learning, which requires samples to be aligned. Despite not requiring such correspondence, we show that GenBCSR surpasses standard approaches in predictive accuracy of critical impact variables, particularly in predicting the tails (99% percentile) of composite indexes composed of interacting variables, achieving up to 4-5 folds of error reduction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.08079v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.ao-ph</category>
      <pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhong Yi Wan, Ignacio Lopez-Gomez, Robert Carver, Tapio Schneider, John Anderson, Fei Sha, Leonardo Zepeda-N\'u\~nez</dc:creator>
    </item>
    <item>
      <title>Towards Automated Algebraic Multigrid Preconditioner Design Using Genetic Programming for Large-Scale Laser Beam Welding Simulations</title>
      <link>https://arxiv.org/abs/2412.08186</link>
      <description>arXiv:2412.08186v1 Announce Type: cross 
Abstract: Multigrid methods are asymptotically optimal algorithms ideal for large-scale simulations. But, they require making numerous algorithmic choices that significantly influence their efficiency. Unlike recent approaches that learn optimal multigrid components using machine learning techniques, we adopt a complementary strategy here, employing evolutionary algorithms to construct efficient multigrid cycles from available individual components. This technology is applied to finite element simulations of the laser beam welding process. The thermo-elastic behavior is described by a coupled system of time-dependent thermo-elasticity equations, leading to nonlinear and ill-conditioned systems. The nonlinearity is addressed using Newton's method, and iterative solvers are accelerated with an algebraic multigrid (AMG) preconditioner using hypre BoomerAMG interfaced via PETSc. This is applied as a monolithic solver for the coupled equations. To further enhance solver efficiency, flexible AMG cycles are introduced, extending traditional cycle types with level-specific smoothing sequences and non-recursive cycling patterns. These are automatically generated using genetic programming, guided by a context-free grammar containing AMG rules. Numerical experiments demonstrate the potential of these approaches to improve solver performance in large-scale laser beam welding simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.08186v1</guid>
      <category>cs.CE</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dinesh Parthasarathy, Tommaso Bevilacqua, Martin Lanser, Axel Klawonn, Harald K\"ostler</dc:creator>
    </item>
    <item>
      <title>Point Source Identification in Subdiffusion from A Posteriori Internal Measurement</title>
      <link>https://arxiv.org/abs/2412.08220</link>
      <description>arXiv:2412.08220v1 Announce Type: cross 
Abstract: In this work we investigate an inverse problem of recovering point sources and their time-dependent strengths from {a posteriori} partial internal measurements in a subdiffusion model which involves a Caputo fractional derivative in time and a general second-order elliptic operator in space. We establish the well-posedness of the direct problem in the sense of transposition and improved local regularity. Using classical unique continuation of the subdiffusion model and improved local solution regularity, we prove the uniqueness of simultaneously recovering the locations of point sources, time-dependent strengths and initial condition for both one- and multi-dimensional cases. Moreover, in the one-dimensional case, the elliptic operator can have time-dependent coefficients. These results extend existing studies on point source identification for parabolic type problems. Additionally we present several numerical experiments to show the feasibility of numerical reconstruction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.08220v1</guid>
      <category>math.AP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Kuang Huang, Bangti Jin, Yavar Kian, Georges Sadaka, Zhi Zhou</dc:creator>
    </item>
    <item>
      <title>Efficient gradient-based methods for bilevel learning via recycling Krylov subspaces</title>
      <link>https://arxiv.org/abs/2412.08264</link>
      <description>arXiv:2412.08264v1 Announce Type: cross 
Abstract: Many optimization problems require hyperparameters, i.e., parameters that must be pre-specified in advance, such as regularization parameters and parametric regularizers in variational regularization methods for inverse problems, and dictionaries in compressed sensing. A data-driven approach to determine appropriate hyperparameter values is via a nested optimization framework known as bilevel learning. Even when it is possible to employ a gradient-based solver to the bilevel optimization problem, construction of the gradients, known as hypergradients, is computationally challenging, each one requiring both a solution of a minimization problem and a linear system solve. These systems do not change much during the iterations, which motivates us to apply recycling Krylov subspace methods, wherein information from one linear system solve is re-used to solve the next linear system. Existing recycling strategies often employ eigenvector approximations called Ritz vectors. In this work we propose a novel recycling strategy based on a new concept, Ritz generalized singular vectors, which acknowledge the bilevel setting. Additionally, while existing iterative methods primarily terminate according to the residual norm, this new concept allows us to define a new stopping criterion that directly approximates the error of the associated hypergradient. The proposed approach is validated through extensive numerical testing in the context of an inverse problem in imaging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.08264v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthias J. Ehrhardt, Silvia Gazzola, Sebastian J. Scott</dc:creator>
    </item>
    <item>
      <title>Reliable Uncertainty Quantification for Fiber Orientation in Composite Molding Processes using Multilevel Polynomial Surrogates</title>
      <link>https://arxiv.org/abs/2412.08459</link>
      <description>arXiv:2412.08459v1 Announce Type: cross 
Abstract: Fiber orientation is decisive for the mechanical properties and thus for the performance of composite materials. During manufacturing, variations in material and process parameters can significantly influence the exact fiber orientation. We employ multilevel polynomial surrogates to model the propagation of uncertain material properties in the injection molding process. To ensure reliable uncertainty quantification, a key focus is deriving novel error bounds for statistical measures of a quantity of interest, computed via these surrogates. To verify these bounds, we conduct numerical experiments using the Cross-WLF viscosity model alongside the Hagen-Poiseuille flow in a rectangular channel. In particular, the impact of uncertainties in fiber length and matrix temperature on the fractional anisotropy of fiber orientation is investigated. The Folgar-Tucker equation and the improved anisotropic rotary diffusion model are used, incorporating recently established analytical solutions of these models as part of our verification. Our results demonstrate that the investigated method significantly improves upon standard Monte Carlo estimation, while also providing error guarantees. These findings offer the first step toward a reliable and practical tool for optimizing fiber-reinforced polymer manufacturing processes in the future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.08459v1</guid>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stjepan Salatovic, Sebastian Krumscheid, Florian Wittemann, Luise K\"arger</dc:creator>
    </item>
    <item>
      <title>Deep learning-based reduced-order methods for fast transient dynamics</title>
      <link>https://arxiv.org/abs/2212.07737</link>
      <description>arXiv:2212.07737v3 Announce Type: replace 
Abstract: In recent years, large-scale numerical simulations played an essential role in estimating the effects of explosion events in urban environments, for the purpose of ensuring the security and safety of cities. Such simulations are computationally expensive and, often, the time taken for one single computation is large and does not permit parametric studies. The aim of this work is therefore to facilitate real-time and multi-query calculations by employing a non-intrusive Reduced Order Method (ROM). We propose a deep learning-based (DL) ROM scheme able to deal with fast transient dynamics. In the case of blast waves, the parametrised PDEs are time-dependent and non-linear. For such problems, the Proper Orthogonal Decomposition (POD), which relies on a linear superposition of modes, cannot approximate the solutions efficiently. The piecewise POD-DL scheme developed here is a local ROM based on time-domain partitioning and a first dimensionality reduction obtained through the POD. Autoencoders are used as a second and non-linear dimensionality reduction. The latent space obtained is then reconstructed from the time and parameter space through deep forward neural networks. The proposed scheme is applied to an example consisting of a blast wave propagating in air and impacting on the outside of a building. The efficiency of the deep learning-based ROM in approximating the time-dependent pressure field is shown.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.07737v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martina Cracco, Giovanni Stabile, Andrea Lario, Armin Sheidani, Martin Larcher, Folco Casadei, Georgios Valsamos, Gianluigi Rozza</dc:creator>
    </item>
    <item>
      <title>Smoothed Circulant Embedding with Applications to Multilevel Monte Carlo Methods for PDEs with Random Coefficients</title>
      <link>https://arxiv.org/abs/2306.13493</link>
      <description>arXiv:2306.13493v3 Announce Type: replace 
Abstract: We consider the computational efficiency of Monte Carlo (MC) and Multilevel Monte Carlo (MLMC) methods applied to partial differential equations with random coefficients. These arise, for example, in groundwater flow modelling, where a commonly used model for the unknown parameter is a random field. We make use of the circulant embedding procedure for sampling from the aforementioned coefficient. To improve the computational complexity of the MLMC estimator in the case of highly oscillatory random fields, we devise and implement a smoothing technique integrated into the circulant embedding method. This allows to choose the coarsest mesh on the first level of MLMC independently of the correlation length of the covariance function of the random field, leading to considerable savings in computational cost. We illustrate this with numerical experiments, where we see a saving of factor 5-10 in computational cost for accuracies of practical interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.13493v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anastasia Istratuca, Aretha Teckentrup</dc:creator>
    </item>
    <item>
      <title>A new interpolated pseudodifferential preconditioner for the Helmholtz equation in heterogeneous media</title>
      <link>https://arxiv.org/abs/2409.16172</link>
      <description>arXiv:2409.16172v2 Announce Type: replace 
Abstract: This paper introduces a new pseudodifferential preconditioner for the Helmholtz equation in variable media with absorption. The pseudodifferential operator is associated with the multiplicative inverse to the symbol of the Helmholtz operator. This approach is well-suited for the intermediate and high-frequency regimes. The main novel idea for the fast evaluation of the preconditioner is to interpolate its symbol, not as a function of the (high-dimensional) phase-space variables, but as a function of the wave speed itself. Since the wave speed is a real-valued function, this approach allows us to interpolate in a univariate setting even when the original problem is posed in a multidimensional physical space. As a result, the needed number of interpolation points is small, and the interpolation coefficients can be computed using the fast Fourier transform. The overall computational complexity is log-linear with respect to the degrees of freedom as inherited from the fast Fourier transform. We present some numerical experiments to illustrate the effectiveness of the preconditioner to solve the discrete Helmholtz equation using the GMRES iterative method. The implementation of an absorbing layer for scattering problems using a complex-valued wave speed is also developed. Limitations and possible extensions are also discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.16172v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sebastian Acosta, Tahsin Khajah, Benjamin Palacios</dc:creator>
    </item>
    <item>
      <title>A class of kernel-based scalable algorithms for data science</title>
      <link>https://arxiv.org/abs/2410.14323</link>
      <description>arXiv:2410.14323v2 Announce Type: replace 
Abstract: We present several generative and predictive algorithms based on the RKHS (reproducing kernel Hilbert spaces) methodology, which, most importantly, are scale up efficiently with large datasets or high-dimensional data. It is well recognized that the RKHS methodology leads one to efficient and robust algorithms for numerous tasks in data science, statistics, and scientific computation. However, the implementations existing the literature are often difficult to scale up for encompassing large datasets. In this paper, we introduce a simple and robust, divide-and-conquer methodology. It applies to large scale datasets and relies on several kernel-based algorithms, which distinguish between various extrapolation, interpolation, and optimal transport steps. We argue how to select the suitable algorithm in specific applications thanks to a feedback of performance criteria. Our primary focus is on applications and problems arising in industrial contexts, such as generating meshes for efficient numerical simulations, designing generators for conditional distributions, constructing transition probability matrices for statistical or stochastic applications, and addressing various tasks relevant to the Artificial Intelligence community. The proposed algorithms are highly relevant to supervised and unsupervised learning, generative methods, as well as reinforcement learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14323v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Philippe G. LeFloch, Jean-Marc Mercier, Shohruh Miryusupov</dc:creator>
    </item>
    <item>
      <title>Runge-Kutta Discontinuous Galerkin Method Based on Flux Vector Splitting with Constrained Optimization-based TVB(D)-minmod Limiter for Solving Hyperbolic Conservation Laws</title>
      <link>https://arxiv.org/abs/2411.16367</link>
      <description>arXiv:2411.16367v5 Announce Type: replace 
Abstract: The flux vector splitting (FVS) method has firstly been incorporated into the discontinuous Galerkin (DG) framework for reconstructing the numerical fluxes required for the spatial semi-discrete formulation, setting it apart from the conventional DG approaches that typically utilize the Lax-Friedrichs flux scheme or classical Riemann solvers. The control equations of hyperbolic conservation systems are initially reformulated into a flux-split form. Subsequently, a variational approach is applied to this flux-split form, from which a DG spatial semi-discrete scheme based on FVS is derived. In order to suppress numerical pseudo-oscillations, the smoothness measurement function IS from the WENO limiter is integrated into the TVB(D)-minmod limiter, constructing an optimization problem based on the smoothness factor constraint, thereby realizing a TVB(D)-minmod limiter applicable to arbitrary high-order polynomial approximation. Subsequently, drawing on the ``reconstructed polynomial and the original high-order scheme's L2 -error constraint'' from the literature [1] , combined with our smoothness factor constraint, a bi-objective optimization problem is formulated to enable the TVB(D)-minmod limiter to balance oscillation suppression and high precision. As for hyperbolic conservation systems, limiters are typically required to be used in conjunction with local characteristic decomposition. To transform polynomials from the physical space to the characteristic space, an interpolation-based characteristic transformation scheme has been proposed, and its equivalence with the original moment characteristic transformation has been demonstrated in one-dimensional scenarios. Finally, the concept of ``flux vector splitting based on Jacobian eigenvalue decomposition'' has been applied to the conservative linear scalar transport equations and the nonlinear Burgers' equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16367v5</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhengrong Xie</dc:creator>
    </item>
    <item>
      <title>Strong Convergence of a Splitting Method for the Stochastic Complex Ginzburg-Landau Equation</title>
      <link>https://arxiv.org/abs/2412.07206</link>
      <description>arXiv:2412.07206v2 Announce Type: replace 
Abstract: We consider the numerical approximation of the stochastic complex Ginzburg-Landau equation with additive noise on the one dimensional torus. The complex nature of the equation means that many of the standard approaches developed for stochastic partial differential equations can not be directly applied. We use an energy approach to prove an existence and uniqueness result as well to obtain moment bounds on the stochastic PDE before introducing our numerical discretization. For such a well studied deterministic equation it is perhaps surprising that its numerical approximation in the stochastic setting has not been considered before. Our method is based on a spectral discretization in space and a Lie-Trotter splitting method in time. We obtain moment bounds for the numerical method before proving our main result: strong convergence on a set of arbitrarily large probability. From this we obtain a result on convergence in probability. We conclude with some numerical experiments that illustrate the effectiveness of our method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.07206v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marvin Jans (Lund University), Gabriel J. Lord (Radboud University), Mariya Ptashnyk (Heriot-Watt University)</dc:creator>
    </item>
    <item>
      <title>The Milstein scheme for singular SDEs with H\"older continuous drift</title>
      <link>https://arxiv.org/abs/2305.16004</link>
      <description>arXiv:2305.16004v2 Announce Type: replace-cross 
Abstract: We study the $L^p$ rate of convergence of the Milstein scheme for SDEs when the drift coefficients possess only H\"older regularity. If the diffusion is elliptic and sufficiently regular, we obtain rates consistent with the additive case. The proof relies on regularisation by noise techniques, particularly stochastic sewing, which in turn requires (at least asymptotically) sharp estimates on the law of the Milstein scheme, which may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.16004v2</guid>
      <category>math.PR</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>M\'at\'e Gerencs\'er, Gerald Lampl, Chengcheng Ling</dc:creator>
    </item>
    <item>
      <title>Sequence of pseudoequilibria describes the long-time behavior of the nonlinear noisy leaky integrate-and-fire model with large delay</title>
      <link>https://arxiv.org/abs/2403.00971</link>
      <description>arXiv:2403.00971v3 Announce Type: replace-cross 
Abstract: There is a wide range of mathematical models that describe populations of large numbers of neurons. In this article, we focus on nonlinear noisy leaky integrate-and-fire (NNLIF) models that describe neuronal activity at the level of the membrane potential. We introduce a sequence of states, which we call pseudoequilibria, and give evidence of their defining role in the behavior of the NNLIF system when a significant synaptic delay is considered. The advantage is that these states are determined solely by the system's parameters and are derived from a sequence of firing rates that result from solving a recurrence equation. We propose a strategy to show convergence to an equilibrium for a weakly connected system with large transmission delay, based on following the sequence of pseudoequilibria. Unlike direct entropy dissipation methods, this technique allows us to see how a large delay favors convergence. We present a detailed numerical study to support our results. This study helps us understand, among other phenomena, the appearance of periodic solutions in strongly inhibitory networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.00971v3</guid>
      <category>math.AP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mar\'ia J. C\'aceres, Jos\'e A. Ca\~nizo, Alejandro Ramos-Lora</dc:creator>
    </item>
    <item>
      <title>Enhanced Facial Feature Extraction and Recignation Using Optimal Fully Dispersed Haar-like Filters</title>
      <link>https://arxiv.org/abs/2404.10476</link>
      <description>arXiv:2404.10476v3 Announce Type: replace-cross 
Abstract: Haar-like filters are renowned for their simplicity, speed, and accuracy in various computer vision tasks. This paper proposes a novel algorithm to identify optimal fully dispersed Haar-like filters for enhanced facial feature extraction and recognation. Unlike traditional Haar-like filters, these novel filters allow pixels to move freely within images, enabling more effictive capture of intricate local features...</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10476v3</guid>
      <category>cs.CV</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zeinab Sedaghatjoo, Hossein Hosseinzadeh, Ahmad shirzadi</dc:creator>
    </item>
    <item>
      <title>Learning incomplete factorization preconditioners for GMRES</title>
      <link>https://arxiv.org/abs/2409.08262</link>
      <description>arXiv:2409.08262v2 Announce Type: replace-cross 
Abstract: Incomplete LU factorizations of sparse matrices are widely used as preconditioners in Krylov subspace methods to speed up solving linear systems. Unfortunately, computing the preconditioner itself can be time-consuming and sensitive to hyper-parameters. Instead, we replace the hand-engineered algorithm with a graph neural network that is trained to approximate the matrix factorization directly. To apply the output of the neural network as a preconditioner, we propose an output activation function that guarantees that the predicted factorization is invertible. Further, applying a graph neural network architecture allows us to ensure that the output itself is sparse which is desirable from a computational standpoint. We theoretically analyze and empirically evaluate different loss functions to train the learned preconditioners and show their effectiveness in decreasing the number of GMRES iterations and improving the spectral properties on synthetic data. The code is available at https://github.com/paulhausner/neural-incomplete-factorization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08262v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paul H\"ausner, Aleix Nieto Juscafresa, Jens Sj\"olund</dc:creator>
    </item>
  </channel>
</rss>
