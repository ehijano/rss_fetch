<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 09 Jul 2024 02:39:21 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 08 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Online Bayesian changepoint detection for network Poisson processes with community structure</title>
      <link>https://arxiv.org/abs/2407.04138</link>
      <description>arXiv:2407.04138v1 Announce Type: new 
Abstract: Network point processes often exhibit latent structure that govern the behaviour of the sub-processes. It is not always reasonable to assume that this latent structure is static, and detecting when and how this driving structure changes is often of interest. In this paper, we introduce a novel online methodology for detecting changes within the latent structure of a network point process. We focus on block-homogeneous Poisson processes, where latent node memberships determine the rates of the edge processes. We propose a scalable variational procedure which can be applied on large networks in an online fashion via a Bayesian forgetting factor applied to sequential variational approximations to the posterior distribution. The proposed framework is tested on simulated and real-world data, and it rapidly and accurately detects changes to the latent edge process rates, and to the latent node group memberships, both in an online manner. In particular, in an application on the Santander Cycles bike-sharing network in central London, we detect changes within the network related to holiday periods and lockdown restrictions between 2019 and 2020.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04138v1</guid>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joshua Corneck, Edward A. K. Cohen, James S. Martin, Francesco Sanna Passino</dc:creator>
    </item>
    <item>
      <title>Geometric statistics with subspace structure preservation for SPD matrices</title>
      <link>https://arxiv.org/abs/2407.03382</link>
      <description>arXiv:2407.03382v1 Announce Type: cross 
Abstract: We present a geometric framework for the processing of SPD-valued data that preserves subspace structures and is based on the efficient computation of extreme generalized eigenvalues. This is achieved through the use of the Thompson geometry of the semidefinite cone. We explore a particular geodesic space structure in detail and establish several properties associated with it. Finally, we review a novel inductive mean of SPD matrices based on this geometry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03382v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.DG</category>
      <category>stat.CO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Cyrus Mostajeran, Natha\"el Da Costa, Graham Van Goffrier, Rodolphe Sepulchre</dc:creator>
    </item>
    <item>
      <title>Continuous Optimization for Offline Change Point Detection and Estimation</title>
      <link>https://arxiv.org/abs/2407.03383</link>
      <description>arXiv:2407.03383v1 Announce Type: cross 
Abstract: This work explores use of novel advances in best subset selection for regression modelling via continuous optimization for offline change point detection and estimation in univariate Gaussian data sequences. The approach exploits reformulating the normal mean multiple change point model into a regularized statistical inverse problem enforcing sparsity. After introducing the problem statement, criteria and previous investigations via Lasso-regularization, the recently developed framework of continuous optimization for best subset selection (COMBSS) is briefly introduced and related to the problem at hand. Supervised and unsupervised perspectives are explored with the latter testing different approaches for the choice of regularization penalty parameters via the discrepancy principle and a confidence bound. The main result is an adaptation and evaluation of the COMBSS approach for offline normal mean multiple change-point detection via experimental results on simulated data for different choices of regularisation parameters. Results and future directions are discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03383v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hans Reimann, Sarat Moka, Georgy Sofronov</dc:creator>
    </item>
    <item>
      <title>Gaussian process regression with log-linear scaling for common non-stationary kernels</title>
      <link>https://arxiv.org/abs/2407.03608</link>
      <description>arXiv:2407.03608v1 Announce Type: cross 
Abstract: We introduce a fast algorithm for Gaussian process regression in low dimensions, applicable to a widely-used family of non-stationary kernels. The non-stationarity of these kernels is induced by arbitrary spatially-varying vertical and horizontal scales. In particular, any stationary kernel can be accommodated as a special case, and we focus especially on the generalization of the standard Mat\'ern kernel. Our subroutine for kernel matrix-vector multiplications scales almost optimally as $O(N\log N)$, where $N$ is the number of regression points. Like the recently developed equispaced Fourier Gaussian process (EFGP) methodology, which is applicable only to stationary kernels, our approach exploits non-uniform fast Fourier transforms (NUFFTs). We offer a complete analysis controlling the approximation error of our method, and we validate the method's practical performance with numerical experiments. In particular we demonstrate improved scalability compared to to state-of-the-art rank-structured approaches in spatial dimension $d&gt;1$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03608v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>stat.CO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>P. Michael Kielstra, Michael Lindsey</dc:creator>
    </item>
    <item>
      <title>Nested smoothing algorithms for inference and tracking of heterogeneous multi-scale state-space systems</title>
      <link>https://arxiv.org/abs/2204.07795</link>
      <description>arXiv:2204.07795v2 Announce Type: replace 
Abstract: Multi-scale problems, where variables of interest evolve in different time-scales and live in different state-spaces, can be found in many fields of science. Here, we introduce a new recursive methodology for Bayesian inference that aims at estimating the static parameters and tracking the dynamic variables of these kind of systems. Although the proposed approach works in rather general multi-scale systems, for clarity we analyze the case of a heterogeneous multi-scale model with 3 time-scales (static parameters, slow dynamic state variables and fast dynamic state variables). The proposed scheme, based on nested filtering methodology of P\'erez-Vieites et al. (2018), combines three intertwined layers of filtering techniques that approximate recursively the joint posterior probability distribution of the parameters and both sets of dynamic state variables given a sequence of partial and noisy observations. We explore the use of sequential Monte Carlo schemes in the first and second layers while we use an unscented Kalman filter to obtain a Gaussian approximation of the posterior probability distribution of the fast variables in the third layer. Some numerical results are presented for a stochastic two-scale Lorenz 96 model with unknown parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2204.07795v2</guid>
      <category>stat.CO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sara P\'erez-Vieites, Harold Molina-Bulla, Joaquin Miguez</dc:creator>
    </item>
    <item>
      <title>Bayesian inference for stochastic oscillatory systems using the phase-corrected Linear Noise Approximation</title>
      <link>https://arxiv.org/abs/2205.05955</link>
      <description>arXiv:2205.05955v4 Announce Type: replace 
Abstract: Likelihood-based inference in stochastic non-linear dynamical systems, such as those found in chemical reaction networks and biological clock systems, is inherently complex and has largely been limited to small and unrealistically simple systems. Recent advances in analytically tractable approximations to the underlying conditional probability distributions enable long-term dynamics to be accurately modelled, and make the large number of model evaluations required for exact Bayesian inference much more feasible. We propose a new methodology for inference in stochastic non-linear dynamical systems exhibiting oscillatory behaviour and show the parameters in these models can be realistically estimated from simulated data. Preliminary analyses based on the Fisher Information Matrix of the model can guide the implementation of Bayesian inference. We show that this parameter sensitivity analysis can predict which parameters are practically identifiable. Several Markov chain Monte Carlo algorithms are compared, with our results suggesting a parallel tempering algorithm consistently gives the best approach for these systems, which are shown to frequently exhibit multi-modal posterior distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.05955v4</guid>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ben Swallow, David A. Rand, Giorgos Minas</dc:creator>
    </item>
    <item>
      <title>Detecting influential observations in single-index Fr\'echet regression</title>
      <link>https://arxiv.org/abs/2311.17246</link>
      <description>arXiv:2311.17246v3 Announce Type: replace 
Abstract: Regression with random data objects is becoming increasingly common in modern data analysis. Unfortunately, this novel regression method is not immune to the trouble caused by unusual observations. A metric Cook's distance extending the original Cook's distances of Cook (1977) to regression between metric-valued response objects and Euclidean predictors is proposed. The performance of the metric Cook's distance is demonstrated in regression across four different response spaces in an extensive experimental study. Two real data applications involving the analyses of distributions of COVID-19 transmission in the State of Texas and the analyses of the structural brain connectivity networks are provided to illustrate the utility of the proposed method in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.17246v3</guid>
      <category>stat.CO</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abdul-Nasah Soale</dc:creator>
    </item>
    <item>
      <title>Active sampling: A machine-learning-assisted framework for finite population inference with optimal subsamples</title>
      <link>https://arxiv.org/abs/2212.10024</link>
      <description>arXiv:2212.10024v3 Announce Type: replace-cross 
Abstract: Data subsampling has become widely recognized as a tool to overcome computational and economic bottlenecks in analyzing massive datasets. We contribute to the development of adaptive design for estimation of finite population characteristics, using active learning and adaptive importance sampling. We propose an active sampling strategy that iterates between estimation and data collection with optimal subsamples, guided by machine learning predictions on yet unseen data. The method is illustrated on virtual simulation-based safety assessment of advanced driver assistance systems. Substantial performance improvements are demonstrated compared to traditional sampling methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.10024v3</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1080/00401706.2024.2374554</arxiv:DOI>
      <dc:creator>Henrik Imberg, Xiaomi Yang, Carol Flannagan, Jonas B\"argman</dc:creator>
    </item>
  </channel>
</rss>
