<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 26 Jul 2024 01:40:17 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 25 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Covering a Graph with Dense Subgraph Families, via Triangle-Rich Sets</title>
      <link>https://arxiv.org/abs/2407.16850</link>
      <description>arXiv:2407.16850v1 Announce Type: cross 
Abstract: Graphs are a fundamental data structure used to represent relationships in domains as diverse as the social sciences, bioinformatics, cybersecurity, the Internet, and more. One of the central observations in network science is that real-world graphs are globally sparse, yet contains numerous "pockets" of high edge density. A fundamental task in graph mining is to discover these dense subgraphs. Most common formulations of the problem involve finding a single (or a few) "optimally" dense subsets. But in most real applications, one does not care for the optimality. Instead, we want to find a large collection of dense subsets that covers a significant fraction of the input graph.
  We give a mathematical formulation of this problem, using a new definition of regularly triangle-rich (RTR) families. These families capture the notion of dense subgraphs that contain many triangles and have degrees comparable to the subgraph size. We design a provable algorithm, RTRExtractor, that can discover RTR families that approximately cover any RTR set. The algorithm is efficient and is inspired by recent results that use triangle counts for community testing and clustering.
  We show that RTRExtractor has excellent behavior on a large variety of real-world datasets. It is able to process graphs with hundreds of millions of edges within minutes. Across many datasets, RTRExtractor achieves high coverage using high edge density datasets. For example, the output covers a quarter of the vertices with subgraphs of edge density more than (say) $0.5$, for datasets with 10M+ edges. We show an example of how the output of RTRExtractor correlates with meaningful sets of similar vertices in a citation network, demonstrating the utility of RTRExtractor for unsupervised graph discovery tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16850v1</guid>
      <category>cs.SI</category>
      <category>cs.DS</category>
      <category>cs.IR</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sabyasachi Basu, Daniel Paul-Pena, Kun Qian, C. Seshadhri, Edward W Huang, Karthik Subbian</dc:creator>
    </item>
    <item>
      <title>Simple Grid Polygon Online Exploration Revisited</title>
      <link>https://arxiv.org/abs/2407.17208</link>
      <description>arXiv:2407.17208v1 Announce Type: cross 
Abstract: Due to some significantly contradicting research results, we reconsider the problem of the online exploration of a simple grid cell environment. In this model an agent attains local information about the direct four-neigbourship of a current grid cell and can also successively build a map of all detected cells. Beginning from a starting cell at the boundary of the environment, the agent has to visit any cell of the grid environment and finally has to return to its starting position. The performance of an online strategy is given by competitive analysis. We compare the number of overall cell visits (number of steps) of an online strategy to the number of such visits in the optimal offline solution under full information of the environment in advance. The corresponding worst-case ratio gives the competitive ratio. The aforementioned contradiction among two publications turns out to be as follows: There is a journal publication that claims to present an optimal competitive strategy with ratio 7/6 and a former conference paper that presents a lower bound of 20/17. In this note we extract the flaw in the upper bound and also present a new slightly improved and (as we think) simplified general lower bound of 13/11.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17208v1</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maximilian Brock, Martin Br\"uckmann, Elmar Langetepe, Raphael Wude</dc:creator>
    </item>
    <item>
      <title>Distance Reconstruction of Sparse Random Graphs</title>
      <link>https://arxiv.org/abs/2407.17376</link>
      <description>arXiv:2407.17376v1 Announce Type: cross 
Abstract: In the distance query model, we are given access to the vertex set of a $n$-vertex graph $G$, and an oracle that takes as input two vertices and returns the distance between these two vertices in $G$. We study how many queries are needed to reconstruct the edge set of $G$ when $G$ is sampled according to the $G(n,p)$ Erd\H{o}s-Renyi-Gilbert distribution. Our approach applies to a large spectrum of values for $p$ starting slightly above the connectivity threshold: $p \geq \frac{2000 \log n}{n}$. We show that there exists an algorithm that reconstructs $G \sim G(n,p)$ using $O( \Delta^2 n \log n )$ queries in expectation, where $\Delta$ is the expected average degree of $G$. In particular, for $p \in [\frac{2000 \log n}{n}, \frac{\log^2 n}{n}]$ the algorithm uses $O(n \log^5 n)$ queries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17376v1</guid>
      <category>math.CO</category>
      <category>cs.DS</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paul Bastide</dc:creator>
    </item>
    <item>
      <title>Competitive Data-Structure Dynamization</title>
      <link>https://arxiv.org/abs/2011.02615</link>
      <description>arXiv:2011.02615v4 Announce Type: replace 
Abstract: Data-structure dynamization is a general approach for making static data structures dynamic. It is used extensively in geometric settings and in the guise of so-called merge (or compaction) policies in big-data databases such as Google Bigtable and LevelDB (our focus). Previous theoretical work is based on worst-case analyses for uniform inputs -- insertions of one item at a time and constant read rate. In practice, merge policies must not only handle batch insertions and varying read/write ratios, they can take advantage of such non-uniformity to reduce cost on a per-input basis.
  To model this, we initiate the study of data-structure dynamization through the lens of competitive analysis, via two new online set-cover problems. For each, the input is a sequence of disjoint sets of weighted items. The sets are revealed one at a time. The algorithm must respond to each with a set cover that covers all items revealed so far. It obtains the cover incrementally from the previous cover by adding one or more sets and optionally removing existing sets. For each new set the algorithm incurs build cost equal to the weight of the items in the set. In the first problem the objective is to minimize total build cost plus total query cost, where the algorithm incurs a query cost at each time $t$ equal to the current cover size. In the second problem, the objective is to minimize the build cost while keeping the query cost from exceeding $k$ (a given parameter) at any time. We give deterministic online algorithms for both variants, with competitive ratios of $\Theta(\log^* n)$ and $k$, respectively. The latter ratio is optimal for the second variant.</description>
      <guid isPermaLink="false">oai:arXiv.org:2011.02615v4</guid>
      <category>cs.DS</category>
      <category>cs.DB</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3672614</arxiv:DOI>
      <arxiv:journal_reference>ACM Trans. Algorithms. June 2024</arxiv:journal_reference>
      <dc:creator>Claire Mathieu, Rajmohan Rajaraman, Neal E. Young, Arman Yousefi</dc:creator>
    </item>
    <item>
      <title>A fast algorithm for All-Pairs-Shortest-Paths suitable for neural networks</title>
      <link>https://arxiv.org/abs/2308.07403</link>
      <description>arXiv:2308.07403v2 Announce Type: replace 
Abstract: Given a directed graph of nodes and edges connecting them, a common problem is to find the shortest path between any two nodes. Here we show that the shortest path distances can be found by a simple matrix inversion: If the edges are given by the adjacency matrix $A_{ij}$ then with a suitably small value of $\gamma$ the shortest path distances are
  $$ D_{ij} = \operatorname{ceil} \left( \log_{\gamma} {\left[ {\left({\mathbf{I}}-\gamma {\mathbf{A}}\right)^{-1}} \right]}_{ij} \right)$$
  We derive several graph-theoretic bounds on the value of $\gamma$, and explore its useful range with numerics on different graph types. Even when the distance function is not globally accurate across the entire graph, it still works locally to instruct pursuit of the shortest path. In this mode, it also extends to weighted graphs with positive edge weights. For a wide range of dense graphs this distance function is computationally faster than the best available alternative. Finally we show that this method leads naturally to a neural network solution of the all-pairs-shortest-path problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.07403v2</guid>
      <category>cs.DS</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zeyu Jing, Markus Meister</dc:creator>
    </item>
    <item>
      <title>Counting on General Run-Length Grammars</title>
      <link>https://arxiv.org/abs/2406.00221</link>
      <description>arXiv:2406.00221v2 Announce Type: replace 
Abstract: We introduce a data structure for counting pattern occurrences in texts compressed with any run-length context-free grammar. Our structure uses space proportional to the grammar size and counts the occurrences of a pattern of length $m$ in a text of length $n$ in time (O(m\log^{2+\epsilon} n)), for any constant (\epsilon &gt; 0). This closes an open problem posed by Christiansen et al.~[ACM TALG 2020] and enhances our abilities for computation over compressed data; we give an example application.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00221v2</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gonzalo Navarro, Alejandro Pacheco</dc:creator>
    </item>
    <item>
      <title>A Faster Branching Algorithm for the Maximum $k$-Defective Clique Problem</title>
      <link>https://arxiv.org/abs/2407.16588</link>
      <description>arXiv:2407.16588v2 Announce Type: replace 
Abstract: A $k$-defective clique of an undirected graph $G$ is a subset of its vertices that induces a nearly complete graph with a maximum of $k$ missing edges. The maximum $k$-defective clique problem, which asks for the largest $k$-defective clique from the given graph, is important in many applications, such as social and biological network analysis. In the paper, we propose a new branching algorithm that takes advantage of the structural properties of the $k$-defective clique and uses the efficient maximum clique algorithm as a subroutine. As a result, the algorithm has a better asymptotic running time than the existing ones. We also investigate upper-bounding techniques and propose a new upper bound utilizing the \textit{conflict relationship} between vertex pairs. Because conflict relationship is common in many graph problems, we believe that this technique can be potentially generalized. Finally, experiments show that our algorithm outperforms state-of-the-art solvers on a wide range of open benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16588v2</guid>
      <category>cs.DS</category>
      <category>cs.AI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chunyu Luo, Yi Zhou, Zhengren Wang, Mingyu Xiao</dc:creator>
    </item>
    <item>
      <title>Efficient Convex Optimization Requires Superlinear Memory</title>
      <link>https://arxiv.org/abs/2203.15260</link>
      <description>arXiv:2203.15260v2 Announce Type: replace-cross 
Abstract: We show that any memory-constrained, first-order algorithm which minimizes $d$-dimensional, $1$-Lipschitz convex functions over the unit ball to $1/\mathrm{poly}(d)$ accuracy using at most $d^{1.25 - \delta}$ bits of memory must make at least $\tilde{\Omega}(d^{1 + (4/3)\delta})$ first-order queries (for any constant $\delta \in [0, 1/4]$). Consequently, the performance of such memory-constrained algorithms are a polynomial factor worse than the optimal $\tilde{O}(d)$ query bound for this problem obtained by cutting plane methods that use $\tilde{O}(d^2)$ memory. This resolves a COLT 2019 open problem of Woodworth and Srebro.</description>
      <guid isPermaLink="false">oai:arXiv.org:2203.15260v2</guid>
      <category>cs.LG</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Annie Marsden, Vatsal Sharan, Aaron Sidford, Gregory Valiant</dc:creator>
    </item>
    <item>
      <title>Unit-length Rectangular Drawings of Graphs</title>
      <link>https://arxiv.org/abs/2208.14142</link>
      <description>arXiv:2208.14142v3 Announce Type: replace-cross 
Abstract: A rectangular drawing of a planar graph $G$ is a planar drawing of $G$ in which vertices are mapped to grid points, edges are mapped to horizontal and vertical straight-line segments, and faces are drawn as rectangles. Sometimes this latter constraint is relaxed for the outer face. In this paper, we study rectangular drawings in which the edges have unit length. We show a complexity dichotomy for the problem of deciding the existence of a unit-length rectangular drawing, depending on whether the outer face must also be drawn as a rectangle or not. Specifically, we prove that the problem is NP-complete for biconnected graphs when the drawing of the outer face is not required to be a rectangle, even if the sought drawing must respect a given planar embedding, whereas it is polynomial-time solvable, both in the fixed and the variable embedding settings, if the outer face is required to be drawn as a rectangle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.14142v3</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Carlos Alegria, Giordano Da Lozzo, Giuseppe Di Battista, Fabrizio Frati, Fabrizio Grosso, Maurizio Patrignani</dc:creator>
    </item>
    <item>
      <title>Efficiently Reconfiguring a Connected Swarm of Labeled Robots</title>
      <link>https://arxiv.org/abs/2209.11028</link>
      <description>arXiv:2209.11028v2 Announce Type: replace-cross 
Abstract: When considering motion planning for a swarm of $n$ labeled robots, we need to rearrange a given start configuration into a desired target configuration via a sequence of parallel, collision-free robot motions. The objective is to reach the new configuration in a minimum amount of time; an important constraint is to keep the swarm connected at all times. Problems of this type have been considered before, with recent notable results achieving constant stretch for not necessarily connected reconfiguration: If mapping the start configuration to the target configuration requires a maximum Manhattan distance of $d$, the total duration of an overall schedule can be bounded to $\mathcal{O}(d)$, which is optimal up to constant factors. However, constant stretch could only be achieved if disconnected reconfiguration is allowed, or for scaled configurations (which arise by increasing all dimensions of a given object by the same multiplicative factor) of unlabeled robots.
  We resolve these major open problems by (1) establishing a lower bound of $\Omega(\sqrt{n})$ for connected, labeled reconfiguration and, most importantly, by (2) proving that for scaled arrangements, constant stretch for connected reconfiguration can be achieved. In addition, we show that (3) it is NP-complete to decide whether a makespan of 2 can be achieved, while it is possible to check in polynomial time whether a makespan of 1 can be achieved.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.11028v2</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <category>cs.RO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>S\'andor P. Fekete, Peter Kramer, Christian Rieck, Christian Scheffer, Arne Schmidt</dc:creator>
    </item>
  </channel>
</rss>
