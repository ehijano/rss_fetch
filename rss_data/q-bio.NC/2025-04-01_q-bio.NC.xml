<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 02 Apr 2025 02:02:34 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>From Eye to Mind: brain2text Decoding Reveals the Neural Mechanisms of Visual Semantic Processing</title>
      <link>https://arxiv.org/abs/2503.22697</link>
      <description>arXiv:2503.22697v1 Announce Type: new 
Abstract: Deciphering the neural mechanisms that transform sensory experiences into meaningful semantic representations is a fundamental challenge in cognitive neuroscience. While neuroimaging has mapped a distributed semantic network, the format and neural code of semantic content remain elusive, particularly for complex, naturalistic stimuli. Traditional brain decoding, focused on visual reconstruction, primarily captures low-level perceptual features, missing the deeper semantic essence guiding human cognition. Here, we introduce a paradigm shift by directly decoding fMRI signals into textual descriptions of viewed natural images. Our novel deep learning model, trained without visual input, achieves state-of-the-art semantic decoding performance, generating meaningful captions that capture the core semantic content of complex scenes. Neuroanatomical analysis reveals the critical role of higher-level visual regions, including MT+, ventral stream visual cortex, and inferior parietal cortex, in this semantic transformation. Category-specific decoding further demonstrates nuanced neural representations for semantic dimensions like animacy and motion. This text-based decoding approach provides a more direct and interpretable window into the brain's semantic encoding than visual reconstruction, offering a powerful new methodology for probing the neural basis of complex semantic processing, refining our understanding of the distributed semantic network, and potentially inspiring brain-inspired language models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.22697v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Feihan Feng, Jingxin Nie</dc:creator>
    </item>
    <item>
      <title>How to set up a psychedelic study: Unique considerations for research involving human participants</title>
      <link>https://arxiv.org/abs/2503.22808</link>
      <description>arXiv:2503.22808v2 Announce Type: new 
Abstract: Setting up a psychedelic study can be a long, arduous, and kafkaesque process. This rapidly-developing field poses several unique challenges for researchers, necessitating a range of considerations that have not yet been standardised. Many of the complexities inherent to psychedelic research also challenge existing assumptions around, for example, approaches to psychiatric prescribing, the conceptual framing of the placebo effect, and definitions of selfhood. This review paper brings together several of the major psychedelic research teams across the United Kingdom to formalise these unique considerations, identify continuing areas of debate, and provide a practical, experience-based guide, with recommendations for policymakers and future researchers intending to set up a psychedelic research study or clinical trial. We approach this such that the paper can either be read end to end, or treated as a manual: readers can dip into relevant sections as needed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.22808v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marcus J. Glennon, Catherine I. V. Bird, Prateek Yadav, Patrick Kleine, Shayam Suseelan, Christina Boman-Markaki, Vasileia Kotoula, Matt Butler, Robert Leech, Leor Roseman, David Erritzoe, Deepak P. Srivastava, Celia Morgan, Christopher Timmermann, Greg Cooper, Jeremy I. Skipper, James Rucker, Sunjeev K. Kamboj, Mitul A. Mehta, Ravi K. Das, Anjali Bhat</dc:creator>
    </item>
    <item>
      <title>Time, control, and the nervous system</title>
      <link>https://arxiv.org/abs/2503.22917</link>
      <description>arXiv:2503.22917v1 Announce Type: new 
Abstract: Because organisms are able to sense its passage, it is perhaps tempting to treat time as a sensory modality, akin to vision or audition. Indeed, certain features of sensory estimation, such as Weber's law, apply to timing and sensation alike (Gibbon, 1977; Pardo-Vazquez et al., 2019). However, from an organismal perspective, time is a derived feature of other signals, not a stimulus that can be readily transduced by sensory receptors. Its importance for biology lies in the fact that the physical world comprises a complex dynamical system. The multiscale spatiotemporal structure of sensory and internally generated signals within an organism is the informational fabric underlying its ability to control behavior. Viewed this way, temporal computations assume a more fundamental role than is implied by treating time as just another element of the experienced world (Paton &amp; Buonomano, 2018). Thus, in this review we focus on temporal processing as a means of approaching the more general problem of how the nervous system produces adaptive behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.22917v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Caroline Haimerl, Filipe S. Rodrigues, Joseph J. Paton</dc:creator>
    </item>
    <item>
      <title>Simulation of Non-Ordinary Consciousness</title>
      <link>https://arxiv.org/abs/2503.23245</link>
      <description>arXiv:2503.23245v1 Announce Type: new 
Abstract: The symbolic architecture of non-ordinary consciousness remains largely unmapped in cognitive science and artificial intelligence. While conventional models prioritize rational coherence, altered states such as those induced by psychedelics reveal distinct symbolic regimes characterized by recursive metaphor, ego dissolution, and semantic destabilization. We present \textit{Glyph}, a generative symbolic interface designed to simulate psilocybin-like symbolic cognition in large language models. Rather than modeling perception or mood, Glyph enacts symbolic transformation through recursive reentry, metaphoric modulation, and entropy-scaled destabilization -- a triadic operator formalized within a tensorial linguistic framework. Experimental comparison with baseline GPT-4o reveals that Glyph consistently generates high-entropy, metaphor-saturated, and ego-dissolving language across diverse symbolic prompt categories. These results validate the emergence of non-ordinary cognitive patterns and support a new paradigm for simulating altered consciousness through language. Glyph opens novel pathways for modeling symbolic cognition, exploring metaphor theory, and encoding knowledge in recursively altered semantic spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23245v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Khalid M. Saqr</dc:creator>
    </item>
    <item>
      <title>Spatiotemporal Learning of Brain Dynamics from fMRI Using Frequency-Specific Multi-Band Attention for Cognitive and Psychiatric Applications</title>
      <link>https://arxiv.org/abs/2503.23394</link>
      <description>arXiv:2503.23394v1 Announce Type: new 
Abstract: Understanding how the brain's complex nonlinear dynamics give rise to adaptive cognition and behavior is a central challenge in neuroscience. These dynamics exhibit scale-free and multifractal properties, influencing the reconfiguration of neural networks. However, conventional neuroimaging models are constrained by linear and stationary assumptions, limiting their ability to capture these processes. Transformer-based architectures, known for capturing long-range dependencies, align well with the brain's hierarchical and temporal organization. We introduce Multi-Band Brain Net (MBBN), a transformer-based framework that models frequency-specific spatiotemporal brain dynamics from fMRI by integrating scale-free network principles with frequency-resolved multi-band self-attention. Trained on three large-scale neuroimaging cohorts (UK Biobank, ABCD, ABIDE) totaling 45,951 individuals, MBBN reveals previously undetectable frequency-dependent network interactions, shedding light on connectivity disruptions in psychiatric conditions (ADHD, ASD, depression). This validation shows robust generalizability and highlights core neural principles conserved across populations. MBBN achieves up to 30.59% higher predictive accuracy than state-of-the-art methods, demonstrating the advantage of frequency-informed spatiotemporal modeling in capturing latent neural computations. MBBN's interpretability uncovers novel frequency-specific biomarkers for neurodevelopmental disorders, providing insights into the hierarchical organization of brain function. By offering an interpretable framework for spatiotemporal learning, MBBN provides insights into how neural computations underpin cognitive function and psychiatric vulnerability, with implications for brain decoding, cognitive neuroscience, and precision psychiatry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23394v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Sangyoon Bae, Junbeom Kwon, Shinjae Yoo, Jiook Cha</dc:creator>
    </item>
    <item>
      <title>Why does tinnitus vary with naps? A polysomnographic prospective study exploring the somatosensory hypothesis</title>
      <link>https://arxiv.org/abs/2503.23808</link>
      <description>arXiv:2503.23808v1 Announce Type: new 
Abstract: Background: Tinnitus, defined as the conscious awareness of a noise without any identifiable corresponding external acoustic source, can be modulated by various factors. Among these factors, tinnitus patients commonly report drastic increases of tinnitus loudness following nap sleep. Previous studies have suggested that this clinical pattern could be attributed to a somatosensory modulation of tinnitus. To our knowledge, no polysomnographic study has been carried out to assess this hypothesis.
Methods: For this observational prospective study, 37 participants reporting frequent increases of tinnitus following naps were recruited. They participated to six full-polysomnography nap attempts over two days. Audiological and kinesiologic tests were conducted before and after each nap attempt.
Results: 197 naps were collected. Each nap at each time of day elicited an overall significant increase in tinnitus minimum masking level (MML). Each inter nap period elicited an overall significant decrease. Tinnitus modulations were found significantly correlated with nap sleep duration (Visual numeric scale on tinnitus loudness, VNS-L, p &lt; 0.05), with snoring duration (MML, p &lt; 0.001), with snoring average sound level (VNS on tinnitus intrusiveness, VNS-I, p &lt; 0.05) and with sleep apnea count (VNS-I, p &lt; 0.001).
Conclusions: This study confirms objectively that tinnitus may increase following naps. No association was found between these modulations and somatosensory modulations involving the temporomandibular joint and cervical areas. However, it may be possible that nap-induced tinnitus modulations are a hidden form of somatosensory modulation as snoring and sleep apnea events are often related to tensor veli palatini muscle dysfunction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23808v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.heares.2024.109152</arxiv:DOI>
      <arxiv:journal_reference>Hearing Research, 2025, 455, pp.109152</arxiv:journal_reference>
      <dc:creator>Robin Guillard (GIPSA-VIBS), Vincent Philippe (VIFASOM), Adam Hessas (VIFASOM), Brice Faraut (VIFASOM), Sarah Michiels (UHasselt, UZA), Minchul Park (GIPSA-VIBS), Marco Congedo (GIPSA-VIBS), Alain Londero (VIFASOM), Damien L\'eger (VIFASOM)</dc:creator>
    </item>
    <item>
      <title>Renormalization group analysis reveals universality classes of stochastic spiking neuron networks</title>
      <link>https://arxiv.org/abs/2301.09600</link>
      <description>arXiv:2301.09600v3 Announce Type: replace 
Abstract: The critical brain hypothesis posits that neural circuits may operate close to ``critical points'' -- boundaries between different phases of collective activity. This has been argued to have functional benefits for neural computation. Studies investigating whether neural circuits are poised near critical points have largely relied on establishing power laws in neural data, while a fundamental understanding of critical phenomena requires a renormalization group (RG) analysis. However, neural activity is typically non-Gaussian, nonlinear, and non-local, rendering models that capture all of these features difficult to study using standard statistical physics techniques. We overcome these issues and adapt the non-perturbative renormalization group (NPRG) to provide the first RG analysis of networks of stochastic spiking neurons. We show that neural populations can belong to at least two important universality classes: 1) in networks with an absorbing state there is a transition between sustained and extinguished activity that belongs to the directed percolation universality class, and 2) in spontaneously active networks there is a continuous transition between high and low firing rate states that belongs to the Ising model universality class. We verify our theoretical results by simulating the network model on lattices in $2$ and $3$ dimensions, recovering known exponents, and then investigate critical phenomena in networks of sparsely-connected excitatory neurons and densely-connected inhibitory neurons. Depending on the amount of inhibitory feedback, these networks may display mean-field exponents or anomalous exponents close to -- but potentially not equal to -- lattices of the same effective dimension.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.09600v3</guid>
      <category>q-bio.NC</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.soft</category>
      <category>cond-mat.stat-mech</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Braden A. W. Brinkman</dc:creator>
    </item>
    <item>
      <title>Exploring Cognitive Paradoxes in Video Games: A Quantum Mechanical Perspective</title>
      <link>https://arxiv.org/abs/2307.08758</link>
      <description>arXiv:2307.08758v2 Announce Type: replace 
Abstract: This paper introduces a quantum-mechanical model that bridges the realms of cognition and quantum mechanics, offering a novel perspective on decision-making under risk and perceptual reversals. By integrating quantum theories addressing decision-theoretic anomalies with examples from immersive video games like "Deal or No Deal", we seek to elucidate complex human cognitive behaviours. Study 1 showcases the proposed quantum model's superiority over traditional decision-making approaches using the "Deal or No Deal" video game experiment. In Study 2, we apply our model to bistable perceptions, taking the Necker cube from the Necker game as a primary example. While previous works have hinted at connections between quantum mechanics and cognition, Study 3 provides a more tangible link, likening the physics that underpins quantum tunnelling to an eye blink's role in perceptual reversals. Conclusively, our model displays a promising ability to interpret diverse optical illusions and psychological phenomena, marking a significant stride in understanding human decision making.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.08758v2</guid>
      <category>q-bio.NC</category>
      <category>cs.CV</category>
      <category>physics.bio-ph</category>
      <category>quant-ph</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ivan S. Maksymov, Ganna Pogrebna</dc:creator>
    </item>
    <item>
      <title>Nonlinear classification of neural manifolds with contextual information</title>
      <link>https://arxiv.org/abs/2405.06851</link>
      <description>arXiv:2405.06851v2 Announce Type: replace 
Abstract: Understanding how neural systems efficiently process information through distributed representations is a fundamental challenge at the interface of neuroscience and machine learning. Recent approaches analyze the statistical and geometrical attributes of neural representations as population-level mechanistic descriptors of task implementation. In particular, manifold capacity has emerged as a promising framework linking population geometry to the separability of neural manifolds. However, this metric has been limited to linear readouts. To address this limitation, we introduce a theoretical framework that leverages latent directions in input space, which can be related to contextual information. We derive an exact formula for the context-dependent manifold capacity that depends on manifold geometry and context correlations, and validate it on synthetic and real data. Our framework's increased expressivity captures representation reformatting in deep networks at early stages of the layer hierarchy, previously inaccessible to analysis. As context-dependent nonlinearity is ubiquitous in neural systems, our data-driven and theoretically grounded approach promises to elucidate context-dependent computation across scales, datasets, and models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06851v2</guid>
      <category>q-bio.NC</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.NE</category>
      <category>stat.ML</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Francesca Mignacco, Chi-Ning Chou, SueYeon Chung</dc:creator>
    </item>
    <item>
      <title>The Geometry of Concepts: Sparse Autoencoder Feature Structure</title>
      <link>https://arxiv.org/abs/2410.19750</link>
      <description>arXiv:2410.19750v2 Announce Type: replace 
Abstract: Sparse autoencoders have recently produced dictionaries of high-dimensional vectors corresponding to the universe of concepts represented by large language models. We find that this concept universe has interesting structure at three levels: 1) The "atomic" small-scale structure contains "crystals" whose faces are parallelograms or trapezoids, generalizing well-known examples such as (man-woman-king-queen). We find that the quality of such parallelograms and associated function vectors improves greatly when projecting out global distractor directions such as word length, which is efficiently done with linear discriminant analysis. 2) The "brain" intermediate-scale structure has significant spatial modularity; for example, math and code features form a "lobe" akin to functional lobes seen in neural fMRI images. We quantify the spatial locality of these lobes with multiple metrics and find that clusters of co-occurring features, at coarse enough scale, also cluster together spatially far more than one would expect if feature geometry were random. 3) The "galaxy" scale large-scale structure of the feature point cloud is not isotropic, but instead has a power law of eigenvalues with steepest slope in middle layers. We also quantify how the clustering entropy depends on the layer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19750v2</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.3390/e27040344</arxiv:DOI>
      <arxiv:journal_reference>Entropy 2025, 27(4), 344</arxiv:journal_reference>
      <dc:creator>Yuxiao Li, Eric J. Michaud, David D. Baek, Joshua Engels, Xiaoqing Sun, Max Tegmark</dc:creator>
    </item>
    <item>
      <title>ConFER: A Neurally Constrained Computational Model of Context-Dependent Fear Extinction Recall and Relapse</title>
      <link>https://arxiv.org/abs/2411.08140</link>
      <description>arXiv:2411.08140v2 Announce Type: replace 
Abstract: Exposure therapy, a standard treatment for anxiety disorders, relies on fear extinction. However, extinction recall is often limited to the spatial and temporal context in which extinction is learned, leading to fear relapse in new settings or after delays. Animal studies offer insights into fear extinction in humans. Computational models that integrate these findings into a neurally grounded framework, while generating testable hypotheses for humans, can bridge this gap. Current models either focus on neuron-level activity, limiting their scope, or abstract away entirely from neural mechanisms. They also often overlook the distinct contributions of cue and context in fear extinction and recall. To address these gaps, we present ConFER, a neurally constrained model of fear extinction, recall, and relapse. ConFER integrates findings from the neural fear circuit, modeling distinct pathways for cue and context processing. These pathways independently activate positive and/or negative memory engrams in the basolateral amygdala, competing to determine the fear response. ConFER simulates fear renewal and spontaneous recovery across context combinations, while generating novel, testable predictions. Notably, it predicts counterconditioning may better prevent relapse than extinction in new contexts or after delays. By mechanistically modeling fear relapse, ConFER offers insights to improve exposure therapy outcomes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08140v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shreya K. Rajagopal, Thad A. Polk</dc:creator>
    </item>
    <item>
      <title>On Questions of Predictability and Control of an Intelligent System Using Probabilistic State-Transitions</title>
      <link>https://arxiv.org/abs/2503.06374</link>
      <description>arXiv:2503.06374v3 Announce Type: replace 
Abstract: One of the central aims of neuroscience is to reliably predict the behavioral response of an organism using its neural activity. If possible, this implies we can causally manipulate the neural response and design brain-computer-interface systems to alter behavior, and vice-versa. Hence, predictions play an important role in both fundamental neuroscience and its applications. Can we predict the neural and behavioral states of an organism at any given time? Can we predict behavioral states using neural states, and vice-versa, and is there a memory-component required to reliably predict such states? Are the predictions computable within a given timescale to meaningfully stimulate and make the system reach the desired states? Through a series of mathematical treatments, such conjectures and questions are discussed. Answering them might be key for future developments in understanding intelligence and designing brain-computer-interfaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.06374v3</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jayanth R Taranath</dc:creator>
    </item>
    <item>
      <title>Orientation selectivity properties for integrated affine quasi quadrature models of complex cells</title>
      <link>https://arxiv.org/abs/2503.21611</link>
      <description>arXiv:2503.21611v3 Announce Type: replace 
Abstract: This paper presents an analysis of the orientation selectivity properties of idealized models of complex cells in terms of affine quasi quadrature measures, which combine the responses of idealized models of simple cells in terms of affine Gaussian derivatives by (i) pointwise squaring, (ii) summation of responses for different orders of spatial derivation and (iii) spatial integration. Specifically, this paper explores the consequences of assuming that the family of spatial receptive fields should be covariant under spatial affine transformations, thereby implying that the receptive fields ought to span a variability over the degree of elongation.
  We investigate the theoretical properties of three main ways of defining idealized models of complex cells and compare the predictions from these models to neurophysiologically obtained receptive field histograms over the resultant of biological orientation selectivity curves. It is shown that the extended modelling mechanism lead to more uniform behaviour and a wider span over the values of the resultat that are covered, compared to earlier presented idealized models of complex cells without spatial integration. More generally, we propose that the presented methodology could be used as a new tool to evaluate other computational models of complex cells in relation to biological measurements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21611v3</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tony Lindeberg</dc:creator>
    </item>
    <item>
      <title>Triple Phase Transitions: Understanding the Learning Dynamics of Large Language Models from a Neuroscience Perspective</title>
      <link>https://arxiv.org/abs/2502.20779</link>
      <description>arXiv:2502.20779v2 Announce Type: replace-cross 
Abstract: Large language models (LLMs) often exhibit abrupt emergent behavior, whereby new abilities arise at certain points during their training. This phenomenon, commonly referred to as a ''phase transition'', remains poorly understood. In this study, we conduct an integrative analysis of such phase transitions by examining three interconnected perspectives: the similarity between LLMs and the human brain, the internal states of LLMs, and downstream task performance. We propose a novel interpretation for the learning dynamics of LLMs that vary in both training data and architecture, revealing that three phase transitions commonly emerge across these models during training: (1) alignment with the entire brain surges as LLMs begin adhering to task instructions Brain Alignment and Instruction Following, (2) unexpectedly, LLMs diverge from the brain during a period in which downstream task accuracy temporarily stagnates Brain Detachment and Stagnation, and (3) alignment with the brain reoccurs as LLMs become capable of solving the downstream tasks Brain Realignment and Consolidation. These findings illuminate the underlying mechanisms of phase transitions in LLMs, while opening new avenues for interdisciplinary research bridging AI and neuroscience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20779v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuko Nakagi, Keigo Tada, Sota Yoshino, Shinji Nishimoto, Yu Takagi</dc:creator>
    </item>
    <item>
      <title>Representational Similarity via Interpretable Visual Concepts</title>
      <link>https://arxiv.org/abs/2503.15699</link>
      <description>arXiv:2503.15699v2 Announce Type: replace-cross 
Abstract: How do two deep neural networks differ in how they arrive at a decision? Measuring the similarity of deep networks has been a long-standing open question. Most existing methods provide a single number to measure the similarity of two networks at a given layer, but give no insight into what makes them similar or dissimilar. We introduce an interpretable representational similarity method (RSVC) to compare two networks. We use RSVC to discover shared and unique visual concepts between two models. We show that some aspects of model differences can be attributed to unique concepts discovered by one model that are not well represented in the other. Finally, we conduct extensive evaluation across different vision model architectures and training protocols to demonstrate its effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15699v2</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Neehar Kondapaneni, Oisin Mac Aodha, Pietro Perona</dc:creator>
    </item>
  </channel>
</rss>
