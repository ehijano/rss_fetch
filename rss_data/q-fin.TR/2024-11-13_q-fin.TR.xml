<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.TR updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.TR</link>
    <description>q-fin.TR updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.TR" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 13 Nov 2024 05:00:23 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Reinforcement Learning Framework for Quantitative Trading</title>
      <link>https://arxiv.org/abs/2411.07585</link>
      <description>arXiv:2411.07585v1 Announce Type: new 
Abstract: The inherent volatility and dynamic fluctuations within the financial stock market underscore the necessity for investors to employ a comprehensive and reliable approach that integrates risk management strategies, market trends, and the movement trends of individual securities. By evaluating specific data, investors can make more informed decisions. However, the current body of literature lacks substantial evidence supporting the practical efficacy of reinforcement learning (RL) agents, as many models have only demonstrated success in back testing using historical data. This highlights the urgent need for a more advanced methodology capable of addressing these challenges. There is a significant disconnect in the effective utilization of financial indicators to better understand the potential market trends of individual securities. The disclosure of successful trading strategies is often restricted within financial markets, resulting in a scarcity of widely documented and published strategies leveraging RL. Furthermore, current research frequently overlooks the identification of financial indicators correlated with various market trends and their potential advantages.
  This research endeavors to address these complexities by enhancing the ability of RL agents to effectively differentiate between positive and negative buy/sell actions using financial indicators. While we do not address all concerns, this paper provides deeper insights and commentary on the utilization of technical indicators and their benefits within reinforcement learning. This work establishes a foundational framework for further exploration and investigation of more complex scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07585v1</guid>
      <category>q-fin.TR</category>
      <category>cs.AI</category>
      <category>q-fin.CP</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alhassan S. Yasin, Prabdeep S. Gill</dc:creator>
    </item>
    <item>
      <title>Implementing Dynamic Pricing Across Multiple Pricing Groups in Real Estate</title>
      <link>https://arxiv.org/abs/2411.07732</link>
      <description>arXiv:2411.07732v1 Announce Type: cross 
Abstract: This article presents a mathematical model of dynamic pricing for real estate (RE) that incorporates multiple pricing groups, thereby expanding the capabilities of existing models. The developed model solves the problem of maximizing aggregate cumulative revenue at the end of the sales period while meeting the revenue and sales goals. A method is proposed for distributing aggregate cumulative revenue goals across different RE pricing groups. The model is further modified to account for the time value of money and the real estate value increase as construction progresses. The algorithm for constructing a pricing policy for multiple pricing groups is described, and numerical simulations are performed to demonstrate how the algorithm operates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07732v1</guid>
      <category>q-fin.MF</category>
      <category>econ.TH</category>
      <category>q-fin.CP</category>
      <category>q-fin.TR</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Lev Razumovskiy, Mariya Gerasimova, Nikolay Karenin, Mikhail Safro</dc:creator>
    </item>
    <item>
      <title>Mean field equilibrium asset pricing model with habit formation</title>
      <link>https://arxiv.org/abs/2406.02155</link>
      <description>arXiv:2406.02155v2 Announce Type: replace-cross 
Abstract: This paper presents an asset pricing model in an incomplete market involving a large number of heterogeneous agents based on the mean field game theory. In the model, we incorporate habit formation in consumption preferences, which has been widely used to explain various phenomena in financial economics. In order to characterize the market-clearing equilibrium, we derive a quadratic-growth mean field backward stochastic differential equation (BSDE) and study its well-posedness and asymptotic behavior in the large population limit. Additionally, we introduce an exponential quadratic Gaussian reformulation of the asset pricing model, in which the solution is obtained in a semi-analytic form.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.02155v2</guid>
      <category>q-fin.MF</category>
      <category>q-fin.PR</category>
      <category>q-fin.TR</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Masaaki Fujii, Masashi Sekine</dc:creator>
    </item>
  </channel>
</rss>
