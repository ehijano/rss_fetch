<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 05 Jun 2025 01:38:25 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Characterization of latency and jitter in TSN emulation</title>
      <link>https://arxiv.org/abs/2506.02133</link>
      <description>arXiv:2506.02133v1 Announce Type: new 
Abstract: This research focuses on timestamping methods for profiling network traffic in software-based environments. Accurate timestamping is crucial for evaluating network performance, particularly in Time-Sensitive Networking (TSN). We explore and compare four timestamping techniques within a TSN emulation context, though its findings extend to other network scenarios. The study leverages the Mininet emulator to model TSN networks, defining hosts, bridges, links, and traffic streams. It characterizes bridge latencies and jitter, solves the TSN scheduling problem based on measured parameters, and evaluates the correctness of a deployed schedule for a use case. Key contributions include a methodology for software-based timestamping, solutions for TSN emulation challenges in Linux and Mininet, and experimental insights for optimizing TSN emulation platforms on various system configurations, with and without Intel TCC, either on a high-end workstation or on an industrial PC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02133v1</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>\'Alex Gracia, Jos\'e Luis Briz, H\'ector Blanco-Alcaine, Juan Segarra, Alitzel G. Torres-Mac\'ias, Antonio Ram\'irez-Trevi\~no</dc:creator>
    </item>
    <item>
      <title>Analyzing Contact Patterns in Public Transportation Systems for Opportunistic Communication Services</title>
      <link>https://arxiv.org/abs/2506.02217</link>
      <description>arXiv:2506.02217v1 Announce Type: new 
Abstract: Vehicle mobility has a significant impact on wireless communication between vehicles (buses) in Public Transportation Systems (PTS). Nevertheless, the transportation literature does not provide satisfactory models for bus movements because they are influenced by a variety of factors (itineraries, timetables, etc.). Custom-made mobility models that take these issues into account require a great deal of effort and may render simulations unfeasible. This article considers a tool (EMMS) that automatically inserts PTS information into a mobility simulator in order to undertake a complete statistical analysis of vehicular density, trip duration, and vehicle-to-vehicle interaction. In light of opportunistic communication services, this analysis is of the utmost importance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02217v1</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Eduardo R. Manika, Emilio C. G. Wille, Joilson Alves Jr</dc:creator>
    </item>
    <item>
      <title>Experimental Covert Communication Using Software-Defined Radio</title>
      <link>https://arxiv.org/abs/2506.02297</link>
      <description>arXiv:2506.02297v1 Announce Type: new 
Abstract: The fundamental information-theoretic limits of covert, or low probability of detection (LPD), communication have been extensively studied for over a decade, resulting in the square root law (SRL): only $L\sqrt{n}$ covert bits can be reliably transmitted over time-bandwidth product $n$, for constant $L&gt;0$. Transmitting more either results in detection or decoding errors. The SRL imposes significant constraints on hardware realization of provably-secure covert communication. Thus, experimental validation of covert communication is underexplored: to date, only two experimental studies of SRL-based covert communication are available, both focusing on optical channels. Here, we report our initial results demonstrating the provably-secure covert radio-frequency (RF) communication using software-defined radios (SDRs). These validate theoretical predictions, open practical avenues for implementing covert communication systems, as well as raise future research questions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02297v1</guid>
      <category>cs.NI</category>
      <category>cs.IT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rohan Bali, Trevor E. Bailey, Michael S. Bullock, Boulat A. Bash</dc:creator>
    </item>
    <item>
      <title>AI-Driven Vehicle Condition Monitoring with Cell-Aware Edge Service Migration</title>
      <link>https://arxiv.org/abs/2506.02785</link>
      <description>arXiv:2506.02785v1 Announce Type: new 
Abstract: Artificial intelligence (AI) has been increasingly applied to the condition monitoring of vehicular equipment, aiming to enhance maintenance strategies, reduce costs, and improve safety. Leveraging the edge computing paradigm, AI-based condition monitoring systems process vast streams of vehicular data to detect anomalies and optimize operational performance. In this work, we introduce a novel vehicle condition monitoring service that enables real-time diagnostics of a diverse set of anomalies while remaining practical for deployment in real-world edge environments. To address mobility challenges, we propose a closed-loop service orchestration framework where service migration across edge nodes is dynamically triggered by network-related metrics. Our approach has been implemented and tested in a real-world race circuit environment equipped with 5G network capabilities under diverse operational conditions. Experimental results demonstrate the effectiveness of our framework in ensuring low-latency AI inference and adaptive service placement, highlighting its potential for intelligent transportation and mobility applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02785v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Charalampos Kalalas, Pavol Mulinka, Guillermo Candela Belmonte, Miguel Fornell, Michail Dalgitsis, Francisco Paredes Vera, Javier Santaella S\'anchez, Carmen Vicente Villares, Roshan Sedar, Eftychia Datsika, Angelos Antonopoulos, Antonio Fern\'andez Ojea, Miquel Payaro</dc:creator>
    </item>
    <item>
      <title>AI-Augmented OTDR Fault Localization Framework for Resilient Rural Fiber Networks in the United States</title>
      <link>https://arxiv.org/abs/2506.03041</link>
      <description>arXiv:2506.03041v1 Announce Type: new 
Abstract: This research presents a novel framework that combines traditional Optical Time-Domain Reflectometer (OTDR) signal analysis with machine learning to localize and classify fiber optic faults in rural broadband infrastructures. The proposed system addresses a critical need in the expansion of middle-mile and last-mile networks, particularly in regions targeted by the U.S. Broadband Equity, Access, and Deployment (BEAD) Program. By enhancing fault diagnosis through a predictive, AI-based model, this work enables proactive network maintenance in low-resource environments. Experimental evaluations using a controlled fiber testbed and synthetic datasets simulating rural network conditions demonstrate that the proposed method significantly improves detection accuracy and reduces false positives compared to conventional thresholding techniques. The solution offers a scalable, field-deployable tool for technicians and ISPs engaged in rural broadband deployment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03041v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sabab Al Farabi (Department of Industrial Engineering, Lamar University, Beaumont, Texas, USA)</dc:creator>
    </item>
    <item>
      <title>Navigating the Edge-Cloud Continuum: A State-of-Practice Survey</title>
      <link>https://arxiv.org/abs/2506.02003</link>
      <description>arXiv:2506.02003v1 Announce Type: cross 
Abstract: The edge-cloud continuum has emerged as a transformative paradigm that meets the growing demand for low-latency, scalable, end-to-end service delivery by integrating decentralized edge resources with centralized cloud infrastructures. Driven by the exponential growth of IoT-generated data and the need for real-time responsiveness, this continuum features multi-layered architectures. However, its adoption is hindered by infrastructural challenges, fragmented standards, and limited guidance for developers and researchers. Existing surveys rarely tackle practical implementation or recent industrial advances. This survey closes those gaps from a developer-oriented perspective, introducing a conceptual framework for navigating the edge-cloud continuum. We systematically examine architectural models, performance metrics, and paradigms for computation, communication, and deployment, together with enabling technologies and widely used edge-to-cloud platforms. We also discuss real-world applications in smart cities, healthcare, and Industry 4.0, as well as tools for testing and experimentation. Drawing on academic research and practices of leading cloud providers, this survey serves as a practical guide for developers and a structured reference for researchers, while identifying open challenges and emerging trends that will shape the future of the continuum.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02003v1</guid>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <category>cs.NI</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Loris Belcastro, Fabrizio Marozzo, Alessio Orsino, Domenico Talia, Paolo Trunfio</dc:creator>
    </item>
    <item>
      <title>eACGM: Non-instrumented Performance Tracing and Anomaly Detection towards Machine Learning Systems</title>
      <link>https://arxiv.org/abs/2506.02007</link>
      <description>arXiv:2506.02007v1 Announce Type: cross 
Abstract: We present eACGM, a full-stack AI/ML system monitoring framework based on eBPF. eACGM collects real-time performance data from key hardware components, including the GPU and network communication layer, as well as from key software stacks such as CUDA, Python, and PyTorch, all without requiring any code instrumentation or modifications. Additionally, it leverages libnvml to gather process-level GPU resource usage information. By applying a Gaussian Mixture Model (GMM) to the collected multidimensional performance metrics for statistical modeling and clustering analysis, eACGM effectively identifies complex failure modes, such as latency anomalies, hardware failures, and communication inefficiencies, enabling rapid diagnosis of system bottlenecks and abnormal behaviors.
  To evaluate eACGM's effectiveness and practicality, we conducted extensive empirical studies and case analyses in multi-node distributed training scenarios. The results demonstrate that eACGM, while maintaining a non-intrusive and low-overhead profile, successfully captures critical performance anomalies during model training and inference. Its stable anomaly detection performance and comprehensive monitoring capabilities validate its applicability and scalability in real-world production environments, providing strong support for performance optimization and fault diagnosis in large-scale AI/ML systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02007v1</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruilin Xu, Zongxuan Xie, Pengfei Chen</dc:creator>
    </item>
    <item>
      <title>A tertiary review on quantum cryptography</title>
      <link>https://arxiv.org/abs/2506.02028</link>
      <description>arXiv:2506.02028v1 Announce Type: cross 
Abstract: Quantum computers impose an immense threat to system security. As a countermeasure, new cryptographic classes have been created to prevent these attacks. Technologies such as post-quantum cryptography and quantum cryptography. Quantum cryptography uses the principle of quantum physics to produce theoretically unbreakable security. This tertiary review selected 51 secondary studies from the Scopus database and presented bibliometric analysis, a list of the main techniques used in the field, and existing open challenges and future directions in quantum cryptography research. The results showed a prevalence of QKD over other techniques among the selected papers and stated that the field still faces many problems related to implementation cost, error correction, decoherence, key rates, communication distance, and quantum hacking.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02028v1</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <category>physics.optics</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Luiz Filipi Anderson de Sousa Moura, Carlos Becker Westphall</dc:creator>
    </item>
    <item>
      <title>Zero-Energy RIS-Assisted Communications With Noise Modulation and Interference-Based Energy Harvesting</title>
      <link>https://arxiv.org/abs/2506.02625</link>
      <description>arXiv:2506.02625v1 Announce Type: cross 
Abstract: To advance towards carbon-neutrality and improve the limited {performance} of conventional passive wireless communications, in this paper, we investigate the integration of noise modulation with zero-energy reconfigurable intelligent surfaces (RISs). In particular, the RIS reconfigurable elements (REs) are divided into two groups: one for beamforming the desired signals in reflection mode and another for harvesting energy from interference signals in an absorption mode, providing the power required for RIS operation. Since the harvested energy is a random variable, a random number of REs can beamform the signals, while the remainder blindly reflects them. We present a closed-form solution and a search algorithm for REs allocation, jointly optimizing both the energy harvesting (EH) and communication performance. Considering the repetition coding technique and discrete phase shifts, we derive analytical expressions for the energy constrained success rate, bit error rate, optimal threshold, mutual information, {and energy efficiency}. Numerical and simulation results confirm the effectiveness of the algorithm and expressions, demonstrating the superiority of the proposed integration over conventional noise-modulation systems. It is shown that by properly allocating the REs, both the EH and communication performance can be improved in low to moderate interference scenarios, while the latter is restricted in the high-interference regime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02625v1</guid>
      <category>cs.IT</category>
      <category>cs.ET</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ahmad Massud Tota Khel, Aissa Ikhlef, Zhiguo Ding, Hongjian Sun</dc:creator>
    </item>
    <item>
      <title>Quantum Data Centers: Why Entanglement Changes Everything</title>
      <link>https://arxiv.org/abs/2506.02920</link>
      <description>arXiv:2506.02920v1 Announce Type: cross 
Abstract: The Quantum Internet is key for distributed quantum computing, by interconnecting multiple quantum processors into a virtual quantum computation system. This allows to scale the number of qubits, by overcoming the inherent limitations of noisy-intermediate-scale quantum (NISQ) devices. Thus, the Quantum Internet is the foundation for large-scale, fault-tolerant quantum computation. Among the distributed architectures, Quantum Data Centers emerge as the most viable in the medium-term, since they integrate multiple quantum processors within a localized network infrastructure, by allowing modular design of quantum networking. We analyze the physical and topological constraints of Quantum Data Centers, by emphasizing the role of entanglement orchestrators in dynamically reconfiguring network topologies through local operations. We examine the major hardware challenge of quantum transduction, essential for interfacing heterogeneous quantum systems. Furthermore, we explore how interconnecting multiple Quantum Data Centers could enable large-scale quantum networks. We discuss the topological constraints of such a scaling and identify open challenges, including entanglement routing and synchronization. The carried analysis positions Quantum Data Centers as both a practical implementation platform and strategic framework for the future Quantum Internet.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02920v1</guid>
      <category>quant-ph</category>
      <category>cs.NI</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Angela Sara Cacciapuoti, Claudio Pellitteri, Jessica Illiano, Laura d'Avossa, Francesco Mazza, Siyi Chen, Marcello Caleffi</dc:creator>
    </item>
    <item>
      <title>Computation- and Communication-Efficient Online FL for Resource-Constrained Aerial Vehicles</title>
      <link>https://arxiv.org/abs/2506.02972</link>
      <description>arXiv:2506.02972v1 Announce Type: cross 
Abstract: Privacy-preserving distributed machine learning (ML) and aerial connected vehicle (ACV)-assisted edge computing have drawn significant attention lately. Since the onboard sensors of ACVs can capture new data as they move along their trajectories, the continual arrival of such 'newly' sensed data leads to online learning and demands carefully crafting the trajectories. Besides, as typical ACVs are inherently resource-constrained, computation- and communication-efficient ML solutions are needed. Therefore, we propose a computation- and communication-efficient online aerial federated learning (2CEOAFL) algorithm to take the benefits of continual sensed data and limited onboard resources of the ACVs. In particular, considering independently owned ACVs act as selfish data collectors, we first model their trajectories according to their respective time-varying data distributions. We then propose a 2CEOAFL algorithm that allows the flying ACVs to (a) prune the received dense ML model to make it shallow, (b) train the pruned model, and (c) probabilistically quantize and offload their trained accumulated gradients to the central server (CS). Our extensive simulation results show that the proposed 2CEOAFL algorithm delivers comparable performances to its non-pruned and nonquantized, hence, computation- and communication-inefficient counterparts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02972v1</guid>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Md-Ferdous Pervej, Richeng Jin, Md Moin Uddin Chowdhury, Simran Singh, \.Ismail G\"uven\c{c}, Huaiyu Dai</dc:creator>
    </item>
    <item>
      <title>Online Learning for Function Placement in Serverless Computing</title>
      <link>https://arxiv.org/abs/2410.13696</link>
      <description>arXiv:2410.13696v2 Announce Type: replace-cross 
Abstract: We study the placement of virtual functions aimed at minimizing the cost. We propose a novel algorithm, using ideas based on multi-armed bandits. We prove that these algorithms learn the optimal placement policy rapidly, and their regret grows at a rate at most $O( N M \sqrt{T\ln T} )$ while respecting the feasibility constraints with high probability, where $T$ is total time slots, $M$ is the number of classes of function and $N$ is the number of computation nodes. We show through numerical experiments that the proposed algorithm both has good practical performance and modest computational complexity. We propose an acceleration technique that allows the algorithm to achieve good performance also in large networks where computational power is limited. Our experiments are fully reproducible, and the code is publicly available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13696v2</guid>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wei Huang, Richard Combes, Andrea Araldo, Hind Castel-Taleb, Badii Jouaber</dc:creator>
    </item>
    <item>
      <title>Combining Threat Intelligence with IoT Scanning to Predict Cyber Attack</title>
      <link>https://arxiv.org/abs/2411.17931</link>
      <description>arXiv:2411.17931v4 Announce Type: replace-cross 
Abstract: While the Web has become a global platform for communication, malicious actors, including hackers and hacktivist groups, often disseminate ideological content and coordinate activities through the "Dark Web", an obscure counterpart of the conventional web. Presently, challenges such as information overload and the fragmented nature of cyber threat data impede comprehensive profiling of these actors, thereby limiting the efficacy of predictive analyses of their online activities. Concurrently, the proliferation of internet-connected devices has surpassed the global human population, with this disparity projected to widen as the Internet of Things (IoT) expands. Technical communities are actively advancing IoT-related research to address its growing societal integration. This paper proposes a novel predictive threat intelligence framework designed to systematically collect, analyze, and visualize Dark Web data to identify malicious websites and correlate this information with potential IoT vulnerabilities. The methodology integrates automated data harvesting, analytical techniques, and visual mapping tools, while also examining vulnerabilities in IoT devices to assess exploitability. By bridging gaps in cybersecurity research, this study aims to enhance predictive threat modeling and inform policy development, thereby contributing to intelligence research initiatives focused on mitigating cyber risks in an increasingly interconnected digital ecosystem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.17931v4</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.NI</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jubin Abhishek Soni, Amit Anand, Rajesh Kumar Pandey, Aniket Abhishek Soni</dc:creator>
    </item>
    <item>
      <title>Learning Cache Coherence Traffic for NoC Routing Design</title>
      <link>https://arxiv.org/abs/2504.04005</link>
      <description>arXiv:2504.04005v2 Announce Type: replace-cross 
Abstract: The rapid growth of multi-core systems highlights the need for efficient Network-on-Chip (NoC) design to ensure seamless communication. Cache coherence, essential for data consistency, substantially reduces task computation time by enabling data sharing among caches. As a result, routing serves two roles: facilitating data sharing (influenced by topology) and managing NoC-level communication. However, cache coherence is often overlooked in routing, causing mismatches between design expectations and evaluation outcomes. Two main challenges are the lack of specialized tools to assess cache coherence's impact and the neglect of topology selection in routing. In this work, we propose a cache coherence-aware routing approach with integrated topology selection, guided by our Cache Coherence Traffic Analyzer (CCTA). Our method achieves up to 10.52% lower packet latency, 55.51% faster execution time, and 49.02% total energy savings, underscoring the critical role of cache coherence in NoC design and enabling effective co-design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04005v2</guid>
      <category>cs.AR</category>
      <category>cs.NI</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3716368.3735166</arxiv:DOI>
      <arxiv:journal_reference>Great Lakes Symposium on VLSI 2025 (GLSVLSI '25)</arxiv:journal_reference>
      <dc:creator>Guochu Xiong, Xiangzhong Luo, Weichen Liu</dc:creator>
    </item>
  </channel>
</rss>
