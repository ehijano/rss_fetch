<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 24 May 2024 04:00:41 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 24 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Trading Volume Maximization with Online Learning</title>
      <link>https://arxiv.org/abs/2405.13102</link>
      <description>arXiv:2405.13102v1 Announce Type: new 
Abstract: We explore brokerage between traders in an online learning framework. At any round $t$, two traders meet to exchange an asset, provided the exchange is mutually beneficial. The broker proposes a trading price, and each trader tries to sell their asset or buy the asset from the other party, depending on whether the price is higher or lower than their private valuations. A trade happens if one trader is willing to sell and the other is willing to buy at the proposed price. Previous work provided guidance to a broker aiming at enhancing traders' total earnings by maximizing the gain from trade, defined as the sum of the traders' net utilities after each interaction. In contrast, we investigate how the broker should behave to maximize the trading volume, i.e., the total number of trades. We model the traders' valuations as an i.i.d. process with an unknown distribution. If the traders' valuations are revealed after each interaction (full-feedback), and the traders' valuations cumulative distribution function (cdf) is continuous, we provide an algorithm achieving logarithmic regret and show its optimality up to constant factors. If only their willingness to sell or buy at the proposed price is revealed after each interaction ($2$-bit feedback), we provide an algorithm achieving poly-logarithmic regret when the traders' valuations cdf is Lipschitz and show that this rate is near-optimal. We complement our results by analyzing the implications of dropping the regularity assumptions on the unknown traders' valuations cdf. If we drop the continuous cdf assumption, the regret rate degrades to $\Theta(\sqrt{T})$ in the full-feedback case, where $T$ is the time horizon. If we drop the Lipschitz cdf assumption, learning becomes impossible in the $2$-bit feedback case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13102v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>q-fin.CP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tommaso Cesari, Roberto Colomboni</dc:creator>
    </item>
    <item>
      <title>FACT or Fiction: Can Truthful Mechanisms Eliminate Federated Free Riding?</title>
      <link>https://arxiv.org/abs/2405.13879</link>
      <description>arXiv:2405.13879v1 Announce Type: new 
Abstract: Standard federated learning (FL) approaches are vulnerable to the free-rider dilemma: participating agents can contribute little to nothing yet receive a well-trained aggregated model. While prior mechanisms attempt to solve the free-rider dilemma, none have addressed the issue of truthfulness. In practice, adversarial agents can provide false information to the server in order to cheat its way out of contributing to federated training. In an effort to make free-riding-averse federated mechanisms truthful, and consequently less prone to breaking down in practice, we propose FACT. FACT is the first federated mechanism that: (1) eliminates federated free riding by using a penalty system, (2) ensures agents provide truthful information by creating a competitive environment, and (3) encourages agent participation by offering better performance than training alone. Empirically, FACT avoids free-riding when agents are untruthful, and reduces agent loss by over 4x.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13879v1</guid>
      <category>cs.GT</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>econ.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marco Bornstein, Amrit Singh Bedi, Abdirisak Mohamed, Furong Huang</dc:creator>
    </item>
    <item>
      <title>Fair Online Bilateral Trade</title>
      <link>https://arxiv.org/abs/2405.13919</link>
      <description>arXiv:2405.13919v1 Announce Type: new 
Abstract: In online bilateral trade, a platform posts prices to incoming pairs of buyers and sellers that have private valuations for a certain good. If the price is lower than the buyers' valuation and higher than the sellers' valuation, then a trade takes place. Previous work focused on the platform perspective, with the goal of setting prices maximizing the gain from trade (the sum of sellers' and buyers' utilities). Gain from trade is, however, potentially unfair to traders, as they may receive highly uneven shares of the total utility. In this work we enforce fairness by rewarding the platform with the fair gain from trade, defined as the minimum between sellers' and buyers' utilities. After showing that any no-regret learning algorithm designed to maximize the sum of the utilities may fail badly with fair gain from trade, we present our main contribution: a complete characterization of the regret regimes for fair gain from trade when, after each interaction, the platform only learns whether each trader accepted the current price. Specifically, we prove the following regret bounds: $\Theta(\ln T)$ in the deterministic setting, $\Omega(T)$ in the stochastic setting, and $\tilde{\Theta}(T^{2/3})$ in the stochastic setting when sellers' and buyers' valuations are independent of each other. We conclude by providing tight regret bounds when, after each interaction, the platform is allowed to observe the true traders' valuations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13919v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fran\c{c}ois Bachoc, Nicol\`o Cesa-Bianchi, Tommaso Cesari, Roberto Colomboni</dc:creator>
    </item>
    <item>
      <title>Verifying Cake-Cutting, Faster</title>
      <link>https://arxiv.org/abs/2405.14068</link>
      <description>arXiv:2405.14068v1 Announce Type: new 
Abstract: Envy-free cake-cutting protocols procedurally divide an infinitely divisible good among a set of agents so that no agent prefers another's allocation to their own. These protocols are highly complex and difficult to prove correct. Recently, Bertram, Levinson, and Hsu introduced a language called Slice for describing and verifying cake-cutting protocols. Slice programs can be translated to formulas encoding envy-freeness, which are solved by SMT. While Slice works well on smaller protocols, it has difficulty scaling to more complex cake-cutting protocols.
  We improve Slice in two ways. First, we show any protocol execution in Slice can be replicated using piecewise uniform valuations. We then reduce Slice's constraint formulas to formulas within the theory of linear real arithmetic, showing that verifying envy-freeness is efficiently decidable. Second, we design and implement a linear type system which enforces that no two agents receive the same part of the good. We implement our methods and verify a range of challenging examples, including the first nontrivial four-agent protocol.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14068v1</guid>
      <category>cs.GT</category>
      <category>cs.PL</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Noah Bertram, Tean Lai, Justin Hsu</dc:creator>
    </item>
    <item>
      <title>Modeling Other Players with Bayesian Beliefs for Games with Incomplete Information</title>
      <link>https://arxiv.org/abs/2405.14122</link>
      <description>arXiv:2405.14122v1 Announce Type: new 
Abstract: Bayesian games model interactive decision-making where players have incomplete information -- e.g., regarding payoffs and private data on players' strategies and preferences -- and must actively reason and update their belief models (with regard to such information) using observation and interaction history. Existing work on counterfactual regret minimization have shown great success for games with complete or imperfect information, but not for Bayesian games. To this end, we introduced a new CFR algorithm: Bayesian-CFR and analyze its regret bound with respect to Bayesian Nash Equilibria in Bayesian games. First, we present a method for updating the posterior distribution of beliefs about the game and other players' types. The method uses a kernel-density estimate and is shown to converge to the true distribution. Second, we define Bayesian regret and present a Bayesian-CFR minimization algorithm for computing the Bayesian Nash equilibrium. Finally, we extend this new approach to other existing algorithms, such as Bayesian-CFR+ and Deep Bayesian CFR. Experimental results show that our proposed solutions significantly outperform existing methods in classical Texas Hold'em games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14122v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zuyuan Zhang, Mahdi Imani, Tian Lan</dc:creator>
    </item>
    <item>
      <title>Metric distortion Under Probabilistic Voting</title>
      <link>https://arxiv.org/abs/2405.14223</link>
      <description>arXiv:2405.14223v1 Announce Type: new 
Abstract: Metric distortion in social choice provides a framework for assessing how well voting rules minimize social cost in scenarios where voters and candidates exist in a shared metric space, with voters submitting rankings and the rule outputting a single winner. We expand this framework to include probabilistic voting. Our extension encompasses a broad range of probability functions, including widely studied models like Plackett-Luce (PL) and Bradley-Terry, and a novel "pairwise quantal voting" model inspired by quantal response theory.
  We demonstrate that distortion results under probabilistic voting better correspond with conventional intuitions regarding popular voting rules such as Plurality, Copeland, and Random Dictator (RD) than those under deterministic voting. For example, in the PL model with candidate strength inversely proportional to the square of their metric distance, we show that Copeland's distortion is at most 2, whereas that of RD is $\Omega(\sqrt{m})$ in large elections, where $m$ is the number of candidates. This contrasts sharply with the classical model, where RD beats Copeland with a distortion of 3 versus 5 [1].</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14223v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sahasrajit Sarmasarkar, Mohak Goyal</dc:creator>
    </item>
    <item>
      <title>Optimized Cost Per Click in Online Advertising: A Theoretical Analysis</title>
      <link>https://arxiv.org/abs/2405.14279</link>
      <description>arXiv:2405.14279v1 Announce Type: new 
Abstract: In recent years, Optimized Cost Per Click (OCPC) and Optimized Cost Per Mille (OCPM) have emerged as the most widely adopted pricing models in the online advertising industry. However, the existing literature has yet to identify the specific conditions under which these models outperform traditional pricing models like Cost Per Click (CPC) and Cost Per Action (CPA). To fill the gap, this paper builds an economic model that compares OCPC with CPC and CPA theoretically, which incorporates out-site scenarios and outside options as two key factors. Our analysis reveals that OCPC can effectively replace CPA by tackling the problem of advertisers strategically manipulating conversion reporting in out-site scenarios where conversions occur outside the advertising platform. Furthermore, OCPC exhibits the potential to surpass CPC in platform payoffs by providing higher advertiser payoffs and consequently attracting more advertisers. However, if advertisers have less competitive outside options and consistently stay in the focal platform, the platform may achieve higher payoffs using CPC. Our findings deliver valuable insights for online advertising platforms in selecting optimal pricing models, and provide recommendations for further enhancing their payoffs. To the best of our knowledge, this is the first study to analyze OCPC from an economic perspective. Moreover, our analysis can be applied to the OCPM model as well.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14279v1</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kaichen Zhang, Zixuan Yuan, Hui Xiong</dc:creator>
    </item>
    <item>
      <title>Sybil-Proof Mechanism for Information Propagation with Budgets</title>
      <link>https://arxiv.org/abs/2405.14293</link>
      <description>arXiv:2405.14293v1 Announce Type: new 
Abstract: This paper examines the problem of distributing rewards on social networks to improve the efficiency of crowdsourcing tasks for sponsors. To complete the tasks efficiently, we aim to design reward mechanisms that incentivize early-joining agents to invite more participants to the tasks. Nonetheless, participants could potentially engage in strategic behaviors, e.g., not inviting others to the tasks, misreporting their capacity for the tasks, or creaking fake identities (aka Sybil attacks), to maximize their own rewards. The focus of this study is to address the challenge outlined above by designing effective reward mechanisms. To this end, we propose a novel reward mechanism, called Propagation Reward Distribution Mechanism (PRDM), for the general information propagation model with limited budgets. It is proved that the PRDM can not only incentivize all agents to contribute their full efforts to the tasks and share the task information to all their neighbors in the social networks, but can also prevent them from Sybil attacks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14293v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junjie Zheng, Xu Ge, Bin Li, Dengji Zhao</dc:creator>
    </item>
    <item>
      <title>Estimating the Expected Social Welfare and Cost of Random Serial Dictatorship</title>
      <link>https://arxiv.org/abs/2405.14316</link>
      <description>arXiv:2405.14316v1 Announce Type: new 
Abstract: We consider the assignment problem, where $n$ agents have to be matched to $n$ items. Each agent has a preference order over the items. In the serial dictatorship (SD) mechanism the agents act in a particular order and pick their most preferred available item when it is their turn to act. Applying SD using a uniformly random permutation as agent ordering results in the well-known random serial dictatorship (RSD) mechanism. Accurate estimates of the (expected) efficiency of its outcome can be used to assess whether RSD is attractive compared to other mechanisms. In this paper, we explore whether such estimates are possible by sampling a (hopefully) small number of agent orderings and applying SD using them. We consider a value setting in which agents have values for the items as well as a metric cost setting where agents and items are assumed to be points in a metric space, and the cost of an agent for an item is equal to the distance of the corresponding points. We show that a (relatively) small number of samples is enough to approximate the expected social welfare of RSD in the value setting and its expected social cost in the metric cost setting despite the #P-hardness of the corresponding exact computation problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14316v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ioannis Caragiannis, Sebastian Homrighausen</dc:creator>
    </item>
    <item>
      <title>Epistemic EFX Allocations Exist for Monotone Valuations</title>
      <link>https://arxiv.org/abs/2405.14463</link>
      <description>arXiv:2405.14463v1 Announce Type: new 
Abstract: We study the fundamental problem of fairly dividing a set of indivisible items among agents with (general) monotone valuations. The notion of envy-freeness up to any item (EFX) is considered to be one of the most fascinating fairness concepts in this line of work. Unfortunately, despite significant efforts, existence of EFX allocations is a major open problem in fair division, thereby making the study of approximations and relaxations of EFX a natural line of research. Recently, Caragiannis et al. introduced a promising relaxation of EFX, called epistemic EFX (EEFX). We say an allocation to be EEFX if, for every agent, it is possible to shuffle the items in the remaining bundles so that she becomes "EFX-satisfied". Caragiannis et al. prove existence and polynomial-time computability of EEFX allocations for additive valuations. A natural question asks what happens when we consider valuations more general than additive?
  We address this important open question and answer it affirmatively by establishing the existence of EEFX allocations for an arbitrary number of agents with general monotone valuations. To the best of our knowledge, EEFX is the only known relaxation of EFX to have such strong existential guarantees. Furthermore, we complement our existential result by proving computational and information-theoretic lower bounds. We prove that even for an arbitrary number of (more than one) agents with identical submodular valuations, it is PLS-hard to compute EEFX allocations and it requires exponentially-many value queries to do so.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14463v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hannaneh Akrami, Nidhi Rathi</dc:creator>
    </item>
    <item>
      <title>Global Behavior of Learning Dynamics in Zero-Sum Games with Memory Asymmetry</title>
      <link>https://arxiv.org/abs/2405.14546</link>
      <description>arXiv:2405.14546v1 Announce Type: new 
Abstract: This study examines the global behavior of dynamics in learning in games between two players, X and Y. We consider the simplest situation for memory asymmetry between two players: X memorizes the other Y's previous action and uses reactive strategies, while Y has no memory. Although this memory complicates the learning dynamics, we discover two novel quantities that characterize the global behavior of such complex dynamics. One is an extended Kullback-Leibler divergence from the Nash equilibrium, a well-known conserved quantity from previous studies. The other is a family of Lyapunov functions of X's reactive strategy. These two quantities capture the global behavior in which X's strategy becomes more exploitative, and the exploited Y's strategy converges to the Nash equilibrium. Indeed, we theoretically prove that Y's strategy globally converges to the Nash equilibrium in the simplest game equipped with an equilibrium in the interior of strategy spaces. Furthermore, our experiments also suggest that this global convergence is universal for more advanced zero-sum games than the simplest game. This study provides a novel characterization of the global behavior of learning in games through a couple of indicators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14546v1</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>math.OC</category>
      <category>nlin.CD</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuma Fujimoto, Kaito Ariu, Kenshi Abe</dc:creator>
    </item>
    <item>
      <title>Share-Based Fairness for Arbitrary Entitlements</title>
      <link>https://arxiv.org/abs/2405.14575</link>
      <description>arXiv:2405.14575v1 Announce Type: new 
Abstract: We consider the problem of fair allocation of indivisible items to agents that have arbitrary entitlements to the items. Every agent $i$ has a valuation function $v_i$ and an entitlement $b_i$, where entitlements sum up to~1. Which allocation should one choose in situations in which agents fail to agree on one acceptable fairness notion? We study this problem in the case in which each agent focuses on the value she gets, and fairness notions are restricted to be {\em share based}. A {\em share} $s$ is an function that maps every $(v_i,b_i)$ to a value $s(v_i,b_i)$, representing the minimal value $i$ should get, and $s$ is {\em feasible} if it is always possible to give every agent $i$ value of at least $s(v_i,b_i)$.
  Our main result is that for additive valuations over goods there is an allocation that gives every agent at least half her share value, regardless of which feasible share-based fairness notion the agent wishes to use. Moreover, the ratio of half is best possible. More generally, we provide tight characterizations of what can be achieved, both ex-post (as single allocations) and ex-ante (as expected values of distributions of allocations), both for goods and for chores. We also show that for chores one can achieve the ex-ante and ex-post guarantees simultaneously (a ``best of both world" result), whereas for goods one cannot.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14575v1</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Moshe Babaioff, Uriel Feige</dc:creator>
    </item>
    <item>
      <title>Axioms for AI Alignment from Human Feedback</title>
      <link>https://arxiv.org/abs/2405.14758</link>
      <description>arXiv:2405.14758v1 Announce Type: new 
Abstract: In the context of reinforcement learning from human feedback (RLHF), the reward function is generally derived from maximum likelihood estimation of a random utility model based on pairwise comparisons made by humans. The problem of learning a reward function is one of preference aggregation that, we argue, largely falls within the scope of social choice theory. From this perspective, we can evaluate different aggregation methods via established axioms, examining whether these methods meet or fail well-known standards. We demonstrate that both the Bradley-Terry-Luce Model and its broad generalizations fail to meet basic axioms. In response, we develop novel rules for learning reward functions with strong axiomatic guarantees. A key innovation from the standpoint of social choice is that our problem has a linear structure, which greatly restricts the space of feasible rules and leads to a new paradigm that we call linear social choice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14758v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luise Ge, Daniel Halpern, Evi Micha, Ariel D. Procaccia, Itai Shapira, Yevgeniy Vorobeychik, Junlin Wu</dc:creator>
    </item>
    <item>
      <title>Quantum algorithm for large-scale market equilibrium computation</title>
      <link>https://arxiv.org/abs/2405.13788</link>
      <description>arXiv:2405.13788v1 Announce Type: cross 
Abstract: Classical algorithms for market equilibrium computation such as proportional response dynamics face scalability issues with Internet-based applications such as auctions, recommender systems, and fair division, despite having an almost linear runtime in terms of the product of buyers and goods. In this work, we provide the first quantum algorithm for market equilibrium computation with sub-linear performance. Our algorithm provides a polynomial runtime speedup in terms of the product of the number of buyers and goods while reaching the same optimization objective value as the classical algorithm. Numerical simulations of a system with 16384 buyers and goods support our theoretical results that our quantum algorithm provides a significant speedup.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13788v1</guid>
      <category>quant-ph</category>
      <category>cs.GT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Po-Wei Huang, Patrick Rebentrost</dc:creator>
    </item>
    <item>
      <title>Mixture of Public and Private Distributions in Imperfect Information Games</title>
      <link>https://arxiv.org/abs/2405.14346</link>
      <description>arXiv:2405.14346v1 Announce Type: cross 
Abstract: In imperfect information games (e.g. Bridge, Skat, Poker), one of the fundamental considerations is to infer the missing information while at the same time avoiding the disclosure of private information. Disregarding the issue of protecting private information can lead to a highly exploitable performance. Yet, excessive attention to it leads to hesitations that are no longer consistent with our private information. In our work, we show that to improve performance, one must choose whether to use a player's private information. We extend our work by proposing a new belief distribution depending on the amount of private and public information desired. We empirically demonstrate an increase in performance and, with the aim of further improving performance, the new distribution should be used according to the position in the game. Our experiments have been done on multiple benchmarks and in multiple determinization-based algorithms (PIMC and IS-MCTS).</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14346v1</guid>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1109/CoG57401.2023.10333169</arxiv:DOI>
      <arxiv:journal_reference>2023 IEEE Conference on Games (CoG)</arxiv:journal_reference>
      <dc:creator>J\'er\^ome Arjonilla, Abdallah Saffidine, Tristan Cazenave</dc:creator>
    </item>
    <item>
      <title>Zero-Knowledge Games</title>
      <link>https://arxiv.org/abs/2009.13521</link>
      <description>arXiv:2009.13521v5 Announce Type: replace 
Abstract: In this paper we model a game such that all strategies are non-revealing, with imperfect recall and incomplete information. We also introduce a modified sliding-block code as a linear transformation which generates common knowledge of how informed a player is. Ultimately, we see that between two players in a zero-knowledge game where both players are informed, the utility of trust is established in the mixed strategy Nash equilibrium. A zero-knowledge game is one of trust and soundness, placing utility in being informed. For any player who may be uninformed, such players reveal they are uninformed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2009.13521v5</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ian Malloy</dc:creator>
    </item>
    <item>
      <title>Discrete &amp; Bayesian Transaction Fee Mechanisms</title>
      <link>https://arxiv.org/abs/2210.07793</link>
      <description>arXiv:2210.07793v5 Announce Type: replace 
Abstract: Cryptocurrencies employ auction-esque transaction fee mechanisms (TFMs) to allocate transactions to blocks, and to determine how much fees miners can collect from transactions. Several impossibility results show that TFMs that satisfy a standard set of "good" properties obtain low revenue, and in certain cases, no revenue at all. In this work, we circumvent previous impossibilities by showing that when desired TFM properties are reasonably relaxed, simple mechanisms can obtain strictly positive revenue. By discretizing fees, we design a TFM that satisfies the extended TFM desiderata: it is dominant strategy incentive-compatible (DSIC), myopic miner incentive-compatible (MMIC), side-contract-proof (SCP) and obtains asymptotically optimal revenue (i.e., linear in the number of allocated bids), and optimal revenue when considering separable TFMs. If instead of discretizing fees we relax the DSIC and SCP properties, we show that Bitcoin's TFM, after applying the revelation principle, is Bayesian incentive-compatible (BIC), MMIC, off-chain-agreement (OCA) proof, and approximately revenue-optimal. We reach our results by characterizing the class of multi-item OCA-proof mechanisms, which may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.07793v5</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yotam Gafni, Aviv Yaish</dc:creator>
    </item>
    <item>
      <title>Towards Realistic Mechanisms That Incentivize Federated Participation and Contribution</title>
      <link>https://arxiv.org/abs/2310.13681</link>
      <description>arXiv:2310.13681v3 Announce Type: replace 
Abstract: Edge device participation in federating learning (FL) is typically studied through the lens of device-server communication (e.g., device dropout) and assumes an undying desire from edge devices to participate in FL. As a result, current FL frameworks are flawed when implemented in realistic settings, with many encountering the free-rider dilemma. In a step to push FL towards realistic settings, we propose RealFM: the first federated mechanism that (1) realistically models device utility, (2) incentivizes data contribution and device participation, (3) provably removes the free-rider dilemma, and (4) relaxes assumptions on data homogeneity and data sharing. Compared to previous FL mechanisms, RealFM allows for a non-linear relationship between model accuracy and utility, which improves the utility gained by the server and participating devices. On real-world data, RealFM improves device and server utility, as well as data contribution, by over 3 and 4 magnitudes respectively compared to baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.13681v3</guid>
      <category>cs.GT</category>
      <category>cs.CY</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>econ.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marco Bornstein, Amrit Singh Bedi, Anit Kumar Sahu, Furqan Khan, Furong Huang</dc:creator>
    </item>
    <item>
      <title>Learning the Expected Core of Strictly Convex Stochastic Cooperative Games</title>
      <link>https://arxiv.org/abs/2402.07067</link>
      <description>arXiv:2402.07067v2 Announce Type: replace 
Abstract: Reward allocation, also known as the credit assignment problem, has been an important topic in economics, engineering, and machine learning. An important concept in reward allocation is the core, which is the set of stable allocations where no agent has the motivation to deviate from the grand coalition. In previous works, computing the core requires either knowledge of the reward function in deterministic games or the reward distribution in stochastic games. However, this is unrealistic, as the reward function or distribution is often only partially known and may be subject to uncertainty. In this paper, we consider the core learning problem in stochastic cooperative games, where the reward distribution is unknown. Our goal is to learn the expected core, that is, the set of allocations that are stable in expectation, given an oracle that returns a stochastic reward for an enquired coalition each round. Within the class of strictly convex games, we present an algorithm named \texttt{Common-Points-Picking} that returns a point in the expected core given a polynomial number of samples, with high probability. To analyse the algorithm, we develop a new extension of the separation hyperplane theorem for multiple convex sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.07067v2</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nam Phuong Tran, The Anh Ta, Shuqing Shi, Debmalya Mandal, Yali Du, Long Tran-Thanh</dc:creator>
    </item>
    <item>
      <title>Regret Minimization in Stackelberg Games with Side Information</title>
      <link>https://arxiv.org/abs/2402.08576</link>
      <description>arXiv:2402.08576v3 Announce Type: replace 
Abstract: Algorithms for playing in Stackelberg games have been deployed in real-world domains including airport security, anti-poaching efforts, and cyber-crime prevention. However, these algorithms often fail to take into consideration the additional information available to each player (e.g. traffic patterns, weather conditions, network congestion), a salient feature of reality which may significantly affect both players' optimal strategies. We formalize such settings as Stackelberg games with side information, in which both players observe an external context before playing. The leader commits to a (context-dependent) strategy, and the follower best-responds to both the leader's strategy and the context. We focus on the online setting in which a sequence of followers arrive over time, and the context may change from round-to-round. In sharp contrast to the non-contextual version, we show that it is impossible for the leader to achieve good performance (measured by regret) in the full adversarial setting. Motivated by our impossibility result, we show that no-regret learning is possible in two natural relaxations: the setting in which the sequence of followers is chosen stochastically and the sequence of contexts is adversarial, and the setting in which the sequence of contexts is stochastic and the sequence of followers is chosen by an adversary.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.08576v3</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Keegan Harris, Zhiwei Steven Wu, Maria-Florina Balcan</dc:creator>
    </item>
    <item>
      <title>New Perspectives in Online Contract Design</title>
      <link>https://arxiv.org/abs/2403.07143</link>
      <description>arXiv:2403.07143v2 Announce Type: replace 
Abstract: This work studies the repeated principal-agent problem from an online learning perspective. The principal's goal is to learn the optimal contract that maximizes her utility through repeated interactions, without prior knowledge of the agent's type (i.e., the agent's cost and production functions). This work contains three technical results. First, learning linear contracts with binary outcomes is equivalent to dynamic pricing with an unknown demand curve. Second, learning an approximately optimal contract with identical agents can be accomplished with a polynomial sample complexity scheme. Third, learning the optimal contract with heterogeneous agents can be reduced to Lipschitz bandits under mild regularity conditions. The technical results demonstrate that the one-dimensional effort model, the default model for principal-agent problems in economics which seems largely ignored in recent works from the computer science community, may possibly be the more suitable choice when studying contract design from a learning perspective.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07143v2</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shiliang Zuo</dc:creator>
    </item>
    <item>
      <title>The Hyperdrive Protocol: An Automated Market Maker for Fixed and Variable Rates</title>
      <link>https://arxiv.org/abs/2404.05036</link>
      <description>arXiv:2404.05036v2 Announce Type: replace 
Abstract: Hyperdrive is a protocol designed to facilitate the trading of fixed and variable rate assets. The protocol's unique pricing model consolidates liquidity into a single pool which addresses the challenges of fragmented liquidity across terms, eliminates the need for rollovers, and allows terms to be issued on demand. Its design meaningfully improves trading efficiency, liquidity provisioning, and user experience over existing fixed and variable rate protocol models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05036v2</guid>
      <category>cs.GT</category>
      <category>cs.CE</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Jonny Rhea, Alex Towle, Mihai Cosma</dc:creator>
    </item>
    <item>
      <title>Reputational Algorithm Aversion</title>
      <link>https://arxiv.org/abs/2402.15418</link>
      <description>arXiv:2402.15418v2 Announce Type: replace-cross 
Abstract: People are often reluctant to incorporate information produced by algorithms into their decisions, a phenomenon called ``algorithm aversion''. This paper shows how algorithm aversion arises when the choice to follow an algorithm conveys information about a human's ability. I develop a model in which workers make forecasts of an uncertain outcome based on their own private information and an algorithm's signal. Low-skill workers receive worse information than the algorithm and hence should always follow the algorithm's signal, while high-skill workers receive better information than the algorithm and should sometimes override it. However, due to reputational concerns, low-skill workers inefficiently override the algorithm to increase the likelihood they are perceived as high-skill. The model provides a fully rational microfoundation for algorithm aversion that aligns with the broad concern that AI systems will displace many types of workers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.15418v2</guid>
      <category>econ.TH</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.HC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gregory Weitzner</dc:creator>
    </item>
    <item>
      <title>am-AMM: An Auction-Managed Automated Market Maker</title>
      <link>https://arxiv.org/abs/2403.03367</link>
      <description>arXiv:2403.03367v3 Announce Type: replace-cross 
Abstract: Automated market makers (AMMs) have emerged as the dominant market mechanism for trading on decentralized exchanges implemented on blockchains. This paper presents a single mechanism that targets two important unsolved problems for AMMs: reducing losses to informed orderflow, and maximizing revenue from uninformed orderflow. The ``auction-managed AMM'' works by running a censorship-resistant onchain auction for the right to temporarily act as ``pool manager'' for a constant-product AMM. The pool manager sets the swap fee rate on the pool, and also receives the accrued fees from swaps. The pool manager can exclusively capture some arbitrage by trading against the pool in response to small price movements, and also can set swap fees incorporating price sensitivity of retail orderflow and adapting to changing market conditions, with the benefits from both ultimately accruing to liquidity providers. Liquidity providers can enter and exit the pool freely in response to changing rent, though they must pay a small fee on withdrawal. We prove that under certain assumptions, this AMM should have higher liquidity in equilibrium than any standard, fixed-fee AMM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.03367v3</guid>
      <category>q-fin.TR</category>
      <category>cs.GT</category>
      <category>math.OC</category>
      <category>q-fin.MF</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Austin Adams, Ciamac C. Moallemi, Sara Reynolds, Dan Robinson</dc:creator>
    </item>
    <item>
      <title>Pursuit Winning Strategies for Reach-Avoid Games with Polygonal Obstacles</title>
      <link>https://arxiv.org/abs/2403.06202</link>
      <description>arXiv:2403.06202v2 Announce Type: replace-cross 
Abstract: This paper studies a multiplayer reach-avoid differential game in the presence of general polygonal obstacles that block the players' motions. The pursuers cooperate to protect a convex region from the evaders who try to reach the region. We propose a multiplayer onsite and close-to-goal (MOCG) pursuit strategy that can tell and achieve an increasing lower bound on the number of guaranteed defeated evaders. This pursuit strategy fuses the subgame outcomes for multiple pursuers against one evader with hierarchical optimal task allocation in the receding-horizon manner. To determine the qualitative subgame outcomes that who is the game winner, we construct three pursuit winning regions and strategies under which the pursuers guarantee to win against the evader, regardless of the unknown evader strategy. First, we utilize the expanded Apollonius circles and propose the onsite pursuit winning that achieves the capture in finite time. Second, we introduce convex goal-covering polygons (GCPs) and propose the close-to-goal pursuit winning for the pursuers whose visibility region contains the whole protected region, and the goal-visible property will be preserved afterwards. Third, we employ Euclidean shortest paths (ESPs) and construct a pursuit winning region and strategy for the non-goal-visible pursuers, where the pursuers are firstly steered to positions with goal visibility along ESPs. In each horizon, the hierarchical optimal task allocation maximizes the number of defeated evaders and consists of four sequential matchings: capture, enhanced, non-dominated and closest matchings. Numerical examples are presented to illustrate the results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06202v2</guid>
      <category>eess.SY</category>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rui Yan, Shuai Mi, Xiaoming Duan, Jintao Chen, Xiangyang Ji</dc:creator>
    </item>
  </channel>
</rss>
