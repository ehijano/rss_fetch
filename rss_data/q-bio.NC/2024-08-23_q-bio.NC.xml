<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 23 Aug 2024 04:00:18 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 23 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Prosody of speech production in latent post-stroke aphasia</title>
      <link>https://arxiv.org/abs/2408.11882</link>
      <description>arXiv:2408.11882v1 Announce Type: new 
Abstract: This study explores prosodic production in latent aphasia, a mild form of aphasia associated with left-hemisphere brain damage (e.g. stroke). Unlike prior research on moderate to severe aphasia, we investigated latent aphasia, which can seem to have very similar speech production with neurotypical speech. We analysed the f0, intensity and duration of utterance-initial and utterance-final words of ten speakers with latent aphasia and ten matching controls. Regression models were fitted to improve our understanding of this understudied type of very mild aphasia. The results highlighted varying degrees of differences in all three prosodic measures between groups. We also investigated the diagnostic classification of latent aphasia versus neurotypical control using random forest, aiming to build a fast and reliable tool to assist with the identification of latent aphasia. The random forest analysis also reinforced the significance of prosodic features in distinguishing latent aphasia.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.11882v1</guid>
      <category>q-bio.NC</category>
      <category>cs.SD</category>
      <category>eess.AS</category>
      <category>q-bio.QM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Cong Zhang, Tong Li, Gayle DeDe, Christos Salis</dc:creator>
    </item>
    <item>
      <title>ST-USleepNet: A Spatial-Temporal Coupling Prominence Network for Multi-Channel Sleep Staging</title>
      <link>https://arxiv.org/abs/2408.11884</link>
      <description>arXiv:2408.11884v1 Announce Type: new 
Abstract: Sleep staging is critical for assessing sleep quality and diagnosing disorders. Recent advancements in artificial intelligence have driven the development of automated sleep staging models, which still face two significant challenges. 1) Simultaneously extracting prominent temporal and spatial sleep features from multi-channel raw signals, including characteristic sleep waveforms and salient spatial brain networks. 2) Capturing the spatial-temporal coupling patterns essential for accurate sleep staging. To address these challenges, we propose a novel framework named ST-USleepNet, comprising a spatial-temporal graph construction module (ST) and a U-shaped sleep network (USleepNet). The ST module converts raw signals into a spatial-temporal graph to model spatial-temporal couplings. The USleepNet utilizes a U-shaped structure originally designed for image segmentation. Similar to how image segmentation isolates significant targets, when applied to both raw sleep signals and ST module-generated graph data, USleepNet segments these inputs to extract prominent temporal and spatial sleep features simultaneously. Testing on three datasets demonstrates that ST-USleepNet outperforms existing baselines, and model visualizations confirm its efficacy in extracting prominent sleep features and temporal-spatial coupling patterns across various sleep stages. The code is available at: https://github.com/Majy-Yuji/ST-USleepNet.git.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.11884v1</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jingying Ma, Qika Lin, Ziyu Jia, Mengling Feng</dc:creator>
    </item>
    <item>
      <title>Topological Representational Similarity Analysis in Brains and Beyond</title>
      <link>https://arxiv.org/abs/2408.11948</link>
      <description>arXiv:2408.11948v1 Announce Type: new 
Abstract: Understanding how the brain represents and processes information is crucial for advancing neuroscience and artificial intelligence. Representational similarity analysis (RSA) has been instrumental in characterizing neural representations, but traditional RSA relies solely on geometric properties, overlooking crucial topological information. This thesis introduces Topological RSA (tRSA), a novel framework combining geometric and topological properties of neural representations.
  tRSA applies nonlinear monotonic transforms to representational dissimilarities, emphasizing local topology while retaining intermediate-scale geometry. The resulting geo-topological matrices enable model comparisons robust to noise and individual idiosyncrasies. This thesis introduces several key methodological advances: (1) Topological RSA (tRSA) for identifying computational signatures and testing topological hypotheses; (2) Adaptive Geo-Topological Dependence Measure (AGTDM) for detecting complex multivariate relationships; (3) Procrustes-aligned Multidimensional Scaling (pMDS) for revealing neural computation stages; (4) Temporal Topological Data Analysis (tTDA) for uncovering developmental trajectories; and (5) Single-cell Topological Simplicial Analysis (scTSA) for characterizing cell population complexity.
  Through analyses of neural recordings, biological data, and neural network simulations, this thesis demonstrates the power and versatility of these methods in understanding brains, computational models, and complex biological systems. They not only offer robust approaches for adjudicating among competing models but also reveal novel theoretical insights into the nature of neural computation. This work lays the foundation for future investigations at the intersection of topology, neuroscience, and time series analysis, paving the way for more nuanced understanding of brain function and dysfunction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.11948v1</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <category>math.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Baihan Lin</dc:creator>
    </item>
    <item>
      <title>Imaging mitochondrial calcium dynamics in the central nervous system</title>
      <link>https://arxiv.org/abs/2408.12202</link>
      <description>arXiv:2408.12202v1 Announce Type: new 
Abstract: Mitochondrial calcium handling is a particularly active research area in the neuroscience field, as it plays key roles in the regulation of several functions of the central nervous system, such as synaptic transmission and plasticity, astrocyte calcium signaling, neuronal activity{\ldots} In the last few decades, a panel of techniques have been developed to measure mitochondrial calcium dynamics, relying mostly on photonic microscopy, and including synthetic sensors, hybrid sensors and genetically encoded calcium sensors. The goal of this review is to endow the reader with a deep knowledge of the historical and latest tools to monitor mitochondrial calcium events in the brain, as well as a comprehensive overview of the current state of the art in brain mitochondrial calcium signaling. We will discuss the main calcium probes used in the field, their mitochondrial targeting strategies, their key properties and major drawbacks. In addition, we will detail the main roles of mitochondrial calcium handling in neuronal tissues through an extended report of the recent studies using mitochondrial targeted calcium sensors in neuronal and astroglial cells, in vitro and in vivo.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12202v1</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>0.1016/j.jneumeth.2022.109560</arxiv:DOI>
      <arxiv:journal_reference>Journal of Neuroscience Methods, 2022, 373, pp.109560</arxiv:journal_reference>
      <dc:creator>Roman Serrat (U1215 Inserm - UB), Alexandre Oliveira-Pinto (U1215 Inserm - UB), Giovanni Marsicano (U1215 Inserm - UB), Sandrine Pouvreau (U1215 Inserm - UB)</dc:creator>
    </item>
    <item>
      <title>Unsupervised discovery of the shared and private geometry in multi-view data</title>
      <link>https://arxiv.org/abs/2408.12091</link>
      <description>arXiv:2408.12091v1 Announce Type: cross 
Abstract: Modern applications often leverage multiple views of a subject of study. Within neuroscience, there is growing interest in large-scale simultaneous recordings across multiple brain regions. Understanding the relationship between views (e.g., the neural activity in each region recorded) can reveal fundamental principles about the characteristics of each representation and about the system. However, existing methods to characterize such relationships either lack the expressivity required to capture complex nonlinearities, describe only sources of variance that are shared between views, or discard geometric information that is crucial to interpreting the data. Here, we develop a nonlinear neural network-based method that, given paired samples of high-dimensional views, disentangles low-dimensional shared and private latent variables underlying these views while preserving intrinsic data geometry. Across multiple simulated and real datasets, we demonstrate that our method outperforms competing methods. Using simulated populations of lateral geniculate nucleus (LGN) and V1 neurons we demonstrate our model's ability to discover interpretable shared and private structure across different noise conditions. On a dataset of unrotated and corresponding but randomly rotated MNIST digits, we recover private latents for the rotated view that encode rotation angle regardless of digit class, and places the angle representation on a 1-d manifold, while shared latents encode digit class but not rotation angle. Applying our method to simultaneous Neuropixels recordings of hippocampus and prefrontal cortex while mice run on a linear track, we discover a low-dimensional shared latent space that encodes the animal's position. We propose our approach as a general-purpose method for finding succinct and interpretable descriptions of paired data sets in terms of disentangled shared and private latent variables.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12091v1</guid>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sai Koukuntla, Joshua B. Julian, Jesse C. Kaminsky, Manuel Schottdorf, David W. Tank, Carlos D. Brody, Adam S. Charles</dc:creator>
    </item>
    <item>
      <title>Neural Fields and Noise-Induced Patterns in Neurons on Large Disordered Networks</title>
      <link>https://arxiv.org/abs/2408.12540</link>
      <description>arXiv:2408.12540v1 Announce Type: cross 
Abstract: We study pattern formation in class of a large-dimensional neural networks posed on random graphs and subject to spatio-temporal stochastic forcing. Under generic conditions on coupling and nodal dynamics, we prove that the network admits a rigorous mean-field limit, resembling a Wilson-Cowan neural field equation. The state variables of the limiting systems are the mean and variance of neuronal activity. We select networks whose mean-field equations are tractable and we perform a bifurcation analysis using as control parameter the diffusivity strength of the afferent white noise on each neuron. We find conditions for Turing-like bifurcations in a system where the cortex is modelled as a ring, and we produce numerical evidence of noise-induced spiral waves in models with a two-dimensional cortex. We provide numerical evidence that solutions of the finite-size network converge weakly to solutions of the mean-field model. Finally, we prove a Large Deviation Principle, which provides a means of assessing the likelihood of deviations from the mean-field equations induced by finite-size effects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12540v1</guid>
      <category>math.PR</category>
      <category>math.DS</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniele Avitabile, James MacLaurin</dc:creator>
    </item>
    <item>
      <title>Learning to combine top-down context and feed-forward representations under ambiguity with apical and basal dendrites</title>
      <link>https://arxiv.org/abs/2312.05484</link>
      <description>arXiv:2312.05484v2 Announce Type: replace 
Abstract: One of the hallmark features of neocortical anatomy is the presence of extensive top-down projections into primary sensory areas, with many impinging on the distal apical dendrites of pyramidal neurons. While it is known that they exert a modulatory effect, altering the gain of responses, their functional role remains an active area of research. It is hypothesized that these top-down projections carry contextual information that can help animals to resolve ambiguities in sensory data. One proposed mechanism of contextual integration is a non-linear integration of distinct input streams at apical and basal dendrites of pyramidal neurons. Computationally, however, it is yet to be demonstrated how such an architecture could leverage distinct compartments for flexible contextual integration and sensory processing when both sensory and context signals can be unreliable. Here, we implement an augmented deep neural network with distinct apical and basal compartments that integrates a) contextual information from top-down projections to apical compartments, and b) sensory representations driven by bottom-up projections to basal compartments, via a biophysically inspired rule. In addition, we develop a new multi-scenario contextual integration task using a generative image modeling approach. In addition to generalizing previous contextual integration tasks, it better captures the diversity of scenarios where neither contextual nor sensory information are fully reliable. To solve this task, this model successfully learns to select among integration strategies. We find that our model outperforms those without the "apical prior" when contextual information contradicts sensory input. Altogether, this suggests that the apical prior and biophysically inspired integration rule could be key components necessary for handling the ambiguities that animals encounter in the diverse contexts of the real world.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.05484v2</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nizar Islah, Guillaume Etter, Mashbayar Tugsbayar, Tugce Gurbuz, Blake Richards, Eilif Muller</dc:creator>
    </item>
    <item>
      <title>Searching for long time scales without fine tuning</title>
      <link>https://arxiv.org/abs/2008.11674</link>
      <description>arXiv:2008.11674v3 Announce Type: replace-cross 
Abstract: Most of animal and human behavior occurs on time scales much longer than the response times of individual neurons. In many cases, it is plausible that these long time scales emerge from the recurrent dynamics of electrical activity in networks of neurons. In linear models, time scales are set by the eigenvalues of a dynamical matrix whose elements measure the strengths of synaptic connections between neurons. It is not clear to what extent these matrix elements need to be tuned in order to generate long time scales; in some cases, one needs not just a single long time scale but a whole range. Starting from the simplest case of random symmetric connections, we combine maximum entropy and random matrix theory methods to construct ensembles of networks, exploring the constraints required for long time scales to become generic. We argue that a single long time scale can emerge generically from realistic constraints, but a full spectrum of slow modes requires more tuning. Langevin dynamics that generates patterns of synaptic connections drawn from these ensembles involves a combination of Hebbian learning and activity-dependent synaptic scaling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2008.11674v3</guid>
      <category>physics.bio-ph</category>
      <category>nlin.AO</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaowen Chen, William Bialek</dc:creator>
    </item>
  </channel>
</rss>
