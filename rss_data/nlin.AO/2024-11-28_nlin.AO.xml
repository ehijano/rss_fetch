<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>nlin.AO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/nlin.AO</link>
    <description>nlin.AO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/nlin.AO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 28 Nov 2024 05:05:19 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Synchronization of two bacterial flagella as a stochastic process</title>
      <link>https://arxiv.org/abs/2411.18103</link>
      <description>arXiv:2411.18103v1 Announce Type: new 
Abstract: Synchronization with noise is important for understanding biophysical processes at nano- and micro-meter scales, such as neuron firing and beating of cilia. To understand the energetics of these processes, stochastic thermodynamics approaches are useful. Due to large fluctuations in a small system, emsemble averages of thermodynamic quantities are not sufficient to characterize the energetics of an individual sample. In this paper, we use a model for synchronization of bacterial flagella as an example, and develop an approximation method for analyzing the phase and heat dissipation in trajectories for different noise realizations. We describe the time development of the phase difference and heat dissipation as stochastic processes, and verify the analytical results by numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18103v1</guid>
      <category>nlin.AO</category>
      <category>physics.bio-ph</category>
      <pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jing Qin, Nariya Uchida</dc:creator>
    </item>
    <item>
      <title>Exotic synchronization in continuous time crystals outside the symmetric subspace</title>
      <link>https://arxiv.org/abs/2401.00675</link>
      <description>arXiv:2401.00675v2 Announce Type: replace-cross 
Abstract: Exploring continuous time crystals (CTCs) within the symmetric subspace of spin systems has been a subject of intensive research in recent times. Thus far, the stability of the time-crystal phase outside the symmetric subspace in such spin systems has gone largely unexplored. Here, we investigate the effect of including the asymmetric subspaces on the dynamics of CTCs in a driven dissipative spin model. This results in multistability, and the dynamics becomes dependent on the initial state. Remarkably, this multistability leads to exotic synchronization regimes such as chimera states and cluster synchronization in an ensemble of coupled identical CTCs. Interestingly, it leads to other nonlinear phenomena such as oscillation death and signature of chaos.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.00675v2</guid>
      <category>quant-ph</category>
      <category>cond-mat.mes-hall</category>
      <category>nlin.AO</category>
      <pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Parvinder Solanki, Midhun Krishna, Michal Hajdu\v{s}ek, Christoph Bruder, Sai Vinjanampathy</dc:creator>
    </item>
    <item>
      <title>An iterated learning model of language change that mixes supervised and unsupervised learning</title>
      <link>https://arxiv.org/abs/2405.20818</link>
      <description>arXiv:2405.20818v3 Announce Type: replace-cross 
Abstract: The iterated learning model is an agent model which simulates the transmission of of language from generation to generation. It is used to study how the language adapts to pressures imposed by transmission. In each iteration, a language tutor exposes a na\"ive pupil to a limited training set of utterances, each pairing a random meaning with the signal that conveys it. Then the pupil becomes a tutor for a new na\"ive pupil in the next iteration. The transmission bottleneck ensures that tutors must generalize beyond the training set that they experienced. Repeated cycles of learning and generalization can result in a language that is expressive, compositional and stable. Previously, the agents in the iterated learning model mapped signals to meanings using an artificial neural network but relied on an unrealistic and computationally expensive process of obversion to map meanings to signals. Here, both maps are neural networks, trained separately through supervised learning and together through unsupervised learning in the form of an autoencoder. This avoids the computational burden entailed in obversion and introduces a mixture of supervised and unsupervised learning as observed during language learning in children. The new model demonstrates a linear relationship between the dimensionality of meaning-signal space and effective bottleneck size and suggests that internal reflection on potential utterances is important in language learning and evolution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20818v3</guid>
      <category>cs.CL</category>
      <category>nlin.AO</category>
      <category>q-bio.PE</category>
      <pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Jack Bunyan, Seth Bullock, Conor Houghton</dc:creator>
    </item>
  </channel>
</rss>
