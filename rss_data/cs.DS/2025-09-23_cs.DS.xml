<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 23 Sep 2025 04:00:22 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 23 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Sublinear Time Quantum Sensitivity Sampling</title>
      <link>https://arxiv.org/abs/2509.16801</link>
      <description>arXiv:2509.16801v1 Announce Type: new 
Abstract: We present a unified framework for quantum sensitivity sampling, extending the advantages of quantum computing to a broad class of classical approximation problems. Our unified framework provides a streamlined approach for constructing coresets and offers significant runtime improvements in applications such as clustering, regression, and low-rank approximation. Our contributions include:
  * $k$-median and $k$-means clustering: For $n$ points in $d$-dimensional Euclidean space, we give an algorithm that constructs an $\epsilon$-coreset in time $\widetilde O(n^{0.5}dk^{2.5}~\mathrm{poly}(\epsilon^{-1}))$ for $k$-median and $k$-means clustering. Our approach achieves a better dependence on $d$ and constructs smaller coresets that only consist of points in the dataset, compared to recent results of [Xue, Chen, Li and Jiang, ICML'23].
  * $\ell_p$ regression: For $\ell_p$ regression problems, we construct an $\epsilon$-coreset of size $\widetilde O_p(d^{\max\{1, p/2\}}\epsilon^{-2})$ in time $\widetilde O_p(n^{0.5}d^{\max\{0.5, p/4\}+1}(\epsilon^{-3}+d^{0.5}))$, improving upon the prior best quantum sampling approach of [Apers and Gribling, QIP'24] for all $p\in (0, 2)\cup (2, 22]$, including the widely studied least absolute deviation regression ($\ell_1$ regression).
  * Low-rank approximation with Frobenius norm error: We introduce the first quantum sublinear-time algorithm for low-rank approximation that does not rely on data-dependent parameters, and runs in $\widetilde O(nd^{0.5}k^{0.5}\epsilon^{-1})$ time. Additionally, we present quantum sublinear algorithms for kernel low-rank approximation and tensor low-rank approximation, broadening the range of achievable sublinear time algorithms in randomized numerical linear algebra.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.16801v1</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>quant-ph</category>
      <pubDate>Tue, 23 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Zhao Song, David P. Woodruff, Lichen Zhang</dc:creator>
    </item>
    <item>
      <title>Quadratic Kernel for Cliques or Trees Vertex Deletion</title>
      <link>https://arxiv.org/abs/2509.16815</link>
      <description>arXiv:2509.16815v1 Announce Type: new 
Abstract: We consider \textsc{Cliques or Trees Vertex Deletion}, which is a hybrid of two fundamental parameterized problems: \textsc{Cluster Vertex Deletion} and \textsc{Feedback Vertex Set}. In this problem, we are given an undirected graph $G$ and an integer $k$, and asked to find a vertex subset $X$ of size at most $k$ such that each connected component of $G-X$ is either a clique or a tree. Jacob et al. (ISAAC, 2024) provided a kernel of $O(k^5)$ vertices for this problem, which was recently improved to $O(k^4)$ by Tsur (IPL, 2025).
  Our main result is a kernel of $O(k^2)$ vertices. This result closes the gap between the kernelization result for \textsc{Feedback Vertex Set}, which corresponds to the case where each connected component of $G-X$ must be a tree.
  Although both \emph{cluster vertex deletion number} and \emph{feedback vertex set number} are well-studied structural parameters, little attention has been given to parameters that generalize both of them. In fact, the lowest common well-known generalization of them is clique-width, which is a highly general parameter. To fill the gap here, we initiate the study of the \emph{cliques or trees vertex deletion number} as a structural parameter. We prove that \textsc{Longest Cycle}, which is a fundamental problem that does not admit $o(n^k)$-time algorithm unless ETH fails when $k$ is the clique-width, becomes fixed-parameter tractable when parameterized by the cliques or trees vertex deletion number.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.16815v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 23 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Soh Kumabe</dc:creator>
    </item>
    <item>
      <title>Optimal 4-Approximation for the Correlated Pandora's Problem</title>
      <link>https://arxiv.org/abs/2509.17029</link>
      <description>arXiv:2509.17029v1 Announce Type: new 
Abstract: The Correlated Pandora's Problem posed by Chawla et al. (2020) generalizes the classical Pandora's Problem by allowing the numbers inside the Pandora's boxes to be correlated. It also generalizes the Min Sum Set Cover problem, and is related to the Uniform Decision Tree problem. This paper gives an optimal 4-approximation for the Correlated Pandora's Problem, matching the lower bound of 4 from Min Sum Set Cover.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.17029v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 23 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nikhil Bansal, Zhiyi Huang, Zixuan Zhu</dc:creator>
    </item>
    <item>
      <title>Distance Approximating Minors for Planar and Minor-Free Graphs</title>
      <link>https://arxiv.org/abs/2509.17226</link>
      <description>arXiv:2509.17226v1 Announce Type: new 
Abstract: Given an edge-weighted graph $G$ and a subset of vertices $T$ called terminals, an $\alpha$-distance-approximating minor ($\alpha$-DAM) of $G$ is a graph minor $H$ of $G$ that contains all terminals, such that the distance between every pair of terminals is preserved up to a factor of $\alpha$. Distance-approximating minor would be an effective distance-sketching structure on minor-closed family of graphs; in the constant-stretch regime it generalizes the well-known Steiner Point Removal problem by allowing the existence of (a small number of) non-terminal vertices. Unfortunately, in the $(1+\varepsilon)$ regime the only known DAM construction for planar graphs relies on overlaying $\tilde{O}_\varepsilon(|T|)$ shortest paths in $G$, which naturally leads to a quadratic bound in the number of terminals [Cheung, Goranci, and Henzinger, ICALP 2016].
  We break the quadratic barrier and build the first $(1+\varepsilon)$-distance-approximating minor for $k$-terminal planar graphs and minor-free graphs of near-linear size $\tilde{O}_\varepsilon(k)$. In addition to the near-optimality in size, the construction relies only on the existence of shortest-path separators [Abraham and Gavoille, PODC 2006] and $\varepsilon$-covers [Thorup, J.\ ACM 2004]. Consequently, this provides an alternative and simpler construction to the near-linear-size emulator for planar graphs [Chang, Krauthgamer, and Tan, STOC 2022], as well as the first near-linear-size emulator for minor-free graphs. Our DAM can be constructed in near-linear time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.17226v1</guid>
      <category>cs.DS</category>
      <category>cs.CG</category>
      <category>cs.DM</category>
      <pubDate>Tue, 23 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Hsien-Chih Chang, Jonathan Conroy</dc:creator>
    </item>
    <item>
      <title>Distribution Testing in the Presence of Arbitrarily Dominant Noise with Verification Queries</title>
      <link>https://arxiv.org/abs/2509.17269</link>
      <description>arXiv:2509.17269v1 Announce Type: new 
Abstract: We study distribution testing without direct access to a source of relevant data, but rather to one where only a tiny fraction is relevant. To enable this, we introduce the following verification query model. The goal is to perform a statistical task on distribution $\boldsymbol{p}$ given sample access to a mixture $\boldsymbol{r} = \lambda \boldsymbol{p} + (1-\lambda)\boldsymbol{q}$ and the ability to query whether a sample was generated by $\boldsymbol{p}$ or by $\boldsymbol{q}$. In general, if $m_0$ samples from $\boldsymbol{p}$ suffice for a task, then $O(m_0/\lambda)$ samples and queries always suffice in our model. Are there tasks for which the number of queries can be significantly reduced?
  We study the canonical problems in distribution testing, and obtain matching upper and lower bounds that reveal smooth trade-offs between sample and query complexity. For all $m \leq n$, we obtain (i) a uniformity and identity tester using $O(m + \frac{\sqrt{n}}{\varepsilon^2 \lambda})$ samples and $O(\frac{n}{m \varepsilon^4 \lambda^2})$ queries, and (ii) a closeness tester using $O(m + \frac{n^{2/3}}{\varepsilon^{4/3} \lambda} + \frac{1}{\varepsilon^4 \lambda^3})$ samples and $O(\frac{n^2}{m^2 \varepsilon^4 \lambda^3})$ queries. Moreover, we show that these query complexities are tight for all testers using $m \ll n$ samples.
  Next, we show that for testing closeness using $m = \widetilde{O}(\frac{n}{\varepsilon^2\lambda})$ samples we can achieve query complexity $\widetilde{O}(\frac{1}{\varepsilon^2\lambda})$ which is nearly optimal even for the basic task of bias estimation with unbounded samples. Our uniformity testers work in the more challenging setting where the contaminated samples are generated by an adaptive adversary (at the cost of a $\log n$ factor). Finally, we show that our lower bounds can be circumvented if the algorithm is provided with the PDF of the mixture.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.17269v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Tue, 23 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hadley Black, Christopher Ye</dc:creator>
    </item>
    <item>
      <title>Theory Meets Practice for Bit Vectors Supporting Rank and Select</title>
      <link>https://arxiv.org/abs/2509.17819</link>
      <description>arXiv:2509.17819v1 Announce Type: new 
Abstract: Bit vectors with support for fast rank and select are a fundamental building block for compressed data structures. We close a gap between theory and practice by analyzing an important part of the design space and experimentally evaluating a sweet spot. The result is the first implementation of a rank and select data structure for bit vectors with worst-case constant query time, good practical performance, and a space-overhead of just 0.78%, i.e., between $4.5\times$ and $64.1\times$ less than previous implementations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.17819v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 23 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Florian Kurpicz, Niccol\`o Rigi-Luperti, Peter Sanders</dc:creator>
    </item>
    <item>
      <title>Ordered Leaf Attachment (OLA) Vectors can Identify Reticulation Events even in Multifurcated Trees</title>
      <link>https://arxiv.org/abs/2509.16405</link>
      <description>arXiv:2509.16405v1 Announce Type: cross 
Abstract: Recently, a new vector encoding, Ordered Leaf Attachment (OLA), was introduced that represents $n$-leaf phylogenetic trees as $n-1$ length integer vectors by recording the placement location of each leaf. Both encoding and decoding of trees run in linear time and depend on a fixed ordering of the leaves. Here, we investigate the connection between OLA vectors and the maximum acyclic agreement forest (MAAF) problem. A MAAF represents an optimal breakdown of $k$ trees into reticulation-free subtrees, with the roots of these subtrees representing reticulation events. We introduce a corrected OLA distance index over OLA vectors of $k$ trees, which is easily computable in linear time. We prove that the corrected OLA distance corresponds to the size of a MAAF, given an optimal leaf ordering that minimizes that distance. Additionally, a MAAF can be easily reconstructed from optimal OLA vectors. We expand these results to multifurcated trees: we introduce an $O(kn \cdot m\log m)$ algorithm that optimally resolves a set of multifurcated trees given a leaf-ordering, where $m$ is the size of a largest multifurcation, and show that trees resolved via this algorithm also minimize the size of a MAAF. These results suggest a new approach to fast computation of phylogenetic networks and identification of reticulation events via random permutations of leaves. Additionally, in the case of microbial evolution, a natural ordering of leaves is often given by the sample collection date, which means that under mild assumptions, reticulation events can be identified in polynomial time on such datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.16405v1</guid>
      <category>q-bio.PE</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Tue, 23 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Alexey Markin, Tavis K. Anderson</dc:creator>
    </item>
    <item>
      <title>WarpSpeed: A High-Performance Library for Concurrent GPU Hash Tables</title>
      <link>https://arxiv.org/abs/2509.16407</link>
      <description>arXiv:2509.16407v1 Announce Type: cross 
Abstract: GPU hash tables are increasingly used to accelerate data processing, but their limited functionality restricts adoption in large-scale data processing applications. Current limitations include incomplete concurrency support and missing compound operations such as upserts.
  This paper presents WarpSpeed, a library of high-performance concurrent GPU hash tables with a unified benchmarking framework for performance analysis. WarpSpeed implements eight state-of-the-art Nvidia GPU hash table designs and provides a rich API designed for modern GPU applications. Our evaluation uses diverse benchmarks to assess both correctness and scalability, and we demonstrate real-world impact by integrating these hash tables into three downstream applications.
  We propose several optimization techniques to reduce concurrency overhead, including fingerprint-based metadata to minimize cache line probes and specialized Nvidia GPU instructions for lock-free queries. Our findings provide new insights into concurrent GPU hash table design and offer practical guidance for developing efficient, scalable data structures on modern GPUs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.16407v1</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 23 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hunter McCoy, Prashant Pandey</dc:creator>
    </item>
    <item>
      <title>Differential Privacy for Euclidean Jordan Algebra with Applications to Private Symmetric Cone Programming</title>
      <link>https://arxiv.org/abs/2509.16915</link>
      <description>arXiv:2509.16915v1 Announce Type: cross 
Abstract: In this paper, we study differentially private mechanisms for functions whose outputs lie in a Euclidean Jordan algebra. Euclidean Jordan algebras capture many important mathematical structures and form the foundation of linear programming, second-order cone programming, and semidefinite programming. Our main contribution is a generic Gaussian mechanism for such functions, with sensitivity measured in $\ell_2$, $\ell_1$, and $\ell_\infty$ norms. Notably, this framework includes the important case where the function outputs are symmetric matrices, and sensitivity is measured in the Frobenius, nuclear, or spectral norm. We further derive private algorithms for solving symmetric cone programs under various settings, using a combination of the multiplicative weights update method and our generic Gaussian mechanism. As an application, we present differentially private algorithms for semidefinite programming, resolving a major open question posed by [Hsu, Roth, Roughgarden, and Ullman, ICALP 2014].</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.16915v1</guid>
      <category>math.OC</category>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Tue, 23 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Zhao Song, Jianfei Xue, Lichen Zhang</dc:creator>
    </item>
    <item>
      <title>Hyperbolic Sets in Incomplete Tables</title>
      <link>https://arxiv.org/abs/2509.17591</link>
      <description>arXiv:2509.17591v1 Announce Type: cross 
Abstract: In this paper, we extend results about the implementation of the Berlekamp-Massey-Sakata algorithm on data tables having a number of unknown values.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.17591v1</guid>
      <category>cs.IT</category>
      <category>cs.DS</category>
      <category>math.IT</category>
      <pubDate>Tue, 23 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>J. J. Bernal, J. J. Sim\'on</dc:creator>
    </item>
    <item>
      <title>Sketching approximations and LP approximations for finite CSPs are related</title>
      <link>https://arxiv.org/abs/2509.17926</link>
      <description>arXiv:2509.17926v1 Announce Type: cross 
Abstract: We identify a connection between the approximability of CSPs in two models: (i) sublinear space streaming algorithms, and (ii) the basic LP relaxation. We show that whenever the basic LP admits an integrality gap, there is an $\Omega(\sqrt{n})$-space sketching lower bound. We also show that all existing linear space streaming lower bounds for Max-CSPs can be lifted to integrality gap instances for basic LPs. For bounded-degree graphs, by combining the distributed algorithm of Yoshida (STOC 2011) for approximately solving the basic LP with techniques described in Saxena, Singer, Sudan, and Velusamy (SODA 2025) for simulating a distributed algorithm by a sublinear space streaming algorithm on bounded-degree instances of Max-DICUT, it appears that there are sublinear space streaming algorithms implementing the basic LP, for every CSP.
  Based on our results, we conjecture the following dichotomy theorem: Whenever the basic LP admits an integrality gap, there is a linear space single-pass streaming lower bound, and when the LP is roundable, there is a sublinear space streaming algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.17926v1</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 23 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Noah G. Singer, Madhur Tulsiani, Santhoshini Velusamy</dc:creator>
    </item>
    <item>
      <title>Computing the $D$-base and $D$-relation in finite closure systems</title>
      <link>https://arxiv.org/abs/2404.07037</link>
      <description>arXiv:2404.07037v3 Announce Type: replace 
Abstract: Implicational bases (IBs) are a common representation of finite closure systems and lattices, along with meet-irreducible elements. They appear in a wide variety of fields ranging from logic and databases to Knowledge Space Theory. Different IBs can represent the same closure system. Therefore, several IBs have been studied, such as the canonical and canonical direct bases. In this paper, we investigate the $D$-base, a refinement of the canonical direct base. It is connected with the $D$-relation, an essential tool in the study of free lattices. The $D$-base demonstrates desirable algorithmic properties, and together with the $D$-relation, it conveys essential properties of the underlying closure system. Hence, computing the $D$-base and the $D$-relation of a closure system from another representation is crucial to enjoy its benefits. However, complexity results for this task are lacking. In this paper, we give algorithms and hardness results for the computation of the $D$-base and $D$-relation. Specifically, we establish the $NP$-completeness of finding the $D$-relation from an arbitrary IB; we give an output-quasi-polynomial time algorithm to compute the $D$-base from meet-irreducible elements; and we obtain a polynomial-delay algorithm computing the $D$-base from an arbitrary IB. These results complete the picture regarding the complexity of identifying the $D$-base and $D$-relation of a closure system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07037v3</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>math.CO</category>
      <pubDate>Tue, 23 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kira Adaricheva, Lhouari Nourine, Simon Vilmin</dc:creator>
    </item>
    <item>
      <title>Parallel Simulation for Log-concave Sampling and Score-based Diffusion Models</title>
      <link>https://arxiv.org/abs/2412.07435</link>
      <description>arXiv:2412.07435v3 Announce Type: replace 
Abstract: Sampling from high-dimensional probability distributions is fundamental in machine learning and statistics. As datasets grow larger, computational efficiency becomes increasingly important, particularly in reducing adaptive complexity, namely the number of sequential rounds required for sampling algorithms. While recent works have introduced several parallelizable techniques, they often exhibit suboptimal convergence rates and remain significantly weaker than the latest lower bounds for log-concave sampling. To address this, we propose a novel parallel sampling method that improves adaptive complexity dependence on dimension $d$ reducing it from $\widetilde{\mathcal{O}}(\log^2 d)$ to $\widetilde{\mathcal{O}}(\log d)$. which is even optimal for log-concave sampling with some specific adaptive complexity. Our approach builds on parallel simulation techniques from scientific computing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.07435v3</guid>
      <category>cs.DS</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 23 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Huanjian Zhou, Masashi Sugiyama</dc:creator>
    </item>
    <item>
      <title>Improved Approximation Algorithms for Chromatic and Pseudometric-Weighted Correlation Clustering</title>
      <link>https://arxiv.org/abs/2505.21939</link>
      <description>arXiv:2505.21939v2 Announce Type: replace 
Abstract: Correlation Clustering (CC) is a foundational problem in unsupervised learning that models binary similarity relations using labeled graphs. While classical CC has been widely studied, many real-world applications involve more nuanced relationships, either multi-class categorical interactions or varying confidence levels in edge labels. To address these, two natural generalizations have been proposed: Chromatic Correlation Clustering (CCC), which assigns semantic colors to edge labels, and pseudometric-weighted CC, which allows edge weights satisfying the triangle inequality. In this paper, we develop improved approximation algorithms for both settings. Our approach leverages LP-based pivoting techniques combined with problem-specific rounding functions. For the pseudometric-weighted correlation clustering problem, we present a tight $10/3$-approximation algorithm, matching the best possible bound achievable within the framework of standard LP relaxation combined with specialized rounding. For the Chromatic Correlation Clustering (CCC) problem, we improve the approximation ratio from the previous best of $2.5$ to $2.15$, and we establish a lower bound of $2.11$ within the same analytical framework, highlighting the near-optimality of our result.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21939v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 23 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chenglin Fan, Dahoon Lee, Euiwoong Lee</dc:creator>
    </item>
    <item>
      <title>Efficient Computation of Closed Substrings</title>
      <link>https://arxiv.org/abs/2506.06452</link>
      <description>arXiv:2506.06452v2 Announce Type: replace 
Abstract: A closed string $u$ is either of length one or contains a border that occurs only as a prefix and as a suffix in $u$ and nowhere else within $u$. In this paper, we present a fast and practical $O(n\log n)$ time algorithm to compute all $\Theta(n^2)$ closed substrings by introducing a compact representation for all closed substrings of a string $ w[1..n]$, using only $O(n \log n)$ space. We also present a simple and space-efficient solution to compute all maximal closed substrings (MCSs) using the suffix array ($\mathsf{SA}$) and the longest common prefix ($\mathsf{LCP}$) array of $w[1..n]$. Finally, we show that the exact number of MCSs ($M(f_n)$) in a Fibonacci word $ f_n $, for $n \geq 5$, is $\approx \left(1 + \frac{1}{\phi^2}\right) F_n \approx 1.382 F_n$, where $ \phi $ is the golden ratio.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.06452v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 23 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-032-05228-5_15</arxiv:DOI>
      <dc:creator>Samkith K Jain, Neerja Mhaskar</dc:creator>
    </item>
    <item>
      <title>New algorithms for girth and cycle detection</title>
      <link>https://arxiv.org/abs/2507.02061</link>
      <description>arXiv:2507.02061v2 Announce Type: replace 
Abstract: Let $G=(V,E)$ be an unweighted undirected graph with $n$ vertices and $m$ edges. Let $g$ be the girth of $G$, that is, the length of a shortest cycle in $G$. We present a randomized algorithm with a running time of $\tilde{O}\big(\ell \cdot n^{1 + \frac{1}{\ell - \varepsilon}}\big)$ that returns a cycle of length at most $ 2\ell \left\lceil \frac{g}{2} \right\rceil - 2 \left\lfloor \varepsilon \left\lceil \frac{g}{2} \right\rceil \right\rfloor, $ where $\ell \geq 2$ is an integer and $\varepsilon \in [0,1]$, for every graph with $g = polylog(n)$.
  Our algorithm generalizes an algorithm of Kadria \etal{} [SODA'22] that computes a cycle of length at most $4\left\lceil \frac{g}{2} \right\rceil - 2\left\lfloor \varepsilon \left\lceil \frac{g}{2} \right\rceil \right\rfloor $ in $\tilde{O}\big(n^{1 + \frac{1}{2 - \varepsilon}}\big)$ time. Kadria \etal{} presented also an algorithm that finds a cycle of length at most $ 2\ell \left\lceil \frac{g}{2} \right\rceil $ in $\tilde{O}\big(n^{1 + \frac{1}{\ell}}\big)$ time, where $\ell$ must be an integer. Our algorithm generalizes this algorithm, as well, by replacing the integer parameter $\ell$ in the running time exponent with a real-valued parameter $\ell - \varepsilon$, thereby offering greater flexibility in parameter selection and enabling a broader spectrum of combinations between running times and cycle lengths.
  We also show that for sparse graphs a better tradeoff is possible, by presenting an $\tilde{O}(\ell\cdot m^{1+1/(\ell-\varepsilon)})$ time randomized algorithm that returns a cycle of length at most $2\ell(\lfloor \frac{g-1}{2}\rfloor) - 2(\lfloor \varepsilon \lfloor \frac{g-1}{2}\rfloor \rfloor+1)$, where $\ell\geq 3$ is an integer and $\varepsilon\in [0,1)$, for every graph with $g=polylog(n)$.
  To obtain our algorithms we develop several techniques and introduce a formal definition of hybrid cycle detection algorithms. [...]</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.02061v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 23 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liam Roditty, Plia Trabelsi</dc:creator>
    </item>
    <item>
      <title>Tighter Bounds for Personalized PageRank</title>
      <link>https://arxiv.org/abs/2507.14462</link>
      <description>arXiv:2507.14462v2 Announce Type: replace 
Abstract: We study Personalized PageRank (PPR), where for nodes $s,t$ in a graph $G$, $\pi(s,t)$ is the probability that an $\alpha$-decay random walk from $s$ ends at $t$. Two key queries are: Single-Source PPR (SSPPR), computing $\pi(s,\cdot)$ for fixed $s$, and Single-Target PPR (STPPR), computing $\pi(\cdot,t)$ for fixed $t$. SSPPR is studied under absolute error (SSPPR-A), requiring $|\hat{\pi}(s,t)-\pi(s,t)|\le \epsilon$, and relative error (SSPPR-R), requiring $|\hat{\pi}(s,t)-\pi(s,t)|\le c\pi(s,t)$ for $t$ with $\pi(s,t)\ge \delta$; STPPR adopts the same relative criterion. These queries support web search, recommendation, sparsification, and graph neural networks.
  The best known upper bounds are $O(\min(\tfrac{\log(1/\epsilon)}{\epsilon^{2}},\tfrac{\sqrt{m\log n}}{\epsilon},m\log\tfrac{1}{\epsilon}))$ for SSPPR-A and $O(\min(\tfrac{\log(1/\delta)}{\delta},\sqrt{\tfrac{m\log n}{\delta}},m\log\tfrac{\log n}{\delta m}))$ for SSPPR-R, while lower bounds remain $\Omega(\min(n,1/\epsilon))$, $\Omega(\min(m,1/\delta))$, and $\Omega(\min(n,1/\delta))$, leaving large gaps. We close these gaps by (i) presenting a Monte Carlo algorithm that tightens the SSPPR-A upper bound to $O(1/\epsilon^{2})$, and (ii) proving, via an arc-centric construction, lower bounds $\Omega(\min(m,\tfrac{\log(1/\delta)}{\delta}))$ for SSPPR-R, $\Omega(\min(m,\tfrac{1}{\epsilon^{2}}))$ (and intermediate $\Omega(\min(m,\tfrac{\log(1/\epsilon)}{\epsilon}))$) for SSPPR-A, and $\Omega(\min(m,\tfrac{n}{\delta}\log n))$ for STPPR. For practical settings ($\delta=\Theta(1/n)$, $\epsilon=\Theta(n^{-1/2})$, $m\in\Omega(n\log n)$) these bounds meet the best known upper bounds, establishing the optimality of Monte Carlo and FORA for SSPPR-R, our algorithm for SSPPR-A, and RBS for STPPR, and yielding a near-complete complexity landscape for PPR queries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.14462v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Tue, 23 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinpeng Jiang, Haoyu Liu, Siqiang Luo, Xiaokui Xiao</dc:creator>
    </item>
    <item>
      <title>Differentially Private Synthetic Graphs Preserving Triangle-Motif Cuts</title>
      <link>https://arxiv.org/abs/2507.14835</link>
      <description>arXiv:2507.14835v2 Announce Type: replace 
Abstract: We study the problem of releasing a differentially private (DP) synthetic graph $G'$ that well approximates the triangle-motif sizes of all cuts of any given graph $G$, where a motif in general refers to a frequently occurring subgraph within complex networks. Non-private versions of such graphs have found applications in diverse fields such as graph clustering, graph sparsification, and social network analysis. Specifically, we present the first $(\varepsilon,\delta)$-DP mechanism that, given an input graph $G$ with $n$ vertices, $m$ edges and local sensitivity of triangles $\ell_{3}(G)$, generates a synthetic graph $G'$ in polynomial time, approximating the triangle-motif sizes of all cuts $(S,V\setminus S)$ of the input graph $G$ up to an additive error of $\tilde{O}(\sqrt{m\ell_{3}(G)}n/\varepsilon^{3/2})$. Additionally, we provide a lower bound of $\Omega(\sqrt{mn}\ell_{3}(G)/\varepsilon)$ on the additive error for any DP algorithm that answers the triangle-motif size queries of all $(S,T)$-cut of $G$. Finally, our algorithm generalizes to weighted graphs, and our lower bound extends to any $K_h$-motif cut for any constant $h\geq 2$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.14835v2</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Tue, 23 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pan Peng, Hangyu Xu</dc:creator>
    </item>
    <item>
      <title>Robustifying Learning-Augmented Caching Efficiently without Compromising 1-Consistency</title>
      <link>https://arxiv.org/abs/2507.16242</link>
      <description>arXiv:2507.16242v4 Announce Type: replace 
Abstract: The online caching problem aims to minimize cache misses when serving a sequence of requests under a limited cache size. While naive learning-augmented caching algorithms achieve ideal $1$-consistency, they lack robustness guarantees. Existing robustification methods either sacrifice $1$-consistency or introduce significant computational overhead. In this paper, we introduce Guard, a lightweight robustification framework that enhances the robustness of a broad class of learning-augmented caching algorithms to $2H_k + 2$, while preserving their $1$-consistency. Guard achieves the current best-known trade-off between consistency and robustness, with only $O(1)$ additional per-request overhead, thereby maintaining the original time complexity of the base algorithm. Extensive experiments across multiple real-world datasets and prediction models validate the effectiveness of Guard in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.16242v4</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Tue, 23 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peng Chen, Hailiang Zhao, Jiaji Zhang, Xueyan Tang, Yixuan Wang, Shuiguang Deng</dc:creator>
    </item>
    <item>
      <title>Parameterized complexity of isometric path partition: treewidth and diameter</title>
      <link>https://arxiv.org/abs/2508.05448</link>
      <description>arXiv:2508.05448v2 Announce Type: replace 
Abstract: We investigate the parameterized complexity of the Isometric Path Partition problem when parameterized by the treewidth ($\mathrm{tw}$) of the input graph, arguably one of the most widely studied parameters. Courcelle's theorem shows that graph problems that are expressible as MSO formulas of constant size admit FPT algorithms parameterized by the treewidth of the input graph. This encompasses many natural graph problems. However, many metric-based graph problems, where the solution is defined using some metric-based property of the graph (often the distance) are not expressible as MSO formulas of constant size. These types of problems, Isometric Path Partition being one of them, require individual attention and often draw the boundary for the success story of parameterization by treewidth.
  We prove that Isometric Path Partition is $W[1]$-hard when parameterized by treewidth (in fact, even pathwidth), answering the question by Dumas et al. [SIDMA, 2024], Fernau et al. [CIAC, 2023], and confirming the aforementioned tendency. We complement this hardness result by designing a tailored dynamic programming algorithm running in $n^{O(\mathrm{tw})}$ time. This dynamic programming approach also results in an algorithm running in time $\textrm{diam}^{O(\mathrm{tw}^2)} \cdot n^{O(1)}$, where $\textrm{diam}$ is the diameter of the graph. Note that the dependency on treewidth is unusually high, as most problems admit algorithms running in time $2^{O(\mathrm{tw})}\cdot n^{O(1)}$ or $2^{O(\mathrm{tw} \log (\mathrm{tw}))}\cdot n^{O(1)}$. However, we rule out the possibility of a significantly faster algorithm by proving that Isometric Path Partition does not admit an algorithm running in time $\textrm{diam}^{o(\mathrm{tw}^2/(\log^3(\mathrm{tw})))} \cdot n^{O(1)}$, unless the Randomized-ETH fails.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05448v2</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <pubDate>Tue, 23 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dibyayan Chakraborty, Oscar Defrain, Florent Foucaud, Mathieu Mari, Prafullkumar Tale</dc:creator>
    </item>
    <item>
      <title>Max-Min and 1-Bounded Space Algorithms for the Bin Packing Problem</title>
      <link>https://arxiv.org/abs/2508.18718</link>
      <description>arXiv:2508.18718v3 Announce Type: replace 
Abstract: In the (1-dimensional) bin packing problem, we are asked to pack all the given items into bins, each of capacity one, so that the number of non-empty bins is minimized. Zhu~[Chaos, Solitons \&amp; Fractals 2016] proposed an approximation algorithm $MM$ that sorts the item sequence in a non-increasing order by size at the beginning, and then repeatedly packs, into the current single open bin, first as many of the largest items in the remaining sequence as possible and then as many of the smallest items in the remaining sequence as possible. In this paper we prove that the asymptotic approximation ratio of $MM$ is at most 1.5. Next, focusing on the fact that $MM$ is at the intersection of two algorithm classes, max-min algorithms and 1-bounded space algorithms, we comprehensively analyze the theoretical performance bounds of each subclass derived from the two classes. Our results include a lower bound of 1.25 for the intersection of the two classes. Furthermore, we extend the theoretical analysis over algorithm classes to the cardinality constrained bin packing problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18718v3</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <category>math.OC</category>
      <pubDate>Tue, 23 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hiroshi Fujiwara, Rina Atsumi, Hiroaki Yamamoto</dc:creator>
    </item>
    <item>
      <title>A Dynamic, Self-balancing k-d Tree</title>
      <link>https://arxiv.org/abs/2509.08148</link>
      <description>arXiv:2509.08148v5 Announce Type: replace 
Abstract: The original description of the k-d tree recognized that rebalancing techniques, used for building an AVL or red-black tree, are not applicable to a k-d tree, because these techniques involve cyclic exchange of tree nodes that violates the invariant of the k-d tree. For this reason, a static, balanced k-d tree is often built from all of the k-dimensional data en masse. However, it is possible to build a dynamic k-d tree that self-balances when necessary after insertion or deletion of each k-dimensional datum. This article describes insertion, deletion, and rebalancing algorithms for a dynamic, self-balancing k-d tree, and measures their performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.08148v5</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 23 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Russell A. Brown</dc:creator>
    </item>
    <item>
      <title>The Chonkers Algorithm: Content-Defined Chunking with Provable Strict Guarantees on Size and Locality</title>
      <link>https://arxiv.org/abs/2509.11121</link>
      <description>arXiv:2509.11121v2 Announce Type: replace 
Abstract: This paper presents the Chonkers algorithm, a novel content-defined chunking method providing simultaneous provable strict guarantees on chunk size and edit locality. Unlike existing algorithms such as Rabin fingerprinting and anchor-based methods, Chonkers achieves bounded propagation of edits and precise control over chunk sizes. I describe the algorithm's layered structure that allows for combination with other chunking algorithms, the theoretical guarantees it provides, implementation considerations, and introduce the Yarn datatype, a deduplicated, merge-tree-based string representation benefiting from Chonkers' strict guarantees. Finally, I experimentally compare Chonkers' ability to deduplicate versioned data to other algorithms and evaluate Chonkers on three corpora with respect to the actually occurring chunk sizes and edit locality, and find that it performs much better in practice than the proved guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11121v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 23 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Benjamin Berger</dc:creator>
    </item>
    <item>
      <title>Selective Population Protocols</title>
      <link>https://arxiv.org/abs/2305.08460</link>
      <description>arXiv:2305.08460v3 Announce Type: replace-cross 
Abstract: The model of population protocols provides a universal platform to study distributed processes driven by pairwise interactions of anonymous agents. While population protocols present an elegant and robust model for randomized distributed computation, their efficiency wanes when tackling issues that require more focused communication or the execution of multiple processes. To address this issue, we propose a new, selective variant of population protocols by introducing a partition of the state space and the corresponding conditional selection of responders. We demonstrate on several examples that the new model offers a natural environment, complete with tools and a high-level description, to facilitate more efficient solutions.
  In particular, we provide fixed-state stable and efficient solutions to two central problems: leader election and majority computation, both with confirmation. This constitutes a separation result, as achieving stable and efficient majority computation requires $\Omega(\log n)$ states in standard population protocols, even when the leader is already determined. Additionally, we explore the computation of the median using the comparison model, where the operational state space of agents is fixed, and the transition function determines the order between (arbitrarily large) hidden keys associated with interacting agents. Our findings reveal that the computation of the median of $n$ numbers requires $\Omega(n)$ time. Moreover, we demonstrate that the problem can be solved in $O(n\log n)$ time, both in expectation and with high probability, in standard population protocols. In contrast, we establish that a feasible solution in selective population protocols can be achieved in $O(\log^4 n)$ time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.08460v3</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 23 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adam Ga\'nczorz, Leszek G\k{a}sieniec, Tomasz Jurdzi\'nski, Jakub Kowalski, Grzegorz Stachowiak</dc:creator>
    </item>
    <item>
      <title>Fast Approximation Algorithms for Euclidean Minimum Weight Perfect Matching</title>
      <link>https://arxiv.org/abs/2407.07749</link>
      <description>arXiv:2407.07749v3 Announce Type: replace-cross 
Abstract: We study the Euclidean minimum weight perfect matching problem for $n$ points in the plane. It is known that any deterministic approximation algorithm whose approximation ratio depends only on $n$ requires at least $\Omega(n \log n)$ time. We propose such an algorithm for the Euclidean minimum weight perfect matching problem with runtime $O(n\log n)$ and show that it has approximation ratio $O(n^{0.206})$. This improves the so far best known approximation ratio of $n/2$. We also develop an $O(n \log n)$ algorithm for the Euclidean minimum weight perfect matching problem in higher dimensions and show it has approximation ratio $O(n^{0.412})$ in all fixed dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07749v3</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Tue, 23 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Stefan Hougardy, Karolina Tammemaa</dc:creator>
    </item>
    <item>
      <title>The Cost of Compression: Tight Quadratic Black-Box Attacks on Sketches for $\ell_2$ Norm Estimation</title>
      <link>https://arxiv.org/abs/2507.16345</link>
      <description>arXiv:2507.16345v2 Announce Type: replace-cross 
Abstract: Dimensionality reduction via linear sketching is a powerful and widely used technique, but it is known to be vulnerable to adversarial inputs. We study the black-box adversarial setting, where a fixed, hidden sketching matrix $A \in R^{k \times n}$ maps high-dimensional vectors $v \in R^n$ to lower-dimensional sketches $A v \in R^k$, and an adversary can query the system to obtain approximate $\ell_2$-norm estimates that are computed from the sketch. We present a universal, nonadaptive attack that, using $\tilde{O}(k^2)$ queries, either causes a failure in norm estimation or constructs an adversarial input on which the optimal estimator for the query distribution (used by the attack) fails. The attack is completely agnostic to the sketching matrix and to the estimator: it applies to any linear sketch and any query responder, including those that are randomized, adaptive, or tailored to the query distribution. Our lower bound construction tightly matches the known upper bounds of $\tilde{\Omega}(k^2)$, achieved by specialized estimators for Johnson Lindenstrauss transforms and AMS sketches. Beyond sketching, our results uncover structural parallels to adversarial attacks in image classification, highlighting fundamental vulnerabilities of compressed representations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.16345v2</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <pubDate>Tue, 23 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>NeurIPS 2025</arxiv:journal_reference>
      <dc:creator>Sara Ahmadian, Edith Cohen, Uri Stemmer</dc:creator>
    </item>
  </channel>
</rss>
