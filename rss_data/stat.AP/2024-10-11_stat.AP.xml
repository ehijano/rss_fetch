<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 11 Oct 2024 04:00:41 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Analysis and Optimization of Seismic Monitoring Networks with Bayesian Optimal Experiment Design</title>
      <link>https://arxiv.org/abs/2410.07215</link>
      <description>arXiv:2410.07215v1 Announce Type: new 
Abstract: Monitoring networks increasingly aim to assimilate data from a large number of diverse sensors covering many sensing modalities. Bayesian optimal experimental design (OED) seeks to identify data, sensor configurations, or experiments which can optimally reduce uncertainty and hence increase the performance of a monitoring network. Information theory guides OED by formulating the choice of experiment or sensor placement as an optimization problem that maximizes the expected information gain (EIG) about quantities of interest given prior knowledge and models of expected observation data. Therefore, within the context of seismo-acoustic monitoring, we can use Bayesian OED to configure sensor networks by choosing sensor locations, types, and fidelity in order to improve our ability to identify and locate seismic sources. In this work, we develop the framework necessary to use Bayesian OED to optimize a sensor network's ability to locate seismic events from arrival time data of detected seismic phases at the regional-scale. Bayesian OED requires four elements:
  1) A likelihood function that describes the distribution of detection and travel time data from the sensor network,
  2) A Bayesian solver that uses a prior and likelihood to identify the posterior distribution of seismic events given the data,
  3) An algorithm to compute EIG about seismic events over a dataset of hypothetical prior events,
  4) An optimizer that finds a sensor network which maximizes EIG.
  Once we have developed this framework, we explore many relevant questions to monitoring such as: how to trade off sensor fidelity and earth model uncertainty; how sensor types, number, and locations influence uncertainty; and how prior models and constraints influence sensor placement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07215v1</guid>
      <category>stat.AP</category>
      <category>cs.LG</category>
      <category>physics.geo-ph</category>
      <category>stat.ML</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jake Callahan, Kevin Monogue, Ruben Villarreal, Tommie Catanach</dc:creator>
    </item>
    <item>
      <title>Chimeric Forecasting: Blending Human Judgment and Computational Methods for Improved, Real-time Forecasts of Influenza Hospitalizations</title>
      <link>https://arxiv.org/abs/2410.07236</link>
      <description>arXiv:2410.07236v1 Announce Type: new 
Abstract: Infectious disease forecasts can reduce mortality and morbidity by supporting evidence-based public health decision making. Most epidemic models train on surveillance and structured data (e.g. weather, mobility, media), missing contextual information about the epidemic. Human judgment forecasts are novel data, asking humans to generate forecasts based on surveillance data and contextual information. Our primary hypothesis is that an epidemic model trained on surveillance plus human judgment forecasts (a chimeric model) can produce more accurate long-term forecasts of incident hospitalizations compared to a control model trained only on surveillance. Humans have a finite amount of cognitive energy to forecast, limiting them to forecast a small number of states. Our secondary hypothesis is that a model can map human judgment forecasts from a small number of states to all states with similar performance. For the 2023/24 season, we collected weekly incident influenza hospitalizations for all US states, and 696 human judgment forecasts of peak epidemic week and the maximum number of hospitalizations (peak intensity) for ten of the most populous states. We found a chimeric model outperformed a control model on long-term forecasts. Compared to human judgment, a chimeric model produced forecasts of peak epidemic week and peak intensity with similar or improved performance. Forecasts of peak epidemic week and peak intensity for the ten states where humans input forecasts vs a model that extended these forecasts to all states showed similar performance to one another. Our results suggest human judgment forecasts are a viable data source that can improve infectious disease forecasts and support public health decisions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07236v1</guid>
      <category>stat.AP</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thomas McAndrew, Mark Lechmanik, ErinN. Hulland, Shaun Truelove, Mark Ilodigwe, Maimuna Majumder</dc:creator>
    </item>
    <item>
      <title>Mapping Hong Kong's Financial Ecosystem: A Network Analysis of the SFC's Licensed Professionals and Institutions</title>
      <link>https://arxiv.org/abs/2410.07970</link>
      <description>arXiv:2410.07970v1 Announce Type: new 
Abstract: We present the first study of the Public Register of Licensed Persons and Registered Institutions maintained by the Hong Kong Securities and Futures Commission (SFC) through the lens of complex network analysis. This dataset, spanning 21 years with daily granularity, provides a unique view of the evolving social network between licensed professionals and their affiliated firms in Hong Kong's financial sector. Leveraging large language models, we classify firms (e.g., asset managers, banks) and infer the likely nationality and gender of employees based on their names. This application enhances the dataset by adding rich demographic and organizational context, enabling more precise network analysis. Our preliminary findings reveal key structural features, offering new insights into the dynamics of Hong Kong's financial landscape. We release the structured dataset to enable further research, establishing a foundation for future studies that may inform recruitment strategies, policy-making, and risk management in the financial industry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07970v1</guid>
      <category>stat.AP</category>
      <category>cs.CE</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abdulla AlKetbi, Gautier Marti, Khaled AlNuaimi, Raed Jaradat, Andreas Henschel</dc:creator>
    </item>
    <item>
      <title>Quasi-average predictions and regression to the trend: an application the M6 financial forecasting competition</title>
      <link>https://arxiv.org/abs/2410.08009</link>
      <description>arXiv:2410.08009v1 Announce Type: new 
Abstract: The efficient market hypothesis considers all available information already reflected in asset prices and limits the possibility of consistently achieving above-average returns by trading on publicly available data. We analyzed low dispersion prediction methods and their application to the M6 financial forecasting competition. Predictive averages and regression to the trend offer slight but potentially consistent advantages over the reference indexes. We put these results in the context of high variability approaches, which, if not accompanied by high information content, are bound to underperform the benchmark index as they are prone to overfit the past. In general, predicting the expected values under high uncertainty conditions, such as those assumed by the efficient market hypothesis, is more effective on average than trying to predict actual values.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08009v1</guid>
      <category>stat.AP</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jose M. G. Vilar</dc:creator>
    </item>
    <item>
      <title>Dynamic Interconnections between Corruption and Economic Growth</title>
      <link>https://arxiv.org/abs/2410.08132</link>
      <description>arXiv:2410.08132v1 Announce Type: new 
Abstract: This study explores the dynamic relationship between corruption and economic growth through an approach based on a system of stochastic equations. In the context of globalization and economic interdependencies, corruption not only affects investment and distorts markets, but it can also, under certain conditions, temporarily boost economic activity. Using data from the Gross Domestic Product (GDP) and the Corruption Perception Index (CPI), we implement a time-series-based model to capture the interactions between these two variables. Through a coupled vector autoregressive equations system, our model identifies patterns of interdependence between economic fluctuations and perceptions of corruption at a global level. Employing graph theory and Granger causality, we build a network of interconnections that illustrates how corruption dynamics in one country can influence economic growth and corruption perception in others. The results provide a robust tool for analyzing international political-economic relationships and can serve as a basis for designing policies that promote transparency and sustainable development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08132v1</guid>
      <category>stat.AP</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Macavilca Tello Bartolome, Kevin Fernandez, Oscar Cutipa-Luque, Yhon Tiahuallpa, Helder Rojas</dc:creator>
    </item>
    <item>
      <title>Feature-centric nonlinear autoregressive models</title>
      <link>https://arxiv.org/abs/2410.07293</link>
      <description>arXiv:2410.07293v1 Announce Type: cross 
Abstract: We propose a novel feature-centric approach to surrogate modeling of dynamical systems driven by time-varying exogenous excitations. This approach, named Functional Nonlinear AutoRegressive with eXogenous inputs (F-NARX), aims to approximate the system response based on temporal features of both the exogenous inputs and the system response, rather than on their values at specific time lags. This is a major step away from the discrete-time-centric approach of classical NARX models, which attempts to determine the relationship between selected time steps of the input/output time series. By modeling the system in a time-feature space instead of the original time axis, F-NARX can provide more stable long-term predictions and drastically reduce the reliance of the model performance on the time discretization of the problem. F-NARX, like NARX, acts as a framework and is not tied to a single implementation. In this work, we introduce an F-NARX implementation based on principal component analysis and polynomial basis functions. To further improve prediction accuracy and computational efficiency, we also introduce a strategy to identify and fit a sparse model structure, thanks to a modified hybrid least angle regression approach that minimizes the expected forecast error, rather than the one-step-ahead prediction error. Since F-NARX is particularly well-suited to modeling engineering structures typically governed by physical processes, we investigate the behavior and capabilities of our F-NARX implementation on two case studies: an eight-story building under wind loading and a three-story steel frame under seismic loading. Our results demonstrate that F-NARX has several favorable properties over classical NARX, making it well suited to emulate engineering systems with high accuracy over extended time periods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07293v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Styfen Sch\"ar, Stefano Marelli, Bruno Sudret</dc:creator>
    </item>
    <item>
      <title>Systematic Feature Design for Cycle Life Prediction of Lithium-Ion Batteries During Formation</title>
      <link>https://arxiv.org/abs/2410.07458</link>
      <description>arXiv:2410.07458v1 Announce Type: cross 
Abstract: Optimization of the formation step in lithium-ion battery manufacturing is challenging due to limited physical understanding of solid electrolyte interphase formation and the long testing time (~100 days) for cells to reach the end of life. We propose a systematic feature design framework that requires minimal domain knowledge for accurate cycle life prediction during formation. Two simple Q(V) features designed from our framework, extracted from formation data without any additional diagnostic cycles, achieved a median of 9.20% error for cycle life prediction, outperforming thousands of autoML models using pre-defined features. We attribute the strong performance of our designed features to their physical origins - the voltage ranges identified by our framework capture the effects of formation temperature and microscopic particle resistance heterogeneity. By designing highly interpretable features, our approach can accelerate formation research, leveraging the interplay between data-driven feature design and mechanistic understanding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07458v1</guid>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinwook Rhyu, Joachim Schaeffer, Michael L. Li, Xiao Cui, William C. Chueh, Martin Z. Bazant, Richard D. Braatz</dc:creator>
    </item>
    <item>
      <title>Learning associations of COVID-19 hospitalizations with wastewater viral signals by Markov modulated models</title>
      <link>https://arxiv.org/abs/2410.07487</link>
      <description>arXiv:2410.07487v1 Announce Type: cross 
Abstract: Viral signal in wastewater offers a promising opportunity to assess and predict the burden of infectious diseases. That has driven the widespread adoption and development of wastewater monitoring tools by public health organizations. Recent research highlights a strong correlation between COVID-19 hospitalizations and wastewater viral signals, and validates that increases in wastewater measurements may offer early warnings of an increase in hospital admissions. Previous studies (e.g. Peng et al. 2023) utilize distributed lag models to explore associations of COVID-19 hospitalizations with lagged SARS-CoV-2 wastewater viral signals. However, the conventional distributed lag models assume the duration time of the lag to be fixed, which is not always plausible. This paper presents Markov-modulated models with distributed lasting time, treating the duration of the lag as a random variable defined by a hidden Markov chain. We evaluate exposure effects over the duration time and estimate the distribution of the lasting time using the wastewater data and COVID-19 hospitalization records from Ottawa, Canada during June 2020 to November 2022. The different COVID-19 waves are accommodated in the statistical learning. In particular, two strategies for comparing the associations over different time intervals are exemplified using the Ottawa data. Of note, the proposed Markov modulated models, an extension of distributed lag models, are potentially applicable to many different problems where the lag time is not fixed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07487v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>K. Ken Peng, Charmaine B. Dean, Robert Delatolla, X. Joan Hu</dc:creator>
    </item>
    <item>
      <title>Leveraging population information in brain connectivity via Bayesian ICA with a novel informative prior for correlation matrices</title>
      <link>https://arxiv.org/abs/2311.03791</link>
      <description>arXiv:2311.03791v2 Announce Type: replace 
Abstract: Brain functional connectivity (FC), the temporal synchrony between brain networks, is essential to understand the functional organization in the brain and to identify changes due to neurological disorders, development, treatment, and other phenomena. Independent component analysis (ICA) is a matrix decomposition method used extensively for simultaneous estimation of functional brain topography and connectivity. However, estimation of FC via ICA is often sub-optimal due to the use of ad-hoc estimation methods or temporal dimension reduction prior to ICA. Bayesian ICA methods can avoid dimension reduction, produce more accurate estimates of latent variables and model parameters, and facilitate inference via posterior distributions. In this paper, we develop a novel, computationally feasible Bayesian ICA method with population-derived priors on both the spatial ICs and their temporal correlation. For the latter we consider two priors: the inverse-Wishart, which is designed for covariance matrices and has limitations for modeling correlation matrices; and a novel informative prior for correlation matrices. For both choices of prior, we derive a variational Bayes algorithm to estimate the model variables and obtain posterior variances or distributions of quantities of interest. Through extensive realistic simulation studies, we evaluate the performance of the proposed methods and compare them with existing approaches. Finally, we analyze fMRI data from over 400 healthy adults in the Human Connectome Project. We find that our Bayesian ICA algorithms produce highly accurate measures of functional connectivity and spatial brain features. Our informative prior for correlation matrices outperforms the inverse-Wishart, but comes with a higher computational burden. The proposed framework is applicable to single-subject analysis, making it potentially clinically viable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.03791v2</guid>
      <category>stat.AP</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amanda Mejia, David Bolin, Daniel Spencer, Ani Eloyan</dc:creator>
    </item>
    <item>
      <title>Sparse higher order partial least squares for simultaneous variable selection, dimension reduction, and tensor denoising</title>
      <link>https://arxiv.org/abs/2310.09428</link>
      <description>arXiv:2310.09428v2 Announce Type: replace-cross 
Abstract: Partial Least Squares (PLS) regression emerged as an alternative to ordinary least squares for addressing multicollinearity in a wide range of scientific applications. As multidimensional tensor data is becoming more widespread, tensor adaptations of PLS have been developed. In this paper, we first establish the statistical behavior of Higher Order PLS (HOPLS) of Zhao et al. (2012), by showing that the consistency of the HOPLS estimator cannot be guaranteed as the tensor dimensions and the number of features increase faster than the sample size. To tackle this issue, we propose Sparse Higher Order Partial Least Squares (SHOPS) regression and an accompanying algorithm. SHOPS simultaneously accommodates variable selection, dimension reduction, and tensor response denoising. We further establish the asymptotic results of the SHOPS algorithm under a high-dimensional regime. The results also complete the unknown theoretic properties of SPLS algorithm (Chun and Kele\c{s}, 2010). We verify these findings through comprehensive simulation experiments, and application to an emerging high-dimensional biological data analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.09428v2</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Kwangmoon Park, S\"und\"uz Kele\c{s}</dc:creator>
    </item>
    <item>
      <title>European Football Player Valuation: Integrating Financial Models and Network Theory</title>
      <link>https://arxiv.org/abs/2312.16179</link>
      <description>arXiv:2312.16179v3 Announce Type: replace-cross 
Abstract: This paper presents a new framework for player valuation in European football, by fusing principles from financial mathematics and network theory. The valuation model leverages a "passing matrix" to encapsulate player interactions on the field, utilizing centrality measures to quantify individual influence. Unlike traditional approaches, such as regressing on past performance-salary data, this model focuses on in-game performance as a player's contributions evolve over time. Consequently, our model provides a dynamic and individualized framework for ascertaining a player's fair market value. The methodology is empirically validated through a case study in European football, employing real-world match and financial data. This cross-disciplinary mechanism for player valuation adapts the effect of connecting pay with performance, first seen in Scully (1974), to include in-game contributions as well as expected present valuation of stochastic variables.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.16179v3</guid>
      <category>physics.soc-ph</category>
      <category>q-fin.CP</category>
      <category>q-fin.PR</category>
      <category>stat.AP</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Albert Cohen, Jimmy Risk</dc:creator>
    </item>
    <item>
      <title>Optical ISAC: Fundamental Performance Limits and Transceiver Design</title>
      <link>https://arxiv.org/abs/2408.11792</link>
      <description>arXiv:2408.11792v5 Announce Type: replace-cross 
Abstract: This paper characterizes the optimal capacity-distortion (C-D) tradeoff in an optical point-to-point system with single-input single-output (SISO) for communication and single-input multiple-output (SIMO) for sensing within an integrated sensing and communication (ISAC) framework. We consider the optimal rate-distortion (R-D) region and explore several inner (IB) and outer bounds (OB). We introduce practical, asymptotically optimal maximum a posteriori (MAP) and maximum likelihood estimators (MLE) for target distance, addressing nonlinear measurement-to-state relationships and non-conjugate priors. As the number of sensing antennas increases, these estimators converge to the Bayesian Cram\'er-Rao bound (BCRB). We also establish that the achievable rate-Cram\'er-Rao bound (R-CRB) serves as an OB for the optimal C-D region, valid for both unbiased estimators and asymptotically large numbers of receive antennas. To clarify that the input distribution determines the tradeoff across the Pareto boundary of the C-D region, we propose two algorithms: i) an iterative Blahut-Arimoto algorithm (BAA)-type method, and ii) a memory-efficient closed-form (CF) approach. The CF approach includes a CF optimal distribution for high optical signal-to-noise ratio (O-SNR) conditions. Additionally, we adapt and refine the deterministic-random tradeoff (DRT) to this optical ISAC context.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.11792v5</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alireza Ghazavi Khorasgani (5/6GIC, Institute for Communication Systems), Mahtab Mirmohseni (5/6GIC, Institute for Communication Systems), Ahmed Elzanaty (5/6GIC, Institute for Communication Systems)</dc:creator>
    </item>
    <item>
      <title>Optimized Magnetic Resonance Fingerprinting Using Ziv-Zakai Bound</title>
      <link>https://arxiv.org/abs/2410.06624</link>
      <description>arXiv:2410.06624v2 Announce Type: replace-cross 
Abstract: Magnetic Resonance Fingerprinting (MRF) has emerged as a promising quantitative imaging technique within the field of Magnetic Resonance Imaging (MRI), offers comprehensive insights into tissue properties by simultaneously acquiring multiple tissue parameter maps in a single acquisition. Sequence optimization is crucial for improving the accuracy and efficiency of MRF. In this work, a novel framework for MRF sequence optimization is proposed based on the Ziv-Zakai bound (ZZB). Unlike the Cram\'er-Rao bound (CRB), which aims to enhance the quality of a single fingerprint signal with deterministic parameters, ZZB provides insights into evaluating the minimum mismatch probability for pairs of fingerprint signals within the specified parameter range in MRF. Specifically, the explicit ZZB is derived to establish a lower bound for the discrimination error in the fingerprint signal matching process within MRF. This bound illuminates the intrinsic limitations of MRF sequences, thereby fostering a deeper understanding of existing sequence performance. Subsequently, an optimal experiment design problem based on ZZB was formulated to ascertain the optimal scheme of acquisition parameters, maximizing discrimination power of MRF between different tissue types. Preliminary numerical experiments show that the optimized ZZB scheme outperforms both the conventional and CRB schemes in terms of the reconstruction accuracy of multiple parameter maps.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06624v2</guid>
      <category>eess.IV</category>
      <category>q-bio.QM</category>
      <category>stat.AP</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chaoguang Gong, Yue Hu, Peng Li, Lixian Zou, Congcong Liu, Yihang Zhou, Yanjie Zhu, Dong Liang, Haifeng Wang</dc:creator>
    </item>
  </channel>
</rss>
