<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.TO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.TO</link>
    <description>q-bio.TO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.TO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 02 Aug 2024 04:14:45 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 02 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Force and kinetics of fast and slow muscle myosin determined with a synthetic sarcomere-like nanomachine</title>
      <link>https://arxiv.org/abs/2408.00373</link>
      <description>arXiv:2408.00373v1 Announce Type: cross 
Abstract: Myosin II is the muscle molecular motor that works in two bipolar arrays in each thick filament of the striated (skeletal and cardiac) muscle, converting the chemical energy into steady force and shortening by cyclic ATP--driven interactions with the nearby actin filaments. Different isoforms of the myosin motor in the skeletal muscles account for the different functional requirements of the slow muscles (primarily responsible for the posture) and fast muscles (responsible for voluntary movements). To clarify the molecular basis of the differences, here the isoform--dependent mechanokinetic parameters underpinning the force of slow and fast muscles are defined with a unidimensional synthetic nanomachine powered by pure myosin isoforms from either slow or fast rabbit skeletal muscle. Data fitting with a stochastic model provides a self--consistent estimate of all the mechanokinetic properties of the motor ensemble including the motor force, the fraction of actin--attached motors and the rate of transition through the attachment--detachment cycle. The achievements in this paper set the stage for any future study on the emergent mechanokinetic properties of an ensemble of myosin molecules either engineered or purified from mutant animal models or human biopsies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.00373v1</guid>
      <category>cond-mat.stat-mech</category>
      <category>q-bio.BM</category>
      <category>q-bio.PE</category>
      <category>q-bio.TO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Valentina Buonfiglio, Irene Pertici, Matteo Marcello, Ilaria Morotti, Marco Caremani, Massimo Reconditi, Marco Linari, Duccio Fanelli, Vincenzo Lombardi, Pasquale Bianco</dc:creator>
    </item>
    <item>
      <title>TriDeNT: Triple Deep Network Training for Privileged Knowledge Distillation in Histopathology</title>
      <link>https://arxiv.org/abs/2312.02111</link>
      <description>arXiv:2312.02111v3 Announce Type: replace-cross 
Abstract: Computational pathology models rarely utilise data that will not be available for inference. This means most models cannot learn from highly informative data such as additional immunohistochemical (IHC) stains and spatial transcriptomics. We present TriDeNT, a novel self-supervised method for utilising privileged data that is not available during inference to improve performance. We demonstrate the efficacy of this method for a range of different paired data including immunohistochemistry, spatial transcriptomics and expert nuclei annotations. In all settings, TriDeNT outperforms other state-of-the-art methods in downstream tasks, with observed improvements of up to 101%. Furthermore, we provide qualitative and quantitative measurements of the features learned by these models and how they differ from baselines. TriDeNT offers a novel method to distil knowledge from scarce or costly data during training, to create significantly better models for routine inputs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.02111v3</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>q-bio.TO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Lucas Farndale, Robert Insall, Ke Yuan</dc:creator>
    </item>
  </channel>
</rss>
