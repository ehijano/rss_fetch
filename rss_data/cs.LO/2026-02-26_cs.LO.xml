<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.LO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.LO</link>
    <description>cs.LO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.LO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 26 Feb 2026 05:00:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Representation Theorems for Cumulative Propositional Dependence Logics</title>
      <link>https://arxiv.org/abs/2602.21360</link>
      <description>arXiv:2602.21360v1 Announce Type: new 
Abstract: This paper establishes and proves representation theorems for cumulative propositional dependence logic and for cumulative propositional logic with team semantics. Cumulative logics are famously given by System C. For propositional dependence logic, we show that System C entailments are exactly captured by cumulative models from Kraus, Lehmann and Magidor. On the other hand, we show that entailment in cumulative propositional logics with team semantics is exactly captured by cumulative and asymmetric models. For the latter, we also obtain equivalence with cumulative logics based on propositional logic with classical semantics. The proofs will be useful for proving representation theorems for other cumulative logics without negation and material implication.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21360v1</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Juha Kontinen, Arne Meier, Kai Sauerwald</dc:creator>
    </item>
    <item>
      <title>Slice and Explain: Logic-Based Explanations for Neural Networks through Domain Slicing</title>
      <link>https://arxiv.org/abs/2602.22115</link>
      <description>arXiv:2602.22115v1 Announce Type: new 
Abstract: Neural networks (NNs) are pervasive across various domains but often lack interpretability. To address the growing need for explanations, logic-based approaches have been proposed to explain predictions made by NNs, offering correctness guarantees. However, scalability remains a concern in these methods. This paper proposes an approach leveraging domain slicing to facilitate explanation generation for NNs. By reducing the complexity of logical constraints through slicing, we decrease explanation time by up to 40\% less time, as indicated through comparative experiments. Our findings highlight the efficacy of domain slicing in enhancing explanation efficiency for NNs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.22115v1</guid>
      <category>cs.LO</category>
      <category>cs.LG</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-032-15984-7_33</arxiv:DOI>
      <dc:creator>Luiz Fernando Paulino Queiroz, Carlos Henrique Leit\~ao Cavalcante, Thiago Alves Rocha</dc:creator>
    </item>
    <item>
      <title>Enhancing Framingham Cardiovascular Risk Score Transparency through Logic-Based XAI</title>
      <link>https://arxiv.org/abs/2602.22149</link>
      <description>arXiv:2602.22149v1 Announce Type: new 
Abstract: Cardiovascular disease (CVD) remains one of the leading global health challenges, accounting for more than 19 million deaths worldwide. To address this, several tools that aim to predict CVD risk and support clinical decision making have been developed. In particular, the Framingham Risk Score (FRS) is one of the most widely used and recommended worldwide. However, it does not explain why a patient was assigned to a particular risk category nor how it can be reduced. Due to this lack of transparency, we present a logical explainer for the FRS. Based on first-order logic and explainable artificial intelligence (XAI) fundaments, the explainer is capable of identifying a minimal set of patient attributes that are sufficient to explain a given risk classification. Our explainer also produces actionable scenarios that illustrate which modifiable variables would reduce a patient's risk category. We evaluated all possible input combinations of the FRS (over 22,000 samples) and tested them with our explainer, successfully identifying important risk factors and suggesting focused interventions for each case. The results may improve clinician trust and facilitate a wider implementation of CVD risk assessment by converting opaque scores into transparent and prescriptive insights, particularly in areas with restricted access to specialists.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.22149v1</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-032-15987-8_30</arxiv:DOI>
      <dc:creator>Emannuel L. de A. Bezerra, Luiz H. T. Viana, Vin\'icius P. Chagas, Diogo E. Rolim, Thiago Alves Rocha, Carlos H. L. Cavalcante</dc:creator>
    </item>
    <item>
      <title>Error-awareness Accelerates Active Automata Learning</title>
      <link>https://arxiv.org/abs/2602.21674</link>
      <description>arXiv:2602.21674v1 Announce Type: cross 
Abstract: Active automata learning (AAL) algorithms can learn a behavioral model of a system from interacting with it. The primary challenge remains scaling to larger models, in particular in the presence of many possible inputs to the system. Modern AAL algorithms fail to scale even if, in every state, most inputs lead to errors. In various challenging problems from the literature, these errors are observable, i.e., they emit a known error output. Motivated by these problems, we study learning these systems more efficiently. Further, we consider various degrees of knowledge about which inputs are non-error producing at which state. For each level of knowledge, we provide a matching adaptation of the state-of-the-art AAL algorithm L# to make the most of this domain knowledge. Our empirical evaluation demonstrates that the methods accelerate learning by orders of magnitude with strong but realistic domain knowledge to a single order of magnitude with limited domain knowledge.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21674v1</guid>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Loes Kruger, Sebastian Junges, Jurriaan Rot</dc:creator>
    </item>
    <item>
      <title>RustyDL: A Program Logic for Rust</title>
      <link>https://arxiv.org/abs/2602.22075</link>
      <description>arXiv:2602.22075v1 Announce Type: cross 
Abstract: Rust is a modern programming language that guarantees memory safety and the absence of data races with a strong type system. We present RustyDL, a program logic for Rust, as a foundation for an auto-interactive, deductive verification tool for Rust. RustyDL reasons about Rust programs directly on the source code level, in contrast to other tools that are all based on translation to an intermediate language. A source-level program logic for Rust is crucial for a human-in-the-loop (HIL) style of verification that permits proving highly complex functional properties. We discuss specific Rust challenges in designing a program logic and calculus for HIL-style verification and propose a solution in each case. We provide a proof-of-concept of our ideas in the form of a prototype of a Rust instance of the deductive verification tool KeY.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.22075v1</guid>
      <category>cs.PL</category>
      <category>cs.LO</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Drodt, Reiner H\"ahnle</dc:creator>
    </item>
    <item>
      <title>Sheaves as oracle computations</title>
      <link>https://arxiv.org/abs/2602.22135</link>
      <description>arXiv:2602.22135v1 Announce Type: cross 
Abstract: In type theory, an oracle may be specified abstractly by a predicate whose domain is the type of queries asked of the oracle, and whose proofs are the oracle answers. Such a specification induces an oracle modality that captures a computational intuition about oracles: at each step of reasoning we either know the result, or we ask the oracle a query and proceed upon receiving an answer. We characterize an oracle modality as the least one forcing the given predicate. We establish an adjoint retraction between modalities and propositional containers, from which it follows that every modality is an oracle modality. The left adjoint maps sums to suprema, which makes suprema of modalities easy to compute when they are given in terms of oracle modalities. We also study sheaves for oracle modalities. We describe sheafification in terms of a quotient-inductive type of computation trees, and describe sheaves as algebras for the corresponding monad. We also introduce equifoliate trees, an intensional notion of oracle computation given by a (non-propositional) container. Equifoliate trees descend to sheaves, and lift from sheaves in case the container is projective. As an application, we give a concrete description of all Lawvere-Tierney topologies in a realizability topos, closely related to a game-theoretic characterization by Takayuki Kihara.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.22135v1</guid>
      <category>math.LO</category>
      <category>cs.LO</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Danel Ahman, Andrej Bauer</dc:creator>
    </item>
    <item>
      <title>Univalent Enriched Categories and the Enriched Rezk Completion</title>
      <link>https://arxiv.org/abs/2401.11752</link>
      <description>arXiv:2401.11752v5 Announce Type: replace 
Abstract: Enriched categories are categories whose sets of morphisms are enriched with extra structure. Such categories play a prominent role in the study of higher categories, homotopy theory, and the semantics of programming languages. In this paper, we study univalent enriched categories. We prove that all essentially surjective and fully faithful functors between univalent enriched categories are equivalences, and we show that every enriched category admits a Rezk completion. Finally, we use the Rezk completion for enriched categories to construct univalent enriched Kleisli categories.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.11752v5</guid>
      <category>cs.LO</category>
      <category>math.CT</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Niels van der Weide</dc:creator>
    </item>
    <item>
      <title>Strong Normalization for the Safe Fragment of a Minimal Rewrite Calculus: A Triple-Lexicographic Proof and a Conjecture on Full-Termination Limits for Pure Recursive Calculi (PRC)</title>
      <link>https://arxiv.org/abs/2512.00081</link>
      <description>arXiv:2512.00081v5 Announce Type: replace 
Abstract: We study KO7, a minimal operator-only rewrite calculus in the Pure Recursive Calculus (PRC) framing: no binders, no external memory, no imported axioms, and an unrestricted step-duplicating recursor. KO7 is used as a calibrated witness system, not as the whole PRC class. It has seven constructors and eight rules. The rec-succ rule duplicates its step argument, creating the central termination stressor and blocking strict decrease for additive and related internal ranking families.
  We isolate a guarded fragment, SafeStep, with per-rule guards (delta-flag, kappa^M, and disequality). For SafeStep we prove strong normalization via a computable triple-lex measure (delta-phase bit, Dershowitz-Manna multiset component kappa^M, and tie-break rank tau). The development includes a certified normalizer (totality and soundness), a formal Newman-style confluence pipeline with fully discharged local-join hypotheses, and unique normal forms for the safe fragment. For the unrestricted full relation Step, we provide an explicit non-local-join witness at eqW void void, so full confluence is not claimed.
  We also machine-check impossibility barriers across twelve strategy families (including additive, polynomial, weight-based, and precedence-based methods), with additional meta-theoretical boundary observations. These results motivate a scoped conjectural boundary: for PRCs, no internally definable method currently known to us proves full-calculus termination under our explicit internal-method definition. The formal Lean 4 development is sorry/admit/unsafe-free (~6,000 LOC) and available at https://github.com/MosesRahnama/OperatorKO7.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00081v5</guid>
      <category>cs.LO</category>
      <category>math.LO</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Moses Rahnama</dc:creator>
    </item>
    <item>
      <title>Rethinking Clause Management for CDCL SAT Solvers</title>
      <link>https://arxiv.org/abs/2602.20829</link>
      <description>arXiv:2602.20829v2 Announce Type: replace 
Abstract: Boolean Satisfiability (SAT) solving underpins a wide range of applications in Electronic Design Automation (EDA), particularly formal verification. However, this paper observes that the mainstream clause reduction heuristic in modern SAT solvers becomes ineffective in the critical domain of complex arithmetic circuit verification, such as multipliers. On these instances, the dominant Literal Block Distance (LBD) metric for measuring clause quality degrades into a simple value of clause length, without any perception of dynamic clause usage during solving. To address this issue, a novel clause reduction mechanism is proposed, which is entirely independent of LBD. Its core idea is to decouple and handle separately the two most fundamental characteristics of learnt clauses--inherent lineage and dynamic usage patterns--thereby avoiding the efficiency degradation caused by inappropriately mixing these properties. Experiments show that our method consistently improves mainstream solvers and achieves speedups of up to 5.74x on complex arithmetic circuit problems, while maintaining comparable performance on general-purpose benchmarks. These results challenge the prevailing LBD-centric clause quality metric for clause management.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.20829v2</guid>
      <category>cs.LO</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yalun Cai, Xindi Zhang, Zhengyuan Shi, Mengxia Tao, Qiang Xu</dc:creator>
    </item>
    <item>
      <title>Premise Selection for a Lean Hammer</title>
      <link>https://arxiv.org/abs/2506.07477</link>
      <description>arXiv:2506.07477v2 Announce Type: replace-cross 
Abstract: Neural methods are transforming automated reasoning for proof assistants, yet integrating these advances into practical verification workflows remains challenging. A hammer is a tool that integrates premise selection, translation to external automatic theorem provers, and proof reconstruction into one overarching tool to automate tedious reasoning steps. We present LeanPremise, a novel neural premise selection system, and we combine it with existing translation and proof reconstruction components to create LeanHammer, the first end-to-end domain general hammer for the Lean proof assistant. Unlike existing Lean premise selectors, LeanPremise is specifically trained for use with a hammer in dependent type theory. It also dynamically adapts to user-specific contexts, enabling it to effectively recommend premises from libraries outside LeanPremise's training data as well as lemmas defined by the user locally. With comprehensive evaluations, we show that LeanPremise enables LeanHammer to solve 21% more goals than existing premise selectors and generalizes well to diverse domains. Our work helps bridge the gap between neural retrieval and symbolic reasoning, making formal verification more accessible to researchers and practitioners.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.07477v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Zhu, Joshua Clune, Jeremy Avigad, Albert Qiaochu Jiang, Sean Welleck</dc:creator>
    </item>
    <item>
      <title>Axis Decomposition for ODRL: Resolving Dimensional Ambiguity in Policy Constraints through Interval Semantics</title>
      <link>https://arxiv.org/abs/2602.19878</link>
      <description>arXiv:2602.19878v2 Announce Type: replace-cross 
Abstract: Every ODRL 2.2 constraint compares a single scalar value: (leftOperand, operator, rightOperand). Five of ODRL's left operands, however, denote multi-dimensional quantities--image dimensions, canvas positions, geographic coordinates--whose specification text explicitly references multiple axes. For these operands, a single scalar constraint admits one interpretation per axis, making policy evaluation non-deterministic.
  We classify ODRL's left operands by value-domain structure (scalar, dimensional, concept-valued), grounded in the ODRL 2.2 specification text, and show that dimensional ambiguity is intrinsic to the constraint syntax. We present an axis-decomposition framework that refines each dimensional operand into axis-specific scalar operands and prove four properties: deterministic interpretation, AABB completeness, projection soundness, and conservative extension.
  Conflict detection operates in two layers: per-axis verdicts are always decidable; box-level verdicts compose through Strong Kleene conjunction into a three-valued logic (Conflict, Compatible, Unknown). For ODRL's disjunctive (odrl:or) and exclusive-or (odrl:xone) logical constraints, where per-axis decomposition does not apply, the framework encodes coupled multi-axis conjectures directly.
  We instantiate the framework as the ODRL Spatial Axis Profile--15 axis-specific left operands for the five affected base terms--and evaluate it on 117 benchmark problems spanning nine categories across both TPTP FOF (Vampire) and SMT-LIB (Z3) encodings, achieving full concordance between provers. Benchmark scenarios are inspired by constraints arising in cultural heritage dataspaces such as Datenraum Kultur. All meta-theorems are mechanically verified in Isabelle/HOL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.19878v2</guid>
      <category>cs.CL</category>
      <category>cs.LO</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daham Mustafa, Diego Collarana, Yixin Peng, Rafiqul Haque, Christoph Lange-Bever, Christoph Quix, Stephan Decker</dc:creator>
    </item>
  </channel>
</rss>
