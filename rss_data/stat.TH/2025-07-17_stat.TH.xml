<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.TH</link>
    <description>stat.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 18 Jul 2025 01:36:17 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Adaptive estimation in regression models for weakly dependent data and explanatory variable with known density</title>
      <link>https://arxiv.org/abs/2507.11725</link>
      <description>arXiv:2507.11725v1 Announce Type: new 
Abstract: This article is dedicated to the estimation of the regression function when the explanatory variable is a weakly dependent process whose correlation coefficient exhibits exponential decay and has a known bounded density function. The accuracy of the estimation is measured using pointwise risk. A data-driven procedure is proposed using kernel estimation with bandwidth selected via the Goldenshluger-Lepski approach. We demonstrate that the resulting estimator satisfies an oracle-type inequality and it is also shown to be adaptive over H\"older classes. Additionally, unsupervised statistical learning techniques are described and applied to calibrate the method, and some simulations are provided to illustrate the performance of the method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.11725v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Karine Bertin, Lisandro Fermin, Miguel Padrino</dc:creator>
    </item>
    <item>
      <title>Enhancing Signal Proportion Estimation Through Leveraging Arbitrary Covariance Structures</title>
      <link>https://arxiv.org/abs/2507.11922</link>
      <description>arXiv:2507.11922v1 Announce Type: new 
Abstract: Accurately estimating the proportion of true signals among a large number of variables is crucial for enhancing the precision and reliability of scientific research. Traditional signal proportion estimators often assume independence among variables and specific signal sparsity conditions, limiting their applicability in real-world scenarios where such assumptions may not hold. This paper introduces a novel signal proportion estimator that leverages arbitrary covariance dependence information among variables, thereby improving performance across a wide range of sparsity levels and dependence structures. Building on previous work that provides lower confidence bounds for signal proportions, we extend this approach by incorporating the principal factor approximation procedure to account for variable dependence. Our theoretical insights offer a deeper understanding of how signal sparsity, signal intensity, and covariance dependence interact. By comparing the conditions for estimation consistency before and after dependence adjustment, we highlight the advantages of integrating dependence information across different contexts. This theoretical foundation not only validates the effectiveness of the new estimator but also guides its practical application, ensuring reliable use in diverse scenarios. Through extensive simulations, we demonstrate that our method outperforms state-of-the-art estimators in both estimation accuracy and the detection of weaker signals that might otherwise go undetected.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.11922v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jingtian Bai, Xinge Jessie Jeng</dc:creator>
    </item>
    <item>
      <title>Minmax Exclusivity Classes for Power-Type Loss Functions</title>
      <link>https://arxiv.org/abs/2507.12447</link>
      <description>arXiv:2507.12447v1 Announce Type: new 
Abstract: In statistical decision theory, the choice of loss function fundamentally shapes which estimators qualify as optimal. This paper introduces and develops the general concept of exclusivity classes of loss functions: subsets of loss functions such that no estimator can be optimal (according to a specified notion) for losses lying in different classes. We focus on the case of minmax optimality and define minmax exclusivity classes, demonstrating that the classical family of power-type loss functions $L_p(\theta,a) = |\theta - a|^p$ forms such a class. Under standard regularity and smoothness assumptions, we prove that no estimator can be simultaneously minmax for losses belonging to two distinct $L_p$ classes. This result is obtained via a perturbation argument relying on differentiability of risk functionals and the conic structure of loss spaces. We formalize the framework of exclusivity partitions, distinguishing trivial and realizable structures, and analyze their algebraic properties. These results open a broader inquiry into the geometry of estimator optimality, and the potential classification of the loss function space via exclusivity principles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12447v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stanis{\l}aw M. S. Halkiewicz</dc:creator>
    </item>
    <item>
      <title>Inference on Optimal Policy Values and Other Irregular Functionals via Smoothing</title>
      <link>https://arxiv.org/abs/2507.11780</link>
      <description>arXiv:2507.11780v1 Announce Type: cross 
Abstract: Constructing confidence intervals for the value of an optimal treatment policy is an important problem in causal inference. Insight into the optimal policy value can guide the development of reward-maximizing, individualized treatment regimes. However, because the functional that defines the optimal value is non-differentiable, standard semi-parametric approaches for performing inference fail to be directly applicable. Existing approaches for handling this non-differentiability fall roughly into two camps. In one camp are estimators based on constructing smooth approximations of the optimal value. These approaches are computationally lightweight, but typically place unrealistic parametric assumptions on outcome regressions. In another camp are approaches that directly de-bias the non-smooth objective. These approaches don't place parametric assumptions on nuisance functions, but they either require the computation of intractably-many nuisance estimates, assume unrealistic $L^\infty$ nuisance convergence rates, or make strong margin assumptions that prohibit non-response to a treatment. In this paper, we revisit the problem of constructing smooth approximations of non-differentiable functionals. By carefully controlling first-order bias and second-order remainders, we show that a softmax smoothing-based estimator can be used to estimate parameters that are specified as a maximum of scores involving nuisance components. In particular, this includes the value of the optimal treatment policy as a special case. Our estimator obtains $\sqrt{n}$ convergence rates, avoids parametric restrictions/unrealistic margin assumptions, and is often statistically efficient.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.11780v1</guid>
      <category>econ.EM</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Justin Whitehouse, Morgane Austern, Vasilis Syrgkanis</dc:creator>
    </item>
    <item>
      <title>A Relativity-Based Framework for Statistical Testing Guided by the Independence of Ancillary Statistics: Methodology and Nonparametric Illustrations</title>
      <link>https://arxiv.org/abs/2507.11816</link>
      <description>arXiv:2507.11816v1 Announce Type: cross 
Abstract: This paper introduces a decision-theoretic framework for constructing and evaluating test statistics based on their relationship with ancillary statistics-quantities whose distributions remain fixed under the null and alternative hypotheses. Rather than focusing solely on maximizing discriminatory power, the proposed approach emphasizes reducing dependence between a test statistic and relevant ancillary structures. We show that minimizing such dependence can yield most powerful (MP) procedures. A Basu-type independence result is established, and we demonstrate that certain MP statistics also characterize the underlying data distribution. The methodology is illustrated through modifications of classical nonparametric tests, including the Shapiro-Wilk, Anderson-Darling, and Kolmogorov-Smirnov tests, as well as a test for the center of symmetry. Simulation studies highlight the power and robustness of the proposed procedures. The framework is computationally simple and offers a principled strategy for improving statistical testing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.11816v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Albert Vexler, Douglas Landsittel</dc:creator>
    </item>
    <item>
      <title>Choosing the Better Bandit Algorithm under Data Sharing: When Do A/B Experiments Work?</title>
      <link>https://arxiv.org/abs/2507.11891</link>
      <description>arXiv:2507.11891v1 Announce Type: cross 
Abstract: We study A/B experiments that are designed to compare the performance of two recommendation algorithms. Prior work has shown that the standard difference-in-means estimator is biased in estimating the global treatment effect (GTE) due to a particular form of interference between experimental units. Specifically, units under the treatment and control algorithms contribute to a shared pool of data that subsequently train both algorithms, resulting in interference between the two groups. The bias arising from this type of data sharing is known as "symbiosis bias". In this paper, we highlight that, for decision-making purposes, the sign of the GTE often matters more than its precise magnitude when selecting the better algorithm. We formalize this insight under a multi-armed bandit framework and theoretically characterize when the sign of the expected GTE estimate under data sharing aligns with or contradicts the sign of the true GTE. Our analysis identifies the level of exploration versus exploitation as a key determinant of how symbiosis bias impacts algorithm selection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.11891v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuangning Li, Chonghuan Wang, Jingyan Wang</dc:creator>
    </item>
    <item>
      <title>On the optimality of coin-betting for mean estimation</title>
      <link>https://arxiv.org/abs/2412.02640</link>
      <description>arXiv:2412.02640v3 Announce Type: replace 
Abstract: Confidence sequences are sequences of confidence sets that adapt to incoming data while maintaining validity. Recent advances have introduced an algorithmic formulation for constructing some of the tightest confidence sequences for the mean of bounded real random variables. These approaches use a coin-betting framework, where a player sequentially bets on differences between potential mean values and observed data. This work discusses the optimality of such coin-betting formulation among algorithmic frameworks building on e-variables methods to test and estimate the mean of bounded random variables.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02640v3</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eugenio Clerico</dc:creator>
    </item>
    <item>
      <title>On the Statistical Properties of Generative Adversarial Models for Low Intrinsic Data Dimension</title>
      <link>https://arxiv.org/abs/2401.15801</link>
      <description>arXiv:2401.15801v2 Announce Type: replace-cross 
Abstract: Despite the remarkable empirical successes of Generative Adversarial Networks (GANs), the theoretical guarantees for their statistical accuracy remain rather pessimistic. In particular, the data distributions on which GANs are applied, such as natural images, are often hypothesized to have an intrinsic low-dimensional structure in a typically high-dimensional feature space, but this is often not reflected in the derived rates in the state-of-the-art analyses. In this paper, we attempt to bridge the gap between the theory and practice of GANs and their bidirectional variant, Bi-directional GANs (BiGANs), by deriving statistical guarantees on the estimated densities in terms of the intrinsic dimension of the data and the latent space. We analytically show that if one has access to $n$ samples from the unknown target distribution and the network architectures are properly chosen, the expected Wasserstein-1 distance of the estimates from the target scales as $O\left( n^{-1/d_\mu } \right)$ for GANs and $\tilde{O}\left( n^{-1/(d_\mu+\ell)} \right)$ for BiGANs, where $d_\mu$ and $\ell$ are the upper Wasserstein-1 dimension of the data-distribution and latent-space dimension, respectively. The theoretical analyses not only suggest that these methods successfully avoid the curse of dimensionality, in the sense that the exponent of $n$ in the error rates does not depend on the data dimension but also serve to bridge the gap between the theoretical analyses of GANs and the known sharp rates from optimal transport literature. Additionally, we demonstrate that GANs can effectively achieve the minimax optimal rate even for non-smooth underlying distributions, with the use of interpolating generator networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.15801v2</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Saptarshi Chakraborty, Peter L. Bartlett</dc:creator>
    </item>
    <item>
      <title>Optimization via Strategic Law of Large Numbers</title>
      <link>https://arxiv.org/abs/2412.05604</link>
      <description>arXiv:2412.05604v2 Announce Type: replace-cross 
Abstract: This paper proposes a unified framework for the global optimization of a continuous function in a bounded rectangular domain. Specifically, we show that: (1) under the optimal strategy for a two-armed decision model, the sample mean converges to a global optimizer under the Strategic Law of Large Numbers, and (2) a sign-based strategy built upon the solution of a parabolic PDE is asymptotically optimal. Motivated by this result, we propose a class of {\bf S}trategic {\bf M}onte {\bf C}arlo {\bf O}ptimization (SMCO) algorithms, which uses a simple strategy that makes coordinate-wise two-armed decisions based on the signs of the partial gradient of the original function being optimized over (without the need of solving PDEs). While this simple strategy is not generally optimal, we show that it is sufficient for our SMCO algorithm to converge to local optimizer(s) from a single starting point, and to global optimizers under a growing set of starting points. Numerical studies demonstrate the suitability of our SMCO algorithms for global optimization, and illustrate the promise of our theoretical framework and practical approach. For a wide range of test functions with challenging optimization landscapes (including ReLU neural networks with square and hinge loss), our SMCO algorithms converge to the global maximum accurately and robustly, using only a small set of starting points (at most 100 for dimensions up to 1000) and a small maximum number of iterations (200). In fact, our algorithms outperform many state-of-the-art global optimizers, as well as local algorithms augmented with the same set of starting points as ours.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05604v2</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaohong Chen, Zengjing Chen, Wayne Yuan Gao, Xiaodong Yan, Guodong Zhang</dc:creator>
    </item>
    <item>
      <title>An Improved Satterthwaite Effective Degrees of Freedom Correction for Weighted Syntheses of Variance</title>
      <link>https://arxiv.org/abs/2503.22080</link>
      <description>arXiv:2503.22080v5 Announce Type: replace-cross 
Abstract: This article presents an improved approximation for the effective degrees of freedom in the Satterthwaite (1941, 1946) method which estimates the distribution of a weighted combination of variance components The standard Satterthwaite approximation assumes a scaled chisquare distribution for the composite variance estimator but is known to be biased downward when component degrees of freedom are small. Building on recent work by von Davier (2025), we propose an adjusted estimator that corrects this bias by modifying both the numerator and denominator of the traditional formula. The new approximation incorporates a weighted average of component degrees of freedom and a scaling factor that ensures consistency as the number of components or their degrees of freedom increases. We demonstrate the utility of this adjustment in practical settings, including Rubin's (1987) total variance estimation in multiple imputations, where weighted variance combinations are common. The proposed estimator generalizes and further improves von Davier's (2025) unweighted case and more accurately approximates synthetic variance estimators with arbitrary weights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.22080v5</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Matthias von Davier</dc:creator>
    </item>
    <item>
      <title>Breaking a Logarithmic Barrier in the Stopping Time Convergence Rate of Stochastic First-order Methods</title>
      <link>https://arxiv.org/abs/2506.23335</link>
      <description>arXiv:2506.23335v2 Announce Type: replace-cross 
Abstract: This work provides a novel convergence analysis for stochastic optimization in terms of stopping times, addressing the practical reality that algorithms are often terminated adaptively based on observed progress. Unlike prior approaches, our analysis: 1. Directly characterizes convergence in terms of stopping times adapted to the underlying stochastic process. 2. Breaks a logarithmic barrier in existing results. Key to our results is the development of a lemma to control the large deviation property of almost super-martingales. This lemma might be of broader interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23335v2</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yasong Feng, Yifan Jiang, Tianyu Wang, Zhiliang Ying</dc:creator>
    </item>
  </channel>
</rss>
