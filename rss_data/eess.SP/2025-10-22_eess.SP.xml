<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>eess.SP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/eess.SP</link>
    <description>eess.SP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/eess.SP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 22 Oct 2025 04:00:03 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Machine Learning-Based Performance Evaluation of a Solar-Powered Hydrogen Fuel Cell Hybrid in a Radio-Controlled Electric Vehicle</title>
      <link>https://arxiv.org/abs/2510.17808</link>
      <description>arXiv:2510.17808v1 Announce Type: new 
Abstract: This paper presents an experimental investigation and performance evaluation of a hybrid electric radio-controlled car powered by a Nickel-Metal Hydride battery combined with a renewable Proton Exchange Membrane Fuel Cell system. The study evaluates the performance of the system under various load-carrying scenarios and varying environmental conditions, simulating real-world operating conditions including throttle operation. In order to build a predictive model, gather operational insights, and detect anomalies, data-driven analyses using signal processing and modern machine learning techniques were employed. Specifically, machine learning techniques were used to distinguish throttle levels with high precision based on the operational data. Anomaly and change point detection methods enhanced voltage stability, resulting in fewer critical faults in the hybrid system compared to battery-only operation. Temporal Convolutional Networks were effectively employed to predict voltage behavior, demonstrating potential for use in planning the locations of fueling or charging stations. Moreover, integration with a solar-powered electrolyzer confirmed the system's potential for off-grid, renewable hydrogen use. The results indicate that integrating a Proton Exchange Membrane Fuel Cell with Nickel-Metal Hydride batteries significantly improves electrical performance and reliability for small electric vehicles, and these findings can be a potential baseline for scaling up to larger vehicles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17808v1</guid>
      <category>eess.SP</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amirhesam Aghanouri, Mohamed Sabry, Joshua Cherian Varughese, Cristina Olaverri-Monreal</dc:creator>
    </item>
    <item>
      <title>In-Process Monitoring of Gear Power Honing Using Vibration Signal Analysis and Machine Learning</title>
      <link>https://arxiv.org/abs/2510.17809</link>
      <description>arXiv:2510.17809v1 Announce Type: new 
Abstract: In modern gear manufacturing, stringent Noise, Vibration, and Harshness (NVH) requirements demand high-precision finishing operations such as power honing. Conventional quality control strategies rely on post-process inspections and Statistical Process Control (SPC), which fail to capture transient machining anomalies and cannot ensure real-time defect detection. This study proposes a novel, data-driven framework for in-process monitoring of gear power honing using vibration signal analysis and machine learning. Our proposed methodology involves continuous data acquisition via accelerometers, followed by time-frequency signal analysis. We investigate and compare the efficacy of three subspace learning methods for features extraction: (1) Principal Component Analysis (PCA) for dimensionality reduction; (2) a two-stage framework combining PCA with Linear Discriminant Analysis (LDA) for enhanced class separation; and (3) Uncorrelated Multilinear Discriminant Analysis with Regularization (R-UMLDA), adapted for tensor data, which enforces feature decorrelation and includes regularization for small sample sizes. These extracted features are then fed into a Support Vector Machine (SVM) classifier to predict four distinct gear quality categories, established through rigorous geometrical inspections and test bench results of assembled gearboxes. The models are trained and validated on an experimental dataset collected in an industrial context during gear power-honing operations, with gears classified into four different quality categories. The proposed framework achieves high classification accuracy (up to 100%) in an industrial setting. The approach offers interpretable spectral features that correlate with process dynamics, enabling practical integration into real-time monitoring and predictive maintenance systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17809v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Massimo Capurso, Luciano Afferrante</dc:creator>
    </item>
    <item>
      <title>Exploring Complexity Changes in Diseased ECG Signals for Enhanced Classification</title>
      <link>https://arxiv.org/abs/2510.17810</link>
      <description>arXiv:2510.17810v1 Announce Type: new 
Abstract: The complex dynamics of the heart are reflected in its electrical activity, captured through electrocardiograms (ECGs). In this study we use nonlinear time series analysis to understand how ECG complexity varies with cardiac pathology. Using the large PTB-XL dataset, we extracted nonlinear measures from lead II ECGs, and cross-channel metrics (leads II, V2, AVL) using Spearman correlations and mutual information. Significant differences between diseased and healthy individuals were found in almost all measures between healthy and diseased classes, and between 5 diagnostic superclasses ($p&lt;.001$). Moreover, incorporating these complexity quantifiers into machine learning models substantially improved classification accuracy measured using area under the ROC curve (AUC) from 0.86 (baseline) to 0.87 (nonlinear measures) and 0.90 (including cross-time series metrics).</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17810v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <category>nlin.CD</category>
      <category>physics.data-an</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Camilo Quiceno Quintero, Sandip Varkey George</dc:creator>
    </item>
    <item>
      <title>Channel Modeling of Satellite-to-Underwater Laser Communication Links: An Analytical-Monte Carlo Hybrid Approach</title>
      <link>https://arxiv.org/abs/2510.17811</link>
      <description>arXiv:2510.17811v1 Announce Type: new 
Abstract: Channel modeling for satellite-to-underwater laser communication (StULC) links remains challenging due to long distances and the diversity of the channel constituents. The StULC channel is typically segmented into three isolated channels: the atmospheric channel, the air-water interface channel, and the underwater channel. Previous studies involving StULC channel modeling either focused on separated channels or neglected the combined effects of particles and turbulence on laser propagation. In this paper, we established a comprehensive StULC channel model by an analytical-Monte Carlo hybrid approach, taking into account the effects of both particles and turbulence. We first obtained the intensity distribution of the transmitted laser beam after passing through the turbulent atmosphere based on the extended Huygens-Fresnel principle. Then we derived a closed-form probability density function of the photon propagating direction after passing through the air-water interface, which greatly simplified the modeling of StULC links. At last, we employed a Monte Carlo method to model the underwater links and obtained the power distribution at the receiving plane. Based on the proposed StULC channel model, we analyzed the bit error rate and the outage probability under different environmental conditions. Numerical results demonstrated that, the influence of underwater particle concentration on the communication performance is much pronounced than those of both the atmospheric turbulence and the underwater turbulence. Notably, increasing the wind speed at the air-water interface does not significantly worsen the communication performance of the StULC links.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17811v1</guid>
      <category>eess.SP</category>
      <category>physics.ao-ph</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhixing Wang, Renzhi Yuan, Haifeng Yao, Chuang Yang, Mugen Peng</dc:creator>
    </item>
    <item>
      <title>Cross-Domain Multi-Person Human Activity Recognition via Near-Field Wi-Fi Sensing</title>
      <link>https://arxiv.org/abs/2510.17816</link>
      <description>arXiv:2510.17816v1 Announce Type: new 
Abstract: Wi-Fi-based human activity recognition (HAR) provides substantial convenience and has emerged as a thriving research field, yet the coarse spatial resolution inherent to Wi-Fi significantly hinders its ability to distinguish multiple subjects. By exploiting the near-field domination effect, establishing a dedicated sensing link for each subject through their personal Wi-Fi device offers a promising solution for multi-person HAR under native traffic. However, due to the subject-specific characteristics and irregular patterns of near-field signals, HAR neural network models require fine-tuning (FT) for cross-domain adaptation, which becomes particularly challenging with certain categories unavailable. In this paper, we propose WiAnchor, a novel training framework for efficient cross-domain adaptation in the presence of incomplete activity categories. This framework processes Wi-Fi signals embedded with irregular time information in three steps: during pre-training, we enlarge inter-class feature margins to enhance the separability of activities; in the FT stage, we innovate an anchor matching mechanism for cross-domain adaptation, filtering subject-specific interference informed by incomplete activity categories, rather than attempting to extract complete features from them; finally, the recognition of input samples is further improved based on their feature-level similarity with anchors. We construct a comprehensive dataset to thoroughly evaluate WiAnchor, achieving over 90% cross-domain accuracy with absent activity categories.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17816v1</guid>
      <category>eess.SP</category>
      <category>cs.CV</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xin Li, Jingzhi Hu, Yinghui He, Hongbo Wang, Jin Gan, Jun Luo</dc:creator>
    </item>
    <item>
      <title>Single-Snapshot Gridless 2D-DoA Estimation for UCAs: A Joint Optimization Approach</title>
      <link>https://arxiv.org/abs/2510.17818</link>
      <description>arXiv:2510.17818v1 Announce Type: new 
Abstract: This paper tackles the challenging problem of gridless two-dimensional (2D) direction-of-arrival (DOA) estimation for a uniform circular array (UCA) from a single snapshot of data. Conventional gridless methods often fail in this scenario due to prohibitive computational costs or a lack of robustness. We propose a novel framework that overcomes these limitations by jointly estimating a manifold transformation matrix and the source azimuth-elevation pairs within a single, unified optimization problem. This problem is solved efficiently using an inexact Augmented Lagrangian Method (iALM), which completely circumvents the need for semidefinite programming. By unifying the objectives of data fidelity and transformation robustness, our approach is uniquely suited for the demanding single-snapshot case. Simulation results confirm that the proposed iALM framework provides robust and high-resolution, gridless 2D-DOA estimates, establishing its efficacy for challenging array signal processing applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17818v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Salar Nouri</dc:creator>
    </item>
    <item>
      <title>CLARAE: Clarity Preserving Reconstruction AutoEncoder for Denoising and Rhythm Classification of Intracardiac Electrograms</title>
      <link>https://arxiv.org/abs/2510.17821</link>
      <description>arXiv:2510.17821v1 Announce Type: new 
Abstract: Intracavitary atrial electrograms (EGMs) provide high-resolution insights into cardiac electrophysiology but are often contaminated by noise and remain high-dimensional, limiting real-time analysis. We introduce CLARAE (CLArity-preserving Reconstruction AutoEncoder), a one-dimensional encoder--decoder designed for atrial EGMs, which achieves both high-fidelity reconstruction and a compact 64-dimensional latent representation. CLARAE is designed to preserve waveform morphology, mitigate reconstruction artifacts, and produce interpretable embeddings through three principles: downsampling with pooling, a hybrid interpolation--convolution upsampling path, and a bounded latent space.
  We evaluated CLARAE on 495,731 EGM segments (unipolar and bipolar) from 29 patients across three rhythm types (AF, SR300, SR600). Performance was benchmarked against six state-of-the-art autoencoders using reconstruction metrics, rhythm classification, and robustness across signal-to-noise ratios from -5 to 15 dB. In downstream rhythm classification, CLARAE achieved F1-scores above 0.97 for all rhythm types, and its latent space showed clear clustering by rhythm. In denoising tasks, it consistently ranked among the top performers for both unipolar and bipolar signals.
  In order to promote reproducibility and enhance accessibility, we offer an interactive web-based application. This platform enables users to explore pre-trained CLARAE models, visualize the reconstructions, and compute metrics in real time. Overall, CLARAE combines robust denoising with compact, discriminative representations, offering a practical foundation for clinical workflows such as rhythm discrimination, signal quality assessment, and real-time mapping.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17821v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Long Lin, Pablo Peiro-Corbacho, Pablo \'Avila, Alejandro Carta-Bergaz, \'Angel Arenal, Gonzalo R. R\'ios-Mu\~noz, Carlos Sevilla-Salcedo</dc:creator>
    </item>
    <item>
      <title>Covariance Matrix Construction with Preprocessing-Based Spatial Sampling for Robust Adaptive Beamforming</title>
      <link>https://arxiv.org/abs/2510.17823</link>
      <description>arXiv:2510.17823v1 Announce Type: new 
Abstract: This work proposes an efficient, robust adaptive beamforming technique to deal with steering vector (SV) estimation mismatches and data covariance matrix reconstruction problems. In particular, the direction-of-arrival(DoA) of interfering sources is estimated with available snapshots in which the angular sectors of the interfering signals are computed adaptively. Then, we utilize the well-known general linear combination algorithm to reconstruct the interference-plus-noise covariance (IPNC) matrix using preprocessing-based spatial sampling (PPBSS). We demonstrate that the preprocessing matrix can be replaced by the sample covariance matrix (SCM) in the shrinkage method. A power spectrum sampling strategy is then devised based on a preprocessing matrix computed with the estimated angular sectors' information. Moreover, the covariance matrix for the signal is formed for the angular sector of the signal-of-interest (SOI), which allows for calculating an SV for the SOI using the power method. An analysis of the array beampattern in the proposed PPBSS technique is carried out, and a study of the computational cost of competing approaches is conducted. Simulation results show the proposed method's effectiveness compared to existing approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17823v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Saeed Mohammadzadeh, Rodrigo C. de Lamare, Yuriy Zakharov</dc:creator>
    </item>
    <item>
      <title>Carbon-Aware Orchestration of Integrated Satellite Aerial Terrestrial Networks via Digital Twin</title>
      <link>https://arxiv.org/abs/2510.17825</link>
      <description>arXiv:2510.17825v1 Announce Type: new 
Abstract: Integrated Satellite Aerial Terrestrial Networks (ISATNs) are envisioned as key enablers of 6G, providing global connectivity for applications such as autonomous transportation, Industrial IoT, and disaster response. Their large-scale deployment, however, risks unsustainable energy use and carbon emissions. This work advances prior energy-aware studies by proposing a carbon-aware orchestration framework for ISATNs that leverages Digital Twin (DT) technology. The framework adopts grams of CO$_2$-equivalent per bit (gCO$_2$/bit) as a primary sustainability metric and implements a multi timescale Plan Do Check Act (PDCA) loop that combines day-ahead forecasting with real-time adaptive optimization. ISATN-specific control knobs, including carbon-aware handovers, UAV duty cycling, and renewable-aware edge placement, are exploited to reduce emissions. Simulation results with real carbon intensity data show up to 29\% lower gCO$_2$/bit than QoS-only orchestration, while improving renewable utilization and resilience under adverse events.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17825v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Shumaila Javaid, Nasir Saeed</dc:creator>
    </item>
    <item>
      <title>Synthetic EEG Generation using Diffusion Models for Motor Imagery Tasks</title>
      <link>https://arxiv.org/abs/2510.17832</link>
      <description>arXiv:2510.17832v1 Announce Type: new 
Abstract: Electroencephalography (EEG) is a widely used, non-invasive method for capturing brain activity, and is particularly relevant for applications in Brain-Computer Interfaces (BCI). However, collecting high-quality EEG data remains a major challenge due to sensor costs, acquisition time, and inter-subject variability. To address these limitations, this study proposes a methodology for generating synthetic EEG signals associated with motor imagery brain tasks using Diffusion Probabilistic Models (DDPM). The approach involves preprocessing real EEG data, training a diffusion model to reconstruct EEG channels from noise, and evaluating the quality of the generated signals through both signal-level and task-level metrics. For validation, we employed classifiers such as K-Nearest Neighbors (KNN), Convolutional Neural Networks (CNN), and U-Net to compare the performance of synthetic data against real data in classification tasks. The generated data achieved classification accuracies above 95%, with low mean squared error and high correlation with real signals.
  Our results demonstrate that synthetic EEG signals produced by diffusion models can effectively complement datasets, improving classification performance in EEG-based BCIs and addressing data scarcity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17832v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Henrique de Lima Alexandre, Clodoaldo Aparecido de Moraes Lima</dc:creator>
    </item>
    <item>
      <title>Two Phases Leakage Detection Strategy Supported by DMAs</title>
      <link>https://arxiv.org/abs/2510.17836</link>
      <description>arXiv:2510.17836v1 Announce Type: new 
Abstract: The present work proposes a novel two phases model-based strategy for leakage detection. The two phases are: the identification of the district metering area (DMA) and the pipe pre-localization into the identified DMA. The strategy is based on detecting and pre-localizing the punctual leakage as anomaly with respect to the normal working conditions. A further novelty is the fact that the pre-localization phase returns the sequence of pipes to inspect, which makes the strategy attractive for water utilities, whose aim is to identify the anomaly at DMA level and, successively, to localize it with the minimum inspection cost. Furthermore, a random database is useful to test the performance of the strategy with respect to the configuration of DMAs and the pressure metering system. Consequently, a novel strategy to design the location of pressure meters is also proposed. It is demonstrated that the entire strategy limits false positives during the DMA identification phase by using the recently proposed index named Asset Management Support Indicator (AMSI). AMSI is invariant with respect to the deterioration, i.e., it is sensitive to its increase causing punctual leakage. The strategy is studied and discussed using two real Apulian WDNs managed by Acquedotto Pugliese.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17836v1</guid>
      <category>eess.SP</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>G. Messa, G. Acconciaioco, S. Ripani, L. Bozzelli, A. Simone, O. Giustolisi</dc:creator>
    </item>
    <item>
      <title>Majority Vote Compressed Sensing</title>
      <link>https://arxiv.org/abs/2510.18008</link>
      <description>arXiv:2510.18008v1 Announce Type: new 
Abstract: We consider the problem of non-coherent over-the-air computation (AirComp), where $n$ devices carry high-dimensional data vectors $\mathbf{x}_i\in\mathbb{R}^d$ of sparsity $\lVert\mathbf{x}_i\rVert_0\leq k$ whose sum has to be computed at a receiver. Previous results on non-coherent AirComp require more than $d$ channel uses to compute functions of $\mathbf{x}_i$, where the extra redundancy is used to combat non-coherent signal aggregation. However, if the data vectors are sparse, sparsity can be exploited to offer significantly cheaper communication. In this paper, we propose to use random transforms to transmit lower-dimensional projections $\mathbf{s}_i\in\mathbb{R}^T$ of the data vectors. These projected vectors are communicated to the receiver using a majority vote (MV)-AirComp scheme, which estimates the bit-vector corresponding to the signs of the aggregated projections, i.e., $\mathbf{y} = \text{sign}(\sum_i\mathbf{s}_i)$. By leveraging 1-bit compressed sensing (1bCS) at the receiver, the real-valued and high-dimensional aggregate $\sum_i\mathbf{x}_i$ can be recovered from $\mathbf{y}$. We prove analytically that the proposed MVCS scheme estimates the aggregated data vector $\sum_i \mathbf{x}_i$ with $\ell_2$-norm error $\epsilon$ in $T=\mathcal{O}(kn\log(d)/\epsilon^2)$ channel uses. Moreover, we specify algorithms that leverage MVCS for histogram estimation and distributed machine learning. Finally, we provide numerical evaluations that reveal the advantage of MVCS compared to the state-of-the-art.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18008v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Henrik Hellstr\"om, Jiwon Jeong, Ayfer \"Ozg\"ur, Viktoria Fodor, Carlo Fischione</dc:creator>
    </item>
    <item>
      <title>MCANet: A Coherent Multimodal Collaborative Attention Network for Advanced Modulation Recognition in Adverse Noisy Environments</title>
      <link>https://arxiv.org/abs/2510.18336</link>
      <description>arXiv:2510.18336v1 Announce Type: new 
Abstract: As wireless communication systems evolve, automatic modulation recognition (AMR) plays a key role in improving spectrum efficiency, especially in cognitive radio systems. Traditional AMR methods face challenges in complex, noisy environments, particularly in low signal-to-noise ratio (SNR) conditions. This paper introduces MCANet (Multimodal Collaborative Attention Network), a multimodal deep learning framework designed to address these challenges. MCANet employs refined feature extraction and global modeling to support its fusion strategy.Experimental results across multiple benchmark datasets show that MCANet outperforms mainstream AMR models, offering better robustness in low-SNR conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18336v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wangye Jiang (Suzhou University of Technology), Haoming Yang (Jinling Institute of Technology), Xinyu Lu (Suzhou University of Technology), Mingyuan Wang (Suzhou University of Technology), Huimei Sun (Suzhou University of Technology), Jingya Zhang (Suzhou University of Technology)</dc:creator>
    </item>
    <item>
      <title>AWSPNet: Attention-based Dual-Tree Wavelet Scattering Prototypical Network for MIMO Radar Target Recognition and Jamming Suppression</title>
      <link>https://arxiv.org/abs/2510.18422</link>
      <description>arXiv:2510.18422v1 Announce Type: new 
Abstract: The increasing of digital radio frequency memory based electronic countermeasures poses a significant threat to the survivability and effectiveness of radar systems. These jammers can generate a multitude of deceptive false targets, overwhelming the radar's processing capabilities and masking targets. Consequently, the ability to robustly discriminate between true targets and complex jamming signals, especially in low signal-to-noise ratio (SNR) environments, is of importance. This paper introduces the attention-based dual-tree wavelet scattering prototypical network (AWSPNet), a deep learning framework designed for simultaneous radar target recognition and jamming suppression. The core of AWSPNet is the encoder that leverages the dual-tree complex wavelet transform to extract features that are inherently robust to noise and signal translations. These features are further refined by an attention mechanism and a pre-trained backbone network. To address the challenge of limited labeled data and enhance generalization, we employ a supervised contrastive learning strategy during the training phase. The classification is performed by a prototypical network, which is particularly effective in few-shot learning scenarios, enabling rapid adaptation to new signal types. We demonstrate the efficacy of our approach through extensive experiments. The results show that AWSPNet achieves 90.45\% accuracy at -6 dB SNR. Furthermore, we provide a physical interpretation of the network's inner workings through t-SNE visualizations, which analyze the feature separability at different stages of the model. Finally, by integrating AWSPNet with a time-domain sliding window approach, we present a complete algorithm capable of not only identifying but also effectively suppressing various types of jamming, thereby validating its potential for practical application in complex electromagnetic environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18422v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yizhen Jia, Siyao Xiao, Wenkai Jia, Hui Chen, Wen-Qin Wang</dc:creator>
    </item>
    <item>
      <title>Microsecond Federated SVD on Grassmann Manifold for Real-time IoT Intrusion Detection</title>
      <link>https://arxiv.org/abs/2510.18501</link>
      <description>arXiv:2510.18501v1 Announce Type: new 
Abstract: This paper introduces FedSVD, a novel unsupervised federated learning framework for real-time anomaly detection in IoT networks. By leveraging Singular Value Decomposition (SVD) and optimization on the Grassmann manifolds, FedSVD enables accurate detection of both known and unknown intrusions without relying on labeled data or centralized data sharing. Tailored for deployment on low-power devices like the NVIDIA Jetson AGX Orin, the proposed method significantly reduces communication overhead and computational cost. Experimental results show that FedSVD achieves performance comparable to deep learning baselines while reducing inference latency by over 10x, making it suitable for latency-sensitive IoT applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18501v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Tung-Anh Nguyen, Van-Phuc Bui, Shashi Raj Pandey, Kim Hue Ta, Nguyen H. Tran, Petar Popovski</dc:creator>
    </item>
    <item>
      <title>Channel-Aware Vector Quantization for Robust Semantic Communication on Discrete Channels</title>
      <link>https://arxiv.org/abs/2510.18604</link>
      <description>arXiv:2510.18604v1 Announce Type: new 
Abstract: Deep learning-based semantic communication has largely relied on analog or semi-digital transmission, which limits compatibility with modern digital communication infrastructures. Recent studies have employed vector quantization (VQ) to enable discrete semantic transmission, yet existing methods neglect channel state information during codebook optimization, leading to suboptimal robustness. To bridge this gap, we propose a channel-aware vector quantization (CAVQ) algorithm within a joint source-channel coding (JSCC) framework, termed VQJSCC, established on a discrete memoryless channel. In this framework, semantic features are discretized and directly mapped to modulation constellation symbols, while CAVQ integrates channel transition probabilities into the quantization process, aligning easily confused symbols with semantically similar codewords. A multi-codebook alignment mechanism is further introduced to handle mismatches between codebook order and modulation order by decomposing the transmission stream into multiple independently optimized subchannels. Experimental results demonstrate that VQJSCC effectively mitigates the digital cliff effect, achieves superior reconstruction quality across various modulation schemes, and outperforms state-of-the-art digital semantic communication baselines in both robustness and efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18604v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <category>eess.IV</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Zian Meng, Qiang Li, Wenqian Tang, Mingdie Yan, Xiaohu Ge</dc:creator>
    </item>
    <item>
      <title>Delay Management Using Packet Fragmentation in Wireless Industrial Automation Systems</title>
      <link>https://arxiv.org/abs/2510.18646</link>
      <description>arXiv:2510.18646v1 Announce Type: new 
Abstract: Managing delay is one of the core requirements of industrial automation applications due to the high risk associated for equipment and human lives. Using efficient Media Access Control (MAC) schemes guarantees the timely transmission of critical data, particularly in the industrial environments where heterogeneous data is inherently expected. This paper compares the performance of Fragmentation based MAC (FROG-MAC) against Fuzzy Priority Scheduling based MAC (FPS-MAC), both of which have been designed to optimize the performance of heterogenous wireless networks. Contiki has been used as a simulation platform and a single hop star topology has been assumed to resemble the industrial environment. It has been shown that FROG-MAC has the potential to outperform FPS-MAC in terms of energy efficiency and delay both, due to its inherent feature of interrupting ongoing lower priority transmission on the channel.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18646v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anwar Ahmed Khan, Shama Siddiqui, Indrakshi Dey</dc:creator>
    </item>
    <item>
      <title>A Comparative Analysis of High-Level vs. Low-Level Simulations for Dynamic MAC Protocols in Wireless Sensor Networks</title>
      <link>https://arxiv.org/abs/2510.18662</link>
      <description>arXiv:2510.18662v1 Announce Type: new 
Abstract: Simulation studies are conducted at different levels of details for assessing the performance of Media Access Control (MAC) protocols in Wireless Sensor Networks (WSN). In the present-day scenario where hundreds of MAC protocols have been proposed, it is important to assess the quality of performance evaluation being conducted for each of the proposed protocols. It therefore becomes crucial to compare the results of high-level theoretical simulations with the detailed implementation results before any network protocol could be deployed for a real-world scenario. In this work, we present a comparison of high-level theoretical and detailed implementation results for Adaptive and Dynamic Polling-MAC (ADP-MAC). MATLAB has been used for conducting initial theoretical simulations and TinyOS has been used to develop the detailed implementation of protocol for Mica2 platform. Performance evaluation of ADP-MAC using the two levels of simulation has been conducted based on energy and delay. In the high-level implementation, energy consumption was found to be decreasing whereas delay was found to be increasing for increasing channel polling intervals. On the other hand, when detailed implementation was developed, it was observed that both energy consumption and delay revealed an increasing trend with the increasing polling intervals. Therefore, it has been shown that the trends for high- and low-level simulations for ADP-MAC are significantly different, due to the lack of realistic assumptions in the higher-level study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18662v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shama Siddiqui, Anwar Ahmed Khan, Indrakshi Dey</dc:creator>
    </item>
    <item>
      <title>mSQUID: Model-Based Leanred Modulo Recovery at Low Sampling Rates</title>
      <link>https://arxiv.org/abs/2510.18729</link>
      <description>arXiv:2510.18729v1 Announce Type: new 
Abstract: Modulo sampling enables acquisition of signals with unlimited dynamic range by folding the input into a bounded interval prior to sampling, thus eliminating the risk of signal clipping and preserving information without requiring highresolution ADCs. While this enables low-cost hardware, the nonlinear distortion introduced by folding presents recovery challenges, particularly under noise and quantization. We propose a model-based deep unfolding network tailored to this setting, combining the interpretability of classical compress sensing (CS) solvers with the flexibility of learning. A key innovation is a soft-quantization module that encodes the modulo prior by guiding the solution toward discrete multiples of the folding range in a differentiable and learnable way. Our method, modulo soft-quantized unfolded iterative decoder (mSQUID), achieves superior reconstruction performance at low sampling rates under additive Gaussian noise. We further demonstrate its utility in a challenging case where signals with vastly different amplitudes and disjoint frequency bands are acquired simultaneously and quantized. In this scenario, classical sampling often struggles due to weak signal distortion or strong signal clipping, while our approach is able to recover the input signals. Our method also offers significantly reduced runtimes, making it suitable for real-time, resource-limited systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18729v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yhonatan Kvich, Rotem Arie, Hana Hasan, Shaik Basheeruddin Shah, Yonina C. Eldar</dc:creator>
    </item>
    <item>
      <title>Wireless-Fed Pinching-Antenna Systems (Wi-PASS) for NextG Wireless Networks</title>
      <link>https://arxiv.org/abs/2510.18743</link>
      <description>arXiv:2510.18743v1 Announce Type: new 
Abstract: Waveguide-based pinching-antenna systems (PASS) have recently emerged as a promising solution to mitigate severe propagation losses in millimeter-wave and terahertz bands by intelligently and flexibly establishing line-of-sight links. However, their reliance on wire-based feeding confines deployment to areas near the base station (BS), limiting installation flexibility and making them cost-ineffective for serving distant users or regions. To overcome this challenge, this article proposes wireless-fed pinchingantenna systems (Wi-PASS), which employ wireless feeding to energize waveguides. Wi-PASS offer a practical and cost-efficient means to extend coverage beyond the BS vicinity. Several indoor and outdoor use cases demonstrate Wi-PASS advantages over PASS. Numerical results further show that Wi-PASS deliver higher data rates than conventional fixed-antenna systems, confirming the superior feasibility and performance of Wi-PASS. Key future research directions are also discussed to advance Wi-PASS deployment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18743v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kasun R. Wijewardhana, Animesh Yadav, Ming Zeng, Mohamed Elsayed, Octavia A. Dobre, Zhiguo Ding</dc:creator>
    </item>
    <item>
      <title>Analyse comparative d'algorithmes de restauration en architecture d\'epli\'ee pour des signaux chromatographiques parcimonieux</title>
      <link>https://arxiv.org/abs/2510.18760</link>
      <description>arXiv:2510.18760v1 Announce Type: new 
Abstract: Data restoration from degraded observations, of sparsity hypotheses, is an active field of study. Traditional iterative optimization methods are now complemented by deep learning techniques. The development of unfolded methods benefits from both families. We carry out a comparative study of three architectures on parameterized chromatographic signal databases, highlighting the performance of these approaches, especially when employing metrics adapted to physico-chemical peak signal characterization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18760v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <category>physics.chem-ph</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mouna Gharbi, Silvia Villa, Emilie Chouzenoux, Jean-Christophe Pesquet, Laurent Duval</dc:creator>
    </item>
    <item>
      <title>SO(3)-invariant PCA with application to molecular data</title>
      <link>https://arxiv.org/abs/2510.18827</link>
      <description>arXiv:2510.18827v1 Announce Type: new 
Abstract: Principal component analysis (PCA) is a fundamental technique for dimensionality reduction and denoising; however, its application to three-dimensional data with arbitrary orientations -- common in structural biology -- presents significant challenges. A naive approach requires augmenting the dataset with many rotated copies of each sample, incurring prohibitive computational costs. In this paper, we extend PCA to 3D volumetric datasets with unknown orientations by developing an efficient and principled framework for SO(3)-invariant PCA that implicitly accounts for all rotations without explicit data augmentation. By exploiting underlying algebraic structure, we demonstrate that the computation involves only the square root of the total number of covariance entries, resulting in a substantial reduction in complexity. We validate the method on real-world molecular datasets, demonstrating its effectiveness and opening up new possibilities for large-scale, high-dimensional reconstruction problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18827v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Fraiman, Paulina Hoyos, Tamir Bendory, Joe Kileel, Oscar Mickelin, Nir Sharon, Amit Singer</dc:creator>
    </item>
    <item>
      <title>Adaptive Per-Channel Energy Normalization Front-end for Robust Audio Signal Processing</title>
      <link>https://arxiv.org/abs/2510.18206</link>
      <description>arXiv:2510.18206v1 Announce Type: cross 
Abstract: In audio signal processing, learnable front-ends have shown strong performance across diverse tasks by optimizing task-specific representation. However, their parameters remain fixed once trained, lacking flexibility during inference and limiting robustness under dynamic complex acoustic environments. In this paper, we introduce a novel adaptive paradigm for audio front-ends that replaces static parameterization with a closed-loop neural controller. Specifically, we simplify the learnable front-end LEAF architecture and integrate a neural controller for adaptive representation via dynamically tuning Per-Channel Energy Normalization. The neural controller leverages both the current and the buffered past subband energies to enable input-dependent adaptation during inference. Experimental results on multiple audio classification tasks demonstrate that the proposed adaptive front-end consistently outperforms prior fixed and learnable front-ends under both clean and complex acoustic conditions. These results highlight neural adaptability as a promising direction for the next generation of audio front-ends.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18206v1</guid>
      <category>eess.AS</category>
      <category>cs.SD</category>
      <category>eess.SP</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hanyu Meng, Vidhyasaharan Sethu, Eliathamby Ambikairajah, Qiquan Zhang, Haizhou Li</dc:creator>
    </item>
    <item>
      <title>Distributed Allocation and Resource Scheduling Algorithms Resilient to Link Failure</title>
      <link>https://arxiv.org/abs/2510.18273</link>
      <description>arXiv:2510.18273v1 Announce Type: cross 
Abstract: Distributed resource allocation (DRA) is fundamental to modern networked systems, spanning applications from economic dispatch in smart grids to CPU scheduling in data centers. Conventional DRA approaches require reliable communication, yet real-world networks frequently suffer from link failures, packet drops, and communication delays due to environmental conditions, network congestion, and security threats.
  We introduce a novel resilient DRA algorithm that addresses these critical challenges, and our main contributions are as follows: (1) guaranteed constraint feasibility at all times, ensuring resource-demand balance even during algorithm termination or network disruption; (2) robust convergence despite sector-bound nonlinearities at nodes/links, accommodating practical constraints like quantization and saturation; and (3) optimal performance under merely uniformly-connected networks, eliminating the need for continuous connectivity.
  Unlike existing approaches that require persistent network connectivity and provide only asymptotic feasibility, our graph-theoretic solution leverages network percolation theory to maintain performance during intermittent disconnections. This makes it particularly valuable for mobile multi-agent systems where nodes frequently move out of communication range. Theoretical analysis and simulations demonstrate that our algorithm converges to optimal solutions despite heterogeneous time delays and substantial link failures, significantly advancing the reliability of distributed resource allocation in practical network environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18273v1</guid>
      <category>eess.SY</category>
      <category>cs.DC</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammadreza Doostmohammadian, Sergio Pequito</dc:creator>
    </item>
    <item>
      <title>Quantification of dual-state 5-ALA-induced PpIX fluorescence: Methodology and validation in tissue-mimicking phantoms</title>
      <link>https://arxiv.org/abs/2510.18387</link>
      <description>arXiv:2510.18387v1 Announce Type: cross 
Abstract: Quantification of protoporphyrin IX (PpIX) fluorescence in human brain tumours has the potential to significantly improve patient outcomes in neuro-oncology, but represents a formidable imaging challenge. Protoporphyrin is a biological molecule which interacts with the tissue micro-environment to form two photochemical states in glioma. Each exhibits markedly different quantum efficiencies, with distinct but overlapping emission spectra that also overlap with tissue autofluorescence. Fluorescence emission is known to be distorted by the intrinsic optical properties of tissue, coupled with marked intra-tumoural heterogeneity as a hallmark of glioma tumours. Existing quantitative fluorescence systems are developed and validated using simplified phantoms that do not simultaneously mimic the complex interactions between fluorophores and tissue optical properties or micro-environment. Consequently, existing systems risk introducing systematic errors into PpIX quantification when used in tissue. In this work, we introduce a novel pipeline for quantification of PpIX in glioma, which robustly differentiates both emission states from background autofluorescence without reliance on a priori spectral information, and accounts for variations in their quantum efficiency. Unmixed PpIX emission forms are then corrected for wavelength-dependent optical distortions and weighted for accurate quantification. Significantly, this pipeline is developed and validated using novel tissue-mimicking phantoms replicating the optical properties of glioma tissues and photochemical variability of PpIX fluorescence in glioma. Our workflow achieves strong correlation with ground-truth PpIX concentrations (R2 = 0.918+-0.002), demonstrating its potential for robust, quantitative PpIX fluorescence imaging in clinical settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18387v1</guid>
      <category>physics.med-ph</category>
      <category>eess.IV</category>
      <category>eess.SP</category>
      <category>q-bio.QM</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Silv\`ere S\'egaud, Charlie Budd, Matthew Elliot, Graeme Stasiuk, Jonathan Shapey, Yijing Xie, Tom Vercauteren</dc:creator>
    </item>
    <item>
      <title>Experimental Assessment of Human Blockage at sub-THz and mmWave Frequency Bands</title>
      <link>https://arxiv.org/abs/2411.13191</link>
      <description>arXiv:2411.13191v2 Announce Type: replace 
Abstract: The fifth generation (5G) of mobile communications relies on extremely high data transmissions using a large variety of frequency bands, such as FR1 (sub-6 GHz) and FR2 (mmWave). Future mobile communications envisage using electromagnetic spectrum beyond FR2, i.e. above 100 GHz, known as sub-THz band. These new frequencies open up challenging scenarios where communications shall rely on a major contribution such as the line-of-sight (LoS) component. To the best of the authors' knowledge, for the first time in literature this work studies the human blockage effects over an extremely wide frequency band from 75 GHz to 215 GHz given: (i) the distance between the blocker and the antennas and (ii) the body orientation. Furthermore, the obtained results are modeled with the classical path loss models and compared to 3GPP alternatives. The average losses increase from 42 dB to 56 dB when frequency rises from 75 GHz to 215 GHz. In terms of distance, a 18 dB increment in the received power is found when the Tx--Rx separation is increased from 1 m to 2.5 m. Finally, the blocker orientation induces variations of up to 4.6 dB.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13191v2</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Juan E. Galeote-Cazorla, Alejandro Ram\'irez-Arroyo, Jos\'e-Mar\'ia Molina-Garc\'ia-Pardo, Mar\'ia-Teresa Mart\'inez-Ingl\'es, Juan F. Valenzuela Vald\'es</dc:creator>
    </item>
    <item>
      <title>Low-cost Embedded Breathing Rate Determination Using 802.15.4z IR-UWB Hardware for Remote Healthcare</title>
      <link>https://arxiv.org/abs/2504.03772</link>
      <description>arXiv:2504.03772v2 Announce Type: replace 
Abstract: Respiratory diseases account for a significant portion of global mortality. Affordable and early detection is an effective way of addressing these ailments. To this end, a low-cost commercial off-the-shelf (COTS), IEEE 802.15.4z standard compliant impulse-radio ultra-wideband (IR-UWB) radar system is used to estimate human respiration rates. We propose a convolutional neural network (CNN) specifically adapted to predict breathing rates from ultra-wideband (UWB) channel impulse response (CIR) data, and compare its performance with both other rule-based algorithms and model-based solutions. The study uses a diverse dataset, incorporating various real-life environments to evaluate system robustness. To facilitate future research, this dataset will be released as open source. Results show that the CNN achieves a mean absolute error (MAE) of 1.73 breaths per minute (BPM) in unseen situations, significantly outperforming rule-based methods (3.40 BPM). By incorporating calibration data from other individuals in the unseen situations, the error is further reduced to 0.84 BPM. In addition, this work evaluates the feasibility of running the pipeline on a low-cost embedded device. Applying 8-bit quantization to both the weights and input/ouput tensors, reduces memory requirements by 67% and inference time by 64% with only a 3% increase in MAE. As a result, we show it is feasible to deploy the algorithm on an nRF52840 system-on-chip (SoC) requiring only 46 KB of memory and operating with an inference time of only 192 ms. Once deployed, an analytical energy model estimates that the system, while continuously monitoring the room, can operate for up to 268 days without recharging when powered by a 20 000 mAh battery pack. For breathing monitoring in bed, the sampling rate can be lowered, extending battery life to 313 days, making the solution highly efficient for real-world, low-cost deployments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03772v2</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Anton Lambrecht, Stijn Luchie, Jaron Fontaine, Ben Van Herbruggen, Adnan Shahid, Eli De Poorter</dc:creator>
    </item>
    <item>
      <title>Semi-Blind Strategies for MMSE Channel Estimation Utilizing Generative Priors</title>
      <link>https://arxiv.org/abs/2504.17573</link>
      <description>arXiv:2504.17573v2 Announce Type: replace 
Abstract: This paper investigates semi-blind channel estimation for massive multiple-input multiple-output (MIMO) systems. To this end, we first estimate a subspace based on all received symbols (pilot and payload) to provide additional information for subsequent channel estimation. This additional information enhances minimum mean square error (MMSE) channel estimation. Two variants of the linear MMSE (LMMSE) estimator are formulated, where the first one solves the estimation within the subspace, and the second one uses a subspace projection as a preprocessing step. Theoretical derivations show the latter method's superior estimation performance in terms of mean square error for uncorrelated Rayleigh fading. Further, we provide asymptotic insights on how the proposed MMSE-based channel estimation strategy outperforms the unbiased Cramer-Rao bound. Subsequently, we introduce parameterizations of these semi-blind LMMSE estimators based on two different conditional Gaussian latent models, i.e., the Gaussian mixture model and the variational autoencoder. Both models learn the propagation environment's underlying channel distribution based on training data and serve as generative priors for our semi-blind channel estimation. Extensive simulations for real-world measurement data and spatial channel models show the proposed methods' superior performance compared to state-of-the-art semi-blind channel estimators in terms of MSE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17573v2</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Franz Wei{\ss}er, Nurettin Turan, Dominik Semmler, Fares Ben Jazia, Wolfgang Utschick</dc:creator>
    </item>
    <item>
      <title>Robust Activity Detection for Massive Random Access</title>
      <link>https://arxiv.org/abs/2505.15555</link>
      <description>arXiv:2505.15555v2 Announce Type: replace 
Abstract: Massive machine-type communications (mMTC) are fundamental to the Internet of Things (IoT) framework in future wireless networks, involving the connection of a vast number of devices with sporadic transmission patterns. Traditional device activity detection (AD) methods are typically developed for Gaussian noise, but their performance may deteriorate when these conditions are not met, particularly in the presence of heavy-tailed impulsive noise. In this paper, we propose robust statistical techniques for AD that do not rely on the Gaussian assumption and replace the Gaussian loss function with robust loss functions that can effectively mitigate the impact of heavy-tailed noise and outliers. First, we prove that the coordinate-wise (conditional) objective function is geodesically convex and derive a fixed-point (FP) algorithm for minimizing it, along with convergence guarantees. Building on the FP algorithm, we propose two robust algorithms for solving the full (unconditional) objective function: a coordinate-wise optimization algorithm (RCWO) and a greedy covariance learning-based matching pursuit algorithm (RCL-MP). Numerical experiments demonstrate that the proposed methods significantly outperform existing algorithms in scenarios with non-Gaussian noise, achieving higher detection accuracy and robustness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.15555v2</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TSP.2025.3597931</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Signal Processing, vol. 73, pp. 3513-3527, August 2025</arxiv:journal_reference>
      <dc:creator>Xinjue Wang, Esa Ollila, Sergiy A. Vorobyov</dc:creator>
    </item>
    <item>
      <title>Near-Field Secure Beamfocusing With Receiver-Centered Protected Zone</title>
      <link>https://arxiv.org/abs/2505.19523</link>
      <description>arXiv:2505.19523v2 Announce Type: replace 
Abstract: This work studies near-field secure communications through transmit beamfocusing. We examine the benefit of having a protected eavesdropper-free zone around the legitimate receiver, and we determine the worst-case secrecy performance against a potential eavesdropper located anywhere outside the protected zone. A max-min optimization problem is formulated for the beamfocusing design with and without artificial noise transmission. Despite the NP-hardness of the problem, we develop a synchronous gradient descent-ascent framework that approximates the global maximin solution. A low-complexity solution is also derived that delivers excellent performance over a wide range of operating conditions. We further extend this study to a scenario where it is not possible to physically enforce a protected zone. To this end, we consider secure communications through the creation of a virtual protected zone using a full-duplex legitimate receiver. Numerical results demonstrate that exploiting either the physical or virtual receiver-centered protected zone with appropriately designed beamfocusing is an effective strategy for achieving secure near-field communications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19523v2</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cen Liu, Xiangyun Zhou, Nan Yang, Salman Durrani, A. Lee Swindlehurst</dc:creator>
    </item>
    <item>
      <title>Model-based Implicit Neural Representation for sub-wavelength Radio Localization</title>
      <link>https://arxiv.org/abs/2506.06387</link>
      <description>arXiv:2506.06387v2 Announce Type: replace 
Abstract: The increasing deployment of large antenna arrays at base stations has significantly improved the spatial resolution and localization accuracy of radio-localization methods. However, traditional signal processing techniques struggle in complex radio environments, particularly in scenarios dominated by non line of sight (NLoS) propagation paths, resulting in degraded localization accuracy. Recent developments in machine learning have facilitated the development of machine learning-assisted localization techniques, enhancing localization accuracy in complex radio environments. However, these methods often involve substantial computational complexity during both the training and inference phases. This work extends the well-established fingerprinting-based localization framework by simultaneously reducing its memory requirements and improving its accuracy. Specifically, a model-based neural network is used to learn the location-to-channel mapping, and then serves as a generative neural channel model. This generative model augments the fingerprinting comparison dictionary while reducing the memory requirements. The proposed method outperforms fingerprinting baselines by achieving sub-wavelength localization accuracy, even in complex static NLoS environments. Remarkably, it offers an improvement by several orders of magnitude in localization accuracy, while simultaneously reducing memory requirements by an order of magnitude compared to classical fingerprinting methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.06387v2</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Baptiste Chatelier (IETR, INSA Rennes, MERCE-France), Vincent Corlay (MERCE-France), Musa Furkan Keskin (INSA Rennes, IETR), Matthieu Crussi\`ere (INSA Rennes, IETR), Henk Wymeersch (INSA Rennes, IETR), Luc Le Magoarou (INSA Rennes, IETR)</dc:creator>
    </item>
    <item>
      <title>Wireless Channel Modeling for Machine Learning - A Critical View on Standardized Channel Models</title>
      <link>https://arxiv.org/abs/2510.12279</link>
      <description>arXiv:2510.12279v2 Announce Type: replace 
Abstract: Standardized (link-level) channel models such as the 3GPP TDL and CDL models are frequently used to evaluate machine learning (ML)-based physical-layer methods. However, in this work, we argue that a link-level perspective incorporates limiting assumptions, causing unwanted distributional shifts or necessitating impractical online training. An additional drawback is that this perspective leads to (near-)Gaussian channel characteristics. Thus, ML-based models, trained on link-level channel data, do not outperform classical approaches for a variety of physical-layer applications. Particularly, we demonstrate the optimality of simple linear methods for channel compression, estimation, and modeling, revealing the unsuitability of link-level channel models for evaluating ML models. On the upside, adopting a scenario-level perspective offers a solution to this problem and unlocks the relative gains enabled by ML.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.12279v2</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Benedikt B\"ock, Amar Kasibovic, Wolfgang Utschick</dc:creator>
    </item>
    <item>
      <title>Byzantine-Eavesdropper Alliance: How to Achieve Symmetric Privacy in Quantum $X$-Secure $B$-Byzantine $E$-Eavesdropped $U$-Unresponsive $T$-Colluding PIR?</title>
      <link>https://arxiv.org/abs/2412.06728</link>
      <description>arXiv:2412.06728v2 Announce Type: replace-cross 
Abstract: We consider the quantum \emph{symmetric} private information retrieval (QSPIR) problem in a system with $N$ databases and $K$ messages, with $U$ unresponsive servers, $T$-colluding servers, and $X$-security parameter, under several fundamental threat models. In the first model, there are $\mathcal{E}_1$ eavesdropped links in the uplink direction (the direction from the user to the $N$ servers), $\mathcal{E}_2$ eavesdropped links in the downlink direction (the direction from the servers to the user), where $|\mathcal{E}_1|, |\mathcal{E}_2| \leq E$; we coin this eavesdropper setting as \emph{dynamic} eavesdroppers. We show that super-dense coding gain can be achieved for some regimes. In the second model, we consider the case with Byzantine servers, i.e., servers that can coordinate to devise a plan to harm the privacy and security of the system together with static eavesdroppers, by listening to the same links in both uplink and downlink directions. It is important to note the considerable difference between the two threat models, since the eavesdroppers can take huge advantage of the presence of the Byzantine servers. Unlike the previous works in SPIR with Byzantine servers, that assume that the Byzantine servers can send only random symbols independent of the stored messages, we follow the definition of Byzantine servers in \cite{byzantine_tpir}, where the Byzantine servers can send symbols that can be functions of the storage, queries, as well as the random symbols in a way that can produce worse harm to the system. In the third and the most novel threat model, we consider the presence of Byzantine servers and dynamic eavesdroppers together. We show that having dynamic eavesdroppers along with Byzantine servers in the same system model creates more threats to the system than having static eavesdroppers with Byzantine servers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06728v2</guid>
      <category>cs.IT</category>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <category>quant-ph</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohamed Nomeir, Alptug Aytekin, Sennur Ulukus</dc:creator>
    </item>
    <item>
      <title>Implicit Neural Compression of Point Clouds</title>
      <link>https://arxiv.org/abs/2412.10433</link>
      <description>arXiv:2412.10433v2 Announce Type: replace-cross 
Abstract: Point clouds have gained prominence across numerous applications due to their ability to accurately represent 3D objects and scenes. However, efficiently compressing unstructured, high-precision point cloud data remains a significant challenge. In this paper, we propose NeRC$^3$, a novel point cloud compression framework that leverages implicit neural representations (INRs) to encode both geometry and attributes of dense point clouds. Our approach employs two coordinate-based neural networks: one maps spatial coordinates to voxel occupancy, while the other maps occupied voxels to their attributes, thereby implicitly representing the geometry and attributes of a voxelized point cloud. The encoder quantizes and compresses network parameters alongside auxiliary information required for reconstruction, while the decoder reconstructs the original point cloud by inputting voxel coordinates into the neural networks. Furthermore, we extend our method to dynamic point cloud compression through techniques that reduce temporal redundancy, including a 4D spatio-temporal representation termed 4D-NeRC$^3$. Experimental results validate the effectiveness of our approach: For static point clouds, NeRC$^3$ outperforms octree-based G-PCC standard and existing INR-based methods. For dynamic point clouds, 4D-NeRC$^3$ achieves superior geometry compression performance compared to the latest G-PCC and V-PCC standards, while matching state-of-the-art learning-based methods. It also demonstrates competitive performance in joint geometry and attribute compression.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10433v2</guid>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongning Ruan, Yulin Shao, Qianqian Yang, Liang Zhao, Zhaoyang Zhang, Dusit Niyato</dc:creator>
    </item>
    <item>
      <title>PAUSE: Low-Latency and Privacy-Aware Active User Selection for Federated Learning</title>
      <link>https://arxiv.org/abs/2503.13173</link>
      <description>arXiv:2503.13173v2 Announce Type: replace-cross 
Abstract: Federated learning (FL) enables multiple edge devices to collaboratively train a machine learning model without the need to share potentially private data. Federated learning proceeds through iterative exchanges of model updates, which pose two key challenges: First, the accumulation of privacy leakage over time, and second, communication latency. These two limitations are typically addressed separately: The former via perturbed updates to enhance privacy and the latter using user selection to mitigate latency - both at the expense of accuracy. In this work, we propose a method that jointly addresses the accumulation of privacy leakage and communication latency via active user selection, aiming to improve the trade-off among privacy, latency, and model performance. To achieve this, we construct a reward function that accounts for these three objectives. Building on this reward, we propose a multi-armed bandit (MAB)-based algorithm, termed Privacy-aware Active User SElection (PAUSE) which dynamically selects a subset of users each round while ensuring bounded overall privacy leakage. We establish a theoretical analysis, systematically showing that the reward growth rate of PAUSE follows that of the best-known rate in MAB literature. To address the complexity overhead of active user selection, we propose a simulated annealing-based relaxation of PAUSE and analyze its ability to approximate the reward-maximizing policy under reduced complexity. We numerically validate the privacy leakage, associated improved latency, and accuracy gains of our methods for the federated training in various scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13173v2</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ori Peleg, Natalie Lang, Dan Ben Ami, Stefano Rini, Nir Shlezinger, Kobi Cohen</dc:creator>
    </item>
  </channel>
</rss>
