<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.ST updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.ST</link>
    <description>math.ST updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.ST" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 30 Jan 2026 03:05:18 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Decoupling and randomization for double-indexed permutation statistics</title>
      <link>https://arxiv.org/abs/2601.20018</link>
      <description>arXiv:2601.20018v1 Announce Type: new 
Abstract: This paper introduces a version of decoupling and randomization to establish concentration inequalities for double-indexed permutation statistics. The results yield, among other applications, a new combinatorial Hanson-Wright inequality and a new combinatorial Bennett inequality. Several illustrative examples from rank-based statistics, graph-based statistics, and causal inference are also provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20018v1</guid>
      <category>math.ST</category>
      <category>econ.EM</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mingxuan Zou, Jingfan Xu, Peng Ding, Fang Han</dc:creator>
    </item>
    <item>
      <title>Matching and mixing: Matchability of graphs under Markovian error</title>
      <link>https://arxiv.org/abs/2601.20020</link>
      <description>arXiv:2601.20020v1 Announce Type: new 
Abstract: We consider the problem of graph matching for a sequence of graphs generated under a time-dependent Markov chain noise model. Our edgelighter error model, a variant of the classical lamplighter random walk, iteratively corrupts the graph $G_0$ with edge-dependent noise, creating a sequence of noisy graph copies $(G_t)$. Much of the graph matching literature is focused on anonymization thresholds in edge-independent noise settings, and we establish novel anonymization thresholds in this edge-dependent noise setting when matching $G_0$ and $G_t$. Moreover, we also compare this anonymization threshold with the mixing properties of the Markov chain noise model. We show that when $G_0$ is drawn from an Erd\H{o}s-R\'enyi model, the graph matching anonymization threshold and the mixing time of the edgelighter walk are both of order $\Theta(n^2\log n)$. We further demonstrate that for more structured model for $G_0$ (e.g., the Stochastic Block Model), graph matching anonymization can occur in $O(n^\alpha\log n)$ time for some $\alpha&lt;2$, indicating that anonymization can occur before the Markov chain noise model globally mixes. Through extensive simulations, we verify our theoretical bounds in the settings of Erd\H{o}s-R\'enyi random graphs and stochastic block model random graphs, and explore our findings on real-world datasets derived from a Facebook friendship network and a European research institution email communication network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20020v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhirui Li, Keith D. Levin, Zhiang Zhao, Vince Lyzinski</dc:creator>
    </item>
    <item>
      <title>Concentration Inequalities for Exchangeable Tensors and Matrix-valued Data</title>
      <link>https://arxiv.org/abs/2601.20152</link>
      <description>arXiv:2601.20152v1 Announce Type: new 
Abstract: We study concentration inequalities for structured weighted sums of random data, including (i) tensor inner products and (ii) sequential matrix sums. We are interested in tail bounds and concentration inequalities for those structured weighted sums under exchangeability, extending beyond the classical framework of independent terms.
  We develop Hoeffding and Bernstein bounds provided with structure-dependent exchangeability. Along the way, we recover known results in weighted sum of exchangeable random variables and i.i.d. sums of random matrices to the optimal constants. Notably, we develop a sharper concentration bound for combinatorial sum of matrix arrays than the results previously derived from Chatterjee's method of exchangeable pairs.
  For applications, the richer structures provide us with novel analytical tools for estimating the average effect of multi-factor response models and studying fixed-design sketching methods in federated averaging. We apply our results to these problems, and find that our theoretical predictions are corroborated by numerical evidence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20152v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chen Cheng, Rina Foygel Barber</dc:creator>
    </item>
    <item>
      <title>Partial heteroscedastic deconvolution estimation in nonparametric regression</title>
      <link>https://arxiv.org/abs/2601.20341</link>
      <description>arXiv:2601.20341v1 Announce Type: new 
Abstract: In this paper, we consider a partial deconvolution kernel estimator for nonparametric regression when some covariates are measured with error while others are observed without error. We focus on a general and realistic setting in which the measurement errors are heteroscedastic. We propose a kernel-based estimator of the regression function in this framework and show that it achieves the optimal convergence rate under suitable regularity conditions. The finite-sample performance of the proposed estimator is illustrated through simulation studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20341v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Baba Thiam (LPP)</dc:creator>
    </item>
    <item>
      <title>Blessing of dimensionality in cross-validated bandwidth selection on the sphere</title>
      <link>https://arxiv.org/abs/2601.20442</link>
      <description>arXiv:2601.20442v1 Announce Type: new 
Abstract: We study the asymptotic behavior of least-squares cross-validation bandwidth selection in kernel density estimation on the $d$-dimensional hypersphere, $d\geq 1$. We show that the exact rate of convergence with respect to the optimal bandwidth minimizing the mean integrated squared error, shown to exist under mild non-uniformity conditions, is $n^{-d/(2d+8)}$, thus approaching the $n^{-1/2}$ parametric rate as $d$ grows. This ``blessing of dimensionality'' in bandwidth selection offers theoretical support for utilizing the conceptually simpler cross-validation selector over plug-in techniques for larger dimensions $d$. We compare this result for bandwidth estimation on the $d$-dimensional Euclidean space through explicit expressions for the asymptotic variance functionals. Numerical experiments corroborate the speed of this convergence in an array of scenarios and dimensions, precisely illustrating the tipping dimension where cross-validation outperforms plug-in approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20442v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jos\'e E. Chac\'on, Eduardo Garc\'ia-Portugu\'es, Andrea Meil\'an-Vila</dc:creator>
    </item>
    <item>
      <title>Improved Computational Lower Bound of Estimation for Multi-Frequency Group Synchronization</title>
      <link>https://arxiv.org/abs/2601.20522</link>
      <description>arXiv:2601.20522v1 Announce Type: new 
Abstract: We study the computational phase transition in a multi-frequency group synchronization problem, where pairwise relative measurements of group elements are observed across multiple frequency channels and corrupted by Gaussian noise. Using the framework of \emph{low-degree polynomial algorithms}, we analyze the task of estimating the structured signal in such observations. We show that, assuming the low-degree heuristic, in synchronization models over the circle group $\mathsf{SO}(2)$, a simple spectral method is computationally optimal among all polynomial-time estimators when the number of frequencies satisfies $L=n^{o(1)}$. This significantly extends prior work \cite{KBK24+}, which only applied to a fixed constant number of frequencies. Together with known upper bounds on the statistical threshold \cite{PWBM18a}, our results establish the existence of a \emph{statistical-to-computational gap} in this model when the number of frequencies is sufficiently large.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20522v1</guid>
      <category>math.ST</category>
      <category>cs.DS</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhangsong Li</dc:creator>
    </item>
    <item>
      <title>Spectral Bayesian Regression on the Sphere</title>
      <link>https://arxiv.org/abs/2601.20528</link>
      <description>arXiv:2601.20528v1 Announce Type: new 
Abstract: We develop a fully intrinsic Bayesian framework for nonparametric regression on the unit sphere based on isotropic Gaussian field priors and the harmonic structure induced by the Laplace-Beltrami operator. Under uniform random design, the regression model admits an exact diagonalization in the spherical harmonic basis, yielding a Gaussian sequence representation with frequency-dependent multiplicities.
  Exploiting this structure, we derive closed-form posterior distributions, optimal spectral truncation schemes, and sharp posterior contraction rates under integrated squared loss. For Gaussian priors with polynomially decaying angular power spectra, including spherical Mat\'ern priors, we establish posterior contraction rates over Sobolev classes, which are minimax-optimal under correct prior calibration.
  We further show that the posterior mean admits an exact variational characterization as a geometrically intrinsic penalized least-squares estimator, equivalent to a Laplace-Beltrami smoothing spline.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20528v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Claudio Durastanti</dc:creator>
    </item>
    <item>
      <title>Causal Inference in Biomedical Imaging via Functional Linear Structural Equation Models</title>
      <link>https://arxiv.org/abs/2601.20610</link>
      <description>arXiv:2601.20610v1 Announce Type: cross 
Abstract: Understanding the causal effects of organ-specific features from medical imaging on clinical outcomes is essential for biomedical research and patient care. We propose a novel Functional Linear Structural Equation Model (FLSEM) to capture the relationships among clinical outcomes, functional imaging exposures, and scalar covariates like genetics, sex, and age. Traditional methods struggle with the infinite-dimensional nature of exposures and complex covariates. Our FLSEM overcomes these challenges by establishing identifiable conditions using scalar instrumental variables. We develop the Functional Group Support Detection and Root Finding (FGS-DAR) algorithm for efficient variable selection, supported by rigorous theoretical guarantees, including selection consistency and accurate parameter estimation. We further propose a test statistic to test the nullity of the functional coefficient, establishing its null limit distribution. Our approach is validated through extensive simulations and applied to UK Biobank data, demonstrating robust performance in detecting causal relationships from medical imaging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20610v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Ting Li, Ethan Fan, Tengfei Li, Hongtu Zhu</dc:creator>
    </item>
    <item>
      <title>Anytime-Valid Quantum Tomography via Confidence Sequences</title>
      <link>https://arxiv.org/abs/2601.20761</link>
      <description>arXiv:2601.20761v1 Announce Type: cross 
Abstract: In this letter, we address the problem of developing quantum state tomography (QST) methods that remain valid at any time during a sequence of measurements. Specifically, the aim is to provide a rigorous quantification of the uncertainty associated with the current state estimate as data are acquired incrementally. To this end, the proposed framework augments existing QST techniques by associating current point estimates of the state with confidence sets that are guaranteed to contain the true quantum state with a user-defined probability. The methodology is grounded in recent statistical advances in anytime-valid confidence sequences. Numerical results confirm the theoretical coverage properties of the proposed anytime-valid QST.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20761v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aldo Cumitini, Luca Barletta, Osvaldo Simeone</dc:creator>
    </item>
    <item>
      <title>Effective Sample Size for Functional Spatial Data</title>
      <link>https://arxiv.org/abs/2601.20812</link>
      <description>arXiv:2601.20812v1 Announce Type: cross 
Abstract: The effective sample size quantifies the amount of independent information contained in a dataset, accounting for redundancy due to correlation between observations. While widely used in geostatistics for scalar data, its extension to functional spatial data has remained largely unexplored. In this work, we introduce a novel definition of the effective sample size for functional geostatistical data, employing the trace-covariogram as a measure of correlation, and show that it retains the intuitive properties of the classical scalar ESS. We illustrate the behavior of this measure using a functional autoregressive process, demonstrating how serial dependence and the allocation of variability across eigen-directions influence the resulting functional ESS. Finally, the approach is applied to a real meteorological dataset of geometric vertical velocities over a portion of the Earth, showing how the method can quantify redundancy and determine the effective number of independent curves in functional spatial datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20812v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alfredo Alegr\'ia, John G\'omez, Jorge Mateu, Ronny Vallejos</dc:creator>
    </item>
    <item>
      <title>Moving Least Squares without Quasi-Uniformity: A Stochastic Approach</title>
      <link>https://arxiv.org/abs/2601.13782</link>
      <description>arXiv:2601.13782v3 Announce Type: replace 
Abstract: Local Polynomial Regression (LPR) and Moving Least Squares (MLS) are closely related nonparametric estimation methods, developed independently in statistics and approximation theory. While statistical LPR analysis focuses on overcoming sampling noise under probabilistic assumptions, the deterministic MLS theory studies smoothness properties and convergence rates with respect to the \textit{fill-distance} (a resolution parameter). Despite this similarity, the deterministic assumptions underlying MLS fail to hold under random sampling. We begin by quantifying the probabilistic behavior of the fill-distance $h_n$ and \textit{separation} $\delta_n$ of an i.i.d. random sample. That is, for a distribution satisfying a mild regularity condition, $h_n\propto n^{-1/d}\log^{1/d} (n)$ and $\delta_n \propto n^{-2/d}$. We then prove that, for MLS of degree $k\!-\!1$, the approximation error associated with a differential operator $Q$ of order $|m|\le k-1$ decays as $h_n^{\,k-|m|}$ up to logarithmic factors, establishing stochastic analogues of the classical MLS estimates. Additionally, We show that the MLS approximant is smooth with high probability. Finally, we apply the stochastic MLS theory to manifold estimation. Assuming that the sampled Manifold is $k$-times smooth, we show that the Hausdorff distance between the true manifold and its MLS reconstruction decays as $h_n^k$, extending the deterministic Manifold-MLS guarantees to random samples. This work provides the first unified stochastic analysis of MLS, demonstrating that -- despite the failure of deterministic sampling assumptions -- the classical convergence and smoothness properties persist under natural probabilistic models</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.13782v3</guid>
      <category>math.ST</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.TH</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shir Tapiro-Moshe, Yariv Aizenbud, Barak Sober</dc:creator>
    </item>
    <item>
      <title>Some Robustness Properties of Label Cleaning</title>
      <link>https://arxiv.org/abs/2509.11379</link>
      <description>arXiv:2509.11379v2 Announce Type: replace-cross 
Abstract: We demonstrate that learning procedures that rely on aggregated labels, e.g., label information distilled from noisy responses, enjoy robustness properties impossible without data cleaning. This robustness appears in several ways. In the context of risk consistency -- when one takes the standard approach in machine learning of minimizing a surrogate (typically convex) loss in place of a desired task loss (such as the zero-one mis-classification error) -- procedures using label aggregation obtain stronger consistency guarantees than those even possible using raw labels. And while classical statistical scenarios of fitting perfectly-specified models suggest that incorporating all possible information -- modeling uncertainty in labels -- is statistically efficient, consistency fails for ``standard'' approaches as soon as a loss to be minimized is even slightly mis-specified. Yet procedures leveraging aggregated information still converge to optimal classifiers, highlighting how incorporating a fuller view of the data analysis pipeline, from collection to model-fitting to prediction time, can yield a more robust methodology by refining noisy signals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11379v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chen Cheng, John Duchi</dc:creator>
    </item>
    <item>
      <title>Higher-Order Feature Attribution: Bridging Statistics, Explainable AI, and Topological Signal Processing</title>
      <link>https://arxiv.org/abs/2510.06165</link>
      <description>arXiv:2510.06165v2 Announce Type: replace-cross 
Abstract: Feature attributions are post-training analysis methods that assess how various input features of a machine learning model contribute to an output prediction. Their interpretation is straightforward when features act independently, but it becomes less clear when the predictive model involves interactions, such as multiplicative relationships or joint feature contributions. In this work, we propose a general theory of higher-order feature attribution, which we develop on the foundation of Integrated Gradients (IG). This work extends existing frameworks in the literature on explainable AI. When using IG as the method of feature attribution, we discover natural connections to statistics and topological signal processing. We provide several theoretical results that establish the theory, and we validate our theory on a few examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06165v2</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kurt Butler, Guanchao Feng, Petar Djuric</dc:creator>
    </item>
    <item>
      <title>Efficient Group Lasso Regularized Rank Regression with Data-Driven Parameter Determination</title>
      <link>https://arxiv.org/abs/2510.11546</link>
      <description>arXiv:2510.11546v2 Announce Type: replace-cross 
Abstract: High-dimensional regression often suffers from heavy-tailed noise and outliers, which can severely undermine the reliability of least-squares based methods. To improve robustness, we adopt a non-smooth Wilcoxon score based rank objective and incorporate structured group sparsity regularization, a natural generalization of the lasso, yielding a group lasso regularized rank regression method. By extending the tuning-free parameter selection scheme originally developed for the lasso, we introduce a data-driven, simulation-based tuning rule and further establish a finite-sample error bound for the resulting estimator. On the computational side, we develop a proximal augmented Lagrangian method for solving the associated optimization problem, which eliminates the singularity issues encountered in existing methods, thereby enabling efficient semismooth Newton updates for the subproblems. Extensive numerical experiments demonstrate the robustness and effectiveness of our proposed estimator against alternatives, and showcase the scalability of the algorithm across both simulated and real-data settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.11546v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Meixia Lin, Meijiao Shi, Yunhai Xiao, Qian Zhang</dc:creator>
    </item>
  </channel>
</rss>
