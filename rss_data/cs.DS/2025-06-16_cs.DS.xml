<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 17 Jun 2025 02:29:16 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>String Matching with a Dynamic Pattern</title>
      <link>https://arxiv.org/abs/2506.11318</link>
      <description>arXiv:2506.11318v1 Announce Type: new 
Abstract: In this work, we tackle a natural variation of the String Matching Problem on the case of a dynamic pattern, that is, given a static text $T$ and a pattern $P$, we want to support character additions and deletions to the pattern, and after each operation compute how many times it occurs in the text. We show a simple and practical algorithm using Suffix Arrays that achieves $\mathcal O(\log |T|)$ update time, after $\mathcal O(|T|)$ preprocess time. We show how to extend our solution to support substring deletion, transposition (moving a substring to another position of the pattern), and copy (copying a substring and pasting it in a specific position), in the same time complexities. Our solution can also be extended to support an online text (adding characters to one end of the text), maintaining the same amortized bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11318v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bruno Monteiro, Vinicius dos Santos</dc:creator>
    </item>
    <item>
      <title>Isometric-Universal Graphs for Trees</title>
      <link>https://arxiv.org/abs/2506.11704</link>
      <description>arXiv:2506.11704v2 Announce Type: new 
Abstract: We consider the problem of finding the smallest graph that contains two input trees each with at most $n$ vertices preserving their distances. In other words, we look for an isometric-universal graph with the minimum number of vertices for two given trees. We prove that this problem can be solved in time $O(n^{5/2}\log{n})$. We extend this result to forests instead of trees, and propose an algorithm with running time $O(n^{7/2}\log{n})$. As a key ingredient, we show that a smallest isometric-universal graph of two trees essentially is a tree. Furthermore, we prove that these results cannot be extended. Firstly, we show that deciding whether there exists an isometric-universal graph with $t$ vertices for three forests is NP-complete. Secondly, we show that any smallest isometric-universal graph cannot be a tree for some families of three trees. This latter result has implications for greedy strategies solving the smallest isometric-universal graph problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11704v2</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Edgar Baucher, Fran\c{c}ois Dross, Cyril Gavoille</dc:creator>
    </item>
    <item>
      <title>Practical colinear chaining on sequences revisited</title>
      <link>https://arxiv.org/abs/2506.11750</link>
      <description>arXiv:2506.11750v1 Announce Type: new 
Abstract: Colinear chaining is a classical heuristic for sequence alignment and is widely used in modern practical aligners. Jain et al. (J. Comput. Biol. 2022) proposed an $O(n \log^3 n)$ time algorithm to chain a set of $n$ anchors so that the chaining cost matches the edit distance of the input sequences, when anchors are maximal exact matches. Moreover, assuming a uniform and sparse distribution of anchors, they provided a practical solution ($\mathtt{ChainX}$) working in $O(n \cdot \mathsf{SOL} + n \log n)$ average-case time, where $\mathsf{SOL}$ is the cost of the output chain and $n$ is the number of anchors in the input. This practical solution is not guaranteed to be optimal: we study the failing cases, introduce the anchor diagonal distance, and find and implement an optimal algorithm working in the same $O(n \cdot \mathsf{OPT} + n \log n)$ average-case time, where $\mathsf{OPT}$ is the optimal chaining cost; then, we validate the results by Jain et al., show that $\mathtt{ChainX}$ can be suboptimal with a realistic long read dataset, and show minimal computational slowdown for our solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11750v1</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicola Rizzo, Manuel C\'aceres, Veli M\"akinen</dc:creator>
    </item>
    <item>
      <title>Breaking the O(mn)-Time Barrier for Vertex-Weighted Global Minimum Cut</title>
      <link>https://arxiv.org/abs/2506.11926</link>
      <description>arXiv:2506.11926v1 Announce Type: new 
Abstract: We consider the Global Minimum Vertex-Cut problem: given an undirected vertex-weighted graph $G$, compute a minimum-weight subset of its vertices whose removal disconnects $G$. The problem is closely related to Global Minimum Edge-Cut, where the weights are on the graph edges instead of vertices, and the goal is to compute a minimum-weight subset of edges whose removal disconnects the graph. Global Minimum Cut is one of the most basic and extensively studied problems in combinatorial optimization and graph theory. While an almost-linear time algorithm was known for the edge version of the problem for awhile (Karger, STOC 1996 and J. ACM 2000), the fastest previous algorithm for the vertex version (Henzinger, Rao and Gabow, FOCS 1996 and J. Algorithms 2000) achieves a running time of $\tilde{O}(mn)$, where $m$ and $n$ denote the number of edges and vertices in the input graph, respectively. For the special case of unit vertex weights, this bound was broken only recently (Li {et al.}, STOC 2021); their result, combined with the recent breakthrough almost-linear time algorithm for Maximum $s$-$t$ Flow (Chen {et al.}, FOCS 2022, van den Brand {et al.}, FOCS 2023), yields an almost-linear time algorithm for Global Minimum Vertex-Cut with unit vertex weights.
  In this paper we break the $28$ years old bound of Henzinger {et al.} for the general weighted Global Minimum Vertex-Cut, by providing a randomized algorithm for the problem with running time $O(\min\{mn^{0.99+o(1)},m^{1.5+o(1)}\})$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11926v1</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julia Chuzhoy, Ohad Trabelsi</dc:creator>
    </item>
    <item>
      <title>Engineering Fast and Space-Efficient Recompression from SLP-Compressed Text</title>
      <link>https://arxiv.org/abs/2506.12011</link>
      <description>arXiv:2506.12011v1 Announce Type: new 
Abstract: Compressed indexing enables powerful queries over massive and repetitive textual datasets using space proportional to the compressed input. While theoretical advances have led to highly efficient index structures, their practical construction remains a bottleneck (especially for complex components like recompression RLSLP), a grammar-based representation crucial for building powerful text indexes that support widely used suffix array queries.
  In this work, we present the first implementation of recompression RLSLP construction that runs in compressed time, operating on an LZ77-like approximation of the input. Compared to state-of-the-art uncompressed-time methods, our approach achieves up to 46$\times$ speedup and 17$\times$ lower RAM usage on large, repetitive inputs. These gains unlock scalability to larger datasets and affirm compressed computation as a practical path forward for fast index construction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.12011v1</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ankith Reddy Adudodla, Dominik Kempa</dc:creator>
    </item>
    <item>
      <title>Few Single-Qubit Measurements Suffice to Certify Any Quantum State</title>
      <link>https://arxiv.org/abs/2506.11355</link>
      <description>arXiv:2506.11355v1 Announce Type: cross 
Abstract: A fundamental task in quantum information science is \emph{state certification}: testing whether a lab-prepared $n$-qubit state is close to a given hypothesis state. In this work, we show that \emph{every} pure hypothesis state can be certified using only $O(n^2)$ single-qubit measurements applied to $O(n)$ copies of the lab state. Prior to our work, it was not known whether even sub-exponentially many single-qubit measurements could suffice to certify arbitrary states. This resolves the main open question of Huang, Preskill, and Soleimanifar (FOCS 2024, QIP 2024).</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11355v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Meghal Gupta, William He, Ryan O'Donnell</dc:creator>
    </item>
    <item>
      <title>Bounded Memory in Distributed Networks</title>
      <link>https://arxiv.org/abs/2506.11644</link>
      <description>arXiv:2506.11644v1 Announce Type: cross 
Abstract: The recent advent of programmable switches makes distributed algorithms readily deployable in real-world datacenter networks. However, there are still gaps between theory and practice that prevent the smooth adaptation of CONGEST algorithms to these environments. In this paper, we focus on the memory restrictions that arise in real-world deployments. We introduce the $\mu$-CONGEST model where on top of the bandwidth restriction, the memory of nodes is also limited to $\mu$ words, in line with real-world systems. We provide fast algorithms of two main flavors.
  First, we observe that many algorithms in the CONGEST model are memory-intensive and do not work in $\mu$-CONGEST. A prime example of a family of algorithms that use large memory is clique-listing algorithms. We show that the memory issue that arises here cannot be resolved without incurring a cost in the round complexity, by establishing a lower bound on the round complexity of listing cliques in $\mu$-CONGEST. We introduce novel techniques to overcome these issues and generalize the algorithms to work within a given memory bound. Combined with our lower bound, these provide tight tradeoffs between the running time and memory of nodes.
  Second, we show that it is possible to efficiently simulate various families of streaming algorithms in $\mu$-CONGEST. These include fast simulations of $p$-pass algorithms, random order streams, and various types of mergeable streaming algorithms.
  Combining our contributions, we show that we can use streaming algorithms to efficiently generate statistics regarding combinatorial structures in the network. An example of an end result of this type is that we can efficiently identify and provide the per-color frequencies of the frequent monochromatic triangles in $\mu$-CONGEST.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11644v1</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3694906.3743302</arxiv:DOI>
      <dc:creator>Ran Ben Basat, Keren Censor-Hillel, Yi-Jun Chang, Wenchen Han, Dean Leitersdorf, Gregory Schwartzman</dc:creator>
    </item>
    <item>
      <title>Adaptive determinantal scheduling with fairness in wireless networks</title>
      <link>https://arxiv.org/abs/2506.11738</link>
      <description>arXiv:2506.11738v1 Announce Type: cross 
Abstract: We propose a novel framework for wireless network scheduling with fairness using determinantal (point) processes. Our approach incorporates the repulsive nature of determinantal processes, generalizing traditional Aloha protocols that schedule transmissions independently. We formulate the scheduling problem with an utility function representing fairness. We then recast this formulation as a convex optimization problem over a certain class of determinantal point processes called $L$-ensembles, which are particularly suited for statistical and numerical treatments. These determinantal processes, which have already proven valuable in subset learning, offer an attractive approach to network resource scheduling and allocating. We demonstrate the suitability of determinantal processes for network models based on the signal-to-interference-plus-noise ratio (SINR). Our results highlight the potential of determinantal scheduling coupled with fairness. This work bridges recent advances in machine learning with wireless communications, providing a mathematically elegant and computationally tractable approach to network scheduling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11738v1</guid>
      <category>cs.NI</category>
      <category>cs.DS</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>H. P. Keeler, B. B{\l}aszczyszyn</dc:creator>
    </item>
    <item>
      <title>A $4/3$ Approximation for $2$-Vertex-Connectivity</title>
      <link>https://arxiv.org/abs/2305.02240</link>
      <description>arXiv:2305.02240v3 Announce Type: replace 
Abstract: The 2-Vertex-Connected Spanning Subgraph problem (2VCSS) is among the most basic NP-hard (Survivable) Network Design problems: we are given an (unweighted) undirected graph $G$. Our goal is to find a spanning subgraph $S$ of $G$ with the minimum number of edges which is $2$-vertex-connected, namely $S$ remains connected after the deletion of an arbitrary node. 2VCSS is well-studied in terms of approximation algorithms, and the current best (polynomial-time) approximation factor is $10/7$ by Heeger and Vygen [SIDMA'17] (improving on earlier results by Khuller and Vishkin [STOC'92] and Garg, Vempala and Singla [SODA'93]).
  Here we present an improved $4/3$ approximation. Our main technical ingredient is an approximation preserving reduction to a conveniently structured subset of instances which are ``almost'' 3-vertex-connected. The latter reduction might be helpful in future work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.02240v3</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.46298/theoretics.25.13</arxiv:DOI>
      <arxiv:journal_reference>TheoretiCS, Volume 4 (2025), Article 13, 1-44</arxiv:journal_reference>
      <dc:creator>Miguel Bosch-Calvo, Fabrizio Grandoni, Afrouz Jabal Ameli</dc:creator>
    </item>
    <item>
      <title>Spanning Trees Minimizing Branching Costs</title>
      <link>https://arxiv.org/abs/2407.10571</link>
      <description>arXiv:2407.10571v3 Announce Type: replace 
Abstract: The Minimum Branch Vertices Spanning Tree problem aims to find a spanning tree $T$ in a given graph $G$ with the fewest branch vertices, defined as vertices with a degree three or more in $T$. This problem, known to be NP-hard, has attracted significant attention due to its importance in network design and optimization. Extensive research has been conducted on the algorithmic and combinatorial aspects of this problem, with recent studies delving into its fixed-parameter tractability.
  In this paper, we focus primarily on the parameter modular-width. We demonstrate that finding a spanning tree with the minimum number of branch vertices is Fixed-Parameter Tractable (FPT) when considered with respect to modular-width. Additionally, in cases where each vertex in the input graph has an associated cost for serving as a branch vertex, we prove that the problem of finding a spanning tree with the minimum branch cost (i.e., minimizing the sum of the costs of branch vertices) is FPT with respect to neighborhood diversity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10571v3</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Luisa Gargano, Adele A. Rescigno</dc:creator>
    </item>
    <item>
      <title>Bidirectional Dijkstra's Algorithm is Instance-Optimal</title>
      <link>https://arxiv.org/abs/2410.14638</link>
      <description>arXiv:2410.14638v3 Announce Type: replace 
Abstract: Although Dijkstra's algorithm has near-optimal time complexity for the problem of finding a shortest path from a given vertex $s$ to a given vertex $t$, in practice other algorithms are often superior on huge graphs. A prominent example is bidirectional search, which concurrently executes Dijkstra's algorithm forward from $s$ and backward from $t$, and stops when these executions meet.
  In this paper, we give a strong theoretical justification for the use of bidirectional search to find a shortest $st$-path. We prove that for weighted multigraphs, both directed and undirected, a careful implementation of bidirectional search is instance-optimal with respect to the number of edges it examines. That is, we prove that no correct algorithm can outperform our implementation of bidirectional search on any single instance by more than a constant factor.
  For unweighted graphs, we show that bidirectional breadth-first search is instance-optimal up to a factor of $O(\Delta)$ where $\Delta$ is the maximum degree of the graph. We also show that this is best possible.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14638v3</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bernhard Haeupler, Richard Hlad\'ik, Vaclav Rozhon, Robert E. Tarjan, Jakub T\v{e}tek</dc:creator>
    </item>
    <item>
      <title>The Days On Days Off Scheduling Problem</title>
      <link>https://arxiv.org/abs/2410.23056</link>
      <description>arXiv:2410.23056v2 Announce Type: replace 
Abstract: Personnel scheduling problems have received considerable academic attention due to their relevance in various real-world applications. These problems involve preparing feasible schedules for an organization's employees and often account for factors such as qualifications of workers and holiday requests, resulting in complex constraints. While certain versions of the personnel rostering problem are widely acknowledged as NP-hard, there is limited theoretical analysis specific to many of its variants. Many studies simply assert the NP-hardness of the general problem without investigating whether the specific cases they address inherit this computational complexity.
  In this paper, we examine a variant of the personnel scheduling problems, which involves scheduling a homogeneous workforce subject to constraints concerning both the total number and the number of consecutive work days and days off. This problem was claimed to be NP-complete by [Brunner+2013]. In this paper, we prove its NP-completeness and investigate how the combination of constraints contributes to this complexity. Furthermore, we analyze various special cases that arise from the omission of certain parameters, classifying them as either NP-complete or polynomial-time solvable. For the latter, we provide easy-to-implement and efficient algorithms to not only determine feasibility, but also compute a corresponding schedule.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23056v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fabien Nie{\ss}en, Paul Paschmanns</dc:creator>
    </item>
    <item>
      <title>Approximating the total variation distance between spin systems</title>
      <link>https://arxiv.org/abs/2502.05437</link>
      <description>arXiv:2502.05437v2 Announce Type: replace 
Abstract: Spin systems form an important class of undirected graphical models. For two Gibbs distributions $\mu$ and $\nu$ induced by two spin systems on the same graph $G = (V, E)$, we study the problem of approximating the total variation distance $d_{TV}(\mu,\nu)$ with an $\epsilon$-relative error. We propose a new reduction that connects the problem of approximating the TV-distance to sampling and approximate counting. Our applications include the hardcore model and the antiferromagnetic Ising model in the uniqueness regime, the ferromagnetic Ising model, and the general Ising model satisfying the spectral condition.
  Additionally, we explore the computational complexity of approximating the total variation distance $d_{TV}(\mu_S,\nu_S)$ between two marginal distributions on an arbitrary subset $S \subseteq V$. We prove that this problem remains hard even when both $\mu$ and $\nu$ admit polynomial-time sampling and approximate counting algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05437v2</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Weiming Feng, Hongyang Liu, Minji Yang</dc:creator>
    </item>
    <item>
      <title>A bargain for mergesorts -- How to prove your mergesort correct and stable, almost for free</title>
      <link>https://arxiv.org/abs/2403.08173</link>
      <description>arXiv:2403.08173v2 Announce Type: replace-cross 
Abstract: We present a novel characterization of stable mergesort functions using relational parametricity, and show that it implies the functional correctness of mergesort. As a result, one can prove the correctness of several variations of mergesort (e.g., top-down, bottom-up, tail-recursive, non-tail-recursive, smooth, and non-smooth mergesorts) by proving the characteristic property for each variation. Thanks to our characterization and the parametricity translation, we deduced the correctness results, including stability, of various implementations of mergesort for lists, including highly optimized ones, in the Rocq Prover (formerly the Coq Proof Assistant).</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.08173v2</guid>
      <category>cs.LO</category>
      <category>cs.DS</category>
      <category>cs.PL</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cyril Cohen, Kazuhiko Sakaguchi</dc:creator>
    </item>
    <item>
      <title>Faster Algorithms for Fair Max-Min Diversification in $\mathbb{R}^d$</title>
      <link>https://arxiv.org/abs/2404.04713</link>
      <description>arXiv:2404.04713v3 Announce Type: replace-cross 
Abstract: The task of extracting a diverse subset from a dataset, often referred to as maximum diversification, plays a pivotal role in various real-world applications that have far-reaching consequences. In this work, we delve into the realm of fairness-aware data subset selection, specifically focusing on the problem of selecting a diverse set of size $k$ from a large collection of $n$ data points (FairDiv).
  The FairDiv problem is well-studied in the data management and theory community. In this work, we develop the first constant approximation algorithm for FairDiv that runs in near-linear time using only linear space. In contrast, all previously known constant approximation algorithms run in super-linear time (with respect to $n$ or $k$) and use super-linear space. Our approach achieves this efficiency by employing a novel combination of the Multiplicative Weight Update method and advanced geometric data structures to implicitly and approximately solve a linear program. Furthermore, we improve the efficiency of our techniques by constructing a coreset. Using our coreset, we also propose the first efficient streaming algorithm for the FairDiv problem whose efficiency does not depend on the distribution of data points. Empirical evaluation on million-sized datasets demonstrates that our algorithm achieves the best diversity within a minute. All prior techniques are either highly inefficient or do not generate a good solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04713v3</guid>
      <category>cs.DB</category>
      <category>cs.DS</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3654940</arxiv:DOI>
      <arxiv:journal_reference>SIGMOD 2024</arxiv:journal_reference>
      <dc:creator>Yash Kurkure, Miles Shamo, Joseph Wiseman, Sainyam Galhotra, Stavros Sintos</dc:creator>
    </item>
    <item>
      <title>Near-Optimal Sample Complexity for MDPs via Anchoring</title>
      <link>https://arxiv.org/abs/2502.04477</link>
      <description>arXiv:2502.04477v2 Announce Type: replace-cross 
Abstract: We study a new model-free algorithm to compute $\varepsilon$-optimal policies for average reward Markov decision processes, in the weakly communicating case. Given a generative model, our procedure combines a recursive sampling technique with Halpern's anchored iteration, and computes an $\varepsilon$-optimal policy with sample and time complexity $\widetilde{O}(|\mathcal{S}||\mathcal{A}|\|h^*\|_{\text{sp}}^{2}/\varepsilon^{2})$ both in high probability and in expectation. To our knowledge, this is the best complexity among model-free algorithms, matching the known lower bound up to a factor $\|h^*\|_{\text{sp}}$. Although the complexity bound involves the span seminorm $\|h^*\|_{\text{sp}}$ of the unknown bias vector, the algorithm requires no prior knowledge and implements a stopping rule which guarantees with probability 1 that the procedure terminates in finite time. We also analyze how these techniques can be adapted for discounted MDPs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04477v2</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>International Conference on Machine Learning 2025</arxiv:journal_reference>
      <dc:creator>Jongmin Lee, Mario Bravo, Roberto Cominetti</dc:creator>
    </item>
    <item>
      <title>Delegation with Costly Inspection</title>
      <link>https://arxiv.org/abs/2506.07162</link>
      <description>arXiv:2506.07162v2 Announce Type: replace-cross 
Abstract: We study the problem of delegated choice with inspection cost (DCIC), which is a variant of the delegated choice problem by Kleinberg and Kleinberg (EC'18) as well as an extension of the Pandora's box problem with nonobligatory inspection (PNOI) by Doval (JET'18). In our model, an agent may strategically misreport the proposed element's utility, unlike the standard delegated choice problem which assumes that the agent truthfully reports the utility for the proposed alternative. Thus, the principal needs to inspect the proposed element possibly along with other alternatives to maximize its own utility, given an exogenous cost of inspecting each element. Further, the delegation itself incurs a fixed cost, thus the principal can decide whether to delegate or not and inspect by herself.
  We show that DCIC indeed is a generalization of PNOI where the side information from a strategic agent is available at certain cost, implying its NP-hardness by Fu, Li, and Liu (STOC'23). We first consider a costless delegation setting in which the cost of delegation is free. We prove that the maximal mechanism over the pure delegation with a single inspection and an PNOI policy without delegation achieves a $3$-approximation for DCIC with costless delegation, which is further proven to be tight. These results hold even when the cost comes from an arbitrary monotone set function, and can be improved to a $2$-approximation if the cost of inspection is the same for every element. We extend these techniques by presenting a constant factor approximate mechanism for the general setting for rich class of instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.07162v2</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <category>econ.TH</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammad T. Hajiaghayi, Piotr Krysta, Mohammad Mahdavi, Suho Shin</dc:creator>
    </item>
  </channel>
</rss>
