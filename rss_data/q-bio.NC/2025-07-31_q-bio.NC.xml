<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 31 Jul 2025 04:00:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Dimensions of Vulnerability in Visual Working Memory: An AI-Driven Approach to Perceptual Comparison</title>
      <link>https://arxiv.org/abs/2507.22067</link>
      <description>arXiv:2507.22067v1 Announce Type: new 
Abstract: Human memory exhibits significant vulnerability in cognitive tasks and daily life. Comparisons between visual working memory and new perceptual input (e.g., during cognitive tasks) can lead to unintended memory distortions. Previous studies have reported systematic memory distortions after perceptual comparison, but understanding how perceptual comparison affects memory distortions in real-world objects remains a challenge. Furthermore, identifying what visual features contribute to memory vulnerability presents a novel research question. Here, we propose a novel AI-driven framework that generates naturalistic visual stimuli grounded in behaviorally relevant object dimensions to elicit similarity-induced memory biases. We use two types of stimuli -- image wheels created through dimension editing and dimension wheels generated by dimension activation values -- in three visual working memory (VWM) experiments. These experiments assess memory distortions under three conditions: no perceptual comparison, perceptual comparison with image wheels, and perceptual comparison with dimension wheels. The results show that similar dimensions, like similar images, can also induce memory distortions. Specifically, visual dimensions are more prone to distortion than semantic dimensions, indicating that the object dimensions of naturalistic visual stimuli play a significant role in the vulnerability of memory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.22067v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuang Cao, Jiachen Zou, Chen Wei, Quanying Liu</dc:creator>
    </item>
    <item>
      <title>Representation biases: will we achieve complete understanding by analyzing representations?</title>
      <link>https://arxiv.org/abs/2507.22216</link>
      <description>arXiv:2507.22216v1 Announce Type: new 
Abstract: A common approach in neuroscience is to study neural representations as a means to understand a system -- increasingly, by relating the neural representations to the internal representations learned by computational models. However, a recent work in machine learning (Lampinen, 2024) shows that learned feature representations may be biased to over-represent certain features, and represent others more weakly and less-consistently. For example, simple (linear) features may be more strongly and more consistently represented than complex (highly nonlinear) features. These biases could pose challenges for achieving full understanding of a system through representational analysis. In this perspective, we illustrate these challenges -- showing how feature representation biases can lead to strongly biased inferences from common analyses like PCA, regression, and RSA. We also present homomorphic encryption as a simple case study of the potential for strong dissociation between patterns of representation and computation. We discuss the implications of these results for representational comparisons between systems, and for neuroscience more generally.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.22216v1</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrew Kyle Lampinen, Stephanie C. Y. Chan, Yuxuan Li, Katherine Hermann</dc:creator>
    </item>
    <item>
      <title>Decoding Neural Signatures of Semantic Evaluations in Depression and Suicidality</title>
      <link>https://arxiv.org/abs/2507.22313</link>
      <description>arXiv:2507.22313v1 Announce Type: new 
Abstract: Depression and suicidality profoundly impact cognition and emotion, yet objective neurophysiological biomarkers remain elusive. We investigated the spatiotemporal neural dynamics underlying affective semantic processing in individuals with varying levels of clinical severity of depression and suicidality using multivariate decoding of electroencephalography (EEG) data. Participants (N=137) completed a sentence evaluation task involving emotionally charged self-referential statements while EEG was recorded. We identified robust, neural signatures of semantic processing, with peak decoding accuracy between 300-600 ms -- a window associated with automatic semantic evaluation and conflict monitoring. Compared to healthy controls, individuals with depression and suicidality showed earlier onset, longer duration, and greater amplitude decoding responses, along with broader cross-temporal generalization and increased activation of frontocentral and parietotemporal components. These findings suggest altered sensitivity and impaired disengagement from emotionally salient content in the clinical groups, advancing our understanding of the neurocognitive basis of mental health and providing a principled basis for developing reliable EEG-based biomarkers of depression and suicidality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.22313v1</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Woojae Jeong, Aditya Kommineni, Kleanthis Avramidis, Colin McDaniel, Donald Berry, Myzelle Hughes, Thomas McGee, Elsi Kaiser, Dani Byrd, Assal Habibi, B. Rael Cahn, Idan A. Blank, Kristina Lerman, Dimitrios Pantazis, Sudarsana R. Kadiri, Takfarinas Medani, Shrikanth Narayanan, Richard M. Leahy</dc:creator>
    </item>
    <item>
      <title>An Uncertainty Principle for Probabilistic Computation in the Retina</title>
      <link>https://arxiv.org/abs/2507.22785</link>
      <description>arXiv:2507.22785v1 Announce Type: new 
Abstract: We introduce a probabilistic model of early visual processing, beginning with the interaction between a light wavefront and the retina. We argue that perception originates not with deterministic transduction, but with probabilistic threshold crossings shaped by quantum photon arrival statistics and biological variability. We formalize this with an uncertainty relation, \( \Delta \alpha \cdot \Delta t \geq \eta \), through the transformation of light into symbolic neural code through the layered retinal architecture. Our model is supported by previous experimental results, which show intrinsic variability in retinal responses even under fixed stimuli. We contrast this with a classical null hypothesis of deterministic encoding and propose experiments to further test our uncertainty relation. By re-framing the retina as a probabilistic measurement device, we lay the foundation for future models of cortical dynamics rooted in quantum-like computation. We are not claiming that the brain could be working as a quantum-system, but rather putting forth the argument that the brain as a classical system could still implement quantum-inspired computations. We define quantum-inspired computation as a scheme that includes both probabilistic and time-sensitive computation, clearly separating it from classically implementable probabilistic systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.22785v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jayanth R Taranath, Salim M'Jahad</dc:creator>
    </item>
    <item>
      <title>Pendulum Model of Spiking Neurons</title>
      <link>https://arxiv.org/abs/2507.22146</link>
      <description>arXiv:2507.22146v1 Announce Type: cross 
Abstract: We propose a biologically inspired model of spiking neurons based on the dynamics of a damped, driven pendulum. Unlike traditional models such as the Leaky Integrate-and-Fire (LIF) neurons, the pendulum neuron incorporates second-order, nonlinear dynamics that naturally give rise to oscillatory behavior and phase-based spike encoding. This model captures richer temporal features and supports timing-sensitive computations critical for sequence processing and symbolic learning. We present an analysis of single-neuron dynamics and extend the model to multi-neuron layers governed by Spike-Timing Dependent Plasticity (STDP) learning rules. We demonstrate practical implementation with python code and with the Brian2 spiking neural simulator, and outline a methodology for deploying the model on neuromorphic hardware platforms, using an approximation of the second-order equations. This framework offers a foundation for developing energy-efficient neural systems for neuromorphic computing and sequential cognition tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.22146v1</guid>
      <category>cs.NE</category>
      <category>q-bio.NC</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joy Bose</dc:creator>
    </item>
    <item>
      <title>Agency Perception and Brain Synchrony: A Hyperscanning Study of Human-Human and Human-AI Interaction</title>
      <link>https://arxiv.org/abs/2402.17650</link>
      <description>arXiv:2402.17650v3 Announce Type: replace 
Abstract: This study investigates how the human brain differentiates between intentional human agents and artificial intelligence (AI) agents during real-time social interaction. Using functional near-infrared spectroscopy (fNIRS) hyperscanning, we recorded prefrontal brain activity of participants as they played a one-on-one virtual tennis game, once against a human opponent and once against an AI-controlled opponent. Task-related cortical activation was evaluated using the General Linear Model (GLM), while inter-brain synchrony was assessed through Intersubject Correlation (ISC) analysis. Results revealed significantly stronger activation in the medial prefrontal cortex (mPFC) when participants interacted with human opponents, particularly in low-frequency hemodynamic bands (0.0098-0.0196 Hz). Moreover, neural synchrony between human dyads was significantly greater than in pseudo-paired controls, with distinct frequency-specific coupling patterns across channels. In contrast, AI interactions elicited reduced cortical engagement and no measurable inter-brain synchrony. These findings suggest that the perception of intentionality strongly modulates social brain responses, even when task structure and behavior remain constant. This work highlights the utility of fNIRS hyperscanning for studying naturalistic human interactions and provides neural evidence for the brain's sensitivity to perceived agency. The results have implications for the design of socially interactive AI systems that more effectively engage human cognition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.17650v3</guid>
      <category>q-bio.NC</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad Ghalavand, Javad Hatami, Seyed Kamaledin Setarehdan, Fatimah Nosrati, Hananeh Ghalavand, Ali Nikhalat-Jahromi</dc:creator>
    </item>
    <item>
      <title>Signed Higher-Order Interactions for Brain Disorder Diagnosis via Multi-Channel Transformers</title>
      <link>https://arxiv.org/abs/2507.20205</link>
      <description>arXiv:2507.20205v3 Announce Type: replace 
Abstract: Accurately characterizing higher-order interactions of brain regions and extracting interpretable organizational patterns from Functional Magnetic Resonance Imaging data is crucial for brain disease diagnosis. Current graph-based deep learning models primarily focus on pairwise or triadic patterns while neglecting signed higher-order interactions, limiting comprehensive understanding of brain-wide communication. We propose HOI-Brain, a novel computational framework leveraging signed higher-order interactions and organizational patterns in fMRI data for brain disease diagnosis. First, we introduce a co-fluctuation measure based on Multiplication of Temporal Derivatives to detect higher-order interactions with temporal resolution. We then distinguish positive and negative synergistic interactions, encoding them in signed weighted simplicial complexes to reveal brain communication insights. Using Persistent Homology theory, we apply two filtration processes to these complexes to extract signed higher-dimensional neural organizations spatiotemporally. Finally, we propose a multi-channel brain Transformer to integrate heterogeneous topological features. Experiments on Alzheimer' s disease, Parkinson' s syndrome, and autism spectrum disorder datasets demonstrate our framework' s superiority, effectiveness, and interpretability. The identified key brain regions and higher-order patterns align with neuroscience literature, providing meaningful biological insights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.20205v3</guid>
      <category>q-bio.NC</category>
      <category>cs.GR</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dengyi Zhao, Zhiheng Zhou, Guiying Yan, Dongxiao Yu, Xingqin Qi</dc:creator>
    </item>
    <item>
      <title>Unsupervised Learning in Echo State Networks for Input Reconstruction</title>
      <link>https://arxiv.org/abs/2501.11409</link>
      <description>arXiv:2501.11409v4 Announce Type: replace-cross 
Abstract: Echo state networks (ESNs) are a class of recurrent neural networks in which only the readout layer is trainable, while the recurrent and input layers are fixed. This architectural constraint enables computationally efficient processing of time-series data. Traditionally, the readout layer in ESNs is trained using supervised learning with target outputs. In this study, we focus on input reconstruction (IR), where the readout layer is trained to reconstruct the input time series fed into the ESN. We show that IR can be achieved through unsupervised learning (UL), without access to supervised targets, provided that the ESN parameters are known a priori and satisfy invertibility conditions. This formulation allows applications relying on IR, such as dynamical system replication and noise filtering, to be reformulated within the UL framework via straightforward integration with existing algorithms. Our results suggest that prior knowledge of ESN parameters can reduce reliance on supervision, thereby establishing a new principle: not only by fixing part of the network parameters but also by exploiting their specific values. Furthermore, our UL-based algorithms for input reconstruction and related tasks are suitable for autonomous processing, offering insights into how analogous computational mechanisms might operate in the brain in principle. These findings contribute to a deeper understanding of the mathematical foundations of ESNs and their relevance to models in computational neuroscience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11409v4</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>eess.SP</category>
      <category>nlin.CD</category>
      <category>q-bio.NC</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Taiki Yamada, Yuichi Katori, Kantaro Fujiwara</dc:creator>
    </item>
    <item>
      <title>Simple low-dimensional computations explain variability in neuronal activity</title>
      <link>https://arxiv.org/abs/2504.08637</link>
      <description>arXiv:2504.08637v2 Announce Type: replace-cross 
Abstract: Our understanding of neural computation is founded on the assumption that neurons fire in response to a linear summation of inputs. Yet experiments demonstrate that some neurons are capable of complex computations that require interactions between inputs. Here we show, across multiple brain regions and species, that simple computations (without interactions between inputs) explain most of the variability in neuronal activity. Neurons are quantitatively described by models that capture the measured dependence on each input individually, but assume nothing about combinations of inputs. These minimal models, which are equivalent to binary artificial neurons, predict complex higher-order dependencies and recover known features of synaptic connectivity. The inferred computations are low-dimensional, indicating a highly redundant neural code that is necessary for error correction. These results suggest that, despite intricate biophysical details, most neurons perform simple computations typically reserved for artificial models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.08637v2</guid>
      <category>physics.bio-ph</category>
      <category>q-bio.NC</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christopher W. Lynn</dc:creator>
    </item>
  </channel>
</rss>
