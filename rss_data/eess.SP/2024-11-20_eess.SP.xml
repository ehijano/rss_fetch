<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>eess.SP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/eess.SP</link>
    <description>eess.SP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/eess.SP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 20 Nov 2024 05:00:15 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Radiance Field Delta Video Compression in Edge-Enabled Vehicular Metaverse</title>
      <link>https://arxiv.org/abs/2411.11857</link>
      <description>arXiv:2411.11857v1 Announce Type: new 
Abstract: Connected and autonomous vehicles (CAVs) offload computationally intensive tasks to multi-access edge computing (MEC) servers via vehicle-to-infrastructure (V2I) communication, enabling applications within the vehicular metaverse, which transforms physical environment into the digital space enabling advanced analysis or predictive modeling. A core challenge is physical-to-virtual (P2V) synchronization through digital twins (DTs), reliant on MEC networks and ultra-reliable low-latency communication (URLLC). To address this, we introduce radiance field (RF) delta video compression (RFDVC), which uses RF-encoder and RF-decoder architecture using distributed RFs as DTs storing photorealistic 3D urban scene in compressed form. This method extracts differences between CAV-frame capturing actual traffic and RF-frame capturing empty scene from the same pose in batches encoded and transmitted over the MEC network. Experiments show data savings up to 90% against H.264 codec and 45% against H.265 codec under different conditions as lighting changes, rain and fog. RFDVC exhibits greater resilience to transmission errors, achieving a bit error rate (BER) of approximately 10^-1.6 at signal-to-noise ratio (SNR) of 10 dB, compared to 10^-1.4 for standard video coding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11857v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mat\'u\v{s} Dopiriak, Eugen \v{S}lapak, Juraj Gazda, Devendra S. Gurjar, Mohammad Abdullah Al Faruque, Marco Levorato</dc:creator>
    </item>
    <item>
      <title>Machine Learning Assisted Postural Movement Recognition using Photoplethysmography(PPG)</title>
      <link>https://arxiv.org/abs/2411.11862</link>
      <description>arXiv:2411.11862v1 Announce Type: new 
Abstract: With the growing percentage of elderly people and care home admissions, there is an urgent need for the development of fall detection and fall prevention technologies. This work presents, for the first time, the use of machine learning techniques to recognize postural movements exclusively from Photoplethysmography (PPG) data. To achieve this goal, a device was developed for reading the PPG signal, segmenting the PPG signals into individual pulses, extracting pulse morphology and homeostatic characteristic features, and evaluating different ML algorithms. Investigations into different postural movements (stationary, sitting to standing, and lying to standing) were performed by 11 participants. The results of these investigations provided insight into the differences in homeostasis after the movements in the PPG signal. Various machine learning approaches were used for classification, and the Artificial Neural Network (ANN) was found to be the best classifier, with a testing accuracy of 85.2\% and an F1 score of 78\% from experimental results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11862v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Robbie Maccay, Roshan Weerasekera</dc:creator>
    </item>
    <item>
      <title>Longitudinal Wrist PPG Analysis for Reliable Hypertension Risk Screening Using Deep Learning</title>
      <link>https://arxiv.org/abs/2411.11863</link>
      <description>arXiv:2411.11863v1 Announce Type: new 
Abstract: Hypertension is a leading risk factor for cardiovascular diseases. Traditional blood pressure monitoring methods are cumbersome and inadequate for continuous tracking, prompting the development of PPG-based cuffless blood pressure monitoring wearables. This study leverages deep learning models, including ResNet and Transformer, to analyze wrist PPG data collected with a smartwatch for efficient hypertension risk screening, eliminating the need for handcrafted PPG features. Using the Home Blood Pressure Monitoring (HBPM) longitudinal dataset of 448 subjects and five-fold cross-validation, our model was trained on over 68k spot-check instances from 358 subjects and tested on real-world continuous recordings of 90 subjects. The compact ResNet model with 0.124M parameters performed significantly better than traditional machine learning methods, demonstrating its effectiveness in distinguishing between healthy and abnormal cases in real-world scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11863v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hui Lin, Jiyang Li, Ramy Hussein, Xin Sui, Xiaoyu Li, Guangpu Zhu, Aggelos K. Katsaggelos, Zijing Zeng, Yelei Li</dc:creator>
    </item>
    <item>
      <title>Efficient Realization of Multi-channel Visible Light Communication System for Dynamic Cross-Water Surface Channels</title>
      <link>https://arxiv.org/abs/2411.11866</link>
      <description>arXiv:2411.11866v1 Announce Type: new 
Abstract: This paper explores the transmission schemes for multi-channel water-to-air optical wireless communication (W2A-OWC) and introduces a prototype of a real-time W2A-OWC system based on a field-programmable gate array (FPGA). Utilizing an LED array as the transmitter and an APD array as the receiver, the system establishes a multi-channel transmission module. Such configuration enables parallel operation of multiple channels, facilitating the simultaneous transmission of multiple data streams and enhancing overall throughput. The FPGA serves as a real-time signal processing unit, handling both signal transmission and reception. By integrating low-density parity-check (LDPC) codes from 5G New Radio, the system significantly boosts its detection capabilities for dynamic W2A-OWC scenarios. The system also optimizes FPGA resource usage through time-multiplexing operation of an LDPC decoder's IP core. To evaluate the system's practicality, experiments were conducted under background radiation in an indoor water tank, measuring the frame error rate under both calm and fluctuating water surfaces. The experimental results confirm the feasibility and effectiveness of the developed W2A-OWC system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11866v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Han Qi, Tianrui Lin, Tianjian Wei, Qingqing Hu, Siyan Sun, Nuo Huang, Chen Gong</dc:creator>
    </item>
    <item>
      <title>A Multi-Modal Unsupervised Machine Learning Approach for Biomedical Signal Processing in CPR</title>
      <link>https://arxiv.org/abs/2411.11869</link>
      <description>arXiv:2411.11869v1 Announce Type: new 
Abstract: Cardiopulmonary resuscitation (CPR) is a critical, life-saving intervention aimed at restoring blood circulation and breathing in individuals experiencing cardiac arrest or respiratory failure. Accurate and real-time analysis of biomedical signals during CPR is essential for monitoring and decision-making, from the pre-hospital stage to the intensive care unit (ICU). However, CPR signals are often corrupted by noise and artifacts, making precise interpretation challenging. Traditional denoising methods, such as filters, struggle to adapt to the varying and complex noise patterns present in CPR signals. Given the high-stakes nature of CPR, where rapid and accurate responses can determine survival, there is a pressing need for more robust and adaptive denoising techniques. In this context, an unsupervised machine learning (ML) methodology is particularly valuable, as it removes the dependence on labeled data, which can be scarce or impractical in emergency scenarios. This paper introduces a novel unsupervised ML approach for denoising CPR signals using a multi-modality framework, which leverages multiple signal sources to enhance the denoising process. The proposed approach not only improves noise reduction and signal fidelity but also preserves critical inter-signal correlations (0.9993) which is crucial for downstream tasks. Furthermore, it outperforms existing methods in an unsupervised context in terms of signal-to-noise ratio (SNR) and peak signal-to-noise ratio (PSNR), making it highly effective for real-time applications. The integration of multi-modality further enhances the system's adaptability to various biomedical signals beyond CPR, improving both automated CPR systems and clinical decision-making.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11869v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Saidul Islam, Jamal Bentahar, Robin Cohen, Gaith Rjoub</dc:creator>
    </item>
    <item>
      <title>Towards a Network Expansion Approach for Reliable Brain-Computer Interface</title>
      <link>https://arxiv.org/abs/2411.11872</link>
      <description>arXiv:2411.11872v1 Announce Type: new 
Abstract: Robotic arms are increasingly being used in collaborative environments, requiring an accurate understanding of human intentions to ensure both effectiveness and safety. Electroencephalogram (EEG) signals, which measure brain activity, provide a direct means of communication between humans and robotic systems. However, the inherent variability and instability of EEG signals, along with their diverse distribution, pose significant challenges in data collection and ultimately affect the reliability of EEG-based applications. This study presents an extensible network designed to improve its ability to extract essential features from EEG signals. This strategy focuses on improving performance by increasing network capacity through expansion when learning performance is insufficient. Evaluations were conducted in a pseudo-online format. Results showed that the proposed method outperformed control groups over three sessions and yielded competitive performance, confirming the ability of the network to be calibrated and personalized with data from new sessions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11872v1</guid>
      <category>eess.SP</category>
      <category>cs.HC</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Byeong-Hoo Lee, Kang Yin</dc:creator>
    </item>
    <item>
      <title>Personalized Continual EEG Decoding Framework for Knowledge Retention and Transfer</title>
      <link>https://arxiv.org/abs/2411.11874</link>
      <description>arXiv:2411.11874v1 Announce Type: new 
Abstract: The significant inter-subject variability in electroencephalogram (EEG) signals often leads to knowledge being overwritten as new tasks are introduced in continual EEG decoding. While retraining on the entire dataset with each new input can prevent forgetting, this approach incurs high computational costs. An ideal brain-computer interface (BCI) model should continuously learn new information without retraining from scratch, thus reducing these costs. Most transfer learning models rely on large source-domain datasets for pre-training, yet data availability is frequently limited in real-world applications due to privacy concerns. Furthermore, such models are prone to catastrophic forgetting in continual EEG decoding tasks. To address these challenges, we propose a personalized subject-incremental learning (SIL) framework for continual EEG decoding that integrates Euclidean Alignment for fast domain adaptation, an exemplar replay mechanism to retain prior knowledge, and reservoir sampling-based memory management to handle memory constraints in long-term learning. Validated on the OpenBMI dataset with 54 subjects, our framework effectively balances knowledge retention with classification performance in continual MI-EEG tasks, offering a scalable solution for real-world BCI applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11874v1</guid>
      <category>eess.SP</category>
      <category>cs.HC</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dan Li, Hye-Bin Shin, Kang Yin</dc:creator>
    </item>
    <item>
      <title>CSP-Net: Common Spatial Pattern Empowered Neural Networks for EEG-Based Motor Imagery Classification</title>
      <link>https://arxiv.org/abs/2411.11879</link>
      <description>arXiv:2411.11879v1 Announce Type: new 
Abstract: Electroencephalogram-based motor imagery (MI) classification is an important paradigm of non-invasive brain-computer interfaces. Common spatial pattern (CSP), which exploits different energy distributions on the scalp while performing different MI tasks, is very popular in MI classification. Convolutional neural networks (CNNs) have also achieved great success, due to their powerful learning capabilities. This paper proposes two CSP-empowered neural networks (CSP-Nets), which integrate knowledge-driven CSP filters with data-driven CNNs to enhance the performance in MI classification. CSP-Net-1 directly adds a CSP layer before a CNN to improve the input discriminability. CSP-Net-2 replaces a convolutional layer in CNN with a CSP layer. The CSP layer parameters in both CSP-Nets are initialized with CSP filters designed from the training data. During training, they can either be kept fixed or optimized using gradient descent. Experiments on four public MI datasets demonstrated that the two CSP-Nets consistently improved over their CNN backbones, in both within-subject and cross-subject classifications. They are particularly useful when the number of training samples is very small. Our work demonstrates the advantage of integrating knowledge-driven traditional machine learning with data-driven deep learning in EEG-based brain-computer interfaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11879v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.knosys.2024.112668</arxiv:DOI>
      <arxiv:journal_reference>Knowledge Based Systems, 305:112668, 2024</arxiv:journal_reference>
      <dc:creator>Xue Jiang, Lubin Meng, Xinru Chen, Yifan Xu, Dongrui Wu</dc:creator>
    </item>
    <item>
      <title>How Many Data are Enough? Optimization of Data Collection for Artifact Detection in EEG Recordings</title>
      <link>https://arxiv.org/abs/2411.11886</link>
      <description>arXiv:2411.11886v1 Announce Type: new 
Abstract: Objective. Electroencephalography (EEG) is a widely used neuroimaging technique known for its cost-effectiveness and user-friendliness. However, the presence of various artifacts, particularly biological artifacts like Electromyography (EMG) ones, leads to a poor signal-to-noise ratio, limiting the precision of analyses and applications. The currently reported EEG data cleaning performance largely depends on the data used for validation, and in the case of machine learning approaches, also on the data used for training. The data are typically gathered either by recruiting subjects to perform specific artifact tasks or by integrating existing datasets. Prevailing approaches, however, tend to rely on intuitive, concept-oriented data collection with minimal justification for the selection of artifacts and their quantities. Given the substantial costs associated with biological data collection and the pressing need for effective data utilization, we propose an optimization procedure for data-oriented data collection design using deep learning-based artifact detection. Approach. We apply a binary classification between artifact epochs (time intervals containing artifacts) and non-artifact epochs (time intervals containing no artifact) using three different architectures. Our aim is to minimize data collection efforts while preserving the cleaning efficiency. Main results. We were able to reduce the number of artifact tasks from twelve to three and decrease repetitions of isometric contraction tasks from ten to three or sometimes even just one. Significance. Our work addresses the need for effective data utilization in biological data collection, offering a systematic and dynamic quantitative approach. By providing clear justifications for the choices of artifacts and their quantity, we aim to guide future studies toward more effective and economical data collection in EEG and EMG research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11886v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lu Wang-N\"oth, Philipp Heiler, Hai Huang, Daniel Lichtenstern, Alexandra Reichenbach, Luis Flacke, Linus Maisch, Helmut Mayer</dc:creator>
    </item>
    <item>
      <title>HeartBERT: A Self-Supervised ECG Embedding Model for Efficient and Effective Medical Signal Analysis</title>
      <link>https://arxiv.org/abs/2411.11896</link>
      <description>arXiv:2411.11896v1 Announce Type: new 
Abstract: The HeartBert model is introduced with three primary objectives: reducing the need for labeled data, minimizing computational resources, and simultaneously improving performance in machine learning systems that analyze Electrocardiogram (ECG) signals. Inspired by Bidirectional Encoder Representations from Transformers (BERT) in natural language processing and enhanced with a self-supervised learning approach, the HeartBert model-built on the RoBERTa architecture-generates sophisticated embeddings tailored for ECG-based projects in the medical domain. To demonstrate the versatility, generalizability, and efficiency of the proposed model, two key downstream tasks have been selected: sleep stage detection and heartbeat classification. HeartBERT-based systems, utilizing bidirectional LSTM heads, are designed to address complex challenges. A series of practical experiments have been conducted to demonstrate the superiority and advancements of HeartBERT, particularly in terms of its ability to perform well with smaller training datasets, reduced learning parameters, and effective performance compared to rival models. The code and data are publicly available at https://github.com/ecgResearch/HeartBert.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11896v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Saedeh Tahery, Fatemeh Hamid Akhlaghi, Termeh Amirsoleimani, Saeed Farzi</dc:creator>
    </item>
    <item>
      <title>Preprocessing for lessening the influence of eye artifacts in eeg analysis</title>
      <link>https://arxiv.org/abs/2411.12092</link>
      <description>arXiv:2411.12092v1 Announce Type: new 
Abstract: We dealt with the problem of artifacts in eeg signals in relation to the usage of lengthy trials. Specifically, we considered eye artifacts found in eeg signals,their influence in the analysis of the data and alternatives to diminish their impact on later studies of brain activity on lengthy tasks. We proposed a scheme of partial rejection on independent signal components, providesd a method to extract eeg signal components with diministhed influence of eye artifacts, and assess the importance of using artifact free signal excerpts to extract signal components in order to analyze brain activity in a musical context.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12092v1</guid>
      <category>eess.SP</category>
      <category>cs.IR</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.3390/app9091757</arxiv:DOI>
      <arxiv:journal_reference>Appl. Sci. 2019, 9, 1757</arxiv:journal_reference>
      <dc:creator>Alejandro Villena, Lorenzo J. Tardon, Isabel Barbancho, Ana M. Barbancho, Elvira Brattico, Niels T. Haumann</dc:creator>
    </item>
    <item>
      <title>From Centralized RAN to Open RAN: A Survey on the Evolution of Distributed Antenna Systems</title>
      <link>https://arxiv.org/abs/2411.12166</link>
      <description>arXiv:2411.12166v1 Announce Type: new 
Abstract: Next-generation mobile networks require evolved radio access network (RAN) architectures to meet the demands of high capacity, massive connectivity, reduced costs, and energy efficiency, and to realize communication with ultra-low latency and ultra-high reliability. {Meeting such} requirements for both mobile users and vertical industries in the next decade {requires novel solutions. One of the potential solutions that attracted significant research attention in the past 15 years} is to redesign the radio access network (RAN). In this survey, we present a comprehensive survey on distributed antenna system (DAS) architectures that address these challenges and improve network performance. We cover the transition from traditional decentralized RAN to DAS, including cloud radio-access networks (C-RAN), fog radio-access networks (F-RAN), virtualized radio-access networks (V-RAN), cell-free massive multiple-input multiple-output (CF-mMIMO), and {the most recent advances manifested in} open radio-access network (O-RAN). In the process, we discuss the benefits and limitations of these architectures, including the impact of limited-capacity fronthaul links, various cooperative uplink and downlink coding strategies, cross-layer optimization, and techniques to optimize the performance of DAS. Moreover, we review key enabling technologies for next-generation RAN systems, such as multi-access edge computing, network function virtualization, software-defined networking, and network slicing; in addition to some crucial radio access technologies, such as millimeter wave, massive multi-input multi-output, device-to-device communication, and massive machine-type communication. Last but not least, we discuss the major research challenges in DAS and identify several possible directions for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12166v1</guid>
      <category>eess.SP</category>
      <category>cs.ET</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mahmoud A. Hasabelnaby, Mohanad Obeed, Mohammed Saif, Anas Chaaban, M. J. Hossain</dc:creator>
    </item>
    <item>
      <title>Robust Deep Joint Source-Channel Coding Enabled Distributed Image Transmission with Imperfect Channel State Information</title>
      <link>https://arxiv.org/abs/2411.12228</link>
      <description>arXiv:2411.12228v1 Announce Type: new 
Abstract: This work is concerned with robust distributed multi-view image transmission over a severe fading channel with imperfect channel state information (CSI), wherein the sources are slightly correlated. Since the signals are further distorted at the decoder, traditional distributed deep joint source-channel coding (DJSCC) suffers considerable performance degradation. To tackle this problem, we leverage the complementarity and consistency characteristics among the distributed, yet correlated sources, and propose an enhanced robust DJSCC, namely RDJSCC. In RDJSCC, we design a novel cross-view information extraction (CVIE) mechanism to capture more nuanced cross-view patterns and dependencies. In addition, a complementarity-consistency fusion (CCF) mechanism is utilized to fuse the complementarity and consistency from multi-view information in a symmetric and compact manner. Theoretical analysis and simulation results show that our proposed RDJSCC can effectively leverage the advantages of correlated sources even under severe fading conditions, leading to an improved reconstruction performance. The open source code of this work is available at:https://dongbiao26.github.io/rdjscc/.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12228v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Biao Dong, Bin Cao, Guan Gui, Qinyu Zhang</dc:creator>
    </item>
    <item>
      <title>Modeling and Analysis of Terahertz Wave Propagation in Charged Dust Using Extended Mie Scattering Theory</title>
      <link>https://arxiv.org/abs/2411.12296</link>
      <description>arXiv:2411.12296v1 Announce Type: new 
Abstract: Terahertz (THz) band (0.1-10 THz) possesses multi-gigahertz continuous bandwidth resources, making it a promising frequency band for high-speed wireless communications and environment sensing. The interaction between the THz wave and the external environment has been studied for various scenarios. However, it has recently been revealed that the friction forces in dust storms as well as the irradiation of sunlight and solar wind lead to the electrification of dust particles on Earth and the Moon. The THz wave propagation in these charged dust has not been fully investigated, which is essential for THz aerial communications in dust storms and lunar communications. In this paper, a channel model for THz wave propagation in charged dust is developed for wireless communications. Specifically, an extended Mie scattering model for charged dust is first introduced, which captures the electrodynamic feature of the interaction between THz wave and charged particles. Then, the diameter and density distributions of dust particles are modeled, based on which the propagation loss of THz wave in charged dust is modeled and elaborated. Finally, numerical results on the additional loss caused by these charged dust with different sizes in the THz band are evaluated and compared. Extensive results demonstrate that as the number of dust charges increases, the extinction cross section of smaller-sized particles significantly increases, and the overall attenuation led by charged dust increases by at most 50% at 0.3 THz.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12296v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weijun Gao, Chong Han</dc:creator>
    </item>
    <item>
      <title>Dual-Functional FMCW Waveform for Terahertz Space Debris Detection and Inter-Satellite Communications</title>
      <link>https://arxiv.org/abs/2411.12298</link>
      <description>arXiv:2411.12298v1 Announce Type: new 
Abstract: Terahertz (THz) band communication, ranging from 0.1 THz to 10 THz, is envisioned as a key enabling technology for next-generation networks and future applications such as inter-satellite communications and environmental sensing. The surging number of space debris in Low Earth Orbit poses a big threat to orbital infrastructure and the development of the space economy. In particular, despite the ability to detect and track large-scale space debris, millions of space debris with a radius within the range of 0.1-10 cm and velocity exceeding 1 km/s remains hard to detect with conventional ground-based radars and optical telescopes. In this study, a dual-functional frequency modulated continuous waveform (FMCW) operating in the THz band is adopted for space debris sensing and inter-satellite communications. Specifically, the radar cross section of space debris with various sizes in the THz band is analyzed to demonstrate the feasibility of THz space debris detection. A joint space debris detection and inter-satellite communications based on the FMCW waveform is derived. Then, the parameter estimation and demodulation algorithms are illustrated. Extensive simulations demonstrate that the proposed method can realize high-accuracy parameter estimation of hypervelocity space debris while achieving high reliability for inter-satellite communications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12298v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhepu Yin, Weijun Gao, Chong Han</dc:creator>
    </item>
    <item>
      <title>Temperature-Aware Phase-shift Design of LC-RIS for Secure Communication</title>
      <link>https://arxiv.org/abs/2411.12342</link>
      <description>arXiv:2411.12342v1 Announce Type: new 
Abstract: Liquid crystal (LC) technology enables low-power and cost-effective solutions for implementing the reconfigurable intelligent surface (RIS). However, the phase-shift response of LC-RISs is temperature-dependent, which, if unaddressed, can degrade the performance. This issue is particularly critical in applications such as secure communications, where variations in phase-shift response may lead to significant information leakage. In this paper, we consider secure communication through an LC-RIS and developed a temperature-aware algorithm adapting the RIS phase shifts to thermal conditions. Our simulation results demonstrate that the proposed algorithm significantly improves the secure data rate compared to scenarios where temperature variations are not accounted for.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12342v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohamadreza Delbari, Bowu Wang, Nairy Moghadas Gholian, Arash Asadi, Vahid Jamali</dc:creator>
    </item>
    <item>
      <title>Bi-LSTM neural network for EEG-based error detection in musicians' performance</title>
      <link>https://arxiv.org/abs/2411.12400</link>
      <description>arXiv:2411.12400v1 Announce Type: new 
Abstract: Electroencephalography (EEG) is a tool that allows us to analyze brain activity with high temporal resolution. These measures, combined with deep learning and digital signal processing, are widely used in neurological disorder detection and emotion and mental activity recognition. In this paper, a new method for mental activity recognition is presented; instantaneous frequency, spectral entropy and Mel-frequency cepstral coefficients (MFCC) are used to classify EEG signals using bidirectional LSTM neural networks. It is shown that this method can be used for intra-subject or inter-subject analysis and has been applied to error detection in musician performance reaching compelling accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12400v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.bspc.2022.103885</arxiv:DOI>
      <arxiv:journal_reference>Biomedical Signal Proces. and Control, Vol.78, 2022</arxiv:journal_reference>
      <dc:creator>Isaac Ariza, Lorenzo J. Tardon, Ana M. Barbancho, Irene De-Torres, Isabel Barbancho</dc:creator>
    </item>
    <item>
      <title>Resolution Improvement in OFDM-based Joint Communication and Sensing through Combined Tracking and Interpolation</title>
      <link>https://arxiv.org/abs/2411.12464</link>
      <description>arXiv:2411.12464v1 Announce Type: new 
Abstract: We investigate a monostatic orthogonal frequency-division multiplexing (OFDM)-based joint communication and sensing (JCAS) system with multiple antennas for object tracking. The native resolution of OFDM sensing, and radar sensing in general, is limited by the observation time and bandwidth. In this work, we improve the resolution through interpolation methods and tracking algorithms. We verify the resolution enhancement by comparing the root mean squared error (RMSE) of the estimated range, velocity and angle and by comparing the mean Euclidean distance between the estimated and true position. We demonstrate how both a Kalman filter for tracking, and interpolation methods using zero-padding and the chirp Z-transform (CZT) improve the estimation error. We discuss the computational complexity of the different methods. We propose the KalmanCZT approach that combines tracking via Kalman filtering and interpolation via the CZT, resulting in a solution with flexible resolution that significantly improves the range RMSE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12464v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Charlotte Muth, Leon Schmidt, Shrinivas Chimmalgi, Laurent Schmalen</dc:creator>
    </item>
    <item>
      <title>AI Flow at the Network Edge</title>
      <link>https://arxiv.org/abs/2411.12469</link>
      <description>arXiv:2411.12469v1 Announce Type: new 
Abstract: Recent advancements in large language models (LLMs) and their multimodal variants have led to remarkable progress across various domains, demonstrating impressive capabilities and unprecedented potential. In the era of ubiquitous connectivity, leveraging communication networks to distribute intelligence is a transformative concept, envisioning AI-powered services accessible at the network edge. However, pushing large models from the cloud to resource-constrained environments faces critical challenges. Model inference on low-end devices leads to excessive latency and performance bottlenecks, while raw data transmission over limited bandwidth networks causes high communication overhead. This article presents AI Flow, a framework that streamlines the inference process by jointly leveraging the heterogeneous resources available across devices, edge nodes, and cloud servers, making intelligence flow across networks. To facilitate cooperation among multiple computational nodes, the proposed framework explores a paradigm shift in the design of communication network systems from transmitting information flow to intelligence flow, where the goal of communications is task-oriented and folded into the inference process. Experimental results demonstrate the effectiveness of the proposed framework through an image captioning use case, showcasing the ability to reduce response latency while maintaining high-quality captions. This article serves as a position paper for identifying the motivation, challenges, and principles of AI Flow.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12469v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiawei Shao, Xuelong Li</dc:creator>
    </item>
    <item>
      <title>High-Throughput Blind Co-Channel Interference Cancellation for Edge Devices Using Depthwise Separable Convolutions, Quantization, and Pruning</title>
      <link>https://arxiv.org/abs/2411.12541</link>
      <description>arXiv:2411.12541v1 Announce Type: new 
Abstract: Co-channel interference cancellation (CCI) is the process used to reduce interference from other signals using the same frequency channel, thereby enhancing the performance of wireless communication systems. An improvement to this approach is blind CCI, which reduces interference without relying on prior knowledge of the interfering signal characteristics. Recent work suggested using machine learning (ML) models for this purpose, but high-throughput ML solutions are still lacking, especially for edge devices with limited resources. This work explores the adaptation of U-Net Convolutional Neural Network models for high-throughput blind source separation. Our approach is established on architectural modifications, notably through quantization and the incorporation of depthwise separable convolution, to achieve a balance between computational efficiency and performance. Our results demonstrate that the proposed models achieve superior MSE scores when removing unknown interference sources from the signals while maintaining significantly lower computational complexity compared to baseline models. One of our proposed models is deeper and fully convolutional, while the other is shallower with a convolutional structure incorporating an LSTM. Depthwise separable convolution and quantization further reduce the memory footprint and computational demands, albeit with some performance trade-offs. Specifically, applying depthwise separable convolutions to the model with the LSTM results in only a 0.72% degradation in MSE score while reducing MACs by 58.66%. For the fully convolutional model, we observe a 0.63% improvement in MSE score with even 61.10% fewer MACs. Overall, our findings underscore the feasibility of using optimized machine-learning models for interference cancellation in devices with limited resources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12541v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mostafa Naseri, Eli De Poorter, Ingrid Moerman, H. Vincent Poor, Adnan Shahid</dc:creator>
    </item>
    <item>
      <title>Power Efficient Cooperative Communication within IIoT Subnetworks: Relay or RIS?</title>
      <link>https://arxiv.org/abs/2411.12557</link>
      <description>arXiv:2411.12557v1 Announce Type: new 
Abstract: The forthcoming sixth-generation (6G) industrial Internet-of-Things (IIoT) subnetworks are expected to support ultra-fast control communication cycles for numerous IoT devices. However, meeting the stringent requirements for low latency and high reliability poses significant challenges, particularly due to signal fading and physical obstructions. In this paper, we propose novel time division multiple access (TDMA) and frequency division multiple access (FDMA) communication protocols for cooperative transmission in IIoT subnetworks. These protocols leverage secondary access points (sAPs) as Decode-and-Forward (DF) and Amplify-and-Forward (AF) relays, enabling shorter cycle times while minimizing overall transmit power. A classification mechanism determines whether the highest-gain link for each IoT device is a single-hop or two-hop connection, and selects the corresponding sAP. We then formulate the problem of minimizing transmit power for DF/AF relaying while adhering to the delay and maximum power constraints. In the FDMA case, an additional constraint is introduced for bandwidth allocation to IoT devices during the first and second phases of cooperative transmission. To tackle the nonconvex problem, we employ the sequential parametric convex approximation (SPCA) method. We extend our analysis to a system model with reconfigurable intelligent surfaces (RISs), enabling transmission through direct and RIS-assisted channels, and optimizing for a multi-RIS scenario for comparative analysis. Simulation results show that our cooperative communication approach reduces the emitted power by up to 7.5 dB while maintaining an outage probability and a resource overflow rate below $10^{-6}$. While the RIS-based solution achieves greater power savings, the relay-based protocol outperforms RIS in terms of outage probability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12557v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hamid Reza Hashempour, Gilberto Berardinelli, Ramoni Adeogun, Eduard A. Jorswieck</dc:creator>
    </item>
    <item>
      <title>An Algorithm to Speed up the Spatial Power Profile Calculation in Backward Raman Amplified Systems</title>
      <link>https://arxiv.org/abs/2411.12688</link>
      <description>arXiv:2411.12688v1 Announce Type: new 
Abstract: As data transmission demands grow, long-haul optical transmission links face increasing pressure to increase their throughput. Expanding usable bandwidth through Ultra-Wide Band (UWB) systems has become the primary strategy for increasing transmission capacity. However, UWB systems present challenges, such as the reliance on backward Raman amplification and the complications posed by inter-channel stimulated Raman scattering (ISRS), which causes uneven signal propagation across bands. To address these issues, accurate and efficient physical models are required for real-time optimization, which rely on the knowledge of the power profile. This paper develops a novel, more efficient method for computing the power profile of signals and pumps, utilizing the integral form of the equations with matrix-based approximations. The algorithm achieves up to a thirty-fold average speed increase over conventional approaches while maintaining an error margin under 0.05 dBm. These results represent a significant step forward towards reducing optimization times and enabling more extensive studies in ultra-wide band long haul optical transmission, further facilitating research and commercialization of UWB systems, in an effort to address the growing demand for higher throughput.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12688v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jad Sarkis, Yanchao Jiang, Pierluigi Poggiolini</dc:creator>
    </item>
    <item>
      <title>ResLearn: Transformer-based Residual Learning for Metaverse Network Traffic Prediction</title>
      <link>https://arxiv.org/abs/2411.11894</link>
      <description>arXiv:2411.11894v1 Announce Type: cross 
Abstract: Our work proposes a comprehensive solution for predicting Metaverse network traffic, addressing the growing demand for intelligent resource management in eXtended Reality (XR) services. We first introduce a state-of-the-art testbed capturing a real-world dataset of virtual reality (VR), augmented reality (AR), and mixed reality (MR) traffic, made openly available for further research. To enhance prediction accuracy, we then propose a novel view-frame (VF) algorithm that accurately identifies video frames from traffic while ensuring privacy compliance, and we develop a Transformer-based progressive error-learning algorithm, referred to as ResLearn for Metaverse traffic prediction. ResLearn significantly improves time-series predictions by using fully connected neural networks to reduce errors, particularly during peak traffic, outperforming prior work by 99%. Our contributions offer Internet service providers (ISPs) robust tools for real-time network management to satisfy Quality of Service (QoS) and enhance user experience in the Metaverse.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11894v1</guid>
      <category>cs.AI</category>
      <category>eess.SP</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yoga Suhas Kuruba Manjunath, Mathew Szymanowski, Austin Wissborn, Mushu Li, Lian Zhao, Xiao-Ping Zhang</dc:creator>
    </item>
    <item>
      <title>Is Locational Marginal Price All You Need for Locational Marginal Emission?</title>
      <link>https://arxiv.org/abs/2411.12104</link>
      <description>arXiv:2411.12104v1 Announce Type: cross 
Abstract: Growing concerns over climate change call for improved techniques for estimating and quantifying the greenhouse gas emissions associated with electricity generation and transmission. Among the emission metrics designated for power grids, locational marginal emission (LME) can provide system operators and electricity market participants with valuable information on the emissions associated with electricity usage at various locations in the power network. In this paper, by investigating the operating patterns and physical interpretations of marginal emissions and costs in the security-constrained economic dispatch (SCED) problem, we identify and draw the exact connection between locational marginal price (LMP) and LME. Such interpretation helps instantly derive LME given nodal demand vectors or LMP, and also reveals the interplay between network congestion and nodal emission pattern. Our proposed approach helps reduce the computation time of LME by an order of magnitude compared to analytical approaches, while it can also serve as a plug-and-play module accompanied by an off-the-shelf market clearing and LMP calculation process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12104v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xuan He, Danny H. K. Tsang, Yize Chen</dc:creator>
    </item>
    <item>
      <title>Forward and Reverse Converters for the Moduli-Set $\{2^{2q+1},2^q+2^{q-1}\pm1\}$</title>
      <link>https://arxiv.org/abs/2411.12213</link>
      <description>arXiv:2411.12213v1 Announce Type: cross 
Abstract: Modulo-$(2^q + 2^{q-1} \pm 1)$ adders have recently been implemented using the regular parallel prefix (RPP) architecture, matching the speed of the widely used modulo-$(2^q \pm 1)$ RPP adders. Consequently, we introduce a new moduli set $\tau^+ = \{2^{2q+1}, 2^q + 2^{q-1} \pm 1\}$, with over $(2^{q+2}) \times$ dynamic range and adder speeds comparable to the conventional $\tau = \{2^q, 2^q \pm 1\}$ set. However, to fully leverage $\tau^+$ in residue number system applications, a complete set of circuitries is necessary. This work focuses on the design and implementation of the forward and reverse converters for $\tau^+$. These converters consist of four and seven levels of carry-save addition units, culminating in a final modulo-$(2^q + 2^{q-1} \pm 1)$ and modulo-$(2^{2q+1} + 2^{2q-2} - 1)$ adder, respectively. Through analytical evaluations and circuit simulations, we demonstrate that the overall performance of a sequence of operations including residue generation -- including residue generation, $k$ additions, and reverse conversion -- using $\tau^+$ surpasses that of $\tau$ when $k$ exceeds a certain practical threshold.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12213v1</guid>
      <category>cs.AR</category>
      <category>eess.SP</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ghassem Jaberipur, Bardia Nadimi, R. Kazemi, Jeong-A Lee</dc:creator>
    </item>
    <item>
      <title>A Neural Denoising Vocoder for Clean Waveform Generation from Noisy Mel-Spectrogram based on Amplitude and Phase Predictions</title>
      <link>https://arxiv.org/abs/2411.12268</link>
      <description>arXiv:2411.12268v1 Announce Type: cross 
Abstract: This paper proposes a novel neural denoising vocoder that can generate clean speech waveforms from noisy mel-spectrograms. The proposed neural denoising vocoder consists of two components, i.e., a spectrum predictor and a enhancement module. The spectrum predictor first predicts the noisy amplitude and phase spectra from the input noisy mel-spectrogram, and subsequently the enhancement module recovers the clean amplitude and phase spectrum from noisy ones. Finally, clean speech waveforms are reconstructed through inverse short-time Fourier transform (iSTFT). All operations are performed at the frame-level spectral domain, with the APNet vocoder and MP-SENet speech enhancement model used as the backbones for the two components, respectively. Experimental results demonstrate that our proposed neural denoising vocoder achieves state-of-the-art performance compared to existing neural vocoders on the VoiceBank+DEMAND dataset. Additionally, despite the lack of phase information and partial amplitude information in the input mel-spectrogram, the proposed neural denoising vocoder still achieves comparable performance with the serveral advanced speech enhancement methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12268v1</guid>
      <category>eess.AS</category>
      <category>eess.SP</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hui-Peng Du, Ye-Xin Lu, Yang Ai, Zhen-Hua Ling</dc:creator>
    </item>
    <item>
      <title>Meeting Future Mobile Traffic Needs by Peak-Throughput Design of Next-Gen RAN</title>
      <link>https://arxiv.org/abs/2411.12621</link>
      <description>arXiv:2411.12621v1 Announce Type: cross 
Abstract: Growing congestion in current mobile networks necessitates innovative solutions. This paper explores the potential of mmWave 5G networks in urban settings, focusing on Integrated Access and Backhaul (IAB) and the Smart Radio Environment (SRE). The mmWave traffic will be mainly made of short bursts to transfer large volumes of data and long idle periods where data are processed. This must change the way of designing mobile radio networks. To this extent, we propose network planning models leveraging the maximization of the achievable peak throughput. Results highlight the advantages of this approach during the network planning phase, providing insights into better accommodating the demands of mobile traffic without sacrificing the overall network capacity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12621v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paolo Fiore, Ilario Filippini, Danilo De Donno</dc:creator>
    </item>
    <item>
      <title>Securing Satellite Link Segment: A Secure-by-Component Design</title>
      <link>https://arxiv.org/abs/2411.12632</link>
      <description>arXiv:2411.12632v1 Announce Type: cross 
Abstract: The rapid evolution of communication technologies, compounded by recent geopolitical events such as the Viasat cyberattack in February 2022, has highlighted the urgent need for fast and reliable satellite missions for military and civil security operations. Consequently, this paper examines two Earth observation (EO) missions: one utilizing a single low Earth orbit (LEO) satellite and another through a network of LEO satellites, employing a secure-by-component design strategy. This approach begins by defining the scope of technical security engineering, decomposing the system into components and data flows, and enumerating attack surfaces. Then it proceeds by identifying threats to low-level components, applying secure-by-design principles, redesigning components into secure blocks in alignment with the Space Attack Research &amp; Tactic Analysis (SPARTA) framework, and crafting shall statements to refactor the system design, with a particular focus on improving the security of the link segment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12632v1</guid>
      <category>cs.CR</category>
      <category>eess.SP</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Olfa Ben Yahia, William Ferguson, Sumit Chakravarty, Nesrine Benchoubane, Gunes Karabulut Kurt, G\"urkan G\"ur, Gregory Falco</dc:creator>
    </item>
    <item>
      <title>Constrained Coding and Deep Learning Aided Threshold Detection for Resistive Memories</title>
      <link>https://arxiv.org/abs/2411.12669</link>
      <description>arXiv:2411.12669v1 Announce Type: cross 
Abstract: Resistive random access memory (ReRAM) is a promising emerging non-volatile memory (NVM) technology that shows high potential for both data storage and computing. However, its crossbar array architecture leads to the sneak path problem, which may severely degrade the reliability of data stored in the ReRAM cell. Due to the complication of memory physics and unique features of the sneak path induced interference (SPI), it is difficult to derive an accurate channel model for it. The deep learning (DL)-based detection scheme \cite{zhong2020sneakdl} can better mitigate the SPI, at the cost of additional power consumption and read latency. In this letter, we first propose a novel CC scheme which can not only reduce the SPI in the memory array, but also effectively differentiate the memory arrays into two categories of sneak-path-free and sneak-path-affected arrays. For the sneak-path-free arrays, we can use a simple middle-point threshold detector to detect the low and high resistance cells of ReRAM. For the sneak-path-affected arrays, a DL detector is first trained off-line (prior to the data detection of ReRAM). To avoid the additional power consumption and latency introduced by the DL detector, we further propose a DL-based threshold detector, whose detection threshold can be derived based on the outputs of the DL detector. It is then utilized for the online data detection of all the identified sneak-path-affected arrays. Simulation results demonstrate that the above CC and DL aided threshold detection scheme can effectively mitigate the SPI of the ReRAM array and achieve better error rate performance than the prior art detection schemes, without the prior knowledge of the channel.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12669v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xingwei Zhong, Kui Cai, Guanghui Song, Weijie Wang, Yao Zhu</dc:creator>
    </item>
    <item>
      <title>ISAC Super-Resolution Receivers: The Effect of Different Dictionary Matrices</title>
      <link>https://arxiv.org/abs/2411.12672</link>
      <description>arXiv:2411.12672v1 Announce Type: cross 
Abstract: This paper presents an off-the-grid estimator for ISAC systems using lifted atomic norm minimization (LANM). The main challenge in the ISAC systems is the unknown nature of both transmitted signals and radar-communication channels. We use a known dictionary to encode transmit signals and show that LANM can localize radar targets and decode communication symbols when the number of observations is proportional to the system's degrees of freedom and the coherence of the dictionary matrix. We reformulate LANM using a dual method and solve it with semidefinite relaxation (SDR) for different dictionary matrices to reduce the number of observations required at the receiver. Simulations demonstrate that the proposed LANM accurately estimates communication data and target parameters under varying complexity by selecting different dictionary matrices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12672v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Iman Valiulahi, Christos Masouros, Athina P. Petropulu</dc:creator>
    </item>
    <item>
      <title>Characteristics-Based Design of Generalized-Exponent Bandpass Filters</title>
      <link>https://arxiv.org/abs/2404.15321</link>
      <description>arXiv:2404.15321v2 Announce Type: replace 
Abstract: We develop characteristics-based design methods for a class of IIR bandpass filters which we refer to as Generalized Exponent Filters (GEFs) and that are represented as second order filters raised to non-unitary exponents. GEFs have a peak, are effectively linear phase, and may be used for phase-picking for seismic signals, cochlear implants, rainbow sensors, and equalizers. The native specifications for GEFs are not on a given frequency response but rather on filter characteristics such as peak frequency, quality factor, and group delay. Our characteristics-based method for design accommodates direct specification of a trio of frequency-domain characteristics from amongst the peak frequency, 3dB quality factor, equivalent rectangular bandwidth, maximum group delay, and phase accumulation. We achieve this by deriving parameterizations for the filters in terms of sets of filter characteristics which involves deriving closed-form analytic expressions mapping sets of filter characteristics to the original filter constants by making sharp-filter approximations. This results in parameterizations for GEFs including mixed parameterizations based on simultaneous specification of magnitude-based characteristics (e.g. bandwidths) and phase-based characteristics (e.g. group delays) which enables designing sharply tuned filters without significant group delay and simultaneous control over frequency selectivity and synchronization which is important in designing filterbanks. Our design methods with direct control over characteristics may also be utilized for higher-order variable bandpass filter design and may be useful for characteristics-based adaptive filtering. Our methods are inherently stable, highly accurate in meeting strict specifications on desired characteristics, and computationally efficient. The methods extend to the design of related bandpass, multiband filters, and filterbanks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15321v2</guid>
      <category>eess.SP</category>
      <category>cs.SD</category>
      <category>eess.AS</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Samiya A Alkhairy</dc:creator>
    </item>
    <item>
      <title>Integrating Base Station with Intelligent Surface for 6G Wireless Networks: Architectures, Design Issues, and Future Directions</title>
      <link>https://arxiv.org/abs/2407.10986</link>
      <description>arXiv:2407.10986v2 Announce Type: replace 
Abstract: Intelligent surface (IS) is envisioned as a promising technology for the sixth-generation (6G) wireless networks, which can effectively reconfigure the wireless propagation environment via dynamically controllable signal reflection/transmission. In particular, integrating passive intelligent surface (IS) into the base station (BS) is a novel solution to enhance the wireless network throughput and coverage both cost-effectively and energyefficiently. In this article, we provide an overview of IS-integrated BSs for wireless networks, including their motivations, practical architectures, and main design issues. Moreover, numerical results are presented to compare the performance of different IS-integrated BS architectures as well as the conventional BS without IS. Finally, promising directions are pointed out to stimulate future research on IS-BS/terminal integration in wireless networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10986v2</guid>
      <category>eess.SP</category>
      <category>cs.NI</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuwei Huang, Lipeng Zhu, Rui Zhang</dc:creator>
    </item>
    <item>
      <title>Subset Random Sampling of Finite Time-vertex Graph Signals</title>
      <link>https://arxiv.org/abs/2410.22731</link>
      <description>arXiv:2410.22731v2 Announce Type: replace 
Abstract: Time-varying data with irregular structures can be described by finite time-vertex graph signals (FTVGS), which represent potential temporal and spatial relationships among multiple sources. While sampling and corresponding reconstruction of FTVGS with known spectral support are well investigated, methods for the case of unknown spectral support remain underdeveloped. Existing random sampling schemes may acquire samples from any vertex at any time, which is uncommon in practical applications where sampling typically involves only a subset of vertices and time instants. In sight of this requirement, this paper proposes a subset random sampling scheme for FTVGS. We first randomly select some rows and columns of the FTVGS to form a submatrix, and then randomly sample within the submatrix. Theoretically, we prove sufficient conditions to ensure that the original FTVGS is reconstructed with high probability. Also, we validate the feasibility of reconstructing the original FTVGS by experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.22731v2</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hang Sheng, Qinji Shu, Hui Feng, Bo Hu</dc:creator>
    </item>
    <item>
      <title>A Flexible Framework for Grant-Free Random Access in Cell-Free Massive MIMO Systems</title>
      <link>https://arxiv.org/abs/2411.09328</link>
      <description>arXiv:2411.09328v2 Announce Type: replace 
Abstract: We propose a novel generalized framework for grant-free random-access (GFRA) in cell-free massive multiple input multiple-output systems where multiple geographically separated access points (APs) or base stations (BSs) aim to detect sporadically active user-equipment (UEs). Unlike a conventional architecture in which all the active UEs transmit their signature or pilot sequences of equal length, we admit a flexible pilot length for each UE, which also enables a seamless integration into conventional grant-based wireless systems. We formulate the joint UE activity detection and the distributed channel estimation as a sparse support and signal recovery problem, and describe a Bayesian learning procedure to solve it. We develop a scheme to fuse the posterior statistics of the latent variables inferred by each AP to jointly detect the UEs' activities, and utilize them to further refine the channel estimates. In addition, we allude to an interesting point which enables this flexible GFRA framework to encode the information bits from the active UEs. We numerically evaluate the normalized mean square error and the probability of miss-detection performances obtained by the Bayesian algorithm and show that the latent-variable fusion enhances the detection and the channel estimation performances by a large margin. We also benchmark against a genie-aided algorithm which has a prior knowledge of the UEs' activities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.09328v2</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sai Subramanyam Thoota, Erik G. Larsson</dc:creator>
    </item>
    <item>
      <title>Movable Antenna Enhanced Networked Full-Duplex Integrated Sensing and Communication System</title>
      <link>https://arxiv.org/abs/2411.09426</link>
      <description>arXiv:2411.09426v2 Announce Type: replace 
Abstract: Integrated sensing and communication (ISAC) is envisioned as a key technology for future sixth-generation (6G) networks. Classical ISAC system considering monostatic and/or bistatic settings will inevitably degrade both communication and sensing performance due to the limited service coverage and easily blocked transmission paths. Besides, existing ISAC studies usually focus on downlink (DL) or uplink (UL) communication demands and unable to achieve the systematic DL and UL communication tasks. These challenges can be overcome by networked FD ISAC framework. Moreover, ISAC generally considers the trade-off between communication and sensing, unavoidably leading to a loss in communication performance. This shortcoming can be solved by the emerging movable antenna (MA) technology. In this paper, we utilize the MA to promote communication capability with guaranteed sensing performance via jointly designing beamforming, power allocation, receiving filters and MA configuration towards maximizing sum rate. The optimization problem is highly difficult due to the unique channel model deriving from the MA. To resolve this challenge, via leveraging the cutting-the-edge majorization-minimization (MM) method, we develop an efficient solution that optimizes all variables via convex optimization techniques. Extensive simulation results verify the effectiveness of our proposed algorithms and demonstrate the substantial performance promotion by deploying MA in the networked FD ISAC system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.09426v2</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuan Guo, Wen Chen, Qingqing Wu, Yang Liu, Qiong Wu, Kunlun Wang, Jun Li, Lexi Xu</dc:creator>
    </item>
    <item>
      <title>Interpretable Fusion Analytics Framework for fMRI Connectivity: Self-Attention Mechanism and Latent Space Item-Response Model</title>
      <link>https://arxiv.org/abs/2207.01581</link>
      <description>arXiv:2207.01581v2 Announce Type: replace-cross 
Abstract: There have been several attempts to use deep learning based on brain fMRI signals to classify cognitive impairment diseases. However, deep learning is a hidden black box model that makes it difficult to interpret the process of classification. To address this issue, we propose a novel analytical framework that interprets the classification result from deep learning processes. We first derive the region of interest (ROI) functional connectivity network (FCN) by embedding functions based on their similar signal patterns. Then, using the self-attention equipped deep learning model, we classify diseases based on their FCN. Finally, in order to interpret the classification results, we employ a latent space item-response interaction network model to identify the significant functions that exhibit distinct connectivity patterns when compared to other diseases. The application of this proposed framework to the four types of cognitive impairment shows that our approach is valid for determining the significant ROI functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.01581v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>eess.SP</category>
      <category>q-bio.NC</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jeong-Jae Kim, Yeseul Jeon, SuMin Yu, Junggu Choi, Sanghoon Han</dc:creator>
    </item>
    <item>
      <title>Digital Twin for Non-Terrestrial Networks: Vision, Challenges, and Enabling Technologies</title>
      <link>https://arxiv.org/abs/2305.10273</link>
      <description>arXiv:2305.10273v3 Announce Type: replace-cross 
Abstract: This paper investigates the transformative potential of digital twin (DT) technology for non-terrestrial networks (NTNs). NTNs, comprising airborne and space-borne elements, face unique challenges in network control, management, and optimization. DT technology provides a novel framework for designing and managing complex cyber-physical systems with enhanced automation, intelligence, and resilience. By offering a dynamic virtual representation of the NTN ecosystem, DTs enable real-time monitoring, simulation, and data-driven decision-making. This paper explores the integration of DTs into NTNs, identifying technical challenges and highlighting some key enabling technologies. Emphasis is placed on technologies such as the Internet of Things (IoT), machine learning, generative AI, space-based clouds, quantum computing, and others, highlighting their potential to empower DT development for NTNs. To illustrate these concepts, we present a case study demonstrating the implementation of a data-driven DT model for enabling dynamic, service-oriented network slicing within an open radio access network (O-RAN) architecture tailored for NTNs. This work aims to advance the understanding and application of DT technology, contributing to the evolution of network control and management in the dynamic and rapidly changing landscape of non-terrestrial communication systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.10273v3</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hayder Al-Hraishawi, Madyan Alsenwi, Junaid ur Rehman, Eva Lagunas, Symeon Chatzinotas</dc:creator>
    </item>
    <item>
      <title>Freezing of Gait Detection Using Gramian Angular Fields and Federated Learning from Wearable Sensors</title>
      <link>https://arxiv.org/abs/2411.11764</link>
      <description>arXiv:2411.11764v2 Announce Type: replace-cross 
Abstract: Freezing of gait (FOG) is a debilitating symptom of Parkinson's disease (PD) that impairs mobility and safety. Traditional detection methods face challenges due to intra and inter-patient variability, and most systems are tested in controlled settings, limiting their real-world applicability. Addressing these gaps, we present FOGSense, a novel FOG detection system designed for uncontrolled, free-living conditions. It uses Gramian Angular Field (GAF) transformations and federated deep learning to capture temporal and spatial gait patterns missed by traditional methods. We evaluated our FOGSense system using a public PD dataset, 'tdcsfog'. FOGSense improves accuracy by 10.4% over a single-axis accelerometer, reduces failure points compared to multi-sensor systems, and demonstrates robustness to missing values. The federated architecture allows personalized model adaptation and efficient smartphone synchronization during off-peak hours, making it effective for long-term monitoring as symptoms evolve. Overall, FOGSense achieves a 22.2% improvement in F1-score compared to state-of-the-art methods, along with enhanced sensitivity for FOG episode detection. Code is available: https://github.com/shovito66/FOGSense.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11764v2</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Shovito Barua Soumma, S M Raihanul Alam, Rudmila Rahman, Umme Niraj Mahi, Abdullah Mamun, Sayyed Mostafa Mostafavi, Hassan Ghasemzadeh</dc:creator>
    </item>
  </channel>
</rss>
