<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.PL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.PL</link>
    <description>cs.PL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.PL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 03 Dec 2024 05:00:20 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Pourquoi existe-t-il de nombreux paradigmes de programmation ?</title>
      <link>https://arxiv.org/abs/2412.00248</link>
      <description>arXiv:2412.00248v1 Announce Type: new 
Abstract: There are a lot of different programming paradigms. Since all Turing-complete programming languages are formally equivalent (they have the same ability to express any computable problem), the existence of so many different paradigms may seem surprising, even pointless. In this article, we will try to understand why there are so many different paradigms. We will start with a definition of what a programming paradigm is, then show how different paradigms are better suited for different applications: learning, solving or expressing certain types of problems, and more generally for the features brought by each paradigm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00248v1</guid>
      <category>cs.PL</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Oscar Plaisant, Max Lemoine</dc:creator>
    </item>
    <item>
      <title>Beyond SICP -- Design and Implementation of a Notional Machine for Scheme</title>
      <link>https://arxiv.org/abs/2412.01545</link>
      <description>arXiv:2412.01545v1 Announce Type: new 
Abstract: Computer science education has been at the heart of Scheme from the beginning. The language was designed in the 1970s concurrently with the MIT course 6.001 and the textbook "Structure and Interpretation of Computer Programs" (SICP). To explain the scope of variables at run time in the presence of higher-order procedures, SICP introduces a mental model called the environment model, along with a pictorial representation of environments and data structures. Recently, the concept of notional machines has emerged in computer science education: a predictive set of abstractions that define the structure and behavior of a computational device. Proponents of notional machines argue that learners benefit when complex dynamic concepts such as the computational structure of Scheme are accompanied with concise notional machines. In this paper, we start with a sublanguage of Scheme sufficient for all programs in SICP that we call SICP Scheme. We extend the environment model to a full notional machine for SICP Scheme that is simple enough to serve as the central mental model in a CS1 course and demonstrate the machine with computer-generated visualizations. Moving beyond SICP Scheme, we show how the notional machine can be further extended to explain Scheme's call/cc and thus make this powerful concept accessible to beginners through a coherent mental model. The presented notional machine serves as the core of a web-based implementation of Scheme that is under development at our university.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01545v1</guid>
      <category>cs.PL</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Kyriel Abad, Martin Henz</dc:creator>
    </item>
    <item>
      <title>Towards the Ultimate Programming Language: Trust and Benevolence in the Age of Artificial Intelligence</title>
      <link>https://arxiv.org/abs/2412.00206</link>
      <description>arXiv:2412.00206v1 Announce Type: cross 
Abstract: This article explores the evolving role of programming languages in the context of artificial intelligence. It highlights the need for programming languages to ensure human understanding while eliminating unnecessary implementation details and suggests that future programs should be designed to recognize and actively support user interests. The vision includes a three-level process: using natural language for requirements, translating it into a precise system definition language, and finally optimizing the code for performance. The concept of an "Ultimate Programming Language" is introduced, emphasizing its role in maintaining human control over machines. Trust, reliability, and benevolence are identified as key elements that will enhance cooperation between humans and AI systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00206v1</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <category>cs.PL</category>
      <category>cs.SE</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bartosz Sawicki, Micha{\l} \'Smia{\l}ek, Bart{\l}omiej Skowron</dc:creator>
    </item>
    <item>
      <title>Gradual Exact Logic: Unifying Hoare Logic and Incorrectness Logic via Gradual Verification</title>
      <link>https://arxiv.org/abs/2412.00339</link>
      <description>arXiv:2412.00339v1 Announce Type: cross 
Abstract: Previously, gradual verification has been developed using overapproximating logics such as Hoare logic. We show that the static verification component of gradual verification is also connected to underapproximating logics like incorrectness logic. To do this, we use a novel definition of gradual verification and a novel gradualization of exact logic [Maksimovic et al. 2023] which we call gradual exact logic. Further, we show that Hoare logic, incorrectness logic, and gradual verification can be defined in terms of gradual exact logic. We hope that this connection can be used to develop tools and techniques that apply to both gradual verification and bug-finding. For example, we envision that techniques defined in terms of exact logic can be directly applied to verification, bug-finding, and gradual verification, using the principles of gradual typing [Garcia et al. 2016].</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00339v1</guid>
      <category>cs.LO</category>
      <category>cs.PL</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Conrad Zimmerman, Jenna DiVincenzo</dc:creator>
    </item>
    <item>
      <title>Dual-Use Commercial and Military Communications on a Single Platform using RAN Domain Specific Language</title>
      <link>https://arxiv.org/abs/2412.00983</link>
      <description>arXiv:2412.00983v1 Announce Type: cross 
Abstract: Despite the success of the O-RAN Alliance in developing a set of interoperable interfaces, development of unique Radio Access Network (RAN) deployments remains challenging. This is especially true for military communications, where deployments are highly specialized with limited volume. The construction and maintenance of the RAN, which is a real time embedded system, is an ill-defined NP problem requiring teams of specialized system engineers, with specialized knowledge of the hardware platform. In this paper, we introduce a RAN Domain Specific Language (RDSL(TM)) to formally describe use cases, constraints, and multi-vendor hardware/software abstraction to allow automation of RAN construction. In this DSL, system requirements are declarative, and performance constraints are guaranteed by construction using an automated system solver. Using our RAN system solver platform, Gabriel(TM) we show how a system engineer can confidently modify RAN functionality without knowledge of the underlying hardware. We show benefits for specific system requirements when compared to the manually optimized, default configuration of the Intel FlexRAN(TM), and conclude that DSL/automation driven construction of the RAN can lead to significant power and latency benefits when the deployment constraints are tuned for a specific case. We give examples of how constraints and requirements can be formatted in a "Kubernetes style" YAML format which allows the use of other tools, such as Ansible, to integrate the generation of these requirements into higher level automation flows such as Service Management and Orchestration (SMO).</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00983v1</guid>
      <category>eess.SY</category>
      <category>cs.AR</category>
      <category>cs.PL</category>
      <category>cs.SY</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alan Gatherer, Chaitali Sengupta, Sudipta Sen, Jeffery H. Reed</dc:creator>
    </item>
    <item>
      <title>Worst-Case Input Generation for Concurrent Programs under Non-Monotone Resource Metrics</title>
      <link>https://arxiv.org/abs/2309.01261</link>
      <description>arXiv:2309.01261v3 Announce Type: replace 
Abstract: Worst-case input generation aims to automatically generate inputs that exhibit the worst-case performance of programs. It has several applications, and can, for example, detect vulnerabilities to denial-of-service (DoS) attacks. However, it is non-trivial to generate worst-case inputs for concurrent programs, particularly for resources like memory where the peak cost depends on how processes are scheduled.
  This article presents the first sound worst-case input generation algorithm for concurrent programs under non-monotone resource metrics like memory. The key insight is to leverage resource-annotated session types and symbolic execution. Session types describe communication protocols on channels in process calculi. Equipped with resource annotations, resource-annotated session types not only encode cost bounds but also indicate how many resources can be reused and transferred between processes. This information is critical for identifying a worst-case execution path during symbolic execution. The algorithm is sound: if it returns any input, it is guaranteed to be a valid worst-case input. The algorithm is also relatively complete: as long as resource-annotated session types are sufficiently expressive and the background theory for SMT solving is decidable, a worst-case input is guaranteed to be returned. A simple case study of a web server's memory usage demonstrates the utility of the worst-case input generation algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.01261v3</guid>
      <category>cs.PL</category>
      <category>cs.DC</category>
      <category>cs.LO</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Long Pham, Jan Hoffmann</dc:creator>
    </item>
    <item>
      <title>HPVM-HDC: A Heterogeneous Programming System for Accelerating Hyperdimensional Computing</title>
      <link>https://arxiv.org/abs/2410.15179</link>
      <description>arXiv:2410.15179v2 Announce Type: replace 
Abstract: Hyperdimensional Computing (HDC), a technique inspired by cognitive models of computation, has been proposed as an efficient and robust alternative basis for machine learning. HDC programs are often manually written in low-level and target specific languages targeting CPUs, GPUs, and FPGAs - these codes cannot be easily retargeted onto HDC-specific accelerators. No previous programming system enables productive development of HDC programs and generates efficient code for several hardware targets.
  We propose a heterogeneous programming system for HDC: a novel programming language, HDC++, for writing applications using a unified programming model, including HDC-specific primitives to improve programmability, and a heterogeneous compiler, HPVM-HDC, that provides an intermediate representation for compiling HDC programs to many hardware targets. We implement two tuning optimizations, automatic binarization and reduction perforation, that exploit the error resilient nature of HDC. Our evaluation shows that HPVM-HDC generates performance-competitive code for CPUs and GPUs, achieving a geomean speed-up of 1.17x over optimized baseline CUDA implementations with a geomean reduction in total lines of code of 1.6x across CPUs and GPUs. Additionally, HPVM-HDC targets an HDC Digital ASIC and an HDC ReRAM accelerator simulator, enabling the first execution of HDC applications on these devices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15179v2</guid>
      <category>cs.PL</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Russel Arbore, Xavier Routh, Abdul Rafae Noor, Akash Kothari, Haichao Yang, Weihong Xu, Sumukh Pinge, Vikram Adve, Tajana Rosing, Minxuan Zhou</dc:creator>
    </item>
    <item>
      <title>Evaluating LLMs for Hardware Design and Test</title>
      <link>https://arxiv.org/abs/2405.02326</link>
      <description>arXiv:2405.02326v2 Announce Type: replace-cross 
Abstract: Large Language Models (LLMs) have demonstrated capabilities for producing code in Hardware Description Languages (HDLs). However, most of the focus remains on their abilities to write functional code, not test code. The hardware design process consists of both design and test, and so eschewing validation and verification leaves considerable potential benefit unexplored, given that a design and test framework may allow for progress towards full automation of the digital design pipeline. In this work, we perform one of the first studies exploring how a LLM can both design and test hardware modules from provided specifications. Using a suite of 8 representative benchmarks, we examined the capabilities and limitations of the state-of-the-art conversational LLMs when producing Verilog for functional and verification purposes. We taped out the benchmarks on a Skywater 130nm shuttle and received the functional chip.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02326v2</guid>
      <category>cs.AR</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <category>cs.PL</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1109/LAD62341.2024.10691811</arxiv:DOI>
      <dc:creator>Jason Blocklove, Siddharth Garg, Ramesh Karri, Hammond Pearce</dc:creator>
    </item>
  </channel>
</rss>
