<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.MF updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.MF</link>
    <description>q-fin.MF updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.MF" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 24 Dec 2024 06:39:56 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Broker-Trader Partial Information Nash Equilibria</title>
      <link>https://arxiv.org/abs/2412.17712</link>
      <description>arXiv:2412.17712v1 Announce Type: new 
Abstract: We study partial information Nash equilibrium between a broker and an informed trader. In this model, the informed trader, who possesses knowledge of a trading signal, trades multiple assets with the broker in a dealer market. Simultaneously, the broker trades these assets in a lit exchange where their actions impact the asset prices. The broker, however, only observes aggregate prices and cannot distinguish between underlying trends and volatility. Both the broker and the informed trader aim to maximize their penalized expected wealth. Using convex analysis, we characterize the Nash equilibrium and demonstrate its existence and uniqueness. Furthermore, we establish that this equilibrium corresponds to the solution of a nonstandard system of forward-backward stochastic differential equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17712v1</guid>
      <category>q-fin.MF</category>
      <category>math.PR</category>
      <category>q-fin.TR</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xuchen Wu, Sebastian Jaimungal</dc:creator>
    </item>
    <item>
      <title>Path-dependent Fractional Volterra Equations and the Microstructure of Rough Volatility Models driven by Poisson Random Measures</title>
      <link>https://arxiv.org/abs/2412.16436</link>
      <description>arXiv:2412.16436v1 Announce Type: cross 
Abstract: We consider a microstructure foundation for rough volatility models driven by Poisson random measures. In our model the volatility is driven by self-exciting arrivals of market orders as well as self-exciting arrivals of limit orders and cancellations. The impact of market order on future order arrivals is captured by a Hawkes kernel with power law decay, and is hence persistent. The impact of limit orders on future order arrivals is temporary, yet possibly long-lived. After suitable scaling the volatility process converges to a fractional Heston model driven by an additional Poisson random measure. The random measure generates occasional spikes and clusters of spikes in the volatility process. Our results are based on novel existence and uniqueness of solutions results for stochastic path-dependent Volterra equations driven by Poisson random measures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16436v1</guid>
      <category>math.PR</category>
      <category>q-fin.MF</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ulrich Horst, Wei Xu, Rouyi Zhang</dc:creator>
    </item>
    <item>
      <title>State spaces of multifactor approximations of nonnegative Volterra processes</title>
      <link>https://arxiv.org/abs/2412.17526</link>
      <description>arXiv:2412.17526v1 Announce Type: cross 
Abstract: We show that the state spaces of multifactor Markovian processes, coming from approximations of nonnegative Volterra processes, are given by explicit linear transformation of the nonnegative orthant. We demonstrate the usefulness of this result for applications, including simulation schemes and PDE methods for nonnegative Volterra processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17526v1</guid>
      <category>math.PR</category>
      <category>q-fin.MF</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eduardo Abi Jaber, Christian Bayer, Simon Breneis</dc:creator>
    </item>
    <item>
      <title>A Two-Stage Pontryagin-Guided Neural Policy Optimization Framework for Merton's Portfolio Problem</title>
      <link>https://arxiv.org/abs/2412.13101</link>
      <description>arXiv:2412.13101v2 Announce Type: replace-cross 
Abstract: We present a two-stage neural policy optimization framework for Merton's portfolio optimization problem that is rigorously aligned with Pontryagin's Maximum Principle (PMP). In Stage 1, we employ a discrete-time, backpropagation-through-time (BPTT)-based gradient scheme that converges to a stationary point of the parameterized control policy. Subsequently, in Stage 2, we refine this policy via a discrete-time, PMP-guided procedure, proven to converge to the Pontryagin-optimal solution. Central to our method is the approximation of adjoint variables from a policy-fixed backward stochastic differential equation (BSDE), yielding parameter gradients consistent with the PMP framework-all without explicitly solving the PMP-derived BSDE. As the policy parameters are iteratively updated, both the suboptimal adjoint variables and the neural network policies converge almost surely to their PMP-optimal counterparts. This ensures that the final learned policy is not only numerically robust but also provably optimal in the continuous-time sense. Our approach thus provides a theoretically grounded yet practically implementable solution, bridging modern deep learning techniques and classical optimal control theory for complex stochastic settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13101v2</guid>
      <category>math.OC</category>
      <category>q-fin.MF</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jeonggyu Huh</dc:creator>
    </item>
  </channel>
</rss>
