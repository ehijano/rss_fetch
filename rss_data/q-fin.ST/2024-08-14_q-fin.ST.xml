<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.ST updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.ST</link>
    <description>q-fin.ST updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.ST" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 15 Aug 2024 01:35:52 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 14 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>The Efficient Tail Hypothesis: An Extreme Value Perspective on Market Efficiency</title>
      <link>https://arxiv.org/abs/2408.06661</link>
      <description>arXiv:2408.06661v1 Announce Type: new 
Abstract: In econometrics, the Efficient Market Hypothesis posits that asset prices reflect all available information in the market. Several empirical investigations show that market efficiency drops when it undergoes extreme events. Many models for multivariate extremes focus on positive dependence, making them unsuitable for studying extremal dependence in financial markets where data often exhibit both positive and negative extremal dependence. To this end, we construct regular variation models on the entirety of $\mathbb{R}^d$ and develop a bivariate measure for asymmetry in the strength of extremal dependence between adjacent orthants. Our directional tail dependence (DTD) measure allows us to define the Efficient Tail Hypothesis (ETH) -- an analogue of the Efficient Market Hypothesis -- for the extremal behaviour of the market. Asymptotic results for estimators of DTD are described, and we discuss testing of the ETH via permutation-based methods and present novel tools for visualization. Empirical study of China's futures market leads to a rejection of the ETH and we identify potential profitable investment opportunities. To promote the research of microstructure in China's derivatives market, we open-source our high-frequency data, which are being collected continuously from multiple derivative exchanges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06661v1</guid>
      <category>q-fin.ST</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Junshu Jiang, Jordan Richards, Rapha\"el Huser, David Bolin</dc:creator>
    </item>
    <item>
      <title>Harnessing Earnings Reports for Stock Predictions: A QLoRA-Enhanced LLM Approach</title>
      <link>https://arxiv.org/abs/2408.06634</link>
      <description>arXiv:2408.06634v1 Announce Type: cross 
Abstract: Accurate stock market predictions following earnings reports are crucial for investors. Traditional methods, particularly classical machine learning models, struggle with these predictions because they cannot effectively process and interpret extensive textual data contained in earnings reports and often overlook nuances that influence market movements. This paper introduces an advanced approach by employing Large Language Models (LLMs) instruction fine-tuned with a novel combination of instruction-based techniques and quantized low-rank adaptation (QLoRA) compression. Our methodology integrates 'base factors', such as financial metric growth and earnings transcripts, with 'external factors', including recent market indices performances and analyst grades, to create a rich, supervised dataset. This comprehensive dataset enables our models to achieve superior predictive performance in terms of accuracy, weighted F1, and Matthews correlation coefficient (MCC), especially evident in the comparison with benchmarks such as GPT-4. We specifically highlight the efficacy of the llama-3-8b-Instruct-4bit model, which showcases significant improvements over baseline models. The paper also discusses the potential of expanding the output capabilities to include a 'Hold' option and extending the prediction horizon, aiming to accommodate various investment styles and time frames. This study not only demonstrates the power of integrating cutting-edge AI with fine-tuned financial data but also paves the way for future research in enhancing AI-driven financial analysis tools.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06634v1</guid>
      <category>q-fin.CP</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <category>q-fin.ST</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haowei Ni, Shuchen Meng, Xupeng Chen, Ziqing Zhao, Andi Chen, Panfeng Li, Shiyao Zhang, Qifu Yin, Yuanqing Wang, Yuxi Chan</dc:creator>
    </item>
    <item>
      <title>Case-based Explainability for Random Forest: Prototypes, Critics, Counter-factuals and Semi-factuals</title>
      <link>https://arxiv.org/abs/2408.06679</link>
      <description>arXiv:2408.06679v1 Announce Type: cross 
Abstract: The explainability of black-box machine learning algorithms, commonly known as Explainable Artificial Intelligence (XAI), has become crucial for financial and other regulated industrial applications due to regulatory requirements and the need for transparency in business practices. Among the various paradigms of XAI, Explainable Case-Based Reasoning (XCBR) stands out as a pragmatic approach that elucidates the output of a model by referencing actual examples from the data used to train or test the model. Despite its potential, XCBR has been relatively underexplored for many algorithms such as tree-based models until recently. We start by observing that most XCBR methods are defined based on the distance metric learned by the algorithm. By utilizing a recently proposed technique to extract the distance metric learned by Random Forests (RFs), which is both geometry- and accuracy-preserving, we investigate various XCBR methods. These methods amount to identify special points from the training datasets, such as prototypes, critics, counter-factuals, and semi-factuals, to explain the predictions for a given query of the RF. We evaluate these special points using various evaluation metrics to assess their explanatory power and effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06679v1</guid>
      <category>cs.LG</category>
      <category>q-fin.ST</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gregory Yampolsky, Dhruv Desai, Mingshu Li, Stefano Pasquali, Dhagash Mehta</dc:creator>
    </item>
  </channel>
</rss>
