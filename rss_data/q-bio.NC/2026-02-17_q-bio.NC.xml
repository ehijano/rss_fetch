<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 18 Feb 2026 02:33:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Graph neural networks uncover structure and functions underlying the activity of simulated neural assemblies</title>
      <link>https://arxiv.org/abs/2602.13325</link>
      <description>arXiv:2602.13325v1 Announce Type: new 
Abstract: Graph neural networks trained to predict observable dynamics can be used to decompose the temporal activity of complex heterogeneous systems into simple, interpretable representations. Here we apply this framework to simulated neural assemblies with thousands of neurons and demonstrate that it can jointly reveal the connectivity matrix, the neuron types, the signaling functions, and in some cases hidden external stimuli. In contrast to existing machine learning approaches such as recurrent neural networks and transformers, which emphasize predictive accuracy but offer limited interpretability, our method provides both reliable forecasts of neural activity and interpretable decomposition of the mechanisms governing large neural assemblies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13325v1</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>C\'edric Allier, Larissa Heinrich, Magdalena Schneider, Stephan Saalfeld</dc:creator>
    </item>
    <item>
      <title>The Influence of Width Ratios on Structural Beauty in Male Faces</title>
      <link>https://arxiv.org/abs/2602.13368</link>
      <description>arXiv:2602.13368v1 Announce Type: new 
Abstract: This study investigates the relationship between interocular distance relative to overall facial width (width ratio) and perceived subjective beauty in male faces. Building on the methodology of Pallett et al. (2010), who found that average proportions in female faces were rated as most attractive, the current study aimed to test this hypothesis in male faces. Faces from the Chicago Face Database (Ma et al., 2015) were morphed into average faces within three groups (with low, medium, and high width ratios), each composed of 96 or 97 individual images. These three average faces were then systematically manipulated in their width ratios across three levels in both directions, respectively, resulting in a total of 21 comparable faces. The use of multiple base faces served as a control for potential artifacts of image processing. Consequently, comparisons were restricted to within-group pairs to avoid confounding by co-varying facial features (e.g., skin tone), which precluded direct cross-condition comparisons but ensured internal validity. In a two-alternative forced-choice task, participants selected the more beautiful face from each pair. The data were analyzed using a Bayesian model which enables inference of the width ratio perceived as most beautiful. Results support the hypothesis that averageness in facial proportions correlates with higher perceived attractiveness. The study highlights the importance of controlling for image manipulation, including attempts at methodological implementation, and of considering ethnicity as a potential moderating variable. These findings offer a data-driven foundation for understanding facial aesthetics and cognitive processes of human perception, with applications in advertising, artificial face generation, and plastic surgery.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13368v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Benjamin Knopp, Theresa Tennstedt, Dominik Endres</dc:creator>
    </item>
    <item>
      <title>Evolutionarily Primitive Social Entities</title>
      <link>https://arxiv.org/abs/2602.14843</link>
      <description>arXiv:2602.14843v1 Announce Type: new 
Abstract: Social entities only exist in virtue of collective acceptance or recognition, or acknowledgement by two or more individuals in the context of joint activities. Joint activities are made possible by the coordination of plans for action, and the coordination of plans for action is made possible by the capacity for collective intentionality. This paper investigates how primitive is the capacity that nonhuman animals have to create social entities, by individuating how primitive is the capacity for collective intentionality. I present a novel argument for the evolutionary primitiveness of social entities, by showing that the collective intentions upon which these social entities are created and shared are metaphysically reducible to the relevant individual intentions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14843v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Angelica Kaufmann</dc:creator>
    </item>
    <item>
      <title>Metabolic cost of information processing in Poisson variational autoencoders</title>
      <link>https://arxiv.org/abs/2602.13421</link>
      <description>arXiv:2602.13421v1 Announce Type: cross 
Abstract: Computation in biological systems is fundamentally energy-constrained, yet standard theories of computation treat energy as freely available. Here, we argue that variational free energy minimization under a Poisson assumption offers a principled path toward an energy-aware theory of computation. Our key observation is that the Kullback-Leibler (KL) divergence term in the Poisson free energy objective becomes proportional to the prior firing rates of model neurons, yielding an emergent metabolic cost term that penalizes high baseline activity. This structure couples an abstract information-theoretic quantity -- the *coding rate* -- to a concrete biophysical variable -- the *firing rate* -- which enables a trade-off between coding fidelity and energy expenditure. Such a coupling arises naturally in the Poisson variational autoencoder (P-VAE) -- a brain-inspired generative model that encodes inputs as discrete spike counts and recovers a spiking form of *sparse coding* as a special case -- but is absent from standard Gaussian VAEs. To demonstrate that this metabolic cost structure is unique to the Poisson formulation, we compare the P-VAE against Grelu-VAE, a Gaussian VAE with ReLU rectification applied to latent samples, which controls for the non-negativity constraint. Across a systematic sweep of the KL term weighting coefficient $\beta$ and latent dimensionality, we find that increasing $\beta$ monotonically increases sparsity and reduces average spiking activity in the P-VAE. In contrast, Grelu-VAE representations remain unchanged, confirming that the effect is specific to Poisson statistics rather than a byproduct of non-negative representations. These results establish Poisson variational inference as a promising foundation for a resource-constrained theory of computation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13421v1</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hadi Vafaii, Jacob L. Yates</dc:creator>
    </item>
    <item>
      <title>Human-Aligned Evaluation of a Pixel-wise DNN Color Constancy Model</title>
      <link>https://arxiv.org/abs/2602.13887</link>
      <description>arXiv:2602.13887v1 Announce Type: cross 
Abstract: We previously investigated color constancy in photorealistic virtual reality (VR) and developed a Deep Neural Network (DNN) that predicts reflectance from rendered images. Here, we combine both approaches to compare and study a model and human performance with respect to established color constancy mechanisms: local surround, maximum flux and spatial mean. Rather than evaluating the model against physical ground truth, model performance was assessed using the same achromatic object selection task employed in the human experiments. The model, a ResNet based U-Net from our previous work, was pre-trained on rendered images to predict surface reflectance. We then applied transfer learning, fine-tuning only the network's decoder on images from the baseline VR condition. To parallel the human experiment, the model's output was used to perform the same achromatic object selection task across all conditions. Results show a strong correspondence between the model and human behavior. Both achieved high constancy under baseline conditions and showed similar, condition-dependent performance declines when the local surround or spatial mean color cues were removed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13887v1</guid>
      <category>cs.CV</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hamed Heidari-Gorji, Raquel Gil Rodriguez, Karl R. Gegenfurtner</dc:creator>
    </item>
    <item>
      <title>Drift-Diffusion Matching: Embedding dynamics in latent manifolds of asymmetric neural networks</title>
      <link>https://arxiv.org/abs/2602.14885</link>
      <description>arXiv:2602.14885v1 Announce Type: cross 
Abstract: Recurrent neural networks (RNNs) provide a theoretical framework for understanding computation in biological neural circuits, yet classical results, such as Hopfield's model of associative memory, rely on symmetric connectivity that restricts network dynamics to gradient-like flows. In contrast, biological networks support rich time-dependent behaviour facilitated by their asymmetry. Here we introduce a general framework, which we term drift-diffusion matching, for training continuous-time RNNs to represent arbitrary stochastic dynamical systems within a low-dimensional latent subspace. Allowing asymmetric connectivity, we show that RNNs can faithfully embed the drift and diffusion of a given stochastic differential equation, including nonlinear and nonequilibrium dynamics such as chaotic attractors. As an application, we construct RNN realisations of stochastic systems that transiently explore various attractors through both input-driven switching and autonomous transitions driven by nonequilibrium currents, which we interpret as models of associative and sequential (episodic) memory. To elucidate how these dynamics are encoded in the network, we introduce decompositions of the RNN based on its asymmetric connectivity and its time-irreversibility. Our results extend attractor neural network theory beyond equilibrium, showing that asymmetric neural populations can implement a broad class of dynamical computations within low-dimensional manifolds, unifying ideas from associative memory, nonequilibrium statistical mechanics, and neural computation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14885v1</guid>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ram\'on Nartallo-Kaluarachchi, Renaud Lambiotte, Alain Goriely</dc:creator>
    </item>
    <item>
      <title>Coevolutionary balance of resting-state brain networks in autism</title>
      <link>https://arxiv.org/abs/2507.09045</link>
      <description>arXiv:2507.09045v3 Announce Type: replace 
Abstract: Autism spectrum disorder (ASD) is associated with atypical large-scale brain organization, yet the functional principles underlying these alterations remain incompletely understood. We examined whether coevolutionary balance, a network-level energy measure derived from signed interactions and nodal activity states, captures disruptions in resting-state functional connectivity in autistic adults. Using resting-state fMRI data from ABIDE I with ComBat harmonization to mitigate multi-site batch effects, we constructed whole-brain networks by combining binarized fALFF activity with signed functional correlations and quantified their coevolutionary energy. In the primary analysis with global signal regression (GSR), the ASD group showed significantly more negative global coevolutionary energy (pFDR &lt; 0.002), higher proportions of agreement links, and lower proportions of imbalanced-same links, indicating a systematic redistribution of local motifs rather than a uniform increase in balance. Because GSR can introduce artifactual negative correlations, we repeated all analyses without GSR. In this sensitivity analysis, whole-brain energy and motif differences were attenuated, but bipolarity, a measure of global two-block signed network organization, became the only FDR-significant metric (pFDR = 0.047), with ASD showing higher bipolarity. Intra-network energy differences did not survive FDR correction under either pipeline. Coevolutionary energy showed modest associations with ADI-R and ADOS scores, none of which survived correction across 720 tests. Machine learning classification achieved 77.8% test accuracy (AUC = 0.79) with GSR and 64.7% (AUC = 0.65) without GSR. These findings suggest that coevolutionary balance captures altered signed network organization in ASD, though the specific metric driving group differences depends on preprocessing choices regarding global signal regression.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09045v3</guid>
      <category>q-bio.NC</category>
      <category>physics.bio-ph</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>S. Rezaei Afshar, G. Reza Jafari</dc:creator>
    </item>
    <item>
      <title>Kinetic energy in random recurrent neural networks</title>
      <link>https://arxiv.org/abs/2508.04983</link>
      <description>arXiv:2508.04983v2 Announce Type: replace-cross 
Abstract: High-dimensional chaotic dynamics can emerge in a large random recurrent neural network when the synaptic gain crosses a threshold. Recent works showed that the kinetic energy of neural activity links the chaotic dynamics and the supporting unstable fixed points (equilibria) in the phase space. Here, we investigate the kinetic-energy-centric properties of random recurrent neural networks by combining dynamical mean-field theory with extensive numerical simulations. We find that the average kinetic energy shifts continuously from zero to a positive value at a critical value of coupling variance (synaptic gain) and exhibits a cubic scaling behavior near the critical point from above. This scaling behavior is supported by numerical simulations and provides a quantitative characterization of how fast the dynamics change during the onset of chaos. The steady-state activity distribution is further calculated by the theory and compared with simulations on finite-size systems from the kinetic-energy optimization perspective as well. The activity distribution is also analyzed in a geometric angle, establishing a relationship between the original chaotic dynamics and the gradient dynamics of the kinetic energy. The trajectory length on the chaotic manifold can be derived from the stationary kinetic energy, and the associated stationary behavior is analyzed as well. This study provides a kinetic-energy-centric route toward understanding the dynamics landscape of recurrent neural networks, which may provide insights for reservoir computing and even for internal synaptic learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04983v2</guid>
      <category>cond-mat.stat-mech</category>
      <category>nlin.CD</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Li-Ru Zhang, Haiping Huang</dc:creator>
    </item>
    <item>
      <title>Emergence of Chimeras States in One-dimensional Ising model with Long-Range Diffusion</title>
      <link>https://arxiv.org/abs/2510.24903</link>
      <description>arXiv:2510.24903v2 Announce Type: replace-cross 
Abstract: In this work, we examine the conditions for the emergence of chimera-like states in Ising systems. We study an Ising chain with periodic boundaries in contact with a thermal bath at temperature T, that induces stochastic changes in spin variables. To capture the non-locality needed for chimera formation, we introduce a model setup with non-local diffusion of spin values through the whole system. More precisely, diffusion is modeled through spin-exchange interactions between units up to a distance R, using Kawasaki dynamics. This setup mimics, e.g., neural media, as the brain, in the presence of electrical (diffusive) interactions. We explored the influence of such non-local dynamics on the emergence of complex spatiotemporal synchronization patterns of activity. Depending on system parameters we report here for the first time chimera-like states in the Ising model, characterized by relatively stable moving domains of spins with different local magnetization. We analyzed the system at T=0, both analytically and via simulations and computed the system's phase diagram, revealing rich behavior: regions with only chimeras, coexistence of chimeras and stable domains, and metastable chimeras that decay into uniform stable domains. This study offers fundamental insights into how coherent and incoherent synchronization patterns can arise in complex networked systems as it is, e.g., the brain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.24903v2</guid>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.chaos.2026.118068</arxiv:DOI>
      <arxiv:journal_reference>Chaos, Solitons and Fractals 207, 118068 (2026)</arxiv:journal_reference>
      <dc:creator>Alejandro de Haro Garc\'ia, Joaqu\'in J. Torres</dc:creator>
    </item>
  </channel>
</rss>
