<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.hist-ph updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.hist-ph</link>
    <description>physics.hist-ph updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.hist-ph" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 01 Apr 2024 04:07:43 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 01 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Revisiting Taylor and the Trinity Test</title>
      <link>https://arxiv.org/abs/2403.19657</link>
      <description>arXiv:2403.19657v1 Announce Type: new 
Abstract: The atomic bomb uses fission of heavy elements to produce a large amount of energy. It was designed and deployed during World War II by the United States military. The first test of an atomic bomb occurred in July of 1945 in New Mexico and was given the name Trinity; this test was not declassified until 1949. In that year Geoffrey Ingram Taylor released two papers, detailing his process in calculating the energy yield of the atomic bomb from pictures of the Trinity explosion alone. Many scientists made similar calculations concurrently, though Taylor is often accredited with them. Since then many scientists have also attempted a to calculate a yield through various methods. This paper walks through these methods with a focus on Taylor's method -- based on first principles -- as well as redoing the calculations that he performed with modern tools. In this paper we make use of the state-of-the-art computer vision tools to find a more precise measurement of the blast radius, as well as using curve fitting and numerical integration methods. With more precise measurements we are able to follow in Taylor's footstep towards a more accurate approximation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.19657v1</guid>
      <category>physics.hist-ph</category>
      <category>physics.data-an</category>
      <category>physics.flu-dyn</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elizabeth Mone (College of Sciences, Georgia Institute of Technology, Atlanta, Georgia), Pranay Seshadri (College of Engineering, Georgia Institute of Technology, Atlanta, Georgia)</dc:creator>
    </item>
    <item>
      <title>Analysis of classical and quantum mechanical concepts of probability: A synopsis</title>
      <link>https://arxiv.org/abs/2403.19658</link>
      <description>arXiv:2403.19658v1 Announce Type: new 
Abstract: This paper addresses the central question of what a coherent concept of probability might look like that would do justice to both classical probability theory, axiomatized by Kolmogorov, and quantum theory. At a time when quanta are receiving increased and expanded attention -- think, for example, of the advances in quantum computers or the promises associated with this new technology (National Academies of Sciences: Engineering, and Medicine, 2019) -- an adequate interpretation of probability, which is no less important, should be given due attention, particularly with regard to quantum theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.19658v1</guid>
      <category>physics.hist-ph</category>
      <category>quant-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Christian Hugo Hoffmann</dc:creator>
    </item>
    <item>
      <title>Drude's lesser known error of a factor of two and Lorentz's correction</title>
      <link>https://arxiv.org/abs/2403.19682</link>
      <description>arXiv:2403.19682v1 Announce Type: new 
Abstract: As is well known, Paul Drude put forward the very first quantitative theory of electrical conduction in metals in 1900. He could successfully account for the Wiedemann-Franz law which states that the ratio of thermal to electrical conductivity divided by temperature is a constant called the Lorenz number. As it turns out, in Drude's derivation, there is a lucky cancellation of two errors. Drude's under-estimate (by an order of 100) of the value of square of the average electron velocity compensated his over-estimate of the electronic heat capacity (by the same order of 100). This compensation or cancellation of two errors lead to a value of the Lorenz number very close to its experimental value. This is well known. There is another error of a factor of two which Drude made when he calculated two different relaxation times for heat conductivity and electrical conductivity. In this article we highlight how and why this error occurred in Drude's derivation and how it was removed 5 years later (that is in 1905) by Hendrik Lorentz when he used the Boltzmann equation and a single relaxation time. This article is of pedagogical value and may be useful to undergraduate/graduate students learning solid state physics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.19682v1</guid>
      <category>physics.hist-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Navinder Singh</dc:creator>
    </item>
    <item>
      <title>The Higgs Mass and a Perspective on Broken Autonomy of Scales</title>
      <link>https://arxiv.org/abs/2403.20282</link>
      <description>arXiv:2403.20282v1 Announce Type: new 
Abstract: The hierarchy problem of the Higgs mass, the violation of the autonomy of far-distant energy scales, is identified as a pseudo-problem. The pseudo-problem is based on the dogmatic adherence to the methodology of effective theories, for which there is no justification when dealing with presumably fundamental phenomena such as the Higgs mechanism. In view of further breaches of autonomy of scales in fundamental principles outside particle physics, the hierarchy problem is instead reinterpreted as an indication of the fundamental ontological status of the Higgs boson. Selective Realism justifies this attribution within the effective theories of the standard model of particle physics. Moreover, a model of changes in aesthetic canons provides an explanation for the existing dogmatism regarding effective theories.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.20282v1</guid>
      <category>physics.hist-ph</category>
      <category>hep-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Johannes Branahl</dc:creator>
    </item>
  </channel>
</rss>
