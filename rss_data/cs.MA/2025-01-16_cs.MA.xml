<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.MA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.MA</link>
    <description>cs.MA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.MA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 16 Jan 2025 05:00:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Heterogeneous Update Processes Shape Information Cascades in Social Networks</title>
      <link>https://arxiv.org/abs/2501.08498</link>
      <description>arXiv:2501.08498v1 Announce Type: new 
Abstract: A common assumption in the literature on information diffusion is that populations are homogeneous regarding individuals' information acquisition and propagation process: Individuals update their informed and actively communicating state either through imitation (simple contagion) or peer influence (complex contagion). Here, we study the impact of the mixing and placement of individuals with different update processes on how information cascades in social networks. We consider Simple Spreaders, which take information from a random neighbor and communicate it, and Threshold-based Spreaders, which require a threshold number of active neighbors to change their state to active communication. Even though, in a population made exclusively of Simple Spreaders, information reaches all elements of any (connected) network, we show that, when Simple and Threshold-based Spreaders coexist and occupy random positions in a social network, the number of Simple Spreaders systematically amplifies the cascades only in degree heterogeneous networks (exponential and scale-free). In random and modular structures, this cascading effect originated by Simple Spreaders only exists above a critical mass of these individuals. In contrast, when Threshold-based Spreaders are assorted preferentially in the nodes with a higher degree, the cascading effect of Simple Spreaders vanishes, and the spread of information is drastically impaired. Overall, the study highlights the significance of the strategic placement of different roles in networked structures, with Simple Spreaders driving widespread cascades in heterogeneous networks and Threshold-based Spreaders playing a critical regulatory role in information spread with a tunable effect based on the threshold value.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08498v1</guid>
      <category>cs.MA</category>
      <category>cs.SI</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fl\'avio L. Pinheiro, V\'itor V. Vasconcelos</dc:creator>
    </item>
    <item>
      <title>Ensuring Truthfulness in Distributed Aggregative Optimization</title>
      <link>https://arxiv.org/abs/2501.08512</link>
      <description>arXiv:2501.08512v1 Announce Type: new 
Abstract: Distributed aggregative optimization methods are gaining increased traction due to their ability to address cooperative control and optimization problems, where the objective function of each agent depends not only on its own decision variable but also on the aggregation of other agents' decision variables. Nevertheless, existing distributed aggregative optimization methods implicitly assume all agents to be truthful in information sharing, which can be unrealistic in real-world scenarios, where agents may act selfishly or strategically. In fact, an opportunistic agent may deceptively share false information in its own favor to minimize its own loss, which, however, will compromise the network-level global performance. To solve this issue, we propose a new distributed aggregative optimization algorithm that can ensure truthfulness of agents and convergence performance. To the best of our knowledge, this is the first algorithm that ensures truthfulness in a fully distributed setting, where no "centralized" aggregator exists to collect private information/decision variables from participating agents. We systematically characterize the convergence rate of our algorithm under nonconvex/convex/strongly convex objective functions, which generalizes existing distributed aggregative optimization results that only focus on convex objective functions. We also rigorously quantify the tradeoff between convergence performance and the level of enabled truthfulness under different convexity conditions. Numerical simulations using distributed charging of electric vehicles confirm the efficacy of our algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08512v1</guid>
      <category>cs.MA</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziqin Chen, Magnus Egerstedt, Yongqiang Wang</dc:creator>
    </item>
    <item>
      <title>Separation Assurance in Urban Air Mobility Systems using Shared Scheduling Protocols</title>
      <link>https://arxiv.org/abs/2501.08933</link>
      <description>arXiv:2501.08933v1 Announce Type: new 
Abstract: Ensuring safe separation between aircraft is a critical challenge in air traffic management, particularly in urban air mobility (UAM) environments where high traffic density and low altitudes require precise control. In these environments, conflicts often arise at the intersections of flight corridors, posing significant risks. We propose a tactical separation approach leveraging shared scheduling protocols, originally designed for Ethernet networks and operating systems, to coordinate access to these intersections. Using a decentralized Markov decision process framework, the proposed approach enables aircraft to autonomously adjust their speed and timing as they navigate these critical areas, maintaining safe separation without a central controller. We evaluate the effectiveness of this approach in simulated UAM scenarios, demonstrating its ability to reduce separation violations to zero while acknowledging trade-offs in flight times as traffic density increases. Additionally, we explore the impact of non-compliant aircraft, showing that while shared scheduling protocols can no longer guarantee safe separation, they still provide significant improvements over systems without scheduling protocols.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08933v1</guid>
      <category>cs.MA</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.2514/6.2025-2116</arxiv:DOI>
      <arxiv:journal_reference>AIAA SciTech 2025 AIAA SciTech 2025 AIAA SciTech 2025 Forum</arxiv:journal_reference>
      <dc:creator>Surya Murthy, Tyler Ingebrand, Sophia Smith, Ufuk Topcu, Peng Wei, Natasha Neogi</dc:creator>
    </item>
    <item>
      <title>A Reinforcement Learning Approach to Quiet and Safe UAM Traffic Management</title>
      <link>https://arxiv.org/abs/2501.08941</link>
      <description>arXiv:2501.08941v1 Announce Type: new 
Abstract: Urban air mobility (UAM) is a transformative system that operates various small aerial vehicles in urban environments to reshape urban transportation. However, integrating UAM into existing urban environments presents a variety of complex challenges. Recent analyses of UAM's operational constraints highlight aircraft noise and system safety as key hurdles to UAM system implementation. Future UAM air traffic management schemes must ensure that the system is both quiet and safe. We propose a multi-agent reinforcement learning approach to manage UAM traffic, aiming at both vertical separation assurance and noise mitigation. Through extensive training, the reinforcement learning agent learns to balance the two primary objectives by employing altitude adjustments in a multi-layer UAM network. The results reveal the tradeoffs among noise impact, traffic congestion, and separation. Overall, our findings demonstrate the potential of reinforcement learning in mitigating UAM's noise impact while maintaining safe separation using altitude adjustments</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08941v1</guid>
      <category>cs.MA</category>
      <category>cs.LG</category>
      <category>cs.RO</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.2514/6.2025-2118</arxiv:DOI>
      <arxiv:journal_reference>AIAA SciTech 2025 Forum</arxiv:journal_reference>
      <dc:creator>Surya Murthy, John-Paul Clarke, Ufuk Topcu, Zhenyu Gao</dc:creator>
    </item>
    <item>
      <title>Physical AI Agents: Integrating Cognitive Intelligence with Real-World Action</title>
      <link>https://arxiv.org/abs/2501.08944</link>
      <description>arXiv:2501.08944v1 Announce Type: new 
Abstract: Vertical AI Agents are revolutionizing industries by delivering domain-specific intelligence and tailored solutions. However, many sectors, such as manufacturing, healthcare, and logistics, demand AI systems capable of extending their intelligence into the physical world, interacting directly with objects, environments, and dynamic conditions. This need has led to the emergence of Physical AI Agents--systems that integrate cognitive reasoning, powered by specialized LLMs, with precise physical actions to perform real-world tasks.
  This work introduces Physical AI Agents as an evolution of shared principles with Vertical AI Agents, tailored for physical interaction. We propose a modular architecture with three core blocks--perception, cognition, and actuation--offering a scalable framework for diverse industries. Additionally, we present the Physical Retrieval Augmented Generation (Ph-RAG) design pattern, which connects physical intelligence to industry-specific LLMs for real-time decision-making and reporting informed by physical context.
  Through case studies, we demonstrate how Physical AI Agents and the Ph-RAG framework are transforming industries like autonomous vehicles, warehouse robotics, healthcare, and manufacturing, offering businesses a pathway to integrate embodied AI for operational efficiency and innovation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08944v1</guid>
      <category>cs.MA</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Fouad Bousetouane</dc:creator>
    </item>
    <item>
      <title>Characterizations of voting rules based on majority margins</title>
      <link>https://arxiv.org/abs/2501.08595</link>
      <description>arXiv:2501.08595v1 Announce Type: cross 
Abstract: In the context of voting with ranked ballots, an important class of voting rules is the class of margin-based rules (also called pairwise rules). A voting rule is margin-based if whenever two elections generate the same head-to-head margins of victory or loss between candidates, then the voting rule yields the same outcome in both elections. Although this is a mathematically natural invariance property to consider, whether it should be regarded as a normative axiom on voting rules is less clear. In this paper, we address this question for voting rules with any kind of output, whether a set of candidates, a ranking, a probability distribution, etc. We prove that a voting rule is margin-based if and only if it satisfies some axioms with clearer normative content. A key axiom is what we call Preferential Equality, stating that if two voters both rank a candidate $x$ immediately above a candidate $y$, then either voter switching to rank $y$ immediately above $x$ will have the same effect on the election outcome as if the other voter made the switch, so each voter's preference for $y$ over $x$ is treated equally.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08595v1</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yifeng Ding, Wesley H. Holliday, Eric Pacuit</dc:creator>
    </item>
    <item>
      <title>Task Allocation in Mobile Robot Fleets: A review</title>
      <link>https://arxiv.org/abs/2501.08726</link>
      <description>arXiv:2501.08726v1 Announce Type: cross 
Abstract: Mobile robot fleets are currently used in different scenarios such as medical environments or logistics. The management of these systems provides different challenges that vary from the control of the movement of each robot to the allocation of tasks to be performed. Task Allocation (TA) problem is a key topic for the proper management of mobile robot fleets to ensure the minimization of energy consumption and quantity of necessary robots. Solutions on this aspect are essential to reach economic and environmental sustainability of robot fleets, mainly in industry applications such as warehouse logistics. The minimization of energy consumption introduces TA problem as an optimization issue which has been treated in recent studies. This work focuses on the analysis of current trends in solving TA of mobile robot fleets. Main TA optimization algorithms are presented, including novel methods based on Artificial Intelligence (AI). Additionally, this work showcases most important results extracted from simulations, including frameworks utilized for the development of the simulations. Finally, some conclusions are obtained from the analysis to target on gaps that must be treated in the future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08726v1</guid>
      <category>cs.RO</category>
      <category>cs.MA</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andr\'es Meseguer Valenzuela, Francisco Blanes Noguera</dc:creator>
    </item>
    <item>
      <title>Networked Agents in the Dark: Team Value Learning under Partial Observability</title>
      <link>https://arxiv.org/abs/2501.08778</link>
      <description>arXiv:2501.08778v1 Announce Type: cross 
Abstract: We propose a novel cooperative multi-agent reinforcement learning (MARL) approach for networked agents. In contrast to previous methods that rely on complete state information or joint observations, our agents must learn how to reach shared objectives under partial observability. During training, they collect individual rewards and approximate a team value function through local communication, resulting in cooperative behavior. To describe our problem, we introduce the networked dynamic partially observable Markov game framework, where agents communicate over a switching topology communication network. Our distributed method, DNA-MARL, uses a consensus mechanism for local communication and gradient descent for local computation. DNA-MARL increases the range of the possible applications of networked agents, being well-suited for real world domains that impose privacy and where the messages may not reach their recipients. We evaluate DNA-MARL across benchmark MARL scenarios. Our results highlight the superior performance of DNA-MARL over previous methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08778v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guilherme S. Varela, Alberto Sardinha, Francisco S. Melo</dc:creator>
    </item>
    <item>
      <title>Computing Game Symmetries and Equilibria That Respect Them</title>
      <link>https://arxiv.org/abs/2501.08905</link>
      <description>arXiv:2501.08905v1 Announce Type: cross 
Abstract: Strategic interactions can be represented more concisely, and analyzed and solved more efficiently, if we are aware of the symmetries within the multiagent system. Symmetries also have conceptual implications, for example for equilibrium selection. We study the computational complexity of identifying and using symmetries. Using the classical framework of normal-form games, we consider game symmetries that can be across some or all players and/or actions. We find a strong connection between game symmetries and graph automorphisms, yielding graph automorphism and graph isomorphism completeness results for characterizing the symmetries present in a game. On the other hand, we also show that the problem becomes polynomial-time solvable when we restrict the consideration of actions in one of two ways.
  Next, we investigate when exactly game symmetries can be successfully leveraged for Nash equilibrium computation. We show that finding a Nash equilibrium that respects a given set of symmetries is PPAD- and CLS-complete in general-sum and team games respectively -- that is, exactly as hard as Brouwer fixed point and gradient descent problems. Finally, we present polynomial-time methods for the special cases where we are aware of a vast number of symmetries, or where the game is two-player zero-sum and we do not even know the symmetries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08905v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.CC</category>
      <category>cs.MA</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Emanuel Tewolde, Brian Hu Zhang, Caspar Oesterheld, Tuomas Sandholm, Vincent Conitzer</dc:creator>
    </item>
    <item>
      <title>Reciprocal Reward Influence Encourages Cooperation From Self-Interested Agents</title>
      <link>https://arxiv.org/abs/2406.01641</link>
      <description>arXiv:2406.01641v3 Announce Type: replace 
Abstract: Cooperation between self-interested individuals is a widespread phenomenon in the natural world, but remains elusive in interactions between artificially intelligent agents. Instead, naive reinforcement learning algorithms typically converge to Pareto-dominated outcomes in even the simplest of social dilemmas. An emerging literature on opponent shaping has demonstrated the ability to reach prosocial outcomes by influencing the learning of other agents. However, such methods differentiate through the learning step of other agents or optimize for meta-game dynamics, which rely on privileged access to opponents' learning algorithms or exponential sample complexity, respectively. To provide a learning rule-agnostic and sample-efficient alternative, we introduce Reciprocators, reinforcement learning agents which are intrinsically motivated to reciprocate the influence of opponents' actions on their returns. This approach seeks to modify other agents' $Q$-values by increasing their return following beneficial actions (with respect to the Reciprocator) and decreasing it after detrimental actions, guiding them towards mutually beneficial actions without directly differentiating through a model of their policy. We show that Reciprocators can be used to promote cooperation in temporally extended social dilemmas during simultaneous learning. Our code is available at https://github.com/johnlyzhou/reciprocator/.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01641v3</guid>
      <category>cs.MA</category>
      <category>cs.AI</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>John L. Zhou, Weizhe Hong, Jonathan C. Kao</dc:creator>
    </item>
    <item>
      <title>Learning Optimal Tax Design in Nonatomic Congestion Games</title>
      <link>https://arxiv.org/abs/2402.07437</link>
      <description>arXiv:2402.07437v2 Announce Type: replace-cross 
Abstract: In multiplayer games, self-interested behavior among the players can harm the social welfare. Tax mechanisms are a common method to alleviate this issue and induce socially optimal behavior. In this work, we take the initial step of learning the optimal tax that can maximize social welfare with limited feedback in congestion games. We propose a new type of feedback named \emph{equilibrium feedback}, where the tax designer can only observe the Nash equilibrium after deploying a tax plan. Existing algorithms are not applicable due to the exponentially large tax function space, nonexistence of the gradient, and nonconvexity of the objective. To tackle these challenges, we design a computationally efficient algorithm that leverages several novel components: (1) a piece-wise linear tax to approximate the optimal tax; (2) extra linear terms to guarantee a strongly convex potential function; (3) an efficient subroutine to find the exploratory tax that can provide critical information about the game. The algorithm can find an $\epsilon$-optimal tax with $O(\beta F^2/\epsilon)$ sample complexity, where $\beta$ is the smoothness of the cost function and $F$ is the number of facilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.07437v2</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiwen Cui, Maryam Fazel, Simon S. Du</dc:creator>
    </item>
    <item>
      <title>Equilibria in multiagent online problems with predictions</title>
      <link>https://arxiv.org/abs/2405.11873</link>
      <description>arXiv:2405.11873v2 Announce Type: replace-cross 
Abstract: We study the power of (competitive) algorithms with predictions in a multiagent setting. To this goal, we introduce a multiagent version of the ski-rental problem. In this problem agents can collaborate by pooling resources to get a group license for some asset. If the license price is not met then agents have to rent the asset individually for the day at a unit price. Otherwise the license becomes available forever to everyone at no extra cost.
  We investigate the effect of using predictors for self and others' behavior in such a setting, as well as the new equilibria formed in this way.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11873v2</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <category>cs.MA</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gabriel Istrate, Cosmin Bonchi\c{s}, Victor Bogdan</dc:creator>
    </item>
    <item>
      <title>Integrated Push-and-Pull Update Model for Goal-Oriented Effective Communication</title>
      <link>https://arxiv.org/abs/2407.14092</link>
      <description>arXiv:2407.14092v2 Announce Type: replace-cross 
Abstract: This paper studies decision-making for goal-oriented effective communication. We consider an end-to-end status update system where a sensing agent (SA) observes a source, generates and transmits updates to an actuation agent (AA), while the AA takes actions to accomplish a goal at the endpoint. We integrate the push- and pull-based update communication models to obtain a push-and-pull model, which allows the transmission controller at the SA to decide to push an update to the AA and the query controller at the AA to pull updates by raising queries at specific time instances. To gauge effectiveness, we utilize a grade of effectiveness (GoE) metric incorporating updates' freshness, usefulness, and timeliness of actions as qualitative attributes. We then derive effect-aware policies to maximize the expected discounted sum of updates' effectiveness subject to induced costs. The effect-aware policy at the SA considers the potential effectiveness of communicated updates at the endpoint, while at the AA, it accounts for the probabilistic evolution of the source and importance of generated updates. Our results show the proposed push-and-pull model outperforms models solely based on push- or pull-based updates both in terms of efficiency and effectiveness. Additionally, using effect-aware policies at both agents enhances effectiveness compared to periodic and/or probabilistic effect-agnostic policies at either or both agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14092v2</guid>
      <category>cs.IT</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pouya Agheli, Nikolaos Pappas, Petar Popovski, Marios Kountouris</dc:creator>
    </item>
  </channel>
</rss>
