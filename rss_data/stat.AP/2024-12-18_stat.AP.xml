<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 18 Dec 2024 05:00:00 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Exploring natural variation in tendon constitutive parameters via Bayesian data selection and mixed effects models</title>
      <link>https://arxiv.org/abs/2412.12983</link>
      <description>arXiv:2412.12983v1 Announce Type: new 
Abstract: Combining microstructural mechanical models with experimental data enhances our understanding of the mechanics of soft tissue, such as tendons. In previous work, a Bayesian framework was used to infer constitutive parameters from uniaxial stress-strain experiments on horse tendons, specifically the superficial digital flexor tendon (SDFT) and common digital extensor tendon (CDET), on a per-experiment basis. Here, we extend this analysis to investigate the natural variation of these parameters across a population of horses. Using a Bayesian mixed effects model, we infer population distributions of these parameters. Given that the chosen hyperelastic model does not account for tendon damage, careful data selection is necessary. Avoiding ad hoc methods, we introduce a hierarchical Bayesian data selection method. This two-stage approach selects data per experiment, and integrates data weightings into the Bayesian mixed effects model. Our results indicate that the CDET is stiffer than the SDFT, likely due to a higher collagen volume fraction. The modes of the parameter distributions yield estimates of the product of the collagen volume fraction and Young's modulus as 811.5 MPa for the SDFT and 1430.2 MPa for the CDET. This suggests that positional tendons have stiffer collagen fibrils and/or higher collagen volume density than energy-storing tendons.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12983v1</guid>
      <category>stat.AP</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>James Casey, Jessica Forsyth, Timothy Waite, Simon Cotter, Tom Shearer</dc:creator>
    </item>
    <item>
      <title>Unified calibration and spatial mapping of fine particulate matter data from multiple low-cost air pollution sensor networks in Baltimore, Maryland</title>
      <link>https://arxiv.org/abs/2412.13034</link>
      <description>arXiv:2412.13034v1 Announce Type: new 
Abstract: Low-cost air pollution sensor networks are increasingly being deployed globally, supplementing sparse regulatory monitoring with localized air quality data. In some areas, like Baltimore, Maryland, there are only few regulatory (reference) devices but multiple low-cost networks. While there are many available methods to calibrate data from each network individually, separate calibration of each network leads to conflicting air quality predictions. We develop a general Bayesian spatial filtering model combining data from multiple networks and reference devices, providing dynamic calibrations (informed by the latest reference data) and unified predictions (combining information from all available sensors) for the entire region. This method accounts for network-specific bias and noise (observation models), as different networks can use different types of sensors, and uses a Gaussian process (state-space model) to capture spatial correlations. We apply the method to calibrate PM$_{2.5}$ data from Baltimore in June and July 2023 -- a period including days of hazardous concentrations due to wildfire smoke. Our method helps mitigate the effects of preferential sampling of one network in Baltimore, results in better predictions and narrower confidence intervals. Our approach can be used to calibrate low-cost air pollution sensor data in Baltimore and any other areas with multiple low-cost networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13034v1</guid>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Claire Heffernan, Kirsten Koehler, Drew R. Gentner, Roger D. Peng, Abhirup Datta</dc:creator>
    </item>
    <item>
      <title>How Often are Fingerprints Repeated in the Population? Expanding on Evidence from AI With the Birthday Paradox</title>
      <link>https://arxiv.org/abs/2412.13135</link>
      <description>arXiv:2412.13135v1 Announce Type: new 
Abstract: The assumption of fingerprint uniqueness is foundational in forensic science and central to criminal identification practices. However, empirical evidence supporting this assumption is limited, and recent findings from artificial intelligence challenge its validity. This paper uses a probabilistic approach to examine whether fingerprint patterns remain unique across large populations. We do this by drawing on Francis Galton's 1892 argument and applying the birthday paradox to estimate the probability of fingerprint repetition. Our findings indicate that there is a 50\% probability of coincidental fingerprint matches in populations of 14 million, rising to near certainty at 40 million, which contradicts the traditional view of fingerprints as unique identifiers. We introduce the concept of a Random Overlap Probability (ROP) to assess the likelihood of fingerprint repetition within specific population sizes. We recommend a shift toward probabilistic models for fingerprint comparisons that account for the likelihood of pattern repetition. This approach could strengthen the reliability and fairness of fingerprint comparisons in the criminal justice system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13135v1</guid>
      <category>stat.AP</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jackson Gold, Maria Cuellar</dc:creator>
    </item>
    <item>
      <title>How to Choose a Threshold for an Evaluation Metric for Large Language Models</title>
      <link>https://arxiv.org/abs/2412.12148</link>
      <description>arXiv:2412.12148v1 Announce Type: cross 
Abstract: To ensure and monitor large language models (LLMs) reliably, various evaluation metrics have been proposed in the literature. However, there is little research on prescribing a methodology to identify a robust threshold on these metrics even though there are many serious implications of an incorrect choice of the thresholds during deployment of the LLMs. Translating the traditional model risk management (MRM) guidelines within regulated industries such as the financial industry, we propose a step-by-step recipe for picking a threshold for a given LLM evaluation metric. We emphasize that such a methodology should start with identifying the risks of the LLM application under consideration and risk tolerance of the stakeholders. We then propose concrete and statistically rigorous procedures to determine a threshold for the given LLM evaluation metric using available ground-truth data. As a concrete example to demonstrate the proposed methodology at work, we employ it on the Faithfulness metric, as implemented in various publicly available libraries, using the publicly available HaluBench dataset. We also lay a foundation for creating systematic approaches to select thresholds, not only for LLMs but for any GenAI applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12148v1</guid>
      <category>stat.ML</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <category>q-fin.ST</category>
      <category>stat.AP</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bhaskarjit Sarmah, Mingshu Li, Jingrao Lyu, Sebastian Frank, Nathalia Castellanos, Stefano Pasquali, Dhagash Mehta</dc:creator>
    </item>
    <item>
      <title>On the Role of Surrogates in Conformal Inference of Individual Causal Effects</title>
      <link>https://arxiv.org/abs/2412.12365</link>
      <description>arXiv:2412.12365v1 Announce Type: cross 
Abstract: Learning the Individual Treatment Effect (ITE) is essential for personalized decision making, yet causal inference has traditionally focused on aggregated treatment effects. While integrating conformal prediction with causal inference can provide valid uncertainty quantification for ITEs, the resulting prediction intervals are often excessively wide, limiting their practical utility. To address this limitation, we introduce \underline{S}urrogate-assisted \underline{C}onformal \underline{I}nference for \underline{E}fficient I\underline{N}dividual \underline{C}ausal \underline{E}ffects (SCIENCE), a framework designed to construct more efficient prediction intervals for ITEs. SCIENCE applies to various data configurations, including semi-supervised and surrogate-assisted semi-supervised learning. It accommodates covariate shifts between source data, which contain primary outcomes, and target data, which may include only surrogate outcomes or covariates. Leveraging semi-parametric efficiency theory, SCIENCE produces rate double-robust prediction intervals under mild rate convergence conditions, permitting the use of flexible non-parametric models to estimate nuisance functions. We quantify efficiency gains by comparing semi-parametric efficiency bounds with and without the incorporation of surrogates. Simulation studies demonstrate that our surrogate-assisted intervals offer substantial efficiency improvements over existing methods while maintaining valid group-conditional coverage. Applied to the phase 3 Moderna COVE COVID-19 vaccine trial, SCIENCE illustrates how multiple surrogate markers can be leveraged to generate more efficient prediction intervals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12365v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Chenyin Gao, Peter B. Gilbert, Larry Han</dc:creator>
    </item>
    <item>
      <title>OpenViewer: Openness-Aware Multi-View Learning</title>
      <link>https://arxiv.org/abs/2412.12596</link>
      <description>arXiv:2412.12596v1 Announce Type: cross 
Abstract: Multi-view learning methods leverage multiple data sources to enhance perception by mining correlations across views, typically relying on predefined categories. However, deploying these models in real-world scenarios presents two primary openness challenges. 1) Lack of Interpretability: The integration mechanisms of multi-view data in existing black-box models remain poorly explained; 2) Insufficient Generalization: Most models are not adapted to multi-view scenarios involving unknown categories. To address these challenges, we propose OpenViewer, an openness-aware multi-view learning framework with theoretical support. This framework begins with a Pseudo-Unknown Sample Generation Mechanism to efficiently simulate open multi-view environments and previously adapt to potential unknown samples. Subsequently, we introduce an Expression-Enhanced Deep Unfolding Network to intuitively promote interpretability by systematically constructing functional prior-mapping modules and effectively providing a more transparent integration mechanism for multi-view data. Additionally, we establish a Perception-Augmented Open-Set Training Regime to significantly enhance generalization by precisely boosting confidences for known categories and carefully suppressing inappropriate confidences for unknown ones. Experimental results demonstrate that OpenViewer effectively addresses openness challenges while ensuring recognition performance for both known and unknown samples. The code is released at https://github.com/dushide/OpenViewer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12596v1</guid>
      <category>cs.CV</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shide Du, Zihan Fang, Yanchao Tan, Changwei Wang, Shiping Wang, Wenzhong Guo</dc:creator>
    </item>
    <item>
      <title>Fast return-level estimates for flood insurance via an improved Bennett inequality for random variables with differing upper bounds</title>
      <link>https://arxiv.org/abs/2311.10001</link>
      <description>arXiv:2311.10001v2 Announce Type: replace 
Abstract: Insurance losses due to flooding can be estimated by simulating and then summing a large number of losses for each in a large set of hypothetical years of flood events. Replicated realisations lead to Monte Carlo return-level estimates and associated uncertainty. The procedure, however, is highly computationally intensive. We develop and use a new, Bennett-like concentration inequality to provide conservative but relatively accurate estimates of return levels. Bennett's inequality accounts for the different variances of each of the variables in a sum but uses a uniform upper bound on their support. Motivated by the variability in the total insured value of risks within a portfolio, we incorporate both individual upper bounds and variances and obtain tractable concentration bounds. Simulation studies and application to a representative portfolio demonstrate a substantial tightening compared with Bennett's bound. We then develop an importance-sampling procedure that repeatedly samples the loss for each year from the distribution implied by the concentration inequality, leading to conservative estimates of the return levels and their uncertainty using orders of magnitude less computation. This enables a simulation study of the sensitivity of the predictions to perturbations in quantities that are usually assumed fixed and known but, in truth, are not.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.10001v2</guid>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anna Maria Barlow, Chris Sherlock</dc:creator>
    </item>
    <item>
      <title>Development of COVID-19 Booster Vaccine Policy by Microsimulation and Q-learning</title>
      <link>https://arxiv.org/abs/2410.12936</link>
      <description>arXiv:2410.12936v2 Announce Type: replace 
Abstract: The COVID-19 pandemic highlighted the urgent need for effective vaccine policies, but traditional clinical trials often lack sufficient data to capture the diverse population characteristics necessary for comprehensive public health strategies. Ethical concerns around randomized trials during a pandemic further complicate policy development for public health. Reinforcement Learning (RL) offers a promising alternative for vaccine policy development. However, direct online RL exploration in real-world scenarios can result in suboptimal and potentially harmful decisions. This study proposes a novel framework combining tabular Q-learning with microsimulation (i.e., a Recurrent Neural Network (RNN) environment simulator) to address these challenges in public health vaccine policymaking, which enables effective vaccine policy learning without real-world interaction, addressing both ethical and exploration challenges. The RNN environment simulator captures temporal associations between infection and patient characteristics, generating realistic simulation data. Our tabular Q-learning model produces an interpretable policy table that balances the risks of severe infection against vaccination side effects. Applied to COVID-19 booster policies, the learned Q-learning-based policy outperforms current practices, offering a path toward more effective vaccination strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12936v2</guid>
      <category>stat.AP</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guoxuan Ma, Lili Zhao, Jian Kang</dc:creator>
    </item>
    <item>
      <title>Clusterability test for categorical data</title>
      <link>https://arxiv.org/abs/2307.07346</link>
      <description>arXiv:2307.07346v2 Announce Type: replace-cross 
Abstract: The objective of clusterability evaluation is to check whether a clustering structure exists within the data set. As a crucial yet often-overlooked issue in cluster analysis, it is essential to conduct such a test before applying any clustering algorithm. If a data set is unclusterable, any subsequent clustering analysis would not yield valid results. Despite its importance, the majority of existing studies focus on numerical data, leaving the clusterability evaluation issue for categorical data as an open problem. Here we present TestCat, a testing-based approach to assess the clusterability of categorical data in terms of an analytical $p$-value. The key idea underlying TestCat is that clusterable categorical data possess many strongly associated attribute pairs and hence the sum of chi-squared statistics of all attribute pairs is employed as the test statistic for $p$-value calculation. We apply our method to a set of benchmark categorical data sets, showing that TestCat outperforms those solutions based on existing clusterability evaluation methods for numeric data. To the best of our knowledge, our work provides the first way to effectively recognize the clusterability of categorical data in a statistically sound manner.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.07346v2</guid>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lianyu Hu, Junjie Dong, Mudi Jiang, Yan Liu, Zengyou He</dc:creator>
    </item>
    <item>
      <title>An Ising Similarity Regression Model for Modeling Multivariate Binary Data</title>
      <link>https://arxiv.org/abs/2401.13379</link>
      <description>arXiv:2401.13379v2 Announce Type: replace-cross 
Abstract: Understanding the dependence structure between response variables is an important component in the analysis of correlated multivariate data. This article focuses on modeling dependence structures in multivariate binary data, motivated by a study aiming to understand how patterns in different U.S. senators' votes are determined by similarities (or lack thereof) in their attributes, e.g., political parties and social network profiles. To address such a research question, we propose a new Ising similarity regression model which regresses pairwise interaction coefficients in the Ising model against a set of similarity measures available/constructed from covariates. Model selection approaches are further developed through regularizing the pseudo-likelihood function with an adaptive lasso penalty to enable the selection of relevant similarity measures. We establish estimation and selection consistency of the proposed estimator under a general setting where the number of similarity measures and responses tend to infinity. Simulation study demonstrates the strong finite sample performance of the proposed estimator, particularly compared with several existing Ising model estimators in estimating the matrix of pairwise interaction coefficients. Applying the Ising similarity regression model to a dataset of roll call voting records of 100 U.S. senators, we are able to quantify how similarities in senators' parties, businessman occupations and social network profiles drive their voting associations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.13379v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhi Yang Tho, Francis K. C. Hui, Tao Zou</dc:creator>
    </item>
    <item>
      <title>Moving Aggregate Modified Autoregressive Copula-Based Time Series Models (MAGMAR-Copulas)</title>
      <link>https://arxiv.org/abs/2402.01491</link>
      <description>arXiv:2402.01491v2 Announce Type: replace-cross 
Abstract: Copula-based time series models implicitly assume a finite Markov order. In reality a time series may not follow the Markov property. We modify the copula-based time series models by introducing a moving aggregate (MAG) part into the model updating equation. The functional form of the MAG-part is given as the inverse of a conditional copula. The resulting MAG-modified Autoregressive Copula-Based Time Series model (MAGMAR-Copula) is discussed in detail and distributional properties are derived in a D-vine framework. The model nests the classical ARMA model and can be interpreted as a non-linear generalization of the ARMA-model. The modeling performance is evaluated by modeling US inflation. Our model is competitive with benchmark models in terms of information criteria.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.01491v2</guid>
      <category>stat.ME</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sven Pappert</dc:creator>
    </item>
    <item>
      <title>General Seemingly Unrelated Local Projections</title>
      <link>https://arxiv.org/abs/2410.17105</link>
      <description>arXiv:2410.17105v2 Announce Type: replace-cross 
Abstract: We provide a framework for efficiently estimating impulse response functions with Local Projections (LPs). Our approach offers a Bayesian treatment for LPs with Instrumental Variables, accommodating multiple shocks and instruments per shock, accounts for autocorrelation in multi-step forecasts by jointly modeling all LPs as a seemingly unrelated system of equations, defines a flexible yet parsimonious joint prior for impulse responses based on a Gaussian Process, allows for joint inference about the entire vector of impulse responses, and uses all available data across horizons by imputing missing values.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.17105v2</guid>
      <category>econ.EM</category>
      <category>stat.AP</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Florian Huber, Christian Matthes, Michael Pfarrhofer</dc:creator>
    </item>
  </channel>
</rss>
