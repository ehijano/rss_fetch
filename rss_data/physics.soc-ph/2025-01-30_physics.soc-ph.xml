<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.soc-ph updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.soc-ph</link>
    <description>physics.soc-ph updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.soc-ph" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 30 Jan 2025 05:03:33 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 30 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Dilemmas and trade-offs in the diffusion of conventions</title>
      <link>https://arxiv.org/abs/2501.17300</link>
      <description>arXiv:2501.17300v1 Announce Type: new 
Abstract: Outside ideal settings, conventions are shaped by heterogeneous competing processes that can challenge the emergence of universal norms. This paper identifies three trade-offs challenging the diffusion of conventions and explores each of them empirically using observational behavioral data. The first trade-off (I) concerns the imperatives of social, sequential, and contextual consistency that individuals must balance when choosing between competing conventions. The second trade-off (II) involves the balance between local and global coordination, depending on whether individuals coordinate their behavior via interactions throughout a social network or external factors transcending the network. The third trade-off (III) is the balance between decision optimality (e.g., collective satisfaction) and decision costs when collectives with conflicting preferences choose one convention. We develop a utilitarian account of conventions which we translate into a broadly applicable statistical physics framework for measuring each of these trade-offs. We then apply this framework to a sign convention in physics using textual and network data. Our analysis suggests that the purpose of conventions may exceed coordination, and that multiple infrastructures (including prior cultural traits and social networks) concurrently shape individual preferences towards conventions. Additionally, we confirm the role of seniority in resolving conflicting preferences in collaborations, resulting in suboptimal outcomes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.17300v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.SI</category>
      <category>stat.AP</category>
      <pubDate>Thu, 30 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lucas Gautheron</dc:creator>
    </item>
    <item>
      <title>Percolation and localisation: Sub-leading eigenvalues of the nonbacktracking matrix</title>
      <link>https://arxiv.org/abs/2501.17774</link>
      <description>arXiv:2501.17774v1 Announce Type: new 
Abstract: The spectrum of the nonbacktracking matrix associated to a network is known to contain fundamental information regarding percolation properties of the network. Indeed, the inverse of its leading eigenvalue is often used as an estimate for the percolation threshold. However, for many networks with nonbacktracking centrality localised on a few nodes, such as networks with a core-periphery structure, this spectral approach badly underestimates the threshold. In this work, we study networks that exhibit this localisation effect by looking beyond the leading eigenvalue and searching deeper into the spectrum of the nonbacktracking matrix. We identify that, when localisation is present, the threshold often more closely aligns with the inverse of one of the sub-leading real eigenvalues: the largest real eigenvalue with a "delocalised" corresponding eigenvector. We investigate a core-periphery network model and determine, both theoretically and experimentally, a regime of parameters for which our approach closely approximates the threshold, while the estimate derived using the leading eigenvalue does not. We further present experimental results on large scale real-world networks that showcase the usefulness of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.17774v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.SI</category>
      <pubDate>Thu, 30 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>James Martin, Tim Rogers, Luca Zanetti</dc:creator>
    </item>
    <item>
      <title>Disentangling the role of heterogeneity and hyperedge overlap in explosive contagion on higher-order networks</title>
      <link>https://arxiv.org/abs/2501.17800</link>
      <description>arXiv:2501.17800v1 Announce Type: new 
Abstract: Higher-order networks are used to model complex contagion processes in social groups of varying sizes, where heterogeneity and microscopic group arrangements can critically influence the dynamics. However, existing frameworks fail to fully capture the interplay between these features. Here, we introduce group-based compartmental modeling (GBCM), a mean-field framework for irreversible contagion that incorporates heterogeneity and captures correlations across group sizes. Validated through numerical simulations, GBCM analytically disentangles the contributions of different interaction orders to global epidemic dynamics. Our results reveal how heterogeneity and inter-order correlations shape epidemic thresholds and demonstrate that high heterogeneity in group membership drives rapid infection growth, leading to abrupt phase transitions. This provides an explanation for the emergence of explosive contagion in higher-order networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.17800v1</guid>
      <category>physics.soc-ph</category>
      <pubDate>Thu, 30 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Federico Malizia, Andr\'es Guzm\'an, Iacopo Iacopini, Istv\'an Z. Kiss</dc:creator>
    </item>
    <item>
      <title>Exploring the economic, social and environmental prospects for commercial natural annual grasslands by performing a sensitivity analysis on a multidisciplinary integrated model</title>
      <link>https://arxiv.org/abs/2501.17215</link>
      <description>arXiv:2501.17215v1 Announce Type: cross 
Abstract: This paper presents an integrated modelling assessment that estimated the sensitivities of five endogenous factors in commercial rangelands, i.e. number of active farmers, profits, stocking rate, standing herbage biomass, and soil erosion, to the same percentage variation in 70 factors, including economic and climate drivers. The assessment utilised a system dynamics model (107 equations) which represents an area of extensive private farms, its farmers, the main local markets on which they trade, and key ecosystem services involved. The assessment procedure consisted in analysing the behaviours of 288,000 variants of this system during 300 years, each under a different economic and climate scenario. Our key findings were as follows: 1) It is likely that at least annual grasslands will suffer environmental degradation in the future, and that such degradation will be primarily caused by climate change, not by the increasing demand for livestock products; 2) Private farming systems provide social and economic security to farmers against the effects of climate change, especially in a scenario of rising prices of animal products. However, this research will remain incomplete until its methods and results can be contrasted with other similar assessments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.17215v1</guid>
      <category>econ.GN</category>
      <category>physics.soc-ph</category>
      <category>q-fin.EC</category>
      <pubDate>Thu, 30 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.scitotenv.2019.135860</arxiv:DOI>
      <dc:creator>Javier Ib\'a\~nez, Jaime Mart\'inez-Valderrama, Joaqu\'in Francisco Lavado Contador, Manuel Pulido Fern\'andez</dc:creator>
    </item>
    <item>
      <title>Comparative Analysis of Stochastic and Predictable Models in the HIV Epidemic Across Genders</title>
      <link>https://arxiv.org/abs/2501.17259</link>
      <description>arXiv:2501.17259v1 Announce Type: cross 
Abstract: This study conducts a comparative analysis of stochastic and deterministic models to better understand the dynamics of the HIV epidemic across genders. By incorporating gender-specific transmission probabilities and treatment uptake rates, the research addresses gaps in existing models that often overlook these critical factors. The introduction of gender-specific treatment, where only one gender receives treatment, allows for a detailed examination of its effects on both male and female populations. Two compartmental models, divided by gender, are analyzed in parallel to identify the parameters that most significantly impact the control of infected populations and the number of treated females. Stochastic methods, including the Euler, Runge-Kutta, and Non-Standard Finite Difference (SNSFD) approaches, demonstrate that stochastic models provide a more accurate and realistic portrayal of HIV transmission and progression compared to deterministic models. Key findings reveal that the stochastic Runge-Kutta method is particularly effective in capturing the epidemic's complex dynamics, such as subtle fluctuations in transmission and population changes. The study also emphasizes the crucial role of transmission probabilities and treatment rates in shaping the epidemic's trajectory, highlighting their importance for optimizing public health interventions. The research concludes that advanced stochastic modeling is essential for improving public health policies and responses, especially in resource-constrained settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.17259v1</guid>
      <category>q-bio.PE</category>
      <category>physics.soc-ph</category>
      <pubDate>Thu, 30 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nuzhat Nuari Khan Rivu, Md Kamrujjaman, Shohel Ahmed</dc:creator>
    </item>
    <item>
      <title>5G Channel Models for Railway Use Cases at mmWave Band and the Path Towards Terahertz</title>
      <link>https://arxiv.org/abs/2501.17309</link>
      <description>arXiv:2501.17309v1 Announce Type: cross 
Abstract: High-speed trains are one of the most relevant scenarios for the fifth-generation (5G) mobile communications and the "smart rail mobility" vision, where a high-data-rate wireless connectivity with up to several GHz bandwidths will be required. This is a strong motivation for the exploration of millimeter wave (mmWave) band. In this article, we identify the main challenges and make progress towards realistic 5G mmWave channel models for railway use cases. In order to cope with the challenge of including the railway features in the channel models, we define reference scenarios to help the parameterization of channel models for railway use at mmWave band. Simulations and the subsequent measurements used to validate the model reflect the detailed influence of railway objects and the accuracy of the simulations. Finally, we point out the future directions towards the full version of the smart rail mobility which will be powered by terahertz (THz) communications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.17309v1</guid>
      <category>eess.SP</category>
      <category>physics.ins-det</category>
      <category>physics.soc-ph</category>
      <pubDate>Thu, 30 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ke Guan, Juan Moreno Garcia-Lloygorri, Bo Ai, Cesar Briso-Rodriguez, Bile Peng, Danping He, Andrej Hrovat, Zhangdui Zhong, Thomas Kurner</dc:creator>
    </item>
    <item>
      <title>Heuristic-Informed Mixture of Experts for Link Prediction in Multilayer Networks</title>
      <link>https://arxiv.org/abs/2501.17557</link>
      <description>arXiv:2501.17557v1 Announce Type: cross 
Abstract: Link prediction algorithms for multilayer networks are in principle required to effectively account for the entire layered structure while capturing the unique contexts offered by each layer. However, many existing approaches excel at predicting specific links in certain layers but struggle with others, as they fail to effectively leverage the diverse information encoded across different network layers. In this paper, we present MoE-ML-LP, the first Mixture-of-Experts (MoE) framework specifically designed for multilayer link prediction. Building on top of multilayer heuristics for link prediction, MoE-ML-LP synthesizes the decisions taken by diverse experts, resulting in significantly enhanced predictive capabilities. Our extensive experimental evaluation on real-world and synthetic networks demonstrates that MoE-ML-LP consistently outperforms several baselines and competing methods, achieving remarkable improvements of +60% in Mean Reciprocal Rank, +82% in Hits@1, +55% in Hits@5, and +41% in Hits@10. Furthermore, MoE-ML-LP features a modular architecture that enables the seamless integration of newly developed experts without necessitating the re-training of the entire framework, fostering efficiency and scalability to new experts, paving the way for future advancements in link prediction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.17557v1</guid>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <category>physics.soc-ph</category>
      <pubDate>Thu, 30 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lucio La Cava, Domenico Mandaglio, Lorenzo Zangari, Andrea Tagarelli</dc:creator>
    </item>
    <item>
      <title>Comparing temporal and aggregated network descriptions of fluid transport in the Mediterranean Sea</title>
      <link>https://arxiv.org/abs/2306.17527</link>
      <description>arXiv:2306.17527v2 Announce Type: replace 
Abstract: Ocean currents exhibit strong time dependence at all scales that influences physical and biochemical dynamics. Network approaches to fluid transport permit to address explicitly how connectivity across the seascape is affected by the spatiotemporal variability of currents. However, such temporal aspect is mostly neglected, relying on a static representation of the flow. We here investigate the role of current variability on networks describing physical transport across the Mediterranean basin. We first focus on degree distributions and community structure comparing ensembles of temporal networks that explicitly resolve time dependence and their aggregated, i.e. time-averaged, counterparts. Furthermore, we explore the implications of the two approaches in a simple reaction dispersal model for a generic tracer. Our analysis evidences that aggregation induces structural network changes that cannot be easily avoided, not even introducing a pruning of the aggregated adjacency matrix. We also highlight that, depending on the time scales considered, the importance of the temporal features of the networks can vary significantly. Finally, we find that the tracer evolution obtained from a temporal dispersal kernel cannot be always approximated by aggregated adjacency matrices, in particular during transients of the dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.17527v2</guid>
      <category>physics.soc-ph</category>
      <category>physics.flu-dyn</category>
      <category>q-bio.PE</category>
      <pubDate>Thu, 30 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Kishor Acharya, Javier Aguilar, Lorenzo Dall'Amico, Kyriacos Nicolaou, Sandro Meloni, Enrico Ser-Giacomi</dc:creator>
    </item>
    <item>
      <title>Modeling the amplification of epidemic spread by individuals exposed to misinformation on social media</title>
      <link>https://arxiv.org/abs/2402.11351</link>
      <description>arXiv:2402.11351v4 Announce Type: replace-cross 
Abstract: Understanding how misinformation affects the spread of disease is crucial for public health, especially given recent research indicating that misinformation can increase vaccine hesitancy and discourage vaccine uptake. However, it is difficult to investigate the interaction between misinformation and epidemic outcomes due to the dearth of data-informed holistic epidemic models. Here, we employ an epidemic model that incorporates a large, mobility-informed physical contact network as well as the distribution of misinformed individuals across counties derived from social media data. The model allows us to simulate various scenarios to understand how epidemic spreading can be affected by misinformation spreading through one particular social media platform. Using this model, we compare a worst-case scenario, in which individuals become misinformed after a single exposure to low-credibility content, to a best-case scenario where the population is highly resilient to misinformation. We estimate the additional portion of the U.S. population that would become infected over the course of the COVID-19 epidemic in the worst-case scenario. This work can provide policymakers with insights about the potential harms of exposure to online vaccine misinformation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.11351v4</guid>
      <category>cs.SI</category>
      <category>cs.CY</category>
      <category>physics.soc-ph</category>
      <pubDate>Thu, 30 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthew R. DeVerna, Francesco Pierri, Yong-Yeol Ahn, Santo Fortunato, Alessandro Flammini, Filippo Menczer</dc:creator>
    </item>
    <item>
      <title>Projections of Earth's Technosphere: Luminosity and Mass as Limits to Growth</title>
      <link>https://arxiv.org/abs/2410.23420</link>
      <description>arXiv:2410.23420v2 Announce Type: replace-cross 
Abstract: Earth remains the only known example of a planet with technology, and future projections of Earth's trajectory provide a basis and motivation for approaching the search for extraterrestrial technospheres. Conventional approaches toward projecting Earth's technosphere include applications of the Kardashev scale, which suggest the possibility that energy-intensive civilizations may expand to harness the entire energy output available to their planet, host star, or even the entire galaxy. In this study, we argue that the Kardashev scale is better understood as a "luminosity limit" that describes the maximum capacity for a civilization to harvest luminous stellar energy across a given spatial domain, and we note that thermodynamic efficiency will always keep a luminosity-limited technosphere from actually reaching this theoretical limit. We suggest the possibility that an advanced technosphere might evolve beyond this luminosity limit to draw its energy directly from harvesting stellar mass, and we also discuss possible trajectories that could exist between Earth today and such hypothetical "stellivores." We develop a framework to describe trajectories for long-lived technospheres that optimize their growth strategies between exploration and exploitation, unlike Earth today. We note that analyses of compact accreting stars could provide ways to test the stellivore hypothesis, and we more broadly suggest an expansion of technosignature search strategies beyond those that reside exactly at the luminosity limit.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23420v2</guid>
      <category>astro-ph.EP</category>
      <category>physics.pop-ph</category>
      <category>physics.soc-ph</category>
      <pubDate>Thu, 30 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jacob Haqq-Misra, Cl\'ement Vidal, George Profitiliotis</dc:creator>
    </item>
  </channel>
</rss>
