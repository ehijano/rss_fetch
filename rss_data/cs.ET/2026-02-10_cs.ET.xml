<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 11 Feb 2026 02:57:43 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Magnetic Field-Mediated Superconducting Logic</title>
      <link>https://arxiv.org/abs/2602.07146</link>
      <description>arXiv:2602.07146v1 Announce Type: new 
Abstract: While superconductors are highly attractive for energy-efficient computing, fundamental limitations in their logic circuit integration have hindered scaling and led to increased energy consumption. We therefore propose and experimentally demonstrate a novel superconducting switching device utilizing the proximity magnetization from a spin-orbit torque-switched magnet to control the resistivity of a superconductor. We further propose a complete logic family comprised solely of these devices. This novel implementation has the potential to drastically outperform existing superconducting logic families in terms of energy efficiency and scalability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07146v1</guid>
      <category>cs.ET</category>
      <category>cond-mat.supr-con</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander J. Edwards, Son T. Le, Nicholas W. G. Smith, Ebenezer C. Usih, Austin Thomas, Christopher J. K. Richardson, Nicholas A. Blumenschein, Aubrey T. Hanbicki, Adam L. Friedman, Joseph S. Friedman</dc:creator>
    </item>
    <item>
      <title>Physical Analog Kolmogorov-Arnold Networks based on Reconfigurable Nonlinear-Processing Units</title>
      <link>https://arxiv.org/abs/2602.07518</link>
      <description>arXiv:2602.07518v1 Announce Type: new 
Abstract: Kolmogorov-Arnold Networks (KANs) shift neural computation from linear layers to learnable nonlinear edge functions, but implementing these nonlinearities efficiently in hardware remains an open challenge. Here we introduce a physical analog KAN architecture in which edge functions are realized in materia using reconfigurable nonlinear-processing units (RNPUs): multi-terminal nanoscale silicon devices whose input-output characteristics are tuned via control voltages. By combining multiple RNPUs into an edge processor and assembling these blocks into a reconfigurable analog KAN (aKAN) architecture with integrated mixed-signal interfacing, we establish a realistic system-level hardware implementation that enables compact KAN-style regression and classification with programmable nonlinear transformations. Using experimentally calibrated RNPU models and hardware measurements, we demonstrate accurate function approximation across increasing task complexity while requiring fewer or comparable trainable parameters than multilayer perceptrons (MLPs). System-level estimates indicate an energy per inference of $\sim$250 pJ and an end-to-end inference latency of $\sim$600 ns for a representative workload, corresponding to a $\sim$10$^{2}$-10$^{3}\times$ reduction in energy accompanied by a $\sim$10$\times$ reduction in area compared to a digital fixed-point MLP at similar approximation error. These results establish RNPUs as scalable, hardware-native nonlinear computing primitives and identify analog KAN architectures as a realistic silicon-based pathway toward energy-, latency-, and footprint-efficient analog neural-network hardware, particularly for edge inference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07518v1</guid>
      <category>cs.ET</category>
      <category>cs.AR</category>
      <category>cs.LG</category>
      <category>nlin.AO</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Manuel Escudero, Mohamadreza Zolfagharinejad, Sjoerd van den Belt, Nikolaos Alachiotis, Wilfred G. van der Wiel</dc:creator>
    </item>
    <item>
      <title>HoloGraph: All-Optical Graph Learning via Light Diffraction</title>
      <link>https://arxiv.org/abs/2602.07724</link>
      <description>arXiv:2602.07724v1 Announce Type: new 
Abstract: As a representative of next-generation device/circuit technology beyond CMOS, physics-based neural networks such as Diffractive Optical Neural Networks (DONNs) have demonstrated promising advantages in computational speed and energy efficiency. However, existing DONNs and other physics-based neural networks have mostly focused on exploring their machine intelligence, with limited studies in handling graph-structured tasks. Thus, we introduce HoloGraph, the first monolithic free-space all-optical graph neural network system. It proposes a novel, domain-specific message-passing mechanism with optical skip channels integrated into light propagation for the all-optical graph learning. HoloGraph enables light-speed optical message passing over graph structures with diffractive propagation and phase modulations. Our experimental results with HoloGraph, conducted using standard graph learning datasets Cora-ML and Citeseer, show competitive or even superior classification performance compared to conventional digital graph neural networks. Comprehensive ablation studies demonstrate the effectiveness of the proposed novel architecture and algorithmic methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07724v1</guid>
      <category>cs.ET</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yingjie Li, Shanglin Zhou, Caiwen Ding, Cunxi Yu</dc:creator>
    </item>
    <item>
      <title>The CAPSARII Approach to Cyber-Secure Wearable, Ultra-Low-Power Networked Sensors for Soldier Health Monitoring</title>
      <link>https://arxiv.org/abs/2602.08080</link>
      <description>arXiv:2602.08080v1 Announce Type: new 
Abstract: The European Defence Agency's revised Capability Development Plan (CDP) identifies as a priority improving ground combat capabilities by enhancing soldiers' equipment for better protection. The CAPSARII project proposes in innovative wearable system and Internet of Battlefield Things (IoBT) framework to monitor soldiers' physiological and psychological status, aiding tactical decisions and medical support. The CAPSARII system will enhance situational awareness and operational effectiveness by monitoring physiological, movement and environmental parameters, providing real-time tactical decision support through AI models deployed on edge nodes and enable data analysis and comparative studies via cloud-based analytics. CAPSARII also aims at improving usability through smart textile integration, longer battery life, reducing energy consumption through software and hardware optimizations, and address security concerns with efficient encryption and strong authentication methods. This innovative approach aims to transform military operations by providing a robust, data-driven decision support tool.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08080v1</guid>
      <category>cs.ET</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/DSD67783.2025.00086</arxiv:DOI>
      <arxiv:journal_reference>2025 28th Euromicro Conference on Digital System Design (DSD), Salerno, Italy, 2025, pp. 586-591</arxiv:journal_reference>
      <dc:creator>Luciano Bozzi, Christian Celidonio, Umberto Nuzzi, Massimo Biagini, Stefano Cherubin, Asbj{\o}rn Djupdal, Tor Andre Haugdahl, Andrea Aliverti, Alessandra Angelucci, Giovanni Agosta, Gerardo Pelosi, Paolo Belluco, Samuele Polistina, Riccardo Volpi, Luigi Malag\`o, Michael Schneider, Florian Wieczorek, Xabier Eguiluz</dc:creator>
    </item>
    <item>
      <title>Quantization-aware Photonic Homodyne computing for Accelerated Artificial Intelligence and Scientific Simulation</title>
      <link>https://arxiv.org/abs/2602.08269</link>
      <description>arXiv:2602.08269v1 Announce Type: new 
Abstract: Modern problems in high-performance computing, ranging from training and inferencing deep learning models in computer vision and language models to simulating complex physical systems with nonlinearly-coupled equations, require exponential growth of computational resources. Photonic analog systems are emerging with solutions of intrinsic parallelism, high bandwidth, and low propagation loss. However, their application has been hindered by the low analog accuracy due to the electro-optic distortion, material nonlinearities, and signal-to-noise ratios. Here we overcome this barrier with a quantization-aware digital-photonic mixed-precision framework across chiplets for accelerated AI processing and physical simulation. Using Lithium Niobate photonics with channel equalization techniques, we demonstrate linear multiplication (9-bit amplitude-phase decoupling) in homodyne optical logics with 6-bit precision at the clock rate of 128 giga-symbol-per-second (128 GS/s), enabling AI processing with 6 ns latency. Codesign hardware-algorithms, including iterative solvers, sparse-dense quantization, and bit-sliced matrix multiplication, explore photonic amplitude and phase coherence for complex-valued, physics-inspired computation. In electromagnetic problems, our approach yields 12-bit solutions for partial differential equations (PDEs) in scattering problems that would conventionally require up to 32-bit and often even 64-bit precision. These results preserve digital-level fidelity while leveraging the high-speed low-energy photonic hardware, establishing a pathway toward general-purpose optical acceleration for generative artificial intelligence, real-time robotics, and accurate simulation for climate challenges and biological discoveries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08269v1</guid>
      <category>cs.ET</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lian Zhou, Kaiwen Xue, Amirhossein Fallah, Lijin Liu, Chun-Ho Lee, Kiwon Kwon, Clayton Cheung, Yuan Li, Yue Yu, Yun-Jhu Lee, Songlin Zhao, Ryan Hamerly, Edo Waks, Dirk Englund, Constantine Sideris, Mengjie Yu, Zaijun Chen</dc:creator>
    </item>
    <item>
      <title>Stochastic Spiking Neuron Based SNN Can be Inherently Bayesian</title>
      <link>https://arxiv.org/abs/2602.07037</link>
      <description>arXiv:2602.07037v1 Announce Type: cross 
Abstract: Uncertainty in biological neural systems appears to be computationally beneficial rather than detrimental. However, in neuromorphic computing systems, device variability often limits performance, including accuracy and efficiency. In this work, we propose a spiking Bayesian neural network (SBNN) framework that unifies the dynamic models of intrinsic device stochasticity (based on Magnetic Tunnel Junctions) and stochastic threshold neurons to leverage noise as a functional Bayesian resource. Experiments demonstrate that SBNN achieves high accuracy (99.16% on MNIST, 94.84% on CIFAR10) with 8-bit precision. Meanwhile rate estimation method provides a ~20-fold training speedup. Furthermore, SBNN exhibits superior robustness, showing a 67% accuracy improvement under synaptic weight noise and 12% under input noise compared to standard spiking neural networks. Crucially, hardware validation confirms that physical device implementation causes invisible accuracy and calibration loss compared to the algorithmic model. Converting device stochasticity into neuronal uncertainty offers a route to compact, energy-efficient neuromorphic computing under uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07037v1</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.ET</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huannan Zheng, Jingli Liu, Kezhou Yang</dc:creator>
    </item>
    <item>
      <title>Open TutorAI: An Open-source Platform for Personalized and Immersive Learning with Generative AI</title>
      <link>https://arxiv.org/abs/2602.07176</link>
      <description>arXiv:2602.07176v1 Announce Type: cross 
Abstract: Recent advances in artificial intelligence have created new possibilities for making education more scalable, adaptive, and learner-centered. However, existing educational chatbot systems often lack contextual adaptability, real-time responsiveness, and pedagogical agility. which can limit learner engagement and diminish instructional effectiveness. Thus, there is a growing need for open, integrative platforms that combine AI and immersive technologies to support personalized, meaningful learning experiences. This paper presents Open TutorAI, an open-source educational platform based on LLMs and generative technologies that provides dynamic, personalized tutoring. The system integrates natural language processing with customizable 3D avatars to enable multimodal learner interaction. Through a structured onboarding process, it captures each learner's goals and preferences in order to configure a learner-specific AI assistant. This assistant is accessible via both text-based and avatar-driven interfaces. The platform includes tools for organizing content, providing embedded feedback, and offering dedicated interfaces for learners, educators, and parents. This work focuses on learner-facing components, delivering a tool for adaptive support that responds to individual learner profiles without requiring technical expertise. Its assistant-generation pipeline and avatar integration enhance engagement and emotional presence, creating a more humanized, immersive learning environment. Embedded learning analytics support self-regulated learning by tracking engagement patterns and generating actionable feedback. The result is Open TutorAI, which unites modular architecture, generative AI, and learner analytics within an open-source framework. It contributes to the development of next-generation intelligent tutoring systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07176v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.HC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Mohamed El Hajji, Tarek Ait Baha, Aicha Dakir, Hammou Fadili, Youssef Es-Saady</dc:creator>
    </item>
    <item>
      <title>Cognitive algorithms and systems of episodic memory, semantic memory and their learnings</title>
      <link>https://arxiv.org/abs/2602.07261</link>
      <description>arXiv:2602.07261v1 Announce Type: cross 
Abstract: Declarative memory, the memory that can be "declared" in words or languages, is made up of two dissociated parts: episodic memory and semantic memory. This dissociation has its neuroanatomical basis episodic memory is mostly associated with the hippocampus and semantic memory with the neocortex. The two memories, on the other hand, are closely related. Lesions in the hippocampus often result in various impairments of explicit memory, e.g., anterograde, retrograde and developmental amnesias, and semantic learning deficit. These impairments provide opportunities for us to understand how the two memories may be acquired, stored and organized. This chapter reviews several cognitive systems that are centered to mimic explicit memory, and other systems that are neuroanatomically based and are implemented to simulate those memory impairments mentioned above. This review includes: the structures of the computational systems, their learning rules, and their simulations of memory acquisition and impairments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07261v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/978-1-4419-1452-1_13</arxiv:DOI>
      <arxiv:journal_reference>Book chapter in Perception-action cycle: Models, Architectures, and Hardware. Springer, 2011</arxiv:journal_reference>
      <dc:creator>Qi Zhang</dc:creator>
    </item>
    <item>
      <title>Haptically Experienced Animacy Facilitates Emotion Regulation: A Theory-Driven Investigation</title>
      <link>https://arxiv.org/abs/2602.07395</link>
      <description>arXiv:2602.07395v1 Announce Type: cross 
Abstract: Emotion regulation (ER) is essential to mental well-being but often difficult to access, especially in high-intensity moments or for individuals with clinical vulnerabilities. While existing technology-based ER tools offer value, they typically rely on self-reflection (e.g., emotion tracking, journaling) or co-regulation through verbal modalities (reminders, text-based conversational tools), which may not be accessible or effective when most needed. The biological role of the touch modality makes it an intriguing alternate pathway, but empirical evidence is limited and under-theorized. Building on our prior theoretical framework describing how a comforting haptic co-regulating adjunct (CHORA) can support ER, we developed a zoomorphic robot CHORA with looped biomimetic breathing and heartbeat behaviors. We evaluated its effects in a mixed-methods in-lab study (N=30), providing physiological, self-report, custom questionnaire, and retrospective interview data. Our findings demonstrate the regulatory effects of haptically experienced animacy, corroborate prior work, and validate CHORA's {theoretically grounded} potential to facilitate four ER strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07395v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <category>cs.ET</category>
      <category>cs.RO</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Preeti Vyas, Bereket Guta, Tim G. Zhou, Noor Naila Himam, Andero Uusberg, Karon E. MacLean</dc:creator>
    </item>
    <item>
      <title>BitLogic: Training Framework for Gradient-Based FPGA-Native Neural Networks</title>
      <link>https://arxiv.org/abs/2602.07400</link>
      <description>arXiv:2602.07400v1 Announce Type: cross 
Abstract: The energy and latency costs of deep neural network inference are increasingly driven by deployment rather than training, motivating hardware-specialized alternatives to arithmetic-heavy models. Field-Programmable Gate Arrays (FPGAs) provide an attractive substrate for such specialization, yet existing FPGA-based neural approaches are fragmented and difficult to compare. We present BitLogic, a fully gradient-based, end-to-end trainable framework for FPGA-native neural networks built around Lookup Table (LUT) computation. BitLogic replaces multiply-accumulate operations with differentiable LUT nodes that map directly to FPGA primitives, enabling native binary computation, sparse connectivity, and efficient hardware realization. The framework offers a modular functional API supporting diverse architectures, along with learned encoders, hardware-aware heads, and multiple boundary-consistent LUT relaxations. An automated Register Transfer Level (RTL) export pipeline translates trained PyTorch models into synthesizable HDL, ensuring equivalence between software and hardware inference. Experiments across standard vision benchmarks and heterogeneous hardware platforms demonstrate competitive accuracy and substantial gains in FPGA efficiency, including 72.3% test accuracy on CIFAR-10 achieved with fewer than 0.3M logic gates, while attaining sub-20 ns single-sample inference using only LUT resources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07400v1</guid>
      <category>cs.LG</category>
      <category>cs.ET</category>
      <category>cs.PF</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Simon B\"uhrer, Andreas Plesner, Aczel Till, Roger Wattenhofer</dc:creator>
    </item>
    <item>
      <title>A Course on the Introduction to Quantum Software Engineering: Experience Report</title>
      <link>https://arxiv.org/abs/2602.07589</link>
      <description>arXiv:2602.07589v1 Announce Type: cross 
Abstract: Quantum computing is increasingly practiced through programming, yet most educational offerings emphasize algorithmic or framework-level use rather than software engineering concerns such as testing, abstraction, tooling, and lifecycle management.
  This paper reports on the design and first offering of a cross-listed undergraduate--graduate course that frames quantum computing through a software engineering lens, focusing on early-stage competence relevant to software engineering practice. The course integrates foundational quantum concepts with software engineering perspectives, emphasizing executable artifacts, empirical reasoning, and trade-offs arising from probabilistic behaviour, noise, and evolving toolchains. Evidence is drawn from instructor observations, student feedback, surveys, and analysis of student work.
  Despite minimal prior exposure to quantum computing, students were able to engage productively with quantum software engineering topics once a foundational understanding of quantum information and quantum algorithms, expressed through executable artifacts, was established. This experience report contributes a modular course design, a scalable assessment model for mixed academic levels, and transferable lessons for software engineering educators developing quantum computing curricula.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07589v1</guid>
      <category>cs.SE</category>
      <category>cs.CY</category>
      <category>cs.ET</category>
      <category>quant-ph</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andriy Miranskyy</dc:creator>
    </item>
    <item>
      <title>Momentum-Driven Reversible Logic Accelerates Efficient Irreversible Universal Computation</title>
      <link>https://arxiv.org/abs/2602.07683</link>
      <description>arXiv:2602.07683v1 Announce Type: cross 
Abstract: We present implementations of two physically-embedded computation-universal logical operations using a 2-bit logical unit composed of coupled quantum flux parametrons -- Josephson-junction superconducting circuits. To illustrate universality, we investigate NAND gates built from these two distinct elementary operations. On the one hand, Controlled Erasure (CE) is designed using fixed-point analysis and assumes that information must be stored in locally-metastable distributions. On the other, Erasure-Flip (EF) leverages momentum as a computational resource and significantly outperforms the metastable approach, simultaneously achieving higher fidelity and faster computational speed without incurring any additional energetic cost. Notably, the momentum degree of freedom allows the EF to achieve universality by using both nontrivial reversible and irreversible logic simultaneously in different logical subspaces. These results not only provide a practical, high-performance protocol ripe for experimental realization but also underscore the broader potential of momentum-based computing paradigms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07683v1</guid>
      <category>cond-mat.stat-mech</category>
      <category>cs.ET</category>
      <category>nlin.AO</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kuen Wai Tang, Kyle J. Ray, James P. Crutchfield</dc:creator>
    </item>
    <item>
      <title>All-Optical Segmentation via Diffractive Neural Networks for Autonomous Driving</title>
      <link>https://arxiv.org/abs/2602.07717</link>
      <description>arXiv:2602.07717v1 Announce Type: cross 
Abstract: Semantic segmentation and lane detection are crucial tasks in autonomous driving systems. Conventional approaches predominantly rely on deep neural networks (DNNs), which incur high energy costs due to extensive analog-to-digital conversions and large-scale image computations required for low-latency, real-time responses. Diffractive optical neural networks (DONNs) have shown promising advantages over conventional DNNs on digital or optoelectronic computing platforms in energy efficiency. By performing all-optical image processing via light diffraction at the speed of light, DONNs save computation energy costs while reducing the overhead associated with analog-to-digital conversions by all-optical encoding and computing. In this work, we propose a novel all-optical computing framework for RGB image segmentation and lane detection in autonomous driving applications. Our experimental results demonstrate the effectiveness of the DONN system for image segmentation on the CityScapes dataset. Additionally, we conduct case studies on lane detection using a customized indoor track dataset and simulated driving scenarios in CARLA, where we further evaluate the model's generalizability under diverse environmental conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07717v1</guid>
      <category>cs.CV</category>
      <category>cs.ET</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yingjie Li, Daniel Robinson, Cunxi Yu</dc:creator>
    </item>
    <item>
      <title>Graph-Enhanced Deep Reinforcement Learning for Multi-Objective Unrelated Parallel Machine Scheduling</title>
      <link>https://arxiv.org/abs/2602.08052</link>
      <description>arXiv:2602.08052v1 Announce Type: cross 
Abstract: The Unrelated Parallel Machine Scheduling Problem (UPMSP) with release dates, setups, and eligibility constraints presents a significant multi-objective challenge. Traditional methods struggle to balance minimizing Total Weighted Tardiness (TWT) and Total Setup Time (TST). This paper proposes a Deep Reinforcement Learning framework using Proximal Policy Optimization (PPO) and a Graph Neural Network (GNN). The GNN effectively represents the complex state of jobs, machines, and setups, allowing the PPO agent to learn a direct scheduling policy. Guided by a multi-objective reward function, the agent simultaneously minimizes TWT and TST. Experimental results on benchmark instances demonstrate that our PPO-GNN agent significantly outperforms a standard dispatching rule and a metaheuristic, achieving a superior trade-off between both objectives. This provides a robust and scalable solution for complex manufacturing scheduling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08052v1</guid>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bulent Soykan, Sean Mondesire, Ghaith Rabadi, Grace Bochenek</dc:creator>
    </item>
    <item>
      <title>Objective Decoupling in Social Reinforcement Learning: Recovering Ground Truth from Sycophantic Majorities</title>
      <link>https://arxiv.org/abs/2602.08092</link>
      <description>arXiv:2602.08092v1 Announce Type: cross 
Abstract: Contemporary AI alignment strategies rely on a fragile premise: that human feedback, while noisy, remains a fundamentally truthful signal. In this paper, we identify this assumption as Dogma 4 of Reinforcement Learning (RL). We demonstrate that while this dogma holds in static environments, it fails in social settings where evaluators may be sycophantic, lazy, or adversarial. We prove that under Dogma 4, standard RL agents suffer from what we call Objective Decoupling, a structural failure mode where the agent's learned objective permanently separates from the latent ground truth, guaranteeing convergence to misalignment. To resolve this, we propose Epistemic Source Alignment (ESA). Unlike standard robust methods that rely on statistical consensus (trusting the majority), ESA utilizes sparse safety axioms to judge the source of the feedback rather than the signal itself. We prove that this "judging the judges" mechanism guarantees convergence to the true objective, even when a majority of evaluators are biased. Empirically, we show that while traditional consensus methods fail under majority collusion, our approach successfully recovers the optimal policy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08092v1</guid>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Majid Ghasemi, Mark Crowley</dc:creator>
    </item>
    <item>
      <title>Trust-Based Incentive Mechanisms in Semi-Decentralized Federated Learning Systems</title>
      <link>https://arxiv.org/abs/2602.08290</link>
      <description>arXiv:2602.08290v1 Announce Type: cross 
Abstract: In federated learning (FL), decentralized model training allows multi-ple participants to collaboratively improve a shared machine learning model without exchanging raw data. However, ensuring the integrity and reliability of the system is challenging due to the presence of potentially malicious or faulty nodes that can degrade the model's performance. This paper proposes a novel trust-based incentive mechanism designed to evaluate and reward the quality of contributions in FL systems. By dynamically assessing trust scores based on fac-tors such as data quality, model accuracy, consistency, and contribution fre-quency, the system encourages honest participation and penalizes unreliable or malicious behavior. These trust scores form the basis of an incentive mechanism that rewards high-trust nodes with greater participation opportunities and penal-ties for low-trust participants. We further explore the integration of blockchain technology and smart contracts to automate the trust evaluation and incentive distribution processes, ensuring transparency and decentralization. Our proposed theoretical framework aims to create a more robust, fair, and transparent FL eco-system, reducing the risks posed by untrustworthy participants.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08290v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ajay Kumar Shrestha</dc:creator>
    </item>
    <item>
      <title>Antiferromagnetic Tunnel Junctions (AFMTJs) for In-Memory Computing: Modeling and Case Study</title>
      <link>https://arxiv.org/abs/2602.08323</link>
      <description>arXiv:2602.08323v1 Announce Type: cross 
Abstract: Antiferromagnetic Tunnel Junctions (AFMTJs) enable picosecond switching and femtojoule writes through ultrafast sublattice dynamics. We present the first end-to-end AFMTJ simulation framework integrating multi-sublattice Landau-Lifshitz-Gilbert (LLG) dynamics with circuit-level modeling. SPICE-based simulations show that AFMTJs achieve ~8x lower write latency and ~9x lower write energy than conventional MTJs. When integrated into an in-memory computing architecture, AFMTJs deliver 17.5x average speedup and nearly 20x energy savings versus a CPU baseline-significantly outperforming MTJ-based IMC. These results establish AFMTJs as a compelling primitive for scalable, low-power computing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08323v1</guid>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yousuf Choudhary, Tosiron Adegbija</dc:creator>
    </item>
    <item>
      <title>Gesture Matters: Pedestrian Gesture Recognition for AVs Through Skeleton Pose Evaluation</title>
      <link>https://arxiv.org/abs/2602.08479</link>
      <description>arXiv:2602.08479v1 Announce Type: cross 
Abstract: Gestures are a key component of non-verbal communication in traffic, often helping pedestrian-to-driver interactions when formal traffic rules may be insufficient. This problem becomes more apparent when autonomous vehicles (AVs) struggle to interpret such gestures. In this study, we present a gesture classification framework using 2D pose estimation applied to real-world video sequences from the WIVW dataset. We categorise gestures into four primary classes (Stop, Go, Thank &amp; Greet, and No Gesture) and extract 76 static and dynamic features from normalised keypoints. Our analysis demonstrates that hand position and movement velocity are especially discriminative in distinguishing between gesture classes, achieving a classification accuracy score of 87%. These findings not only improve the perceptual capabilities of AV systems but also contribute to the broader understanding of pedestrian behaviour in traffic contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08479v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/ICA65945.2025.11252086</arxiv:DOI>
      <dc:creator>Alif Rizqullah Mahdi, Mahdi Rezaei, Natasha Merat</dc:creator>
    </item>
    <item>
      <title>Technosocial risks of ideal emotion recognition technologies: A defense of the (social) value of emotional expressions</title>
      <link>https://arxiv.org/abs/2602.08706</link>
      <description>arXiv:2602.08706v1 Announce Type: cross 
Abstract: The prospect of AI systems that I call ideal emotion recognition technologies (ERTs) is often defended on the assumption that social life would benefit from increased affective transparency. This paper challenges that assumption by examining the technosocial risks posed by ideal ERTs, understood as multimodal systems capable of reliably inferring inner affective states in real time. Drawing on philosophical accounts of emotional expression and social practice, as well as empirical work in affective science and social psychology, I argue that the appeal of such systems rests on a misunderstanding of the social functions of emotional expression. Emotional expressions function not only as read-outs of inner states, but also as tools for coordinating action, enabling moral repair, sustaining interpersonal trust, and supporting collective norms. These functions depend on a background of partial opacity and epistemic friction. When deployed in socially authoritative or evaluative contexts, ideal ERTs threaten this expressive space by collapsing epistemic friction, displacing relational meaning with technology-mediated affective profiles, and narrowing the space for aspirational and role-sensitive expressions. The result is a drift towards affective determinism and ambient forms of affective auditing, which undermine both social cohesion and individual agency. I argue that, although it is intuitive to think that increasing accuracy would legitimise such systems, in the case of ERTs accuracy does not straightforwardly justify their deployment, and may, in some contexts, provide a reason for regulatory restraint. I conclude by defending a function-first regulatory approach that treats expressive discretion and intentional emotional expression as constitutive of certain social goods, and that accordingly seeks to protect these goods from excessive affective legibility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08706v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alexandra Pregent</dc:creator>
    </item>
    <item>
      <title>ZK-Rollup for Hyperledger Fabric: Architecture and Performance Evaluation</title>
      <link>https://arxiv.org/abs/2602.08870</link>
      <description>arXiv:2602.08870v1 Announce Type: cross 
Abstract: A big challenge posed in blockchain centric platforms is achieving scalability while also preserving user privacy. This report details the design, implementation and evaluation of a Layer-2 scaling solution for Hyperledger Fabric using Zero Knowledge Rollups (ZK Rollups). The proposed architecture introduces an off chain sequencer that accepts transactions immediately and sends them for batching into a Merkle tree based rollup, using ZK proofs to attest to the correctness and verifiability of the entire batch.
  The design aims to decouple transaction ingestion from actual on chain settlements to address Fabric scalability limitations and increase throughput under high load conditions. The baseline architecture in Hyperledger Fabric constrains transaction requests due to endorsement, ordering and validation phases, leading to a throughput of 5 to 7 TPS with an average latency of 4 seconds. Our Layer-2 solution achieves an ingestion throughput of 70 to 100 TPS, leading to an increase of nearly ten times due to the sequencer immediate acceptance of each transaction and reducing client perceived latency by nearly eighty percent to 700 to 1000 milliseconds. This work demonstrates that integrating ZK Rollups in Hyperledger Fabric enhances scalability while not compromising the security guarantees of a permissioned blockchain network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08870v1</guid>
      <category>cs.CR</category>
      <category>cs.ET</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sania Siddiqui,  Neha, Hari Babu K</dc:creator>
    </item>
    <item>
      <title>AMS-HD: Hyperdimensional Computing for Real-Time and Energy-Efficient Acute Mountain Sickness Detection</title>
      <link>https://arxiv.org/abs/2602.08916</link>
      <description>arXiv:2602.08916v1 Announce Type: cross 
Abstract: Altitude sickness is a potentially life-threatening condition that impacts many individuals traveling to elevated altitudes. Timely detection is critical as symptoms can escalate rapidly. Early recognition enables simple interventions such as descent, oxygen, or medication, and prompt treatment can save lives by significantly lowering the risk of severe complications. Although conventional machine learning (ML) techniques have been applied to identify altitude sickness using physiological signals, such as heart rate, oxygen saturation, respiration rate, blood pressure, and body temperature, they often struggle to balance predictive performance with low hardware demands. In contrast, hyperdimensional computing (HDC) remains under-explored for this task with limited biomedical features, where it may offer a compelling alternative to existing classification models. Its vector symbolic framework is inherently suited to hardware-efficient design, making it a strong candidate for low-power systems like wearables. Leveraging lightweight computation and efficient streamlined memory usage, HDC enables real-time detection of altitude sickness from physiological parameters collected by wearable devices, achieving accuracy comparable to that of traditional ML models. We present AMS-HD, a novel system that integrates tailored feature extraction and Hadamard HV encoding to enhance both the precision and efficiency of HDC-based detection. This framework is well-positioned for deployment in wearable health monitoring platforms, enabling continuous, on-the-go tracking of acute altitude sickness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08916v1</guid>
      <category>cs.SC</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abu Masum, Mehran Moghadam, M. Hassan Najafi, Bige Unluturk, Ulkuhan Guler, Sercan Aygun</dc:creator>
    </item>
    <item>
      <title>A Reconfigurable Time-Domain In-Memory Computing Macro using FeFET-Based CAM with Multilevel Delay Calibration in 28 nm CMOS</title>
      <link>https://arxiv.org/abs/2504.03925</link>
      <description>arXiv:2504.03925v3 Announce Type: replace 
Abstract: Time-domain nonvolatile in-memory computing (TD-nvIMC) offers a promising pathway to reduce data movement and improve energy efficiency by encoding computation in delay rather than voltage or current. This work presents a fully integrated and reconfigurable TD-nvIMC macro, fabricated in 28 nm CMOS, that combines a ferroelectric FET (FeFET)-based content-addressable memory array, a cascaded delay element chain, and a time-to-digital converter. The architecture supports binary multiply-and-accumulate (MAC) operations using XOR- and AND-based matching, as well as in-memory Boolean logic and arithmetic functions. Sub-nanosecond MAC resolution is achieved through experimentally demonstrated 550 ps delay steps, representing a 2000$\times$ improvement over prior FeFET TD-nvIMC work, enabled by multilevel-state calibration with $\leq$ 100 ps resolution. Write-disturb resilience is ensured via isolated triple-well bulks. The proposed macro achieves a measured throughput of 222.2 MOPS/cell and energy efficiency of 1887 TOPS/W at 0.85 V, establishing a viable path toward scalable, energy-efficient TD-nvIMC accelerators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03925v3</guid>
      <category>cs.ET</category>
      <category>cs.AR</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jeries Mattar, Mor M. Dahan, Stefan Dunkel, Halid Mulaosmanovic, Gunda Beernink, Sven Beyer, Eilam Yalon, Nicol\'as Wainstein</dc:creator>
    </item>
    <item>
      <title>Machine Unlearning and Continual Learning in Hybrid Resistive Memory Neuromorphic Systems</title>
      <link>https://arxiv.org/abs/2601.10037</link>
      <description>arXiv:2601.10037v2 Announce Type: replace 
Abstract: Resistive memory (RM) based neuromorphic systems can emulate synaptic plasticity and thus support continual learning, but they generally lack biologically inspired mechanisms for active forgetting, which are critical for meeting modern data privacy requirements. Algorithmic forgetting, or machine unlearning, seeks to remove the influence of specific data from trained models to prevent memorization of sensitive information and the generation of harmful content, yet existing exact and approximate unlearning schemes incur prohibitive programming overheads on RM hardware owing to device variability and iterative write-verify cycles. Analogue implementations of continual learning face similar barriers. Here we present a hardware-software co-design that enables an efficient training, deployment and inference pipeline for machine unlearning and continual learning on RM accelerators. At the software level, we introduce a low-rank adaptation (LoRA) framework that confines updates to compact parameter branches, substantially reducing the number of trainable parameters and therefore the training cost. At the hardware level, we develop a hybrid analogue-digital compute-in-memory system in which well-trained weights are stored in analogue RM arrays, whereas dynamic LoRA updates are implemented in a digital computing unit with SRAM buffer. This hybrid architecture avoids costly reprogramming of analogue weights and maintains high energy efficiency during inference. Fabricated in a 180 nm CMOS process, the prototype achieves up to a 147.76-fold reduction in training cost, a 387.95-fold reduction in deployment overhead and a 48.44-fold reduction in inference energy across privacy-sensitive tasks including face recognition, speaker authentication and stylized image generation, paving the way for secure and efficient neuromorphic intelligence at the edge.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10037v2</guid>
      <category>cs.ET</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ning Lin, Jichang Yang, Yangu He, Zijian Ye, Kwun Hang Wong, Xinyuan Zhang, Songqi Wang, Yi Li, Kemi Xu, Leo Yu Zhang, Xiaoming Chen, Dashan Shang, Han Wang, Xiaojuan Qi, Zhongrui Wang</dc:creator>
    </item>
    <item>
      <title>The Quantum Cliff: A Critical Proton Tunneling Threshold Determines Clinical Severity in RPE65-Mediated Retinal Disease</title>
      <link>https://arxiv.org/abs/2601.18435</link>
      <description>arXiv:2601.18435v2 Announce Type: replace 
Abstract: Predicting clinical severity from genotype remains a fundamental challenge in molecular medicine, particularly for enzymes whose function depends on sub-atomic-scale geometry. Mutations in the \textit{RPE65} isomerohydrolase cause Leber Congenital Amaurosis (LCA) and related retinal diseases; however, the kinetic mechanisms connecting sub-atomic-scale perturbations to blindness remain unclear. In this study, we demonstrate that mutations in the human visual isomerase RPE65 are governed by a quantum-mechanical threshold effect arising from proton tunneling in the active site. We established a hybrid quantum-classical structure-to-phenotype pipeline combining AlphaFold structure prediction with \textit{ab initio} quantum simulation using the Variational Quantum Eigensolver (VQE) to analyze minimal proton-coupled electron transfer in the visual cycle. Our analysis reveals that many pathogenic mutations do not merely occlude the active site, but rather strongly reduce the quantum probability of proton tunneling. We observed a sharp non-linear effect, termed the "Quantum Cliff," where minute structural changes (below 0.1 \AA) reduce the reaction rate by multiple orders of magnitude. Based on these findings, we introduce a dimensionless Relative Quantum Activity Score (RQAS) that isolates the geometry-controlled exponential sensitivity of the reaction rate and successfully distinguishes between mild and severe patient phenotypes. These results suggest that RPE65 operates near a quantum-critical point, where sub-Angstrom structural perturbations induce a catastrophic loss of function. Furthermore, our findings establish quantum tunneling as a predictive mechanistic link between atomic structure and clinical phenotype, proposing a general framework for quantum-structural disease modeling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.18435v2</guid>
      <category>cs.ET</category>
      <category>q-bio.BM</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Biraja Ghoshal, William Woof, Bhargab Ghoshal, Nikolas Pontikos</dc:creator>
    </item>
    <item>
      <title>Evaluating Kubernetes Performance for GenAI Inference: From Automatic Speech Recognition to LLM Summarization</title>
      <link>https://arxiv.org/abs/2602.04900</link>
      <description>arXiv:2602.04900v2 Announce Type: replace 
Abstract: As Generative AI (GenAI), particularly inference, rapidly emerges as a dominant workload category, the Kubernetes ecosystem is proactively evolving to natively support its unique demands. This industry paper demonstrates how emerging Kubernetes-native projects can be combined to deliver the benefits of container orchestration, such as scalability and resource efficiency, to complex AI workflows. We implement and evaluate an illustrative, multi-stage use case consisting of automatic speech recognition and summarization. First, we address batch inference by using Kueue to manage jobs that transcribe audio files with Whisper models and Dynamic Accelerator Slicer (DAS) to increase parallel job execution. Second, we address a discrete online inference scenario by feeding the transcripts to a Large Language Model for summarization hosted using llm-d, a novel solution utilizing the recent developments around the Kubernetes Gateway API Inference Extension (GAIE) for optimized routing of inference requests. Our findings illustrate that these complementary components (Kueue, DAS, and GAIE) form a cohesive, high-performance platform, proving Kubernetes' capability to serve as a unified foundation for demanding GenAI workloads: Kueue reduced total makespan by up to 15%; DAS shortened mean job completion time by 36%; and GAIE improved Time to First Token by 82\%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.04900v2</guid>
      <category>cs.ET</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sai Sindhur Malleni, Ra\'ul Sevilla, Aleksei Vasilevskii, Jos\'e Castillo Lema, Andr\'e Bauer</dc:creator>
    </item>
    <item>
      <title>Vibe Coding for Product Design: Understanding Product Team Members' Perceptions of AI-Assisted Design and Development</title>
      <link>https://arxiv.org/abs/2509.10652</link>
      <description>arXiv:2509.10652v2 Announce Type: replace-cross 
Abstract: Generative AI is reshaping product design practices through "vibe coding", where product team members express intent in natural language and AI translates it into functional prototypes and code. Despite rapid adoption, little research has examined how vibe coding reconfigures product development workflows and collaboration. Drawing on interviews with 22 product team members across enterprises, startups, and academia, we show how vibe coding follows a four-stage workflow of ideation, generation, debugging, and review. This accelerates iteration, supports creativity, and lowers participation barriers. However, participants reported challenges of code unreliability, integration, and AI over-reliance. We find tensions between efficiency-driven prototyping ("intending the right design") and reflection ("designing the right intention"), introducing new asymmetries in trust, responsibility, and social stigma within teams. Through a responsible human-AI collaboration lens for AI-assisted product design and development, we contribute a deeper understanding of deskilling, ownership and disclosure, and creativity safeguarding in the age of vibe coding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10652v2</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.ET</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Jie Li, Youyang Hou, Laura Lin, Ruihao Zhu, Hancheng Cao, Abdallah El Ali</dc:creator>
    </item>
    <item>
      <title>Temperature Scaling Attack Disrupting Model Confidence in Federated Learning</title>
      <link>https://arxiv.org/abs/2602.06638</link>
      <description>arXiv:2602.06638v2 Announce Type: replace-cross 
Abstract: Predictive confidence serves as a foundational control signal in mission-critical systems, directly governing risk-aware logic such as escalation, abstention, and conservative fallback. While prior federated learning attacks predominantly target accuracy or implant backdoors, we identify confidence calibration as a distinct attack objective. We present the Temperature Scaling Attack (TSA), a training-time attack that degrades calibration while preserving accuracy. By injecting temperature scaling with learning rate-temperature coupling during local training, malicious updates maintain benign-like optimization behavior, evading accuracy-based monitoring and similarity-based detection. We provide a convergence analysis under non-IID settings, showing that this coupling preserves standard convergence bounds while systematically distorting confidence. Across three benchmarks, TSA substantially shifts calibration (e.g., 145% error increase on CIFAR-100) with &lt;2 accuracy change, and remains effective under robust aggregation and post-hoc calibration defenses. Case studies further show that confidence manipulation can cause up to 7.2x increases in missed critical cases (healthcare) or false alarms (autonomous driving), even when accuracy is unchanged. Overall, our results establish calibration integrity as a critical attack surface in federated learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.06638v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Kichang Lee, Jaeho Jin, JaeYeon Park, Songkuk Kim, JeongGil Ko</dc:creator>
    </item>
  </channel>
</rss>
