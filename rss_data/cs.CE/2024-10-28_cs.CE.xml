<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 29 Oct 2024 04:01:23 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>High-Precision Real-Time Pores Detection in LPBF using Thermal Energy Density (TED) Signals</title>
      <link>https://arxiv.org/abs/2410.19737</link>
      <description>arXiv:2410.19737v1 Announce Type: new 
Abstract: Pore formation during Laser Powder Bed Fusion (LPBF) has long posed challenges in metal 3D printing, significantly affecting the mechanical properties of the final product. Porosity frequently occurs because of an unstable keyhole formation, triggered by an excess laser energy. Traditional approaches for detecting pores rely heavily on CT scanning, a time-consuming and costly method unsuitable for large-scale production. In response to these limitations, we have developed a real-time pore detection method using thermal sensor data, offering a more efficient, cost-effective alternative for quality control during the LPBF process. Our method, validated against CT-scanned pore counts, provides a high degree of accuracy, achieving an R^2 value of 0.94 between the across eight sample prints. This approach also effectively tracks pore formation trends as the layer-wise printing pattern changes, providing timely insights into product quality, which may serve as important datapoints for real-time adaptive parameters optimization in the future. In contrast to prior machine learning-based techniques, which were limited by high computational costs and lacked direct validation strategy, the method intr</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19737v1</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chuxiao Meng, Conor Porter, Sina Malakpour, Garrett Mathesen, Seongyeon Yang</dc:creator>
    </item>
    <item>
      <title>SeisGPT: A Physics-Informed Data-Driven Large Model for Real-Time Seismic Response Prediction</title>
      <link>https://arxiv.org/abs/2410.20186</link>
      <description>arXiv:2410.20186v1 Announce Type: new 
Abstract: Accurately predicting the dynamic responses of building structures under seismic loads is essential for ensuring structural safety and minimizing potential damage. This critical aspect of structural analysis allows engineers to evaluate how structures perform under various loading conditions, facilitating informed design and safety decisions. Traditional methods, which rely on complex finite element models often struggle with balancing computational efficiency and accuracy. To address this challenge, we introduce SeisGPT, a data-driven, large physics-informed model that leverages deep neural networks based on the Generative Pre-trained Transformer (GPT) architecture. SeisGPT is designed to predict, in real-time the dynamic behavior of building structures under seismic forces. Trained on a diverse corpus of seismic data and structural engineering principles, it instantly generates predictive responses, including displacement, acceleration, and inter-story drift, with high accuracy and computational efficiency. Its adaptability across various building typologies and seismic intensities makes this framework a valuable tool for designing robust structures and assessing seismic risk. Through comprehensive validation, this approach exhibits superior performance, offering engineers and researchers a powerful tool for assessing seismic response and informing resilient design strategies. This innovative framework represents a significant advancement in seismic engineering practice, with potential applications in mitigating seismic hazards and enhancing structural resilience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20186v1</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shiqiao Meng, Ying Zhou, Qinghua Zheng, Bingxu Liao, Mushi Chang, Tianshu Zhang, Abderrahim Djerrad</dc:creator>
    </item>
    <item>
      <title>Enhancing Inflation Nowcasting with LLM: Sentiment Analysis on News</title>
      <link>https://arxiv.org/abs/2410.20198</link>
      <description>arXiv:2410.20198v1 Announce Type: new 
Abstract: This study explores the integration of large language models (LLMs) into classic inflation nowcasting frameworks, particularly in light of high inflation volatility periods such as the COVID-19 pandemic. We propose InflaBERT, a BERT-based LLM fine-tuned to predict inflation-related sentiment in news. We use this model to produce NEWS, an index capturing the monthly sentiment of the news regarding inflation. Incorporating our expectation index into the Cleveland Fed's model, which is only based on macroeconomic autoregressive processes, shows a marginal improvement in nowcast accuracy during the pandemic. This highlights the potential of combining sentiment analysis with traditional economic indicators, suggesting further research to refine these methodologies for better real-time inflation monitoring. The source code is available at https://github.com/paultltc/InflaBERT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20198v1</guid>
      <category>cs.CE</category>
      <category>cs.CL</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marc-Antoine Allard, Paul Teiletche, Adam Zinebi</dc:creator>
    </item>
    <item>
      <title>Application of an ANN and LSTM-based Ensemble Model for Stock Market Prediction</title>
      <link>https://arxiv.org/abs/2410.20253</link>
      <description>arXiv:2410.20253v1 Announce Type: new 
Abstract: Stock trading has always been a key economic indicator in modern society and a primary source of profit for financial giants such as investment banks, quantitative trading firms, and hedge funds. Discovering the underlying patterns within the seemingly volatile yet intrinsically structured economic activities has become a central focus of research for many companies. Our study leverages widely-used modern financial forecasting algorithms, including LSTM, ANN, CNN, and BiLSTM. We begin by comparing the predictive performance of these well-known algorithms on our stock market data, utilizing metrics such as R2, MAE, MSE, RMSE for detailed evaluation. Based on the performance of these models, we then aim to combine their strengths while mitigating their weaknesses, striving to construct a powerful hybrid model that overcomes the performance limitations of individual models.Through rigorous experimentation and exploration, we ultimately developed an LSTM+ANN model that breaks through prior performance bottlenecks, achieving promising and exciting results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20253v1</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fang Liu, Shaobo Guo, Qianwen Xing, Xinye Sha, Ying Chen, Yuhui Jin, Qi Zheng, Chang Yu</dc:creator>
    </item>
    <item>
      <title>On performance bounds for topology optimization</title>
      <link>https://arxiv.org/abs/2410.20375</link>
      <description>arXiv:2410.20375v1 Announce Type: new 
Abstract: Topology optimization has matured to become a powerful engineering design tool that is capable of designing extraordinary structures and materials taking into account various physical phenomena. Despite the method's great advancements in recent years, several unanswered questions remain. This paper takes a step towards answering one of the larger questions, namely: How far from the global optimum is a given topology optimized design? Typically this is a hard question to answer, as almost all interesting topology optimization problems are non-convex. Unfortunately, this non-convexity implies that local minima may plague the design space, resulting in optimizers ending up in suboptimal designs. In this work, we investigate performance bounds for topology optimization via a computational framework that utilizes Lagrange duality theory. This approach provides a viable measure of how \say{close} a given design is to the global optimum for a subset of optimization formulations. The method's capabilities are exemplified via several numerical examples, including the design of mode converters and resonating plates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20375v1</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anna Dalklint, Rasmus E. Christiansen, Ole Sigmund</dc:creator>
    </item>
    <item>
      <title>History-Matching of Imbibition Flow in Multiscale Fractured Porous Media Using Physics-Informed Neural Networks (PINNs)</title>
      <link>https://arxiv.org/abs/2410.20801</link>
      <description>arXiv:2410.20801v1 Announce Type: new 
Abstract: We propose a workflow based on physics-informed neural networks (PINNs) to model multiphase fluid flow in fractured porous media. After validating the workflow in forward and inverse modeling of a synthetic problem of flow in fractured porous media, we applied it to a real experimental dataset in which brine is injected at a constant pressure drop into a CO2 saturated naturally fractured shale core plug. The exact spatial positions of natural fractures and the dynamic in-situ distribution of fluids were imaged using a CT-scan setup. To model the targeted system, we followed a domain decomposition approach for matrix and fractures and a multi-network architecture for the separate calculation of water saturation and pressure. The flow equations in the matrix, fractures and interplay between them were solved during training. Prior to fully-coupled simulations, we proposed pre-training the model. This aided in a more efficient and successful training of the coupled system. Both for the synthetic and experimental inverse problems, we determined flow parameters within the matrix and the fractures. Multiple random initializations of network and system parameters were performed to assess the uncertainty and uniqueness of the results. The results confirmed the precision of the inverse calculated parameters in retrieving the main flow characteristics of the system. The consideration of multiscale matrix-fracture impacts is commonly overlooked in existing workflows. Accounting for them led to several orders of magnitude variations in the calculated flow properties compared to not accounting for them. To the best of our knowledge, the proposed PINNs-based workflow is the first to offer a reliable and computationally efficient solution for inverse modeling of multiphase flow in fractured porous media, achieved through history-matching noisy and multi-fidelity experimental measurements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20801v1</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jassem Abbasi, Ben Moseley, Takeshi Kurotori, Ameya D. Jagtab, Anthony R. Kovscek, Aksel Hiorth, P{\aa}l {\O}steb{\o} Andersen</dc:creator>
    </item>
    <item>
      <title>Development of a conditional diffusion model to predict process parameters and microstructures of dendrite crystals of matrix resin based on mechanical properties</title>
      <link>https://arxiv.org/abs/2410.20822</link>
      <description>arXiv:2410.20822v1 Announce Type: new 
Abstract: In this study, we develop a conditional diffusion model that proposes the optimal process parameters, such as processing temperature, and predicts the microstructure for the desired mechanical properties, such as the elastic constants of the matrix resin contained in carbon fiber reinforced thermoplastics (CFRTPs). In CFRTPs, not only the carbon fibers but also the matrix resin contribute to the macroscopic mechanical properties. Matrix resins contain a mixture of dendrites, which are crystalline phases, and amorphous phases even after crystal growth is complete, and it is important to consider the microstructures consisting of the crystalline structure and the remaining amorphous phase to achieve the desired mechanical properties. Typically, the temperature during forming affects the microstructures, which in turn affect the macroscopic mechanical properties. The training data for the conditional diffusion model in this study are the crystallization temperatures, microstructures and the elasticity matrix. The elasticity matrix is normalized and introduced into the model as a condition. The trained diffusion model can propose not only the processing temperature but also the microstructure when Young's modulus and Poisson's ratio are given. The capability of our conditional diffusion model to represent complex dendrites is also noteworthy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20822v1</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arisa Ikeda, Ryo Higuchi, Tomohiro Yokozeki, Katsuhiro Endo, Yuta Kojima, Misato Suzuki, Mayu Muramatsu</dc:creator>
    </item>
    <item>
      <title>Simplest Mechanism Builder Algorithm (SiMBA): An Automated Microkinetic Model Discovery Tool</title>
      <link>https://arxiv.org/abs/2410.21205</link>
      <description>arXiv:2410.21205v1 Announce Type: new 
Abstract: Microkinetic models are key for evaluating industrial processes' efficiency and chemicals' environmental impact. Manual construction of these models is difficult and time-consuming, prompting a shift to automated methods. This study introduces SiMBA (Simplest Mechanism Builder Algorithm), a novel approach for generating microkinetic models from kinetic data. SiMBA operates through four phases: mechanism generation, mechanism translation, parameter estimation, and model comparison. Our approach systematically proposes reaction mechanisms, using matrix representations and a parallelized backtracking algorithm to manage complexity. These mechanisms are then translated into microkinetic models represented by ordinary differential equations, and optimized to fit available data. Models are compared using information criteria to balance accuracy and complexity, iterating until convergence to an optimal model is reached. Case studies on an aldol condensation reaction, and the dehydration of fructose demonstrate SiMBA's effectiveness in distilling complex kinetic behaviors into simple yet accurate models. While SiMBA predicts intermediates correctly for all case studies, it does not chemically identify intermediates, requiring expert input for complex systems. Despite this, SiMBA significantly enhances mechanistic exploration, offering a robust initial mechanism that accelerates the development and modeling of chemical processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21205v1</guid>
      <category>cs.CE</category>
      <category>cs.SC</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Miguel \'Angel de Carvalho Servia (Mimi), King Kuok (Mimi),  Hii, Klaus Hellgardt, Dongda Zhang, Ehecatl Antonio del Rio Chanona</dc:creator>
    </item>
    <item>
      <title>Enhancing Trust and Safety in Digital Payments: An LLM-Powered Approach</title>
      <link>https://arxiv.org/abs/2410.19845</link>
      <description>arXiv:2410.19845v1 Announce Type: cross 
Abstract: Digital payment systems have revolutionized financial transactions, offering unparalleled convenience and accessibility to users worldwide. However, the increasing popularity of these platforms has also attracted malicious actors seeking to exploit their vulnerabilities for financial gain. To address this challenge, robust and adaptable scam detection mechanisms are crucial for maintaining the trust and safety of digital payment ecosystems. This paper presents a comprehensive approach to scam detection, focusing on the Unified Payments Interface (UPI) in India, Google Pay (GPay) as a specific use case. The approach leverages Large Language Models (LLMs) to enhance scam classification accuracy and designs a digital assistant to aid human reviewers in identifying and mitigating fraudulent activities. The results demonstrate the potential of LLMs in augmenting existing machine learning models and improving the efficiency, accuracy, quality, and consistency of scam reviews, ultimately contributing to a safer and more secure digital payment landscape. Our evaluation of the Gemini Ultra model on curated transaction data showed a 93.33% accuracy in scam classification. Furthermore, the model demonstrated 89% accuracy in generating reasoning for these classifications. A promising fact, the model identified 32% new accurate reasons for suspected scams that human reviewers had not included in the review notes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19845v1</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Devendra Dahiphale (Google, Inc), Naveen Madiraju (Google, Inc), Justin Lin (Google, Inc), Rutvik Karve (Google, Inc), Monu Agrawal (Google, Inc), Anant Modwal (Google, Inc), Ramanan Balakrishnan (Google, Inc), Shanay Shah (Google, Inc), Govind Kaushal (Google, Inc), Priya Mandawat (Google, Inc), Prakash Hariramani (Google, Inc), Arif Merchant (Google, Inc)</dc:creator>
    </item>
    <item>
      <title>Enhancing Deep Learning based RMT Data Inversion using Gaussian Random Field</title>
      <link>https://arxiv.org/abs/2410.19858</link>
      <description>arXiv:2410.19858v1 Announce Type: cross 
Abstract: Deep learning (DL) methods have emerged as a powerful tool for the inversion of geophysical data. When applied to field data, these models often struggle without additional fine-tuning of the network. This is because they are built on the assumption that the statistical patterns in the training and test datasets are the same. To address this, we propose a DL-based inversion scheme for Radio Magnetotelluric data where the subsurface resistivity models are generated using Gaussian Random Fields (GRF). The network's generalization ability was tested with an out-of-distribution (OOD) dataset comprising a homogeneous background and various rectangular-shaped anomalous bodies. After end-to-end training with the GRF dataset, the pre-trained network successfully identified anomalies in the OOD dataset. Synthetic experiments confirmed that the GRF dataset enhances generalization compared to a homogeneous background OOD dataset. The network accurately recovered structures in a checkerboard resistivity model, and demonstrated robustness to noise, outperforming traditional gradient-based methods. Finally, the developed scheme is tested using exemplary field data from a waste site near Roorkee, India. The proposed scheme enhances generalization in a data-driven supervised learning framework, suggesting a promising direction for OOD generalization in DL methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19858v1</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <category>eess.SP</category>
      <category>physics.geo-ph</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Koustav Ghosal, Arun Singh, Samir Malakar, Shalivahan Srivastava, Deepak Gupta</dc:creator>
    </item>
    <item>
      <title>Causality-Respecting Adaptive Refinement for PINNs: Enabling Precise Interface Evolution in Phase Field Modeling</title>
      <link>https://arxiv.org/abs/2410.20212</link>
      <description>arXiv:2410.20212v1 Announce Type: cross 
Abstract: Physics-informed neural networks (PINNs) have emerged as a powerful tool for solving physical systems described by partial differential equations (PDEs). However, their accuracy in dynamical systems, particularly those involving sharp moving boundaries with complex initial morphologies, remains a challenge. This study introduces an approach combining residual-based adaptive refinement (RBAR) with causality-informed training to enhance the performance of PINNs in solving spatio-temporal PDEs. Our method employs a three-step iterative process: initial causality-based training, RBAR-guided domain refinement, and subsequent causality training on the refined mesh. Applied to the Allen-Cahn equation, a widely-used model in phase field simulations, our approach demonstrates significant improvements in solution accuracy and computational efficiency over traditional PINNs. Notably, we observe an 'overshoot and relocate' phenomenon in dynamic cases with complex morphologies, showcasing the method's adaptive error correction capabilities. This synergistic interaction between RBAR and causality training enables accurate capture of interface evolution, even in challenging scenarios where traditional PINNs fail. Our framework not only resolves the limitations of uniform refinement strategies but also provides a generalizable methodology for solving a broad range of spatio-temporal PDEs. The simplicity and effectiveness of our RBAR-causality combined PINN offer promising potential for applications across various physical systems characterized by complex, evolving interfaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20212v1</guid>
      <category>physics.comp-ph</category>
      <category>cs.CE</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wei Wang, Tang Paai Wong, Haihui Ruan, Somdatta Goswami</dc:creator>
    </item>
    <item>
      <title>Atrial Fibrillation Detection System via Acoustic Sensing for Mobile Phones</title>
      <link>https://arxiv.org/abs/2410.20852</link>
      <description>arXiv:2410.20852v1 Announce Type: cross 
Abstract: Atrial fibrillation (AF) is characterized by irregular electrical impulses originating in the atria, which can lead to severe complications and even death. Due to the intermittent nature of the AF, early and timely monitoring of AF is critical for patients to prevent further exacerbation of the condition. Although ambulatory ECG Holter monitors provide accurate monitoring, the high cost of these devices hinders their wider adoption. Current mobile-based AF detection systems offer a portable solution, however, these systems have various applicability issues such as being easily affected by environmental factors and requiring significant user effort. To overcome the above limitations, we present MobileAF, a novel smartphone-based AF detection system using speakers and microphones. In order to capture minute cardiac activities, we propose a multi-channel pulse wave probing method. In addition, we enhance the signal quality by introducing a three-stage pulse wave purification pipeline. What's more, a ResNet-based network model is built to implement accurate and reliable AF detection. We collect data from 23 participants utilizing our data collection application on the smartphone. Extensive experimental results demonstrate the superior performance of our system, with 97.9% accuracy, 96.8% precision, 97.2% recall, 98.3% specificity, and 97.0% F1 score.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20852v1</guid>
      <category>cs.SD</category>
      <category>cs.CE</category>
      <category>eess.AS</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xuanyu Liu, Jiao Li, Haoxian Liu, Zongqi Yang, Yi Huang, Jin Zhang</dc:creator>
    </item>
    <item>
      <title>Physics-informed Partitioned Coupled Neural Operator for Complex Networks</title>
      <link>https://arxiv.org/abs/2410.21025</link>
      <description>arXiv:2410.21025v1 Announce Type: cross 
Abstract: Physics-Informed Neural Operators provide efficient, high-fidelity simulations for systems governed by partial differential equations (PDEs). However, most existing studies focus only on multi-scale, multi-physics systems within a single spatial region, neglecting the case with multiple interconnected sub-regions, such as gas and thermal systems. To address this, this paper proposes a Physics-Informed Partitioned Coupled Neural Operator (PCNO) to enhance the simulation performance of such networks. Compared to the existing Fourier Neural Operator (FNO), this method designs a joint convolution operator within the Fourier layer, enabling global integration capturing all sub-regions. Additionally, grid alignment layers are introduced outside the Fourier layer to help the joint convolution operator accurately learn the coupling relationship between sub-regions in the frequency domain. Experiments on gas networks demonstrate that the proposed operator not only accurately simulates complex systems but also shows good generalization and low model complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21025v1</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weidong Wu, Yong Zhang, Lili Hao, Yang Chen, Xiaoyan Sun, Dunwei Gong</dc:creator>
    </item>
    <item>
      <title>AFBench: A Large-scale Benchmark for Airfoil Design</title>
      <link>https://arxiv.org/abs/2406.18846</link>
      <description>arXiv:2406.18846v2 Announce Type: replace 
Abstract: Data-driven generative models have emerged as promising approaches towards achieving efficient mechanical inverse design. However, due to prohibitively high cost in time and money, there is still lack of open-source and large-scale benchmarks in this field. It is mainly the case for airfoil inverse design, which requires to generate and edit diverse geometric-qualified and aerodynamic-qualified airfoils following the multimodal instructions, \emph{i.e.,} dragging points and physical parameters. This paper presents the open-source endeavors in airfoil inverse design, \emph{AFBench}, including a large-scale dataset with 200 thousand airfoils and high-quality aerodynamic and geometric labels, two novel and practical airfoil inverse design tasks, \emph{i.e.,} conditional generation on multimodal physical parameters, controllable editing, and comprehensive metrics to evaluate various existing airfoil inverse design methods. Our aim is to establish \emph{AFBench} as an ecosystem for training and evaluating airfoil inverse design methods, with a specific focus on data-driven controllable inverse design models by multimodal instructions capable of bridging the gap between ideas and execution, the academic research and industrial applications. We have provided baseline models, comprehensive experimental observations, and analysis to accelerate future research. Our baseline model is trained on an RTX 3090 GPU within 16 hours. The codebase, datasets and benchmarks will be available at \url{https://hitcslj.github.io/afbench/}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.18846v2</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jian Liu, Jianyu Wu, Hairun Xie, Guoqing Zhang, Jing Wang, Wei Liu, Wanli Ouyang, Junjun Jiang, Xianming Liu, Shixiang Tang, Miao Zhang</dc:creator>
    </item>
    <item>
      <title>TorchOpera: A Compound AI System for LLM Safety</title>
      <link>https://arxiv.org/abs/2406.10847</link>
      <description>arXiv:2406.10847v2 Announce Type: replace-cross 
Abstract: We introduce TorchOpera, a compound AI system for enhancing the safety and quality of prompts and responses for Large Language Models. TorchOpera ensures that all user prompts are safe, contextually grounded, and effectively processed, while enhancing LLM responses to be relevant and high quality. TorchOpera utilizes the vector database for contextual grounding, rule-based wrappers for flexible modifications, and specialized mechanisms for detecting and adjusting unsafe or incorrect content. We also provide a view of the compound AI system to reduce the computational cost. Extensive experiments show that TorchOpera ensures the safety, reliability, and applicability of LLMs in real-world settings while maintaining the efficiency of LLM responses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10847v2</guid>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.CL</category>
      <category>cs.MA</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shanshan Han, Zijian Hu, Alay Dilipbhai Shah, Han Jin, Yuhang Yao, Dimitris Stripelis, Zhaozhuo Xu, Chaoyang He</dc:creator>
    </item>
    <item>
      <title>PatternPaint: Generating Layout Patterns Using Generative AI and Inpainting Techniques</title>
      <link>https://arxiv.org/abs/2409.01348</link>
      <description>arXiv:2409.01348v2 Announce Type: replace-cross 
Abstract: Generation of diverse VLSI layout patterns is crucial for various downstream tasks in design for manufacturing (DFM) studies. However, the lengthy design cycles often hinder the creation of a comprehensive layout pattern library, and new detrimental patterns may be discovered late in the product development process. Existing training-based ML pattern generation approaches struggle to produce legal layout patterns in the early stages of technology node development due to the limited availability of training samples.To address this challenge, we propose PatternPaint, a training-free framework capable of generating legal patterns with limited DRC Clean training samples. PatternPaint simplifies complex layout pattern generation into a series of inpainting processes with a template-based denoising scheme. Our framework enables even a general pre-trained image foundation model (stable-diffusion), to generate valuable pattern variations, thereby enhancing the library. Notably, PatternPaint can operate with any input size. Furthermore, we explore fine-tuning a pre-trained model with VLSI layout images, resulting in a 2x generation efficiency compared to the base model. Our results show that the proposed model can generate legal patterns in complex 2D metal interconnect design rule settings and achieves a high diversity score. The designed system, with its flexible settings, supports pattern generation with localized changes and design rule violation correction. Validated on a sub-3nm technology node (Intel 18A), PatternPaint is the first framework to generate a complex 2D layout pattern library using only 20 design rule clean layout patterns as input.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.01348v2</guid>
      <category>cs.CV</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Guanglei Zhou, Bhargav Korrapati, Gaurav Rajavendra Reddy, Jiang Hu, Yiran Chen, Dipto G. Thakurta</dc:creator>
    </item>
  </channel>
</rss>
