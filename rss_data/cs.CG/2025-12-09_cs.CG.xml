<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CG updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CG</link>
    <description>cs.CG updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CG" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 10 Dec 2025 02:44:18 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A fast algorithm for the Hecke representation of the braid group, and applications to the computation of the HOMFLY-PT polynomial and the search for interesting braids</title>
      <link>https://arxiv.org/abs/2512.06142</link>
      <description>arXiv:2512.06142v1 Announce Type: new 
Abstract: Knot theory is an active field of mathematics, in which combinatorial and computational methods play an important role. One side of computational knot theory, that has gained interest in recent years, both for complexity analysis and practical algorithms, is quantum topology and the computation of topological invariants issued from the theory.
  In this article, we leverage the rigidity brought by the representation-theoretic origins of the quantum invariants for algorithmic purposes. We do so by exploiting braids and the algebraic properties of the braid group to describe, analyze, and implement a fast algorithm to compute the Hecke representation of the braid group. We apply this construction to design a parameterized algorithm to compute the HOMFLY-PT polynomial of knots, and demonstrate its interest experimentally. Finally, we combine our fast Hecke representation algorithm with Garside theory, to implement a reservoir sampling search and find non-trivial braids with trivial Hecke representations with coefficients in $\mathbb{Z}/p\mathbb{Z}$. We find several such braids, in particular proving that the Hecke representation of $B_5$ with $\mathbb{Z}/2\mathbb{Z}$ coefficients is non-faithful, a previously unknown fact.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06142v1</guid>
      <category>cs.CG</category>
      <category>math.GT</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cl\'ement Maria, Hoel Queffelec</dc:creator>
    </item>
    <item>
      <title>Tight Universal Bounds for Partially Presorted Pareto Front and Convex Hull</title>
      <link>https://arxiv.org/abs/2512.06559</link>
      <description>arXiv:2512.06559v1 Announce Type: new 
Abstract: TimSort is a well-established sorting algorithm whose running time depends on how sorted the input already is. Recently, Eppstein, Goodrich, Illickan, and To designed algorithms inspired by TimSort for Pareto front, planar convex hull, and two other problems. For each of these problems, they define a Range Partition Entropy; a function $H$ mapping lists $I$ that store $n$ points to a number between $0$ and $\log n$. Their algorithms have, for each list of points $I$, a running time of $O(n(1 + H(I)))$.
  In this paper, we provide matching lower bounds for the Pareto front and convex hull algorithms by Eppstein, Goodrich, Illickan, and To. In particular, we show that their algorithm does not correspond to TimSort (or related stack-based MergeSort variants) but rather to a variant of QuickSort. From this, we derive an intuitive notion of universal optimality. We show comparison-based lower bounds that prove that the algorithms by Eppstein, Goodrich, Illickan and To are universally optimal under this notion of universal optimality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06559v1</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ivor van der Hoog, Eva Rotenberg, Daniel Rutschmann</dc:creator>
    </item>
    <item>
      <title>General Computation using Slidable Tiles with Deterministic Global Forces</title>
      <link>https://arxiv.org/abs/2512.06574</link>
      <description>arXiv:2512.06574v1 Announce Type: new 
Abstract: We study the computational power of the Full-Tilt model of motion planning, where slidable polyominos are moved maximally around a board by way of a sequence of directional ``tilts.'' We focus on the deterministic scenario in which the tilts constitute a repeated clockwise rotation. We show that general-purpose computation is possible within this framework by providing a direct and efficient simulation of space-bounded Turing machines in which one computational step of the machine is simulated per $O(1)$ rotations. We further show that the initial tape of the machine can be programmed by an initial tilt-sequence preceding the rotations. This result immediately implies new PSPACE-completeness results for the well-studied problems of \emph{occupancy} (deciding if a given board location can be occupied by a tile), \emph{vacancy} (deciding if a location can be emptied), \emph{relocation} (deciding if a tile can be moved from one location to another), and \emph{reconfiguration} (can a given board configuration be reconfigured into a second given configuration) that hold even for deterministically repeating tilt cycles such as rotations. All of our PSPACE-completeness results hold even when there is only a single domino in the system beyond singleton tiles. Following, we show that these results work in the Single-Step tilt model for larger constant cycles. We then investigate computational efficiency by showing a modification to implement a two-tape Turing machine in the Full-Tilt model and Systolic Arrays in the Single-Step model. Finally, we show a cyclic implementation for tilt-efficient Threshold Circuits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06574v1</guid>
      <category>cs.CG</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Alberto Avila-Jimenez, David Barreda, Sarah-Laurie Evans, Austin Luchsinger, Aiden Massie, Robert Schweller, Evan Tomai, Tim Wylie</dc:creator>
    </item>
    <item>
      <title>On computing the (exact) Fr\'echet distance with a frog</title>
      <link>https://arxiv.org/abs/2512.07728</link>
      <description>arXiv:2512.07728v2 Announce Type: new 
Abstract: The continuous Frechet distance between two polygonal curves is classically computed by exploring their free space diagram. Recently, Har-Peled, Raichel, and Robson [SoCG'25] proposed a radically different approach: instead of directly traversing the continuous free space, they approximate the distance by computing paths in a discrete graph derived from the discrete free space, recursively bisecting edges until the discrete distance converges to the continuous Frechet distance. They implement this so-called frog-based technique and report substantial practical speedups over the state of the art.
  We revisit the frog-based approach and address three of its limitations. First, the method does not compute the Frechet distance exactly. Second, the recursive bisection procedure only introduces the monotonicity events required to realise the Frechet distance asymptotically, that is, only in the limit. Third, the applied simplification technique is heuristic. Motivated by theoretical considerations, we develop new techniques that guarantee exactness, polynomial-time convergence, and near-optimal lossless simplifications. We provide an open-source C++ implementation of our variant.
  Our primary contribution is an extensive empirical evaluation. As expected, exact computation introduces overhead and increases the median running time. Yet, our method is often faster in the worst case, the slowest ten percent of instances, or even on average due to its convergence guarantees. More surprisingly, in our experiments, the implementation of Bringmann, Kuennemann, and Nusser [SoCG'19] consistently outperforms all frog-based approaches in practice. This appears to contrast published claims of the efficiency of the frog-based techniques. These results thereby provide nuanced perspective on frogs: highlighting both the theoretical appeal, but also the practical limitations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.07728v2</guid>
      <category>cs.CG</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jacobus Conradi, Ivor van der Hoog, Eva Rotenberg</dc:creator>
    </item>
    <item>
      <title>Recognition of Unit Segment and Polyline Graphs is $\exists\mathbb{R}$-Complete</title>
      <link>https://arxiv.org/abs/2401.02172</link>
      <description>arXiv:2401.02172v3 Announce Type: replace 
Abstract: Given a set of objects $O$ in the plane, the corresponding intersection graph is defined as follows. Each object defines a vertex and an edge joins two vertices whenever the corresponding objects intersect. We study here the case of unit segments and polylines with exactly $k$ bends. In the recognition problem, we are given a graph and want to decide whether the graph can be represented as an intersection graph of certain geometric objects. In previous work it was shown that various recognition problems are $\exists\mathbb{R}$-complete, leaving unit segments and polylines among the few remaining natural cases where the recognition complexity remained open. We show that recognition for both families of objects is $\exists\mathbb{R}$-complete.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.02172v3</guid>
      <category>cs.CG</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Hoffmann, Tillmann Miltzow, Simon Weber, Lasse Wulf</dc:creator>
    </item>
    <item>
      <title>Instance-Optimal Imprecise Convex Hull</title>
      <link>https://arxiv.org/abs/2504.02611</link>
      <description>arXiv:2504.02611v4 Announce Type: replace 
Abstract: Imprecise measurements of a point set P = (p1, ..., pn) can be modelled by a family of regions F = (R1, ..., Rn), where each imprecise region Ri contains a unique point pi. A retrieval models an accurate measurement by replacing an imprecise region Ri with its corresponding point pi. We construct the convex hull of an imprecise point set in the plane, where regions in F may be retrieved at unit cost. The goal is to determine the cyclic ordering of the convex hull vertices of P as efficiently as possible. Here, efficiency is interpreted in two ways: (i) minimising the number of retrievals, and (ii) computing each retrieval location quickly.
  Prior works focused on only one of these two aspects: either minimising retrievals or optimising algorithmic runtime. Our contribution is the first to simultaneously achieve both. Let r(F, P) denote the minimal number of retrievals required by any algorithm to determine the convex hull of P for a given instance (F, P). For a family F of n constant-complexity polygons, our main result is a reconstruction algorithm that performs O(r(F, P)) retrievals in O(r(F, P) log^3 n) time.
  Compared to previous approaches that achieve optimal retrieval counts, we improve the runtime per retrieval by a exponential factor, from polynomial to polylogarithmic. Compared to near-linear time algorithms, we significantly reduce the number of retrievals used, and broaden the input families to include overlapping regions. We further extend our results to simple k-gons and to pairwise disjoint disks with radii in [1,k], where our runtime scales linearly with k.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02611v4</guid>
      <category>cs.CG</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sarita de Berg, Ivor van der Hoog, Eva Rotenberg, Daniel Rutschmann, Sampson Wong</dc:creator>
    </item>
    <item>
      <title>MCHex: Marching Cubes Based Adaptive Hexahedral Mesh Generation with Guaranteed Positive Jacobian</title>
      <link>https://arxiv.org/abs/2511.02064</link>
      <description>arXiv:2511.02064v2 Announce Type: replace 
Abstract: Constructing an adaptive hexahedral tessellation to fit an input triangle boundary is a key challenge in grid-based methods. The conventional method first removes outside elements (RO) and then projects the axis-aligned boundary onto the input triangle boundary, which has no guarantee on improving the initial Intersection over Union (IoU) and Hausdorff distance ratio (HR, w.r.t bounding box diagonal). The proposed MCHex approach replaces RO with a Marching Cubes method MCHex. Given the same computational budget (benchmarked using an identical precomputed Signed Distance Field, which dominates the runtime), MCHex provides better boundary approximation (higher IoU and lower HR) while guaranteeing a lower, yet still positive, minimum scaled Jacobian (&gt;0 vs. RO's &gt;0.48).</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.02064v2</guid>
      <category>cs.CG</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hua Tong, Yongjie Jessica Zhang</dc:creator>
    </item>
    <item>
      <title>Anatomical basis of sex differences in the electrocardiogram identified by three-dimensional torso-heart imaging reconstruction pipeline</title>
      <link>https://arxiv.org/abs/2312.13976</link>
      <description>arXiv:2312.13976v4 Announce Type: replace-cross 
Abstract: The electrocardiogram (ECG) is used for diagnosis and risk stratification in myocardial infarction (MI). Women have a higher incidence of missed MI diagnosis and complications following infarction, and to address this we aim to provide quantitative information on sex-differences in ECG and torso-ventricular anatomical features and their interdependence. A novel computational automated pipeline is presented enabling the three-dimensional reconstruction of torso-ventricular anatomies for 425 post-MI subjects and 1051 healthy controls from UK Biobank clinical images. Regression models were created relating torso-ventricular and ECG parameters. We found that female hearts were positioned more posteriorly and superiorly than male, and in MI hearts were oriented more horizontally, especially for women. Post-MI women exhibited less QRS prolongation, requiring 27% more prolongation than men to exceed 120ms. Only half of the sex difference in QRS duration was associated with smaller female cavities. Lower STj amplitude in women was striking, associated with smaller ventricles, but also more superior and posterior cardiac position. Post-MI, T wave amplitude and R axis deviations were more strongly associated with posterior and horizontal cardiac positioning in women than in men. Our study highlights the need to quantify sex differences in anatomical features, their implications in ECG interpretation, and the application of clinical ECG thresholds in post-MI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.13976v4</guid>
      <category>physics.med-ph</category>
      <category>cs.AI</category>
      <category>cs.CG</category>
      <category>eess.IV</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hannah J. Smith, Blanca Rodriguez, Yuling Sang, Marcel Beetz, Robin P. Choudhury, Vicente Grau, Abhirup Banerjee</dc:creator>
    </item>
    <item>
      <title>Localized Evaluation for Constructing Discrete Vector Fields</title>
      <link>https://arxiv.org/abs/2408.04769</link>
      <description>arXiv:2408.04769v3 Announce Type: replace-cross 
Abstract: Topological abstractions offer a method to summarize the behavior of vector fields but computing them robustly can be challenging due to numerical precision issues. One alternative is to represent the vector field using a discrete approach, which constructs a collection of pairs of simplices in the input mesh that satisfies criteria introduced by Forman's discrete Morse theory. While numerous approaches exist to compute pairs in the restricted case of the gradient of a scalar field, state-of-the-art algorithms for the general case of vector fields require expensive optimization procedures. This paper introduces a fast, novel approach for pairing simplices of two-dimensional, triangulated vector fields that do not vary in time. The key insight of our approach is that we can employ a local evaluation, inspired by the approach used to construct a discrete gradient field, where every simplex in a mesh is considered by no more than one of its vertices. Specifically, we observe that for any edge in the input mesh, we can uniquely assign an outward direction of flow. We can further expand this consistent notion of outward flow at each vertex, which corresponds to the concept of a downhill flow in the case of scalar fields. Working with outward flow enables a linear-time algorithm that processes the (outward) neighborhoods of each vertex one-by-one, similar to the approach used for scalar fields. We couple our approach to constructing discrete vector fields with a method to extract, simplify, and visualize topological features. Empirical results on analytic and simulation data demonstrate drastic improvements in running time, produce features similar to the current state-of-the-art, and show the application of simplification to large, complex flows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04769v3</guid>
      <category>cs.GR</category>
      <category>cs.CG</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tanner Finken, Julien Tierny, Joshua A Levine</dc:creator>
    </item>
  </channel>
</rss>
