<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.QM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.QM</link>
    <description>q-bio.QM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.QM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 23 Oct 2025 04:00:54 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>ECKO: Explainable Clinical Knowledge for Oncology</title>
      <link>https://arxiv.org/abs/2510.18929</link>
      <description>arXiv:2510.18929v1 Announce Type: new 
Abstract: Personalized oncology aims to tailor treatment strategies to the unique molecular and clinical profiles of individual patients, moving beyond the traditional paradigm of treating the disease not the patient. Achieving this vision requires the integration and interpretation of vast, heterogeneous biomedical data within a meaningful scientific framework. Knowledge graphs, structured according to biomedical ontologies, offer a powerful approach to contextualize and interconnect diverse datasets, enabling more precise and informed clinical decision-making.
  We present ECKO (Explainable Clinical Knowledge for Oncology), a comprehensive knowledge graph that integrates 33 biomedical ontologies and aggregates data from multiple studies to create a unified resource optimized for data-driven clinical applications in oncology. Designed to support personalized drug recommendations, ECKO facilitates the identification of optimal therapeutic options by linking patient-specific molecular data to relevant pharmacological knowledge. It provides transparent, interpretable explanations for drug recommendations, fostering greater trust and understanding among clinicians and researchers. This resource represents a significant advancement toward explainable, scalable, and clinically actionable personalized medicine in oncology, with potential applications in biomarker discovery, treatment optimization, and translational research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18929v1</guid>
      <category>q-bio.QM</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Marta Contreiras Silva, Daniel Faria, Laura Balbi, Susana Nunes, Ana Filipa Rodrigues, Aleksander Palkowski, Michal Waleron, Emilia Daghir-Wojtkowiak, Ashwin Adrian Kallor, Christophe Battail, Federico Maria Corazza, Manuel Fiorelli, Armando Stellato, Javier Antonio Alfaro, Fabio Massimo Zanzotto, Catia Pesquita</dc:creator>
    </item>
    <item>
      <title>Interactive visualization of kidney micro-compartmental segmentations and associated pathomics on whole slide images</title>
      <link>https://arxiv.org/abs/2510.19499</link>
      <description>arXiv:2510.19499v1 Announce Type: new 
Abstract: Application of machine learning techniques enables segmentation of functional tissue units in histology whole-slide images (WSIs). We built a pipeline to apply previously validated segmentation models of kidney structures and extract quantitative features from these structures. Such quantitative analysis also requires qualitative inspection of results for quality control, exploration, and communication. We extend the Vitessce web-based visualization tool to enable visualization of segmentations of multiple types of functional tissue units, such as, glomeruli, tubules, arteries/arterioles in the kidney. Moreover, we propose a standard representation for files containing multiple segmentation bitmasks, which we define polymorphically, such that existing formats including OME-TIFF, OME-NGFF, AnnData, MuData, and SpatialData can be used. We demonstrate that these methods enable researchers and the broader public to interactively explore datasets containing multiple segmented entities and associated features, including for exploration of renal morphometry of biopsies from the Kidney Precision Medicine Project (KPMP) and the Human Biomolecular Atlas Program (HuBMAP).</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19499v1</guid>
      <category>q-bio.QM</category>
      <category>cs.HC</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mark S. Keller (for the Kidney Precision Medicine Project, for the HuBMAP Consortium), Nicholas Lucarelli (for the Kidney Precision Medicine Project, for the HuBMAP Consortium), Yijiang Chen (for the Kidney Precision Medicine Project, for the HuBMAP Consortium), Samuel Border (for the Kidney Precision Medicine Project, for the HuBMAP Consortium), Andrew Janowczyk (for the Kidney Precision Medicine Project, for the HuBMAP Consortium), Jonathan Himmelfarb (for the Kidney Precision Medicine Project, for the HuBMAP Consortium), Matthias Kretzler (for the Kidney Precision Medicine Project, for the HuBMAP Consortium), Jeffrey Hodgin (for the Kidney Precision Medicine Project, for the HuBMAP Consortium), Laura Barisoni (for the Kidney Precision Medicine Project, for the HuBMAP Consortium), Dawit Demeke (for the Kidney Precision Medicine Project, for the HuBMAP Consortium), Leal Herlitz (for the Kidney Precision Medicine Project, for the HuBMAP Consortium), Gilbert Moeckel (for the Kidney Precision Medicine Project, for the HuBMAP Consortium), Avi Z. Rosenberg (for the Kidney Precision Medicine Project, for the HuBMAP Consortium), Yanli Ding (for the Kidney Precision Medicine Project, for the HuBMAP Consortium), Pinaki Sarder, Nils Gehlenborg</dc:creator>
    </item>
    <item>
      <title>Learning noisy tissue dynamics across time scales</title>
      <link>https://arxiv.org/abs/2510.19090</link>
      <description>arXiv:2510.19090v1 Announce Type: cross 
Abstract: Tissue dynamics play a crucial role in biological processes ranging from wound healing to morphogenesis. However, these noisy multicellular dynamics are notoriously hard to predict. Here, we introduce a biomimetic machine learning framework capable of inferring noisy multicellular dynamics directly from experimental movies. This generative model combines graph neural networks, normalizing flows and WaveNet algorithms to represent tissues as neural stochastic differential equations where cells are edges of an evolving graph. This machine learning architecture reflects the architecture of the underlying biological tissues, substantially reducing the amount of data needed to train it compared to convolutional or fully-connected neural networks. Taking epithelial tissue experiments as a case study, we show that our model not only captures stochastic cell motion but also predicts the evolution of cell states in their division cycle. Finally, we demonstrate that our method can accurately generate the experimental dynamics of developmental systems, such as the fly wing, and cell signaling processes mediated by stochastic ERK waves, paving the way for its use as a digital twin in bioengineering and clinical contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19090v1</guid>
      <category>cond-mat.soft</category>
      <category>cs.LG</category>
      <category>physics.bio-ph</category>
      <category>q-bio.QM</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ming Han, John Devany, Michel Fruchart, Margaret L. Gardel, Vincenzo Vitelli</dc:creator>
    </item>
    <item>
      <title>Automated Morphological Analysis of Neurons in Fluorescence Microscopy Using YOLOv8</title>
      <link>https://arxiv.org/abs/2510.19455</link>
      <description>arXiv:2510.19455v1 Announce Type: cross 
Abstract: Accurate segmentation and precise morphological analysis of neuronal cells in fluorescence microscopy images are crucial steps in neuroscience and biomedical imaging applications. However, this process is labor-intensive and time-consuming, requiring significant manual effort and expertise to ensure reliable outcomes. This work presents a pipeline for neuron instance segmentation and measurement based on a high-resolution dataset of stem-cell-derived neurons. The proposed method uses YOLOv8, trained on manually annotated microscopy images. The model achieved high segmentation accuracy, exceeding 97%. In addition, the pipeline utilized both ground truth and predicted masks to extract biologically significant features, including cell length, width, area, and grayscale intensity values. The overall accuracy of the extracted morphological measurements reached 75.32%, further supporting the effectiveness of the proposed approach. This integrated framework offers a valuable tool for automated analysis in cell imaging and neuroscience research, reducing the need for manual annotation and enabling scalable, precise quantification of neuron morphology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19455v1</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>q-bio.QM</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.5121/csit.2025.151921</arxiv:DOI>
      <dc:creator>Banan Alnemri, Arwa Basbrain</dc:creator>
    </item>
    <item>
      <title>EasyVitessce: auto-magically adding interactivity to Scverse single-cell and spatial biology plots</title>
      <link>https://arxiv.org/abs/2510.19532</link>
      <description>arXiv:2510.19532v1 Announce Type: cross 
Abstract: EasyVitessce is a Python package that turns existing static Scanpy and SpatialData plots into interactive visualizations by virtue of adding a single line of Python code. The package uses Vitessce internally to render interactive plots, and abstracts away technical details involved with configuration of Vitessce. The resulting interactive plots can be viewed in computational notebook environments or their configurations can be exported for usage in other contexts such as web applications, enhancing the utility of popular Scverse Python plotting APIs. EasyVitessce is released under the MIT License and available on the Python Package Index (PyPI). The source code is publicly available on GitHub.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19532v1</guid>
      <category>cs.HC</category>
      <category>q-bio.QM</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Selena Luo, Mark S. Keller, Tabassum Kakar, Lisa Choy, Nils Gehlenborg</dc:creator>
    </item>
    <item>
      <title>BATIS: Bayesian Approaches for Targeted Improvement of Species Distribution Models</title>
      <link>https://arxiv.org/abs/2510.19749</link>
      <description>arXiv:2510.19749v1 Announce Type: cross 
Abstract: Species distribution models (SDMs), which aim to predict species occurrence based on environmental variables, are widely used to monitor and respond to biodiversity change. Recent deep learning advances for SDMs have been shown to perform well on complex and heterogeneous datasets, but their effectiveness remains limited by spatial biases in the data. In this paper, we revisit deep SDMs from a Bayesian perspective and introduce BATIS, a novel and practical framework wherein prior predictions are updated iteratively using limited observational data. Models must appropriately capture both aleatoric and epistemic uncertainty to effectively combine fine-grained local insights with broader ecological patterns. We benchmark an extensive set of uncertainty quantification approaches on a novel dataset including citizen science observations from the eBird platform. Our empirical study shows how Bayesian deep learning approaches can greatly improve the reliability of SDMs in data-scarce locations, which can contribute to ecological understanding and conservation efforts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19749v1</guid>
      <category>cs.LG</category>
      <category>q-bio.PE</category>
      <category>q-bio.QM</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Catherine Villeneuve, Benjamin Akera, M\'elisande Teng, David Rolnick</dc:creator>
    </item>
    <item>
      <title>Comorbid anxiety predicts lower odds of MDD improvement in a trial of smartphone-delivered interventions</title>
      <link>https://arxiv.org/abs/2409.11183</link>
      <description>arXiv:2409.11183v4 Announce Type: replace 
Abstract: Comorbid anxiety disorders are common among patients with major depressive disorder (MDD), but their impact on outcomes of digital and smartphone-delivered interventions is not well understood. This study is a secondary analysis of a randomized controlled effectiveness trial (n=638) that assessed three smartphone-delivered interventions: Project EVO (a cognitive training app), iPST (a problem-solving therapy app), and Health Tips (an active control). We applied classical machine learning models (logistic regression, support vector machines, decision trees, random forests, and k-nearest-neighbors) to identify baseline predictors of MDD improvement at 4 weeks after trial enrollment. Our analysis produced a decision tree model indicating that a baseline GAD-7 questionnaire score of 11 or higher, a threshold consistent with at least moderate anxiety, strongly predicts lower odds of MDD improvement in this trial. Our exploratory findings suggest that depressed individuals with comorbid anxiety have reduced odds of substantial improvement in the context of smartphone-delivered interventions, as the association was observed across all three intervention groups. Our work highlights a methodology that can identify interpretable clinical thresholds, which, if validated, could predict symptom trajectories and inform treatment selection and intensity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.11183v4</guid>
      <category>q-bio.QM</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.jad.2025.120416</arxiv:DOI>
      <arxiv:journal_reference>Talbot, Morgan B., Jessica M. Lipschitz*, and Omar Costilla-Reyes*. "Comorbid anxiety predicts lower odds of MDD improvement in a trial of smartphone-delivered interventions." J. of Affective Disorders (2025): 120416. *Co-Senior Authors</arxiv:journal_reference>
      <dc:creator>Morgan B. Talbot, Jessica M. Lipschitz, Omar Costilla-Reyes</dc:creator>
    </item>
    <item>
      <title>Intelligent Software System for Low-Cost, Brightfield Segmentation: Algorithmic Implementation for Cytometric Auto-Analysis</title>
      <link>https://arxiv.org/abs/2509.11354</link>
      <description>arXiv:2509.11354v4 Announce Type: replace 
Abstract: Bright-field microscopy, a cost-effective solution for live-cell culture, is often the only resource available, along with standard CPUs, for many low-budget labs. The inherent chal- lenges of bright-field images - their noisiness, low contrast, and dynamic morphology - coupled with a lack of GPU resources and complex software interfaces, hinder the desired research output. This article presents a novel microscopy image analysis frame- work designed for low-budget labs equipped with a standard CPU desktop. The Python-based program enables cytometric analysis of live, unstained cells in culture through an advanced computer vision and machine learning pipeline. Crucially, the framework operates on label-free data, requiring no manually annotated training data or training phase. It is accessible via a user-friendly, cross-platform GUI that requires no programming skills, while also providing a scripting interface for programmatic control and integration by developers. The end-to-end workflow performs semantic and instance segmentation, feature extraction, analysis, evaluation, and automated report generation. Its modular archi- tecture supports easy maintenance and flexible integration while supporting both single-image and batch processing. Validated on several unstained cell types from the public dataset of livecells, the framework demonstrates superior accuracy and reproducibility compared to contemporary tools like Cellpose and StarDist. Its competitive segmentation speed on a CPU-based platform highlights its significant potential for basic research and clinical applications - particularly in cell transplantation for personalised medicine and muscle regeneration therapies. The access to the application is available for reproducibility</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11354v4</guid>
      <category>q-bio.QM</category>
      <category>cs.CV</category>
      <category>eess.IV</category>
      <category>q-bio.CB</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Surajit Das, Pavel Zun</dc:creator>
    </item>
    <item>
      <title>LICO: Large Language Models for In-Context Molecular Optimization</title>
      <link>https://arxiv.org/abs/2406.18851</link>
      <description>arXiv:2406.18851v2 Announce Type: replace-cross 
Abstract: Optimizing black-box functions is a fundamental problem in science and engineering. To solve this problem, many approaches learn a surrogate function that estimates the underlying objective from limited historical evaluations. Large Language Models (LLMs), with their strong pattern-matching capabilities via pretraining on vast amounts of data, stand out as a potential candidate for surrogate modeling. However, directly prompting a pretrained language model to produce predictions is not feasible in many scientific domains due to the scarcity of domain-specific data in the pretraining corpora and the challenges of articulating complex problems in natural language. In this work, we introduce LICO, a general-purpose model that extends arbitrary base LLMs for black-box optimization, with a particular application to the molecular domain. To achieve this, we equip the language model with a separate embedding layer and prediction layer, and train the model to perform in-context predictions on a diverse set of functions defined over the domain. Once trained, LICO can generalize to unseen molecule properties simply via in-context prompting. LICO performs competitively on PMO, a challenging molecular optimization benchmark comprising 23 objective functions, and achieves state-of-the-art performance on its low-budget version PMO-1K.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.18851v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>physics.chem-ph</category>
      <category>q-bio.BM</category>
      <category>q-bio.QM</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tung Nguyen, Aditya Grover</dc:creator>
    </item>
    <item>
      <title>Saccade crossing avoidance as a visual search strategy</title>
      <link>https://arxiv.org/abs/2508.18404</link>
      <description>arXiv:2508.18404v2 Announce Type: replace-cross 
Abstract: Although visual search appears largely random, several oculomotor biases exist such that the likelihoods of saccade directions and lengths depend on the previous scan path. Compared to the most recent fixations, the impact of the longer path history is more difficult to quantify. Using the step-selection framework commonly used in movement ecology, and analyzing data from 45-second viewings of "Where's Waldo?", we report a new memory-dependent effect that also varies significantly between individuals, which we term self-crossing avoidance. This is a tendency for saccades to avoid crossing those earlier in the scan path, and is most evident when both have small amplitudes. We show this by comparing real data to synthetic data generated from a memoryless approximation of the spatial statistics (i.e. a Markovian nonparametric model with a matching distribution of saccade lengths over time). Maximum likelihood fitting indicates that this effect is strongest when including the last $\approx 7$ seconds of a scan path. The effect size is comparable to well-known forms of history dependence such as inhibition of return. A parametric probabilistic model including a self-crossing penalty term was able to reproduce joint statistics of saccade lengths and self-crossings. We also quantified individual strategic differences, and their consistency over the six images viewed per participant, using mixed-effect regressions. Participants with a higher tendency to avoid crossings displayed smaller saccade lengths and shorter fixation durations on average, but did not display more horizontal, vertical, forward or reverse saccades. Together, these results indicate that the avoidance of crossings is a local orienting strategy that facilitates and complements inhibition of return, and hence exploration of visual scenes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18404v2</guid>
      <category>q-bio.NC</category>
      <category>cs.CV</category>
      <category>q-bio.QM</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alex Szorkovszky, Rujeena Mathema, Pedro Lencastre, Pedro Lind, Anis Yazidi</dc:creator>
    </item>
  </channel>
</rss>
