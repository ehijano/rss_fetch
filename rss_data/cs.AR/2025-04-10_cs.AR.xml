<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.AR updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.AR</link>
    <description>cs.AR updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.AR" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 11 Apr 2025 04:00:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 11 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>CiMBA: Accelerating Genome Sequencing through On-Device Basecalling via Compute-in-Memory</title>
      <link>https://arxiv.org/abs/2504.07298</link>
      <description>arXiv:2504.07298v1 Announce Type: new 
Abstract: As genome sequencing is finding utility in a wide variety of domains beyond the confines of traditional medical settings, its computational pipeline faces two significant challenges. First, the creation of up to 0.5 GB of data per minute imposes substantial communication and storage overheads. Second, the sequencing pipeline is bottlenecked at the basecalling step, consuming &gt;40% of genome analysis time. A range of proposals have attempted to address these challenges, with limited success. We propose to address these challenges with a Compute-in-Memory Basecalling Accelerator (CiMBA), the first embedded ($\sim25$mm$^2$) accelerator capable of real-time, on-device basecalling, coupled with AnaLog (AL)-Dorado, a new family of analog focused basecalling DNNs. Our resulting hardware/software co-design greatly reduces data communication overhead, is capable of a throughput of 4.77 million bases per second, 24x that required for real-time operation, and achieves 17x/27x power/area efficiency over the best prior basecalling embedded accelerator while maintaining a high accuracy comparable to state-of-the-art software basecallers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.07298v1</guid>
      <category>cs.AR</category>
      <category>q-bio.GN</category>
      <pubDate>Fri, 11 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TPDS.2025.3550811</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Parallel and Distributed Systems, pp. 1-15, 2025</arxiv:journal_reference>
      <dc:creator>William Andrew Simon, Irem Boybat, Riselda Kodra, Elena Ferro, Gagandeep Singh, Mohammed Alser, Shubham Jain, Hsinyu Tsai, Geoffrey W. Burr, Onur Mutlu, Abu Sebastian</dc:creator>
    </item>
    <item>
      <title>UniCAIM: A Unified CAM/CIM Architecture with Static-Dynamic KV Cache Pruning for Efficient Long-Context LLM Inference</title>
      <link>https://arxiv.org/abs/2504.07479</link>
      <description>arXiv:2504.07479v1 Announce Type: new 
Abstract: Transformer-based large language models (LLMs) have achieved impressive performance in various natural language processing (NLP) applications. However, the high memory and computation cost induced by the KV cache limits the inference efficiency, especially for long input sequences. Compute-in-memory (CIM)-based accelerators have been proposed for LLM acceleration with KV cache pruning. However, as existing accelerators only support static pruning with a fixed pattern or dynamic pruning with primitive implementations, they suffer from either high accuracy degradation or low efficiency. In this paper, we propose a ferroelectric FET (FeFET)-based unified content addressable memory (CAM) and CIM architecture, dubbed as UniCAIM. UniCAIM features simultaneous support for static and dynamic pruning with 3 computation modes: 1) in the CAM mode, UniCAIM enables approximate similarity measurement in O(1) time for dynamic KV cache pruning with high energy efficiency; 2) in the charge-domain CIM mode, static pruning can be supported based on accumulative similarity score, which is much more flexible compared to fixed patterns; 3) in the current-domain mode, exact attention computation can be conducted with a subset of selected KV cache. We further propose a novel CAM/CIM cell design that leverages the multi-level characteristics of FeFETs for signed multibit storage of the KV cache and in-place attention computation. With extensive experimental results, we demonstrate UniCAIM can reduce the area-energy-delay product (AEDP) by 8.2-831x over the state-ofthe-art CIM-based LLM accelerators at the circuit level, along with high accuracy comparable with dense attention at the application level, showing its great potential for efficient long-context LLM inference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.07479v1</guid>
      <category>cs.AR</category>
      <pubDate>Fri, 11 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weikai Xu, Wenxuan Zeng, Qianqian Huang, Meng Li, Ru Huang</dc:creator>
    </item>
    <item>
      <title>A 950 MHz SIMT Soft Processor</title>
      <link>https://arxiv.org/abs/2504.07538</link>
      <description>arXiv:2504.07538v1 Announce Type: new 
Abstract: Although modern FPGAs have a performance potential of a 1 GHz clock frequency - with both clock networks and embedded blocks such as memories and DSP Blocks capable of these clock rates - user implementations approaching this speed are rarely realized in practice. This is especially true of complex designs such as soft processors.
  In this work we implement a soft GPGPU which exceeds 950 MHz in an Altera Agilex-7 FPGA. The architecture is a 32-bit fixed point Single Instruction, Multiple Thread (SIMT) design, with parameterized thread and register spaces. Up to 4096 threads and 64K registers can be specified by the user. In one example, a processor with 16K registers and a 16KB shared memory required approximately 7K ALMs, 99 M20K memories, and 32 DSP Blocks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.07538v1</guid>
      <category>cs.AR</category>
      <pubDate>Fri, 11 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martin Langhammer, Gregg Baeckler, Kim Bozman</dc:creator>
    </item>
    <item>
      <title>Just TestIt! An SBST Approach To Automate System-Integration Testing</title>
      <link>https://arxiv.org/abs/2504.07555</link>
      <description>arXiv:2504.07555v1 Announce Type: new 
Abstract: This paper introduces TestIt, an open-source Python package designed to automate full-system integration testing using a Software-Based Self-Test (SBST) approach. By dynamically generating test vectors and golden references, TestIt significantly reduces development time and complexity while supporting both simulation and FPGA environments. Its flexible design positions TestIt as a key enabler for the widespread adoption of CI/CD methodologies in open-source RTL development. A case study on the X-HEEP RISC-V microcontroller (MCU), which integrates a custom accelerator, showcases TestIt's ability to detect hardware and software faults that traditional formal methods may overlook. Furthermore, the case study highlights how TestIt can be leveraged to characterize system performance with minimal effort. By automating testing on the PYNQ-Z2 FPGA development board, we achieved a 11x speed-up with respect to RTL simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.07555v1</guid>
      <category>cs.AR</category>
      <pubDate>Fri, 11 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Tommaso Terzano, Luigi Giuffrida, Juan Sapriza, Pasquale Davide Schiavone, Guido Masera, David Atienza, Luciano Lavagno, Maurizio Martina</dc:creator>
    </item>
    <item>
      <title>Quadrilatero: A RISC-V programmable matrix coprocessor for low-power edge applications</title>
      <link>https://arxiv.org/abs/2504.07565</link>
      <description>arXiv:2504.07565v1 Announce Type: new 
Abstract: The rapid growth of AI-based Internet-of-Things applications increased the demand for high-performance edge processing engines on a low-power budget and tight area constraints. As a consequence, vector processor architectures, traditionally designed for high-performance computing (HPC), made their way into edge devices, promising high utilization of floating-point units (FPUs) and low power consumption. However, vector processors can only exploit a single dimension of parallelism, leading to expensive accesses to the vector register file (VRF) when performing matrix computations, which are pervasive in AI workloads. To overcome these limitations while guaranteeing programmability, many researchers and companies are developing dedicated instructions for a more efficient matrix multiplication (MatMul) execution. In this context, we propose Quadrilatero, an open-source RISC-V programmable systolic array coprocessor for low-power edge applications that implements a streamlined matrix ISA extension. We evaluate the post-synthesis power, performance, and area (PPA) metrics of Quadrilatero in a mature 65-nm technology node, showing that it requires only 0.65 mm^2 and that it can reach up to 99.4% of FPU utilization. Compared to a state-of-the-art open-source RISC-V vector processor and a hybrid vector-matrix processor optimized for embedded applications, Quadrilatero improves area efficiency and energy efficiency by up to 77% and 15%, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.07565v1</guid>
      <category>cs.AR</category>
      <pubDate>Fri, 11 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3706594.3726978</arxiv:DOI>
      <dc:creator>Danilo Cammarata, Matteo Perotti, Marco Bertuletti, Angelo Garofalo, Pasquale Davide Schiavone, David Atienza, Luca Benini</dc:creator>
    </item>
    <item>
      <title>High-Level Synthesis of Digital Circuits from Template Haskell and SDF-AP</title>
      <link>https://arxiv.org/abs/2504.07585</link>
      <description>arXiv:2504.07585v1 Announce Type: new 
Abstract: Functional languages as input specifications for High-Level Synthesis (HLS) tools allow to specify data dependencies but do not contain a notion of time nor execution order. In this paper, we propose a method to add this notion to the functional description using the dataflow model SDF-AP. SDF-AP consists of patterns that express consumption and production that we can use to enforce resource usage. We created an HLS-tool that can synthesize parallel hardware, both data and control path, based on the repetition, expressed in Higher-Order Functions, combined with specified SDF-AP patterns.
  Our HLS-tool, based on Template Haskell, generates an Abstract Syntax Tree based on the given patterns and the functional description uses the Clash-compiler to generate VHDL/Verilog.
  Case studies show consistent resource consumption and temporal behavior for our HLS. A comparison with a commercially available HLS-tool shows that our HLS tool outperforms in terms of latency and sometimes in resource consumption.
  The method and tool presented in this paper offer more transparency to the developer and allow to specify more accurately the synthesized hardware compared to what is possible with pragmas of the Vitis HLS-tool.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.07585v1</guid>
      <category>cs.AR</category>
      <pubDate>Fri, 11 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-031-15074-6_1</arxiv:DOI>
      <arxiv:journal_reference>Lecture Notes in Computer Science (LNCS,volume 13511), Springer 2022</arxiv:journal_reference>
      <dc:creator>Hendrik Folmer, Robert de Groote, Marco Bekooij</dc:creator>
    </item>
    <item>
      <title>High-Level Synthesis using SDF-AP, Template Haskell, QuasiQuotes, and GADTs to Generate Circuits from Hierarchical Input Specification</title>
      <link>https://arxiv.org/abs/2504.07595</link>
      <description>arXiv:2504.07595v1 Announce Type: new 
Abstract: FPGAs provide highly parallel and customizable hardware solutions but are traditionally programmed using low-level Hardware Description Languages (HDLs) like VHDL and Verilog. These languages have a low level of abstraction and require engineers to manage control and scheduling manually. High-Level Synthesis (HLS) tools attempt to lift this level of abstraction by translating C/C++ code into hardware descriptions, but their reliance on imperative paradigms leads to challenges in deriving parallelism due to pointer aliasing and sequential execution models.
  Functional programming, with its inherent purity, immutability, and parallelism, presents a more natural abstraction for FPGA design. Existing functional hardware description tools such as Clash enable high-level circuit descriptions but lack automated scheduling and control mechanisms. Prior work by Folmer introduced a framework integrating SDF-AP graphs into Haskell for automatic hardware generation, but it lacked hierarchy and reusability.
  This paper extends that framework by introducing hierarchical pattern specification, enabling structured composition and scalable parallelism. Key contributions include: (1) automatic hardware generation, where both data and control paths are derived from functional specifications with hierarchical patterns, (2) parameterized buffers using GADTs, eliminating the need for manual buffer definitions and facilitating component reuse, and (3) provision of a reference "golden model" that can be simulated in the integrated environment for validation.
  The core focus of this paper is on methodology. But we also evaluate our approach against Vitis HLS, comparing both notation and resulting hardware architectures. Experimental results demonstrate that our method provides greater transparency in resource utilization and scheduling, often outperforming Vitis in both scheduling and predictability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.07595v1</guid>
      <category>cs.AR</category>
      <pubDate>Fri, 11 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hendrik Folmer</dc:creator>
    </item>
    <item>
      <title>Artificial intelligence in creating, representing or expressing an immersive soundscape</title>
      <link>https://arxiv.org/abs/2504.07153</link>
      <description>arXiv:2504.07153v1 Announce Type: cross 
Abstract: In today's tech-driven world, significant advancements in artificial intelligence and virtual reality have emerged. These developments drive research into exploring their intersection in the realm of soundscape. Not only do these technologies raise questions about how they will revolutionize the way we design and create soundscapes, but they also draw significant inquiries into their impact on human perception, understanding, and expression of auditory environments. This paper aims to review and discuss the latest applications of artificial intelligence in this domain. It explores how artificial intelligence can be utilized to create a virtual reality immersive soundscape, exploiting its ability to recognize complex patterns in various forms of data. This includes translating between different modalities such as text, sounds, and animations as well as predicting and generating data across these domains. It addresses questions surrounding artificial intelligence's capacity to predict, detect, and comprehend soundscape data, ultimately aiming to bridge the gap between sound and other forms of human-readable data.  1.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.07153v1</guid>
      <category>cs.SD</category>
      <category>cs.AR</category>
      <category>cs.GR</category>
      <category>physics.class-ph</category>
      <pubDate>Fri, 11 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rima Ayoubi (CRENAU, AAU), Laurent Lescop (CRENAU, AAU), Sang Bum Park</dc:creator>
    </item>
  </channel>
</rss>
