<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 12 Jun 2024 01:49:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 11 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Distributionally Risk-Receptive and Robust Multistage Stochastic Integer Programs and Two-player Interdiction Games with(out) Decision-Dependent Uncertainty</title>
      <link>https://arxiv.org/abs/2406.05256</link>
      <description>arXiv:2406.05256v1 Announce Type: new 
Abstract: In this paper, we study distributionally risk-receptive and distributionally robust (or risk-averse) multistage stochastic mixed-integer programs (denoted by DRR- and DRA-MSIPs). These frameworks are useful for optimization problems under uncertainty where the focus is on analyzing outcomes based on multiple decision-makers' differing perspectives, such as interdiction problems that are attacker-defender games having non-cooperative players. We present cutting plane-based and reformulation-based approaches for solving DRR- and DRA-MSIPs without and with decision-dependent uncertainty to optimality. We show that these approaches are finitely convergent with probability one. Furthermore, we introduce generalizations of DRR- and DRA-MSIPs by presenting multistage stochastic disjunctive programs and algorithms for solving them. To assess the performance of the algorithms for DRR- and DRA-MSIPs, we consider instances of distributionally ambiguous multistage maximum flow and facility location interdiction problems that are important in their own right. Based on our computational results, we observe that the cutting plane-based approaches are 2800% and 2410% (on average) faster than the reformulation-based approaches for the foregoing instances with distributional risk-aversion and risk-receptiveness, respectively. Additionally, we conducted out-of-sample tests to showcase the significance of the DRR framework in revealing network vulnerabilities and also in mitigating the impact of data corruption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05256v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sumin Kang, Manish Bansal</dc:creator>
    </item>
    <item>
      <title>Gradient-based algorithms for multi-objective bi-level optimization</title>
      <link>https://arxiv.org/abs/2406.05455</link>
      <description>arXiv:2406.05455v1 Announce Type: new 
Abstract: Multi-Objective Bi-Level Optimization (MOBLO) addresses nested multi-objective optimization problems common in a range of applications. However, its multi-objective and hierarchical bilevel nature makes it notably complex. Gradient-based MOBLO algorithms have recently grown in popularity, as they effectively solve crucial machine learning problems like meta-learning, neural architecture search, and reinforcement learning. Unfortunately, these algorithms depend on solving a sequence of approximation subproblems with high accuracy, resulting in adverse time and memory complexity that lowers their numerical efficiency. To address this issue, we propose a gradient-based algorithm for MOBLO, called gMOBA, which has fewer hyperparameters to tune, making it both simple and efficient. Additionally, we demonstrate the theoretical validity by accomplishing the desirable Pareto stationarity. Numerical experiments confirm the practical efficiency of the proposed method and verify the theoretical results. To accelerate the convergence of gMOBA, we introduce a beneficial L2O neural network (called L2O-gMOBA) implemented as the initialization phase of our gMOBA algorithm. Comparative results of numerical experiments are presented to illustrate the performance of L2O-gMOBA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05455v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s11425-023-2302-9</arxiv:DOI>
      <arxiv:journal_reference>Sci. China Math. 67, 1419--1438 (2024)</arxiv:journal_reference>
      <dc:creator>Xinmin Yang, Wei Yao, Haian Yin, Shangzhi Zeng, Jin Zhang</dc:creator>
    </item>
    <item>
      <title>Accelerated Stochastic Gradient Method with Applications to Consensus Problem in Markov-Varying Networks</title>
      <link>https://arxiv.org/abs/2406.05474</link>
      <description>arXiv:2406.05474v1 Announce Type: new 
Abstract: Stochastic optimization is a vital field in the realm of mathematical optimization, finding applications in diverse areas ranging from operations research to machine learning. In this paper, we introduce a novel first-order optimization algorithm designed for scenarios where Markovian noise is present, incorporating Nesterov acceleration for enhanced efficiency. The convergence analysis is performed using an assumption on noise depending on the distance to the solution. We also delve into the consensus problem over Markov-varying networks, exploring how this algorithm can be applied to achieve agreement among multiple agents with differing objectives during changes in the communication system. To show the performance of our method on the problem above, we conduct experiments to demonstrate the superiority over the classic approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05474v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vladimir Solodkin, Savelii Chezhegov, Ruslan Nazikov, Aleksandr Beznosikov, Alexander Gasnikov</dc:creator>
    </item>
    <item>
      <title>Optimal Storage Design: An $L^{\infty}$ infused Inventory Control</title>
      <link>https://arxiv.org/abs/2406.05526</link>
      <description>arXiv:2406.05526v1 Announce Type: new 
Abstract: Inventory control typically considers controlling the price and the production rate. However, such systems have rigidity towards altering the physical storage capacity -- one can not easily alter the physical size after the initial design. The paper focuses on this critical aspect, consideration of which leads to a non-standard control problem. Here, the objective is a weighted combination of the classical integral term (formed by usual inventory costs) and an $L^{\infty}$ term (the maximum inventory level in the entire planning horizon). Our approach is to consider an additional state component to capture the `instantaneous' $L^{\infty}$ term (maximum inventory level till that instant) by virtue of which, we could convert the problem to the classical framework. For the direct ($L^{\infty}$) problem, we first identify a relation between the optimal price and the production rate policy, thereby reducing the dimensionality of the problem. By numerically solving a smooth variant of the converted problem, we obtain an optimal policy that illustrates a significant reduction in the storage capacity requirement. Interestingly, the loss in the revenue is negligible (less than $6\%$). As the importance of the $L^{\infty}$ component increases, the variations in the corresponding optimal inventory-level trajectory reduce. In the scenarios with partial/zero information about future demand curves, the above observation provides a guidance -- one should continually tune the policies to maintain instantaneous inventory-levels as close to zero as possible. With such a policy, the reduction in revenue is negligible, while having significant improvements for storage capacity. We theoretically establish certain interesting properties of the optimal policy, which also support the above guidance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05526v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Madhu Dhiman, Veeraruna Kavitha, Nandyala Hemachandra</dc:creator>
    </item>
    <item>
      <title>Best Response Strategies for Asymmetric Sensing in Linear-Quadratic Differential Games</title>
      <link>https://arxiv.org/abs/2406.05632</link>
      <description>arXiv:2406.05632v1 Announce Type: new 
Abstract: In this paper, we revisit the two-player continuous-time infinite-horizon linear quadratic differential game problem, where one of the players can sample the state of the system only intermittently due to a sensing constraint while the other player can do so continuously. Under these asymmetric sensing limitations between the players, we analyze the optimal sensing and control strategies for the player at a disadvantage while the other player continues to play its security strategy. We derive an optimal sensor policy within the class of stationary randomized policies. Finally, using simulations, we show that the expected cost accrued by the first player approaches its security level as its sensing limitation is relaxed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05632v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shubham Aggarwal, Tamer Ba\c{s}ar, Dipankar Maity</dc:creator>
    </item>
    <item>
      <title>A Generalized Version of Chung's Lemma and its Applications</title>
      <link>https://arxiv.org/abs/2406.05637</link>
      <description>arXiv:2406.05637v1 Announce Type: new 
Abstract: Chung's lemma is a classical tool for establishing asymptotic convergence rates of (stochastic) optimization methods under strong convexity-type assumptions and appropriate polynomial diminishing step sizes. In this work, we develop a generalized version of Chung's lemma, which provides a simple non-asymptotic convergence framework for a more general family of step size rules. We demonstrate broad applicability of the proposed generalized Chung's lemma by deriving tight non-asymptotic convergence rates for a large variety of stochastic methods. In particular, we obtain partially new non-asymptotic complexity results for stochastic optimization methods, such as stochastic gradient descent and random reshuffling, under a general $(\theta,\mu)$-Polyak-Lojasiewicz (PL) condition and for various step sizes strategies, including polynomial, constant, exponential, and cosine step sizes rules. Notably, as a by-product of our analysis, we observe that exponential step sizes can adapt to the objective function's geometry, achieving the optimal convergence rate without requiring exact knowledge of the underlying landscape. Our results demonstrate that the developed variant of Chung's lemma offers a versatile, systematic, and streamlined approach to establish non-asymptotic convergence rates under general step size rules.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05637v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Li Jiang, Xiao Li, Andre Milzarek, Junwen Qiu</dc:creator>
    </item>
    <item>
      <title>Exponential Conic Relaxations for Signomial Geometric Programming</title>
      <link>https://arxiv.org/abs/2406.05638</link>
      <description>arXiv:2406.05638v1 Announce Type: new 
Abstract: Signomial geometric programming (SGP) is a computationally challenging, NP-Hard class of nonconvex nonlinear optimization problems. SGP can be solved iteratively using a sequence of convex relaxations; consequently, the strength of such relaxations is an important factor to this iterative approach. Motivated by recent advances in solving exponential conic programming (ECP) problems, this paper develops a novel convex relaxation for SGP. Unlike existing work on relaxations, the base model in this paper does not assume bounded variables. However, bounded variables or monomial terms can be used to strengthen the relaxation by means of additional valid linear inequalities. We show how to embed the ECP relaxation in an iterative algorithm for SGP; leveraging recent advances in interior point method solvers, our computational experiments demonstrate the practical effectiveness of this approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05638v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Milad Dehghani Filabadi, Chen Chen</dc:creator>
    </item>
    <item>
      <title>Distributionally robust stochastic optimal control</title>
      <link>https://arxiv.org/abs/2406.05648</link>
      <description>arXiv:2406.05648v1 Announce Type: new 
Abstract: The main goal of this paper is to discuss the construction of distributionally robust counterparts of stochastic optimal control problems. Randomized and non-randomized policies are considered. In particular, necessary and sufficient conditions for the existence of non-randomized policies are given.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05648v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Shapiro, Yan Li</dc:creator>
    </item>
    <item>
      <title>Decision-Focused Surrogate Modeling for Mixed-Integer Linear Optimization</title>
      <link>https://arxiv.org/abs/2406.05697</link>
      <description>arXiv:2406.05697v1 Announce Type: new 
Abstract: Mixed-integer optimization is at the core of many online decision-making systems that demand frequent updates of decisions in real time. However, due to their combinatorial nature, mixed-integer linear programs (MILPs) can be difficult to solve, rendering them often unsuitable for time-critical online applications. To address this challenge, we develop a data-driven approach for constructing surrogate optimization models in the form of linear programs (LPs) that can be solved much more efficiently than the corresponding MILPs. We train these surrogate LPs in a decision-focused manner such that for different model inputs, they achieve the same or close to the same optimal solutions as the original MILPs. One key advantage of the proposed method is that it allows the incorporation of all the original MILP's linear constraints, which significantly increases the likelihood of obtaining feasible predicted solutions. Results from two computational case studies indicate that this decision-focused surrogate modeling approach is highly data-efficient and provides very accurate predictions of the optimal solutions. In these examples, it outperforms more commonly used neural-network-based optimization proxies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05697v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shivi Dixit, Rishabh Gupta, Qi Zhang</dc:creator>
    </item>
    <item>
      <title>Convergence of ZH-type nonmonotone descent method for Kurdyka-{\L}ojasiewicz optimization problems</title>
      <link>https://arxiv.org/abs/2406.05740</link>
      <description>arXiv:2406.05740v1 Announce Type: new 
Abstract: This note concerns a class of nonmonotone descent methods for minimizing a proper lower semicontinuous Kurdyka-{\L}$\ddot{o}$jasiewicz (KL) function $\Phi$, whose iterate sequence obeys the ZH-type nonmonotone decrease condition and a relative error condition. We prove that the iterate sequence converges to a critical point of $\Phi$, and if $\Phi$ has the KL property of exponent $\theta\in(0,1)$ at this critical point, the convergence has a linear rate for $\theta\in(0,1/2]$ and a sublinear rate of exponent $\frac{1-\theta}{1-2\theta}$ for $\theta\in(1/2,1)$. Our results first resolve the full convergence of the iterate sequence generated by the ZH-type nonmonotone descent method for nonconvex and nonsmooth optimization problems, and extend the full convergence of monotone descent methods for KL optimization problems to the ZH-type nonmonotone descent method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05740v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yitian Qian, Ting Tao, Shaohua Pan, Houduo Qi</dc:creator>
    </item>
    <item>
      <title>An efficient branch-and-cut approach for large-scale competitive facility location problems with limited choice rule</title>
      <link>https://arxiv.org/abs/2406.05775</link>
      <description>arXiv:2406.05775v1 Announce Type: new 
Abstract: In the paper, we consider the competitive facility location problem with limited choice rule (CFLPLCR), which attempts to open a subset of facilities to maximize the net profit of a newcomer company, requiring customers to patronize only a limited number of opening facilities and an outside option. We propose an efficient branch-and-cut (B&amp;C) approach for the CFLPLCR based on newly proposed mixed integer linear programming (MILP) formulations. Specifically, by establishing the submodularity of the probability function, we develop an MILP formulation for the CFLPLCR using the submodular inequalities. For the special case where each customer patronizes at most one open facility and the outside option, we show that the submodular inequalities can characterize the convex hull of the considered set and provide a compact MILP formulation. Moreover, for the general case, we strengthen the submodular inequalities by sequential lifting, resulting in a class of facet-defining inequalities. The proposed lifted submodular inequalities are shown to be stronger than the classic submodular inequalities, enabling to obtain another MILP formulation with a tighter linear programming (LP) relaxation. By extensive numerical experiments, we show that the proposed B&amp;C approach outperforms the state-of-the-art generalized Benders decomposition approach by at least one order of magnitude. Furthermore, it enables to solve CFLPLCR instances with 10000 customers and 2000 facilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05775v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wei-Kun Chen, Wei-Yang Zhang, Yan-Ru Wang, Shahin Gelareh, Yu-Hong Dai</dc:creator>
    </item>
    <item>
      <title>Production and distribution planning, scheduling, and routing optimization in a yogurt supply chain under demand uncertainty: A case study</title>
      <link>https://arxiv.org/abs/2406.05803</link>
      <description>arXiv:2406.05803v1 Announce Type: new 
Abstract: Considering the evolution of the food industry and its challenges, like high perishability, managing the food industry supply chain is a key focus for researchers and decision-makers. Uncertainty in decision-making has gained importance, particularly in the yogurt industry, known for its complexity. This study addresses production and distribution planning, scheduling, and routing in the yogurt supply chain. The problem is characterized by multiple products, a single plant, multiple distribution centers, multiple periods, and various transportation methods. A mixed-integer non-linear programming (MINLP) model is used to minimize total costs, including production, setup, overtime, unmet demand, and transportation. Additionally, a robust fuzzy programming approach is applied under uncertainty, with linearization procedures proposed to convert it into a linearized mixed-integer programming formulation. The problem is tested with two data types: a sample problem in three sizes (small, medium, and large) and real data from Kalle Dairy Company, Iran. A Genetic Algorithm (GA) is developed to solve the problem, with necessary modifications made for its application. The GA's performance is compared to an exact algorithm (Branch &amp; Cut), showing that the company's production policy adapts daily to meet demand precisely. The shift to smaller batch production and longer shelf life allows better stock allocation and avoids shortages in uncertain conditions. The company's policies adapt to severe fluctuations in the business environment, though this requires high costs, such as inventory maintenance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05803v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Babak Javadi, Zeinab Salimzadeh, Amir Hossein Akbari, Mahla Yadegari, Mohammadreza Abdali</dc:creator>
    </item>
    <item>
      <title>Probabilistic Approach to Black-Box Binary Optimization with Budget Constraints: Application to Sensor Placement</title>
      <link>https://arxiv.org/abs/2406.05830</link>
      <description>arXiv:2406.05830v1 Announce Type: new 
Abstract: We present a fully probabilistic approach for solving binary optimization problems with black-box objective functions and with budget constraints. In the probabilistic approach, the optimization variable is viewed as a random variable and is associated with a parametric probability distribution. The original optimization problem is replaced with an optimization over the expected value of the original objective, which is then optimized over the probability distribution parameters. The resulting optimal parameter (optimal policy) is used to sample the binary space to produce estimates of the optimal solution(s) of the original binary optimization problem. The probability distribution is chosen from the family of Bernoulli models because the optimization variable is binary. The optimization constraints generally restrict the feasibility region. This can be achieved by modeling the random variable with a conditional distribution given satisfiability of the constraints. Thus, in this work we develop conditional Bernoulli distributions to model the random variable conditioned by the total number of nonzero entries, that is, the budget constraint. This approach (a) is generally applicable to binary optimization problems with nonstochastic black-box objective functions and budget constraints; (b) accounts for budget constraints by employing conditional probabilities that sample only the feasible region and thus considerably reduces the computational cost compared with employing soft constraints; and (c) does not employ soft constraints and thus does not require tuning of a regularization parameter, for example to promote sparsity, which is challenging in sensor placement optimization problems. The proposed approach is verified numerically by using an idealized bilinear binary optimization problem and is validated by using a sensor placement experiment in a parameter identification setup.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05830v1</guid>
      <category>math.OC</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>math.CO</category>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ahmed Attia</dc:creator>
    </item>
    <item>
      <title>Fast and Certifiable Trajectory Optimization</title>
      <link>https://arxiv.org/abs/2406.05846</link>
      <description>arXiv:2406.05846v2 Announce Type: new 
Abstract: We propose semidefinite trajectory optimization (STROM), a framework that computes fast and certifiably optimal solutions for nonconvex trajectory optimization problems defined by polynomial objectives and constraints. STROM employs sparse second-order Lasserre's hierarchy to generate semidefinite program (SDP) relaxations of trajectory optimization. Different from existing tools (e.g., YALMIP and SOSTOOLS in Matlab), STROM generates chain-like multiple-block SDPs with only positive semidefinite (PSD) variables. Moreover, STROM does so two orders of magnitude faster. Underpinning STROM is cuADMM, the first ADMM-based SDP solver implemented in CUDA and runs in GPUs. cuADMM builds upon the symmetric Gauss-Seidel ADMM algorithm and leverages GPU parallelization to speedup solving sparse linear systems and projecting onto PSD cones. In five trajectory optimization problems (inverted pendulum, cart-pole, vehicle landing, flying robot, and car back-in), cuADMM computes optimal trajectories (with certified suboptimality below 1%) in minutes (when other solvers take hours or run out of memory) and seconds (when others take minutes). Further, when warmstarted by data-driven initialization in the inverted pendulum problem, cuADMM delivers real-time performance: providing certifiably optimal trajectories in 0.66 seconds despite the SDP has 49,500 variables and 47,351 constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05846v2</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shucheng Kang, Xiaoyang Xu, Jay Sarva, Ling Liang, Heng Yang</dc:creator>
    </item>
    <item>
      <title>An optimal control strategy to design passive thermal cloaks of arbitrary shape</title>
      <link>https://arxiv.org/abs/2406.05905</link>
      <description>arXiv:2406.05905v1 Announce Type: new 
Abstract: In this paper we describe a numerical framework for achieving passive thermal cloaking of arbitrary shapes in both static and transient regimes. The design strategy is cast as the solution of an optimal control problem (OCP) for the heat equation where the coefficients of the thermal diffusivity matrix take the role of control functions and the distance between the uncloaked and the cloaked field is minimized in a suitable observation domain. The control actions enter bilinearly in the heat equation, thus making the resulting OCP nonlinear, and its analysis nontrivial. We show that optimal diffusivity coefficients exist both for the static and the transient case; we derive a system of first-order necessary optimality conditions; finally, we carry out their numerical approximation using the Finite Element Method. A series of numerical test cases assess the capability of our strategy to tackle passive thermal cloaking of arbitrarily complex two-dimensional objects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05905v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Riccardo Saporiti, Carlo Sinigaglia, Andrea Manzoni, Francesco Braghin</dc:creator>
    </item>
    <item>
      <title>Delayed supermartingale convergence lemmas for stochastic approximation with Nesterov momentum</title>
      <link>https://arxiv.org/abs/2406.06018</link>
      <description>arXiv:2406.06018v1 Announce Type: new 
Abstract: This paper focus on the convergence of stochastic approximation with Nesterov momentum. Nesterov acceleration has proven effective in machine learning for its ability to reduce computational complexity. The issue of delayed information in the acceleration term remains a challenge to achieving the almost sure convergence. Based on the delayed supermatingale convergence lemmas, we give a series of framework for almost sure convergence. Our framework applies to several widely-used random iterative methods, such as stochastic subgradient methods, the proximal Robbins-Monro method for general stochastic optimization, and the proximal stochastic subgradient method for composite optimization. Through the applications of our framework, these methods with Nesterov acceleration achieve almost sure convergence. And three groups of numerical experiments is to check out theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06018v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zhang Ming-Kun</dc:creator>
    </item>
    <item>
      <title>Algorithms for Multi-Criteria Decision-Making and Efficiency Analysis Problems</title>
      <link>https://arxiv.org/abs/2406.06090</link>
      <description>arXiv:2406.06090v1 Announce Type: new 
Abstract: Multi-criteria decision-making (MCDM) problems involve the evaluation of alternatives based on various minimization and maximization criteria. Similarly, efficiency evaluation (EA) methods assess decision-making units (DMUs) by analyzing their input consumption and output production. MCDM and EA methods face challenges in managing alternatives and DMUs with varying capacities across different criteria (inputs and outputs). That leads to performance assessments often skewed by subjective biases in criteria weighting. We introduce two innovative scenarios utilizing linear programming-based Virtual Gap Analysis (VGA) models to address these limitations. This dual-scenario approach aims to mitigate traditional biases, offering robust solutions for comprehensively assessing alternatives and DMUs. Our methodology allows for the influential ranking of alternatives in MCDM problems and enables each DMU to adjust its input and output ratios to achieve efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06090v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fuh-Hwa Franklin Liu, Su-Chuan Shih</dc:creator>
    </item>
    <item>
      <title>Primitive Heavy-ball Dynamics Achieves $O(\varepsilon^{-7/4})$ Convergence for Nonconvex Optimization</title>
      <link>https://arxiv.org/abs/2406.06100</link>
      <description>arXiv:2406.06100v1 Announce Type: new 
Abstract: First-order optimization methods for nonconvex functions with Lipschitz continuous gradients and Hessian have been studied intensively in both machine learning and optimization. State-of-the-art methods finding an $\varepsilon$-stationary point within $O(\varepsilon^{-{7/4}})$ or $\tilde{O}(\varepsilon^{-{7/4}})$ gradient evaluations are based on Nesterov's accelerated gradient descent (AGD) or Polyak's heavy-ball method. However, these algorithms employ additional mechanisms, such as restart schemes and negative curvature exploitation, which complicate the algorithms' behavior and make it challenging to apply them to more advanced settings (e.g., stochastic optimization). To realize a simpler algorithm, we investigate the heavy-ball differential equation, a continuous-time analogy of the AGD and heavy-ball methods; we prove that the dynamics attains an $\varepsilon$-stationary point within $O(\varepsilon^{-{7/4}})$ time. We also show that a vanilla heavy-ball algorithm, obtained by discretizing the dynamics, achieves the complexity of $O(\varepsilon^{-{7/4}})$ under an additional assumption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06100v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kaito Okamura, Naoki Marumo, Akiko Takeda</dc:creator>
    </item>
    <item>
      <title>On the Complexity of Inverse Bivariate Multi-unit Assignment Valuation Problems</title>
      <link>https://arxiv.org/abs/2406.06152</link>
      <description>arXiv:2406.06152v1 Announce Type: new 
Abstract: Inverse and bilevel optimization problems play a central role in both theory and applications. These two classes are known to be closely related due to the pioneering work of Dempe and Lohse (2006), and thus have often been discussed together ever since. In this paper, we consider inverse problems for multi-unit assignment valuations. Multi-unit assignment valuations form a subclass of strong-substitutes valuations that can be represented by edge-weighted complete bipartite graphs. These valuations play a key role in auction theory as the strong substitutes condition implies the existence of a Walrasian equilibrium. A recent line of research concentrated on the problem of deciding whether a bivariate valuation function is an assignment valuation or not. In this paper, we consider an \emph{inverse} variant of the problem: we are given a bivariate function $g$, and our goal is to find a bivariate multi-unit assignment valuation function $f$ that is as close to $g$ as possible. The difference between $f$ and $g$ can be measured either in $\ell_1$- or $\ell_\infty$-norm. Using tools from discrete convex analysis, we show that the problem is strongly NP-hard. On the other hand, we derive linear programming formulations that solve relaxed versions of the problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06152v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Krist\'of B\'erczi, Lydia Mirabel Mendoza-Cadena</dc:creator>
    </item>
    <item>
      <title>The $n$-Queens Problem in Higher Dimensions</title>
      <link>https://arxiv.org/abs/2406.06260</link>
      <description>arXiv:2406.06260v1 Announce Type: new 
Abstract: How many mutually non-attacking queens can be placed on a d-dimensional chessboard of size n? The n-queens problem in higher dimensions is a generalization of the well-known n-queens problem. We provide a comprehensive overview of theoretical results, bounds, solution methods, and the interconnectivity of the problem within topics of discrete optimization and combinatorics. We present an integer programming formulation of the n-queens problem in higher dimensions and several strengthenings through additional valid inequalities. Compared to recent benchmarks, we achieve a speedup in computational time between 15-70x over all instances of the integer programs. Our computational results prove optimality of certificates for several large instances. Breaking additional, previously unsolved instances with the proposed methods is likely possible. On the primal side, we further discuss heuristic approaches to constructing solutions that turn out to be optimal when compared to the IP. We conclude with preliminary results on the number and density of the solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06260v1</guid>
      <category>math.OC</category>
      <category>math.CO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tim Kunt</dc:creator>
    </item>
    <item>
      <title>Universality of AdaGrad Stepsizes for Stochastic Optimization: Inexact Oracle, Acceleration and Variance Reduction</title>
      <link>https://arxiv.org/abs/2406.06398</link>
      <description>arXiv:2406.06398v1 Announce Type: new 
Abstract: We present adaptive gradient methods (both basic and accelerated) for solving convex composite optimization problems in which the main part is approximately smooth (a.k.a. $(\delta, L)$-smooth) and can be accessed only via a (potentially biased) stochastic gradient oracle. This setting covers many interesting examples including H\"older smooth problems and various inexact computations of the stochastic gradient. Our methods use AdaGrad stepsizes and are adaptive in the sense that they do not require knowing any problem-dependent constants except an estimate of the diameter of the feasible set but nevertheless achieve the best possible convergence rates as if they knew the corresponding constants. We demonstrate that AdaGrad stepsizes work in a variety of situations by proving, in a unified manner, three types of new results. First, we establish efficiency guarantees for our methods in the classical setting where the oracle's variance is uniformly bounded. We then show that, under more refined assumptions on the variance, the same methods without any modifications enjoy implicit variance reduction properties allowing us to express their complexity estimates in terms of the variance only at the minimizer. Finally, we show how to incorporate explicit SVRG-type variance reduction into our methods and obtain even faster algorithms. In all three cases, we present both basic and accelerated algorithms achieving state-of-the-art complexity bounds. As a direct corollary of our results, we obtain universal stochastic gradient methods for H\"older smooth problems which can be used in all situations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06398v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anton Rodomanov, Xiaowen Jiang, Sebastian Stich</dc:creator>
    </item>
    <item>
      <title>On the structure of the value function of optimal exit time problems</title>
      <link>https://arxiv.org/abs/2406.06409</link>
      <description>arXiv:2406.06409v1 Announce Type: new 
Abstract: In this paper, we study an optimal exit time problem with general running and terminal costs and a target $\mathcal{S}\subset\mathbb{R}^d$ having an inner ball property for a nonlinear control system that satisfies mild controllability assumptions. In particular, Petrov's condition at the boundary of $\mathcal{S}$ is not required and the value function $V$ may fail to be locally Lipschitz. In such a weakened set-up, we first establish a representation formula for proximal (horizontal) supergradients of $V$ by using transported proximal normal vectors. This allows us to obtain an external sphere condition for the hypograph of $V$ which yields several regularity properties. In particular, $V$ is almost everywhere twice differentiable and the Hausdorff dimension of its singularities is not greater than $d-1/2$. Furthermore, besides optimality conditions for trajectories of the optimal control problem, we extend the analysis to propagation of singularities and differentiability properties of the value function. An upper bound for the Hausdorff measure of the singular set is also studied, which implies that $V$ is a function of special bounded variation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06409v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Piermarco Cannarsa, Marco Mazzola, Khai T. Nguyen</dc:creator>
    </item>
    <item>
      <title>Improved convergence rates for the multiobjective Frank-Wolfe method</title>
      <link>https://arxiv.org/abs/2406.06457</link>
      <description>arXiv:2406.06457v1 Announce Type: new 
Abstract: This paper analyzes the convergence rates of the {\it Frank-Wolfe } method for solving convex constrained multiobjective optimization. We establish improved convergence rates under different assumptions on the objective function, the feasible set, and the localization of the limit point of the sequence generated by the method. In terms of the objective function values, we firstly show that if the objective function is strongly convex and the limit point of the sequence generated by the method lies in the relative interior of the feasible set, then the algorithm achieves a linear convergence rate. Next, we focus on a special class of problems where the feasible constraint set is $(\alpha,q)$-uniformly convex for some $\alpha &gt;0$ and $q \geq 2$, including, in particular, \(\ell_p\)-balls for all $p&gt;1$. In this context, we prove that the method attains: (i) a rate of $\mathcal{O}(1/k^\frac{q}{q-1})$ when the objective function is strongly convex; and (ii) a linear rate (if $q=2$) or a rate of $\mathcal{O}(1/k^{\frac{q}{q-2}})$ (if $q&gt;2$) under an additional assumption, which always holds if the feasible set does not contain an unconstrained weak Pareto point. We also discuss enhanced convergence rates for the algorithm in terms of an optimality measure. Finally, we provide some simple examples to illustrate the convergence rates and the set of assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06457v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Douglas S. Gon\c{c}alves, Max L. N. Gon\c{c}alves, Jefferson G. Melo</dc:creator>
    </item>
    <item>
      <title>Online Newton Method for Bandit Convex Optimisation</title>
      <link>https://arxiv.org/abs/2406.06506</link>
      <description>arXiv:2406.06506v1 Announce Type: new 
Abstract: We introduce a computationally efficient algorithm for zeroth-order bandit convex optimisation and prove that in the adversarial setting its regret is at most $d^{3.5} \sqrt{n} \mathrm{polylog}(n, d)$ with high probability where $d$ is the dimension and $n$ is the time horizon. In the stochastic setting the bound improves to $M d^{2} \sqrt{n} \mathrm{polylog}(n, d)$ where $M \in [d^{-1/2}, d^{-1 / 4}]$ is a constant that depends on the geometry of the constraint set and the desired computational properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06506v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hidde Fokkema, Dirk van der Hoeven, Tor Lattimore, Jack J. Mayo</dc:creator>
    </item>
    <item>
      <title>Smart Navigation System for Parking Assignment at Large Events: Incorporating Heterogeneous Driver Characteristics</title>
      <link>https://arxiv.org/abs/2406.05135</link>
      <description>arXiv:2406.05135v1 Announce Type: cross 
Abstract: Parking challenges escalate significantly during large events such as concerts or sports games, yet few studies address dynamic parking lot assignments for such occasions. This paper introduces a smart navigation system designed to optimize parking assignments swiftly during large events, utilizing a mixed search algorithm that accounts for the heterogeneous characteristics of drivers. We conducted simulations in the Berkeley city area during the "Big Game" to validate our system and demonstrate the benefits of our innovative parking assignment approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05135v1</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xi Cheng, Gaofeng Su, Siyuan Feng, Ke Liu, Chen Zhu, Hui Lin, Jilin Song, Jianan Chen</dc:creator>
    </item>
    <item>
      <title>Machine Learning-Driven Optimization of TPMS Architected Materials Using Simulated Annealing</title>
      <link>https://arxiv.org/abs/2406.05142</link>
      <description>arXiv:2406.05142v1 Announce Type: cross 
Abstract: The research paper presents a novel approach to optimizing the tensile stress of Triply Periodic Minimal Surface (TPMS) structures through machine learning and Simulated Annealing (SA). The study evaluates the performance of Random Forest, Decision Tree, and XGBoost models in predicting tensile stress, using a dataset generated from finite element analysis of TPMS models. The objective function minimized the negative R-squared value on the validation set to enhance model accuracy. The SA-XGBoost model outperformed the others, achieving an R-squared value of 0.96. In contrast, the SA-Random Forest model achieved an R squared value of 0.89 while the SA-Decision Tree model exhibited greater fluctuations in validation scores. This demonstrates that the SA-XGBoost model is most effective in capturing the complex relationships within the data. The integration of SA helps in optimizing the hyperparameters of these machine learning models, thereby enhancing their predictive capabilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05142v1</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Akshansh Mishra</dc:creator>
    </item>
    <item>
      <title>Risk-Aware Finite-Horizon Social Optimal Control of Mean-Field Coupled Linear-Quadratic Subsystems</title>
      <link>https://arxiv.org/abs/2406.05239</link>
      <description>arXiv:2406.05239v1 Announce Type: cross 
Abstract: We formulate and solve an optimal control problem with cooperative, mean-field coupled linear-quadratic subsystems and additional risk-aware costs depending on the covariance and skew of the disturbance. This problem quantifies the variability of the subsystem state energy rather than merely its expectation. In contrast to related work, we develop an alternative approach that illuminates a family of matrices with many analytical properties, which are useful for effectively extracting the mean-field coupled solution from a standard LQR solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05239v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dhairya Patel, Margaret Chapman</dc:creator>
    </item>
    <item>
      <title>Reinforcement Learning for Intensity Control: An Application to Choice-Based Network Revenue Management</title>
      <link>https://arxiv.org/abs/2406.05358</link>
      <description>arXiv:2406.05358v1 Announce Type: cross 
Abstract: Intensity control is a type of continuous-time dynamic optimization problems with many important applications in Operations Research including queueing and revenue management. In this study, we adapt the reinforcement learning framework to intensity control using choice-based network revenue management as a case study, which is a classical problem in revenue management that features a large state space, a large action space and a continuous time horizon. We show that by utilizing the inherent discretization of the sample paths created by the jump points, a unique and defining feature of intensity control, one does not need to discretize the time horizon in advance, which was believed to be necessary because most reinforcement learning algorithms are designed for discrete-time problems. As a result, the computation can be facilitated and the discretization error is significantly reduced. We lay the theoretical foundation for the Monte Carlo and temporal difference learning algorithms for policy evaluation and develop policy gradient based actor critic algorithms for intensity control. Via a comprehensive numerical study, we demonstrate the benefit of our approach versus other state-of-the-art benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05358v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huiling Meng, Ningyuan Chen, Xuefeng Gao</dc:creator>
    </item>
    <item>
      <title>Regret Bounds for Episodic Risk-Sensitive Linear Quadratic Regulator</title>
      <link>https://arxiv.org/abs/2406.05366</link>
      <description>arXiv:2406.05366v1 Announce Type: cross 
Abstract: Risk-sensitive linear quadratic regulator is one of the most fundamental problems in risk-sensitive optimal control. In this paper, we study online adaptive control of risk-sensitive linear quadratic regulator in the finite horizon episodic setting. We propose a simple least-squares greedy algorithm and show that it achieves $\widetilde{\mathcal{O}}(\log N)$ regret under a specific identifiability assumption, where $N$ is the total number of episodes. If the identifiability assumption is not satisfied, we propose incorporating exploration noise into the least-squares-based algorithm, resulting in an algorithm with $\widetilde{\mathcal{O}}(\sqrt{N})$ regret. To our best knowledge, this is the first set of regret bounds for episodic risk-sensitive linear quadratic regulator. Our proof relies on perturbation analysis of less-standard Riccati equations for risk-sensitive linear quadratic control, and a delicate analysis of the loss in the risk-sensitive performance criterion due to applying the suboptimal controller in the online learning process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05366v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenhao Xu, Xuefeng Gao, Xuedong He</dc:creator>
    </item>
    <item>
      <title>Uplink resource allocation optimization for user-centric cell-free MIMO networks</title>
      <link>https://arxiv.org/abs/2406.05576</link>
      <description>arXiv:2406.05576v1 Announce Type: cross 
Abstract: We examine the problem of optimizing resource allocation in the uplink for a user-centric, cell-free, multi-input multi-output network. We start by modeling and developing resource allocation algorithms for two standard network operation modes. The centralized mode provides high data rates but suffers multiple issues, including scalability. On the other hand, the distributed mode has the opposite problem: relatively low rates, but is scalable. To address these challenges, we combine the strength of the two standard modes, creating a new semi-distributed operation mode. To avoid the need for information exchange between access points, we introduce a new quality of service metric to decentralize the resource allocation algorithms. Our results show that we can eliminate the need for information exchange with a relatively small penalty on data rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05576v1</guid>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TWC.2024.3393869</arxiv:DOI>
      <dc:creator>Zehua Li, Raviraj Adve</dc:creator>
    </item>
    <item>
      <title>Conserving Human Creativity with Evolutionary Generative Algorithms: A Case Study in Music Generation</title>
      <link>https://arxiv.org/abs/2406.05873</link>
      <description>arXiv:2406.05873v1 Announce Type: cross 
Abstract: This study explores the application of evolutionary generative algorithms in music production to preserve and enhance human creativity. By integrating human feedback into Differential Evolution algorithms, we produced six songs that were submitted to international record labels, all of which received contract offers. In addition to testing the commercial viability of these methods, this paper examines the long-term implications of content generation using traditional machine learning methods compared with evolutionary algorithms. Specifically, as current generative techniques continue to scale, the potential for computer-generated content to outpace human creation becomes likely. This trend poses a risk of exhausting the pool of human-created training data, potentially forcing generative machine learning models to increasingly depend on their random input functions for generating novel content. In contrast to a future of content generation guided by aimless random functions, our approach allows for individualized creative exploration, ensuring that computer-assisted content generation methods are human-centric and culturally relevant through time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05873v1</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Justin Kilb, Caroline Ellis</dc:creator>
    </item>
    <item>
      <title>Expressive Power of Graph Neural Networks for (Mixed-Integer) Quadratic Programs</title>
      <link>https://arxiv.org/abs/2406.05938</link>
      <description>arXiv:2406.05938v1 Announce Type: cross 
Abstract: Quadratic programming (QP) is the most widely applied category of problems in nonlinear programming. Many applications require real-time/fast solutions, though not necessarily with high precision. Existing methods either involve matrix decomposition or use the preconditioned conjugate gradient method. For relatively large instances, these methods cannot achieve the real-time requirement unless there is an effective precondition.
  Recently, graph neural networks (GNNs) opened new possibilities for QP. Some promising empirical studies of applying GNNs for QP tasks show that GNNs can capture key characteristics of an optimization instance and provide adaptive guidance accordingly to crucial configurations during the solving process, or directly provide an approximate solution. Despite notable empirical observations, theoretical foundations are still lacking. In this work, we investigate the expressive or representative power of GNNs, a crucial aspect of neural network theory, specifically in the context of QP tasks, with both continuous and mixed-integer settings. We prove the existence of message-passing GNNs that can reliably represent key properties of quadratic programs, including feasibility, optimal objective value, and optimal solution. Our theory is validated by numerical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05938v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziang Chen, Xiaohan Chen, Jialin Liu, Xinshang Wang, Wotao Yin</dc:creator>
    </item>
    <item>
      <title>Computational and Statistical Guarantees for Tensor-on-Tensor Regression with Tensor Train Decomposition</title>
      <link>https://arxiv.org/abs/2406.06002</link>
      <description>arXiv:2406.06002v1 Announce Type: cross 
Abstract: Recently, a tensor-on-tensor (ToT) regression model has been proposed to generalize tensor recovery, encompassing scenarios like scalar-on-tensor regression and tensor-on-vector regression. However, the exponential growth in tensor complexity poses challenges for storage and computation in ToT regression. To overcome this hurdle, tensor decompositions have been introduced, with the tensor train (TT)-based ToT model proving efficient in practice due to reduced memory requirements, enhanced computational efficiency, and decreased sampling complexity. Despite these practical benefits, a disparity exists between theoretical analysis and real-world performance. In this paper, we delve into the theoretical and algorithmic aspects of the TT-based ToT regression model. Assuming the regression operator satisfies the restricted isometry property (RIP), we conduct an error analysis for the solution to a constrained least-squares optimization problem. This analysis includes upper error bound and minimax lower bound, revealing that such error bounds polynomially depend on the order $N+M$. To efficiently find solutions meeting such error bounds, we propose two optimization algorithms: the iterative hard thresholding (IHT) algorithm (employing gradient descent with TT-singular value decomposition (TT-SVD)) and the factorization approach using the Riemannian gradient descent (RGD) algorithm. When RIP is satisfied, spectral initialization facilitates proper initialization, and we establish the linear convergence rate of both IHT and RGD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06002v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhen Qin, Zhihui Zhu</dc:creator>
    </item>
    <item>
      <title>Mean-field games for harvesting problems: Uniqueness, long-time behaviour and weak KAM theory</title>
      <link>https://arxiv.org/abs/2406.06057</link>
      <description>arXiv:2406.06057v1 Announce Type: cross 
Abstract: The goal of this paper is to study a Mean Field Game (MFG) system stemming from the harvesting of resources. Modelling the latter through a reaction-diffusion equation and the harvesters as competing rational agents, we are led to a non-local (in time and space) MFG system that consists of three equations, the study of which is quite delicate. The main focus of this paper is on the derivation of analytical results (e.g existence, uniqueness) and of long time behaviour (here, convergence to the ergodic system). We provide some explicit solutions to this ergodic system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06057v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziad Kobeissi, Idriss Mazari-Fouquer, Dom\`enec Ruiz-Balet</dc:creator>
    </item>
    <item>
      <title>A Guide to Stochastic Optimisation for Large-Scale Inverse Problems</title>
      <link>https://arxiv.org/abs/2406.06342</link>
      <description>arXiv:2406.06342v1 Announce Type: cross 
Abstract: Stochastic optimisation algorithms are the de facto standard for machine learning with large amounts of data. Handling only a subset of available data in each optimisation step dramatically reduces the per-iteration computational costs, while still ensuring significant progress towards the solution. Driven by the need to solve large-scale optimisation problems as efficiently as possible, the last decade has witnessed an explosion of research in this area. Leveraging the parallels between machine learning and inverse problems has allowed harnessing the power of this research wave for solving inverse problems. In this survey, we provide a comprehensive account of the state-of-the-art in stochastic optimisation from the viewpoint of inverse problems. We present algorithms with diverse modalities of problem randomisation and discuss the roles of variance reduction, acceleration, higher-order methods, and other algorithmic modifications, and compare theoretical results with practical behaviour. We focus on the potential and the challenges for stochastic optimisation that are unique to inverse imaging problems and are not commonly encountered in machine learning. We conclude the survey with illustrative examples from imaging problems to examine the advantages and disadvantages that this new generation of algorithms bring to the field of inverse problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06342v1</guid>
      <category>math.NA</category>
      <category>cs.CV</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthias J. Ehrhardt, Zeljko Kereta, Jingwei Liang, Junqi Tang</dc:creator>
    </item>
    <item>
      <title>Challenges with Differentiable Quantum Dynamics</title>
      <link>https://arxiv.org/abs/2406.06361</link>
      <description>arXiv:2406.06361v1 Announce Type: cross 
Abstract: Differentiable quantum dynamics require automatic differentiation of a complex-valued initial value problem, which numerically integrates a system of ordinary differential equations from a specified initial condition, as well as the eigendecomposition of a matrix. We explored several automatic differentiation frameworks for these tasks, finding that no framework natively supports our application requirements. We therefore demonstrate a need for broader support of complex-valued, differentiable numerical integration in scientific computing libraries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06361v1</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sri Hari Krisha Narayanan, Michael Perlin, Robert Lewis-Swan, Jeffrey Larson, Matt Menickelly, Jan H\"uckelheim, Paul Hovland</dc:creator>
    </item>
    <item>
      <title>Random Features Approximation for Control-Affine Systems</title>
      <link>https://arxiv.org/abs/2406.06514</link>
      <description>arXiv:2406.06514v2 Announce Type: cross 
Abstract: Modern data-driven control applications call for flexible nonlinear models that are amenable to principled controller synthesis and realtime feedback. Many nonlinear dynamical systems of interest are control affine. We propose two novel classes of nonlinear feature representations which capture control affine structure while allowing for arbitrary complexity in the state dependence. Our methods make use of random features (RF) approximations, inheriting the expressiveness of kernel methods at a lower computational cost. We formalize the representational capabilities of our methods by showing their relationship to the Affine Dot Product (ADP) kernel proposed by Casta\~neda et al. (2021) and a novel Affine Dense (AD) kernel that we introduce. We further illustrate the utility by presenting a case study of data-driven optimization-based control using control certificate functions (CCF). Simulation experiments on a double pendulum empirically demonstrate the advantages of our methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06514v2</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kimia Kazemian, Yahya Sattar, Sarah Dean</dc:creator>
    </item>
    <item>
      <title>Decentralized Personalized Federated Learning</title>
      <link>https://arxiv.org/abs/2406.06520</link>
      <description>arXiv:2406.06520v1 Announce Type: cross 
Abstract: This work tackles the challenges of data heterogeneity and communication limitations in decentralized federated learning. We focus on creating a collaboration graph that guides each client in selecting suitable collaborators for training personalized models that leverage their local data effectively. Our approach addresses these issues through a novel, communication-efficient strategy that enhances resource efficiency. Unlike traditional methods, our formulation identifies collaborators at a granular level by considering combinatorial relations of clients, enhancing personalization while minimizing communication overhead. We achieve this through a bi-level optimization framework that employs a constrained greedy algorithm, resulting in a resource-efficient collaboration graph for personalized learning. Extensive evaluation against various baselines across diverse datasets demonstrates the superiority of our method, named DPFL. DPFL consistently outperforms other approaches, showcasing its effectiveness in handling real-world data heterogeneity, minimizing communication overhead, enhancing resource efficiency, and building personalized models in decentralized federated learning scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06520v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.MA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Salma Kharrat, Marco Canini, Samuel Horvath</dc:creator>
    </item>
    <item>
      <title>Algorithms for optimal control of hybrid systems with sliding motion</title>
      <link>https://arxiv.org/abs/2101.04754</link>
      <description>arXiv:2101.04754v2 Announce Type: replace 
Abstract: This paper concerns two algorithms for solving optimal control problems with hybrid systems. The first algorithm aims at hybrid systems exhibiting sliding modes. The first algorithm has several features which distinguishes it from the other algorithms for problems described by hybrid systems. First of all, it can cope with hybrid systems which exhibit sliding modes. Secondly, the systems motion on the switching surface is described by index 2 differential--algebraic equations and that guarantees accurate tracking of the sliding motion surface. Thirdly, the gradients of the problems functionals are evaluated with the help of adjoint equations. The adjoint equations presented in the paper take into account sliding motion and exhibit jump conditions at transition times. We state optimality conditions in the form of the weak maximum principle for optimal control problems with hybrid systems exhibiting sliding modes and with piecewise differentiable controls. The second algorithm is for optimal control problems with hybrid systems which do not exhibit sliding motion. In the case of this algorithm we assume that control functions are measurable functions. For each algorithm, we show that every accumulation point of the sequence generated by the algorithm satisfies the weak maximum principle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2101.04754v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Radoslaw Pytlak, Damian Suski</dc:creator>
    </item>
    <item>
      <title>An Integer L-shaped Method for Dynamic Order Fulfillment in Autonomous Last-Mile Delivery with Demand Uncertainty</title>
      <link>https://arxiv.org/abs/2208.09067</link>
      <description>arXiv:2208.09067v3 Announce Type: replace 
Abstract: Given their potential to significantly lower costs and enhance flexibility in last-mile delivery, autonomous delivery solutions like sidewalk robots and drones have garnered increased interest. This paper addresses the dynamic order fulfillment problem faced by a retailer who operates a fleet of low-capacity autonomous delivery vehicles, servicing requests arriving in a stochastic manner. These delivery requests may vary in package profiles, delivery locations, and urgency. We adopt a rolling-horizon framework for order fulfillment and devise a two-stage stochastic program aimed at strategically managing existing orders while considering incoming requests that are subject to various uncertainties. A significant challenge in deploying the envisioned two-stage model lies in its incorporation of vehicle routing constraints, on which exact or brute-force methods are computationally inefficient and unsuitable for real-time operational decisions. To address this, we propose an accelerated L-shaped algorithm, which (i) reduces the branching tree size; (ii) substitutes exact second-stage solutions with heuristic estimations; and (iii) adapts an alternating strategy for adding optimality cuts. This heuristic algorithm demonstrates remarkable performance superiority over the exact method, boasting a more than 20-fold improvement in average running time while maintaining an average optimality gap of less than 1%. It is then employed to solve a wide range of instances to evaluate the advantages of adopting the stochastic model. Our findings demonstrate long-term cost savings of up to 20% when accounting for demand uncertainty in order fulfillment decisions. Meanwhile, the derived savings could diminish as the uncertainty in order arrivals increases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.09067v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Linxuan Shi, Zhengtian Xu, Miguel Lejeune, Qi Luo</dc:creator>
    </item>
    <item>
      <title>A New Class of Path-Following Method for Time-Varying Optimization with Optimal Parametric Function</title>
      <link>https://arxiv.org/abs/2210.00931</link>
      <description>arXiv:2210.00931v3 Announce Type: replace 
Abstract: In this paper, we consider a formulation of nonlinear constrained optimization problems.
  We reformulate it as a time-varying optimization using continuous-time parametric functions
  and derive a dynamical system for tracking the optimal solution.
  We then re-parameterize the dynamical system to express it based on a linear combination of the parametric functions.
  Calculus of variations is applied to optimize the parametric functions, 
  so that the optimality distance of the solution is minimized. 
  Accordingly, an iterative dynamic algorithm, named as OP-TVO,
  is devised to find the solution with an efficient convergence rate.
  We benchmark the performance of the proposed algorithm with the prediction-correction method (PCM)
  from the optimality and computational complexity point-of-views.
  The results show that OP-TVO can compete with PCM
  for the optimization problem of interest,
  which indicates it can be a promising approach to replace PCM for some time-varying optimization problems.
  Furthermore, this work provides a novel paradigm for solving parametric dynamical system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.00931v3</guid>
      <category>math.OC</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Mohsen Amidzadeh</dc:creator>
    </item>
    <item>
      <title>Sampled-data funnel control and its use for safe continual learning</title>
      <link>https://arxiv.org/abs/2303.00523</link>
      <description>arXiv:2303.00523v4 Announce Type: replace 
Abstract: We propose a novel sampled-data output-feedback controller for nonlinear systems of arbitrary relative degree that ensures reference tracking within prescribed error bounds. We provide explicit bounds on the maximum input signal and the required uniform sampling time. A key strength of this approach is its capability to serve as a safety filter for various learning-based controller designs, enabling the use of learning techniques in safety-critical applications. We illustrate its versatility by integrating it with two different controllers: a reinforcement learning controller and a non-parametric predictive controller based on Willems et al.'s fundamental lemma. Numerical simulations illustrate effectiveness of the combined controller design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.00523v4</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Lukas Lanza, Dario Dennst\"adt, Karl Worthmann, Philipp Schmitz, G\"ok\c{c}en Devlet \c{S}en, Stephan Trenn, Manuel Schaller</dc:creator>
    </item>
    <item>
      <title>Random Function Descent</title>
      <link>https://arxiv.org/abs/2305.01377</link>
      <description>arXiv:2305.01377v2 Announce Type: replace 
Abstract: Classical worst-case optimization theory neither explains the success of optimization in machine learning, nor does it help with step size selection. We establish a connection between Bayesian Optimization (i.e. average case optimization theory) and classical optimization using a 'stochastic Taylor approximation' to rediscover gradient descent. This rediscovery yields a step size schedule we call Random Function Descent (RFD), which, in contrast to classical derivations, is scale invariant. Furthermore, our analysis of RFD step sizes yields a theoretical foundation for common step size heuristics such as gradient clipping and gradual learning rate warmup. We finally propose a statistical procedure for estimating the RFD step size schedule and validate this theory with a case study on the MNIST dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.01377v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Felix Benning, Leif D\"oring</dc:creator>
    </item>
    <item>
      <title>Safely Learning Dynamical Systems</title>
      <link>https://arxiv.org/abs/2305.12284</link>
      <description>arXiv:2305.12284v2 Announce Type: replace 
Abstract: A fundamental challenge in learning an unknown dynamical system is to reduce model uncertainty by making measurements while maintaining safety. We formulate a mathematical definition of what it means to safely learn a dynamical system by sequentially deciding where to initialize trajectories. The state of the system must stay within a safety region for a horizon of $T$ time steps under the action of all dynamical systems that (i) belong to a given initial uncertainty set, and (ii) are consistent with information gathered so far.
  First, we consider safely learning a linear dynamical system involving $n$ states. For the case $T=1$, we present an LP-based algorithm that either safely recovers the true dynamics from at most $n$ trajectories, or certifies that safe learning is impossible. For $T=2$, we give an SDP representation of the set of safe initial conditions and show that $\lceil n/2 \rceil$ trajectories generically suffice for safe learning. For $T = \infty$, we provide SDP-representable inner approximations of the set of safe initial conditions and show that one trajectory generically suffices for safe learning. We extend a number of our results to the cases where the initial uncertainty set contains sparse, low-rank, or permutation matrices, or when the system has a control input.
  Second, we consider safely learning a general class of nonlinear dynamical systems. For the case $T=1$, we give an SOCP-based representation of the set of safe initial conditions. For $T=\infty$, we provide semidefinite representable inner approximations to the set of safe initial conditions. We show how one can safely collect trajectories and fit a polynomial model of the nonlinear dynamics that is consistent with the initial uncertainty set and best agrees with the observations. We also present some extensions to cases where the measurements are noisy or the dynamical system involves disturbances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.12284v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amir Ali Ahmadi, Abraar Chaudhry, Vikas Sindhwani, Stephen Tu</dc:creator>
    </item>
    <item>
      <title>On Linear Quadratic Potential Games</title>
      <link>https://arxiv.org/abs/2305.13476</link>
      <description>arXiv:2305.13476v3 Announce Type: replace 
Abstract: Our paper addresses characterizing conditions for a linear quadratic (LQ) game to be a potential game. The desired properties of potential games in finite action settings, such as convergence of learning dynamics to Nash equilibria, and the challenges of learning Nash equilibria in continuous state and action settings motivate us to characterize LQ potential games. Our first contribution is to show that the set of LQ games with full-state feedback that are potential games is very limited, essentially differing only slightly from an identical interest game. Given this finding, we restrict the class of LQ games to those with decoupled dynamics and decoupled state information structure. For this subclass, we show that the set of potential games strictly includes non-identical interest games and characterize conditions for the LQ games in this subclass to be potential. We further derive their corresponding potential function and prove the existence of a Nash equilibrium. Meanwhile, we highlight the challenges in the characterization and computation of Nash equilibrium for this class of potential LQ games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.13476v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Sara Hosseinirad, Giulio Salizzoni, Alireza Alian Porzani, Maryam Kamgarpour</dc:creator>
    </item>
    <item>
      <title>Learning the Uncertainty Sets for Control Dynamics via Set Membership: A Non-Asymptotic Analysis</title>
      <link>https://arxiv.org/abs/2309.14648</link>
      <description>arXiv:2309.14648v2 Announce Type: replace 
Abstract: This paper studies uncertainty set estimation for unknown linear systems. Uncertainty sets are crucial for the quality of robust control since they directly influence the conservativeness of the control design. Departing from the confidence region analysis of least squares estimation, this paper focuses on set membership estimation (SME). Though good numerical performances have attracted applications of SME in the control literature, the non-asymptotic convergence rate of SME for linear systems remains an open question. This paper provides the first convergence rate bounds for SME and discusses variations of SME under relaxed assumptions. We also provide numerical results demonstrating SME's practical promise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.14648v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yingying Li, Jing Yu, Lauren Conger, Taylan Kargin, Adam Wierman</dc:creator>
    </item>
    <item>
      <title>An Alternative Approach to Inverse Z-Transform of Rational Functions</title>
      <link>https://arxiv.org/abs/2310.09808</link>
      <description>arXiv:2310.09808v3 Announce Type: replace 
Abstract: Our paper introduces a novel method for calculating the inverse $\mathcal{Z}$-transform of rational functions. Unlike some existing approaches that rely on partial fraction expansion and involve dividing by $z$, our method allows for the direct computation of the inverse $\mathcal{Z}$-transform without such division. Furthermore, our method expands the rational functions over real numbers instead of complex numbers. Hence, it doesn't need algebraic manipulations to obtain a real-valued answer. Furthermore, it aligns our method more closely with established techniques used in integral, Laplace, and Fourier transforms. In addition, it can lead to fewer calculations in some cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.09808v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>MohammadJavad Vaez, Alireza Hosseini, Kamal Jamshidi</dc:creator>
    </item>
    <item>
      <title>Homotopy trust-region method for phase-field approximations in perimeter-regularized binary optimal control</title>
      <link>https://arxiv.org/abs/2310.12478</link>
      <description>arXiv:2310.12478v2 Announce Type: replace 
Abstract: We consider optimal control problems that have binary-valued control input functions and a perimeter regularization. We develop and analyze a trust-region algorithm that solves a sequence of subproblems in which the regularization term and the binarity constraint are relaxed by a non-convex energy functional. We show how the parameter that controls the distinctiveness of the resulting phase field can be coupled to the trust-region radius updates and be driven to zero over the course of the iterations in order to obtain convergence to stationary points of the limit problem under suitable regularity assumptions. Finally, we highlight and discuss the assumptions and restrictions of our approach and provide the first computational results for a motivating application in the field of control of acoustic waves in dissipative media.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.12478v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paul Manns, Vanja Nikoli\'c</dc:creator>
    </item>
    <item>
      <title>Improved Performance of Stochastic Gradients with Gaussian Smoothing</title>
      <link>https://arxiv.org/abs/2311.00531</link>
      <description>arXiv:2311.00531v2 Announce Type: replace 
Abstract: This work formalizes and analyzes Gaussian smoothing applied to three optimization methods, namely: stochastic gradient descent (GSmoothSGD); Adam (GSmoothAdam) and; stochastic variance reduced gradient (GSmoothSVRG), in the context of training deep learning models. Gaussian smoothing can enhance the behavior of functions by flattening out small fluctuations, thereby reducing the likelihood of gradient descent algorithms converging to suboptimal local minima. The resulting new approaches aim to reduce the complexity of the loss landscape while improving robustness to noise and generalization, which enhances the effectiveness of the base algorithms and facilitating their convergence towards global minima. In addition, the vast majority of efforts aimed at applying Gaussian smoothing to a neural network involve zero-order approximations, resulting in decreased computational efficiency by increasing the time required to train compared to automatic differentiation. To overcome this computational burden, we explicitly construct new smoothed neural networks by deriving Gaussian smoothed versions of the loss functions coming from both feedforward and convolutional network architectures. Finally, we present several numerical examples that exemplify our theoretical results and demonstrate the improved performance of the proposed smoothing algorithms compared to their unsmoothed counterparts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.00531v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrew Starnes, Clayton Webster</dc:creator>
    </item>
    <item>
      <title>Causality-Informed Data-Driven Predictive Control</title>
      <link>https://arxiv.org/abs/2311.09545</link>
      <description>arXiv:2311.09545v2 Announce Type: replace 
Abstract: As a useful and efficient alternative to generic model-based control scheme, data-driven predictive control is subject to bias-variance trade-off and is known to not perform desirably in face of uncertainty. Through the connection between direct data-driven control and subspace predictive control, we gain insight into the reason being the lack of causality as a main cause for high variance of implicit prediction. In this article, we seek to address this deficiency by devising a novel causality-informed formulation of direct data-driven control. Built upon LQ factorization, an equivalent two-stage reformulation of regularized data-driven control is first derived, which bears clearer interpretability and a lower complexity than generic forms. This paves the way for deriving a two-stage causality-informed formulation of data-driven predictive control, as well as a regularized form that balances between control cost minimization and implicit identification of multi-step predictor. Since it only calls for block-triangularization of a submatrix in LQ factorization, the new causality-informed formulation comes at no excess cost as compared to generic ones. Its efficacy is investigated based on numerical examples and application to model-free control of a simulated industrial heating furnace. Empirical results corroborate that the proposed method yields obvious performance improvement over existing formulations in handling stochastic noise and process nonlinearity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.09545v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Malika Sader, Yibo Wang, Dexian Huang, Chao Shang, Biao Huang</dc:creator>
    </item>
    <item>
      <title>Avoiding strict saddle points of nonconvex regularized problems</title>
      <link>https://arxiv.org/abs/2401.09274</link>
      <description>arXiv:2401.09274v2 Announce Type: replace 
Abstract: We introduce a strict saddle property for $\ell_p$ regularized functions, and propose an iterative reweighted $\ell_1$ algorithm to solve the $\ell_p$ regularized problems. The algorithm is guaranteed to converge only to local minimizers when randomly initialized. The strict saddle property is shown generic on these sparse optimization problems. Those analyses as well as the proposed algorithm can be easily extended to general nonconvex regularized problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.09274v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luwei Bai</dc:creator>
    </item>
    <item>
      <title>Bandit Convex Optimisation</title>
      <link>https://arxiv.org/abs/2402.06535</link>
      <description>arXiv:2402.06535v2 Announce Type: replace 
Abstract: Bandit convex optimisation is a fundamental framework for studying zeroth-order convex optimisation. These notes cover the many tools used for this problem, including cutting plane methods, interior point methods, continuous exponential weights, gradient descent and online Newton step. The nuances between the many assumptions and setups are explained. Although there is not much truly new here, some existing tools are applied in novel ways to obtain new algorithms. A few bounds are improved in minor ways.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.06535v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tor Lattimore</dc:creator>
    </item>
    <item>
      <title>Efficient Algorithms for Sum-of-Minimum Optimization</title>
      <link>https://arxiv.org/abs/2402.07070</link>
      <description>arXiv:2402.07070v2 Announce Type: replace 
Abstract: In this work, we propose a novel optimization model termed "sum-of-minimum" optimization. This model seeks to minimize the sum or average of $N$ objective functions over $k$ parameters, where each objective takes the minimum value of a predefined sub-function with respect to the $k$ parameters. This universal framework encompasses numerous clustering applications in machine learning and related fields. We develop efficient algorithms for solving sum-of-minimum optimization problems, inspired by a randomized initialization algorithm for the classic $k$-means (Arthur &amp; Vassilvitskii, 2007) and Lloyd's algorithm (Lloyd, 1982). We establish a new tight bound for the generalized initialization algorithm and prove a gradient-descent-like convergence rate for generalized Lloyd's algorithm. The efficiency of our algorithms is numerically examined on multiple tasks, including generalized principal component analysis, mixed linear regression, and small-scale neural network training. Our approach compares favorably to previous ones based on simpler-but-less-precise optimization reformulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.07070v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lisang Ding, Ziang Chen, Xinshang Wang, Wotao Yin</dc:creator>
    </item>
    <item>
      <title>MPC without Terminal Ingredients Tailored to the SEIR Compartmental Epidemic Model</title>
      <link>https://arxiv.org/abs/2403.09151</link>
      <description>arXiv:2403.09151v2 Announce Type: replace 
Abstract: We consider the SEIR compartmental epidemic model subject to state and input constraints (a cap on the proportion of infectious individuals and limits on the allowed social distancing and quarantining measures, respectively). We present a tailored model predictive control (MPC) scheme without terminal conditions. We rigorously show recursive feasibility and asymptotic convergence of the MPC closed loop to the continuum of disease-free equilibrium points for suitably designed quadratic running cost and a sufficiently long prediction horizon (forecast window). Moreover, we establish the viability kernel (a.k.a. the admissible set) as a domain of attraction of the continuum of equilibria.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09151v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Willem Esterhuizen, Philipp Sauerteig, Stefan Streif, Karl Worthmann</dc:creator>
    </item>
    <item>
      <title>Integer Optimal Control with Fractional Perimeter Regularization</title>
      <link>https://arxiv.org/abs/2404.04938</link>
      <description>arXiv:2404.04938v2 Announce Type: replace 
Abstract: Motivated by many applications, optimal control problems with integer controls have recently received a significant attention. Some state-of-the-art work uses perimeter-regularization to derive stationarity conditions and trust-region algorithms. However, the discretization is difficult in this case because the perimeter is concentrated on a set of dimension $d - 1$ for a domain of dimension $d$.
  This article proposes a potential way to overcome this challenge by using the fractional nonlocal perimeter with fractional exponent $0&lt;\alpha&lt;1$. In this way, the boundary integrals in the perimeter regularization are replaced by volume integrals. Besides establishing some non-trivial properties associated with this perimeter, a $\Gamma$-convergence result is derived. This result establishes convergence of minimizers of fractional perimeter-regularized problem, to the standard one, as the exponent $\alpha$ tends to 1. In addition, the stationarity results are derived and algorithmic convergence analysis is carried out for $\alpha \in (0.5,1)$ under an additional assumption on the gradient of the reduced objective.
  The theoretical results are supplemented by a preliminary computational experiment. We observe that the isotropy of the total variation may be approximated by means of the fractional perimeter functional.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04938v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Harbir Antil, Paul Manns</dc:creator>
    </item>
    <item>
      <title>Fast Two-Time-Scale Stochastic Gradient Method with Applications in Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2405.09660</link>
      <description>arXiv:2405.09660v2 Announce Type: replace 
Abstract: Two-time-scale optimization is a framework introduced in Zeng et al. (2024) that abstracts a range of policy evaluation and policy optimization problems in reinforcement learning (RL). Akin to bi-level optimization under a particular type of stochastic oracle, the two-time-scale optimization framework has an upper level objective whose gradient evaluation depends on the solution of a lower level problem, which is to find the root of a strongly monotone operator. In this work, we propose a new method for solving two-time-scale optimization that achieves significantly faster convergence than the prior arts. The key idea of our approach is to leverage an averaging step to improve the estimates of the operators in both lower and upper levels before using them to update the decision variables. These additional averaging steps eliminate the direct coupling between the main variables, enabling the accelerated performance of our algorithm. We characterize the finite-time convergence rates of the proposed algorithm under various conditions of the underlying objective function, including strong convexity, convexity, Polyak-Lojasiewicz condition, and general non-convexity. These rates significantly improve over the best-known complexity of the standard two-time-scale stochastic approximation algorithm. When applied to RL, we show how the proposed algorithm specializes to novel online sample-based methods that surpass or match the performance of the existing state of the art. Finally, we support our theoretical results with numerical simulations in RL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.09660v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sihan Zeng, Thinh T. Doan</dc:creator>
    </item>
    <item>
      <title>On the Convergence of the Sinkhorn-Knopp Algorithm with Sparse Cost Matrices</title>
      <link>https://arxiv.org/abs/2405.20528</link>
      <description>arXiv:2405.20528v2 Announce Type: replace 
Abstract: This paper presents a theoretical analysis of the convergence rate of the Sinkhorn-Knopp algorithm when the cost matrix is sparse. We derive bounds on the convergence rate that depend on the sparsity pattern and the degree of nonsparsity of the cost matrix. We also explore connections to existing convergence results for dense cost matrices. Our analysis provides new insights into the behavior of the Sinkhorn-Knopp algorithm in the presence of sparsity and highlights potential avenues for algorithmic improvements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20528v2</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jose Rafael Espinosa Mena</dc:creator>
    </item>
    <item>
      <title>Faster Convergence of Local SGD for Over-Parameterized Models</title>
      <link>https://arxiv.org/abs/2201.12719</link>
      <description>arXiv:2201.12719v3 Announce Type: replace-cross 
Abstract: Modern machine learning architectures are often highly expressive. They are usually over-parameterized and can interpolate the data by driving the empirical loss close to zero. We analyze the convergence of Local SGD (or FedAvg) for such over-parameterized models in the heterogeneous data setting and improve upon the existing literature by establishing the following convergence rates. For general convex loss functions, we establish an error bound of $\O(1/T)$ under a mild data similarity assumption and an error bound of $\O(K/T)$ otherwise, where $K$ is the number of local steps and $T$ is the total number of iterations. For non-convex loss functions we prove an error bound of $\O(K/T)$. These bounds improve upon the best previous bound of $\O(1/\sqrt{nT})$ in both cases, where $n$ is the number of nodes, when no assumption on the model being over-parameterized is made. We complete our results by providing problem instances in which our established convergence rates are tight to a constant factor with a reasonably small stepsize. Finally, we validate our theoretical results by performing large-scale numerical experiments that reveal the convergence behavior of Local SGD for practical over-parameterized deep learning models, in which the $\O(1/T)$ convergence rate of Local SGD is clearly shown.</description>
      <guid isPermaLink="false">oai:arXiv.org:2201.12719v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Transactions on Machine Learning Research, ISSN 2835-8856, 2024</arxiv:journal_reference>
      <dc:creator>Tiancheng Qin, S. Rasoul Etesami, C\'esar A. Uribe</dc:creator>
    </item>
    <item>
      <title>Velocity Obstacle for Polytopic Collision Avoidance for Distributed Multi-robot Systems</title>
      <link>https://arxiv.org/abs/2304.07954</link>
      <description>arXiv:2304.07954v2 Announce Type: replace-cross 
Abstract: Obstacle avoidance for multi-robot navigation with polytopic shapes is challenging. Existing works simplify the system dynamics or consider it as a convex or non-convex optimization problem with positive distance constraints between robots, which limits real-time performance and scalability. Additionally, generating collision-free behavior for polytopic-shaped robots is harder due to implicit and non-differentiable distance functions between polytopes. In this paper, we extend the concept of velocity obstacle (VO) principle for polytopic-shaped robots and propose a novel approach to construct the VO in the function of vertex coordinates and other robot's states. Compared with existing work about obstacle avoidance between polytopic-shaped robots, our approach is much more computationally efficient as the proposed approach for construction of VO between polytopes is optimization-free. Based on VO representation for polytopic shapes, we later propose a navigation approach for distributed multi-robot systems. We validate our proposed VO representation and navigation approach in multiple challenging scenarios including large-scale randomized tests, and our approach outperforms the state of art in many evaluation metrics, including completion rate, deadlock rate, and the average travel distance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.07954v2</guid>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jihao Huang, Jun Zeng, Xuemin Chi, Koushil Sreenath, Zhitao Liu, Hongye Su</dc:creator>
    </item>
    <item>
      <title>Nonlinear Distributionally Robust Optimization</title>
      <link>https://arxiv.org/abs/2306.03202</link>
      <description>arXiv:2306.03202v2 Announce Type: replace-cross 
Abstract: This article focuses on a class of distributionally robust optimization (DRO) problems where, unlike the growing body of the literature, the objective function is potentially nonlinear in the distribution. Existing methods to optimize nonlinear functions in probability space use the Frechet derivatives, which present both theoretical and computational challenges. Motivated by this, we propose an alternative notion for the derivative and corresponding smoothness based on Gateaux (G)-derivative for generic risk measures. These concepts are explained via three running risk measure examples of variance, entropic risk, and risk on finite support sets. We then propose a G-derivative based Frank-Wolfe (FW) algorithm for generic nonlinear optimization problems in probability spaces and establish its convergence under the proposed notion of smoothness in a completely norm-independent manner. We use the set-up of the FW algorithm to devise a methodology to compute a saddle point of the nonlinear DRO problem. Finally, we validate our theoretical results on two cases of the entropic and variance risk measures in the context of portfolio selection problems. In particular, we analyze their regularity conditions and "sufficient statistic", compute the respective FW-oracle in various settings, and confirm the theoretical outcomes through numerical validation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.03202v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammed Rayyan Sheriff, Peyman Mohajerin Esfahani</dc:creator>
    </item>
    <item>
      <title>Algorithms for mean-field variational inference via polyhedral optimization in the Wasserstein space</title>
      <link>https://arxiv.org/abs/2312.02849</link>
      <description>arXiv:2312.02849v2 Announce Type: replace-cross 
Abstract: We develop a theory of finite-dimensional polyhedral subsets over the Wasserstein space and optimization of functionals over them via first-order methods. Our main application is to the problem of mean-field variational inference, which seeks to approximate a distribution $\pi$ over $\mathbb{R}^d$ by a product measure $\pi^\star$. When $\pi$ is strongly log-concave and log-smooth, we provide (1) approximation rates certifying that $\pi^\star$ is close to the minimizer $\pi^\star_\diamond$ of the KL divergence over a \emph{polyhedral} set $\mathcal{P}_\diamond$, and (2) an algorithm for minimizing $\text{KL}(\cdot\|\pi)$ over $\mathcal{P}_\diamond$ with accelerated complexity $O(\sqrt \kappa \log(\kappa d/\varepsilon^2))$, where $\kappa$ is the condition number of $\pi$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.02849v2</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yiheng Jiang, Sinho Chewi, Aram-Alexandre Pooladian</dc:creator>
    </item>
    <item>
      <title>Sum-of-Squares &amp; Gaussian Processes I: Certification</title>
      <link>https://arxiv.org/abs/2401.14383</link>
      <description>arXiv:2401.14383v2 Announce Type: replace-cross 
Abstract: We propose a new SoS hierarchy for a broad class of average-case problems. The new high-entropy steps (HES) SoS hierarchy certifies properties of input instances only over a certain family of well behaved distributions of possible solutions. This allows the hierarchy to circumvent the oft-cited impossibility of providing a low-degree SoS proof of concentration of measure \cite[Lec.~1.2, Marley Paradigm]{barak2016proofs} by vastly reducing the set of solution concepts they need to be proven over.
  We evaluate the HES SoS hierarchy on a well-studied Gaussian process: the spherical spin-glass, which is a particular ensemble of random low-degree polynomials (LDPs). We prove that, given an instance sampled from the problem distribution, with high probability there exists a HES distribution that achieves value arbitrarily close to the conjectured optimal algorithmic threshold and, at the same time, there are low-degree SoS certificates that no HES distribution can achieve value above a constant factor times this threshold, improving over standard SoS whose certificates are loose by a factor of $n^{\lfloor p/2 - 1\rfloor/2}$ for a degree-$p$ random polynomial \cite{bhattiprolu2017sum, hopkins2017power}. We also give examples of anisotropic modifications to the spherical spin glass problem where there is proof (or strong evidence) that the HES SoS hierarchy does better than the only other known algorithm \cite{subag2021following}. We conjecture that the HES SoS hierarchy can be applied to any LDP approximate Gaussian process to obtain value that is optimal among polynomial-time algorithms.
  The rounding algorithm is introduced and analyzed in a companion paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.14383v2</guid>
      <category>cs.CC</category>
      <category>math-ph</category>
      <category>math.CA</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>J. S. Sandhu, J. Shi</dc:creator>
    </item>
    <item>
      <title>Rethinking the Capacity of Graph Neural Networks for Branching Strategy</title>
      <link>https://arxiv.org/abs/2402.07099</link>
      <description>arXiv:2402.07099v2 Announce Type: replace-cross 
Abstract: Graph neural networks (GNNs) have been widely used to predict properties and heuristics of mixed-integer linear programs (MILPs) and hence accelerate MILP solvers. This paper investigates the capacity of GNNs to represent strong branching (SB), the most effective yet computationally expensive heuristic employed in the branch-and-bound algorithm. In the literature, message-passing GNN (MP-GNN), as the simplest GNN structure, is frequently used as a fast approximation of SB and we find that not all MILPs's SB can be represented with MP-GNN. We precisely define a class of "MP-tractable" MILPs for which MP-GNNs can accurately approximate SB scores. Particularly, we establish a universal approximation theorem: for any data distribution over the MP-tractable class, there always exists an MP-GNN that can approximate the SB score with arbitrarily high accuracy and arbitrarily high probability, which lays a theoretical foundation of the existing works on imitating SB with MP-GNN. For MILPs without the MP-tractability, unfortunately, a similar result is impossible, which can be illustrated by two MILP instances with different SB scores that cannot be distinguished by any MP-GNN, regardless of the number of parameters. Recognizing this, we explore another GNN structure called the second-order folklore GNN (2-FGNN) that overcomes this limitation, and the aforementioned universal approximation theorem can be extended to the entire MILP space using 2-FGNN, regardless of the MP-tractability. A small-scale numerical experiment is conducted to directly validate our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.07099v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziang Chen, Jialin Liu, Xiaohan Chen, Xinshang Wang, Wotao Yin</dc:creator>
    </item>
    <item>
      <title>Training Dynamics of Multi-Head Softmax Attention for In-Context Learning: Emergence, Convergence, and Optimality</title>
      <link>https://arxiv.org/abs/2402.19442</link>
      <description>arXiv:2402.19442v2 Announce Type: replace-cross 
Abstract: We study the dynamics of gradient flow for training a multi-head softmax attention model for in-context learning of multi-task linear regression. We establish the global convergence of gradient flow under suitable choices of initialization. In addition, we prove that an interesting "task allocation" phenomenon emerges during the gradient flow dynamics, where each attention head focuses on solving a single task of the multi-task model. Specifically, we prove that the gradient flow dynamics can be split into three phases -- a warm-up phase where the loss decreases rather slowly and the attention heads gradually build up their inclination towards individual tasks, an emergence phase where each head selects a single task and the loss rapidly decreases, and a convergence phase where the attention parameters converge to a limit. Furthermore, we prove the optimality of gradient flow in the sense that the limiting model learned by gradient flow is on par with the best possible multi-head softmax attention model up to a constant factor. Our analysis also delineates a strict separation in terms of the prediction accuracy of ICL between single-head and multi-head attention models. The key technique for our convergence analysis is to map the gradient flow dynamics in the parameter space to a set of ordinary differential equations in the spectral domain, where the relative magnitudes of the semi-singular values of the attention weights determines task allocation. To our best knowledge, our work provides the first convergence result for the multi-head softmax attention model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.19442v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siyu Chen, Heejune Sheen, Tianhao Wang, Zhuoran Yang</dc:creator>
    </item>
    <item>
      <title>Efficient Algorithms for Regularized Nonnegative Scale-invariant Low-rank Approximation Models</title>
      <link>https://arxiv.org/abs/2403.18517</link>
      <description>arXiv:2403.18517v3 Announce Type: replace-cross 
Abstract: Regularized nonnegative low-rank approximations such as sparse Nonnegative Matrix Factorization or sparse Nonnegative Tucker Decomposition are an important branch of dimensionality reduction models with enhanced interpretability. However, from a practical perspective, the choice of regularizers and regularization coefficients, as well as the design of efficient algorithms, is challenging because of the multifactor nature of these models and the lack of theory to back these choices. This paper aims at improving upon these issues. By studying a more general model called the Homogeneous Regularized Scale-Invariant, we prove that the scale-invariance inherent to low-rank approximation models causes an implicit regularization with both unexpected beneficial and detrimental effects. This observation allows to better understand the effect of regularization functions in low-rank approximation models, to guide the choice of the regularization hyperparameters, and to design balancing strategies to enhance the convergence speed of dedicated optimization algorithms. Some of these results were already known but restricted to specific instances of regularized low-rank approximations. We also derive a generic Majorization Minimization algorithm that handles many regularized nonnegative low-rank approximations, with convergence guarantees. We showcase our contributions on sparse Nonnegative Matrix Factorization, ridge-regularized Canonical Polyadic decomposition and sparse Nonnegative Tucker Decomposition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18517v3</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jeremy E. Cohen, Valentin Leplat</dc:creator>
    </item>
    <item>
      <title>Randomized Geometric Algebra Methods for Convex Neural Networks</title>
      <link>https://arxiv.org/abs/2406.02806</link>
      <description>arXiv:2406.02806v2 Announce Type: replace-cross 
Abstract: We introduce randomized algorithms to Clifford's Geometric Algebra, generalizing randomized linear algebra to hypercomplex vector spaces. This novel approach has many implications in machine learning, including training neural networks to global optimality via convex optimization. Additionally, we consider fine-tuning large language model (LLM) embeddings as a key application area, exploring the intersection of geometric algebra and modern AI techniques. In particular, we conduct a comparative analysis of the robustness of transfer learning via embeddings, such as OpenAI GPT models and BERT, using traditional methods versus our novel approach based on convex optimization. We test our convex optimization transfer learning method across a variety of case studies, employing different embeddings (GPT-4 and BERT embeddings) and different text classification datasets (IMDb, Amazon Polarity Dataset, and GLUE) with a range of hyperparameter settings. Our results demonstrate that convex optimization and geometric algebra not only enhances the performance of LLMs but also offers a more stable and reliable method of transfer learning via embeddings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.02806v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yifei Wang, Sungyoon Kim, Paul Chu, Indu Subramaniam, Mert Pilanci</dc:creator>
    </item>
  </channel>
</rss>
