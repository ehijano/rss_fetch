<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.IT</link>
    <description>math.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 11 Jun 2025 04:02:58 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Learning-Based Multiuser Scheduling in MIMO-OFDM Systems with Hybrid Beamforming</title>
      <link>https://arxiv.org/abs/2506.08263</link>
      <description>arXiv:2506.08263v1 Announce Type: new 
Abstract: We investigate the multiuser scheduling problem in multiple-input multiple-output (MIMO) systems using orthogonal frequency division multiplexing (OFDM) and hybrid beamforming in which a base station (BS) communicates with multiple users over millimeter wave (mmWave) channels in the downlink. Improved scheduling is critical for enhancing spectral efficiency and the long-term performance of the system from the perspective of proportional fairness (PF) metric in hybrid beamforming systems due to its limited multiplexing gain. Our objective is to maximize PF by properly designing the analog and digital precoders within the hybrid beamforming and selecting the users subject to the number of radio frequency (RF) chains. Leveraging the characteristics of mmWave channels, we apply a two-timescale protocol. On a long timescale, we assign an analog beam to each user. Scheduling the users and designing the digital precoder are done accordingly on a short timescale. To conduct scheduling, we propose combinatorial solutions, such as greedy and sorting algorithms, followed by a machine learning (ML) approach. Our numerical results highlight the trade-off between the performance and complexity of the proposed approaches. Consequently, we show that the choice of approach depends on the specific criteria within a given scenario.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.08263v1</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pouya Agheli, Tugce Kobal, Fran\c{c}ois Durand, Matthew Andrews</dc:creator>
    </item>
    <item>
      <title>Reed-Muller Codes for Quantum Pauli and Multiple Access Channels</title>
      <link>https://arxiv.org/abs/2506.08651</link>
      <description>arXiv:2506.08651v1 Announce Type: new 
Abstract: Reed-Muller (RM) codes have undergone significant analytical advancements over the past decade, particularly for binary memoryless symmetric (BMS) channels. We extend the scope of RM codes development and analysis to multiple-access channels (MACs) and quantum Pauli channels, leveraging a unified approach. Specifically, we first derive the achievable rate region for RM codes on so-called Q-MACs, a class of MACs with additive correlated noise. This is achieved via a generalization of the bending and boosting arguments defined in arXiv:2304.02509. We then put forward a connection between the rate region of these QMACs and quantum RM codes designed for Pauli noise channels. This connection highlights a universality property of quantum RM codes, demonstrating their rate-optimal performance across a range of channel parameters, rather than for a single Pauli channel.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.08651v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>quant-ph</category>
      <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dina Abdelhadi, Colin Sandon, Emmanuel Abbe, Ruediger Urbanke</dc:creator>
    </item>
    <item>
      <title>Linear exact repair schemes for free MDS and Reed-Solomon codes over Galois rings</title>
      <link>https://arxiv.org/abs/2506.09017</link>
      <description>arXiv:2506.09017v1 Announce Type: new 
Abstract: Codes over rings, especially over Galois rings, have been extensively studied for nearly three decades due to their similarity to linear codes over finite fields. A distributed storage system uses a linear code to encode a large file across several nodes. If one of the nodes fails, a linear exact repair scheme efficiently recovers the failed node by accessing and downloading data from the rest of the servers of the storage system. In this article, we develop a linear repair scheme for free maximum distance separable codes, which coincide with free maximum distance with respect to the rank codes over Galois rings. In particular, we give a linear repair scheme for full-length Reed-Solomon codes over a Galois ring.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09017v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.RA</category>
      <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel P. Bossaller, Hiram H. L\'opez</dc:creator>
    </item>
    <item>
      <title>Optimizing Learned Image Compression on Scalar and Entropy-Constraint Quantization</title>
      <link>https://arxiv.org/abs/2506.08662</link>
      <description>arXiv:2506.08662v1 Announce Type: cross 
Abstract: The continuous improvements on image compression with variational autoencoders have lead to learned codecs competitive with conventional approaches in terms of rate-distortion efficiency. Nonetheless, taking the quantization into account during the training process remains a problem, since it produces zero derivatives almost everywhere and needs to be replaced with a differentiable approximation which allows end-to-end optimization. Though there are different methods for approximating the quantization, none of them model the quantization noise correctly and thus, result in suboptimal networks. Hence, we propose an additional finetuning training step: After conventional end-to-end training, parts of the network are retrained on quantized latents obtained at the inference stage. For entropy-constraint quantizers like Trellis-Coded Quantization, the impact of the quantizer is particularly difficult to approximate by rounding or adding noise as the quantized latents are interdependently chosen through a trellis search based on both the entropy model and a distortion measure. We show that retraining on correctly quantized data consistently yields additional coding gain for both uniform scalar and especially for entropy-constraint quantization, without increasing inference complexity. For the Kodak test set, we obtain average savings between 1% and 2%, and for the TecNick test set up to 2.2% in terms of Bj{\o}ntegaard-Delta bitrate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.08662v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1109/ICIP51287.2024.10648254</arxiv:DOI>
      <arxiv:journal_reference>2024 IEEE International Conference on Image Processing (ICIP), Abu Dhabi, United Arab Emirates, 2024, pp. 3688-3694</arxiv:journal_reference>
      <dc:creator>Florian Borzechowski, Michael Sch\"afer, Heiko Schwarz, Jonathan Pfaff, Detlev Marpe, Thomas Wiegand</dc:creator>
    </item>
    <item>
      <title>Normalized Radon Cumulative Distribution Transforms for Invariance and Robustness in Optimal Transport Based Image Classification</title>
      <link>https://arxiv.org/abs/2506.08761</link>
      <description>arXiv:2506.08761v1 Announce Type: cross 
Abstract: The Radon cumulative distribution transform (R-CDT), is an easy-to-compute feature extractor that facilitates image classification tasks especially in the small data regime. It is closely related to the sliced Wasserstein distance and provably guaranties the linear separability of image classes that emerge from translations or scalings. In many real-world applications, like the recognition of watermarks in filigranology, however, the data is subject to general affine transformations originating from the measurement process. To overcome this issue, we recently introduced the so-called max-normalized R-CDT that only requires elementary operations and guaranties the separability under arbitrary affine transformations. The aim of this paper is to continue our study of the max-normalized R-CDT especially with respect to its robustness against non-affine image deformations. Our sensitivity analysis shows that its separability properties are stable provided the Wasserstein-infinity distance between the samples can be controlled. Since the Wasserstein-infinity distance only allows small local image deformations, we moreover introduce a mean-normalized version of the R-CDT. In this case, robustness relates to the Wasserstein-2 distance and also covers image deformations caused by impulsive noise for instance. Our theoretical results are supported by numerical experiments showing the effectiveness of our novel feature extractors as well as their robustness against local non-affine deformations and impulsive noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.08761v1</guid>
      <category>math.NA</category>
      <category>cs.CV</category>
      <category>cs.IT</category>
      <category>cs.NA</category>
      <category>math.IT</category>
      <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matthias Beckmann, Robert Beinert, Jonas Bresch</dc:creator>
    </item>
    <item>
      <title>InfoDPCCA: Information-Theoretic Dynamic Probabilistic Canonical Correlation Analysis</title>
      <link>https://arxiv.org/abs/2506.08884</link>
      <description>arXiv:2506.08884v1 Announce Type: cross 
Abstract: Extracting meaningful latent representations from high-dimensional sequential data is a crucial challenge in machine learning, with applications spanning natural science and engineering. We introduce InfoDPCCA, a dynamic probabilistic Canonical Correlation Analysis (CCA) framework designed to model two interdependent sequences of observations. InfoDPCCA leverages a novel information-theoretic objective to extract a shared latent representation that captures the mutual structure between the data streams and balances representation compression and predictive sufficiency while also learning separate latent components that encode information specific to each sequence. Unlike prior dynamic CCA models, such as DPCCA, our approach explicitly enforces the shared latent space to encode only the mutual information between the sequences, improving interpretability and robustness. We further introduce a two-step training scheme to bridge the gap between information-theoretic representation learning and generative modeling, along with a residual connection mechanism to enhance training stability. Through experiments on synthetic and medical fMRI data, we demonstrate that InfoDPCCA excels as a tool for representation learning. Code of InfoDPCCA is available at https://github.com/marcusstang/InfoDPCCA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.08884v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shiqin Tang, Shujian Yu</dc:creator>
    </item>
    <item>
      <title>Semantic Communication for Cooperative Multi-Tasking over Rate-Limited Wireless Channels with Implicit Optimal Prior</title>
      <link>https://arxiv.org/abs/2506.08944</link>
      <description>arXiv:2506.08944v1 Announce Type: cross 
Abstract: In this work, we expand the cooperative multi-task semantic communication framework (CMT-SemCom) introduced in [1], which divides the semantic encoder on the transmitter side into a common unit (CU) and multiple specific units (SUs), to a more applicable design. Our proposed system model addresses real-world constraints by introducing a general design that operates over rate-limited wireless channels. Further, we aim to tackle the rate-limit constraint, represented through the Kullback-Leibler (KL) divergence, by employing the density ratio trick alongside the implicit optimal prior method (IoPm). By applying the IoPm to our multi-task processing framework, we propose a hybrid learning approach that combines deep neural networks with kernelized-parametric machine learning methods, enabling a robust solution for the CMT-SemCom. Our framework is grounded in information-theoretic principles and employs variational approximations to bridge theoretical foundations with practical implementations. Simulation results demonstrate the proposed system's effectiveness in rate-constrained multi-task SemCom scenarios, highlighting its potential for enabling intelligence in next-generation wireless networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.08944v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ahmad Halimi Razlighi, Carsten Bockelmann, Armin Dekorsy</dc:creator>
    </item>
    <item>
      <title>Building Resilience in Wireless Communication Systems With a Secret-Key Budget</title>
      <link>https://arxiv.org/abs/2407.11604</link>
      <description>arXiv:2407.11604v2 Announce Type: replace 
Abstract: Resilience and power consumption are two important performance metrics for many modern communication systems, and it is therefore important to define, analyze, and optimize them. In this work, we consider a wireless communication system with secret-key generation, in which the secret-key bits are added to and used from a pool of available key bits. We propose novel physical layer resilience metrics for the survivability of such systems. In addition, we propose multiple power allocation schemes and analyze their trade-off between resilience and power consumption. In particular, we investigate and compare constant power allocation, an adaptive analytical algorithm, and a reinforcement learning-based solution. It is shown how the transmit power can be minimized such that a specified resilience is guaranteed. These results can be used directly by designers of such systems to optimize the system parameters for the desired performance in terms of reliability, security, and resilience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11604v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TCOMM.2025.3577649</arxiv:DOI>
      <dc:creator>Karl-Ludwig Besser, Rafael F. Schaefer, H. Vincent Poor</dc:creator>
    </item>
    <item>
      <title>Integrated Sensing and Communications in Downlink FDD MIMO without CSI Feedback</title>
      <link>https://arxiv.org/abs/2412.12590</link>
      <description>arXiv:2412.12590v2 Announce Type: replace 
Abstract: In this paper, we propose a precoding framework for frequency division duplex (FDD) integrated sensing and communication (ISAC) systems with multiple-input multiple-output (MIMO). Specifically, we aim to maximize ergodic sum spectral efficiency (SE) while satisfying a sensing beam pattern constraint defined by the mean squared error (MSE). Our method reconstructs downlink (DL) channel state information (CSI) from uplink (UL) training signals using partial reciprocity, eliminating the need for CSI feedback. To obtain the error covariance matrix of the reconstructed DL CSI, we devise an observed Fisher information-based estimation technique. Leveraging this, to mitigate interference caused by imperfect DL CSI reconstruction and sensing operations, we propose a rate-splitting multiple access (RSMA) aided precoder optimization method. This method jointly updates the precoding vector and Lagrange multipliers by solving the nonlinear eigenvalue problem with eigenvector dependency to maximize SE. The numerical results show that the proposed design achieves precise beam pattern control, maximizes SE, and significantly improves the sensing-communication trade-off compared to the state-of-the-art methods in FDD ISAC scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12590v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Namhyun Kim, Juntaek Han, Jinseok Choi, Ahmed Alkhateeb, Chan-Byoung Chae, Jeonghun Park</dc:creator>
    </item>
    <item>
      <title>Quantifying imperfect cognition via achieved information gain</title>
      <link>https://arxiv.org/abs/2502.04088</link>
      <description>arXiv:2502.04088v3 Announce Type: replace 
Abstract: Cognition, information processing in form of inference, communication, and memorization, is the central activity of any intelligence. Its physical realization in a brain, computer, or in any other intelligent system requires resources like time, energy, memory, bandwidth, money, and others. Due to limited resources, many real world intelligent systems perform only imperfect cognition. To understand the trade-off between accuracy and resource investments in existing systems, e.g. in biology, as well as for the resource-aware optimal design of information processing systems, like computer algorithms and artificial neural networks, a quantification of information obtained in an imperfect cognitive operation is desirable. To this end, we propose the concept of the achieved information gain (AIG) of a belief update, which is given by the amount of information obtained by updating from the initial state of knowledge to the ideal state, minus the amount that a change from the imperfect to the ideal state would yield. AIG has many desirable properties for quantifying imperfect cognition. The ratio of achieved to ideally obtainable information measures cognitive fidelity and that of AIG to the necessary cognitive effort measures cognitive efficiency. We provide an axiomatic derivation of AIG, relate it to other information measures, illustrate its application to common scenarios of posterior inaccuracies, and discuss the implication of cognitive efficiency for sustainable resource allocation in computational inference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04088v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1002/andp.202500057</arxiv:DOI>
      <arxiv:journal_reference>En{\ss}lin, Annalen der Physik 2025, e2500057</arxiv:journal_reference>
      <dc:creator>Torsten En{\ss}lin</dc:creator>
    </item>
    <item>
      <title>New Difference Triangle Sets by an FPGA-Based Search Technique</title>
      <link>https://arxiv.org/abs/2502.19517</link>
      <description>arXiv:2502.19517v2 Announce Type: replace 
Abstract: We provide some difference triangle sets with scopes that improve upon the best known values. These are found with purpose-built digital circuits realized with field-programmable gate arrays (FPGAs) rather than software algorithms running on general-purpose processors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.19517v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohannad Shehadeh, William Kingsford, Frank R. Kschischang</dc:creator>
    </item>
    <item>
      <title>Generalization analysis of an unfolding network for analysis-based Compressed Sensing</title>
      <link>https://arxiv.org/abs/2303.05582</link>
      <description>arXiv:2303.05582v3 Announce Type: replace-cross 
Abstract: Unfolding networks have shown promising results in the Compressed Sensing (CS) field. Yet, the investigation of their generalization ability is still in its infancy. In this paper, we perform a generalization analysis of a state-of-the-art ADMM-based unfolding network, which jointly learns a decoder for CS and a sparsifying redundant analysis operator. To this end, we first impose a structural constraint on the learnable sparsifier, which parametrizes the network's hypothesis class. For the latter, we estimate its Rademacher complexity. With this estimate in hand, we deliver generalization error bounds -- which scale like the square root of the number of layers -- for the examined network. Finally, the validity of our theory is assessed and numerical comparisons to a state-of-the-art unfolding network are made, on synthetic and real-world datasets. Our experimental results demonstrate that our proposed framework complies with our theoretical findings and outperforms the baseline, consistently for all datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.05582v3</guid>
      <category>cs.LG</category>
      <category>cs.IR</category>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.acha.2025.101787</arxiv:DOI>
      <dc:creator>Vicky Kouni, Yannis Panagakis</dc:creator>
    </item>
    <item>
      <title>Efficient Multiparty Entanglement Distribution with DODAG-X Protocol</title>
      <link>https://arxiv.org/abs/2408.07118</link>
      <description>arXiv:2408.07118v2 Announce Type: replace-cross 
Abstract: In this work we introduce the DODAG-X protocol for multipartite entanglement distribution in quantum networks. Leveraging the power of Destination Oriented Directed Acyclic Graphs (DODAGs), our protocol optimizes resource consumption and enhances robustness to noise in dynamic and lossy networks. Implementing a variation on the X-protocol within the DODAG, we minimize graph verification and path-finding calculations, significantly reducing computational overhead when compared to other entanglement routing schemes. Additionally, our benchmarks on grid lattice and small-world topologies reveal substantial measurement reduction compared to existing protocols. We demonstrate the success of DODAG-X for generating maximal three-party entanglement in arbitrary networks, and describe the potential for scaling to generic $n$-party entanglement. The DODAG-X protocol provides a scalable and efficient solution for entanglement routing, advancing current techniques for reliable quantum communication and network applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07118v2</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math-ph</category>
      <category>math.IT</category>
      <category>math.MP</category>
      <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roberto Negrin, Nicolas Dirnegger, William Munizzi, Jugal Talukdar, Prineha Narang</dc:creator>
    </item>
    <item>
      <title>Bounds on MLDR Codes Over ${\mathbb Z}_{p^t}$</title>
      <link>https://arxiv.org/abs/2408.11107</link>
      <description>arXiv:2408.11107v3 Announce Type: replace-cross 
Abstract: Upper bounds on the minimum Lee distance of codes that are linear over ${\mathbb Z}_q$, $q=p^t$, $p$ prime are discussed. The bounds are Singleton like, depending on the length, rank, and alphabet size of the code. Codes meeting such bounds are referred to as Maximum Lee Distance with respect to Rank (MLDR) Codes. We present some new bounds on MLDR codes, using combinatorial arguments. In the context of MLDR codes, our work provides improvements over existing bounds in the literature</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.11107v3</guid>
      <category>math.CO</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tim L. Alderson</dc:creator>
    </item>
    <item>
      <title>The Causal Information Bottleneck and Optimal Causal Variable Abstractions</title>
      <link>https://arxiv.org/abs/2410.00535</link>
      <description>arXiv:2410.00535v4 Announce Type: replace-cross 
Abstract: To effectively study complex causal systems, it is often useful to construct abstractions of parts of the system by discarding irrelevant details while preserving key features. The Information Bottleneck (IB) method is a widely used approach to construct variable abstractions by compressing random variables while retaining predictive power over a target variable. Traditional methods like IB are purely statistical and ignore underlying causal structures, making them ill-suited for causal tasks. We propose the Causal Information Bottleneck (CIB), a causal extension of the IB, which compresses a set of chosen variables while maintaining causal control over a target variable. This method produces abstractions of (sets of) variables which are causally interpretable, give us insight about the interactions between the abstracted variables and the target variable, and can be used when reasoning about interventions. We present experimental results demonstrating that the learned abstractions accurately capture causal relations as intended.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00535v4</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Francisco N. F. Q. Simoes, Mehdi Dastani, Thijs van Ommen</dc:creator>
    </item>
    <item>
      <title>Cooperative and Collaborative Multi-Task Semantic Communication for Distributed Sources</title>
      <link>https://arxiv.org/abs/2411.02150</link>
      <description>arXiv:2411.02150v2 Announce Type: replace-cross 
Abstract: In this paper, we explore a multi-task semantic communication (SemCom) system for distributed sources, extending the existing focus on collaborative single-task execution. We build on the cooperative multi-task processing introduced in [1], which divides the encoder into a common unit (CU) and multiple specific units (SUs). While earlier studies in multi-task SemCom focused on full observation settings, our research explores a more realistic case where only distributed partial observations are available, such as in a production line monitored by multiple sensing nodes. To address this, we propose an SemCom system that supports multi-task processing through cooperation on the transmitter side via split structure and collaboration on the receiver side. We have used an information-theoretic perspective with variational approximations for our end-to-end data-driven approach. Simulation results demonstrate that the proposed cooperative and collaborative multi-task (CCMT) SemCom system significantly improves task execution accuracy, particularly in complex datasets, if the noise introduced from the communication channel is not limiting the task performance too much. Our findings contribute to a more general SemCom framework capable of handling distributed sources and multiple tasks simultaneously, advancing the applicability of SemCom systems in real-world scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02150v2</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ahmad Halimi Razlighi, Maximilian H. V. Tillmann, Edgar Beck, Carsten Bockelmann, Armin Dekorsy</dc:creator>
    </item>
    <item>
      <title>Spectral Estimators for Multi-Index Models: Precise Asymptotics and Optimal Weak Recovery</title>
      <link>https://arxiv.org/abs/2502.01583</link>
      <description>arXiv:2502.01583v2 Announce Type: replace-cross 
Abstract: Multi-index models provide a popular framework to investigate the learnability of functions with low-dimensional structure and, also due to their connections with neural networks, they have been object of recent intensive study. In this paper, we focus on recovering the subspace spanned by the signals via spectral estimators -- a family of methods routinely used in practice, often as a warm-start for iterative algorithms. Our main technical contribution is a precise asymptotic characterization of the performance of spectral methods, when sample size and input dimension grow proportionally and the dimension $p$ of the space to recover is fixed. Specifically, we locate the top-$p$ eigenvalues of the spectral matrix and establish the overlaps between the corresponding eigenvectors (which give the spectral estimators) and a basis of the signal subspace. Our analysis unveils a phase transition phenomenon in which, as the sample complexity grows, eigenvalues escape from the bulk of the spectrum and, when that happens, eigenvectors recover directions of the desired subspace. The precise characterization we put forward enables the optimization of the data preprocessing, thus allowing to identify the spectral estimator that requires the minimal sample size for weak recovery.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01583v2</guid>
      <category>stat.ML</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Filip Kova\v{c}evi\'c, Yihan Zhang, Marco Mondelli</dc:creator>
    </item>
    <item>
      <title>A Theory of Machine Understanding via the Minimum Description Length Principle</title>
      <link>https://arxiv.org/abs/2504.00395</link>
      <description>arXiv:2504.00395v3 Announce Type: replace-cross 
Abstract: Deep neural networks trained through end-to-end learning have achieved remarkable success across various domains in the past decade. However, the end-to-end learning strategy, originally designed to minimize predictive loss in a black-box manner, faces two fundamental limitations: the struggle to form explainable representations in a self-supervised manner, and the inability to compress information rigorously following the Minimum Description Length (MDL) principle. These two limitations point to a deeper issue: an end-to-end learning model is not able to "understand" what it learns. In this paper, we establish a novel theory connecting these two limitations. We design the Spectrum VAE, a novel deep learning architecture whose minimum description length (MDL) can be rigorously evaluated. Then, we introduce the concept of latent dimension combinations, or what we term spiking patterns, and demonstrate that the observed spiking patterns should be as few as possible based on the training data in order for the Spectrum VAE to achieve the MDL. Finally, our theory demonstrates that when the MDL is achieved with respect to the given data distribution, the Spectrum VAE will naturally produce explainable latent representations of the data. In other words, explainable representations--or "understanding"--can emerge in a self-supervised manner simply by making the deep network obey the MDL principle. In our opinion, this also implies a deeper insight: To understand is to compress. At its core, our theory advocates for a shift in the training objective of deep networks: not only to minimize predictive loss, but also to minimize the description length regarding the given data. That is, a deep network should not only learn, but also understand what it learns. This work is entirely theoretical and aims to inspire future research toward self-supervised, explainable AI grounded in the MDL principle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.00395v3</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Canlin Zhang, Xiuwen Liu</dc:creator>
    </item>
  </channel>
</rss>
