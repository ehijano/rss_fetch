<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GR updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GR</link>
    <description>cs.GR updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GR" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 23 Oct 2025 04:00:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Visually Comparing Graph Vertex Ordering Algorithms through Geometrical and Topological Approaches</title>
      <link>https://arxiv.org/abs/2510.19009</link>
      <description>arXiv:2510.19009v1 Announce Type: new 
Abstract: Graph vertex ordering is widely employed in spatial data analysis, especially in urban analytics, where street graphs serve as spatial discretization for modeling and simulation. It is also crucial for visualization, as many methods require vertices to be arranged in a well-defined order to reveal non-trivial patterns. The goal of vertex ordering methods is to preserve neighborhood relations, but the structural complexity of real-world graphs often introduces distortions. Comparing different ordering methods is therefore essential to identify the most suitable one for each application. Existing metrics for assessing spatial vertex ordering typically focus on global quality, which hinders the identification of localized distortions. Visual evaluation is particularly valuable, as it allows analysts to compare methods within a single visualization, assess distortions, identify anomalous regions, and, in urban contexts, explain spatial inconsistencies. This work presents a visualization-assisted tool for assessing vertex ordering techniques, with a focus on urban analytics. We evaluate geometric and topological ordering approaches using urban street graphs. The visual tool integrates existing and newly proposed metrics, validated through experiments on data from multiple cities. Results demonstrate that the proposed methodology effectively supports users in selecting suitable vertex ordering techniques, tuning hyperparameters, and identifying regions with high ordering distortions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19009v1</guid>
      <category>cs.GR</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Karelia Salinas, Victor Barella, Thales Viera, Luis Gustavo Nonato</dc:creator>
    </item>
    <item>
      <title>A New Type of Adversarial Examples</title>
      <link>https://arxiv.org/abs/2510.19347</link>
      <description>arXiv:2510.19347v1 Announce Type: cross 
Abstract: Most machine learning models are vulnerable to adversarial examples, which poses security concerns on these models. Adversarial examples are crafted by applying subtle but intentionally worst-case modifications to examples from the dataset, leading the model to output a different answer from the original example. In this paper, adversarial examples are formed in an exactly opposite manner, which are significantly different from the original examples but result in the same answer. We propose a novel set of algorithms to produce such adversarial examples, including the negative iterative fast gradient sign method (NI-FGSM) and the negative iterative fast gradient method (NI-FGM), along with their momentum variants: the negative momentum iterative fast gradient sign method (NMI-FGSM) and the negative momentum iterative fast gradient method (NMI-FGM). Adversarial examples constructed by these methods could be used to perform an attack on machine learning systems in certain occasions. Moreover, our results show that the adversarial examples are not merely distributed in the neighbourhood of the examples from the dataset; instead, they are distributed extensively in the sample space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19347v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.GR</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xingyang Nie, Guojie Xiao, Su Pan, Biao Wang, Huilin Ge, Tao Fang</dc:creator>
    </item>
    <item>
      <title>Optimized 3D Gaussian Splatting using Coarse-to-Fine Image Frequency Modulation</title>
      <link>https://arxiv.org/abs/2503.14475</link>
      <description>arXiv:2503.14475v2 Announce Type: replace 
Abstract: The field of Novel View Synthesis has been revolutionized by 3D Gaussian Splatting (3DGS), which enables high-quality scene reconstruction that can be rendered in real-time. 3DGS-based techniques typically suffer from high GPU memory and disk storage requirements which limits their practical application on consumer-grade devices. We propose Opti3DGS, a novel frequency-modulated coarse-to-fine optimization framework that aims to minimize the number of Gaussian primitives used to represent a scene, thus reducing memory and storage demands. Opti3DGS leverages image frequency modulation, initially enforcing a coarse scene representation and progressively refining it by modulating frequency details in the training images. On the baseline 3DGS, we demonstrate an average reduction of 62% in Gaussians, a 40% reduction in the training GPU memory requirements and a 20% reduction in optimization time without sacrificing the visual quality. Furthermore, we show that our method integrates seamlessly with many 3DGS-based techniques, consistently reducing the number of Gaussian primitives while maintaining, and often improving, visual quality. Additionally, Opti3DGS inherently produces a level-of-detail scene representation at no extra cost, a natural byproduct of the optimization pipeline. Results and code will be made publicly available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14475v2</guid>
      <category>cs.GR</category>
      <category>cs.CV</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Umar Farooq, Jean-Yves Guillemaut, Adrian Hilton, Marco Volino</dc:creator>
    </item>
    <item>
      <title>LookUp3D: Data-Driven 3D Scanning</title>
      <link>https://arxiv.org/abs/2405.14882</link>
      <description>arXiv:2405.14882v2 Announce Type: replace-cross 
Abstract: High speed, high-resolution, and accurate 3D scanning would open doors to many new applications in graphics, robotics, science, and medicine by enabling the accurate scanning of deformable objects during interactions. Past attempts to use structured light, time-of-flight, and stereo in high-speed settings have usually required tradeoffs in resolution or inaccuracy. In this paper, we introduce a method that enables, for the first time, 3D scanning at 450 frames per second at 1~Megapixel, or 1,450 frames per second at 0.4~Megapixel in an environment with controlled lighting. The key idea is to use a per-pixel lookup table that maps colors to depths, which is built using a linear stage. Imperfections, such as lens-distortion and sensor defects are baked into the calibration. We describe our method and test it on a novel hardware prototype. We compare the system with both ground-truth geometry as well as commercially available dynamic sensors like the Microsoft Kinect and Intel Realsense. Our results show the system acquiring geometry of objects undergoing high-speed deformations and oscillations and demonstrate the ability to recover physical properties from the reconstructions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14882v2</guid>
      <category>cs.CV</category>
      <category>cs.GR</category>
      <category>eess.IV</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giancarlo Pereira, Yidan Gao, Yurii Piadyk, David Fouhey, Claudio T Silva, Daniele Panozzo</dc:creator>
    </item>
  </channel>
</rss>
