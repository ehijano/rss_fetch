<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 05 Nov 2024 05:00:05 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Optimal Inapproximability of Promise Equations over Finite Groups</title>
      <link>https://arxiv.org/abs/2411.01630</link>
      <description>arXiv:2411.01630v1 Announce Type: new 
Abstract: A celebrated result of Hastad established that, for any constant $\varepsilon&gt;0$, it is NP-hard to find an assignment satisfying a $(1/|G|+\varepsilon)$-fraction of the constraints of a given 3-LIN instance over an Abelian group $G$ even if one is promised that an assignment satisfying a $(1-\varepsilon)$-fraction of the constraints exists. Engebretsen, Holmerin, and Russell showed the same result for 3-LIN instances over any finite (not necessarily Abelian) group. In other words, for almost-satisfiable instances of 3-LIN the random assignment achieves an optimal approximation guarantee. We prove that the random assignment algorithm is still best possible under a stronger promise that the 3-LIN instance is almost satisfiable over an arbitrarily more restrictive group.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01630v1</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Silvia Butti, Alberto Larrauri, Stanislav \v{Z}ivn\'y</dc:creator>
    </item>
    <item>
      <title>Closing the complexity gap of the double distance problem</title>
      <link>https://arxiv.org/abs/2411.01691</link>
      <description>arXiv:2411.01691v1 Announce Type: new 
Abstract: Genome rearrangement has been an active area of research in computational comparative genomics for the last three decades. While initially mostly an interesting algorithmic endeavor, now the practical application by applying rearrangement distance methods and more advanced phylogenetic tasks is becoming common practice, given the availability of many completely sequenced genomes. Several genome rearrangement models have been developed over time, sometimes with surprising computational properties. A prominent example is the fact that computing the reversal distance of two signed permutations is possible in linear time, while for two unsigned permutations it is NP-hard. Therefore one has always to be careful about the precise problem formulation and complexity analysis of rearrangement problems in order not to be fooled. The double distance is the minimum number of genomic rearrangements between a singular and a duplicated genome that, in addition to rearrangements, are separated by a whole genome duplication. At the same time it allows to assign the genes of the duplicated genome to the two paralogous chromosome copies that existed right after the duplication event. Computing the double distance is another example of a tricky hardness landscape: If the distance measure underlying the double distance is the simple breakpoint distance, the problem can be solved in linear time, while with the more elaborate DCJ distance it is NP-hard. Indeed, there is a family of distance measures, parameterized by an even number k, between the breakpoint distance (k=2) and the DCJ distance (k=\infty). Little was known about the hardness border between these extremes; the problem complexity was known only for k=4 and k=6. In this paper, we close the gap, providing a full picture of the hardness landscape when computing the double distance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01691v1</guid>
      <category>cs.CC</category>
      <category>math.CO</category>
      <category>q-bio.PE</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lu\'is Cunha, Thiago Lopes, U\'everton Souza, Mar\'ilia D. V. Braga, Jens Stoye</dc:creator>
    </item>
    <item>
      <title>Some easy optimization problems have the overlap-gap property</title>
      <link>https://arxiv.org/abs/2411.01836</link>
      <description>arXiv:2411.01836v1 Announce Type: new 
Abstract: We show that the shortest $s$-$t$ path problem has the overlap-gap property in (i) sparse $\mathbf{G}(n,p)$ graphs and (ii) complete graphs with i.i.d. Exponential edge weights. Furthermore, we demonstrate that in sparse $\mathbf{G}(n,p)$ graphs, shortest path is solved by $O(\log n)$-degree polynomial estimators, and a uniform approximate shortest path can be sampled in polynomial time. This constitutes the first example in which the overlap-gap property is not predictive of algorithmic intractability for a (non-algebraic) average-case optimization problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01836v1</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <category>math.PR</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuangping Li, Tselil Schramm</dc:creator>
    </item>
    <item>
      <title>Parks: A Doubly Infinite Family of NP-Complete Puzzles and Generalizations of A002464</title>
      <link>https://arxiv.org/abs/2411.02251</link>
      <description>arXiv:2411.02251v1 Announce Type: new 
Abstract: The Parks Puzzle is a paper-and-pencil puzzle game that is classically played on a square grid with different colored regions (the parks). The player needs to place a certain number of "trees" in each row, column, and park such that none are adjacent, even diagonally. We define a doubly-infinite family of such puzzles, the $(c, r)$-tree Parks puzzles, where there need be $c$ trees per column and $r$ per row. We then prove that for each $c$ and $r$ the set of $(c, r)$-tree puzzles is NP-complete. For each $c$ and $r$, there is a sequence of possible board sizes $m \times n$, and the number of possible puzzle solutions for these board sizes is a doubly-infinite generalization of OEIS sequence A002464, which itself describes the case $c = r = 1$. This connects the Parks puzzle to chess-based puzzle problems, as the sequence describes the number of ways to place non-attacking kings on a chessboard so that there is exactly one in each column and row (i.e. to place non-attacking dragon kings in shogi). These findings add yet another puzzle to the set of chess puzzles and expands the list of known NP-complete problems described.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02251v1</guid>
      <category>cs.CC</category>
      <category>math.CO</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Igor Minevich, Gabe Cunningham, Aditya Karan, Joshua V. Gyllinsky</dc:creator>
    </item>
    <item>
      <title>One-Way Functions and Polynomial Time Dimension</title>
      <link>https://arxiv.org/abs/2411.02392</link>
      <description>arXiv:2411.02392v1 Announce Type: new 
Abstract: This work solves an open problem regarding the rate of time-bounded Kolmogorov complexity and polynomial-time dimension, conditioned on a hardness assumption. Hitchcock and Vinodchandran (CCC 2004) show that the polynomial-time dimension of infinite sequences (denoted ${\mathrm{cdim}}_\mathrm{P}$) defined using betting algorithms called gales, is lower bounded by the asymptotic lower rate of polynomial-time Kolmogorov complexity (denoted $\mathcal{K}_\text{poly}$). Hitchcock and Vindochandran and Stull asked whether the converse relationship also holds. This question has thus far resisted resolution. The corresponding unbounded notions, namely, the constructive dimension and the asymptotic lower rate of unbounded Kolmogorov complexity are equal for every sequence. Analogous notions are equal even at finite-state level. In view of these results, it is reasonable to conjecture that the polynomial-time quantities are identical for every sequence and set of sequences.
  However, under a plausible assumption which underlies modern cryptography - namely the existence of one-way functions, we refute the conjecture thereby giving a negative answer to the open question posed by Hitchcock and Vinodchandran and Stull .
  We show the following, conditioned on the existence of one-way functions: There are sets $\mathcal{F}$ of infinite sequences whose polytime dimension strictly exceeds $\mathcal{K}_\text{poly}(\mathcal{F})$, that is ${\mathrm{cdim}}_\mathrm{P}(\mathcal{F}) &gt; \mathcal{K}_\text{poly}(\mathcal{F})$. We establish a stronger version of this result, that there are individual sequences $X$ whose poly-time dimension strictly exceeds $\mathcal{K}_\text{poly}(X)$, that is ${\mathrm{cdim}}_\mathrm{P}(X) &gt; \mathcal{K}_\text{poly}(X)$. Further, we show that the gap between these quantities can be made arbitrarily close to 1. We also establish similar bounds for strong poly-time dimension</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02392v1</guid>
      <category>cs.CC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Satyadev Nandakumar, Subin Pulari, Akhil S, Suronjona Sarma</dc:creator>
    </item>
    <item>
      <title>Classical versus quantum queries in quantum PCPs with classical proofs</title>
      <link>https://arxiv.org/abs/2411.00946</link>
      <description>arXiv:2411.00946v1 Announce Type: cross 
Abstract: We generalize quantum-classical PCPs, first introduced by Weggemans, Folkertsma and Cade (TQC 2024), to allow for $q$ quantum queries to a polynomially-sized classical proof ($\mathsf{QCPCP}_{Q,c,s}[q]$). Exploiting a connection with the polynomial method, we prove that for any constant $q$, promise gap $c-s = \Omega(1/\text{poly}(n))$ and $\delta&gt;0$, we have $\mathsf{QCPCP}_{Q,c,s}[q] \subseteq \mathsf{QCPCP}_{1-\delta,1/2+\delta}[3] \subseteq \mathsf{BQ} \cdot \mathsf{NP}$, where $\mathsf{BQ} \cdot \mathsf{NP}$ is the class of promise problems with quantum reductions to an $\mathsf{NP}$-complete problem. Surprisingly, this shows that we can amplify the promise gap from inverse polynomial to constant for constant query quantum-classical PCPs, and that any quantum-classical PCP making any constant number of quantum queries can be simulated by one that makes only three classical queries. Nevertheless, even though we can achieve promise gap amplification, our result also gives strong evidence that there exists no constant query quantum-classical PCP for $\mathsf{QCMA}$, as it is unlikely that $\mathsf{QCMA} \subseteq \mathsf{BQ} \cdot \mathsf{NP}$, which we support by giving oracular evidence. In the (poly-)logarithmic query regime, we show for any positive integer $c$, there exists an oracle relative to which $\mathsf{QCPCP}[\mathcal{O}(\log^c n)] \subsetneq \mathsf{QCPCP}_Q[\mathcal{O}(\log^c n)]$, contrasting the constant query case where the equivalence of both query models holds relative to any oracle. Finally, we connect our results to more general quantum-classical interactive proof systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00946v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Harry Buhrman, Fran\c{c}ois Le Gall, Jordi Weggemans</dc:creator>
    </item>
    <item>
      <title>Low-degree approximation of QAC$^0$ circuits</title>
      <link>https://arxiv.org/abs/2411.00976</link>
      <description>arXiv:2411.00976v1 Announce Type: cross 
Abstract: QAC$^0$ is the class of constant-depth quantum circuits with polynomially many ancillary qubits, where Toffoli gates on arbitrarily many qubits are allowed. In this work, we show that the parity function cannot be computed in QAC$^0$, resolving a long-standing open problem in quantum circuit complexity more than twenty years old. As a result, this proves ${\rm QAC}^0 \subsetneqq {\rm QAC}_{\rm wf}^0$. We also show that any QAC circuit of depth $d$ that approximately computes parity on $n$ bits requires $2^{\widetilde{\Omega}(n^{1/d})}$ ancillary qubits, which is close to tight. This implies a similar lower bound on approximately preparing cat states using QAC circuits. Finally, we prove a quantum analog of the Linial-Mansour-Nisan theorem for QAC$^0$. This implies that, for any QAC$^0$ circuit $U$ with $a={\rm poly}(n)$ ancillary qubits, and for any $x\in\{0,1\}^n$, the correlation between $Q(x)$ and the parity function is bounded by ${1}/{2} + 2^{-\widetilde{\Omega}(n^{1/d})}$, where $Q(x)$ denotes the output of measuring the output qubit of $U|x,0^a\rangle$. All the above consequences rely on the following technical result. If $U$ is a QAC$^0$ circuit with $a={\rm poly}(n)$ ancillary qubits, then there is a distribution $\mathcal{D}$ of bounded polynomials of degree polylog$(n)$ such that with high probability, a random polynomial from $\mathcal{D}$ approximates the function $\langle x,0^a| U^\dag Z_{n+1} U |x,0^a\rangle$ for a large fraction of $x\in \{0,1\}^n$. This result is analogous to the Razborov-Smolensky result on the approximation of AC$^0$ circuits by random low-degree polynomials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00976v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ashley Montanaro, Changpeng Shao, Dominic Verdon</dc:creator>
    </item>
    <item>
      <title>Rapidly mixing loop representation quantum Monte Carlo for Heisenberg models on star-like bipartite graphs</title>
      <link>https://arxiv.org/abs/2411.01452</link>
      <description>arXiv:2411.01452v1 Announce Type: cross 
Abstract: Quantum Monte Carlo (QMC) methods have proven invaluable in condensed matter physics, particularly for studying ground states and thermal equilibrium properties of quantum Hamiltonians without a sign problem. Over the past decade, significant progress has also been made on their rigorous convergence analysis.
  Heisenberg antiferromagnets (AFM) with bipartite interaction graphs are a popular target of computational QMC studies due to their physical importance, but despite the apparent empirical efficiency of these simulations it remains an open question whether efficient classical approximation of the ground energy is possible in general. In this work we introduce a ground state variant of the stochastic series expansion QMC method, and for the special class of AFM on interaction graphs with an $O(1)$-bipartite component (star-like), we prove rapid mixing of the associated QMC Markov chain (polynomial time in the number of qubits) by using Jerrum and Sinclair's method of canonical paths. This is the first Markov chain analysis of a practical class of QMC algorithms with the loop representation of Heisenberg models.
  Our findings contribute to the broader effort to resolve the computational complexity of Heisenberg AFM on general bipartite interaction graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01452v1</guid>
      <category>quant-ph</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.CC</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jun Takahashi, Sam Slezak, Elizabeth Crosson</dc:creator>
    </item>
    <item>
      <title>Unlocking the Theory Behind Scaling 1-Bit Neural Networks</title>
      <link>https://arxiv.org/abs/2411.01663</link>
      <description>arXiv:2411.01663v1 Announce Type: cross 
Abstract: Recently, 1-bit Large Language Models (LLMs) have emerged, showcasing an impressive combination of efficiency and performance that rivals traditional LLMs. Research by Wang et al. (2023); Ma et al. (2024) indicates that the performance of these 1-bit LLMs progressively improves as the number of parameters increases, hinting at the potential existence of a Scaling Law for 1-bit Neural Networks. In this paper, we present the first theoretical result that rigorously establishes this scaling law for 1-bit models. We prove that, despite the constraint of weights restricted to $\{-1, +1\}$, the dynamics of model training inevitably align with kernel behavior as the network width grows. This theoretical breakthrough guarantees convergence of the 1-bit model to an arbitrarily small loss as width increases. Furthermore, we introduce the concept of the generalization difference, defined as the gap between the outputs of 1-bit networks and their full-precision counterparts, and demonstrate that this difference maintains a negligible level as network width scales. Building on the work of Kaplan et al. (2020), we conclude by examining how the training loss scales as a power-law function of the model size, dataset size, and computational resources utilized for training. Our findings underscore the promising potential of scaling 1-bit neural networks, suggesting that int1 could become the standard in future neural network precision.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01663v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CC</category>
      <category>cs.CL</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Majid Daliri, Zhao Song, Chiwun Yang</dc:creator>
    </item>
    <item>
      <title>Toward Separating QMA from QCMA with a Classical Oracle</title>
      <link>https://arxiv.org/abs/2411.01718</link>
      <description>arXiv:2411.01718v1 Announce Type: cross 
Abstract: QMA is the class of languages that can be decided by an efficient quantum verifier given a quantum witness, whereas QCMA is the class of such languages where the efficient quantum verifier only is given a classical witness. A challenging fundamental goal in quantum query complexity is to find a classical oracle separation for these classes. In this work, we offer a new approach towards proving such a separation that is qualitatively different than prior work, and show that our approach is sound assuming a natural statistical conjecture which may have other applications to quantum query complexity lower bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01718v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mark Zhandry</dc:creator>
    </item>
    <item>
      <title>Ask, and it shall be given: Turing completeness of prompting</title>
      <link>https://arxiv.org/abs/2411.01992</link>
      <description>arXiv:2411.01992v1 Announce Type: cross 
Abstract: Since the success of GPT, large language models (LLMs) have been revolutionizing machine learning and have initiated the so-called LLM prompting paradigm. In the era of LLMs, people train a single general-purpose LLM and provide the LLM with different prompts to perform different tasks. However, such empirical success largely lacks theoretical understanding. Here, we present the first theoretical study on the LLM prompting paradigm to the best of our knowledge. In this work, we show that prompting is in fact Turing-complete: there exists a finite-size Transformer such that for any computable function, there exists a corresponding prompt following which the Transformer computes the function. Furthermore, we show that even though we use only a single finite-size Transformer, it can still achieve nearly the same complexity bounds as that of the class of all unbounded-size Transformers. Overall, our result reveals that prompting can enable a single finite-size Transformer to be efficiently universal, which establishes a theoretical underpinning for prompt engineering in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01992v1</guid>
      <category>cs.LG</category>
      <category>cs.CC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruizhong Qiu, Zhe Xu, Wenxuan Bao, Hanghang Tong</dc:creator>
    </item>
    <item>
      <title>An Exponential Separation Between Quantum and Quantum-Inspired Classical Algorithms for Machine Learning</title>
      <link>https://arxiv.org/abs/2411.02087</link>
      <description>arXiv:2411.02087v1 Announce Type: cross 
Abstract: Achieving a provable exponential quantum speedup for an important machine learning task has been a central research goal since the seminal HHL quantum algorithm for solving linear systems and the subsequent quantum recommender systems algorithm by Kerenidis and Prakash. These algorithms were initially believed to be strong candidates for exponential speedups, but a lower bound ruling out similar classical improvements remained absent. In breakthrough work by Tang, it was demonstrated that this lack of progress in classical lower bounds was for good reasons. Concretely, she gave a classical counterpart of the quantum recommender systems algorithm, reducing the quantum advantage to a mere polynomial. Her approach is quite general and was named quantum-inspired classical algorithms. Since then, almost all the initially exponential quantum machine learning speedups have been reduced to polynomial via new quantum-inspired classical algorithms. From the current state-of-affairs, it is unclear whether we can hope for exponential quantum speedups for any natural machine learning task.
  In this work, we present the first such provable exponential separation between quantum and quantum-inspired classical algorithms. We prove the separation for the basic problem of solving a linear system when the input matrix is well-conditioned and has sparse rows and columns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02087v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Allan Gr{\o}nlund, Kasper Green Larsen</dc:creator>
    </item>
    <item>
      <title>Optimality of Frequency Moment Estimation</title>
      <link>https://arxiv.org/abs/2411.02148</link>
      <description>arXiv:2411.02148v1 Announce Type: cross 
Abstract: Estimating the second frequency moment of a stream up to $(1\pm\varepsilon)$ multiplicative error requires at most $O(\log n / \varepsilon^2)$ bits of space, due to a seminal result of Alon, Matias, and Szegedy. It is also known that at least $\Omega(\log n + 1/\varepsilon^{2})$ space is needed. We prove an optimal lower bound of $\Omega\left(\log \left(n \varepsilon^2 \right) / \varepsilon^2\right)$ for all $\varepsilon = \Omega(1/\sqrt{n})$. Note that when $\varepsilon&gt;n^{-1/2 + c}$, where $c&gt;0$, our lower bound matches the classic upper bound of AMS. For smaller values of $\varepsilon$ we also introduce a revised algorithm that improves the classic AMS bound and matches our lower bound. Our lower bound holds also for the more general problem of $p$-th frequency moment estimation for the range of $p\in (1,2]$, giving a tight bound in the only remaining range to settle the optimal space complexity of estimating frequency moments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02148v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mark Braverman, Or Zamir</dc:creator>
    </item>
    <item>
      <title>A Criterion for Quantum Advantage</title>
      <link>https://arxiv.org/abs/2411.02369</link>
      <description>arXiv:2411.02369v1 Announce Type: cross 
Abstract: Assuming the polynomial hierarchy is infinite, we prove a sufficient condition for determining if uniform and polynomial size quantum circuits over a non-universal gate set are not efficiently classically simulable in the weak multiplicative sense. Our criterion exploits the fact that subgroups of $\mathrm{SL}(2;\mathbb{C})$ are essentially either discrete or dense in $\mathrm{SL}(2;\mathbb{C})$. Using our criterion, we give a new proof that both instantaneous quantum polynomial (IQP) circuits and conjugated Clifford circuits (CCCs) afford a quantum advantage. We also prove that both commuting CCCs and CCCs over various fragments of the Clifford group afford a quantum advantage, which settles two questions of Bouland, Fitzsimons, and Koh. Our results imply that circuits over just $(U^\dagger \otimes U^\dagger) \mathrm{CZ} (U \otimes U)$ afford a quantum advantage for almost all $U \in \mathrm{U}(2)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02369v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chaitanya Karamchedu, Matthew Fox, Daniel Gottesman</dc:creator>
    </item>
    <item>
      <title>Constructibility, computational complexity and P versus NP</title>
      <link>https://arxiv.org/abs/2406.16843</link>
      <description>arXiv:2406.16843v2 Announce Type: replace 
Abstract: If an algorithm is to be counted as a practically working solution to a decision problem, then the algorithm must must verifiable in some constructed and ``trusted'' theory such as PA or ZF. In this paper, a class of decision problems related to inconsistency proofs for a general class of formal theories is used to demonstrate that under this constructibility restriction, there are plausible arguments for the existence of decision problems which can be proved formally to be in NP, and for which there exists an explicitly constructible algorithm recognizing correct solutions in polynomial time, but for which there exists no explicitly constructible, verifiable solution algorithm. While these arguments do not solve the P versus NP problem in the classical sense of supplying a proof one way or the other in a ``trusted'' formal theory, arguably they resolve a constructive version of it.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16843v2</guid>
      <category>cs.CC</category>
      <category>cs.LO</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arne Hole</dc:creator>
    </item>
    <item>
      <title>Local Quantum Search Algorithm for Random $k$-SAT with $\Omega(n^{1+\epsilon})$ Clauses</title>
      <link>https://arxiv.org/abs/2403.03237</link>
      <description>arXiv:2403.03237v2 Announce Type: replace-cross 
Abstract: The random k-SAT instances undergo a "phase transition" from being generally satisfiable to unsatisfiable as the clause number m passes a critical threshold, $r_k n$. This causes a drastic reduction in the number of satisfying assignments, shifting the problem from being generally solvable on classical computers to typically insolvable. Beyond this threshold, it is challenging to comprehend the computational complexity of random k-SAT. In quantum computing, Grover's search still yields exponential time requirements due to the neglect of structural information.
  Leveraging the structure inherent in search problems, we propose the k-local quantum search algorithm, which extends quantum search to structured scenarios. Grover's search, by contrast, addresses the unstructured case where k=n. Given that the search algorithm necessitates the presence of a target, we specifically focus on the problem of searching the interpretation of satisfiable instances of k-SAT, denoted as max-k-SSAT. If this problem is solvable in polynomial time, then k-SAT can also be solved within the same complexity. We demonstrate that, for small $k \ge 3$, any small $\epsilon&gt;0$ and sufficiently large n:
  $\cdot$ k-local quantum search achieves general efficiency on random instances of max-k-SSAT with $m=\Omega(n^{2+\delta+\epsilon})$ using $\mathcal{O}(n)$ iterations, and
  $\cdot$ k-local adiabatic quantum search enhances the bound to $m=\Omega(n^{1+\delta+\epsilon})$ within an evolution time of $\mathcal{O}(n^2)$.
  In both cases, the circuit complexity of each iteration is $\mathcal{O}(n^k)$, and the efficiency is assured with overwhelming probability $1 - \mathcal{O}(\mathrm{erfc}(n^{\delta/2}))$. By modifying this algorithm capable of solving all instances of max-k-SSAT, we further prove that max-k-SSAT is polynomial on average when $m=\Omega(n^{2+\epsilon})$ based on the average-case complexity theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.03237v2</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mingyou Wu</dc:creator>
    </item>
    <item>
      <title>Assembly Theory Reduced to Shannon Entropy and Rendered Redundant by Naive Statistical Algorithms</title>
      <link>https://arxiv.org/abs/2408.15108</link>
      <description>arXiv:2408.15108v5 Announce Type: replace-cross 
Abstract: We respond to arguments against our criticism that claim to show a divergence of Assembly Theory from popular compression. We have proven that any implementation of the concept of `copy number' underlying Assembly Theory (AT) and its assembly index (Ai) is equivalent to Shannon Entropy and not fundamentally or methodologically different from algorithms like ZIP compression. We show that the weak empirical correlation between Ai and LZW, which the authors offered as a defense against the proof that the assembly index calculation method is a compression scheme, is based on an incomplete and misleading experiment. When the experiment is completed, the asymptotic convergence to LZ compression and Shannon Entropy is evident and aligned with the mathematical proof previously offered. Therefore, this completes the theoretical and empirical demonstrations that any variation of the copy-number concept underlying AT, which resorts to counting the number of object repetitions `to arrive at a measure for life,' is equivalent to statistical compression and Shannon Entropy. We demonstrate that the authors' `we-are-better-because-we-are-worse' defense argument against compression does not withstand basic scrutiny and that their empirical results separating organic from inorganic compounds have not only been previously reported -- sans claims to unify physics and biology -- but are also driven solely by molecular length, not a particular feature of life captured by their assembly index. Finally, we show that Ai is a particular case of our BDM introduced almost a decade earlier and that arguments attributing special stochastic properties to Ai are misleading, not unique, and exactly the same as those that Shannon Entropy is already not only equipped with but designed for which we have also proven to be equivalent to Ai making AT redundant even in practice when applied to their own experimental data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.15108v5</guid>
      <category>cs.IT</category>
      <category>cs.CC</category>
      <category>math.IT</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luan Ozelim, Abicumaran Uthamacumaran, Felipe S. Abrah\~ao, Santiago Hern\'andez-Orozco, Narsis A. Kiani, Jesper Tegn\'er, Hector Zenil</dc:creator>
    </item>
    <item>
      <title>Constant congestion linkages in polynomially strong digraphs in polynomial time</title>
      <link>https://arxiv.org/abs/2409.03873</link>
      <description>arXiv:2409.03873v2 Announce Type: replace-cross 
Abstract: Given integers $k,c &gt; 0$, we say that a digraph $D$ is $(k,c)$-linked if for every pair of ordered sets $\{s_1, \ldots, s_k\}$ and $\{t_1, \ldots, t_k\}$ of vertices of $D$, there are $P_1, \ldots, P_k$ such that for $i \in [k]$ each $P_i$ is a path from $s_i$ to $t_i$ and every vertex of $D$ appears in at most $c$ of those paths. Thomassen [Combinatorica, 1991] showed that for every fixed $k \geq 2$ there is no integer $p$ such that every $p$-strong digraph is $(k,1)$-linked. Edwards et al. [ESA, 2017] showed that every digraph $D$ with directed treewidth at least some function $f(k)$ contains a large bramble of congestion $2$ and that every $(36k^3 + 2k)$-strong digraph containing a bramble of congestion $2$ and size roughly $188k^3$ is $(k,2)$-linked. Since the directed treewidth of a digraph has to be at least its strong connectivity, this implies that there is a function $L(k)$ such that every $L(k)$-strong digraph is $(k,2)$-linked. This result was improved by Campos et al. [ESA, 2023], who showed that any $k$-strong digraph containing a bramble of size at least $2k(c\cdot k -c + 2) + c(k-1)$ and congestion $c$ is $(k,c)$-linked. Regarding the bramble, although the given bound on $f(k)$ is very large, Masa\v{r}\'ik et al. [SIDMA, 2022] showed that directed treewidth $\mathcal{O}(k^{48}\log^{13} k)$ suffices if the congestion is relaxed to $8$. We first show how to drop the dependence on $c$, for even $c$, on the size of the bramble that is needed in the work of Campos et al. [ESA, 2023]. Then, by making two local changes in the proof of Masa\v{r}\'ik et al. [SIDMA, 2022] we show how to build in polynomial time a bramble of size $k$ and congestion $8$ assuming that a large obstruction to directed treewidth (namely, a path system) is given. Applying these results, we show that there is a polynomial function $g(k)$ such that every $g(k)$-strong digraph is $(k,8)$-linked.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03873v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>math.CO</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Raul Lopes, Ignasi Sau</dc:creator>
    </item>
    <item>
      <title>An Algorithm for a Variation of the Shortest Common Superstring Problem</title>
      <link>https://arxiv.org/abs/2410.23900</link>
      <description>arXiv:2410.23900v2 Announce Type: replace-cross 
Abstract: This study develops an algorithm to solve a variation of the Shortest Common Superstring (SCS) problem. There are two modifications to the base SCS problem. First, one string in the set S is allowed to have up to K mistakes, defined as not matching the SCS in at most K positions. Second, no string in S can be a substring of another in S. The algorithm proposed for the problem is exact.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23900v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arthur Gilfanov</dc:creator>
    </item>
  </channel>
</rss>
